{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n",
    "\n",
    "This is the third and final tutorial on doing “NLP From Scratch”, where we write our own classes and functions to preprocess the data to do our NLP modeling tasks. We hope after you complete this tutorial that you’ll proceed to learn how torchtext can handle much of this preprocessing for you in the three tutorials immediately following this one.\n",
    "\n",
    "In this project we will be teaching a neural network to translate from French to English.\n",
    "\n",
    "```\n",
    "[KEY: > input, = target, < output]\n",
    "\n",
    "> il est en train de peindre un tableau .\n",
    "= he is painting a picture .\n",
    "< he is painting a picture .\n",
    "\n",
    "> pourquoi ne pas essayer ce vin delicieux ?\n",
    "= why not try that delicious wine ?\n",
    "< why not try that delicious wine ?\n",
    "\n",
    "> elle n est pas poete mais romanciere .\n",
    "= she is not a poet but a novelist .\n",
    "< she not not a poet but a novelist .\n",
    "\n",
    "> vous etes trop maigre .\n",
    "= you re too skinny .\n",
    "< you re all alone .\n",
    "```\n",
    "\n",
    "… to varying degrees of success.\n",
    "\n",
    "This is made possible by the simple but powerful idea of the [sequence to sequence network](https://arxiv.org/abs/1409.3215), in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "To improve upon this model we’ll use an [attention mechanism](https://arxiv.org/abs/1409.0473), which lets the decoder learn to focus over a specific range of the input sequence.\n",
    "\n",
    "**Recommended Reading:**\n",
    "\n",
    "I assume you have at least installed PyTorch, know Python, and understand Tensors:\n",
    "\n",
    "* [https://pytorch.org/](https://pytorch.org/) For installation instructions\n",
    "* [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) to get started with PyTorch in general\n",
    "* [Learning PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) for a wide and deep overview\n",
    "* [PyTorch for Former Torch Users](https://pytorch.org/tutorials/beginner/former_torchies_tutorial.html) if you are former Lua Torch user\n",
    "\n",
    "It would also be useful to know about Sequence to Sequence networks and how they work:\n",
    "\n",
    "* [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
    "* [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "* [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "* [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)\n",
    "\n",
    "You will also find the previous tutorials on [NLP From Scratch: Classifying Names with a Character-Level RNN](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) and [NLP From Scratch: Generating Names with a Character-Level RNN](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html) helpful as those concepts are very similar to the Encoder and Decoder models, respectively.\n",
    "\n",
    "And for more, read the papers that introduced these topics:\n",
    "\n",
    "* [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
    "* [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "* [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "* [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)\n",
    "\n",
    "**Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data files\n",
    "\n",
    "The data for this project is a set of many thousands of English to French translation pairs.\n",
    "\n",
    "[This question on Open Data Stack Exchange](https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages) pointed me to the open translation site https://tatoeba.org/ which has downloads available at https://tatoeba.org/eng/downloads - and better yet, someone did the extra work of splitting language pairs into individual text files here: https://www.manythings.org/anki/\n",
    "\n",
    "The English to French pairs are too big to include in the repo, so download to ``data/eng-fra.txt`` before continuing. The file is a tab separated list of translation pairs:\n",
    "\n",
    "``\n",
    "I am cold.    J'ai froid.\n",
    "``\n",
    "\n",
    "**Note**\n",
    "\n",
    "Download the data from [here](https://download.pytorch.org/tutorial/data.zip) and extract it to the current directory.\n",
    "\n",
    "Similar to the character encoding used in the character-level RNN tutorials, we will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "We’ll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called ``Lang`` which has word → index (``word2index``) and index → word (``index2word``) dictionaries, as well as a count of each word ``word2count`` to use to later replace rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: data/eng-fra.txt        \n",
      "   creating: data/names/\n",
      "  inflating: data/names/Arabic.txt   \n",
      "  inflating: data/names/Chinese.txt  \n",
      "  inflating: data/names/Czech.txt    \n",
      "  inflating: data/names/Dutch.txt    \n",
      "  inflating: data/names/English.txt  \n",
      "  inflating: data/names/French.txt   \n",
      "  inflating: data/names/German.txt   \n",
      "  inflating: data/names/Greek.txt    \n",
      "  inflating: data/names/Irish.txt    \n",
      "  inflating: data/names/Italian.txt  \n",
      "  inflating: data/names/Japanese.txt  \n",
      "  inflating: data/names/Korean.txt   \n",
      "  inflating: data/names/Polish.txt   \n",
      "  inflating: data/names/Portuguese.txt  \n",
      "  inflating: data/names/Russian.txt  \n",
      "  inflating: data/names/Scottish.txt  \n",
      "  inflating: data/names/Spanish.txt  \n",
      "  inflating: data/names/Vietnamese.txt  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-07-02 15:32:54--  https://download.pytorch.org/tutorial/data.zip\n",
      "Resolving download.pytorch.org (download.pytorch.org)... 99.86.212.76, 99.86.212.109, 99.86.212.125, ...\n",
      "Connecting to download.pytorch.org (download.pytorch.org)|99.86.212.76|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2882130 (2.7M) [application/zip]\n",
      "Saving to: 'data.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1% 35.3M 0s\n",
      "    50K .......... .......... .......... .......... ..........  3% 3.24M 0s\n",
      "   100K .......... .......... .......... .......... ..........  5% 38.3M 0s\n",
      "   150K .......... .......... .......... .......... ..........  7% 22.6M 0s\n",
      "   200K .......... .......... .......... .......... ..........  8% 76.0M 0s\n",
      "   250K .......... .......... .......... .......... .......... 10% 22.7M 0s\n",
      "   300K .......... .......... .......... .......... .......... 12% 19.6M 0s\n",
      "   350K .......... .......... .......... .......... .......... 14% 20.9M 0s\n",
      "   400K .......... .......... .......... .......... .......... 15% 23.9M 0s\n",
      "   450K .......... .......... .......... .......... .......... 17% 79.2M 0s\n",
      "   500K .......... .......... .......... .......... .......... 19% 20.7M 0s\n",
      "   550K .......... .......... .......... .......... .......... 21% 24.3M 0s\n",
      "   600K .......... .......... .......... .......... .......... 23% 19.8M 0s\n",
      "   650K .......... .......... .......... .......... .......... 24%  113M 0s\n",
      "   700K .......... .......... .......... .......... .......... 26% 21.7M 0s\n",
      "   750K .......... .......... .......... .......... .......... 28% 19.0M 0s\n",
      "   800K .......... .......... .......... .......... .......... 30% 22.4M 0s\n",
      "   850K .......... .......... .......... .......... .......... 31% 20.0M 0s\n",
      "   900K .......... .......... .......... .......... .......... 33% 94.3M 0s\n",
      "   950K .......... .......... .......... .......... .......... 35% 15.3M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 37% 32.5M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 39% 22.6M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 40%  113M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 42% 22.3M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 44% 24.4M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 46% 21.9M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 47% 20.5M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 49% 90.9M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 51% 8.10M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 53%  109M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 55% 16.3M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 56% 21.9M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 58% 95.7M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 60% 21.1M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 62% 34.8M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 63% 22.5M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 65%  118M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 67% 23.0M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 69% 18.4M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 71% 44.9M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 72% 27.5M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 74% 96.7M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 76% 19.3M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 78% 26.6M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 79% 17.7M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 81%  117M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 83% 10.3M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 85% 88.6M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 87% 43.6M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 88% 30.3M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 90%  101M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 92% 21.8M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 94% 22.1M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 95% 17.9M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 97%  114M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 99% 13.0M 0s\n",
      "  2800K .......... ....                                       100%  223M=0.1s\n",
      "\n",
      "2020-07-02 15:32:55 (23.3 MB/s) - 'data.zip’ saved [2882130/2882130]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -r data\n",
    "rm data.zip\n",
    "wget -c https://download.pytorch.org/tutorial/data.zip\n",
    "unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. The files are all English → Other Language, so if we want to translate from Other Language → English I added the ``reverse`` flag to reverse the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we’re filtering to sentences that translate to the form “I am” or “He is” etc. (accounting for apostrophes replaced earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "* Read text file and split into lines, split lines into pairs\n",
    "* Normalize text, filter by length and content\n",
    "* Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['il est connu comme un grand peintre .', 'he is known as a great painter .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A [Sequence to Sequence network](https://arxiv.org/abs/1409.3215), or seq2seq network, or [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages.\n",
    "\n",
    "Consider the sentence “Je ne suis pas le chat noir” → “I am not the black cat”. Most of the words in the input sentence have a direct translation in the output sentence, but are in slightly different orders, e.g. “chat noir” and “black cat”. Because of the “ne/pas” construction there is also one more word in the input sentence. It would be difficult to produce a correct translation directly from the sequence of input words.\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some N dimensional space of sentences."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Decoder\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and outputs a sequence of words to create the translation.\n",
    "\n",
    "#### Simple Decoder\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
    "    \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encourage you to train and observe the results of this model, but to save space we’ll be going straight for the gold and introducing the Attention Mechanism."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAE8CAYAAACrTIieAAAgAElEQVR4Ae1dCbAcRf3mFMHiElABFcoClUMKSxEPFJCiBOSwQClASi1FOUoKRLC00CJljgIjoFHUglwk5JEQEkLuhOTlghzkIAe5Q0jIRQ4SSExe7v7X1/572bev3+5vunt6Z2a/rpo3Mz39O/rrb7/XM7M7c4hiIQJEgAgQARECh4hasRERIAJEgAgoCiZJQASIABEQIkDBFALFZkSACBABCiY5QASIABEQIkDBFALFZkSACBABCiY5QASIABEQIkDBFALFZkSACBABCiY5UHcErrnmGnXIIYdwIQZ15QB4WKtQMGshxOOpIwCxZCEC9UZAwkMytd6jxPh6VkEYiEC9EaBg1nsEGF+EgISoIkdsRAQ8EJDwkDNMD4BpGgYBCVHDRKIXItA+AhIeUjDbx49HIiEgIWqkVBimgRGQ8JCC2cAEyUrXJUTNSq7Mo7gISHhIwSzu+OemZxKi5qYzTDS3CEh4SMHM7fAWJ3EJUYvTW/YkqwhIeEjBzOroNVBeEqLmEY79+/ervXv3lpYs9cHkdvDgwSylVddcJDykYNZ1iBgcCEiImkekbrnllla/XDnyyCPVGWecoX7/+9+r999/v65duuuuu3RuAwcOrGseWQou4SEFM0sj1qC5SIiaR2iMYP785z9XTz/9tPrHP/6hTN15552ntm/fXrduUTDbQi/hIQWzLW6siYyAhKiRUwoSzojjs88+28rf9ddfr2d3Xbt21fU4Le7UqZOefZ500knq5ptvVps2bWpl06tXLwWRPf7449UPfvADNWLEiFbHH3vsMfW1r31NHXfcceo73/mOmj59eqvjo0eP1vYnnHCCgoD/9Kc/bTXD3Lhxo7rpppsUjp911lmqS5cuypyub9u2TZ1//vnqnnvuUb/85S/VySefrHr27NnKfxF2JDykYBZhpHPeBwlR89jF9gTz0Ucf1WJ19913625BLIHBJz7xCXXppZfq7QsvvLDU5eeee07XHX744eryyy9XRx11lDr66KPVmjVrdJuHH364dPwLX/iC3j7ssMPU66+/ro+vWLFCYR8xvvGNb6hTTjlFb2Mfp+QQRsTD/kUXXaTOPPNMvd25c2dtv2XLFr2PuGjzkY98RI0bN66UX1E20LdapXaLWh54nAh4IiAhqmeIupi3J5i9e/fWwoOn4+Dmy7HHHqsOPfTQ0qzy1ltv1cdfeeUVnfe5556r98eOHav3Mdv87ne/q15++WWFmSHw++hHP6pWrVqlj2N2iDqIK8pDDz2k93/xi1/o/R07dqhjjjlG10EwMVtF+yuuuEIfb2lp0ccx20V+RjDRBjnhUgLqi1bQv1qldotaHnicCHgiICGqZ4i6mLcnmH/729+0QP34xz9WK1eu1Ns4FX7ggQf0AjEEJk8++aTat2+fnh3ihhGErLIMHjxYty1/NNn69et1HUQRs0ecwsPfoEGDSuYQR9RBMHE6j+2LL764lMPpp5+u69auXVsSTJzuF7kAg1qldotaHnicCHgiICGqZ4i6mLcnmPfdd58Woz/96U8lwcQs88orr2y14Drhrl27dFtcu7SV/v376+O333576TBmgDgFP+KII/RM8Pvf/75uM2zYsFKbG2+8UddBMM0lAly7rMwBp/NmholT9SIXCQ8pmEVmQE76JiFqTrrSKk2bYL799tv6xgr6PGfOHN3+s5/9rL4mCXFEmTJlir5G+MEHH+j90047TYsbxAsFp+Jf/OIX1VNPPaXeeustfQzXJc1pspl1muugv/71r3WbP//5z9oes06cbiMHCCaudWIbN5tMgRDPnDlTHThwoCSYZ599tjlcyLWEhxTMQg59vjolIWq+evS/bI1gQmguueQS9aUvfUnh1Br9xV1qU+644w5dd/XVV2sRhJjh9Pedd97RTTp06KCP46bQ/fffrz7zmc/o/Xnz5unjl112md7HDZ8777xTX89EjBdeeEEfh/BhH9c5H3nkEfWtb31L76MOgglRPPHEE3Vuv/vd70rXPK+66iptb2aY8F/kAjxqldotanngcSLgiYCEqJ4h6mJuBBP9wwLBwswQp8C7d+8u5YQvsd9www2lO9nnnHOOwizRFFy7xPcmzZ1u+Hj88cfNYfXf//5X/fCHP9SzVMSB+P373/8uHcdGt27d9N1tHMed8gcffFDnBMFEmTFjhv46EY7jVB7XUdetW6ePUTA1DPoPBfNDLLhVJwTwIWVRWkRx17u9smfPHrVhw4b2DusbRLhJY74/WdkQ9u+++25ldat9iCMEuBGLhIdkaiMyI2N9lhA1YykznQIiIOEhBbOAA5+3LkmImrc+Md/8ISDhIQUzf+NauIwlRC1cp9mhzCEg4SEFM3PD1ngJSYjaeKiwx7ERkPCQghl7VBivDQISorYxYgURCIyAhIcUzMCg011yBCRETe6VFkQgGQISHlIwk2HK1ikgICFqCmHpkgi0QkDCQwpmK8i4Uw8EJEStR16M2VgISHhIwWwsTmSytxKiZjJxJlUoBCQ8pGAWasjz2RkJUfPZM2adJwQkPKRg5mlEC5qrhKgF7Tq7lSEEJDykYGZowBo1FQlRGxUb9jseAhIeUjDjjYdTJDxIob2HKTg5zKCRhKgZTJspFQwBCQ8pmBkf9DFjxqhnnnmm9L6WWOniqTYLFiyIEk5C1CiJMEhDIyDhIQUz4xSph2DiFa8QafPSrbQhkhA17RzonwhIeEjBzDhPKgUTL7KaOHGifjXBiy++qPr27atee+01/dRsdAVvDkSb5cuXq0mTJunjL730UumNhGgzdepU3Wbr1q269zjlhw3eHojXJAwYMEALJt6nXf7irLSgkhA1rdj0SwQMAhIeUjANWhldVwomZn4QMggl3g2NV7aibunSpboHWJe3gahiH+3MWweNT8wkUSCYaNOvXz+1c+dO9fzzz5dszBO504RHQtQ049M3EQACEh5SMDPOFSNu5p3TEDYsRuzmz5+v96dPn657YgQT4rd3715dh1Nr2MydO1fvG5/GR7lgogGuX6I9T8k1XPzTIAhQMAsw0EbcygUTs0VT8BZCiBveNIhiBHPChAmmiVq8eLFug1N0FOMzLcGcNWuWSrJce+21idon8R2zLV42lqUFN+3wygu85IylNgIUzNoYZb6FEbdywXzuuedKea9evbqmYOL1rBBVI6LGp3m/y759+/RxzEpRfGeYSUWqKIKZtN9pt588ebLCJRmMq3llb4k43GiDAAWzDST5qzDillQwm5qaSp3FTSEIJj6gKM3NzXrfvMb1vffeayWYmJXwlLwEX+438A8Tb5Gs9gK13HcyQAcomAFArLcLV8GE4A0dOlTfQe/Zs6fq0aOHwutcUWbPnq0FcciQIWrhwoX6Tnj37t31TATHcfcc9piZTJs2LfUvzkuIWu9xyHt8XLrBeOJsgsWOgISHvOljxy4zta6CiTvoeLc1hA/XPM1ddHQM78TGV43MMVzrwp1xc0qOm0DmOIQWXzVKs0iImmb8RvGNf6DmrKJR+pyknxIeUjCTIJqDtuamz+uvv66zxdeEIIC2AiFs7xja4/3UMW4YSIhqy591yRDA2cIbb7yRzKiBWkt4SMEsGCEqBTMP3ZMQNQ/9yHqO+Aoarmez2BGQ8JCCaccut7U45Ro2bJj+KlFeOiEhal76kuU8KZjVR0fCQwpmdQx5NAICEqJGSKPwISiY1YdYwkMKZnUMeTQCAhKiRkij8CEomNWHWMJDCmZ1DHk0AgISokZIo/AhKJjVh1jCQwpmdQx5NAICEqJGSKPwISiY1YdYwkMKZnUMeTQCAhKiRkij8CEomNWHWMJDCmZ1DHk0AgISokZIo/AhKJjVh1jCQwpmdQyDHsWXxG1fFK+sr9y3JVGrTa3jNp/1qpMQtV65FSkuBbP6aEp4SMGsjmHQo/hNN36OWPl7Xvz8EPX79+/X8caPH6/3169fb42PerRHu/bKq6++qtvgN8RZLxKiZr0PeciPgll9lCQ8pGBWxzDoUalg4svn+H03fppoKxRMGyqsq4UABbM6QhTM6vhEPyoVzBkzZugnCJkH/OI333gIB15NgQco4AlDlTPMtWvXaps+ffooPAcRDwtGm/IZJn5H3L9/f/16C8xOzSsrAEStdwWlCZaEqGnGbxTfFMzqIy3hIWeY1TEMetQIJl4ngYdjmAWPVqt2Sv7yyy/r43jGJR7JZtqbU/Lt27frx7fBBwQVDxg2bYxgQixxHE8kGj58uN7GE4lMwbFq7woy7dJYS4iaRtxG80nBrD7iEh5SMKtjGPSoEUyIk22xXcPcvHmzbgsRrDxuBBMzUvjDzBIF10jNy9EgmLgBBDHEtVIzqzQPEV63bp22MfmYWS0+XKgz7woKCkSFMwlRK0y464AABbM6aBIeUjCrYxj0qBHMt956S+HVEmYxs8FKQcS1SvN6CQicKeYdPUYwX3nlFS1uZjaJdiNHjizV7dixQ2/jdB0CiAWv1IUgvvnmm9ottqu9K8jElqyTvnqhKK+oCPU+H1y/xj/K0IWCWR1RCmZ1fKIfNYKZ5C75smXLtLDhXeSmQHAhcEYwzUOGyx8OiwcIow1E1AgmZpmjRo1qtZgHC6NttXcFmdiSdaMKZtJ+t9ceZwp4pYT5ZybBXNKGglkdJQpmdXyiH3URTPNCMtyUMcV8ZcgI5tSpU7U4zpkzxzTRN3aMYKISN3swgzSzWPjF6bh5FW9IwSwlIdyQEFXoqjDN8NIyiCberxSqUDCrIynhIU/Jq2MY9KiLYOL64wsvvKAFEaflEEvzvU0jmOY6Z69evfT7evA8THOab07T8RpeiOLo0aPVokWLtKBixmm+ukTBDDrUQZzhCenl/wR9nVIwqyNIwayOT/SjLoKJJLds2aIGDBigBa9v375qyZIletsIJtrgq0YQTAgf7pSbG0FGMDGTHDt2bEls8fpV8yZK2FMwo9OhZsDQAhfaX80O5KwBBTNnA1YrXbyfp1rB+3dqvbAMbcyd8mq+Yh6TEDVmPlmJFVrgQvvLCk6h8pDwkKfkodCmH2cEJER1dp5jw9ACF9pfjqG1pi7hIQXTCh0rYyIgIWrMfLISK7TAhfaXFZxC5SHhIQUzFNr044yAhKjOznNsGFrgQvvLMbTW1CU8pGBaoWNlTAQkRI2ZT1ZihRa40P6yglOoPCQ8pGCGQpt+nBGQENXZeY4NQwtcaH85htaauoSHFEwrdKyMiYCEqDHzyUqs0AIX2l9WcAqVh4SHFMxQaNOPMwISojo7z7FhaIEL7S/H0FpTl/CQgmmFjpUxEZAQNWY+WYkVWuBC+8sKTqHykPCQghkKbfpxRkBCVGfnOTYMLXCh/eUYWmvqEh5SMK3QsTImAhKixswnK7FCC1xof1nBKVQeEh5SMEOhTT/OCEiI6uw8x4ahBS60vxxDa01dwkMKphU6VsZEQELUmPlkJVZogQvtLys4hcpDwkMKZii06ccZAQlRnZ3n2DC0wIX2l2NoralLeEjBtELHypgISIgaM5+sxAotcKH9ZQWnUHlIeEjBDIU2/TgjICGqs/McG4YWuND+cgytNXUJDymYVuhYGRMBCVFj5pOVWKEFLrS/rOAUKg8JDymYodCmH2cEJER1dp5jw9ACF9pfjqG1pi7hIQXTCh0rYyIgIWrMfLISK7TAhfaXFZxC5SHhIQUzFNr044yAhKjOznNqOGHCBDV48GD9Lqfydy+5die0P9c8smwn4SEFM8sj2CC5SYjaIFDobi5YsEB16NCh1eLTf+PvL3/5i3r88ce1Xx9/RbWV8JCCWdTRz1G/JETNUXe8U8UbPjt16qSFDWu8XtmnhPbnk0uWbSU8pGBmeQQbJDcJURsEilI3m5qatGB27txZv2a5dMBxI7Q/xzQybSbhIQUz00PYGMlJiNoYSHzYy6VLl6ouXbqobt26fVjpsRXan0cqmTWV8JCCmdnha5zEJERtHDT+11O8Px7XMUeOHBmk66H9BUkqY04kPKRgZmzQGjEdCVEbERf2OS4CEh5SMOOOCaNZEJAQ1WLGKiIQFAEJDymYQSGnMxcEJER18UsbIpAEAQkPKZhJEGXbVBCQEDWVwHRKBMoQkPCQglkGGDfrg4CEqPXJjFEbCQEJDymYjcSIjPZVQtSMpl4zLXxpHEuWysGDB3VO+/fvz1Jadc9FwkMKZt2HiQlIiJpHlIYNG6bQNyz4LXdlgZA+/fTTavz48aVD69evV/fdd5/at29fqc53o9LnwIEDdU533XWXr+tC2Ut4SMEs1JDnszMSouaxZzfccENJMG+99dY2XXjggQf08X79+pWOnX766bou5Ky00ueyZcv0b8rHjRtXissNpXGvhQMFsxZCPJ46AkUUzA0bNqjDDjtMXXXVVeqCCy5QRxxxhNq8eXMJy969e6uPf/zj+kP66U9/Wv32t79Vt912m7YBHuedd54aM2aMbo/Z6Ve+8hX1sY99TF188cVq0qRJJT+/+c1v1Pnnn6+mTZumrrjiCnXssceqSy+9VK1YsUK3sfkcO3astunYsWPJD8TzuuuuUyeccII699xz1ZNPPqlw6o6CNWLcfvvtqn///vo4cr/nnnvUnj17Sj7yviHhIQUz76NcgPwlRM1bNx999FEthhDGxx57TG//9a9/LXWjR48eWpzQ90996lP6NPxHP/qROvTQQ3Xbz3/+82rUqFFq4cKFWkQhvt/73vfUUUcdpfcXLVqkfd100026/YknnqjF+ayzztL7V199tT5u81l5Sj516lTtF7mcc845pRz+8Ic/aB/4lRCOQbBPOukkdeONN6pjjjlG1/Xs2bPUp7xvSHhIwcz7KBcgfwlR89ZNCNeRRx6p3n//fbV69WotLmeffXarbtx77726vvyU/JOf/KSuM6fkP/vZz/T+f/7zH2370ksv6f1f/epXet8I5oMPPqj33377bX38tNNOK8Wq9FkpmJiRYgz++c9/apvFixdr0Tz88MMVrn8awUSbGTNm6DZ4VBz2McMtSpHwkIJZlNHOcT8kRM1T9yZOnKjF5KKLLlKTJ0/WC8QS/Sy/+SMRzK9+9ava7ic/+YnCNc+7775b73/zm9/UkBjBLP/NOeIcd9xxJciqCSaE2cxaIe6mXHLJJToO/BrBPProo81hZUT3jjvuKNXlfUPCQwpm3ke5APlLiJqnbuJaH/pkW2655ZZSVySCiWuX8PPtb39bXXnllaUFM08UI5gQaVMwM8S1TFOqCebu3bsV2uMU28xqYXfttdfquHjquxHMk08+2bhUQ4YM0ccpmCVIuEEE4iBQJMHctm2bnrFh1nbnnXeWFpxCQ5jKb/7cf//9WnT69u1bAvrUU0/VdRAylIceekjvY0aHsm7dOvXiiy8qnHqjGMEsvxFUKZiVPs3s0Hyt6Mtf/rKOYb7ehNiYTWJccEfdCOYpp5yiY+IPBbMEBTeIQFwEiiSYTz31lBaam2++uQ2I119/vT7WtWtXfeyPf/yj3r/88stL1w9xswd4QMxeffVVfacc+2eeeab6+9//ri677DJ9HDeNUCSCWemzUjBNzpiV4s735z73OR0DN4xQKJgaBv2Hp+QfYsGtOiFQJMG88MILtdjgVLayYGaIvuJ6Jr6qM2vWLH3nGXUQTRS8kgL7WP71r3/pOggsxAx1OC3GF9tNkQhmpc9KwYSvJ554QuFGEWJghoprpuaaJgXToK0UBfNDLLhVJwTwIW3UgtPfNWvWtOr+li1b1NatW1vVQWDXrl1b+m5kq4OCHZtPmxlO+Yv03UpbH9urk/CwcZnaHmqsj46AhKjRk2LAhkNAwkMKZsPRInsdlhA1e1kzo6IhIOEhBbNoo57D/kiImsNuMeWcISDhIQUzZ4NaxHQlRC1iv9mnbCEg4SEFM1tj1pDZSIjakMCw01ERkPCQghl1SBjMhoCEqDY71hGBkAhIeEjBDIk4fTkhICGqk+M6GA0YMECtWrXKKTIesYYHX7gUfKdz5syZLqZqyZIlyvXZmHiwCPpchCLhIQWzCCOd8z5IiJqHLi5fvlzZvrAuzR2PgtuxY4e0eat2PoKJmIjtWtBn9D3vRcJDCmbeR7kA+UuImvVu4ovleEwbvvjtUvBF9aamJhdTbeMjmHCA2JVflpcmg0fAoe/AIM9FwkMKZp5HuCC5S4ia9a7igb54h49rmT9/fqsnqSf14yuYeHgHcnAtw4cP1w87drXPgp2EhxTMLIxUg+cgIWqWIcLbF/v06aM2bdrknCaerm5eK+HixFcwERs5uBa8fgMY5PlNlBIeUjBdGUK7YAhIiBosWAqO5s2bp0aPHu3sGaeyePpQS0uLsw9fwURs5OBzWo13EM2dO9e5D/U2lPCQglnvUWJ8/YScvMKA1+Hihonr9T/0e+PGjfoJ5j4Y+AomYuMpRsjFteBZoMCi/EHErr7qYUfBrAfqjJkYAQlREzuNZAChMg/edQ05e/ZshReR+ZQQgokckItPaW5udv56k0/cELYSHnKGGQJp+vBCQEJUrwApGePRbHhr4vbt270iDB06VL8ozcdJCMHEdyqRi08BFsDEPDHex1dsWwkPKZixR4Xx2iAgIWobowxU4F3geMmZT8FNku7duyuc2vuUEIKJHJCL742bKVOmeM+YfbBwtZXwkILpii7tgiEgIWqwYIEc7dy5U8+ksPYpeHgw3o/jW0IIJnJALpUPNE6a265du4JgkzSub3sJDymYvijT3hsBCVG9gwR2gJklZpi+Zfr06UGu+YUSTPy8Ejn5FvgofzGbr78Y9hIeUjBjjARjVEVAQtSqDiIf/OCDD1SvXr2CXKcbNGiQ2rBhg3cPQgkmckFOvgWvuQBGwCovRcJDCmZeRrPAeUqImqXu4664791k9AeigmuGeMmYbwklmMgFOYV4rw8wcn2ohy8eLvYSHlIwXZClTVAEJEQNGtDDGb5vie8a+t6kQQorV65UI0aM8MjmQ9NQggmPyAm5+ZYQ31H1zSGJvYSHFMwkiLJtKghIiJpKYAen+EUPftkTouBucqhfxoQUTOSE3EIU/D7d5yeXIXKQ+pDwkIIpRZPtUkNAQtTUgidwjFfV9u3b1+vng+Xh+vfvr+AzRAkpmMgJuYUo+KklMAvVzxA5tedDwkMKZnvosT4aAhKiRkumSqCJEycGmxHiGiF+ux2qhBRM5ITcQlzHhC/MWIFd1ouEhxTMrI9iA+QnIWoWYMC1S99f9Zh+vPvuu14PGzZ+zBqCiSVUwUOBQ9y9Rz7ADNhlvUh4SMHM+ig2QH4SotYbBtzsCXWair7gCeW+v0EvxyS0YCK3ZcuWlYfw2gZ2Pg8o8QouNJbwkIIpBJPN0kNAQtT0oss8QzxCChxuHIX44rvJPrRgIrdQN7eQY2gBNv0OuZbwkIIZEnH6ckJAQlQnxwGNcB3O94lC5elA4FxfWlbux2yn4Q8+QxVgF+obAaFyqvQj4SEFsxI17kdHQELU6ElVBAw9g0tD4LIswPgSe8j8KoYnyK6EhxTMIFDTiQ8CEqL6+A9h22gCl/X+hhjTSh8SHlIwK1HjfnQEJESNnlRFwKwLSKPlVzE8QXYlPKRgBoGaTnwQkBDVx38I20YTpKz3N8SYVvqQ8JCCWYka96MjICFq9KQqAmZdQBotv4rhCbIr4SEFMwjUdOKDgISoPv5D2DaaIGW9vyHGtNKHhIcUzErUuB8dAQlRoydVETDrAtJo+VUMT5BdCQ8pmEGgphMfBCRE9fEfwrbRBCnr/Q0xppU+JDykYFaixv3oCEiIGj2psoATJkxQTU1Nelm1alXZEbdN+nPDLW0rCQ8pmGmPAv3XREBC1JpOUmqwYMEC1aFDh1aLTyj66+ADX6q2Eh5SMFMdAjqXICAhqsRPGm327t2rOnXqpAWzY8eOqrm52SsM/fnh5wV+DWMJDymYNUDk4fQRkBA1/Szaj4DTccwyIZghHoRLf+1jXc8jEh5SMOs5QoytEZAQtZ5QLV26VItl165dg6RBf0FgDO5EwkMKZnDY6TApAhKiJvUZsj3epIgZZqiH4NJfyNEJ50vCQwpmOLzpyREBCVEdXQczwxsQcf0xVKG/UEiG8yPhIQUzHN705IiAhKiOrmlGBMQISHhIwRTDyYZpISAhalqx6ZcIGAQkPKRgGrS4rhsCEqLWLTkGbhgEJDykYDYMHbLbUQlRs5s9MysKAhIeUjCLMto57oeEqDG619LSol8tu27dOiVd8Cpa2NkKXqU7duxYNXToUPGC9rCzlREjRqjTTz9dAS/pgvaws5XQ+YXGz5ZzmnUSHlIw0xwB+hYhICGqyJFnI4ifVCjL27X3/u6kYmmEFXa2klQsjajCzlZC5xcaP1vOadZJeEjBTHME6FuEgISoIkeejcpFMOm2LbQRQJe1zZ8RQJe1zZ9LXsbG5i8pZuXtbf5i10l4SMGMPSqM1wYBCVHbGKVQUf4BTrptS8eIi8va5s9FKI2NzZ9LXsbG5i8pZuXtbf5i10l4SMGMPSqM1wYBCVHbGKVQUf4BTrptS8eIi8va5s+In8va5s8lL2Nj85cUs/L2Nn+x6yQ8pGDGHhXGa4OAhKhtjFKoKP8AJ922pWPExWVt8+cilMbG5s8lL2Nj85cUs/L2Nn+x6yQ8pGDGHhXGa4OAhKhtjFKoKP8AJ922pWPExWVt82fEz2Vt8+eSl7Gx+UuKWXl7m7/YdRIeUjBjjwrjtUFAQtQ2RilUlH+Ak27b0jHi4rK2+XMRSmNj8+eSl7Gx+UuKWXl7m7/YdRIeUjBjjwrjtUFAQtQ2RilUlH+Ak27b0jHi4rK2+TPi57K2+XPJy9jY/CXFrLy9zV/sOgkPKZixR4Xx2iAgIWoboxQqyj/ASbdt6RhxcVnb/LkIpbGx+XPJy9jY/CXFrLy9zV/sOgkPKZixR4Xx2iAgIWoboxQqyj/ASbdt6RhxcVnb/Bnxc1nb/LnkZWxs/h94MMgAABeiSURBVJJiVt7e5i92nYSHFMzYo8J4bRCQELWNUQoV5R/gpNu2dIy4uKxt/lyE0tjY/LnkZWxs/pJiVt7e5i92nYSHFMzYo8J4bRCQELWNUQoV5R/gpNu2dIy4uKxt/oz4uaxt/lzyMjY2f0kxK29v8xe7TsJDCmbsUWG8NghIiNrGKIWK0L+FDv1bbf6WPIVBL3Mp4SEFswwwbtYHAQlRY2QW+mk7oZ8GxKcVpcsCCQ8pmOmOAb0LEJAQVeCGTYiAFwISHlIwvSCmcQgEJEQNEYc+iEA1BCQ8pGBWQ5DHoiAgIWqURBikoRGQ8JCC2dAUyUbnJUTNRqbMosgISHhIwSwyA3LSNwlRc9IVppljBCQ8pGDmeICLkrqEqEXpK/uRXQQkPKRgZnf8GiYzCVEbBgx2tG4ISHhIwazb8DCwQUBCVNOWayKQFgISHlIw00KffsUISIgqdtZgDXfu3Knuv/9+1dTU1GA9D99dCQ8pmOFxp8eECEiImtBl4Zvv379f9xFr4AfRZPFDQMJDCqYfxrQOgICEqAHCFMpFv3791Ne//nU1evRodfLJJ6tHHnlEPfHEE+qCCy5Qu3fvLlRfY3VGwkMKZqzRYJx2EZAQtV3jBj3QtWtXdfzxx+vZJfAzy0knnaRmz57doKj4dVvCQwqmH8a0DoCAhKgBwhTOxYEDB9Rtt92mxfKwww5Tr7zySuH6GLNDEh5SMGOOCGNZEZAQ1WrY4JWdO3fWYvnwww+rU089VZ155pkKT0hicUNAwkMKphu2tAqIgISoAcMVwtXBgwfVvffeq8455xy1d+9e9fzzz6szzjhDvf7664XoXz06IeEhBbMeI8OYrRCQELWVAXdKCGzdurW0ja8YsbgjIOEhBdMdX1oGQkBC1ECh6IYItIuAhIcUzHbh44FYCEiIGisXxmlcBCQ8pGA2Lj8y03MJUTOTLBMpLAISHlIwCzv8+emYhKj56Q0zzSsCEh5SMPM6ugXKW0LUAnWXXckoAhIeUjAzOniNlJaEqI2EB/taHwQkPKRg1mdsGLUMAQlRy5pzkwikgoCEhxTMVKCn0yQISIiaxB/bEgEXBCQ8pGC6IEuboAhIiBo0IJ0RAQsCEh5SMC3AsSouAhKixsjowPqJqmXIJWpn0+fEC9rDzlZmvt2iftJjvbrmb++IF7SHna1sGduiXjt3rRp//Crxgvaws5XNe1aoiVv+qUZv7CJe0B52trJ95Hi16DMXqbmHnCZe0B52WSgSHlIwszBSDZ6DhKgxIEoqlkZYYWcrScXSCCvsbCWpWBphhZ2tJBVLI6yws5WkYmmEFXZZKBIeigQTP/Rvb6l3R01e9c6D8d0RqCTqqlWrVIcOHVRzc7PasmWLu+OElkYAXda2UEYAXdY2f0YAXdY2f0YAXdY2f0YAXdY2f7HrKnloiy8SzB49eqhnnnnGuixYsMDmN1pd3759dV7RAkYMtGvXLjVt2jT9zypE2JkzZ6osLtddd12rvPB+Gghmx44d9dKtWzc1cuTIEBBU9eEilMbG5thFKI2NzZ+LUBobmz8XoTQ2Nn8uQmlsbP5i1wUXzEWLFqklS5a0WsqflhK7g4hXZMGEcOAfFWbRIcqsWbNUyAVP9jaLj99rr722VV54VBkE0yx47iO20y5G/FzWttyM+Lmsbf6M+Lmsbf6M+Lmsbf6M+Lmsbf5i1wUXTPPiJVtHpk+frgYNGqQ2bdqkZwPPPvusGj58uNq+fXup+b59+9Rrr72m33CHDwW2d+zYUTqOGdXkyZNV//79dZtJkya1eT8JPph4nwnaLF26tI1gtrS0qHHjxqk+ffqoF154Qc2dO7fkf+XKlTrHxYsX6zWOl8cvNVRKzZs3T7388svK9AP9MmX16tXafv78+aZKzwTRf5xCAidsT5kyRSEW4qC/5e1r+ZgwYYIyM3v4Wrt2rRbOqVOnamyQF97nsmKF/QJ8KbEcbFQSdeLEiVogO3XqpPuKccbTxdMuLkJpbGy5uQilsbH5cxFKY2Pz5yKUxsbmz0UojY3NX+y6Sh7a4ic6JYfA4RSxfDEiCpHCbAgzPnyQIRLYx7YpY8eO1XUQPIgRjptTLYjpSy+9VDpuZo4vvvhi6cMCwYFNz5491ahRo7SgdO/eXdeZGMbHkCFDtKiivRFNzJCx36tXL70899xz1tkbRBntIFgDBw4sbW/evFmHWb58ua7DPwlT8HoA2OCJ1+gLtiFq8IG+mjxhi1LLx/jx40uCiRzWrFmjIPjwi75DOIEj/Nd7lm8wcF3biIpLPXgwbsxixM9lbcvTiJ/L2ubPiJ/L2ubPiJ/L2ubPiJ/L2uYvdp2Nh5U5JBJMfFgrF/OGOiOYM2bM0DEwc0Nb877kbdu26X18yI3IYhYFOzz41IgZBBbHITrDhg3TNpiloWBWCZ+YbaG8/fbbeh91KO+8847eNyIMP71799YijtNaEwM5wf+ePXu0XfkfzFDhD6JqZp8QXNSNGDFCN60ldkYwYYOcUJYtW6Z9QNBRavlAG2AFH+aUHCKKfeCBGO+99572b8ZAO87hHwlRY9wIchFKY2OD3UUojY3Nn4tQGhubPxehNDY2fy5CaWxs/mLXSXiYSDBxGgmxKl/Mh9kIJmZCpmBWhVkWipkdoZ2t4I4oxADCYsqbb76p63BqjlMy+IOQmdMzCIWZucEGp9HwgRkdZn9YzHXAclHGqXJ7BR9M+BgzZkypCS4VoA7ii2ITOzN7Lp9hon1lrlIfiFMpmBBK5IEFM0vMNN96661Sni4bWbgJVHnTx5YTxjHtG0FG/FzWNuyN+Lmsbf6M+Lmsbf6M+Lmsbf6M+Lmsbf5i1wUXTDMztHXECOaGDRtKh/GhNoJpRKY9sTL2EGVTjA3EFLEhFBBMU1CHGKhHMYKJywEQk/IF11LNDLPae08gQPCH62im4NQQcXApAP8gTF64NGEKZsawqxRM8w/F5AofKLV8oE2lYBq7oUOHlvqNmD6i6XOzxmZrbgJhbTtuq6u86WNrE+NGkItQGhs9qBV/XITS2FS40rsuQmlsbP5chNLY2Py5CKWxsfmLXZcpwdy4caMWFHNKCjAgnvjw4xqcOe199dVXSziZWae5BmkE5P3339dt1q9fr30awcQ1Rmzj1NUUiIm59mgEEx/I9gqEFT7Kr2+aWefgwYO1mdnHzNcUc62zXDDhB/1GwT8S7KMdSi0faGNmx2aWiv4uXLhQ//PA5YQ5c+Zon5jd5rlIiBrjRpARP5e1DX8jfi5rmz8jfi5rmz8jfi5rmz8jfi5rm7/YdRIeJjolh7jhumL5gg8tipkhtjfDRBvc7YVowA+EEbM23NRBgQjizjZOsXEDxczYcPPHXKPDzBD2EC7MYCCg5afk8IP2mMWhLa6nor258WQEE7bVCq5VGnFDnpjVYh+XFVDM9VicXuOyAYTd5FEpmMgReRjxM+JfywfiGBFGDvCLGS3yQDxcv8U1YOyb68bV+pTlYxKiIv+0bwS5CKWxseHrIpTGxubPRSiNjc2fi1AaG5s/F6E0NjZ/seskPEwkmPhwVi7m1FUimBBFc3ccYglhghCYgpkgxNCID7bLf+mBU2NzNxr2EArcDUdOpuDrP+YOPYQTMczb9KSCiRsq6A8EEb4hwubGk4mD66PIAblihofZMtqWCyZEEvVogwUCV35Zo5oPxHnjjTdKeCN35AUfmP0i1oABA/Td8th3kw0GodYSotpiYZaO65r4B1LOE1tbSZ0RP5e1zb8RP5e1zZ8RP5e1zZ8RP5e1zZ8RP5e1zV/sOgkPRYIZOnGcTlb7kOOY7Q62yQMzTohHtSJpU80ex3D90YitrS1ysPUD9RA03NVHqdbf9nyYeOiHDQvciEqr2G66pFknueljix/6RhB/Sy57CAd/S57WJ69B/VYKZt5gsN108amrdSNIctPHFj/0jSA+rai2YPJpRXn7NOcgX5x24zpv+c2nHKRdtxQlp0K25GLcCLLFZV0xEZDwsC6n5MWEm71yRUBC1PZ8p30jqL24rC8eAhIeUjCLN+6565GEqLnrFBPOHQISHlIwczesxUtYQtTi9Zo9yhoCEh5SMLM2ag2Yj4SoDQgLuxwZAQkPKZiRB4Xh2iIgIWpbK9YQgbAISHhIwQyLOb05ICAhqoPboCb4hZb5lVYIx/QXAsWwPiQ8pGCGxZzeHBCQENXBbVAT8z3QUE7pLxSS4fxIeEjBDIc3PTkiICGqo+tgZhQ4PyhD4+eXjd1awkMKph071kZEQELUiOlYQ4X+wNOfFea6Vkp4SMGs6xAxOBCQELXeSFHg/EYgNH5+2ditJTykYNqxY21EBCREjZiONVToDzz9WWGua6WEhxTMug4RgwMBCVHrjRQFzm8EQuPnl43dWsJDCqYdO9ZGREBC1IjpWEOF/sDTnxXmulZKeEjBrOsQMTgQkBC13khR4PxGIDR+ftnYrSU8pGDasWNtRAQkRI2YjjVU6A88/VlhrmulhIcUzLoOEYMDAQlR640UBc5vBELj55eN3VrCQwqmHTvWRkRAQtSI6VhDhf7A058V5rpWSnhIwazrEDE4EJAQtd5IUeD8RiA0fn7Z2K0lPKRg2rFjbUQEJESNmI41VOgPPP1ZYa5rpYSHFMy6DhGDAwEJUeuJFF5tjDdUYsGrfX0L/fkimI69hIcUzHSwp9cECEiImsBd0KZ4ZxDefV6++ASgvw4+8KVqK+EhBTPVIaBzCQISokr8pNEG753v1KmTFkysm5ubvcLQnx9+XuDXMJbwkIJZA0QeTh8BCVHTz6L9CDgVxwyzc+fOasuWLe03FB6hPyFQkZtJeEjBjDwoDNcWAQlR21rFq1m6dKnq0qWL6tatW5Cg9BcExuBOJDykYAaHnQ6TIiAhalKfIdsfOHBAzzBHjhwZxC39BYExuBMJDymYwWGnw6QISIia1CfbE4GkCEh4SMFMiirbB0dAQtTgQemQCFQgIOEhBbMCNO7GR0BC1PhZMWKjISDhIQWz0ViRwf5KiJrBtJlSwRCQ8JCCWbBBz2N3JESN0q/9e9TBls3q4K6N8qVls1L791jT27R9v2peslONXLBDvKA97Gxly9gW9dq5a9X441eJF7SHna207P9ArW9ZqNbsekO8oD3sbOVgy261d8MmtXfdu/JlwyYFuywUCQ8pmFkYqQbPQULUGBAlFksjrBBNS0kqlkZYYWcrScXSCCvsbCWpWBphhZ2tJBZLI6wbNtncRa+T8JCCGX1YGLASAQlRK23S2E80szRi+f9rWz5GAF3WNn9GAF3WNn9GAF3WNn+JZpZGLP9/bfMXu07CQwpm7FFhvDYISIjaxiiFCgqm/NTcBj8F04YK64hAYAQomG2vcdogdplZGhubP5eZpbGx+aNg2lBhHREIjAAFk4IZmFJO7iQ85Cm5E7Q0ComAhKgh47Xni6fkPCVvjxumnoJpkOC6bghQMDnDrBv5ygJLeEjBLAOMm/VBQELUGJlxhskZZi2eUTBrIcTjqSNAweQMM3WSCQJIeEjBFADJJukiICFquhn8zztnmJxh1uIZBbMWQjyeOgIUTM4wUyeZIICEhxRMAZBski4CEqKmm8H/vHOGyRlmLZ5RMGshxOOpI5AZwUz64A3z80j+llxzhL8lT/2jwgBEIEPvJefTimo+tYhPK+InlgjUGYGszDDrDAPD1xkBCQ95Sl7nQWL4DM0wORgNjQAFs6GHPz+dlxA1P71hpnlFQMJDzjDzOroFyltC1AJ1l13JKAISHlIwMzp4jZSWhKiNhAf7Wh8EJDykYNZnbBi1DAEJUcuac5MIpIKAhIcUzFSgp9MkCEiImsQf2xIBFwQkPKRguiBLm6AISIgaNCCdEQELAhIeUjAtwLEqLgISosbNiNEaEQEJDymYjciMjPVZQtR6p7x69Wo1YMCAYGksWbJEjRs3Lpg/OJo1a5aaOXNmEJ/IbfHixUF8wQmwW7VqVTB/aTiS8JCCmQby9JkIAQlREzlMqfHgwYPV8uXLg3jfsWOH6t27dxBfxklIwURuyDFEAWbALutFwkMKZtZHsQHykxA1CzCsX79e9evXTx08eDBIOk1NTWrr1q1BfMFJKMFETsgtRAFWwAzYZb1IeEjBzPooNkB+EqJmBYbhw4erhQsXBkln0qRJav78+UF8wUkowUROyC1EWbRokRo2bFgIV6n7kPCQgpn6MDBALQQkRK3lI9bxzZs3qz59+qj9+/d7h1yxYoUaNWqUtx/jIJRgIifk5luAEbDatGmTr6so9hIeUjCjDAWDVENAQtRq9rGPjRkzRs2dO9c7bEtLi+rRo0ewU/wQgolTaOSE3HzLvHnz1OjRo33dRLOX8JCCGW04GKg9BCREbc+2HvXbtm3TN2z27t3rHX7gwIFq48aN3n7gIIRgIhfk5Fv27dunMQp5jdY3p1r2Eh5SMGuhyOOpIyAhaupJJAzQ3Nwc5Cs8U6dOVbNnz04Y3d48hGAiF+TkW5DL+PHjfd1EtZfwkIIZdUgYzIbANddc06Z6zpw5CktlyUr99u3bVc+ePbVo+uSJ73cOHTpU99XHD3CCSOGmlI8f5IKcfHDevXu3xgYY+fgpH/sYfh588MHykNZtCqYVFlYSgdoITJkyxXs2hlPX7t27B7mJ5DvDxE0a5IKcfMq0adPU5MmTfVxk1paCmdmhYWJZR2DXrl16JrVz506vVIcMGaLWrFnj5QPGvoKJHJCLTwEWmHn7YuKTQ5q2FMw00aXvwiMwffp07+8s4ueM8ONbfAUTOfj+tBIzS8wwi1oomEUdWfYrCgJ79uxRvXr1Uh988IFzvA0bNqhBgwY52xtDX8FEDsjFtQADYIFrmEUtFMyijiz7FQ0B3Fn2eZDGgQMH9LVDiK9P8RFMxMb1S+TiWnBXPNQdf9cc0rajYKaNMP0XHoEQ3zkcMWKEWrlypRdWPoKJ2MjBteD7lnhgh+8NI9f4sewomLGQZpxCI4DfX/v8zBG/HMJdd5/iI5iI7fPrJfyiB7/sKXqhYBZ9hNm/KAjgJ4V9+/ZVW7ZscYoHu/79+zvZGiMfwURsn9zR91BPcTL9yeKagpnFUWFOuUQAM7SJEyc6547fcPtcx3QVTMREbNeCPvvMTl3j1sOOglkP1BmzkAjgly0+DwXGQ3Z97lJDMLEkLe+++67XA37RZ/S9EQoFsxFGmX2MhgBObV0fOIG7zMuWLXPO1VUw8UR01999o6++lxKcO1wHQwpmHUBnyOIi4CN6+MK3z40TV8FETNcvm0PgXcU2jyygYOZx1JhzZhHAk35cr+e5Cp4BA/Yuv9TBdydd7BAXfQ3xdCPTh6yvKZhZHyHmlysEfMTHVfAMQK72rnaIC1ssjVIomI0y0uxnFAR8xcd1pofOucZ2tfOJGWUwUghCwUwBVLpsXATqKT6usV3tMMo+tnlkCQUzj6PGnDOLgI+A+NgCEFd7VzufmJkdwBqJUTBrAMTDRCAJAvUUH9fYrnbAxcc2Ca5ZaUvBzMpIMI9CIOAjID62AM/V3tXOJ2ZeB5uCmdeRY96ZRKCe4uMa29UOA+Bjm8kBrJEUBbMGQDxMBJIg4CMgPrbI0dXe1c4nZhJMs9SWgpml0WAuuUZgwoQJqqmpSS+rVq1K1BdfW2M/ZsyYqHFd+5soyQw1pmBmaDCYSn4RWLBggerQoUOrRdqbRrOV4pLFdhTMLI4Kc8odAnv37lWdOnXSgtmxY0fV3Nws7kNI2379+tUlbpL+ihPMYEMKZgYHhSnlEwGcnmKWCcFM+jDeULZJn8cZKm7S/uZzhJWiYOZ15Jh35hBYunSpFsuuXbsmzs3XtkuXLgpxk/600jcu/jm49DcxQBkxoGBmZCCYRv4RwBsXMcN0eYhwCNtnn302sWCGiOvS37yONgUzryPHvDOJAN6aiGuSLsXHFvFc7V3tfGK64JMFGwpmFkaBORABIpALBCiYuRgmJkkEiEAWEKBgZmEUmAMRIAK5QICCmYthYpJEgAhkAQEKZhZGgTkQASKQCwQomLkYJiZJBIhAFhCgYGZhFJgDESACuUCAgpmLYWKSRIAIZAEBCmYWRoE5EAEikAsE/g/LjuMqjAyPNwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Decoder\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder, that single vector carries the burden of encoding the entire sentence.\n",
    "\n",
    "Attention allows the decoder network to “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs. First we calculate a set of *attention weights*. These will be multiplied by the encoder output vectors to create a weighted combination. The result (called ``attn_applied`` in the code) should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward layer ``attn``, using the decoder’s input and hidden state as inputs. Because there are sentences of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        print(\"embedded size\")\n",
    "        print(embedded.size())\n",
    "        print(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        print(\"attn_weights size\")\n",
    "        print(attn_weights.size())\n",
    "        print(attn_weights)\n",
    "        \n",
    "        print(\"encoder_outputs size\")\n",
    "        print(encoder_outputs.size())\n",
    "        print(encoder_outputs)\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        print(\"attn_aplied size\")\n",
    "        print(attn_applied.size())\n",
    "        print(attn_applied)\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "There are other forms of attention that work around the length limitation by using a relative position approach. Read about “local attention” in [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Preparing Training Data\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[210],\n",
      "        [211],\n",
      "        [180],\n",
      "        [  5],\n",
      "        [  1]], device='cuda:0')\n",
      "tensor([[129],\n",
      "        [ 78],\n",
      "        [115],\n",
      "        [  4],\n",
      "        [  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_tensor, target_tensor = tensorsFromPair(random.choice(pairs))\n",
    "print(input_tensor)\n",
    "print(target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the ``<SOS>`` token as its first input, and the last hidden state of the encoder as its first hidden state.\n",
    "\n",
    "“Teacher forcing” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster but [when the trained network is exploited, it may exhibit instability](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - intuitively it has learned to represent the output grammar and can “pick up” the meaning once the teacher tells it the first few words, but it has not properly learned how to create the sentence from the translation in the first place.\n",
    "\n",
    "Because of the freedom PyTorch’s autograd gives us, we can randomly choose to use teacher forcing or not with a simple if statement. Turn ``teacher_forcing_ratio`` up to use more of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "* Start a timer\n",
    "* Initialize optimizers and criterion\n",
    "* Create set of training pairs\n",
    "* Start empty losses array for plotting\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (% of examples, time so far, estimated time) and average loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values ``plot_losses`` saved while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder’s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder’s attention outputs for display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating\n",
    "\n",
    "With all these helper functions in place (it looks like extra work, but it makes it easier to run multiple experiments) we can actually initialize a network and start training.\n",
    "\n",
    "Remember that the input sentences were heavily filtered. For this small dataset we can use relatively small networks of 256 hidden nodes and a single GRU layer. After about 40 minutes on a MacBook CPU we’ll get some reasonable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "If you run this notebook you can train, interrupt the kernel, evaluate, and continue training later. Comment out the lines where the encoder and decoder are initialized and run ``trainIters`` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7472e-02,  4.0022e-01, -9.6455e-01, -6.8092e-01,  3.7529e-01,\n",
      "          -2.0166e-01,  1.4643e+00,  0.0000e+00, -3.5829e+00,  9.0700e-01,\n",
      "           4.2786e-01, -6.2946e-01,  2.6014e+00, -6.3073e-01, -5.4134e-01,\n",
      "          -1.5811e-01,  8.5166e-01,  0.0000e+00,  4.5522e-01,  4.3629e-01,\n",
      "          -6.3291e-01,  0.0000e+00,  1.6394e+00,  1.5113e+00,  7.5305e-01,\n",
      "           0.0000e+00, -1.8859e-01, -7.6042e-01,  1.6533e+00,  8.6126e-01,\n",
      "           1.2313e+00,  1.2194e+00, -1.0340e+00, -8.3093e-02, -1.5341e+00,\n",
      "           1.3956e+00,  2.8036e-01,  0.0000e+00,  1.9775e-01,  1.5996e+00,\n",
      "          -4.5892e-01, -1.3979e+00, -2.6939e-01, -1.7137e+00, -1.5230e+00,\n",
      "           6.6836e-01,  0.0000e+00,  3.7149e-01, -1.3401e+00,  0.0000e+00,\n",
      "          -6.2931e-01,  2.7501e+00,  6.0995e-01, -1.0282e+00, -2.4795e-02,\n",
      "           2.0437e-01, -8.8097e-01, -1.2503e+00, -2.3763e-01, -4.2657e-01,\n",
      "           1.0982e+00,  1.4065e+00, -2.0186e-01, -5.0092e-01, -2.9618e+00,\n",
      "           5.5184e-01,  1.2775e+00, -1.2871e+00,  4.0926e-01,  0.0000e+00,\n",
      "          -1.2663e+00, -2.9246e-02,  7.0733e-01, -3.6387e+00,  3.2454e-01,\n",
      "          -4.0456e-04, -1.6019e-01,  1.0609e+00, -5.7071e-02, -1.1734e-01,\n",
      "          -1.3994e+00,  2.1291e+00, -9.2385e-01,  1.0060e+00,  0.0000e+00,\n",
      "           4.3693e-01,  1.6610e+00,  0.0000e+00, -1.0477e-01, -5.8113e-01,\n",
      "          -2.2717e+00,  1.0995e+00, -6.2226e-01, -1.1360e+00,  4.6659e-01,\n",
      "          -1.1696e+00,  3.2052e-02,  6.2871e-01,  1.7191e+00, -7.7756e-01,\n",
      "           2.6965e+00, -1.4610e+00,  1.0759e+00,  1.4520e+00, -6.6592e-01,\n",
      "          -7.6187e-01,  1.2103e+00,  1.2751e-01, -1.4729e+00, -1.4216e-02,\n",
      "          -2.4784e-01,  1.3379e-01, -1.0467e+00,  1.3102e+00, -1.6522e+00,\n",
      "          -2.9873e+00, -5.7056e-02, -4.9871e-01, -1.9350e-01,  0.0000e+00,\n",
      "          -1.4642e+00,  7.0177e-01,  0.0000e+00, -7.2547e-01, -9.5733e-01,\n",
      "          -1.3065e+00,  8.9493e-01,  1.6938e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -8.2438e-01,  5.3135e-01, -1.5823e+00,  9.8390e-01,  2.7646e-01,\n",
      "          -5.8898e-01,  6.5783e-01,  5.7592e-01, -1.1593e+00,  0.0000e+00,\n",
      "          -3.8765e-01,  0.0000e+00, -7.8890e-01, -1.0028e-01, -1.6841e+00,\n",
      "          -9.9882e-02, -5.4263e-01, -8.4414e-01, -7.5438e-01,  1.7771e-01,\n",
      "           1.9971e+00, -1.9905e-01, -1.9292e+00, -4.0627e-01,  4.4122e-01,\n",
      "          -1.9451e-01, -6.5221e-02, -1.3082e-01,  3.8573e-02,  5.3727e-01,\n",
      "          -2.6712e-02,  2.2062e+00,  4.8114e-01, -5.5091e-01, -5.2522e-01,\n",
      "          -8.9048e-01,  2.8170e-01,  8.2460e-02, -3.5830e-01,  0.0000e+00,\n",
      "           7.3560e-01, -3.0175e-02,  0.0000e+00, -1.0034e+00,  1.2773e+00,\n",
      "          -1.0974e+00,  0.0000e+00, -2.0745e+00,  1.9677e+00,  8.6282e-02,\n",
      "          -3.1236e-02,  3.5045e-02,  6.7053e-01,  9.8015e-01, -7.4824e-01,\n",
      "          -3.4117e-01, -2.7810e+00, -7.8220e-01,  1.2088e+00,  1.0127e+00,\n",
      "           0.0000e+00,  4.9373e-01, -1.4453e-01,  0.0000e+00,  5.5938e-01,\n",
      "           2.1637e+00, -1.1871e+00,  5.3487e-01,  1.8109e+00, -9.4569e-01,\n",
      "          -1.6626e+00,  0.0000e+00,  1.2423e+00, -1.2230e-01,  2.3205e-01,\n",
      "          -5.7435e-01, -2.2915e+00,  6.8189e-01, -1.0724e+00, -4.7147e-01,\n",
      "           2.8672e+00, -5.7306e-01,  0.0000e+00,  7.9238e-01,  3.2773e-02,\n",
      "          -6.8290e-01, -1.0163e+00,  9.6711e-01, -2.4513e-01,  2.1680e+00,\n",
      "          -1.0828e+00, -4.2655e-01, -1.8431e+00,  0.0000e+00,  3.4019e-01,\n",
      "           7.0473e-01, -6.9675e-01, -6.2814e-01,  2.9222e-01, -1.5771e+00,\n",
      "          -1.1078e+00,  1.5811e+00, -6.1360e-01,  1.3104e+00, -2.9784e+00,\n",
      "           4.0329e+00,  5.8494e-01,  4.2515e-02,  0.0000e+00, -2.8564e-01,\n",
      "           7.4219e-01, -3.2458e+00, -3.0327e-01, -8.5143e-01,  1.1379e-02,\n",
      "           2.7594e-01,  2.7466e-01,  0.0000e+00,  2.6161e-01,  3.8696e-01,\n",
      "          -3.6573e-01, -1.6002e-01, -5.5289e-01, -5.1725e-02, -1.1459e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0696, 0.0734, 0.0727, 0.0577, 0.1066, 0.2150, 0.1023, 0.0810, 0.0801,\n",
      "         0.1417]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2663,  0.0089, -0.0874,  ...,  0.1464,  0.0284,  0.0604],\n",
      "        [ 0.0741, -0.1391, -0.0497,  ...,  0.3278,  0.2387, -0.0089],\n",
      "        [ 0.1325,  0.4101, -0.1348,  ..., -0.3434,  0.2340, -0.1407],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0775e-01,  8.6845e-02, -1.9430e-01,  1.8667e-01, -2.5816e-02,\n",
      "          -4.4985e-02,  1.7265e-02, -1.6385e-02,  4.8715e-02, -3.8471e-02,\n",
      "           3.6743e-02, -6.8085e-02, -5.1629e-02,  5.7424e-02,  3.8630e-02,\n",
      "          -1.0493e-03,  1.7701e-01,  1.2421e-02, -8.7035e-02,  1.2590e-01,\n",
      "           8.4243e-02,  3.3816e-02,  1.3509e-01, -9.0675e-03,  7.1872e-03,\n",
      "           1.6762e-01, -3.6524e-02, -2.1758e-01,  1.7271e-02,  1.3586e-01,\n",
      "           9.6100e-02, -8.4004e-02,  8.8515e-02, -9.3707e-02,  1.4093e-01,\n",
      "           3.3240e-02, -1.0710e-01, -3.6040e-02, -1.5084e-01,  1.9067e-01,\n",
      "          -1.1305e-02, -7.3846e-03, -8.9415e-02, -1.2812e-01,  9.3736e-05,\n",
      "           1.7396e-01,  7.3221e-02,  1.8843e-02, -3.3494e-02, -3.3318e-02,\n",
      "           1.4157e-01,  3.0147e-02, -1.9559e-01, -3.8278e-02,  4.9675e-02,\n",
      "           2.2964e-02,  6.5363e-02,  9.0687e-02, -6.5521e-02, -7.0177e-02,\n",
      "          -7.8122e-02,  5.3461e-02,  2.6284e-02,  1.2707e-01,  1.2342e-01,\n",
      "          -2.2201e-02, -1.9231e-02,  1.8611e-01, -3.4901e-02,  1.8475e-01,\n",
      "          -5.4918e-02,  1.7089e-01,  5.8828e-02,  6.4940e-02, -9.1286e-02,\n",
      "          -8.9474e-02, -5.1477e-02,  5.8981e-02, -5.7358e-03,  6.5445e-02,\n",
      "          -1.3993e-02, -9.4372e-02, -1.6658e-01, -5.7304e-02, -9.1215e-02,\n",
      "          -1.8374e-02, -1.5938e-02,  7.7979e-02,  6.7639e-02,  3.1087e-02,\n",
      "          -3.4385e-02,  2.7886e-03,  4.8023e-02, -2.4626e-02, -7.3565e-02,\n",
      "           6.5507e-02, -4.0980e-03,  2.3245e-01,  1.0829e-01,  2.2281e-01,\n",
      "          -9.6280e-02,  7.5876e-02,  1.7017e-02,  9.3553e-02, -1.5931e-01,\n",
      "          -1.7069e-01,  5.6522e-02,  7.8310e-02, -1.7589e-01,  5.2173e-02,\n",
      "           1.1657e-01,  4.3544e-02,  6.4416e-02, -1.6019e-01, -4.7119e-02,\n",
      "          -2.2075e-01,  9.4548e-02,  7.3350e-02, -7.1947e-02, -1.0213e-01,\n",
      "           5.7803e-02, -2.4273e-02, -5.0401e-02,  1.0515e-01,  1.6694e-02,\n",
      "          -3.8417e-02,  2.4781e-01, -1.2556e-01,  1.1085e-01, -6.4852e-02,\n",
      "          -5.9089e-03, -1.5750e-02,  2.3250e-02,  1.8593e-01,  3.7101e-02,\n",
      "          -1.3307e-02,  2.8127e-01, -1.9374e-02,  4.1024e-02, -1.4807e-02,\n",
      "           8.2108e-02,  8.3991e-02,  4.2785e-02,  5.7095e-02,  1.5999e-01,\n",
      "          -2.5968e-02,  1.9511e-02, -2.3565e-02,  1.6388e-01, -6.4616e-02,\n",
      "          -1.2111e-01,  1.2646e-01,  2.3415e-02,  1.4952e-01,  9.1109e-02,\n",
      "           1.4105e-01, -5.2584e-02,  7.4338e-02, -1.1025e-01,  1.1054e-02,\n",
      "          -4.2708e-02, -1.5971e-01, -1.8164e-01,  2.3115e-01, -1.2233e-03,\n",
      "           1.5956e-02,  1.1778e-03, -1.3145e-01, -4.9551e-02,  3.6751e-02,\n",
      "           4.3791e-03,  8.9206e-03,  9.3536e-02, -3.9235e-02, -6.5084e-02,\n",
      "          -8.1493e-02,  2.2856e-01,  1.4215e-01,  1.4661e-01, -1.4337e-03,\n",
      "          -1.4275e-02, -8.1346e-02,  1.2932e-01, -5.7943e-02,  1.0418e-02,\n",
      "           3.8469e-02, -5.3072e-02,  1.3048e-01,  2.0377e-02, -7.2801e-02,\n",
      "           7.6825e-02,  8.5238e-02, -1.5816e-01, -2.8253e-02,  1.2319e-01,\n",
      "          -5.9080e-02, -1.2290e-01,  1.7328e-01,  1.2323e-01,  9.5035e-03,\n",
      "          -1.1112e-01,  1.5218e-01, -7.7010e-03,  8.6500e-02,  1.5996e-01,\n",
      "          -7.2024e-02, -4.2881e-02,  2.6003e-01, -3.9319e-02,  2.0571e-03,\n",
      "           8.2140e-03, -2.8683e-01, -2.3676e-02,  9.6134e-02, -5.1278e-02,\n",
      "           2.0356e-01,  6.3761e-02,  1.7107e-01, -1.9305e-01,  1.6834e-01,\n",
      "           1.5882e-01, -3.7005e-02,  1.1348e-01, -1.5442e-01,  8.1610e-02,\n",
      "           6.2912e-03,  5.0495e-02, -1.4465e-01, -2.6134e-01,  1.0471e-01,\n",
      "          -1.1980e-01,  4.1522e-02, -1.4825e-01,  2.1183e-02,  4.9456e-02,\n",
      "          -1.4066e-02, -4.0393e-02, -2.4512e-02,  1.8950e-01,  1.4877e-01,\n",
      "           9.7909e-02, -8.5290e-03,  9.4349e-02, -4.9877e-02,  1.5050e-01,\n",
      "           2.1954e-02, -1.6298e-01, -3.4195e-02,  1.5057e-01, -2.7140e-02,\n",
      "           1.0229e-01,  7.6456e-02, -2.0796e-01, -1.1659e-01,  1.3779e-01,\n",
      "          -6.7536e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4727, -0.4586, -1.2334, -0.1189,  0.4613,  0.0260,  0.6620,\n",
      "           0.5338,  0.6710,  0.9340,  1.7075, -1.0164,  0.9455, -0.2516,\n",
      "          -1.6339,  0.5121,  1.8776,  0.0000, -1.5632, -2.6430, -1.1332,\n",
      "           0.1685,  2.9292,  0.0000,  0.0000,  3.2087,  1.8370,  0.5186,\n",
      "          -2.2265, -1.2860,  0.0287,  1.0129,  0.3251,  0.8597, -0.7989,\n",
      "           0.0000,  0.6196, -0.7716,  1.9912,  0.1016,  0.4671, -2.2047,\n",
      "          -0.5665, -0.1149, -0.7131, -0.6889,  1.9271,  0.1099, -0.2871,\n",
      "          -1.8504,  1.4676,  0.4623,  0.6673, -0.2830,  0.5316,  0.2750,\n",
      "          -1.2430, -0.9507,  1.8135, -0.0119,  0.2053, -1.8189,  0.0000,\n",
      "          -0.8063,  1.1798,  0.2654, -0.1673, -0.2546, -0.0048, -0.4608,\n",
      "          -0.3250, -0.3240,  0.0000, -0.1263,  0.0000, -0.8062,  2.0663,\n",
      "           1.6791,  0.0878, -0.5455,  1.2268,  0.0860,  0.3266, -1.8363,\n",
      "          -0.0708, -1.7315, -1.4585, -0.8916,  0.6230,  0.8108,  0.0000,\n",
      "          -1.1442,  1.9848, -0.3662, -0.7340,  0.0000,  2.1407,  0.0000,\n",
      "          -0.3039, -1.8394, -1.2907, -0.7210, -0.7664,  0.2367,  0.3817,\n",
      "           1.1138, -1.0709,  2.2522, -0.2630, -0.2884, -0.0535,  0.6104,\n",
      "          -0.2543, -0.2805, -1.9418,  1.1286,  1.0065, -2.4969, -0.5754,\n",
      "           0.0296, -1.6944, -0.4008, -0.3790, -0.0782, -0.5366, -1.1106,\n",
      "           1.3039,  0.1695,  0.3223,  1.3583,  2.0787, -2.6339,  0.0000,\n",
      "          -0.7231,  0.4292,  0.0603,  0.3264, -2.1009,  0.0000, -1.6773,\n",
      "          -0.6418,  0.0000, -1.1867, -1.2145, -0.6308, -0.0402,  0.4647,\n",
      "           1.7381,  1.5950,  1.4320, -1.2624, -0.5773, -0.4801,  0.0000,\n",
      "           0.0000, -0.1172,  1.3536, -0.0318, -1.9003, -1.8066, -1.4263,\n",
      "          -0.9001,  0.0000, -0.3891, -0.9805, -0.1289,  0.4064,  0.9701,\n",
      "           0.5178, -0.1475,  1.5127, -0.3729,  0.0000, -2.0085,  0.1301,\n",
      "          -0.3527, -0.8297, -0.7686, -0.0404, -0.9373,  0.7277,  1.0417,\n",
      "           0.0470,  0.4632,  0.3159, -0.1183, -0.5405, -0.6644,  0.7547,\n",
      "          -1.0639, -0.5870, -1.7884,  1.2674, -0.9263, -1.6148, -0.3333,\n",
      "          -1.1569, -1.9606, -0.0720, -0.3747,  2.6968,  0.0000, -2.6311,\n",
      "           0.0000, -0.7155, -1.3864, -1.2540,  0.1718,  0.2190, -1.1107,\n",
      "           0.9448, -0.6922, -1.5191,  0.3621,  0.2381, -1.4262, -2.3444,\n",
      "           0.0479, -1.4793,  0.0000,  0.0130, -0.9014,  0.3010, -1.1655,\n",
      "          -1.3004, -0.1877,  1.2719,  1.2661, -2.1879, -0.0559,  0.0000,\n",
      "          -1.1753,  0.9562,  1.9994,  0.5276,  0.7883, -0.6785,  0.1042,\n",
      "          -0.6804, -2.2617,  0.1674,  0.0000, -1.0431, -0.3821, -1.0798,\n",
      "           0.5576,  1.4991,  0.0000, -1.3767,  1.2436,  0.5828,  1.7528,\n",
      "           1.9519,  0.3627,  0.4876,  0.3901]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0298, 0.2301, 0.0974, 0.0568, 0.1247, 0.1091, 0.0342, 0.1624, 0.0878,\n",
      "         0.0676]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2663,  0.0089, -0.0874,  ...,  0.1464,  0.0284,  0.0604],\n",
      "        [ 0.0741, -0.1391, -0.0497,  ...,  0.3278,  0.2387, -0.0089],\n",
      "        [ 0.1325,  0.4101, -0.1348,  ..., -0.3434,  0.2340, -0.1407],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.2995e-02,  4.6306e-02, -1.3690e-01,  2.4241e-01, -1.9728e-02,\n",
      "           1.4287e-02,  7.6387e-02,  1.1297e-02,  3.4599e-02,  3.7613e-02,\n",
      "          -8.5362e-02,  2.1321e-02, -6.3540e-02,  4.4885e-02,  6.9644e-02,\n",
      "           7.7812e-02,  2.1634e-01,  8.2573e-02, -4.0931e-02,  1.5267e-01,\n",
      "           1.0579e-01,  6.0283e-02,  2.1122e-01,  2.3913e-02,  6.6692e-02,\n",
      "           1.4835e-01, -8.8159e-03, -2.1381e-01, -5.0501e-02,  1.7536e-01,\n",
      "           8.2066e-02, -9.0440e-02,  9.2239e-02, -5.6124e-02,  1.3211e-01,\n",
      "          -5.2520e-02, -7.7305e-02, -5.0598e-02, -1.3288e-01,  2.6133e-01,\n",
      "          -2.8766e-03, -5.9518e-03, -6.3287e-02, -1.4154e-01, -6.2036e-02,\n",
      "           1.3419e-01,  1.1318e-01,  2.4078e-03, -1.0540e-01, -3.5887e-02,\n",
      "           1.3991e-01,  9.9313e-02, -2.2251e-01, -8.0494e-02,  1.6737e-01,\n",
      "           6.7098e-02,  1.7398e-01,  8.9186e-02, -8.3385e-02, -1.2695e-01,\n",
      "          -1.5220e-01,  1.2022e-01,  3.8514e-02,  7.7192e-02,  1.7393e-01,\n",
      "          -1.0639e-03,  3.2299e-02,  1.7000e-01,  9.4875e-03,  1.8556e-01,\n",
      "          -8.8640e-02,  1.5423e-01,  1.3394e-01,  5.2744e-02,  1.0988e-02,\n",
      "          -1.4701e-01,  1.5038e-02, -1.0157e-02,  6.0149e-03,  5.3985e-02,\n",
      "          -1.7458e-02, -8.2101e-02, -1.6259e-01, -8.7464e-02, -1.1393e-01,\n",
      "          -7.0603e-02, -2.9427e-02,  9.8316e-02,  1.0717e-01,  8.6601e-02,\n",
      "          -1.0446e-01, -2.1850e-02,  9.8627e-02, -3.4599e-02, -2.5011e-02,\n",
      "           2.1359e-02, -2.8796e-02,  2.3495e-01,  1.0587e-01,  2.0513e-01,\n",
      "          -1.3743e-01,  1.4604e-01, -6.2241e-02,  8.9249e-03, -1.2517e-01,\n",
      "          -2.0461e-01,  8.4695e-04,  4.4652e-02, -2.4765e-01,  2.0963e-02,\n",
      "           8.9849e-02,  1.3005e-02,  4.9976e-02, -1.8658e-01, -5.6453e-02,\n",
      "          -2.5210e-01,  1.7077e-01,  1.3900e-01, -5.4419e-02, -1.0921e-01,\n",
      "           1.2570e-01,  3.1742e-02, -1.0489e-02,  1.0356e-01,  1.0085e-01,\n",
      "          -1.7826e-02,  2.5221e-01, -1.3542e-01,  4.5974e-02, -4.4151e-02,\n",
      "           4.8486e-02,  6.0075e-02, -5.6907e-02,  1.8838e-01, -3.3401e-02,\n",
      "          -1.0264e-01,  2.5122e-01, -1.1458e-01,  7.9063e-02, -4.4992e-03,\n",
      "           9.9593e-02,  5.8439e-02, -2.3275e-02,  2.4306e-02,  1.7612e-01,\n",
      "           4.6506e-02,  3.8709e-02, -9.5886e-02,  2.5244e-01, -1.6035e-01,\n",
      "          -6.7603e-02,  1.5587e-01,  2.9553e-02,  1.4759e-01,  1.1162e-01,\n",
      "           1.8997e-01, -7.4306e-02,  1.2854e-01, -1.3174e-01,  6.0611e-02,\n",
      "          -4.7071e-02, -2.0710e-01, -1.4886e-01,  2.2488e-01,  7.5976e-04,\n",
      "          -1.0825e-02, -7.3797e-02, -6.3336e-02, -1.2837e-01,  1.8137e-02,\n",
      "          -2.2147e-02, -7.5601e-02,  9.4102e-02,  3.3836e-04, -7.2500e-02,\n",
      "          -7.1034e-02,  2.9146e-01,  1.2615e-01,  7.7727e-02, -6.3282e-02,\n",
      "           2.9678e-02, -6.6673e-02,  2.2053e-01, -1.1911e-01, -5.1748e-02,\n",
      "           4.1709e-02,  4.5212e-02,  1.2116e-01, -3.8257e-02, -9.5951e-02,\n",
      "           1.1211e-01,  4.1117e-02, -1.0041e-01,  3.4968e-02,  1.2861e-01,\n",
      "          -3.5431e-02, -1.8267e-01,  1.8054e-01,  5.7511e-02, -1.0160e-01,\n",
      "          -1.1677e-01,  1.1989e-01, -7.0625e-02,  7.3086e-02,  1.7068e-01,\n",
      "          -1.0034e-01,  3.7542e-02,  2.6947e-01, -9.1080e-05,  1.2371e-01,\n",
      "           3.0122e-02, -2.4616e-01, -1.1149e-01,  9.0803e-02, -3.6101e-02,\n",
      "           1.3481e-01,  1.2743e-01,  1.7578e-01, -1.9150e-01,  2.0320e-01,\n",
      "           2.0921e-01, -7.7893e-02,  9.5030e-02, -1.8307e-01,  5.3597e-02,\n",
      "          -5.0615e-02,  1.4702e-02, -1.9042e-01, -2.4528e-01,  8.9252e-02,\n",
      "          -5.8690e-02,  4.1679e-02, -1.2696e-01,  1.6048e-01,  8.5134e-02,\n",
      "           4.6035e-02,  4.0373e-03,  1.8117e-02,  2.1279e-01,  1.4889e-01,\n",
      "           1.5214e-01,  1.0196e-01,  1.5499e-01, -8.0181e-02,  1.9042e-01,\n",
      "           6.4809e-02, -2.1093e-01,  3.4483e-02,  1.6619e-01, -1.7150e-02,\n",
      "           9.2885e-02,  1.0292e-01, -2.6513e-01, -6.2164e-02,  1.7100e-01,\n",
      "          -6.0637e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0625e+00, -6.9628e-02, -1.8077e+00,  1.3220e+00,  5.1613e-01,\n",
      "          -3.7611e-01,  1.0160e-03, -7.2273e-01,  2.1177e+00, -2.1362e-01,\n",
      "           2.8201e-01,  8.3052e-01,  0.0000e+00,  1.9963e-01,  3.1265e-01,\n",
      "           3.5178e-01, -6.8277e-01,  1.6934e-01,  8.7440e-01,  5.4580e-01,\n",
      "           1.8833e+00,  6.0202e-01, -3.7070e-02, -5.3540e-01, -1.0052e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.3622e+00, -2.1266e+00, -1.0344e+00,\n",
      "           3.8876e-02, -1.4545e+00, -2.0766e+00,  3.1548e-01, -2.8514e-01,\n",
      "          -2.0017e+00,  2.1906e-01,  0.0000e+00,  6.0145e-01,  9.5355e-01,\n",
      "          -2.2507e-01, -2.2111e+00, -7.0598e-01,  1.3960e+00,  8.9893e-02,\n",
      "          -1.1382e+00,  2.4239e-01,  7.4222e-01, -7.0946e-01, -1.3359e+00,\n",
      "           1.6084e+00, -1.3750e-01,  6.6253e-01,  1.1165e+00,  5.6729e-01,\n",
      "           3.3319e-01,  0.0000e+00, -8.8801e-01,  1.3376e-01,  6.2826e-01,\n",
      "          -7.0456e-01,  5.6336e-01, -6.9346e-01, -1.5469e+00,  2.8920e-01,\n",
      "           9.5831e-02, -1.7762e-01,  0.0000e+00, -2.1389e+00,  5.5968e-01,\n",
      "           1.8256e-01, -5.1256e-01, -3.4093e-01, -1.1321e+00, -6.4741e-01,\n",
      "           4.6098e-01, -1.0492e+00,  1.1892e-01,  5.1719e-01, -1.8629e-01,\n",
      "          -3.8506e-01,  2.1577e+00,  7.7731e-01, -8.4536e-01,  3.9781e-01,\n",
      "           4.1914e-01,  1.6047e+00, -5.6405e-01, -1.4129e+00, -1.4906e+00,\n",
      "           4.0449e-01, -3.5133e-01,  4.9398e-01, -2.3211e+00,  1.2379e+00,\n",
      "          -9.6281e-01,  1.3202e+00, -9.0727e-01,  2.3908e+00,  9.5489e-01,\n",
      "          -1.2008e+00,  5.9457e-01,  1.0663e+00, -1.7340e+00,  3.6519e-01,\n",
      "           4.0243e-01, -1.2704e+00,  4.5466e-01,  1.9687e+00,  1.4960e-01,\n",
      "          -8.3261e-01,  5.3422e-01,  8.0841e-01,  6.6387e-01, -1.0554e+00,\n",
      "           9.1774e-01,  0.0000e+00, -8.4507e-01,  2.5769e-01,  8.7980e-01,\n",
      "          -8.7730e-01, -1.3959e+00, -3.6481e-01, -1.8464e+00, -1.3005e+00,\n",
      "           1.0694e+00,  0.0000e+00,  6.4904e-01,  2.5569e-01, -1.4896e+00,\n",
      "           2.5020e+00,  3.7788e-01,  0.0000e+00,  7.2208e-01,  3.2007e+00,\n",
      "          -7.5256e-01, -3.8376e-01,  1.2824e+00,  2.2519e+00,  1.9422e-01,\n",
      "          -3.9026e-02,  3.0300e+00,  3.6271e-01, -1.8727e-01, -1.1120e+00,\n",
      "           1.2473e+00,  7.7532e-01, -7.7474e-01, -4.4872e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6528e-01, -2.8964e-01, -2.1307e+00, -5.8167e-01,\n",
      "           7.8595e-01, -1.8622e+00, -1.3048e+00,  1.9039e-01, -3.6287e+00,\n",
      "          -1.8688e+00,  0.0000e+00, -8.5968e-01,  9.5950e-01,  0.0000e+00,\n",
      "          -2.7074e-02,  1.9743e+00,  1.1269e+00, -4.8571e-01, -1.2413e+00,\n",
      "          -2.1248e-01, -1.3224e+00, -1.6392e+00, -7.7177e-01,  6.8263e-01,\n",
      "           0.0000e+00, -1.2607e-01,  0.0000e+00, -7.4918e-01,  2.5919e-01,\n",
      "           1.3327e+00, -2.5533e+00,  2.7795e-01, -5.8355e-01,  1.6233e+00,\n",
      "          -1.2404e+00, -1.8179e-03, -5.0166e-02,  0.0000e+00,  0.0000e+00,\n",
      "          -4.1988e-01,  0.0000e+00, -1.1559e-01,  8.0960e-01,  1.0504e+00,\n",
      "           0.0000e+00, -1.4389e+00, -4.1530e-01, -7.5026e-01, -4.5418e-01,\n",
      "          -5.4753e-01,  7.2237e-01, -1.8529e+00,  0.0000e+00,  8.3786e-01,\n",
      "          -1.5240e+00, -3.5862e-01,  6.4771e-01,  2.0052e-01, -2.1783e+00,\n",
      "           8.3527e-01, -1.2910e+00,  0.0000e+00,  2.6095e-01, -1.5635e+00,\n",
      "           2.0758e+00,  0.0000e+00,  2.5769e+00,  0.0000e+00, -5.7958e-01,\n",
      "          -1.4281e+00,  0.0000e+00, -3.8087e-01,  1.4695e+00,  8.0538e-01,\n",
      "           3.6935e-01,  6.6978e-01, -7.0040e-01,  8.8800e-02,  1.0253e+00,\n",
      "           9.7857e-01, -1.4083e+00,  6.5952e-01, -1.1451e+00,  0.0000e+00,\n",
      "          -6.0043e-01,  8.7381e-03, -7.1090e-01,  0.0000e+00, -2.2388e-01,\n",
      "          -7.5251e-01,  0.0000e+00,  5.3058e-01, -6.6383e-01,  1.5464e+00,\n",
      "           5.7814e-01,  1.8918e+00, -8.6388e-01,  0.0000e+00, -3.8723e-01,\n",
      "           4.9978e-01, -9.7497e-01,  1.7726e+00, -1.0637e+00,  0.0000e+00,\n",
      "          -6.2207e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0733, 0.1143, 0.1036, 0.1929, 0.0759, 0.1429, 0.0714, 0.0516, 0.0752,\n",
      "         0.0989]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2663,  0.0089, -0.0874,  ...,  0.1464,  0.0284,  0.0604],\n",
      "        [ 0.0741, -0.1391, -0.0497,  ...,  0.3278,  0.2387, -0.0089],\n",
      "        [ 0.1325,  0.4101, -0.1348,  ..., -0.3434,  0.2340, -0.1407],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1317,  0.1192, -0.1442,  0.2731, -0.0121, -0.0828,  0.0434,\n",
      "           0.0649,  0.0444,  0.0125, -0.0312, -0.0035, -0.0022,  0.0322,\n",
      "           0.0055,  0.0295,  0.2719, -0.0021, -0.0247,  0.1726,  0.0882,\n",
      "           0.0856,  0.1753, -0.0128,  0.0402,  0.1900, -0.0393, -0.2244,\n",
      "           0.0016,  0.1546,  0.0974, -0.0636,  0.1364, -0.0546,  0.1742,\n",
      "          -0.0618, -0.0879,  0.0014, -0.1608,  0.2738,  0.0063, -0.0295,\n",
      "          -0.0309, -0.1811, -0.0244,  0.1645,  0.1100,  0.0684, -0.1101,\n",
      "          -0.0236,  0.1776,  0.0989, -0.1927,  0.0010,  0.1311,  0.0482,\n",
      "           0.1907,  0.1180, -0.0933, -0.1437, -0.1128,  0.0793,  0.0662,\n",
      "           0.1427,  0.1224, -0.0270,  0.0128,  0.1738,  0.0019,  0.1393,\n",
      "          -0.1090,  0.1862,  0.0687,  0.0576, -0.0217, -0.1135, -0.0513,\n",
      "          -0.0144,  0.0041, -0.0334,  0.0206, -0.0871, -0.1391, -0.0839,\n",
      "          -0.1412, -0.0639, -0.0255,  0.0752,  0.1404,  0.0394, -0.0832,\n",
      "          -0.0074,  0.0908, -0.0433, -0.0862,  0.0628, -0.0680,  0.2899,\n",
      "           0.1331,  0.2041, -0.1050,  0.0849, -0.0383,  0.0725, -0.2417,\n",
      "          -0.1665,  0.0064, -0.0054, -0.2477,  0.0340,  0.1306,  0.0003,\n",
      "           0.0821, -0.1570, -0.0133, -0.2914,  0.1739,  0.1219, -0.0803,\n",
      "          -0.0972,  0.1416,  0.0173,  0.0280,  0.1039,  0.1223, -0.0783,\n",
      "           0.3086, -0.1526,  0.0853, -0.0720,  0.0124,  0.0014, -0.0352,\n",
      "           0.1918,  0.0640, -0.0073,  0.2861, -0.0522,  0.0480, -0.0138,\n",
      "           0.1490,  0.0126,  0.0601,  0.0398,  0.1892,  0.0155, -0.0192,\n",
      "          -0.1167,  0.1946, -0.1843, -0.0441,  0.1302,  0.0525,  0.1342,\n",
      "           0.1182,  0.1560, -0.0632,  0.0641, -0.1005,  0.0905, -0.0472,\n",
      "          -0.1913, -0.1342,  0.2062,  0.0052,  0.0057, -0.1001, -0.1191,\n",
      "          -0.0781,  0.0177,  0.0427, -0.0582,  0.0821, -0.0241, -0.0875,\n",
      "          -0.0487,  0.3114,  0.1330,  0.1378,  0.0088,  0.0980, -0.1096,\n",
      "           0.2457, -0.0709, -0.0806,  0.0848,  0.0267,  0.1243,  0.0025,\n",
      "          -0.0946,  0.0954,  0.0605, -0.0924, -0.0521,  0.1510,  0.0079,\n",
      "          -0.2163,  0.2119,  0.1562, -0.0055, -0.1247,  0.1390,  0.0168,\n",
      "           0.0835,  0.1871, -0.0960, -0.0427,  0.2504, -0.0159,  0.0729,\n",
      "           0.0616, -0.2959, -0.0706,  0.1296, -0.0825,  0.2121,  0.0938,\n",
      "           0.1760, -0.2021,  0.2153,  0.1778, -0.0121,  0.1053, -0.1552,\n",
      "           0.0471, -0.0340,  0.0146, -0.1272, -0.3121,  0.0989, -0.1520,\n",
      "           0.0439, -0.2008,  0.1687,  0.1263,  0.0325, -0.0399, -0.0287,\n",
      "           0.2093,  0.1261,  0.1469,  0.0566,  0.1965, -0.0687,  0.2208,\n",
      "           0.0685, -0.1667, -0.0276,  0.1689, -0.0420,  0.1127,  0.1247,\n",
      "          -0.2756, -0.1207,  0.1535, -0.0661]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2145e+00,  1.9548e+00,  0.0000e+00, -1.2732e+00, -1.6875e+00,\n",
      "           1.4302e+00,  2.0849e+00, -8.0140e-01, -2.4209e-01,  1.5025e-01,\n",
      "           3.9157e-01,  8.1437e-01, -5.3817e-01,  7.2680e-03,  3.1026e-01,\n",
      "          -1.3439e+00,  0.0000e+00,  2.1811e-01,  3.8045e-01,  4.0276e-01,\n",
      "           6.9892e-01,  1.0701e+00,  2.7980e+00,  5.0775e-01, -1.3777e+00,\n",
      "          -1.0715e+00,  5.5912e-02, -5.3069e-01,  1.0689e-01, -9.0278e-01,\n",
      "           1.7018e+00, -2.5195e-01,  3.0459e-01,  3.4922e-01,  1.0045e+00,\n",
      "          -1.0171e+00,  7.3023e-01, -2.7398e-01, -7.6549e-01, -6.1106e-02,\n",
      "          -1.2187e+00, -9.6327e-01,  6.9202e-01,  4.6122e-01, -2.2547e-01,\n",
      "          -4.9890e-01,  1.3850e+00,  1.9253e+00, -5.8739e-01, -1.7936e+00,\n",
      "           6.5157e-01,  1.8293e-01,  1.9094e+00,  3.6484e-02,  5.0716e-01,\n",
      "           1.1992e-02,  8.2549e-01,  4.5320e-01,  3.7066e-01, -5.5691e-01,\n",
      "          -5.5821e-01, -2.1649e+00,  9.7214e-01, -4.2788e-01, -2.1487e+00,\n",
      "          -7.3824e-01, -8.8805e-01, -2.9442e-01,  6.2575e-01,  0.0000e+00,\n",
      "           9.7896e-01,  3.2790e-01, -1.1141e-01, -3.9414e-01,  2.5193e+00,\n",
      "           0.0000e+00,  1.9344e-01, -8.2211e-02, -1.1222e+00,  1.0309e+00,\n",
      "          -1.4983e+00, -6.0961e-01, -7.4008e-01,  5.0861e-01, -3.0659e-01,\n",
      "           1.2769e-01,  5.3750e-01,  1.8817e+00, -2.7006e-01,  1.2686e+00,\n",
      "          -1.3820e+00, -6.9639e-01,  1.1105e+00, -2.3924e-01,  4.2367e-01,\n",
      "           8.6825e-02, -5.2170e-01,  0.0000e+00, -5.4694e-01, -2.4458e-01,\n",
      "          -3.0390e-01, -3.7437e-01, -3.0830e-01,  1.4459e+00,  3.1817e-01,\n",
      "          -2.1772e-01,  0.0000e+00,  8.5004e-01, -7.7208e-02,  2.6140e+00,\n",
      "          -1.8020e+00,  5.4100e-02,  1.6502e+00, -2.5753e-01,  3.9695e-01,\n",
      "           1.0300e+00,  1.2515e+00,  7.1808e-01,  1.2860e+00, -1.7569e+00,\n",
      "           0.0000e+00, -4.7110e-01,  1.0173e+00, -8.9609e-02,  8.5072e-01,\n",
      "          -1.4630e+00,  0.0000e+00, -2.5757e-01, -1.1308e+00,  2.5047e-01,\n",
      "           2.7183e-01,  1.1887e+00,  8.1597e-01,  1.4579e-01, -5.0862e-01,\n",
      "           4.4279e-03, -7.2850e-01, -3.4654e-01,  1.0280e+00, -1.8978e-01,\n",
      "           2.0756e+00,  1.1949e+00, -6.9063e-01, -7.3709e-01,  9.0350e-01,\n",
      "          -1.0653e+00, -1.0943e+00, -2.7294e-01,  6.3402e-02, -1.6972e+00,\n",
      "          -5.8329e-01,  6.4009e-01,  5.6198e-01,  8.9732e-01,  1.4513e+00,\n",
      "          -5.2604e-01,  7.7646e-01,  9.0546e-01, -1.9766e-01,  5.7958e-01,\n",
      "          -1.5882e+00, -1.2754e+00,  1.9656e-01, -4.8017e-01, -1.2563e-01,\n",
      "          -1.0646e+00, -6.6068e-02, -4.9360e-01,  2.6933e-03, -5.4600e-01,\n",
      "          -5.9126e-01,  5.4900e-01, -2.7584e-01,  5.4477e-01, -1.3026e+00,\n",
      "           3.4180e-02, -5.0635e-01,  5.8828e-01,  0.0000e+00,  3.8357e-01,\n",
      "          -6.4563e-01, -9.8698e-01, -1.1286e+00,  2.5551e-01,  0.0000e+00,\n",
      "          -6.9888e-02,  1.5551e+00,  1.1998e+00,  8.8800e-01, -2.5811e-01,\n",
      "          -1.3346e+00,  0.0000e+00, -4.3066e-01,  9.0441e-01, -1.2725e+00,\n",
      "           9.7534e-01, -1.3324e-01, -2.3901e-01, -8.4791e-01, -8.3300e-02,\n",
      "          -3.4544e-02,  1.6270e+00,  3.3584e+00,  9.6540e-01,  2.7384e-01,\n",
      "           1.0958e+00, -2.6787e-02,  8.6049e-01,  1.3642e+00, -1.6661e+00,\n",
      "          -1.2361e+00, -1.4498e-01,  1.3175e+00, -7.2948e-01,  0.0000e+00,\n",
      "           1.7395e+00,  7.3913e-01,  4.3623e-01,  1.8402e+00,  8.3976e-01,\n",
      "           1.5018e+00,  3.9054e-01, -1.2277e+00,  1.4762e+00, -1.2884e+00,\n",
      "          -7.7983e-01,  2.8105e-01,  2.1957e-01, -2.2286e+00,  2.0219e+00,\n",
      "           1.1894e+00,  8.9518e-01, -2.3925e-01, -8.8616e-01,  8.0222e-01,\n",
      "          -2.7839e-02,  2.5082e+00,  0.0000e+00, -2.3750e-01, -1.7030e+00,\n",
      "          -8.1635e-01, -2.2855e-01, -2.0578e+00, -9.3819e-01,  1.9448e+00,\n",
      "           2.2887e-01,  8.8060e-02,  1.6648e-01,  5.7529e-01,  6.6580e-01,\n",
      "          -1.6299e-01,  6.8746e-01,  1.1315e+00,  1.2908e+00,  9.9967e-01,\n",
      "          -8.0318e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1318, 0.1236, 0.1014, 0.0323, 0.0797, 0.1455, 0.0555, 0.1367, 0.0597,\n",
      "         0.1337]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2663,  0.0089, -0.0874,  ...,  0.1464,  0.0284,  0.0604],\n",
      "        [ 0.0741, -0.1391, -0.0497,  ...,  0.3278,  0.2387, -0.0089],\n",
      "        [ 0.1325,  0.4101, -0.1348,  ..., -0.3434,  0.2340, -0.1407],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0724e-01,  6.8115e-02, -1.5182e-01,  2.2458e-01, -2.4509e-02,\n",
      "           3.1929e-02,  2.4453e-02, -9.7948e-03,  2.7973e-02,  4.4932e-02,\n",
      "          -4.6405e-02, -7.4403e-03, -4.7082e-02,  6.1038e-02,  6.3568e-02,\n",
      "           8.7189e-02,  1.8793e-01,  6.4541e-02, -2.1583e-02,  1.5425e-01,\n",
      "           7.3608e-02,  7.2757e-02,  1.9740e-01,  1.9689e-02,  3.4746e-02,\n",
      "           1.2356e-01, -3.0652e-02, -2.1681e-01, -4.0921e-03,  1.4341e-01,\n",
      "           1.0301e-01, -7.8118e-02,  4.7465e-02, -4.4922e-02,  1.2649e-01,\n",
      "          -5.8285e-03, -3.7367e-02, -1.6466e-02, -9.7006e-02,  1.9362e-01,\n",
      "          -2.4456e-02, -3.3926e-03, -5.8651e-02, -1.0638e-01, -7.4020e-03,\n",
      "           1.5354e-01,  8.9621e-02,  1.6678e-02, -4.3440e-02, -1.0514e-02,\n",
      "           9.2057e-02,  1.0036e-01, -2.0105e-01, -8.0305e-02,  1.3509e-01,\n",
      "           5.9608e-02,  1.0748e-01,  1.2341e-01, -9.0431e-02, -8.6188e-02,\n",
      "          -9.2324e-02,  9.5202e-02,  4.7347e-02,  5.0848e-02,  1.5595e-01,\n",
      "          -1.0808e-02, -1.1815e-02,  1.6529e-01, -3.1350e-02,  1.7790e-01,\n",
      "          -5.7867e-02,  1.3270e-01,  1.1550e-01,  4.9672e-02, -6.0676e-02,\n",
      "          -1.2728e-01, -9.5448e-03,  1.3301e-02,  1.1907e-02,  7.9483e-02,\n",
      "          -4.5814e-02, -1.1060e-01, -1.4294e-01, -8.1280e-02, -9.6312e-02,\n",
      "          -4.0263e-02, -6.1532e-02,  8.7390e-02,  6.9774e-02,  4.4380e-02,\n",
      "          -7.7957e-02, -2.6946e-02,  1.0205e-01, -8.0082e-03, -2.5885e-02,\n",
      "           2.4288e-02, -2.6411e-02,  2.2485e-01,  7.9496e-02,  1.9373e-01,\n",
      "          -1.2243e-01,  1.1472e-01, -6.1360e-02,  5.4194e-02, -1.7154e-01,\n",
      "          -1.7450e-01, -1.4512e-02,  4.0678e-02, -2.0418e-01, -2.2873e-03,\n",
      "           1.3109e-01,  3.5080e-02,  5.8324e-02, -1.7753e-01, -4.7083e-02,\n",
      "          -2.3500e-01,  1.1492e-01,  9.5464e-02, -7.9968e-03, -5.5298e-02,\n",
      "           5.5936e-02, -9.0145e-03, -7.2800e-03,  9.0450e-02,  9.0963e-02,\n",
      "          -7.8946e-03,  2.2229e-01, -1.1278e-01,  5.0456e-02, -2.1055e-02,\n",
      "           4.0632e-02,  3.0995e-02, -5.3579e-04,  1.6348e-01, -9.2469e-03,\n",
      "          -7.7015e-02,  2.5332e-01, -9.3765e-02,  5.9038e-02,  5.8317e-03,\n",
      "           9.6506e-02,  7.9511e-02,  1.8677e-02,  4.4260e-02,  1.6115e-01,\n",
      "           2.9118e-02, -2.7576e-03, -9.1737e-02,  2.1795e-01, -1.0629e-01,\n",
      "          -7.6132e-02,  1.3778e-01,  5.2220e-02,  1.4080e-01,  8.0060e-02,\n",
      "           1.4923e-01, -5.6859e-02,  6.7321e-02, -1.3567e-01,  1.5029e-02,\n",
      "          -3.6363e-02, -1.8643e-01, -1.3453e-01,  2.0159e-01,  1.8499e-02,\n",
      "           1.6332e-02, -1.0879e-02, -5.5330e-02, -1.2128e-01,  2.6099e-02,\n",
      "          -7.3340e-03, -2.1907e-02,  7.6649e-02, -3.6002e-02, -5.7866e-02,\n",
      "          -4.3884e-02,  2.6574e-01,  1.2447e-01,  7.6399e-02, -4.5247e-02,\n",
      "           4.7661e-02, -7.4227e-02,  1.7234e-01, -8.6210e-02, -5.2369e-02,\n",
      "           6.0482e-02, -1.2104e-02,  8.2129e-02,  5.4984e-03, -7.7254e-02,\n",
      "           9.3559e-02,  7.7645e-02, -1.5840e-01,  1.2303e-02,  9.4910e-02,\n",
      "          -2.4922e-02, -1.3369e-01,  1.4261e-01,  6.7473e-02, -7.8014e-02,\n",
      "          -1.2048e-01,  1.1435e-01, -7.4148e-02,  9.0858e-02,  1.6993e-01,\n",
      "          -5.6357e-02,  3.0552e-02,  2.6980e-01,  1.4046e-02,  4.3998e-02,\n",
      "           5.0381e-02, -2.5805e-01, -1.0084e-01,  8.6822e-02, -4.0187e-02,\n",
      "           1.3476e-01,  1.1701e-01,  1.7037e-01, -1.9926e-01,  1.4213e-01,\n",
      "           1.6722e-01, -6.8902e-02,  1.0546e-01, -1.9543e-01,  4.4730e-02,\n",
      "          -9.6144e-04,  2.2328e-02, -1.5191e-01, -2.3704e-01,  1.0821e-01,\n",
      "          -7.8972e-02,  6.5901e-02, -7.6254e-02,  9.5926e-02,  9.5332e-02,\n",
      "           7.2531e-02,  1.8219e-02, -1.0611e-04,  1.9284e-01,  1.1157e-01,\n",
      "           1.4654e-01,  6.9074e-02,  1.1256e-01, -8.7041e-02,  1.5376e-01,\n",
      "           5.0013e-02, -2.1448e-01,  2.6193e-02,  1.6539e-01, -2.2959e-03,\n",
      "           5.9014e-02,  4.2164e-02, -2.3268e-01, -6.2027e-02,  1.2805e-01,\n",
      "          -4.9441e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4065e+00,  0.0000e+00, -5.0548e-01, -1.7432e+00, -1.6360e+00,\n",
      "           1.7946e+00,  5.2218e-01, -5.9347e-02,  1.3379e+00, -1.4212e+00,\n",
      "           6.2513e-01, -9.3946e-01,  0.0000e+00, -1.3269e+00, -1.0479e+00,\n",
      "          -7.1195e-01, -1.4539e-01,  0.0000e+00, -2.4719e-01,  0.0000e+00,\n",
      "           4.4451e-01,  1.3998e-01, -1.6761e-01, -4.9194e-01, -9.1135e-01,\n",
      "          -4.7016e-01, -6.6489e-01,  0.0000e+00, -6.5305e-01,  6.6344e-03,\n",
      "           1.0456e-01, -7.4298e-01,  3.2110e-01, -2.0971e+00,  7.1924e-01,\n",
      "           0.0000e+00, -1.6270e+00, -2.1935e-01,  3.9282e-02, -1.5910e-01,\n",
      "           7.5637e-01, -7.0412e-01,  5.8398e-01,  1.8466e+00, -2.2171e-01,\n",
      "          -4.5821e-01,  0.0000e+00, -1.8173e-01, -5.7292e-01,  0.0000e+00,\n",
      "           7.1654e-01,  3.2965e-01,  0.0000e+00,  6.6120e-01, -8.9917e-01,\n",
      "          -3.6404e-01,  6.6161e-01, -2.3483e+00,  8.4839e-01,  7.9076e-01,\n",
      "           1.2953e+00,  0.0000e+00, -3.1265e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -2.2926e+00,  0.0000e+00,  3.8208e-01, -1.0175e+00,  1.7845e+00,\n",
      "          -1.4239e+00,  2.5523e+00, -3.0540e-01,  9.9611e-01, -7.8718e-01,\n",
      "           5.5205e-01,  6.2525e-01, -1.9149e+00, -8.4086e-01,  6.8401e-01,\n",
      "          -1.3774e+00,  1.0664e-01,  1.4607e+00, -1.0944e+00,  0.0000e+00,\n",
      "          -1.2549e+00, -1.2985e+00, -5.9113e-01, -6.4206e-01, -1.0084e+00,\n",
      "           6.1262e-02, -7.8648e-03,  8.0413e-01, -5.8644e-01,  4.2972e-01,\n",
      "           0.0000e+00,  7.6816e-01,  1.0133e+00,  2.1472e-01,  6.5477e-01,\n",
      "           5.1490e-01, -1.7431e+00, -4.5873e-01, -7.5818e-01, -8.8122e-01,\n",
      "          -2.1244e+00, -1.5732e-01,  1.0827e+00,  2.3483e-01,  2.9613e-02,\n",
      "          -1.2011e+00, -4.3878e-02,  7.2651e-01,  8.7746e-01,  1.4494e+00,\n",
      "          -6.7297e-01, -1.4878e-01,  1.3625e+00,  1.3761e+00,  2.0169e+00,\n",
      "          -8.6358e-01, -1.0325e+00,  0.0000e+00,  1.3128e-01, -1.1738e+00,\n",
      "           1.6570e+00, -5.9386e-01,  4.2011e-01,  1.0023e+00,  1.3996e+00,\n",
      "          -9.7219e-01,  2.3746e+00, -5.7912e-01,  9.0372e-02, -2.7829e-01,\n",
      "           0.0000e+00, -8.3332e-03,  2.4142e-01,  6.6535e-01,  1.2497e+00,\n",
      "           6.8914e-01, -2.6211e-01, -8.7036e-01,  5.4591e-01,  2.1088e+00,\n",
      "          -5.2348e-01, -8.7526e-01, -1.7575e+00, -8.0259e-01,  7.1551e-01,\n",
      "           9.1706e-01, -2.2768e+00, -2.2810e-01, -1.4594e+00,  3.3861e-04,\n",
      "          -1.0641e+00,  2.3942e+00,  1.3058e+00, -2.8856e-01, -1.2956e+00,\n",
      "           5.0007e-01,  1.3568e+00, -7.9364e-01,  1.7782e+00,  1.1946e+00,\n",
      "           1.5204e-01,  0.0000e+00,  3.9762e-01,  1.3047e-01, -1.1706e-01,\n",
      "          -7.1817e-01,  4.9067e-01,  1.5771e+00,  0.0000e+00, -8.9533e-01,\n",
      "           1.3497e+00, -3.6786e-01, -6.0905e-01,  0.0000e+00,  1.6614e+00,\n",
      "           1.0986e+00, -4.2379e-01,  0.0000e+00,  0.0000e+00, -2.9641e-01,\n",
      "           1.0316e+00, -2.1157e+00, -9.0835e-01, -1.2506e+00,  1.6836e-01,\n",
      "           0.0000e+00,  1.1616e+00, -1.6628e-01, -8.3821e-01,  3.9088e-01,\n",
      "           1.2377e+00,  2.8931e+00,  9.6567e-01,  0.0000e+00, -6.8676e-01,\n",
      "           4.7204e-01, -4.4303e-01, -1.6407e+00,  1.1171e+00, -8.6368e-01,\n",
      "          -6.2825e-01,  2.2528e+00,  0.0000e+00,  2.6811e-01, -1.0533e+00,\n",
      "           2.1132e+00,  0.0000e+00,  6.6112e-01,  1.7226e-01,  0.0000e+00,\n",
      "           2.8962e-01, -1.2549e+00, -1.5452e+00, -1.9427e-01,  0.0000e+00,\n",
      "          -8.8037e-02,  1.7657e+00,  0.0000e+00,  1.9972e+00,  1.3505e+00,\n",
      "          -1.0767e+00, -1.8763e+00,  7.1708e-01, -2.0419e-01, -9.1553e-01,\n",
      "          -5.3449e-01,  2.0365e-01,  2.5357e-01,  7.1405e-01,  5.7126e-01,\n",
      "          -1.8057e+00, -7.6265e-02,  2.5685e-01,  9.1238e-01,  6.6431e-01,\n",
      "          -9.4947e-01,  1.0534e+00, -8.7128e-01,  4.0944e-01, -2.5924e+00,\n",
      "          -2.3841e-01,  0.0000e+00, -1.1677e+00,  1.4444e-01,  2.5147e-01,\n",
      "           3.0536e-01, -1.7722e+00, -2.1237e+00, -1.2336e+00, -1.5485e+00,\n",
      "           9.5823e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0672, 0.0974, 0.0946, 0.1332, 0.1238, 0.1454, 0.1333, 0.0728, 0.0439,\n",
      "         0.0885]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2663,  0.0089, -0.0874,  ...,  0.1464,  0.0284,  0.0604],\n",
      "        [ 0.0741, -0.1391, -0.0497,  ...,  0.3278,  0.2387, -0.0089],\n",
      "        [ 0.1325,  0.4101, -0.1348,  ..., -0.3434,  0.2340, -0.1407],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.1970e-01,  9.6994e-02, -1.5723e-01,  2.3119e-01, -1.0974e-02,\n",
      "          -8.1960e-02,  2.4835e-02,  4.0692e-02,  3.9486e-02, -1.3801e-02,\n",
      "          -1.0825e-02, -1.8635e-02, -2.4095e-02,  5.3523e-02,  1.9819e-02,\n",
      "           1.4428e-02,  2.2670e-01,  1.3791e-02, -5.3623e-02,  1.5169e-01,\n",
      "           8.5161e-02,  6.0043e-02,  1.6425e-01, -1.9625e-02,  3.3292e-02,\n",
      "           1.8511e-01, -1.9586e-02, -2.2433e-01,  4.0361e-03,  1.5266e-01,\n",
      "           1.0599e-01, -6.3050e-02,  1.2588e-01, -7.8994e-02,  1.5722e-01,\n",
      "          -3.0814e-02, -1.0061e-01, -1.1526e-02, -1.5763e-01,  2.5821e-01,\n",
      "           3.9050e-03, -7.7970e-03, -4.8875e-02, -1.6997e-01, -3.4186e-02,\n",
      "           1.7599e-01,  1.0093e-01,  5.1934e-02, -7.8153e-02, -3.1981e-02,\n",
      "           1.7056e-01,  7.0686e-02, -1.9288e-01, -1.2684e-02,  9.7763e-02,\n",
      "           3.5389e-02,  1.4044e-01,  1.0178e-01, -8.3398e-02, -1.2427e-01,\n",
      "          -9.5208e-02,  6.1466e-02,  4.2422e-02,  1.5204e-01,  1.1149e-01,\n",
      "          -2.7367e-02, -3.0168e-03,  1.8338e-01, -1.7441e-02,  1.6258e-01,\n",
      "          -7.7413e-02,  1.8763e-01,  6.6301e-02,  5.6784e-02, -3.7875e-02,\n",
      "          -8.9093e-02, -5.3124e-02,  1.2571e-02,  5.6587e-03,  5.8604e-03,\n",
      "           1.8453e-02, -6.1308e-02, -1.4915e-01, -6.3702e-02, -1.2134e-01,\n",
      "          -5.3142e-02, -5.5175e-03,  8.1241e-02,  1.1183e-01,  4.4360e-02,\n",
      "          -6.7143e-02, -6.3602e-03,  6.9062e-02, -4.7065e-02, -7.8325e-02,\n",
      "           7.6697e-02, -4.3941e-02,  2.5730e-01,  1.3716e-01,  2.0734e-01,\n",
      "          -9.3501e-02,  9.5877e-02, -2.3713e-02,  7.2997e-02, -1.8679e-01,\n",
      "          -1.6722e-01,  2.5754e-02,  3.7928e-02, -2.3082e-01,  4.3871e-02,\n",
      "           1.1708e-01,  1.9306e-02,  6.9300e-02, -1.4625e-01, -2.2821e-02,\n",
      "          -2.5814e-01,  1.4591e-01,  1.0818e-01, -8.6735e-02, -9.5923e-02,\n",
      "           1.0389e-01,  9.6130e-03, -3.6008e-03,  1.1014e-01,  6.8628e-02,\n",
      "          -6.5245e-02,  2.8666e-01, -1.4349e-01,  9.1546e-02, -7.7018e-02,\n",
      "           4.4347e-03, -1.2116e-02, -2.4369e-02,  1.9775e-01,  6.3144e-02,\n",
      "          -1.9243e-02,  2.7641e-01, -2.6592e-02,  4.2337e-02, -1.2582e-02,\n",
      "           1.1403e-01,  4.0090e-02,  4.2238e-02,  3.4622e-02,  1.7500e-01,\n",
      "          -2.3922e-04,  5.1860e-04, -7.7965e-02,  1.9194e-01, -1.3838e-01,\n",
      "          -8.6908e-02,  1.3799e-01,  3.3565e-02,  1.3797e-01,  1.1500e-01,\n",
      "           1.5411e-01, -5.8197e-02,  7.0893e-02, -1.1233e-01,  7.0801e-02,\n",
      "          -4.4330e-02, -1.7525e-01, -1.5259e-01,  2.2216e-01, -1.5288e-02,\n",
      "           5.5631e-03, -6.8783e-02, -1.2269e-01, -7.9841e-02,  1.0401e-02,\n",
      "           2.1913e-02, -3.4128e-02,  8.5217e-02, -1.2717e-02, -7.4760e-02,\n",
      "          -6.7106e-02,  2.8557e-01,  1.3476e-01,  1.3105e-01,  1.0948e-04,\n",
      "           5.1024e-02, -9.9473e-02,  1.9769e-01, -7.3106e-02, -3.7843e-02,\n",
      "           7.5200e-02,  1.8446e-02,  1.1855e-01, -1.2824e-02, -9.1305e-02,\n",
      "           9.4120e-02,  6.5225e-02, -1.0930e-01, -4.4950e-02,  1.2812e-01,\n",
      "          -1.5874e-02, -1.7568e-01,  2.0067e-01,  1.4006e-01, -8.7089e-03,\n",
      "          -1.1482e-01,  1.4062e-01,  7.4160e-03,  6.9053e-02,  1.6739e-01,\n",
      "          -1.0157e-01, -4.4014e-02,  2.4742e-01, -2.0208e-02,  3.5196e-02,\n",
      "           2.5903e-02, -2.8804e-01, -5.7439e-02,  1.2326e-01, -7.9118e-02,\n",
      "           2.0354e-01,  9.5863e-02,  1.7287e-01, -1.9985e-01,  1.9567e-01,\n",
      "           1.6798e-01, -7.3904e-03,  1.1032e-01, -1.4307e-01,  5.3912e-02,\n",
      "          -1.8148e-02,  1.2777e-02, -1.3692e-01, -3.0581e-01,  9.3193e-02,\n",
      "          -1.3406e-01,  3.2388e-02, -1.9437e-01,  1.2594e-01,  1.0237e-01,\n",
      "           1.6829e-02, -4.5586e-02, -2.3514e-02,  2.0910e-01,  1.4121e-01,\n",
      "           1.2269e-01,  3.3133e-02,  1.7608e-01, -4.6560e-02,  2.0488e-01,\n",
      "           4.4691e-02, -1.6378e-01, -3.8410e-02,  1.5134e-01, -6.0572e-02,\n",
      "           1.1276e-01,  1.1543e-01, -2.4785e-01, -1.3106e-01,  1.6021e-01,\n",
      "          -6.9299e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7285e-01, -4.3053e-01,  3.1471e-01, -1.0845e+00, -1.1724e+00,\n",
      "           7.4207e-01, -1.9141e+00,  1.3514e+00,  1.9064e-01,  6.1736e-01,\n",
      "           1.9024e+00,  6.0246e-01,  2.2865e-01, -9.1598e-01, -3.1815e+00,\n",
      "          -6.8725e-02, -1.6329e+00, -9.4329e-01,  1.3611e+00, -1.4344e+00,\n",
      "           0.0000e+00, -5.2298e-01, -1.1192e+00, -2.5945e+00, -7.5227e-02,\n",
      "           1.3912e+00, -6.1907e-01,  0.0000e+00,  1.2771e-01,  5.5370e-01,\n",
      "           9.1430e-01, -3.5014e-03,  2.2328e-01,  2.0150e+00, -6.4119e-02,\n",
      "          -1.4085e+00, -1.1202e-01, -8.1825e-01,  3.1458e-01,  8.5156e-02,\n",
      "           8.6160e-01, -9.0043e-01,  1.0092e+00,  0.0000e+00,  1.9435e+00,\n",
      "          -3.0004e-01,  7.0406e-01, -6.0082e-01, -1.0204e+00,  1.1161e+00,\n",
      "          -1.3216e+00,  2.6763e+00,  6.6661e-01, -8.4644e-01,  2.2733e-01,\n",
      "          -3.0867e-01,  0.0000e+00, -9.6872e-02,  1.2744e+00,  2.1809e+00,\n",
      "          -1.0063e+00,  3.6101e-02, -2.8034e-01,  2.6583e-01, -6.2549e-02,\n",
      "           3.9477e-01,  5.7811e-01,  0.0000e+00,  1.5803e+00, -1.4151e+00,\n",
      "           4.2772e-01,  2.9651e-01, -3.1373e-02, -7.9780e-01, -2.1464e-01,\n",
      "           1.3922e-01,  5.2555e-01,  1.3986e+00,  1.0269e+00, -7.9271e-01,\n",
      "           7.5707e-01, -1.0063e+00,  7.5669e-01,  1.0587e+00, -1.2139e+00,\n",
      "          -1.1318e-01, -1.1073e+00,  5.4869e-01,  0.0000e+00, -1.9016e+00,\n",
      "           5.2889e-01,  9.8626e-01,  1.7014e+00,  9.4323e-01,  6.0845e-01,\n",
      "          -1.5773e-02,  3.5250e-01,  0.0000e+00,  1.3709e+00,  2.4476e+00,\n",
      "           2.4404e-01,  4.6430e-02, -4.6595e-01, -9.8940e-01,  1.6393e+00,\n",
      "          -1.0220e+00,  3.0283e+00,  6.1943e-01, -1.0223e-01, -1.2354e+00,\n",
      "           1.8976e-01, -5.0278e-01, -5.7016e-01,  7.1222e-01, -7.8032e-01,\n",
      "           6.3148e-01,  0.0000e+00,  2.2408e-01, -2.3274e+00,  2.9414e-02,\n",
      "          -8.1320e-01, -1.4097e+00, -1.8368e+00,  6.0346e-01, -9.5595e-01,\n",
      "          -1.9978e-01,  3.8981e-02,  0.0000e+00,  1.3964e+00, -2.0873e+00,\n",
      "          -9.2654e-01,  4.4926e-01, -1.1669e+00,  4.2503e-01, -4.6896e-01,\n",
      "          -7.4398e-01, -1.0650e+00, -9.7454e-01, -1.9435e-02,  2.3976e+00,\n",
      "           6.9830e-01, -1.1218e+00,  1.6914e+00, -1.3993e-01, -6.6915e-01,\n",
      "           0.0000e+00,  7.5930e-01,  0.0000e+00, -1.0328e+00, -9.5686e-02,\n",
      "           1.5603e+00,  5.8699e-01, -3.3917e-01,  6.5751e-01,  1.8405e+00,\n",
      "          -2.5225e-01, -2.1686e-01,  6.2316e-01, -2.3618e+00,  1.0554e+00,\n",
      "           3.0217e-01, -7.7682e-02,  1.5384e-01, -1.2113e+00, -2.2221e-02,\n",
      "           1.6815e+00,  1.8512e+00,  2.7031e-01, -1.2701e+00, -7.1369e-01,\n",
      "          -1.2241e+00, -1.0938e+00, -2.5899e+00,  5.0537e-01, -3.0574e+00,\n",
      "          -2.8689e-01,  4.9857e-01,  8.2909e-01,  3.1701e-01, -7.9275e-01,\n",
      "           0.0000e+00,  2.3396e+00,  1.0568e+00,  8.3815e-01, -4.0330e-01,\n",
      "           7.2667e-01,  0.0000e+00,  3.5918e-01,  8.4181e-01, -1.8294e+00,\n",
      "           1.3637e+00,  2.1587e+00,  3.3750e-01, -1.0150e+00, -1.1708e+00,\n",
      "          -2.2147e+00,  1.6652e+00,  2.1520e+00,  3.6331e-01,  2.3834e+00,\n",
      "           3.2372e-02, -5.0150e-01, -1.2756e+00, -5.4227e-01, -4.0735e-01,\n",
      "          -1.4464e+00,  9.5403e-01,  0.0000e+00,  8.3137e-01, -1.5597e+00,\n",
      "           6.3595e-01,  6.7658e-01,  2.3968e+00,  5.4800e-02,  1.8945e+00,\n",
      "           1.3071e+00,  5.8096e-01, -2.3167e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -2.2714e-01,  1.7329e+00,  2.7726e-01, -1.5522e+00,  9.2256e-01,\n",
      "          -1.2246e+00, -8.4753e-01, -1.8007e+00, -2.3079e-05,  3.7349e-01,\n",
      "          -1.5730e+00, -1.2321e-01,  9.6647e-01, -1.7356e+00,  1.6936e+00,\n",
      "          -1.4405e+00,  6.3400e-01, -1.7212e+00,  9.8062e-01, -1.7146e+00,\n",
      "           1.5597e+00, -2.7189e-01, -2.5965e+00,  1.2380e+00, -1.2290e+00,\n",
      "           1.8830e+00, -5.0846e-01,  0.0000e+00, -2.6170e-01, -1.0211e+00,\n",
      "           1.3328e+00,  3.0962e-01, -5.1712e-02, -2.2900e-01, -1.6108e+00,\n",
      "           1.8060e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0638, 0.1401, 0.1344, 0.0806, 0.1248, 0.1020, 0.1224, 0.0622, 0.1025,\n",
      "         0.0672]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2663,  0.0089, -0.0874,  ...,  0.1464,  0.0284,  0.0604],\n",
      "        [ 0.0741, -0.1391, -0.0497,  ...,  0.3278,  0.2387, -0.0089],\n",
      "        [ 0.1325,  0.4101, -0.1348,  ..., -0.3434,  0.2340, -0.1407],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0502e-01,  7.9867e-02, -1.3574e-01,  2.3759e-01, -1.4613e-02,\n",
      "          -3.8535e-02,  3.8764e-02,  2.4021e-02,  2.7761e-02,  2.7046e-02,\n",
      "          -6.2467e-02,  1.6939e-02, -3.4986e-02,  6.8085e-02,  5.7664e-02,\n",
      "           6.7529e-02,  2.1862e-01,  5.7824e-02, -2.0378e-02,  1.5541e-01,\n",
      "           7.8350e-02,  7.3392e-02,  2.0473e-01,  5.4153e-03,  5.5773e-02,\n",
      "           1.5545e-01, -1.4622e-02, -2.1862e-01, -2.7969e-02,  1.4297e-01,\n",
      "           1.0202e-01, -6.9032e-02,  9.1760e-02, -5.5991e-02,  1.4481e-01,\n",
      "          -3.8689e-02, -7.1836e-02, -2.0404e-02, -1.2792e-01,  2.6525e-01,\n",
      "           1.3120e-02, -4.7889e-03, -5.0480e-02, -1.5060e-01, -3.5724e-02,\n",
      "           1.5465e-01,  1.1391e-01,  3.3423e-02, -8.4906e-02, -2.3740e-02,\n",
      "           1.4543e-01,  1.0448e-01, -2.0700e-01, -5.6306e-02,  1.5258e-01,\n",
      "           4.7039e-02,  1.5286e-01,  1.0044e-01, -9.6989e-02, -1.2849e-01,\n",
      "          -1.1653e-01,  9.0584e-02,  4.7599e-02,  1.0374e-01,  1.3579e-01,\n",
      "          -2.1439e-02,  1.3617e-02,  1.8132e-01, -1.1340e-02,  1.7985e-01,\n",
      "          -6.1274e-02,  1.7135e-01,  9.5388e-02,  5.2421e-02, -1.8458e-03,\n",
      "          -1.1557e-01, -2.7314e-02, -8.6930e-03,  2.0552e-02,  1.5853e-02,\n",
      "          -3.2693e-03, -6.6524e-02, -1.4668e-01, -8.4516e-02, -1.1711e-01,\n",
      "          -6.2061e-02, -1.8883e-02,  9.0724e-02,  1.1002e-01,  6.6272e-02,\n",
      "          -1.0747e-01, -2.8520e-02,  9.1756e-02, -4.1558e-02, -4.3383e-02,\n",
      "           4.2415e-02, -3.6765e-02,  2.3504e-01,  1.0408e-01,  1.9417e-01,\n",
      "          -1.1152e-01,  1.2270e-01, -7.6148e-02,  4.2460e-02, -1.5474e-01,\n",
      "          -1.6100e-01, -7.3577e-03,  2.4809e-02, -2.4932e-01,  1.4761e-02,\n",
      "           1.1083e-01,  1.1968e-02,  5.6076e-02, -1.5385e-01, -3.0917e-02,\n",
      "          -2.5970e-01,  1.6149e-01,  1.1577e-01, -4.0978e-02, -8.1236e-02,\n",
      "           1.0835e-01,  2.0925e-02,  9.7267e-03,  1.0463e-01,  9.5139e-02,\n",
      "          -3.2559e-02,  2.6370e-01, -1.3718e-01,  6.4415e-02, -4.8001e-02,\n",
      "           2.5589e-02,  2.4851e-02, -4.9511e-02,  1.8825e-01,  2.2150e-02,\n",
      "          -6.6867e-02,  2.4746e-01, -7.3393e-02,  5.6831e-02,  4.2453e-03,\n",
      "           1.0835e-01,  4.5928e-02,  1.6445e-02,  1.5642e-02,  1.6963e-01,\n",
      "           2.6648e-02,  2.0292e-03, -9.1644e-02,  2.3512e-01, -1.5035e-01,\n",
      "          -7.3608e-02,  1.4296e-01,  3.8047e-02,  1.2955e-01,  1.1172e-01,\n",
      "           1.5515e-01, -6.2754e-02,  8.2029e-02, -1.2514e-01,  6.6259e-02,\n",
      "          -4.2226e-02, -1.7748e-01, -1.2944e-01,  2.1435e-01, -9.1577e-03,\n",
      "           8.0610e-03, -5.9251e-02, -7.7584e-02, -1.2308e-01,  1.4907e-04,\n",
      "          -4.2090e-03, -6.3092e-02,  9.0895e-02, -5.1853e-03, -6.0033e-02,\n",
      "          -6.2267e-02,  2.9366e-01,  1.3309e-01,  9.0844e-02, -1.6937e-02,\n",
      "           5.8643e-02, -7.5324e-02,  2.0921e-01, -9.2290e-02, -5.7495e-02,\n",
      "           7.4508e-02,  4.3232e-02,  9.1268e-02, -3.4723e-02, -8.5023e-02,\n",
      "           1.0630e-01,  5.1488e-02, -1.0829e-01, -1.3651e-02,  1.0571e-01,\n",
      "          -6.1061e-03, -1.7803e-01,  1.7956e-01,  9.7093e-02, -6.6416e-02,\n",
      "          -1.1148e-01,  1.1132e-01, -2.3670e-02,  5.5536e-02,  1.6536e-01,\n",
      "          -9.9751e-02, -7.7292e-05,  2.5967e-01,  1.9949e-03,  8.1833e-02,\n",
      "           3.9431e-02, -2.5733e-01, -9.5339e-02,  1.0816e-01, -6.0895e-02,\n",
      "           1.5971e-01,  1.3646e-01,  1.6023e-01, -2.0024e-01,  1.8745e-01,\n",
      "           1.8728e-01, -2.2008e-02,  9.4353e-02, -1.7225e-01,  4.6606e-02,\n",
      "          -3.3900e-02, -1.6446e-02, -1.5549e-01, -2.8091e-01,  9.0828e-02,\n",
      "          -9.4893e-02,  4.1630e-02, -1.5465e-01,  1.5683e-01,  1.1488e-01,\n",
      "           6.3500e-02, -4.3097e-03, -1.3487e-03,  2.0581e-01,  1.3641e-01,\n",
      "           1.3110e-01,  8.2367e-02,  1.7550e-01, -6.6133e-02,  2.0716e-01,\n",
      "           5.5653e-02, -1.9910e-01, -3.4955e-03,  1.5065e-01, -4.4763e-02,\n",
      "           9.5784e-02,  9.9737e-02, -2.4498e-01, -1.0494e-01,  1.6262e-01,\n",
      "          -6.3906e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7416e-02,  4.0022e-01, -9.6453e-01, -6.8091e-01,  3.7530e-01,\n",
      "          -2.0165e-01,  1.4643e+00, -8.3789e-02, -3.5829e+00,  9.0700e-01,\n",
      "           4.2787e-01, -6.2943e-01,  2.6014e+00, -6.3069e-01, -5.4137e-01,\n",
      "           0.0000e+00,  8.5159e-01,  1.0941e+00,  4.5524e-01,  0.0000e+00,\n",
      "          -6.3294e-01, -3.8220e-01,  1.6394e+00,  1.5112e+00,  7.5310e-01,\n",
      "          -7.6136e-02, -1.8855e-01, -7.6035e-01,  1.6533e+00,  8.6122e-01,\n",
      "           1.2313e+00,  1.2194e+00, -1.0341e+00,  0.0000e+00, -1.5341e+00,\n",
      "           1.3955e+00,  0.0000e+00, -3.7438e+00,  1.9775e-01,  0.0000e+00,\n",
      "          -4.5889e-01,  0.0000e+00, -2.6936e-01, -1.7137e+00, -1.5230e+00,\n",
      "           6.6834e-01,  5.4036e-01,  3.7154e-01,  0.0000e+00,  1.4482e-01,\n",
      "          -6.2933e-01,  2.7501e+00,  6.0997e-01, -1.0282e+00, -2.4807e-02,\n",
      "           2.0432e-01, -8.8096e-01, -1.2504e+00, -2.3759e-01, -4.2650e-01,\n",
      "           1.0983e+00,  1.4065e+00, -2.0187e-01, -5.0091e-01, -2.9618e+00,\n",
      "           0.0000e+00,  1.2776e+00, -1.2871e+00,  4.0940e-01,  5.2671e-01,\n",
      "          -1.2662e+00, -2.9275e-02,  7.0731e-01, -3.6387e+00,  3.2462e-01,\n",
      "          -3.9440e-04, -1.6018e-01,  1.0609e+00, -5.7083e-02,  0.0000e+00,\n",
      "          -1.3993e+00,  2.1292e+00,  0.0000e+00,  1.0060e+00, -2.0752e-01,\n",
      "           4.3684e-01,  1.6610e+00, -9.7399e-01,  0.0000e+00, -5.8110e-01,\n",
      "          -2.2717e+00,  1.0995e+00, -6.2232e-01, -1.1360e+00,  4.6661e-01,\n",
      "          -1.1696e+00,  3.2149e-02,  6.2872e-01,  1.7191e+00, -7.7762e-01,\n",
      "           0.0000e+00, -1.4610e+00,  1.0759e+00,  1.4520e+00, -6.6593e-01,\n",
      "          -7.6193e-01,  1.2103e+00,  1.2748e-01, -1.4729e+00, -1.4181e-02,\n",
      "          -2.4781e-01,  1.3386e-01, -1.0467e+00,  1.3102e+00, -1.6522e+00,\n",
      "           0.0000e+00, -5.7062e-02, -4.9873e-01, -1.9346e-01,  4.4585e-01,\n",
      "          -1.4643e+00,  7.0180e-01,  0.0000e+00, -7.2543e-01, -9.5736e-01,\n",
      "          -1.3066e+00,  8.9499e-01,  1.6940e-01,  1.2841e+00,  0.0000e+00,\n",
      "          -8.2442e-01,  0.0000e+00, -1.5823e+00,  9.8389e-01,  2.7643e-01,\n",
      "          -5.8897e-01,  6.5789e-01,  5.7590e-01, -1.1593e+00, -1.0090e+00,\n",
      "          -3.8764e-01,  6.7771e-01, -7.8896e-01, -1.0026e-01, -1.6841e+00,\n",
      "          -9.9890e-02, -5.4259e-01, -8.4408e-01,  0.0000e+00,  1.7771e-01,\n",
      "           1.9972e+00, -1.9905e-01, -1.9292e+00, -4.0628e-01,  4.4121e-01,\n",
      "          -1.9455e-01, -6.5206e-02, -1.3082e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -2.6718e-02,  2.2061e+00,  4.8115e-01, -5.5086e-01, -5.2520e-01,\n",
      "          -8.9052e-01,  2.8171e-01,  8.2478e-02, -3.5824e-01,  0.0000e+00,\n",
      "           7.3561e-01, -3.0228e-02,  2.0032e-02, -1.0033e+00,  0.0000e+00,\n",
      "          -1.0974e+00, -9.8526e-01,  0.0000e+00,  1.9677e+00,  8.6295e-02,\n",
      "          -3.1279e-02,  3.5033e-02,  6.7053e-01,  9.8009e-01, -7.4816e-01,\n",
      "          -3.4113e-01, -2.7810e+00, -7.8226e-01,  1.2088e+00,  1.0127e+00,\n",
      "           0.0000e+00,  4.9378e-01, -1.4453e-01, -5.9244e-01,  5.5942e-01,\n",
      "           2.1637e+00, -1.1871e+00,  5.3493e-01,  1.8109e+00, -9.4568e-01,\n",
      "          -1.6625e+00, -1.0152e+00,  1.2423e+00, -1.2230e-01,  2.3207e-01,\n",
      "           0.0000e+00, -2.2915e+00,  6.8188e-01, -1.0724e+00, -4.7145e-01,\n",
      "           2.8671e+00,  0.0000e+00, -3.4155e-01,  7.9239e-01,  3.2638e-02,\n",
      "          -6.8285e-01, -1.0164e+00,  9.6707e-01, -2.4515e-01,  0.0000e+00,\n",
      "          -1.0827e+00, -4.2654e-01,  0.0000e+00, -4.9992e-01,  3.4015e-01,\n",
      "           7.0476e-01, -6.9670e-01, -6.2815e-01,  2.9227e-01, -1.5771e+00,\n",
      "          -1.1078e+00,  1.5811e+00, -6.1352e-01,  1.3104e+00, -2.9785e+00,\n",
      "           4.0329e+00,  5.8496e-01,  4.2605e-02, -1.5777e+00, -2.8566e-01,\n",
      "           0.0000e+00, -3.2459e+00, -3.0330e-01, -8.5138e-01,  1.1389e-02,\n",
      "           2.7589e-01,  0.0000e+00,  2.5217e-01,  2.6161e-01,  3.8691e-01,\n",
      "          -3.6578e-01, -1.6001e-01, -5.5291e-01, -5.1783e-02,  0.0000e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0489, 0.0729, 0.0787, 0.0753, 0.0997, 0.2182, 0.0888, 0.1044, 0.0842,\n",
      "         0.1288]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1732, -0.2346, -0.0185,  ...,  0.2897,  0.3430,  0.1642],\n",
      "        [ 0.1087, -0.0476, -0.0888,  ..., -0.1927,  0.0939,  0.3790],\n",
      "        [-0.2757,  0.3716, -0.2437,  ..., -0.1737,  0.0500,  0.0917],\n",
      "        ...,\n",
      "        [ 0.1814, -0.1248, -0.1933,  ..., -0.2475, -0.3869, -0.1654],\n",
      "        [ 0.0794, -0.2387, -0.3348,  ..., -0.4656,  0.1668, -0.1036],\n",
      "        [ 0.1476,  0.1658, -0.6604,  ..., -0.2523, -0.0332, -0.0783]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3073e-01, -9.8318e-03, -9.2799e-02,  8.0087e-02, -2.8179e-02,\n",
      "           1.1323e-01, -1.7901e-01, -2.1077e-02,  1.0164e-01,  2.7522e-01,\n",
      "           8.1396e-02, -1.6673e-02,  2.1648e-01, -1.4372e-01,  8.3133e-03,\n",
      "           1.4165e-01,  5.7107e-02, -8.8114e-02, -8.4344e-02,  5.8202e-02,\n",
      "           1.5569e-01, -3.2581e-01, -1.0444e-01,  1.1549e-01,  6.3919e-02,\n",
      "           2.2645e-01,  5.9888e-02, -1.3966e-01, -2.1510e-02, -3.1082e-03,\n",
      "           2.5259e-01,  1.3101e-01,  5.2215e-02, -8.0501e-03,  2.0636e-01,\n",
      "          -6.8706e-02,  1.3776e-01,  7.7212e-02, -1.2124e-01, -1.0181e-01,\n",
      "          -5.6758e-02,  1.7035e-01, -6.8866e-03, -1.9809e-01,  1.9347e-02,\n",
      "           1.6661e-02,  5.6525e-02, -2.7637e-01,  3.0879e-02,  1.6323e-01,\n",
      "          -2.6733e-01, -1.0371e-01, -3.3588e-02, -2.5706e-01, -2.9954e-01,\n",
      "          -1.6657e-01, -9.0796e-02, -3.6989e-02, -1.3623e-01,  2.4960e-02,\n",
      "          -1.6785e-01, -9.1702e-02,  5.8168e-03,  6.9354e-02,  3.1245e-01,\n",
      "           3.4619e-02, -1.3152e-01,  2.6774e-02, -7.4101e-02,  1.6462e-01,\n",
      "           1.2184e-01,  1.9110e-01,  1.8674e-02, -1.1166e-01,  1.6980e-02,\n",
      "          -2.6063e-02,  1.1634e-02,  1.5244e-01, -1.9570e-01,  2.1321e-01,\n",
      "           4.8669e-02, -6.0850e-02, -1.4432e-01,  3.7875e-01, -4.1457e-02,\n",
      "           4.0958e-01, -8.4627e-02,  2.8287e-01, -1.0483e-01,  1.0036e-01,\n",
      "           1.7557e-01,  2.2142e-01,  3.4321e-05, -1.6473e-01,  1.6062e-01,\n",
      "           1.5290e-01,  5.7576e-02,  2.8232e-01,  3.3852e-01,  1.0882e-01,\n",
      "           5.3113e-02, -2.3671e-02,  2.7191e-01,  7.2659e-02, -3.3428e-02,\n",
      "          -1.6440e-01,  1.4527e-02,  5.1470e-03,  1.0977e-02,  1.0962e-01,\n",
      "           1.7176e-01,  2.5653e-01,  1.6953e-01, -7.7773e-02, -7.6354e-02,\n",
      "          -1.3785e-01,  6.5811e-04,  8.7382e-02,  8.9639e-02,  7.1552e-02,\n",
      "           2.7051e-01,  7.4160e-02, -2.6887e-01,  2.2245e-03, -1.3385e-01,\n",
      "          -1.1368e-01, -6.5407e-02, -8.3176e-03,  1.9150e-01, -5.5746e-02,\n",
      "           1.1802e-01, -3.1127e-05,  1.4385e-01,  5.9626e-02, -1.1972e-01,\n",
      "          -3.3462e-02,  8.0251e-02,  2.5711e-03, -9.7525e-03, -1.5606e-01,\n",
      "           1.2498e-04,  3.6344e-01, -1.1961e-01,  2.5998e-01, -1.7315e-02,\n",
      "           1.0661e-01,  1.8643e-01,  3.2935e-01,  6.4128e-02,  1.5032e-01,\n",
      "          -1.5018e-01, -1.2441e-01, -1.2764e-01,  1.3330e-01,  7.7029e-02,\n",
      "           1.1912e-01, -5.6633e-02,  2.4703e-01, -2.7330e-01, -1.2277e-02,\n",
      "          -7.8518e-02, -1.6733e-01,  3.9446e-02,  2.9077e-01, -1.9851e-01,\n",
      "          -9.8835e-02,  1.5095e-01,  6.6405e-02, -1.8471e-02,  1.8096e-02,\n",
      "          -3.0506e-01,  7.3909e-02,  2.2259e-02,  3.5201e-03,  8.2418e-02,\n",
      "           2.3378e-02,  1.2134e-01, -2.8924e-02,  2.2233e-01,  4.4309e-02,\n",
      "          -9.7368e-02,  6.9015e-02,  1.3536e-02,  8.3255e-02, -1.2610e-02,\n",
      "          -2.5445e-01, -1.5415e-01, -1.3477e-01, -3.4589e-02,  1.0745e-03,\n",
      "           1.2591e-01, -3.6588e-02,  1.0818e-01, -7.0395e-02,  2.7717e-02,\n",
      "          -7.3878e-02, -2.1485e-01,  7.1324e-02, -5.1565e-02, -1.8225e-01,\n",
      "          -1.3529e-01,  9.6171e-02,  2.0823e-01,  1.6772e-01, -8.4453e-02,\n",
      "           5.9114e-02, -1.2991e-01,  1.7221e-01, -1.5562e-01,  2.4496e-02,\n",
      "           8.9364e-02,  1.5094e-01,  2.2334e-02,  1.5767e-01,  1.8457e-01,\n",
      "          -8.6586e-02,  8.3597e-03,  2.1918e-01,  4.9027e-02,  1.0899e-02,\n",
      "           7.0424e-02, -1.5253e-01,  3.7862e-01, -1.7479e-01, -6.1446e-02,\n",
      "           1.4405e-02, -2.4391e-02, -9.6652e-02, -3.0379e-01,  2.7590e-01,\n",
      "          -1.7151e-02, -8.7169e-02, -1.8663e-01, -1.5350e-01, -1.9459e-01,\n",
      "           5.7236e-02, -1.1924e-01,  1.7358e-01,  4.4540e-01,  2.9028e-01,\n",
      "           6.7025e-02, -2.4962e-01,  8.6865e-02, -2.6561e-05, -3.4630e-02,\n",
      "          -3.1350e-01, -3.2458e-01,  2.9747e-02,  1.3030e-01,  6.7369e-02,\n",
      "           2.4705e-01, -1.5375e-01,  4.2006e-02, -8.6823e-02,  1.0696e-01,\n",
      "          -7.6884e-03]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4728, -0.4586, -1.2333, -0.1188,  0.4614,  0.0260,  0.6619,\n",
      "           0.5338,  0.6709,  0.9340,  1.7074,  0.0000,  0.9455, -0.2516,\n",
      "          -1.6338,  0.0000,  1.8776, -0.7568,  0.0000, -2.6431, -1.1333,\n",
      "           0.1684,  2.9292,  0.5544, -0.1170,  3.2087,  1.8371,  0.5186,\n",
      "          -2.2265, -1.2860,  0.0288,  0.0000,  0.3250,  0.8596, -0.7987,\n",
      "          -1.4655,  0.6197, -0.7716,  1.9912,  0.1016,  0.4672,  0.0000,\n",
      "          -0.5666, -0.1148, -0.7131, -0.6889,  1.9271,  0.1099, -0.2870,\n",
      "          -1.8504,  1.4676,  0.0000,  0.6673, -0.2831,  0.5316,  0.2749,\n",
      "          -1.2430, -0.9507,  1.8136, -0.0118,  0.2053, -1.8187, -1.4010,\n",
      "          -0.8063,  1.1798,  0.2654, -0.1672, -0.2547, -0.0048, -0.4608,\n",
      "          -0.3251, -0.3240,  0.1474, -0.1263,  0.6585, -0.8062,  2.0664,\n",
      "           0.0000,  0.0000,  0.0000,  1.2268,  0.0861,  0.3266, -1.8362,\n",
      "          -0.0709, -1.7315, -1.4585, -0.8915,  0.6230,  0.8108, -1.2239,\n",
      "          -1.1442,  1.9848, -0.3662, -0.7341,  0.1563,  2.1408, -0.4057,\n",
      "          -0.3039, -1.8394, -1.2906,  0.0000, -0.7663,  0.2367,  0.3817,\n",
      "           1.1138, -1.0708,  2.2523, -0.2629, -0.2883, -0.0534,  0.0000,\n",
      "          -0.2543, -0.2804, -1.9418,  1.1286,  1.0065, -2.4969, -0.5753,\n",
      "           0.0296, -1.6944, -0.4008, -0.3790, -0.0782, -0.5367, -1.1106,\n",
      "           1.3040,  0.1695,  0.3222,  1.3582,  2.0787, -2.6339,  0.3600,\n",
      "           0.0000,  0.4292,  0.0603,  0.3264, -2.1011, -0.4969, -1.6773,\n",
      "          -0.6417,  0.2343, -1.1867, -1.2145, -0.6308, -0.0403,  0.4647,\n",
      "           1.7382,  1.5949,  1.4319, -1.2625,  0.0000,  0.0000, -0.0393,\n",
      "           0.3265,  0.0000,  1.3535, -0.0318, -1.9003, -1.8065, -1.4264,\n",
      "          -0.9002, -0.7061, -0.3891, -0.9805, -0.1290,  0.4064,  0.9700,\n",
      "           0.0000, -0.1476,  1.5128, -0.3730, -0.3158, -2.0086,  0.1300,\n",
      "          -0.3526, -0.8298, -0.7686, -0.0404, -0.9373,  0.7276,  1.0417,\n",
      "           0.0469,  0.0000,  0.3159, -0.1183, -0.5406, -0.6643,  0.7547,\n",
      "          -1.0640, -0.5870, -1.7884,  0.0000, -0.9263, -1.6148, -0.3333,\n",
      "          -1.1569, -1.9605, -0.0720, -0.3748,  2.6969, -0.9218, -2.6310,\n",
      "          -0.5863, -0.7156, -1.3863, -1.2539,  0.0000,  0.2191, -1.1106,\n",
      "           0.9448, -0.6921, -1.5191,  0.3621,  0.2379, -1.4262, -2.3444,\n",
      "           0.0478, -1.4793,  0.4269,  0.0000, -0.9014,  0.3010, -1.1654,\n",
      "          -1.3005, -0.1877,  1.2719,  1.2662, -2.1878, -0.0559,  1.7376,\n",
      "          -1.1753,  0.9562,  1.9994,  0.5275,  0.7884,  0.0000,  0.1042,\n",
      "          -0.6804, -2.2617,  0.1674, -0.3133, -1.0431, -0.3820, -1.0798,\n",
      "           0.0000,  1.4992, -0.5644, -1.3767,  1.2435,  0.5827,  1.7529,\n",
      "           1.9518,  0.3627,  0.4876,  0.3901]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0332, 0.2082, 0.0788, 0.0604, 0.1213, 0.1282, 0.0364, 0.1855, 0.0881,\n",
      "         0.0601]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1732, -0.2346, -0.0185,  ...,  0.2897,  0.3430,  0.1642],\n",
      "        [ 0.1087, -0.0476, -0.0888,  ..., -0.1927,  0.0939,  0.3790],\n",
      "        [-0.2757,  0.3716, -0.2437,  ..., -0.1737,  0.0500,  0.0917],\n",
      "        ...,\n",
      "        [ 0.1814, -0.1248, -0.1933,  ..., -0.2475, -0.3869, -0.1654],\n",
      "        [ 0.0794, -0.2387, -0.3348,  ..., -0.4656,  0.1668, -0.1036],\n",
      "        [ 0.1476,  0.1658, -0.6604,  ..., -0.2523, -0.0332, -0.0783]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.1428e-01, -3.1885e-02, -1.1171e-01,  6.3751e-02,  2.3026e-03,\n",
      "           1.6236e-01, -2.3814e-01, -5.5272e-02,  9.5211e-02,  3.2838e-01,\n",
      "           6.6153e-02, -4.9206e-02,  1.7189e-01, -2.2204e-01, -2.8309e-02,\n",
      "           1.5600e-01,  9.4759e-03, -9.1326e-02, -8.2675e-02, -3.7285e-02,\n",
      "           1.5770e-01, -3.0446e-01, -1.6581e-01,  1.4553e-01,  1.1479e-01,\n",
      "           2.5984e-01,  7.4081e-02, -2.1930e-03, -2.3500e-02,  1.3527e-02,\n",
      "           1.7283e-01,  1.3957e-01,  6.5837e-02, -2.6941e-02,  1.7247e-01,\n",
      "          -1.0578e-01,  1.2490e-01,  6.0996e-02, -9.6674e-02, -1.0461e-01,\n",
      "          -2.7244e-02,  1.8334e-01,  6.5218e-03, -1.7621e-01, -2.7594e-03,\n",
      "           5.9905e-02, -1.8825e-02, -2.7791e-01,  5.3306e-02,  2.6159e-01,\n",
      "          -2.2419e-01, -1.6083e-01,  7.7218e-03, -2.0091e-01, -3.3971e-01,\n",
      "          -4.2011e-02, -7.3239e-02,  7.7057e-03, -7.7172e-02, -9.4534e-02,\n",
      "          -1.6476e-01, -1.3544e-01, -7.6246e-03,  4.0927e-02,  3.3334e-01,\n",
      "           3.1737e-02, -1.0114e-01, -5.2568e-03, -7.4147e-02,  8.3635e-02,\n",
      "           1.6388e-01,  1.2137e-01,  1.3100e-01, -9.8505e-02,  5.9222e-02,\n",
      "           3.2363e-02,  8.2951e-02,  1.0378e-01, -1.9865e-01,  1.7760e-01,\n",
      "           6.0588e-02,  4.7596e-02, -1.1585e-01,  3.6366e-01, -5.0934e-02,\n",
      "           3.5878e-01, -9.3119e-02,  3.1542e-01, -1.4496e-01,  7.5562e-02,\n",
      "           2.1962e-01,  2.5236e-01,  3.6874e-02, -2.6148e-01,  1.6103e-01,\n",
      "           1.5866e-01,  7.3758e-02,  2.3703e-01,  3.1769e-01,  2.8947e-02,\n",
      "           1.7625e-01,  9.7730e-03,  2.1819e-01,  6.9264e-02, -5.9509e-02,\n",
      "          -1.8307e-01, -7.1771e-02, -4.5591e-03, -3.8751e-02,  6.1079e-02,\n",
      "           2.0201e-01,  2.9377e-01,  8.0460e-02, -3.5591e-02, -6.1962e-02,\n",
      "          -7.5933e-02,  9.3819e-02,  3.5026e-02,  3.2163e-02,  8.5203e-02,\n",
      "           2.1845e-01,  3.4153e-02, -2.4297e-01, -2.6805e-02, -1.0157e-01,\n",
      "          -1.3535e-01, -5.4537e-02,  6.6979e-03,  1.8779e-01, -5.0015e-02,\n",
      "           5.9844e-02,  8.4590e-02,  8.9970e-02,  2.1708e-02, -1.8281e-01,\n",
      "          -2.7399e-02,  1.2486e-01, -3.7983e-03, -8.3461e-02, -1.5778e-01,\n",
      "          -1.2818e-01,  2.8718e-01, -2.2080e-01,  1.8732e-01, -7.2272e-02,\n",
      "           9.9641e-02,  1.9211e-01,  3.2005e-01,  5.0360e-02,  9.5327e-02,\n",
      "          -1.2329e-01, -1.7496e-01, -1.1491e-01,  6.0547e-02,  9.8192e-02,\n",
      "           5.1648e-02, -6.1356e-02,  2.3872e-01, -2.5606e-01,  4.5036e-02,\n",
      "          -1.2392e-01, -1.0331e-01,  8.7010e-02,  2.8602e-01, -2.2033e-01,\n",
      "          -3.4950e-02,  1.4483e-01,  5.0566e-02,  3.3062e-02, -2.0018e-02,\n",
      "          -3.0149e-01,  1.0085e-01, -4.9699e-02,  8.7774e-02,  2.9561e-02,\n",
      "           6.2837e-02,  1.1598e-01, -3.1405e-02,  1.8101e-01,  7.8075e-02,\n",
      "          -8.9633e-02,  4.8784e-03,  1.9241e-02,  7.8944e-02,  3.2867e-04,\n",
      "          -2.5530e-01, -7.8124e-02, -1.4521e-01, -1.1422e-01,  5.3809e-02,\n",
      "           7.5911e-02, -2.2107e-02,  1.6428e-01, -5.3495e-02, -6.3495e-02,\n",
      "          -9.3324e-02, -2.5480e-01, -5.1128e-02, -9.0453e-02, -1.1772e-01,\n",
      "          -1.0764e-01,  5.0902e-02,  2.2212e-01,  1.3648e-01, -9.1904e-02,\n",
      "           1.1669e-01, -1.3434e-01,  8.5750e-02, -2.1158e-01,  4.5364e-02,\n",
      "           1.1553e-01,  2.1544e-01, -1.4736e-02,  1.7249e-01,  2.0067e-01,\n",
      "          -1.2377e-01, -4.8432e-03,  2.0209e-01,  2.4977e-02, -3.9275e-02,\n",
      "          -1.5344e-02, -1.3129e-01,  3.6405e-01, -1.2361e-01, -4.9976e-02,\n",
      "          -5.2900e-02,  8.6850e-03, -1.7180e-02, -2.4797e-01,  2.8937e-01,\n",
      "           5.1030e-02, -1.2407e-01, -1.9711e-01, -1.1086e-01, -2.3595e-01,\n",
      "           3.9697e-02, -8.7602e-02,  1.7960e-01,  4.4970e-01,  2.3526e-01,\n",
      "           9.3432e-02, -2.3591e-01,  1.2739e-01,  5.6022e-03, -9.3329e-02,\n",
      "          -3.2081e-01, -3.4700e-01,  7.7323e-02,  4.6579e-02,  2.2906e-02,\n",
      "           2.0909e-01, -2.1374e-01,  9.7867e-02, -1.1110e-01,  5.2431e-02,\n",
      "           3.3929e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2144e+00,  1.9547e+00, -3.6760e-01, -1.2732e+00, -1.6875e+00,\n",
      "           1.4303e+00,  2.0849e+00, -8.0146e-01, -2.4206e-01,  1.5030e-01,\n",
      "           3.9156e-01,  8.1437e-01, -5.3819e-01,  7.2569e-03,  3.1029e-01,\n",
      "           0.0000e+00, -1.4740e+00,  2.1801e-01,  3.8048e-01,  4.0277e-01,\n",
      "           6.9893e-01,  1.0701e+00,  2.7980e+00,  5.0776e-01, -1.3777e+00,\n",
      "          -1.0714e+00,  5.5935e-02, -5.3069e-01,  0.0000e+00, -9.0277e-01,\n",
      "           1.7018e+00, -2.5197e-01,  3.0462e-01,  3.4924e-01,  1.0045e+00,\n",
      "          -1.0170e+00,  7.3028e-01, -2.7396e-01, -7.6550e-01, -6.1111e-02,\n",
      "          -1.2187e+00, -9.6327e-01,  6.9201e-01,  4.6117e-01, -2.2543e-01,\n",
      "          -4.9895e-01,  1.3850e+00,  0.0000e+00,  0.0000e+00, -1.7936e+00,\n",
      "           0.0000e+00,  1.8293e-01,  0.0000e+00,  3.6423e-02,  5.0714e-01,\n",
      "           1.1930e-02,  8.2551e-01,  4.5319e-01,  3.7065e-01, -5.5693e-01,\n",
      "           0.0000e+00, -2.1648e+00,  9.7215e-01, -4.2785e-01, -2.1487e+00,\n",
      "           0.0000e+00, -8.8801e-01, -2.9440e-01,  6.2583e-01, -2.9893e+00,\n",
      "           9.7900e-01,  3.2787e-01, -1.1143e-01, -3.9418e-01,  2.5192e+00,\n",
      "           9.5694e-01,  1.9348e-01,  0.0000e+00, -1.1223e+00,  1.0309e+00,\n",
      "          -1.4983e+00, -6.0959e-01, -7.4007e-01,  5.0860e-01,  0.0000e+00,\n",
      "           1.2770e-01,  5.3750e-01,  0.0000e+00, -2.7006e-01,  1.2686e+00,\n",
      "          -1.3820e+00,  0.0000e+00,  1.1105e+00, -2.3919e-01,  4.2364e-01,\n",
      "           8.6824e-02, -5.2170e-01,  6.8134e-01, -5.4694e-01, -2.4452e-01,\n",
      "          -3.0389e-01, -3.7444e-01, -3.0828e-01,  1.4459e+00,  3.1821e-01,\n",
      "          -2.1774e-01,  1.8081e-01,  8.5009e-01, -7.7212e-02,  2.6141e+00,\n",
      "          -1.8021e+00,  5.4078e-02,  0.0000e+00, -2.5750e-01,  3.9696e-01,\n",
      "           1.0299e+00,  1.2516e+00,  7.1804e-01,  1.2861e+00, -1.7569e+00,\n",
      "          -1.7317e+00, -4.7120e-01,  1.0173e+00,  0.0000e+00,  8.5078e-01,\n",
      "          -1.4631e+00, -7.2108e-01, -2.5752e-01, -1.1308e+00,  2.5048e-01,\n",
      "           2.7185e-01,  1.1886e+00,  8.1594e-01,  1.4584e-01, -5.0861e-01,\n",
      "           0.0000e+00, -7.2842e-01, -3.4645e-01,  1.0280e+00, -1.8979e-01,\n",
      "           2.0756e+00,  1.1949e+00, -6.9063e-01, -7.3710e-01,  9.0350e-01,\n",
      "          -1.0654e+00, -1.0944e+00, -2.7298e-01,  6.3468e-02, -1.6972e+00,\n",
      "          -5.8330e-01,  6.4010e-01,  0.0000e+00,  8.9725e-01,  1.4513e+00,\n",
      "          -5.2605e-01,  7.7649e-01,  9.0549e-01, -1.9761e-01,  5.7960e-01,\n",
      "          -1.5882e+00,  0.0000e+00,  1.9655e-01, -4.8012e-01, -1.2564e-01,\n",
      "          -1.0646e+00, -6.6111e-02,  0.0000e+00,  2.7363e-03, -5.4602e-01,\n",
      "          -5.9126e-01,  5.4900e-01, -2.7585e-01,  5.4475e-01,  0.0000e+00,\n",
      "           3.4184e-02, -5.0640e-01,  5.8831e-01, -1.2881e+00,  3.8353e-01,\n",
      "          -6.4571e-01,  0.0000e+00, -1.1286e+00,  2.5554e-01,  0.0000e+00,\n",
      "          -6.9891e-02,  1.5551e+00,  1.1998e+00,  8.8799e-01,  0.0000e+00,\n",
      "          -1.3347e+00, -1.5611e+00, -4.3068e-01,  0.0000e+00, -1.2726e+00,\n",
      "           9.7543e-01, -1.3326e-01, -2.3906e-01, -8.4792e-01, -8.3286e-02,\n",
      "          -3.4543e-02,  1.6270e+00,  3.3584e+00,  0.0000e+00,  2.7381e-01,\n",
      "           1.0958e+00, -2.6697e-02,  0.0000e+00,  0.0000e+00, -1.6661e+00,\n",
      "          -1.2360e+00, -1.4498e-01,  0.0000e+00, -7.2948e-01, -5.4787e-01,\n",
      "           1.7395e+00,  7.3912e-01,  4.3627e-01,  1.8402e+00,  8.3978e-01,\n",
      "           1.5018e+00,  3.9054e-01, -1.2277e+00,  0.0000e+00, -1.2883e+00,\n",
      "          -7.7988e-01,  2.8104e-01,  2.1952e-01, -2.2286e+00,  2.0219e+00,\n",
      "           1.1893e+00,  8.9513e-01,  0.0000e+00, -8.8615e-01,  0.0000e+00,\n",
      "          -2.7816e-02,  2.5081e+00, -3.8429e-01,  0.0000e+00, -1.7030e+00,\n",
      "          -8.1643e-01, -2.2854e-01, -2.0579e+00, -9.3820e-01,  1.9448e+00,\n",
      "           2.2884e-01,  8.8072e-02,  1.6646e-01,  5.7535e-01,  6.6584e-01,\n",
      "          -1.6297e-01,  0.0000e+00,  0.0000e+00,  1.2908e+00,  9.9962e-01,\n",
      "          -8.0321e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1073, 0.1417, 0.1018, 0.0277, 0.0796, 0.1586, 0.0459, 0.1035, 0.0668,\n",
      "         0.1673]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1732, -0.2346, -0.0185,  ...,  0.2897,  0.3430,  0.1642],\n",
      "        [ 0.1087, -0.0476, -0.0888,  ..., -0.1927,  0.0939,  0.3790],\n",
      "        [-0.2757,  0.3716, -0.2437,  ..., -0.1737,  0.0500,  0.0917],\n",
      "        ...,\n",
      "        [ 0.1814, -0.1248, -0.1933,  ..., -0.2475, -0.3869, -0.1654],\n",
      "        [ 0.0794, -0.2387, -0.3348,  ..., -0.4656,  0.1668, -0.1036],\n",
      "        [ 0.1476,  0.1658, -0.6604,  ..., -0.2523, -0.0332, -0.0783]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1240,  0.0019, -0.1284,  0.0664, -0.0054,  0.0983, -0.2114,\n",
      "          -0.0645,  0.0845,  0.3043,  0.1227, -0.0817,  0.1531, -0.1822,\n",
      "          -0.0070,  0.0982,  0.0311, -0.1208, -0.1447, -0.0343,  0.1693,\n",
      "          -0.2942, -0.1249,  0.0876,  0.0777,  0.2688,  0.0389, -0.0449,\n",
      "          -0.0036, -0.0286,  0.1643,  0.0830, -0.0019, -0.0209,  0.1598,\n",
      "          -0.0587,  0.0899,  0.0080, -0.1339, -0.1136, -0.0362,  0.1818,\n",
      "          -0.0563, -0.1597,  0.0312,  0.0412, -0.0371, -0.2409,  0.0188,\n",
      "           0.2059, -0.1665, -0.1789,  0.0076, -0.1968, -0.2881, -0.0988,\n",
      "          -0.0903,  0.0307, -0.0790, -0.0538, -0.1094, -0.0992,  0.0088,\n",
      "           0.0050,  0.3280,  0.0106, -0.0944,  0.0663, -0.0770,  0.1693,\n",
      "           0.1394,  0.1913,  0.0618, -0.0341,  0.0106, -0.0121,  0.0405,\n",
      "           0.1256, -0.2036,  0.1930,  0.0648, -0.0089, -0.1768,  0.3152,\n",
      "          -0.0403,  0.3744, -0.0704,  0.2972, -0.1401,  0.1091,  0.1988,\n",
      "           0.2318,  0.0072, -0.1883,  0.1574,  0.1077,  0.0784,  0.2680,\n",
      "           0.2723,  0.1144,  0.0566, -0.0271,  0.2237,  0.0664, -0.0977,\n",
      "          -0.1524,  0.0278,  0.0292, -0.0037,  0.1029,  0.1823,  0.2436,\n",
      "           0.1176, -0.0620, -0.0918, -0.1093,  0.0687,  0.0321,  0.0383,\n",
      "           0.0548,  0.2091, -0.0071, -0.2570,  0.0025, -0.1014, -0.1132,\n",
      "          -0.0012,  0.0365,  0.1515, -0.0555,  0.0827,  0.0179,  0.1087,\n",
      "           0.0488, -0.1577, -0.0333,  0.1598, -0.0239, -0.0578, -0.1148,\n",
      "          -0.1039,  0.2963, -0.1266,  0.2043, -0.0334,  0.0862,  0.1610,\n",
      "           0.2810,  0.0561,  0.0885, -0.0949, -0.1728, -0.1029,  0.0855,\n",
      "           0.1191,  0.0577, -0.0426,  0.2021, -0.2238,  0.0071, -0.0876,\n",
      "          -0.1110,  0.0542,  0.3192, -0.1682, -0.0532,  0.1835, -0.0024,\n",
      "           0.0327,  0.0255, -0.2809,  0.1161, -0.0267,  0.0434,  0.0221,\n",
      "           0.0275,  0.0792, -0.0092,  0.2456,  0.0712, -0.0896,  0.0334,\n",
      "           0.0309,  0.0524, -0.0015, -0.2518, -0.1413, -0.1006, -0.0496,\n",
      "           0.0557,  0.1217,  0.0125,  0.0924, -0.0418, -0.0298, -0.1057,\n",
      "          -0.2215, -0.0351, -0.0096, -0.1026, -0.1177,  0.0785,  0.1967,\n",
      "           0.1277, -0.0669,  0.0875, -0.1340,  0.1595, -0.1897,  0.0293,\n",
      "           0.0936,  0.1300,  0.0306,  0.1562,  0.1819, -0.0209, -0.0157,\n",
      "           0.1731, -0.0022,  0.0422, -0.0079, -0.1368,  0.3034, -0.1254,\n",
      "           0.0269, -0.0484,  0.0045, -0.0896, -0.2613,  0.2919,  0.0237,\n",
      "          -0.0632, -0.1646, -0.1789, -0.2093,  0.0511, -0.0833,  0.1570,\n",
      "           0.4157,  0.2140,  0.1062, -0.2516,  0.0706,  0.0215, -0.0706,\n",
      "          -0.2844, -0.3269,  0.0647,  0.1267,  0.0690,  0.1927, -0.1932,\n",
      "           0.0202, -0.0860,  0.1044,  0.0425]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4948,  1.3394,  1.6357, -0.5213,  0.6128, -0.8448,  0.5356,\n",
      "          -2.2966,  0.5186,  0.5508,  0.1152,  0.8371, -0.6380,  1.6211,\n",
      "          -0.9292,  0.7404,  0.0000, -0.4478,  0.0000, -0.2111,  1.6733,\n",
      "           0.6202, -1.2471, -1.1120, -0.3097, -0.4955,  0.0000, -1.9692,\n",
      "           0.2527,  0.0000, -0.4371, -0.5127, -0.0531, -1.3693,  0.0000,\n",
      "           0.5027, -0.7311, -0.5372, -0.4124, -0.0607, -0.1329,  2.9002,\n",
      "          -1.2678,  0.1426, -1.5398,  0.0383,  0.9134,  0.7181, -1.2736,\n",
      "          -1.2230, -0.2042,  0.3196, -0.0381,  0.7533, -0.2374,  2.4547,\n",
      "          -0.4389, -1.9683,  0.0607, -1.5413, -0.0414, -0.5703,  0.3405,\n",
      "           0.8439, -1.5039,  0.2720, -0.5674, -0.4235, -1.3315, -0.7834,\n",
      "          -1.6775, -1.3192,  2.3763, -0.2214, -1.1424, -0.2752,  2.1747,\n",
      "          -1.6951, -0.6015, -1.5266,  0.1800, -0.8863,  0.6990, -0.9897,\n",
      "          -2.1091,  1.0208,  2.4606,  0.0000,  0.8545,  0.4435,  0.4730,\n",
      "           0.0993,  0.0000,  0.0896,  1.1561, -0.1494,  0.4214,  0.4051,\n",
      "          -0.8989,  0.6069,  0.4777,  0.0000, -2.3706,  1.9165,  1.5937,\n",
      "          -0.0759,  0.0000, -0.8316, -0.2047,  2.1879,  0.0218,  1.1714,\n",
      "          -0.6709, -1.3796, -0.5576,  0.6556,  0.0000, -0.0892, -1.4339,\n",
      "          -0.1999,  0.8132, -1.0610,  0.0000,  1.4184, -1.5580, -0.4756,\n",
      "           0.0000,  0.2549,  0.9326,  1.5652, -0.9903, -1.0206,  0.0000,\n",
      "          -0.0191,  1.1280, -0.1810, -2.0600,  0.6161,  0.0000,  1.9542,\n",
      "           0.3748,  0.0000, -0.1812, -2.6065,  0.2687, -0.7283,  0.5797,\n",
      "           0.2356,  0.0000,  2.1191, -1.7739, -0.3392,  0.0399,  0.2899,\n",
      "          -0.9379, -1.1762,  0.5137,  0.9559,  0.0000, -0.6644,  0.2260,\n",
      "           0.4704, -2.0087, -0.5008, -1.4648, -0.4248, -1.8299,  0.8127,\n",
      "           0.2219,  1.9092,  0.0000, -0.2265, -0.5205, -0.2066, -0.7871,\n",
      "           0.9041, -1.0562,  0.6844,  0.3005, -1.6286,  0.6128, -0.9399,\n",
      "           0.3274,  1.6614,  0.4429, -1.5483, -0.9545,  0.6448, -0.5213,\n",
      "           0.0108, -1.2260, -0.0948,  0.0000, -0.0327, -1.5257,  0.3804,\n",
      "          -0.9090, -0.8496,  0.7242,  1.9618,  0.5750, -1.2566,  0.1917,\n",
      "          -0.1579,  0.5557, -1.7970, -0.1457,  1.4672, -0.8936,  1.3200,\n",
      "          -0.8092,  0.3385,  1.5922,  0.0000,  0.0000, -0.4913,  0.8604,\n",
      "           0.0000,  0.6022,  0.0000, -0.9776,  1.0776,  0.3333,  0.4732,\n",
      "          -0.1149,  0.0000,  0.2195,  0.0296,  0.3388, -1.7372,  0.0577,\n",
      "          -1.1993,  0.9936,  1.8374,  0.8460, -0.6814,  1.2701,  0.0000,\n",
      "          -1.1624,  1.5500, -0.0259,  1.2902, -1.3475, -1.3427, -1.4844,\n",
      "          -0.0681,  0.4578, -0.5426,  0.1520, -0.3816,  0.6338, -0.7510,\n",
      "          -0.5027,  1.7237,  1.1371, -0.8913]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0897, 0.0851, 0.0738, 0.0960, 0.0710, 0.0664, 0.1676, 0.1219, 0.1793,\n",
      "         0.0492]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1732, -0.2346, -0.0185,  ...,  0.2897,  0.3430,  0.1642],\n",
      "        [ 0.1087, -0.0476, -0.0888,  ..., -0.1927,  0.0939,  0.3790],\n",
      "        [-0.2757,  0.3716, -0.2437,  ..., -0.1737,  0.0500,  0.0917],\n",
      "        ...,\n",
      "        [ 0.1814, -0.1248, -0.1933,  ..., -0.2475, -0.3869, -0.1654],\n",
      "        [ 0.0794, -0.2387, -0.3348,  ..., -0.4656,  0.1668, -0.1036],\n",
      "        [ 0.1476,  0.1658, -0.6604,  ..., -0.2523, -0.0332, -0.0783]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.1939e-02, -8.2927e-02, -1.5353e-01,  4.4265e-02,  4.6932e-02,\n",
      "           1.4627e-01, -2.9947e-01, -1.4138e-02,  8.1411e-02,  2.3391e-01,\n",
      "           3.4585e-02,  3.0179e-02,  1.6496e-01, -1.4274e-01, -3.6523e-03,\n",
      "           1.3645e-01, -2.1009e-02, -8.2963e-02, -1.2552e-01, -2.7272e-02,\n",
      "           2.3924e-01, -3.1894e-01, -1.1129e-01,  5.6966e-02,  1.2628e-01,\n",
      "           1.8644e-01,  1.0035e-01, -1.0267e-01, -1.7725e-02,  8.4199e-02,\n",
      "           2.5331e-01,  1.3992e-01,  7.2183e-02, -2.0803e-02,  1.4943e-01,\n",
      "          -1.0438e-01,  1.1337e-01,  4.6934e-02, -9.9026e-02, -1.2434e-01,\n",
      "          -4.1606e-02,  2.0219e-01, -3.5249e-02, -2.1107e-01, -6.3505e-03,\n",
      "           7.2277e-02,  2.8737e-02, -2.6670e-01,  5.9170e-02,  1.7341e-01,\n",
      "          -2.7155e-01, -1.0416e-01,  3.4829e-03, -2.7089e-01, -3.1397e-01,\n",
      "          -7.9030e-02, -1.2175e-01, -1.0357e-01, -1.0765e-01, -2.2575e-02,\n",
      "          -1.7202e-01, -1.0849e-01,  7.9973e-05,  1.2269e-01,  2.9271e-01,\n",
      "           5.6744e-02, -1.5078e-01,  1.1394e-01, -4.1321e-02,  1.7149e-01,\n",
      "           1.9391e-01,  1.2175e-01,  1.0666e-01, -1.0283e-01,  2.9780e-02,\n",
      "           4.6113e-02,  6.6129e-02,  1.6096e-01, -1.6389e-01,  2.2021e-01,\n",
      "           1.3979e-02,  3.8808e-02, -1.5349e-01,  3.8532e-01, -3.2998e-02,\n",
      "           3.6264e-01, -4.1259e-02,  2.5294e-01, -8.5363e-02,  9.9348e-02,\n",
      "           1.8257e-01,  2.3949e-01, -4.6859e-02, -1.9559e-01,  1.2511e-01,\n",
      "           1.3982e-01,  5.4599e-02,  1.5790e-01,  3.5054e-01,  9.2587e-02,\n",
      "           1.8268e-01,  1.6204e-02,  2.3891e-01,  7.8910e-02, -4.1138e-02,\n",
      "          -1.7543e-01, -6.2719e-02, -3.1539e-02, -1.1273e-01,  9.4042e-02,\n",
      "           9.0805e-02,  3.6204e-01,  9.0435e-02, -6.9514e-02, -4.1287e-02,\n",
      "          -1.0666e-01,  1.2790e-02,  9.4348e-02,  7.8901e-02,  3.8580e-02,\n",
      "           2.1607e-01,  6.4801e-02, -3.4803e-01, -1.0567e-02, -1.9704e-01,\n",
      "          -8.4280e-02,  3.8872e-02, -1.4310e-01,  1.9239e-01, -9.6984e-02,\n",
      "           1.2305e-01,  5.8843e-02,  3.2441e-02,  8.1326e-02, -1.2682e-01,\n",
      "          -1.2856e-03,  1.4203e-01,  4.0532e-02, -3.2905e-02, -1.0763e-01,\n",
      "          -5.4930e-02,  3.2987e-01, -1.5698e-01,  2.1360e-01, -6.3657e-02,\n",
      "           9.6061e-02,  2.2751e-01,  3.0553e-01,  1.0671e-01,  1.7485e-01,\n",
      "          -1.4339e-01, -1.0948e-01, -1.5969e-01,  1.1220e-01,  1.3129e-01,\n",
      "           1.1154e-01, -5.8562e-02,  2.5883e-01, -2.9668e-01,  2.8971e-02,\n",
      "          -8.4547e-02, -9.0578e-02,  8.3400e-02,  3.2085e-01, -2.6822e-01,\n",
      "          -7.2554e-02,  1.4994e-01, -1.5985e-02, -9.1644e-02, -6.2491e-02,\n",
      "          -3.1979e-01,  1.0567e-01, -1.6066e-02,  7.4166e-02,  8.8951e-02,\n",
      "          -4.1895e-02,  1.7746e-01, -8.0831e-02,  1.2984e-01,  9.4610e-02,\n",
      "          -1.1188e-01,  2.1125e-03, -2.6329e-02,  6.9709e-02, -2.0704e-02,\n",
      "          -2.7143e-01, -4.9596e-02, -1.4984e-01, -1.6377e-01,  4.0512e-02,\n",
      "           1.5242e-01, -2.1672e-02,  1.7407e-01, -9.7811e-02, -6.2682e-02,\n",
      "          -7.2776e-02, -1.7811e-01,  2.8418e-02, -4.2485e-02, -1.8949e-01,\n",
      "          -7.5852e-02,  3.1722e-02,  2.0774e-01,  9.7050e-02, -8.4095e-02,\n",
      "           7.1441e-02, -5.5904e-02,  1.3089e-01, -1.3917e-01, -8.8682e-03,\n",
      "           7.6430e-02,  1.5635e-01, -3.8890e-02,  1.2895e-01,  1.9910e-01,\n",
      "          -1.4377e-01, -4.4522e-02,  2.0970e-01,  3.4120e-02, -1.0915e-01,\n",
      "           6.5699e-02, -7.6587e-02,  4.1999e-01, -1.2837e-01, -4.8755e-02,\n",
      "          -6.3457e-03, -8.3516e-02, -1.7041e-02, -2.9812e-01,  2.4395e-01,\n",
      "           1.8078e-02, -1.6004e-01, -2.6173e-01, -9.2324e-02, -1.4548e-01,\n",
      "           9.5956e-02, -9.0426e-02,  1.0305e-01,  4.8858e-01,  2.8072e-01,\n",
      "           6.8230e-02, -2.8088e-01,  1.2219e-01,  5.7615e-02, -1.3800e-02,\n",
      "          -3.3665e-01, -2.7535e-01, -3.7783e-02,  3.1373e-02, -1.9552e-02,\n",
      "           2.3523e-01, -1.6836e-01,  1.1175e-01, -1.5769e-01,  5.6526e-02,\n",
      "          -4.2710e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4399e-01, -1.4336e+00, -1.4751e-01, -2.0005e-01, -7.6297e-01,\n",
      "          -9.6891e-01,  1.0221e-01, -6.1552e-02,  6.6568e-01,  9.5849e-01,\n",
      "          -2.9219e-02,  8.9951e-03, -4.9964e-01,  6.4359e-01,  5.5419e-01,\n",
      "           2.6699e+00, -2.8936e-01,  1.0260e+00, -1.5081e+00, -1.4264e-02,\n",
      "          -3.4168e-01,  2.2337e+00,  3.5268e-01, -1.8288e-01, -1.1858e-01,\n",
      "           3.3114e-01,  6.7090e-01,  4.4809e-01,  1.7215e-01, -6.7601e-01,\n",
      "          -4.5146e-01, -3.1703e-01,  0.0000e+00, -2.1954e+00,  1.4447e+00,\n",
      "          -2.2064e-01, -1.0908e+00,  1.3737e+00, -4.3124e-01,  0.0000e+00,\n",
      "          -9.7013e-01,  3.0099e+00,  1.1976e+00, -6.2977e-02,  1.8139e+00,\n",
      "          -1.9049e+00,  1.1579e+00, -7.1054e-01,  1.8835e-01,  1.6588e+00,\n",
      "           7.9717e-01, -1.4625e+00,  1.6614e+00,  9.6100e-01,  0.0000e+00,\n",
      "           1.1107e+00, -1.1958e+00,  7.4744e-01,  1.5675e+00, -2.9071e-01,\n",
      "          -1.3888e+00, -2.7666e-01, -1.0927e+00, -3.1775e+00,  0.0000e+00,\n",
      "          -1.4136e+00,  4.8494e-01,  1.5915e+00,  1.4404e+00,  6.1354e-01,\n",
      "          -1.1493e+00, -1.0686e+00,  6.0796e-01,  3.6740e-02, -4.6373e-02,\n",
      "           2.1406e+00,  1.0710e+00,  3.4767e-01,  8.1256e-02, -3.2292e+00,\n",
      "           7.0394e-01,  1.0747e+00, -9.9015e-01, -4.9037e-01,  6.1956e-02,\n",
      "           2.8062e-01,  3.9078e-01,  1.5539e+00, -4.2874e-01,  1.0542e+00,\n",
      "           6.3034e-01,  7.4437e-01,  4.4943e-01, -3.3578e-01,  2.1539e+00,\n",
      "          -1.1724e+00,  8.7680e-01, -5.7438e-01,  5.2897e-02, -6.9318e-01,\n",
      "           2.0050e+00,  1.2555e-01, -1.8124e+00,  4.8427e-01,  7.5363e-01,\n",
      "           0.0000e+00,  0.0000e+00,  3.9455e-02,  9.1236e-01,  0.0000e+00,\n",
      "          -1.5939e+00,  9.5886e-01, -2.8355e-01, -7.6175e-01,  2.2174e-01,\n",
      "           4.5196e-01,  7.9347e-03, -3.5588e-01,  0.0000e+00, -6.9892e-01,\n",
      "           5.9764e-01,  5.7046e-02, -9.4636e-01,  4.0932e-01,  1.0958e+00,\n",
      "           0.0000e+00, -4.0152e-02, -1.4611e-01, -1.3232e+00,  6.9313e-01,\n",
      "          -8.6974e-01,  5.1486e-01, -3.7767e-01,  1.5273e-01,  1.5009e+00,\n",
      "          -1.2919e-01,  3.7551e-01, -1.2977e+00, -1.4626e+00, -2.9762e-01,\n",
      "           4.2972e-01,  1.0086e+00, -3.5791e+00,  1.2639e+00,  2.9082e-01,\n",
      "           1.2457e+00, -6.5100e-01,  0.0000e+00, -6.1106e-01,  0.0000e+00,\n",
      "          -2.6225e+00, -9.9134e-02,  1.0031e+00, -3.7964e-01, -6.2610e-01,\n",
      "           5.1166e-01, -9.7915e-01,  0.0000e+00,  3.4119e-01, -8.9486e-01,\n",
      "           9.5971e-01, -1.3382e-01, -2.2437e+00, -1.7920e-01,  9.3324e-01,\n",
      "           3.6114e-01, -2.1352e+00,  1.7292e+00,  4.1715e-01,  0.0000e+00,\n",
      "           1.6392e+00,  4.9781e-01, -2.1221e-03,  2.4555e-01, -8.0625e-02,\n",
      "           4.2291e-01,  2.9242e-01, -1.1184e+00,  0.0000e+00, -1.7061e+00,\n",
      "           1.9176e+00,  8.4174e-01, -1.8039e-01,  1.6086e+00,  1.7024e+00,\n",
      "           1.6363e+00,  2.0701e-01,  5.4097e-01, -1.3445e+00,  2.6291e-01,\n",
      "          -1.5586e+00,  1.0090e+00,  0.0000e+00, -1.4234e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.5373e+00, -1.3749e+00, -2.4631e-01,  2.3482e+00,\n",
      "           1.8641e+00,  0.0000e+00,  5.4217e-01, -6.2748e-01,  9.1717e-01,\n",
      "           6.2288e-01, -7.6104e-01, -9.3958e-01,  5.8336e-01,  9.2538e-01,\n",
      "           6.2167e-01,  2.9678e-01, -3.1304e-01,  8.5714e-01,  0.0000e+00,\n",
      "           9.4796e-01,  0.0000e+00, -8.8162e-01, -1.0619e+00,  1.9934e-01,\n",
      "           0.0000e+00,  1.5467e+00, -3.0230e-01,  0.0000e+00,  2.1349e-01,\n",
      "          -4.6503e-01,  1.2198e+00,  2.9554e-01,  2.6785e-01,  1.2017e+00,\n",
      "          -1.4104e+00, -3.4675e-02,  1.3702e-01, -2.3607e-01,  3.8487e-01,\n",
      "          -2.5183e-01,  5.3249e-01, -6.5995e-01, -7.1170e-01,  6.4904e-01,\n",
      "           3.2165e+00,  1.3366e+00, -1.3917e+00, -8.2209e-01,  1.7681e+00,\n",
      "           1.5245e+00, -3.2453e-01, -1.7378e+00,  6.5037e-02,  1.2118e+00,\n",
      "           7.4997e-01,  2.9102e+00, -5.9099e-01,  8.5160e-01,  2.2605e-03,\n",
      "          -4.3466e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1042, 0.0675, 0.0643, 0.1188, 0.1989, 0.0732, 0.1052, 0.1318, 0.0521,\n",
      "         0.0841]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1732, -0.2346, -0.0185,  ...,  0.2897,  0.3430,  0.1642],\n",
      "        [ 0.1087, -0.0476, -0.0888,  ..., -0.1927,  0.0939,  0.3790],\n",
      "        [-0.2757,  0.3716, -0.2437,  ..., -0.1737,  0.0500,  0.0917],\n",
      "        ...,\n",
      "        [ 0.1814, -0.1248, -0.1933,  ..., -0.2475, -0.3869, -0.1654],\n",
      "        [ 0.0794, -0.2387, -0.3348,  ..., -0.4656,  0.1668, -0.1036],\n",
      "        [ 0.1476,  0.1658, -0.6604,  ..., -0.2523, -0.0332, -0.0783]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.2604e-02, -5.1986e-02, -1.4144e-01,  6.7854e-02, -7.0075e-02,\n",
      "           7.7282e-02, -1.8513e-01,  2.0699e-03,  1.0418e-01,  2.8279e-01,\n",
      "           7.7410e-02, -2.2584e-02,  2.0830e-01, -2.3349e-01, -5.0323e-02,\n",
      "           9.6520e-02,  2.3824e-03, -8.0710e-02, -4.8873e-02,  5.9207e-02,\n",
      "           1.7188e-01, -3.0295e-01, -1.6508e-01,  6.8773e-02,  7.7718e-02,\n",
      "           2.3631e-01,  4.1892e-02, -2.7239e-02, -5.1568e-02,  3.1415e-02,\n",
      "           1.9914e-01,  1.1310e-01,  9.6884e-02,  1.0076e-02,  1.4335e-01,\n",
      "          -2.0249e-01,  1.3384e-01,  3.5455e-04, -3.6509e-02, -1.1489e-01,\n",
      "           1.9106e-02,  1.6037e-01,  4.9792e-02, -1.9386e-01,  3.2441e-02,\n",
      "           1.9259e-02,  6.8198e-02, -2.4133e-01,  8.0878e-02,  1.2790e-01,\n",
      "          -3.0808e-01, -6.5933e-02, -2.5452e-02, -2.5703e-01, -3.1671e-01,\n",
      "          -8.9848e-02, -7.7298e-02, -4.2163e-02, -1.7793e-01,  4.3918e-03,\n",
      "          -1.6236e-01, -1.2497e-01,  5.7514e-02,  5.4087e-02,  3.1335e-01,\n",
      "           4.7722e-02, -1.3924e-01, -8.1709e-03, -3.0443e-02,  7.2165e-02,\n",
      "           1.5531e-01,  9.4173e-02,  6.1182e-02, -8.5065e-02,  7.4068e-02,\n",
      "          -2.9603e-02,  5.9762e-02,  9.2327e-02, -1.5071e-01,  1.6395e-01,\n",
      "           4.3247e-02, -2.6550e-02, -4.3553e-02,  3.4908e-01, -6.2487e-02,\n",
      "           3.8594e-01, -9.7043e-02,  2.2097e-01, -1.0908e-01,  6.3956e-02,\n",
      "           1.9637e-01,  2.7995e-01, -6.0297e-03, -2.0633e-01,  1.4322e-01,\n",
      "           1.3921e-01,  8.1597e-03,  2.1539e-01,  3.4091e-01,  4.3093e-02,\n",
      "           1.6829e-01, -4.6550e-02,  2.7990e-01,  5.4124e-02, -6.8016e-02,\n",
      "          -1.3683e-01, -1.0887e-01, -9.1471e-02, -2.7949e-03,  9.9357e-02,\n",
      "           1.2893e-01,  3.2081e-01,  1.5512e-01, -1.8305e-02, -7.8256e-02,\n",
      "          -1.1131e-01, -2.2429e-04,  8.5586e-02,  5.8508e-02,  7.4208e-02,\n",
      "           2.7969e-01,  1.1481e-01, -2.6700e-01,  1.0056e-02, -1.0306e-01,\n",
      "          -1.1474e-01, -9.3298e-02, -7.2245e-02,  2.1793e-01, -7.6622e-02,\n",
      "           9.7006e-02,  3.1299e-02,  8.1951e-02,  4.8412e-02, -1.5314e-01,\n",
      "           3.3413e-02,  1.3106e-01, -2.0301e-02, -3.6481e-02, -1.5588e-01,\n",
      "          -4.6661e-02,  3.5497e-01, -2.4110e-01,  2.5972e-01, -5.9970e-02,\n",
      "           1.0578e-01,  1.7832e-01,  2.6595e-01,  7.4163e-02,  1.7001e-01,\n",
      "          -1.4449e-01, -1.6746e-01, -9.8696e-02,  1.1376e-01,  7.1170e-02,\n",
      "           6.7030e-02, -2.7321e-02,  2.1130e-01, -2.2308e-01,  7.9150e-02,\n",
      "          -7.9995e-02, -1.1341e-01,  6.4839e-02,  1.8160e-01, -2.2764e-01,\n",
      "          -4.5747e-02,  1.6360e-01,  9.6796e-03, -3.1863e-03, -1.4587e-02,\n",
      "          -3.0102e-01,  1.1606e-01, -3.0469e-02,  4.4138e-02,  3.9214e-02,\n",
      "           2.2919e-02,  1.3719e-01, -1.0143e-01,  1.5935e-01,  5.1988e-02,\n",
      "          -6.1021e-02,  7.6484e-02,  2.5492e-02,  6.6962e-02, -2.6536e-02,\n",
      "          -3.1302e-01, -1.4770e-01, -1.0650e-01, -6.3127e-02,  6.6298e-02,\n",
      "           4.4883e-02, -1.6671e-02,  1.5524e-01, -7.8608e-02,  3.7058e-02,\n",
      "          -3.5010e-03, -2.0421e-01,  1.6353e-02, -3.8564e-02, -1.2801e-01,\n",
      "          -1.0076e-01,  2.5902e-02,  2.1196e-01,  1.6400e-01, -6.2196e-02,\n",
      "           7.1126e-02, -6.1330e-02,  1.5349e-01, -2.0656e-01,  3.3677e-02,\n",
      "           1.4783e-01,  1.7270e-01, -3.0572e-02,  1.4750e-01,  1.4248e-01,\n",
      "          -9.3043e-02, -6.3116e-02,  2.4333e-01,  1.1536e-01, -2.7938e-02,\n",
      "           6.9920e-02, -1.2957e-01,  3.4174e-01, -1.3464e-01, -9.3225e-02,\n",
      "          -5.3837e-02,  3.6845e-02, -7.9138e-02, -1.6970e-01,  2.6149e-01,\n",
      "           7.9270e-04, -1.4052e-01, -2.2954e-01, -9.1701e-02, -1.5098e-01,\n",
      "           1.7360e-02, -9.1338e-02,  1.7469e-01,  4.2756e-01,  2.7321e-01,\n",
      "           4.7194e-02, -2.1289e-01,  9.8564e-02,  2.1335e-02,  2.0024e-02,\n",
      "          -3.0590e-01, -2.3662e-01,  2.2913e-02,  6.9193e-02,  8.5239e-02,\n",
      "           2.6011e-01, -1.9049e-01,  9.0780e-02, -4.7249e-02,  6.2133e-02,\n",
      "          -3.8837e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4399e-01, -1.4336e+00,  0.0000e+00, -2.0005e-01, -7.6297e-01,\n",
      "          -9.6891e-01,  1.0221e-01,  0.0000e+00,  6.6568e-01,  9.5849e-01,\n",
      "          -2.9219e-02,  8.9951e-03, -4.9964e-01,  6.4359e-01,  5.5419e-01,\n",
      "           2.6699e+00, -2.8936e-01,  1.0260e+00, -1.5081e+00, -1.4264e-02,\n",
      "          -3.4168e-01,  2.2337e+00,  3.5268e-01, -1.8288e-01, -1.1858e-01,\n",
      "           3.3114e-01,  6.7090e-01,  4.4809e-01,  1.7215e-01,  0.0000e+00,\n",
      "           0.0000e+00, -3.1703e-01, -1.6332e-01, -2.1954e+00,  1.4447e+00,\n",
      "           0.0000e+00, -1.0908e+00,  1.3737e+00, -4.3124e-01, -1.1496e+00,\n",
      "          -9.7013e-01,  3.0099e+00,  1.1976e+00,  0.0000e+00,  1.8139e+00,\n",
      "          -1.9049e+00,  1.1579e+00, -7.1054e-01,  0.0000e+00,  1.6588e+00,\n",
      "           7.9717e-01, -1.4625e+00,  1.6614e+00,  9.6100e-01, -1.8615e+00,\n",
      "           1.1107e+00, -1.1958e+00,  7.4744e-01,  1.5675e+00, -2.9071e-01,\n",
      "          -1.3888e+00, -2.7666e-01, -1.0927e+00, -3.1775e+00, -3.3953e+00,\n",
      "          -1.4136e+00,  4.8494e-01,  1.5915e+00,  1.4404e+00,  6.1354e-01,\n",
      "          -1.1493e+00,  0.0000e+00,  0.0000e+00,  3.6740e-02, -4.6373e-02,\n",
      "           2.1406e+00,  1.0710e+00,  3.4767e-01,  8.1256e-02, -3.2292e+00,\n",
      "           7.0394e-01,  1.0747e+00, -9.9015e-01, -4.9037e-01,  6.1956e-02,\n",
      "           2.8062e-01,  3.9078e-01,  0.0000e+00, -4.2874e-01,  1.0542e+00,\n",
      "           6.3034e-01,  7.4437e-01,  0.0000e+00,  0.0000e+00,  2.1539e+00,\n",
      "           0.0000e+00,  8.7680e-01, -5.7438e-01,  5.2897e-02, -6.9318e-01,\n",
      "           2.0050e+00,  1.2555e-01, -1.8124e+00,  4.8427e-01,  7.5363e-01,\n",
      "           8.6540e-01, -5.9817e-01,  3.9455e-02,  9.1236e-01,  1.2970e+00,\n",
      "           0.0000e+00,  9.5886e-01, -2.8355e-01, -7.6175e-01,  0.0000e+00,\n",
      "           4.5196e-01,  7.9347e-03, -3.5588e-01,  6.6109e-01, -6.9892e-01,\n",
      "           5.9764e-01,  5.7046e-02, -9.4636e-01,  4.0932e-01,  1.0958e+00,\n",
      "           8.9023e-01, -4.0152e-02, -1.4611e-01, -1.3232e+00,  6.9313e-01,\n",
      "          -8.6974e-01,  5.1486e-01, -3.7767e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.2919e-01,  3.7551e-01,  0.0000e+00, -1.4626e+00, -2.9762e-01,\n",
      "           4.2972e-01,  1.0086e+00,  0.0000e+00,  1.2639e+00,  2.9082e-01,\n",
      "           1.2457e+00, -6.5100e-01,  2.1264e+00, -6.1106e-01, -3.3558e-01,\n",
      "          -2.6225e+00, -9.9134e-02,  1.0031e+00,  0.0000e+00, -6.2610e-01,\n",
      "           5.1166e-01, -9.7915e-01,  1.8716e+00,  3.4119e-01,  0.0000e+00,\n",
      "           9.5971e-01, -1.3382e-01, -2.2437e+00, -1.7920e-01,  9.3324e-01,\n",
      "           3.6114e-01, -2.1352e+00,  1.7292e+00,  4.1715e-01,  1.9769e+00,\n",
      "           1.6392e+00,  0.0000e+00, -2.1221e-03,  2.4555e-01, -8.0625e-02,\n",
      "           4.2291e-01,  2.9242e-01, -1.1184e+00,  7.6419e-01, -1.7061e+00,\n",
      "           1.9176e+00,  8.4174e-01, -1.8039e-01,  1.6086e+00,  1.7024e+00,\n",
      "           1.6363e+00,  2.0701e-01,  5.4097e-01, -1.3445e+00,  2.6291e-01,\n",
      "          -1.5586e+00,  1.0090e+00,  9.6411e-01, -1.4234e+00,  4.9974e-01,\n",
      "          -1.3733e+00, -1.5373e+00, -1.3749e+00, -2.4631e-01,  2.3482e+00,\n",
      "           1.8641e+00, -1.2517e+00,  5.4217e-01, -6.2748e-01,  9.1717e-01,\n",
      "           6.2288e-01, -7.6104e-01, -9.3958e-01,  5.8336e-01,  0.0000e+00,\n",
      "           6.2167e-01,  2.9678e-01, -3.1304e-01,  0.0000e+00,  5.4144e-01,\n",
      "           9.4796e-01, -9.2193e-01, -8.8162e-01, -1.0619e+00,  1.9934e-01,\n",
      "           0.0000e+00,  1.5467e+00, -3.0230e-01, -9.5807e-01,  2.1349e-01,\n",
      "          -4.6503e-01,  0.0000e+00,  2.9554e-01,  0.0000e+00,  1.2017e+00,\n",
      "           0.0000e+00, -3.4675e-02,  1.3702e-01, -2.3607e-01,  0.0000e+00,\n",
      "          -2.5183e-01,  0.0000e+00, -6.5995e-01, -7.1170e-01,  6.4904e-01,\n",
      "           3.2165e+00,  0.0000e+00, -1.3917e+00, -8.2209e-01,  1.7681e+00,\n",
      "           1.5245e+00,  0.0000e+00, -1.7378e+00,  0.0000e+00,  1.2118e+00,\n",
      "           7.4997e-01,  2.9102e+00, -5.9099e-01,  8.5160e-01,  2.2605e-03,\n",
      "          -4.3466e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0902, 0.0700, 0.0609, 0.0779, 0.1759, 0.0969, 0.1418, 0.1277, 0.0616,\n",
      "         0.0971]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1732, -0.2346, -0.0185,  ...,  0.2897,  0.3430,  0.1642],\n",
      "        [ 0.1087, -0.0476, -0.0888,  ..., -0.1927,  0.0939,  0.3790],\n",
      "        [-0.2757,  0.3716, -0.2437,  ..., -0.1737,  0.0500,  0.0917],\n",
      "        ...,\n",
      "        [ 0.1814, -0.1248, -0.1933,  ..., -0.2475, -0.3869, -0.1654],\n",
      "        [ 0.0794, -0.2387, -0.3348,  ..., -0.4656,  0.1668, -0.1036],\n",
      "        [ 0.1476,  0.1658, -0.6604,  ..., -0.2523, -0.0332, -0.0783]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1073, -0.0473, -0.1147,  0.0545, -0.0314,  0.0972, -0.2001,\n",
      "           0.0019,  0.0948,  0.2586,  0.0639, -0.0040,  0.2279, -0.2081,\n",
      "          -0.0258,  0.1094,  0.0148, -0.0898, -0.0679,  0.0440,  0.1976,\n",
      "          -0.3267, -0.1480,  0.0622,  0.0763,  0.2142,  0.0535, -0.0686,\n",
      "          -0.0460,  0.0471,  0.2362,  0.1195,  0.0964,  0.0153,  0.1481,\n",
      "          -0.1473,  0.1305,  0.0322, -0.0670, -0.1198, -0.0053,  0.1536,\n",
      "           0.0086, -0.2138,  0.0483,  0.0242,  0.0688, -0.2443,  0.0616,\n",
      "           0.1312, -0.2973, -0.0705, -0.0155, -0.2629, -0.3034, -0.1181,\n",
      "          -0.0951, -0.0629, -0.1524,  0.0277, -0.1743, -0.0952,  0.0405,\n",
      "           0.0794,  0.3139,  0.0433, -0.1302,  0.0318, -0.0291,  0.1171,\n",
      "           0.1391,  0.1064,  0.0429, -0.1066,  0.0477, -0.0246,  0.0265,\n",
      "           0.1155, -0.1688,  0.2006,  0.0389, -0.0483, -0.0882,  0.3619,\n",
      "          -0.0600,  0.3966, -0.0861,  0.2386, -0.1024,  0.0686,  0.1720,\n",
      "           0.2474, -0.0064, -0.1773,  0.1492,  0.1250,  0.0157,  0.2181,\n",
      "           0.3282,  0.0763,  0.1496, -0.0714,  0.2798,  0.0628, -0.0665,\n",
      "          -0.1479, -0.0923, -0.0907, -0.0005,  0.1115,  0.1226,  0.3204,\n",
      "           0.1470, -0.0593, -0.0669, -0.1187, -0.0010,  0.1044,  0.0810,\n",
      "           0.0692,  0.2878,  0.1000, -0.2960,  0.0079, -0.1362, -0.1011,\n",
      "          -0.0660, -0.0606,  0.2200, -0.0780,  0.1294,  0.0213,  0.0796,\n",
      "           0.0425, -0.1372, -0.0063,  0.1035, -0.0117, -0.0211, -0.1515,\n",
      "          -0.0221,  0.3749, -0.1797,  0.2669, -0.0623,  0.1061,  0.1887,\n",
      "           0.2859,  0.0852,  0.1737, -0.1407, -0.1611, -0.0998,  0.1273,\n",
      "           0.0691,  0.0775, -0.0601,  0.2341, -0.2528,  0.0428, -0.0634,\n",
      "          -0.1172,  0.0730,  0.2441, -0.2107, -0.0567,  0.1895,  0.0200,\n",
      "          -0.0340, -0.0039, -0.3032,  0.0914, -0.0199,  0.0391,  0.0486,\n",
      "          -0.0075,  0.1451, -0.0885,  0.1586,  0.0642, -0.0769,  0.0620,\n",
      "           0.0172,  0.0766, -0.0474, -0.2971, -0.1344, -0.1264, -0.0655,\n",
      "           0.0536,  0.0948, -0.0054,  0.1492, -0.0757,  0.0353, -0.0338,\n",
      "          -0.2008,  0.0685, -0.0438, -0.1501, -0.1150,  0.0575,  0.2221,\n",
      "           0.1529, -0.0602,  0.0624, -0.0647,  0.1622, -0.1750,  0.0355,\n",
      "           0.1155,  0.1482, -0.0249,  0.1439,  0.1568, -0.0795, -0.0635,\n",
      "           0.2351,  0.0942, -0.0356,  0.0901, -0.1159,  0.3768, -0.1650,\n",
      "          -0.0790, -0.0242,  0.0007, -0.0624, -0.2153,  0.2730, -0.0189,\n",
      "          -0.1232, -0.2433, -0.1039, -0.1610,  0.0392, -0.1110,  0.1508,\n",
      "           0.4378,  0.2878,  0.0564, -0.2552,  0.0976,  0.0281,  0.0128,\n",
      "          -0.3163, -0.2531,  0.0022,  0.0824,  0.0740,  0.2585, -0.1741,\n",
      "           0.0987, -0.0697,  0.0676, -0.0359]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7265e-02,  4.0019e-01, -9.6446e-01, -6.8081e-01,  3.7533e-01,\n",
      "          -2.0177e-01,  1.4643e+00, -8.3733e-02, -3.5829e+00,  9.0705e-01,\n",
      "           4.2787e-01, -6.2937e-01,  2.6015e+00, -6.3065e-01, -5.4136e-01,\n",
      "          -1.5810e-01,  8.5157e-01,  1.0941e+00,  4.5526e-01,  4.3619e-01,\n",
      "          -6.3304e-01, -3.8217e-01,  1.6395e+00,  1.5112e+00,  7.5313e-01,\n",
      "          -7.6064e-02, -1.8861e-01, -7.6032e-01,  1.6533e+00,  8.6123e-01,\n",
      "           1.2313e+00,  1.2195e+00, -1.0341e+00, -8.3101e-02, -1.5340e+00,\n",
      "           1.3955e+00,  2.8045e-01,  0.0000e+00,  1.9774e-01,  1.5997e+00,\n",
      "          -4.5891e-01,  0.0000e+00, -2.6936e-01, -1.7137e+00, -1.5230e+00,\n",
      "           6.6823e-01,  5.4030e-01,  3.7152e-01, -1.3402e+00,  1.4481e-01,\n",
      "          -6.2935e-01,  2.7501e+00,  0.0000e+00, -1.0283e+00,  0.0000e+00,\n",
      "           2.0436e-01, -8.8096e-01, -1.2504e+00, -2.3755e-01, -4.2647e-01,\n",
      "           1.0982e+00,  1.4066e+00, -2.0190e-01, -5.0094e-01, -2.9617e+00,\n",
      "           5.5185e-01,  1.2777e+00, -1.2871e+00,  0.0000e+00,  5.2671e-01,\n",
      "          -1.2662e+00, -2.9320e-02,  7.0729e-01, -3.6387e+00,  3.2463e-01,\n",
      "          -3.6584e-04, -1.6020e-01,  1.0609e+00, -5.7087e-02,  0.0000e+00,\n",
      "          -1.3992e+00,  2.1293e+00,  0.0000e+00,  1.0060e+00, -2.0758e-01,\n",
      "           4.3681e-01,  1.6610e+00, -9.7393e-01, -1.0477e-01, -5.8105e-01,\n",
      "          -2.2719e+00,  0.0000e+00, -6.2231e-01, -1.1359e+00,  4.6664e-01,\n",
      "          -1.1695e+00,  0.0000e+00,  6.2880e-01,  1.7191e+00, -7.7757e-01,\n",
      "           2.6965e+00, -1.4610e+00,  1.0760e+00,  1.4521e+00,  0.0000e+00,\n",
      "          -7.6204e-01,  1.2104e+00,  0.0000e+00, -1.4729e+00, -1.4142e-02,\n",
      "          -2.4779e-01,  1.3384e-01, -1.0468e+00,  1.3102e+00, -1.6522e+00,\n",
      "          -2.9873e+00, -5.7056e-02, -4.9880e-01, -1.9347e-01,  4.4585e-01,\n",
      "          -1.4642e+00,  7.0179e-01, -1.4599e+00, -7.2555e-01, -9.5730e-01,\n",
      "          -1.3067e+00,  8.9504e-01,  1.6934e-01,  1.2842e+00, -7.5048e-01,\n",
      "          -8.2442e-01,  5.3126e-01, -1.5824e+00,  9.8390e-01,  2.7638e-01,\n",
      "          -5.8893e-01,  6.5796e-01,  5.7592e-01, -1.1594e+00, -1.0090e+00,\n",
      "          -3.8769e-01,  6.7764e-01, -7.8895e-01, -1.0030e-01, -1.6842e+00,\n",
      "          -9.9915e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7774e-01,\n",
      "           1.9971e+00,  0.0000e+00, -1.9292e+00, -4.0626e-01,  4.4118e-01,\n",
      "           0.0000e+00, -6.5162e-02, -1.3082e-01,  3.8638e-02,  5.3732e-01,\n",
      "          -2.6699e-02,  2.2060e+00,  4.8117e-01, -5.5079e-01, -5.2531e-01,\n",
      "           0.0000e+00,  2.8174e-01,  0.0000e+00, -3.5819e-01, -4.7794e-01,\n",
      "           7.3561e-01, -3.0234e-02,  2.0074e-02, -1.0033e+00,  1.2773e+00,\n",
      "          -1.0974e+00, -9.8535e-01, -2.0746e+00,  1.9677e+00,  8.6283e-02,\n",
      "          -3.1255e-02,  3.5026e-02,  6.7047e-01,  9.8004e-01, -7.4808e-01,\n",
      "          -3.4117e-01, -2.7810e+00, -7.8232e-01,  0.0000e+00,  1.0127e+00,\n",
      "           3.0717e+00,  4.9378e-01, -1.4446e-01, -5.9250e-01,  5.5941e-01,\n",
      "           2.1637e+00, -1.1872e+00,  5.3496e-01,  1.8109e+00, -9.4576e-01,\n",
      "          -1.6626e+00, -1.0152e+00,  1.2423e+00, -1.2229e-01,  0.0000e+00,\n",
      "          -5.7436e-01, -2.2915e+00,  6.8177e-01, -1.0724e+00, -4.7147e-01,\n",
      "           0.0000e+00, -5.7311e-01, -3.4143e-01,  7.9240e-01,  3.2612e-02,\n",
      "          -6.8284e-01, -1.0164e+00,  9.6707e-01,  0.0000e+00,  2.1681e+00,\n",
      "          -1.0828e+00, -4.2656e-01, -1.8431e+00, -4.9988e-01,  0.0000e+00,\n",
      "           0.0000e+00, -6.9669e-01, -6.2809e-01,  2.9237e-01, -1.5772e+00,\n",
      "          -1.1078e+00,  1.5811e+00, -6.1346e-01,  1.3104e+00, -2.9785e+00,\n",
      "           4.0330e+00,  0.0000e+00,  4.2618e-02, -1.5777e+00, -2.8569e-01,\n",
      "           0.0000e+00, -3.2459e+00, -3.0330e-01, -8.5140e-01,  1.1329e-02,\n",
      "           2.7595e-01,  2.7467e-01,  2.5207e-01,  2.6155e-01,  3.8688e-01,\n",
      "          -3.6582e-01, -1.5996e-01, -5.5296e-01, -5.1720e-02, -1.1460e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0610, 0.0763, 0.0748, 0.0646, 0.1195, 0.2597, 0.0637, 0.0836, 0.0639,\n",
      "         0.1328]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1822, -0.1966,  0.5943,  ...,  0.0884, -0.1281, -0.4098],\n",
      "        [ 0.0378, -0.5038,  0.5732,  ..., -0.3222, -0.0886, -0.2678],\n",
      "        [ 0.0689, -0.1241,  0.0573,  ..., -0.2873, -0.3183,  0.2320],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.4145e-02, -3.1724e-02, -7.1664e-02,  9.4868e-02,  1.2502e-02,\n",
      "           1.3597e-01, -1.1243e-01,  4.7269e-02,  1.2357e-02,  7.2454e-02,\n",
      "           2.5720e-01, -6.0219e-02, -7.7615e-02,  1.5432e-01,  2.4164e-01,\n",
      "          -5.2376e-02,  4.5649e-02,  2.8968e-02, -1.1284e-02, -6.2273e-02,\n",
      "          -1.6959e-02, -4.0610e-02,  1.0507e-01, -2.5454e-01, -1.8688e-01,\n",
      "          -9.3478e-02, -6.9902e-02, -1.4469e-01,  1.1220e-01, -3.4051e-02,\n",
      "           1.3000e-02,  1.6504e-01, -7.2600e-02, -3.1587e-01,  5.8873e-02,\n",
      "           1.4926e-01,  1.1003e-01, -1.1381e-01,  6.1990e-02,  2.2600e-01,\n",
      "           1.9019e-01,  6.5146e-02, -6.4913e-02, -1.4317e-04, -1.6204e-01,\n",
      "           1.9859e-01, -2.9055e-02,  4.2144e-02,  9.8399e-03, -1.6791e-03,\n",
      "          -6.1758e-02, -3.6429e-02, -1.2048e-01, -4.3454e-03, -1.6694e-02,\n",
      "          -1.8705e-01, -9.3560e-02, -1.1286e-01,  2.6818e-02,  1.7091e-01,\n",
      "           2.7706e-01, -6.1950e-02, -5.5344e-02, -2.8506e-02,  5.1349e-02,\n",
      "           2.0739e-01, -2.4118e-02,  2.1505e-01, -9.7847e-02,  2.0853e-01,\n",
      "           2.9526e-02,  2.3096e-01, -1.6834e-01,  5.2921e-02, -1.2177e-01,\n",
      "          -8.0641e-03, -1.3707e-01,  2.5732e-01,  1.4121e-01,  1.7175e-01,\n",
      "           9.6895e-02,  3.6054e-02, -2.2801e-02,  2.0261e-02,  1.1163e-01,\n",
      "           2.0795e-01,  2.8503e-01,  8.5444e-02,  3.5190e-02, -6.9732e-02,\n",
      "           1.9929e-01, -1.1208e-01,  1.0792e-01, -5.2768e-02, -1.0589e-01,\n",
      "          -1.8870e-01,  1.7973e-02, -8.0212e-02,  3.5812e-02, -2.6744e-02,\n",
      "          -2.1575e-01,  1.4576e-01,  5.3175e-02,  3.1558e-01,  2.6333e-01,\n",
      "          -2.0575e-01,  1.4451e-02,  1.9134e-01,  1.1618e-01,  2.7476e-01,\n",
      "           2.0965e-01,  4.4131e-02, -1.7048e-01, -1.7003e-01, -1.3177e-01,\n",
      "          -1.3828e-01, -5.6385e-02,  1.2821e-01, -5.0196e-02, -7.8375e-02,\n",
      "          -7.4995e-02, -1.3707e-01,  3.5228e-03,  1.6121e-01, -1.1364e-01,\n",
      "          -5.9092e-02,  1.4560e-01,  1.6638e-02,  8.2767e-02,  4.7756e-02,\n",
      "          -4.9399e-02,  9.4551e-02,  1.0754e-01,  2.5360e-01, -8.0459e-02,\n",
      "          -1.8929e-01,  1.4345e-01, -9.3767e-02, -1.1096e-01, -1.2906e-02,\n",
      "          -1.4490e-01,  2.1536e-01,  1.3333e-01, -9.8360e-02, -1.0634e-01,\n",
      "          -5.5232e-02, -1.0231e-01,  3.8158e-02,  4.4939e-02, -1.0881e-01,\n",
      "          -2.1285e-01,  2.5702e-01, -1.1504e-01,  2.2165e-01,  3.7229e-02,\n",
      "           2.5660e-01, -1.1866e-01,  7.6094e-02, -2.1498e-01,  1.5946e-01,\n",
      "           7.0316e-02, -1.0949e-01, -3.6942e-02,  1.3250e-01, -2.6037e-01,\n",
      "          -8.1059e-02,  4.5304e-02, -2.7801e-02,  4.1592e-03,  1.7418e-01,\n",
      "          -1.3311e-01, -4.2343e-02,  2.1293e-01,  2.8513e-02, -6.1439e-02,\n",
      "          -9.9581e-02,  3.5590e-02,  1.4713e-01,  1.7519e-01, -2.7260e-02,\n",
      "          -1.1930e-01,  9.6819e-02, -1.0400e-01, -2.3980e-02,  7.8449e-02,\n",
      "          -8.8529e-02,  2.0534e-02,  5.2406e-02,  8.9222e-02, -3.2468e-02,\n",
      "          -1.7333e-01, -1.2095e-01, -2.1375e-01, -2.1908e-02, -3.5352e-01,\n",
      "          -1.8425e-02,  8.0599e-03,  7.1588e-02, -3.1775e-02, -9.8222e-02,\n",
      "           8.2269e-02, -1.3621e-01,  1.6028e-01,  1.8344e-03, -1.2129e-01,\n",
      "           6.7352e-02, -3.3305e-02,  1.6238e-01,  1.0262e-01, -1.2595e-01,\n",
      "          -9.5485e-02, -5.7669e-02, -2.1822e-01, -3.4497e-02,  1.0966e-01,\n",
      "           1.0716e-01,  2.1234e-01, -1.6067e-02,  6.1110e-02, -5.8743e-03,\n",
      "           5.0608e-02, -2.7708e-02, -1.4289e-02, -7.2383e-02, -9.7065e-02,\n",
      "           2.2126e-02, -1.9754e-01, -2.1213e-01, -2.1493e-01,  1.2309e-01,\n",
      "           8.8848e-02, -1.9405e-01,  2.0077e-02,  4.6011e-02, -1.0689e-01,\n",
      "           8.1954e-02, -8.2727e-02, -2.1347e-02,  8.8963e-02,  1.2723e-01,\n",
      "          -2.0519e-01, -1.1116e-01,  1.3225e-02, -1.0733e-01, -3.3954e-02,\n",
      "          -9.3902e-02,  2.3980e-02,  3.0600e-03,  2.6130e-01, -1.6033e-01,\n",
      "          -6.7803e-02,  1.7489e-01, -1.0530e-01, -1.0209e-01,  2.5200e-02,\n",
      "          -1.1168e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0447,  1.2545, -0.4664,  1.7172,  2.1263, -0.2518, -0.9079,\n",
      "          -0.0987,  1.1704, -2.1523, -0.5854,  0.0000, -2.9079,  0.3783,\n",
      "           2.3036,  0.7980, -0.4095, -0.6149, -0.2802,  0.1081,  0.0000,\n",
      "           0.2528, -0.6048,  0.6490,  0.8123,  0.0000,  0.0000, -1.4426,\n",
      "           0.7556,  1.0295,  2.7913,  0.1369, -1.2163, -1.0197,  0.0882,\n",
      "          -0.0186, -0.6008,  0.2674,  0.6425, -0.5310, -0.2679, -0.9844,\n",
      "           0.1589, -0.2240,  1.0190, -0.3817, -0.5498, -2.1849,  0.0000,\n",
      "           0.4284,  2.3789, -1.0152,  0.4626,  0.4322, -2.0464,  0.6874,\n",
      "          -0.5578, -0.1243,  0.0000,  1.5114,  0.3691, -0.7990, -0.3513,\n",
      "          -0.4274,  0.1153, -1.0634,  1.2920, -1.1348, -1.4302,  0.7685,\n",
      "           0.0000, -0.2438, -0.7989, -0.4705, -1.2764,  0.6310,  0.2607,\n",
      "           0.1704, -1.4213, -2.2301,  1.6305,  0.1555,  1.0571, -0.0068,\n",
      "           0.0000,  0.0000, -0.5064,  0.2261,  1.5821,  0.0000,  0.8279,\n",
      "           0.6211,  0.0000, -2.0888, -0.1636,  0.7981,  0.9418,  0.3355,\n",
      "          -1.9782,  0.6223,  1.2575,  1.1964, -0.5282, -0.4682,  0.5846,\n",
      "           1.3580,  2.2053,  0.0000,  0.0000, -0.1461, -1.2139, -1.7617,\n",
      "           0.0000, -0.7763, -0.4877,  0.5292, -0.6109, -0.9200, -1.9305,\n",
      "           0.5734,  0.6996, -1.1987, -0.8502, -0.2661,  0.0000, -0.7541,\n",
      "           1.0484,  2.0803, -1.2004, -2.0669, -1.1239, -0.2625,  1.2993,\n",
      "          -0.7233, -1.7858, -2.8104, -2.1605,  0.0000, -0.7178,  0.1088,\n",
      "           1.0378, -1.4278, -1.6466,  1.4237,  2.6916,  0.7387,  1.2630,\n",
      "           3.2325,  1.2307,  1.2100, -0.6048, -1.7824, -0.0645, -1.6570,\n",
      "          -0.1895, -0.7709,  0.3756,  0.6389,  1.3775,  0.2800, -0.1719,\n",
      "          -1.0613, -1.4685,  0.4448,  0.4868,  0.0000,  0.0334, -1.9414,\n",
      "          -0.2388, -1.4670,  0.5140,  1.3974,  0.5180, -0.8871,  1.1623,\n",
      "           1.5167, -0.3159,  0.0000,  0.4780, -0.3760,  0.4144, -0.3535,\n",
      "           0.9598,  0.3760,  1.9492, -1.7205, -1.0728, -0.1612,  0.7115,\n",
      "           0.0966, -0.7704, -1.2740,  0.0000,  0.8758,  0.3841, -1.2635,\n",
      "           2.8157, -0.4361,  0.6855,  0.1763,  0.0954,  0.0000,  0.9878,\n",
      "          -0.5555, -0.1357, -2.0006,  0.2932,  0.8690,  1.2635,  2.1706,\n",
      "           0.3261,  0.0000, -0.7076, -0.5392,  0.5765,  1.1522,  0.0000,\n",
      "          -0.0532,  0.0000, -1.1537,  1.3688,  0.0000, -0.7013,  2.1902,\n",
      "          -1.9717, -0.6011,  0.0000, -0.2504,  1.7971,  1.2116,  0.4037,\n",
      "           0.0847, -0.0390,  0.5899,  0.0000, -1.0875,  1.6295, -1.3611,\n",
      "          -0.0792, -0.5929,  0.0000, -1.0670, -0.0632,  1.1017,  1.1766,\n",
      "           0.1782, -0.0545, -0.2369,  0.5079,  1.2424,  0.0000, -0.0663,\n",
      "          -1.0721,  0.0000, -0.9917, -0.5375]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0604, 0.1693, 0.0683, 0.0947, 0.0944, 0.0515, 0.1845, 0.1029, 0.1055,\n",
      "         0.0686]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1822, -0.1966,  0.5943,  ...,  0.0884, -0.1281, -0.4098],\n",
      "        [ 0.0378, -0.5038,  0.5732,  ..., -0.3222, -0.0886, -0.2678],\n",
      "        [ 0.0689, -0.1241,  0.0573,  ..., -0.2873, -0.3183,  0.2320],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0409, -0.0426, -0.0091,  0.1371,  0.0298,  0.1708, -0.0345,\n",
      "          -0.0282,  0.0397,  0.1304,  0.2577, -0.1034,  0.0156,  0.0323,\n",
      "           0.1992, -0.0216,  0.0621, -0.0350,  0.0411, -0.0863, -0.0413,\n",
      "          -0.0594,  0.0899, -0.2009, -0.1335, -0.0311, -0.1762, -0.1873,\n",
      "           0.1355, -0.0363, -0.0371,  0.1227, -0.1138, -0.2795,  0.0383,\n",
      "           0.1859,  0.1223, -0.0452,  0.0988,  0.1377,  0.1994,  0.0525,\n",
      "          -0.0756,  0.0562, -0.0581,  0.1314, -0.0576,  0.0397, -0.0608,\n",
      "          -0.0350, -0.0688, -0.0376, -0.1234, -0.0070,  0.0625, -0.1478,\n",
      "          -0.1052, -0.1036,  0.0105,  0.1999,  0.2585, -0.0911, -0.0242,\n",
      "          -0.0334,  0.0822,  0.1937,  0.0481,  0.1669, -0.0412,  0.1954,\n",
      "          -0.0279,  0.2492, -0.1339,  0.0730, -0.1320, -0.0722, -0.1291,\n",
      "           0.3144,  0.0845,  0.1401,  0.0674, -0.0761, -0.0069, -0.0513,\n",
      "           0.1038,  0.2723,  0.1990,  0.0446,  0.0700, -0.1154,  0.1808,\n",
      "          -0.0761,  0.0530,  0.0451, -0.1497, -0.1798,  0.0199,  0.0123,\n",
      "          -0.0087,  0.0171, -0.1781,  0.0839,  0.0467,  0.2639,  0.1617,\n",
      "          -0.1565, -0.0276,  0.0810,  0.1044,  0.2009,  0.2190,  0.0357,\n",
      "          -0.1693, -0.2081, -0.1370, -0.1626, -0.0537,  0.0922,  0.0140,\n",
      "          -0.0929, -0.0101, -0.1326,  0.0289,  0.1113, -0.0701, -0.0806,\n",
      "           0.0742,  0.0211,  0.1157,  0.0606, -0.0356,  0.0700,  0.1966,\n",
      "           0.2530, -0.1157, -0.1525,  0.1636, -0.1168, -0.1076, -0.0082,\n",
      "          -0.0568,  0.1523,  0.1298, -0.0576, -0.0565, -0.0551, -0.1404,\n",
      "           0.0120, -0.0040, -0.1502, -0.1394,  0.1539, -0.0702,  0.2310,\n",
      "           0.0457,  0.2126, -0.1195,  0.0477, -0.1590,  0.1176,  0.0975,\n",
      "          -0.1001,  0.0014,  0.1543, -0.1016, -0.0085,  0.0852,  0.0134,\n",
      "           0.1107,  0.1937, -0.0202, -0.0049,  0.2101, -0.0658, -0.1005,\n",
      "           0.0040,  0.0413,  0.1233,  0.1941,  0.1482, -0.1298,  0.0756,\n",
      "          -0.0663,  0.0306,  0.0141, -0.0690, -0.0400,  0.0534,  0.1156,\n",
      "           0.0301, -0.1868, -0.0392, -0.2211, -0.0627, -0.2662, -0.0879,\n",
      "          -0.0971,  0.0584, -0.0259, -0.0301,  0.0487, -0.1049,  0.2037,\n",
      "           0.0908, -0.1096,  0.0957, -0.0152,  0.2133,  0.0537, -0.0087,\n",
      "           0.0235, -0.0540, -0.1595,  0.0407,  0.0964,  0.1555,  0.1273,\n",
      "          -0.0497,  0.0534,  0.0973,  0.0243, -0.1116, -0.0158, -0.0679,\n",
      "          -0.0588,  0.0833, -0.0792, -0.1861, -0.1585,  0.1746, -0.0265,\n",
      "          -0.0798,  0.0980, -0.0144, -0.1032,  0.0228, -0.0760, -0.0675,\n",
      "           0.0668,  0.1175, -0.1001, -0.1884, -0.0627, -0.2011, -0.0313,\n",
      "          -0.0225,  0.0370,  0.0502,  0.2660, -0.0214, -0.0469,  0.1594,\n",
      "          -0.1420, -0.0871, -0.0499, -0.1139]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.0941, -0.1614,  0.3731, -0.0932,  0.7085,  0.9551,  0.6023,\n",
      "          -0.3026,  0.2414,  0.3973,  1.0981,  0.0665, -0.6744,  0.0000,\n",
      "          -0.6126,  1.0058, -0.3360,  0.5974,  0.0000, -1.3972, -2.1202,\n",
      "           0.0000,  0.3558,  0.6889, -0.9241, -0.9805,  0.3373,  0.5069,\n",
      "           0.0000,  0.8584, -0.6988,  0.1067, -0.6291,  0.0000,  0.0000,\n",
      "          -0.0093, -0.4483, -1.3332,  1.4292,  0.0000, -3.2113,  0.3180,\n",
      "           0.3125, -0.1164, -1.7016, -0.7101,  0.3843, -1.1722,  2.0965,\n",
      "           0.5176,  1.8876, -1.1040,  0.0120,  0.0000,  0.7306,  0.0000,\n",
      "          -0.1301, -0.1740, -0.7078,  1.5829,  0.2870,  0.8485, -0.5350,\n",
      "          -1.4271, -1.7302, -1.0932, -1.0571,  1.5332, -0.9760, -2.8618,\n",
      "          -0.8794,  0.6237,  0.6305,  0.6899,  0.8270,  0.7255, -1.5638,\n",
      "          -0.6860,  0.0000,  0.0000, -2.5652,  1.7533, -0.2438, -1.8565,\n",
      "           0.0131,  0.7637, -2.0536,  0.4764, -1.5655,  1.4045,  0.3867,\n",
      "           2.2181,  1.1676,  0.3621, -0.7886, -0.8631,  1.1110, -1.5580,\n",
      "          -0.4713,  0.2909,  2.5618, -0.0387,  0.9105,  1.0134, -1.6311,\n",
      "          -0.2822,  0.0000, -0.0731, -1.7932, -0.1224, -2.1291, -0.3012,\n",
      "           0.8063, -1.5057,  1.7413,  1.1382, -0.5672, -0.1111,  0.0000,\n",
      "           0.3974, -1.0820,  0.9299,  0.1317, -0.0160, -0.9526,  1.4320,\n",
      "           0.0000, -2.0541, -0.6395,  1.5839,  0.0259, -0.3278,  1.8961,\n",
      "          -0.1421,  0.5612, -1.5777,  0.9248,  0.0000,  0.0586, -0.6009,\n",
      "          -1.3204, -1.6199, -2.6012, -0.4693,  0.0000,  1.6322,  2.6976,\n",
      "           0.2648,  2.3254,  0.2288, -0.7262, -0.3726,  0.2995,  0.4823,\n",
      "          -0.3898,  0.6453,  0.7785, -2.0626, -0.7020, -0.6596, -0.1057,\n",
      "          -0.2028,  0.5920,  1.0009,  0.4459, -0.0064,  0.1477,  0.4864,\n",
      "           1.4363,  0.4875, -1.0582,  0.7620,  0.8800,  0.3100,  0.4729,\n",
      "          -0.4097,  0.1282, -0.5822, -0.8414,  0.6762, -0.5429, -0.4512,\n",
      "          -1.5850, -0.3777, -2.6268, -1.4817, -3.0928,  1.2700,  0.0000,\n",
      "           0.2082, -2.2931, -0.4414,  0.2269,  0.2342, -0.5827,  0.2411,\n",
      "          -0.1657,  0.3729, -0.6380, -0.3940, -0.7197,  1.0417,  1.1621,\n",
      "           0.0000, -0.0412, -1.6270,  1.7329, -0.2360, -0.5529,  1.0346,\n",
      "           0.6089, -0.5156,  0.0533,  1.3249, -1.3381,  0.1287, -1.7174,\n",
      "          -0.9361,  0.0423,  1.1060,  0.2096,  0.8281,  0.4407,  1.1009,\n",
      "           0.9417,  1.0811, -2.3691,  0.3785, -0.3604,  0.0000,  1.9905,\n",
      "          -0.4454, -1.7797,  1.4100, -1.8060, -1.9360,  0.6736, -0.1133,\n",
      "          -0.6518,  0.8868,  0.6446,  0.2634,  0.0000,  0.2403,  1.2993,\n",
      "           0.7225, -0.5934,  0.1785, -0.0819, -0.0247, -0.1575,  1.3646,\n",
      "          -0.9094, -1.3063,  0.8916, -0.6969]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0777, 0.0874, 0.0690, 0.0752, 0.2106, 0.1786, 0.0545, 0.0731, 0.0975,\n",
      "         0.0764]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1822, -0.1966,  0.5943,  ...,  0.0884, -0.1281, -0.4098],\n",
      "        [ 0.0378, -0.5038,  0.5732,  ..., -0.3222, -0.0886, -0.2678],\n",
      "        [ 0.0689, -0.1241,  0.0573,  ..., -0.2873, -0.3183,  0.2320],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0388, -0.0157, -0.0371,  0.1482,  0.0108,  0.1739, -0.1007,\n",
      "           0.0842,  0.0239,  0.1309,  0.2623, -0.0605, -0.0545,  0.1499,\n",
      "           0.2509, -0.0491,  0.0785, -0.0053,  0.0378, -0.0719, -0.0241,\n",
      "          -0.0152,  0.0927, -0.2612, -0.1966, -0.1371, -0.1292, -0.1102,\n",
      "           0.1107, -0.0472, -0.0263,  0.2094, -0.0921, -0.2969,  0.0632,\n",
      "           0.1416,  0.1591, -0.1271,  0.0909,  0.2273,  0.2098,  0.0393,\n",
      "          -0.0381,  0.0105, -0.1506,  0.1784, -0.0328,  0.0647, -0.0335,\n",
      "           0.0277, -0.0665, -0.0183, -0.1132,  0.0195,  0.0126, -0.2196,\n",
      "          -0.0876, -0.1220,  0.0228,  0.1913,  0.3178, -0.0532, -0.0396,\n",
      "          -0.0970,  0.0816,  0.2329, -0.0108,  0.1725, -0.0771,  0.1618,\n",
      "          -0.0083,  0.2125, -0.1998,  0.0551, -0.1021, -0.0313, -0.1316,\n",
      "           0.2831,  0.1492,  0.1463,  0.1058,  0.0059,  0.0269,  0.0031,\n",
      "           0.1102,  0.2324,  0.3000,  0.0727,  0.0429, -0.0966,  0.2188,\n",
      "          -0.1272,  0.1478, -0.0443, -0.1026, -0.2302, -0.0005, -0.0894,\n",
      "          -0.0017, -0.0830, -0.2322,  0.1080,  0.0461,  0.3307,  0.2545,\n",
      "          -0.2062, -0.0184,  0.1592,  0.1367,  0.2831,  0.2365,  0.0069,\n",
      "          -0.1844, -0.1911, -0.1189, -0.1677, -0.0490,  0.1595, -0.0278,\n",
      "          -0.0719, -0.0616, -0.1520,  0.0804,  0.1489, -0.0649, -0.0812,\n",
      "           0.1460,  0.0545,  0.0741,  0.0706, -0.0470,  0.1212,  0.1122,\n",
      "           0.2381, -0.0868, -0.1797,  0.1302, -0.1430, -0.1312, -0.0215,\n",
      "          -0.1443,  0.2031,  0.1778, -0.0964, -0.1249, -0.0337, -0.1404,\n",
      "           0.0046,  0.0132, -0.1589, -0.1474,  0.2584, -0.1034,  0.2336,\n",
      "           0.0280,  0.2537, -0.1382,  0.0617, -0.2033,  0.1925,  0.0658,\n",
      "          -0.1216,  0.0237,  0.0798, -0.2539, -0.0947,  0.0263,  0.0058,\n",
      "           0.0382,  0.2087, -0.1084, -0.0725,  0.2185,  0.0096, -0.0836,\n",
      "          -0.0615,  0.0162,  0.1502,  0.1935, -0.0070, -0.0678,  0.1277,\n",
      "          -0.0743, -0.0076,  0.0385, -0.1110,  0.0328,  0.0548,  0.1376,\n",
      "          -0.0044, -0.2088, -0.1448, -0.2024, -0.0268, -0.3775,  0.0311,\n",
      "          -0.0309,  0.0328, -0.0459, -0.0978,  0.0826, -0.1769,  0.1995,\n",
      "           0.0108, -0.1347,  0.1029, -0.0250,  0.1221,  0.1238, -0.0940,\n",
      "          -0.0713, -0.0326, -0.2503, -0.0452,  0.1259,  0.1055,  0.2065,\n",
      "          -0.0521,  0.1025,  0.0021,  0.0175, -0.0343, -0.0416, -0.0688,\n",
      "          -0.1310,  0.0032, -0.2014, -0.1970, -0.1771,  0.1450,  0.0932,\n",
      "          -0.2013,  0.0753,  0.0900, -0.1077,  0.1039, -0.0607, -0.0287,\n",
      "           0.0509,  0.0951, -0.2002, -0.0673,  0.0155, -0.1431, -0.0523,\n",
      "          -0.0749,  0.0662,  0.0337,  0.3093, -0.1216, -0.1076,  0.1888,\n",
      "          -0.1166, -0.0651, -0.0184, -0.1132]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.5440, -0.8019,  0.0000,  0.5587,  0.0464,  0.0448, -1.5632,\n",
      "          -2.0464, -0.2872, -0.4442, -0.3400,  0.0000, -0.8139, -0.0554,\n",
      "          -1.3502, -0.1552,  0.6750, -0.5926, -0.5979,  0.2574, -0.5441,\n",
      "          -0.0628,  0.3478,  0.0000,  0.0229, -0.2860, -1.2706, -0.8009,\n",
      "           0.6559,  0.0000, -0.0866,  0.0000,  0.0000, -0.8500,  1.3583,\n",
      "           0.0000, -0.9685, -1.0022,  1.5032, -0.0426,  0.0000,  0.0000,\n",
      "           0.8305, -1.1553, -0.2069,  0.8342,  0.0797, -1.0454,  0.3092,\n",
      "          -1.0957,  0.6672, -0.9095,  0.1966, -0.6842,  1.8213,  1.6353,\n",
      "           2.1396,  0.9924, -0.7134,  0.0000, -0.0650,  1.1920,  1.5259,\n",
      "           0.8725,  0.3927, -2.2612,  0.3491, -1.1279,  0.0000,  1.5738,\n",
      "           0.2187,  0.0000,  1.3885,  0.2062, -0.6418, -0.1833, -0.6469,\n",
      "          -0.9042,  0.6201, -1.7468,  1.7297,  1.1526,  0.7419,  0.6546,\n",
      "           0.3913,  0.2644,  1.8163,  0.9158, -0.3761,  0.4591, -0.8488,\n",
      "          -1.0221,  0.1039, -0.7372, -0.0633,  0.3550,  0.0301, -0.3294,\n",
      "          -1.7313,  1.1351,  1.3056,  1.9752, -2.4441,  0.0080, -0.2794,\n",
      "           0.9806,  1.2269,  1.8037,  0.3411, -0.8274,  1.0200, -0.1049,\n",
      "           0.7287,  1.5603,  0.4336, -1.4456, -0.8736,  1.7184, -0.9716,\n",
      "           0.1111, -1.5147, -1.3742,  0.1671,  0.4193,  1.0547,  2.7549,\n",
      "          -0.0662, -1.7301, -0.2874,  1.2141,  0.5724, -0.9714, -2.2362,\n",
      "           0.0000, -0.3114, -0.7988,  1.5176, -0.9011,  1.0693, -0.7458,\n",
      "           1.3625,  1.3049, -0.8583,  2.9543,  0.0000,  0.4068, -0.8877,\n",
      "           0.3422, -0.3933,  0.8219, -2.1080,  0.5195,  0.0000,  2.0369,\n",
      "          -0.2954,  2.1204, -0.2091, -0.8815,  0.0000,  0.0186,  0.5404,\n",
      "           0.3585,  0.8909, -1.6315,  1.1186, -0.6625, -0.4411, -1.6355,\n",
      "           0.1859,  0.5705, -0.2259, -1.0192,  0.0315, -0.3880, -0.9063,\n",
      "          -0.7551,  0.9211,  0.0130,  0.3568,  1.5420,  1.2526, -2.1007,\n",
      "          -0.4109, -1.4741,  0.1257, -1.8482,  1.1941,  0.0000, -0.1822,\n",
      "          -0.7091, -0.2601, -0.6036,  0.5403,  0.6189, -0.5952, -0.5479,\n",
      "           0.8817,  0.0000, -0.5878,  0.2840, -0.4232,  0.5201, -0.8451,\n",
      "           2.7251,  3.4905, -0.4932, -1.0711,  0.6492,  0.7190, -0.4547,\n",
      "           0.0000, -2.3304, -0.9164,  0.1707,  1.6365, -0.9369, -0.8402,\n",
      "          -0.5808,  0.0000,  0.4581,  0.4131, -0.4451,  0.5038, -0.1392,\n",
      "          -0.6725,  0.1607,  1.7498, -0.3114,  0.8899,  0.0000,  0.8691,\n",
      "          -0.4799, -0.6704,  0.5663,  0.0000,  1.3095,  1.5521, -0.0439,\n",
      "           1.1181,  0.3957,  1.0532,  2.1932, -0.3005,  0.2739,  0.7371,\n",
      "           1.0870,  0.0000,  2.0813, -1.3700, -0.3933,  1.8213, -0.5707,\n",
      "           1.5501, -0.4506,  1.4709,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0729, 0.0345, 0.1000, 0.0698, 0.1420, 0.0766, 0.1107, 0.0571, 0.1737,\n",
      "         0.1627]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1822, -0.1966,  0.5943,  ...,  0.0884, -0.1281, -0.4098],\n",
      "        [ 0.0378, -0.5038,  0.5732,  ..., -0.3222, -0.0886, -0.2678],\n",
      "        [ 0.0689, -0.1241,  0.0573,  ..., -0.2873, -0.3183,  0.2320],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.3628e-02,  1.2214e-02, -5.2880e-02,  1.1442e-01, -2.1227e-02,\n",
      "           1.2656e-01, -4.7779e-02,  2.4026e-02,  2.8633e-02,  8.3608e-02,\n",
      "           2.3186e-01, -7.4648e-02, -5.3058e-02,  9.7877e-02,  2.0051e-01,\n",
      "          -1.6093e-02,  1.0215e-01, -2.2872e-02,  2.7149e-02, -5.2485e-02,\n",
      "          -1.0777e-02, -5.4010e-03,  7.3585e-02, -1.9265e-01, -1.6593e-01,\n",
      "          -9.9644e-02, -1.2562e-01, -9.4042e-02,  1.0063e-01, -3.0842e-02,\n",
      "          -5.1515e-02,  1.3820e-01, -8.4982e-02, -2.3276e-01,  6.9625e-02,\n",
      "           1.4531e-01,  1.0609e-01, -8.3322e-02,  4.8078e-02,  1.5569e-01,\n",
      "           1.4754e-01,  1.2918e-03, -4.9944e-02,  2.7408e-02, -7.7163e-02,\n",
      "           1.3097e-01, -3.1018e-02,  4.4737e-02, -1.3236e-02,  1.9130e-02,\n",
      "          -7.2365e-02,  9.1123e-03, -9.9753e-02,  6.8389e-03,  1.9594e-02,\n",
      "          -1.8051e-01, -7.6932e-02, -8.5419e-02,  2.3368e-02,  1.2714e-01,\n",
      "           2.4556e-01, -2.0339e-02, -1.7246e-02, -7.7714e-02,  6.0272e-02,\n",
      "           1.7106e-01, -6.4925e-03,  1.5778e-01, -4.8352e-02,  1.3819e-01,\n",
      "          -1.7497e-02,  1.7836e-01, -1.4002e-01,  6.2655e-02, -1.1397e-01,\n",
      "          -3.9142e-02, -1.1934e-01,  2.3958e-01,  1.0397e-01,  1.1044e-01,\n",
      "           5.5123e-02, -5.8747e-02, -1.1593e-02, -2.8959e-02,  8.8250e-02,\n",
      "           1.7754e-01,  2.0788e-01,  3.1733e-02,  1.8345e-02, -9.6420e-02,\n",
      "           1.5824e-01, -7.5022e-02,  1.0744e-01, -2.8618e-02, -8.9589e-02,\n",
      "          -2.0166e-01,  1.4513e-03, -5.6375e-02, -2.9341e-02, -2.8734e-02,\n",
      "          -1.5820e-01,  6.6267e-02,  2.9933e-02,  2.9903e-01,  1.6202e-01,\n",
      "          -1.7713e-01, -1.2464e-02,  1.0991e-01,  1.1164e-01,  2.3446e-01,\n",
      "           1.9942e-01,  1.6885e-02, -1.4217e-01, -1.8679e-01, -1.0669e-01,\n",
      "          -1.0708e-01, -7.5896e-02,  9.3373e-02, -1.9662e-02, -7.4507e-02,\n",
      "          -2.7150e-02, -1.1831e-01,  2.7805e-02,  8.9577e-02, -4.0055e-02,\n",
      "          -4.9483e-02,  1.3120e-01,  3.3552e-02,  9.3706e-02,  7.0055e-02,\n",
      "          -3.5209e-02,  8.3757e-02,  1.1578e-01,  1.7240e-01, -1.0312e-01,\n",
      "          -1.0573e-01,  1.1328e-01, -1.2740e-01, -1.0520e-01, -1.4978e-02,\n",
      "          -8.8618e-02,  1.8235e-01,  1.5318e-01, -4.5110e-02, -7.7693e-02,\n",
      "          -5.8826e-02, -1.2738e-01,  6.1849e-03, -3.1531e-03, -1.2461e-01,\n",
      "          -1.2195e-01,  1.8347e-01, -8.9941e-02,  1.9128e-01,  1.6148e-02,\n",
      "           2.1025e-01, -9.8440e-02,  3.1228e-02, -1.3405e-01,  1.0432e-01,\n",
      "           4.5552e-02, -9.3315e-02, -3.5524e-03,  7.1259e-02, -1.6489e-01,\n",
      "          -6.6178e-02,  6.3380e-02, -3.4945e-02,  6.4860e-02,  1.7552e-01,\n",
      "          -5.6547e-02, -3.8732e-02,  1.7624e-01, -4.6734e-02, -8.6266e-02,\n",
      "          -3.0619e-02, -1.3839e-03,  1.3928e-01,  1.8626e-01,  4.8073e-02,\n",
      "          -6.3756e-02,  1.0261e-01, -6.5874e-02,  2.8632e-02,  4.5175e-02,\n",
      "          -9.5500e-02, -3.6793e-02,  5.6868e-02,  1.5429e-01, -6.6001e-05,\n",
      "          -1.7858e-01, -7.5825e-02, -1.8937e-01, -2.7819e-02, -2.4919e-01,\n",
      "           2.8631e-02, -2.2548e-02,  4.0657e-02,  1.0715e-02, -2.3589e-02,\n",
      "           3.9780e-02, -9.8845e-02,  1.7470e-01,  5.7038e-02, -7.6661e-02,\n",
      "           1.0386e-01, -5.0857e-02,  1.2488e-01,  6.0180e-02, -4.0611e-02,\n",
      "          -1.4912e-02, -5.9910e-02, -1.6432e-01, -4.1297e-02,  8.6550e-02,\n",
      "           1.1564e-01,  1.3011e-01, -1.8118e-02,  5.8322e-02,  3.5861e-02,\n",
      "           2.4013e-02, -5.8207e-02, -2.3560e-02, -7.1805e-02, -5.3171e-02,\n",
      "           1.4456e-02, -1.1967e-01, -1.1907e-01, -1.2436e-01,  1.1815e-01,\n",
      "           3.2954e-04, -1.3396e-01,  7.0774e-02,  4.7263e-03, -8.6930e-02,\n",
      "           5.6365e-02, -5.3530e-02, -3.7480e-02,  2.8897e-02,  6.3932e-02,\n",
      "          -1.5976e-01, -8.2973e-02, -1.6325e-02, -1.4031e-01, -3.9444e-02,\n",
      "          -5.3881e-02,  4.3861e-02,  1.6431e-02,  2.1904e-01, -4.6168e-02,\n",
      "          -6.7295e-02,  1.2017e-01, -1.0447e-01, -4.5292e-02, -4.6025e-02,\n",
      "          -7.0519e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.6435,  2.0459, -0.6809, -0.2478,  0.0000, -1.4182,  0.1269,\n",
      "           0.7674,  1.0366, -0.3423, -0.5237,  0.1155,  2.4892, -1.7194,\n",
      "           1.4405,  0.5214, -1.4875, -0.2207,  0.9172,  1.6345,  1.3094,\n",
      "          -2.5374, -0.9276, -0.0280, -2.5927,  0.6455,  0.7818, -0.4479,\n",
      "           1.5586,  1.3721, -0.1802,  0.0470, -1.3794, -2.1242, -0.7561,\n",
      "           0.9970,  0.4268,  0.5055, -0.9474,  0.4169, -0.6455,  0.0000,\n",
      "           0.9126,  0.0000,  0.0000, -1.2199,  1.4447,  1.1089,  1.0203,\n",
      "           0.2340,  0.0701,  0.5213, -2.0085, -1.2947, -0.9276, -0.5518,\n",
      "           0.0000,  0.0000, -0.1041,  1.7015, -0.5453, -1.6602, -1.1826,\n",
      "          -1.8966,  1.6183,  0.5788,  0.4110, -0.9959, -1.2443, -1.9292,\n",
      "          -0.5008,  0.5095,  0.0000,  2.1776,  1.3325, -2.0596, -1.6802,\n",
      "          -0.6453,  1.0170, -0.2148, -0.1081,  0.0000,  0.9477,  0.5387,\n",
      "          -1.5139, -0.8369, -0.7804, -0.7200,  0.0556,  0.8452,  0.0000,\n",
      "           0.7421,  1.7474, -0.2854, -1.0863,  1.8921,  2.1565, -0.0302,\n",
      "          -0.1048, -0.3800, -1.5179, -0.3371,  0.9345, -2.2290,  1.1609,\n",
      "          -0.7709, -0.4636,  0.7783,  0.0000, -0.0539,  0.6578,  1.0125,\n",
      "          -0.4442,  0.1583, -0.3159,  0.5870, -0.3080, -1.6774,  0.3514,\n",
      "           0.5718,  0.0617,  0.8216,  0.0000,  1.0404,  0.1285,  2.0126,\n",
      "          -0.3322, -0.7497,  0.8064,  0.7907, -0.0611, -0.1431,  0.4523,\n",
      "           0.6861,  0.3368,  1.4481,  0.0000, -0.4528,  0.4573, -0.9273,\n",
      "           0.2243, -0.4181,  0.0000, -1.1189, -0.8111, -0.7665,  0.6763,\n",
      "           0.9565, -0.1579,  0.1040, -0.8175,  2.1768,  1.4338,  0.5714,\n",
      "           0.9246,  2.3593,  0.3013, -1.4427,  0.8088, -0.2174, -0.0606,\n",
      "           0.0776,  0.7396, -2.2586,  0.5185, -0.0495, -0.9782, -1.9771,\n",
      "           1.0501,  1.7286,  0.0000, -1.8026,  0.2602, -0.0332,  1.0605,\n",
      "           2.1793, -0.2679,  0.0963,  0.3270,  0.9701, -0.0391,  0.0000,\n",
      "           2.0097,  0.3746, -2.0383, -1.8315, -2.6977, -0.0874,  0.2745,\n",
      "          -0.6763,  0.0000,  0.0662,  0.9254,  0.0594, -0.6230,  0.4179,\n",
      "           0.1641,  0.0000,  0.0000, -1.3520,  0.0000,  1.9539, -1.1131,\n",
      "          -1.4349, -2.0862,  0.7270,  0.0000, -0.3304, -0.4336, -0.1376,\n",
      "          -0.1802, -0.1579,  0.0000, -0.4227, -1.6515,  1.0795, -1.7547,\n",
      "           0.0110,  0.7003,  0.0000,  1.0524, -0.4331,  0.5836,  0.2987,\n",
      "           0.8398,  0.2902,  0.4711,  0.6623, -0.3723, -0.9649,  0.4859,\n",
      "          -0.0110, -0.1968, -4.2006,  0.2984, -0.0817, -0.4778,  1.3375,\n",
      "          -1.9530, -0.0632,  0.0912, -1.4795,  0.9389,  0.0828, -0.2130,\n",
      "           0.6209, -1.0161,  0.6196,  0.9791, -0.3826,  0.6135,  0.0000,\n",
      "          -1.0907, -1.7584,  1.1315, -0.2068]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0574, 0.1792, 0.0639, 0.1932, 0.0722, 0.1187, 0.0825, 0.0671, 0.1146,\n",
      "         0.0513]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1822, -0.1966,  0.5943,  ...,  0.0884, -0.1281, -0.4098],\n",
      "        [ 0.0378, -0.5038,  0.5732,  ..., -0.3222, -0.0886, -0.2678],\n",
      "        [ 0.0689, -0.1241,  0.0573,  ..., -0.2873, -0.3183,  0.2320],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.2207e-02, -9.9737e-02,  6.2333e-02,  1.4380e-01,  1.2186e-02,\n",
      "           1.5512e-01, -7.1340e-02,  1.1429e-02, -9.4734e-03,  1.6673e-01,\n",
      "           2.6094e-01, -4.7218e-02,  4.7188e-02,  7.8074e-02,  2.1619e-01,\n",
      "          -1.0125e-02,  7.6535e-02, -4.7285e-03,  8.3896e-02, -1.3056e-01,\n",
      "          -8.3953e-03, -7.3725e-02,  8.7929e-02, -2.5634e-01, -1.5416e-01,\n",
      "          -4.9827e-02, -1.4579e-01, -1.8657e-01,  1.5519e-01, -2.5530e-02,\n",
      "          -4.3252e-02,  1.8392e-01, -6.5592e-02, -3.1646e-01,  2.4146e-03,\n",
      "           1.9963e-01,  1.6205e-01, -2.1959e-02,  1.5873e-01,  2.1664e-01,\n",
      "           2.5150e-01,  6.2107e-02, -4.7349e-02,  7.8001e-02, -1.3184e-01,\n",
      "           1.3075e-01, -2.3241e-02,  7.0095e-02, -6.4916e-02, -2.8037e-02,\n",
      "          -5.1538e-02,  8.4549e-03, -1.0166e-01,  1.8150e-02,  1.1389e-01,\n",
      "          -1.9706e-01, -9.2494e-02, -1.6657e-01,  1.7111e-04,  1.8232e-01,\n",
      "           3.2280e-01, -1.5214e-01, -3.6363e-02, -2.4162e-02,  1.2391e-02,\n",
      "           2.0334e-01,  2.2818e-02,  1.7047e-01, -4.4675e-02,  2.0652e-01,\n",
      "           3.6048e-02,  3.0456e-01, -1.2307e-01,  7.2297e-02, -1.0098e-01,\n",
      "          -2.3823e-02, -1.5001e-01,  3.3783e-01,  1.1454e-01,  1.4094e-01,\n",
      "           1.2385e-01,  5.8494e-03,  1.4553e-02, -1.9757e-02,  1.3059e-01,\n",
      "           2.7849e-01,  2.4124e-01,  3.3919e-02,  1.0202e-01, -1.3469e-01,\n",
      "           1.7846e-01, -8.8690e-02,  2.6155e-02,  2.1200e-02, -1.3533e-01,\n",
      "          -1.8939e-01, -2.3275e-02, -5.3658e-02,  1.8798e-02, -2.2035e-02,\n",
      "          -1.5965e-01,  1.3725e-01, -1.2598e-03,  2.7399e-01,  2.4773e-01,\n",
      "          -1.5833e-01, -4.6844e-02,  1.1514e-01,  5.5990e-02,  2.2427e-01,\n",
      "           2.2684e-01,  3.4801e-02, -2.2912e-01, -1.9867e-01, -1.2012e-01,\n",
      "          -1.1817e-01, -2.6247e-02,  1.3109e-01, -8.0114e-03, -7.0391e-02,\n",
      "          -7.8407e-03, -9.7427e-02,  6.2215e-02,  9.7372e-02, -6.7930e-02,\n",
      "          -8.1727e-02,  6.3808e-02,  5.4004e-02,  1.0230e-01,  3.6778e-02,\n",
      "          -3.2688e-02,  1.0145e-01,  1.8451e-01,  2.5375e-01, -1.3221e-01,\n",
      "          -2.0930e-01,  1.2550e-01, -1.0939e-01, -1.6945e-01,  2.9050e-03,\n",
      "          -4.9930e-02,  1.3708e-01,  1.4542e-01, -1.0196e-01, -9.0345e-02,\n",
      "          -5.6228e-02, -1.9234e-01, -3.1107e-02,  2.5379e-02, -2.0703e-01,\n",
      "          -1.3520e-01,  2.1633e-01, -1.2165e-01,  2.7172e-01,  1.1347e-01,\n",
      "           2.4338e-01, -1.4079e-01, -1.2843e-03, -1.6683e-01,  1.6731e-01,\n",
      "           1.0702e-01, -1.0450e-01,  5.0451e-02,  1.7841e-01, -1.9233e-01,\n",
      "          -3.3421e-02,  7.4835e-02,  4.4544e-02,  6.0408e-02,  1.6932e-01,\n",
      "          -1.0198e-02,  2.6206e-02,  2.1268e-01, -5.3629e-02, -1.1309e-01,\n",
      "           2.7585e-02,  7.4737e-02,  1.0251e-01,  1.6678e-01,  1.8140e-01,\n",
      "          -1.0974e-01,  1.1384e-01, -5.2171e-02,  3.1220e-02,  3.3580e-02,\n",
      "          -9.8903e-02,  7.4624e-03, -1.7251e-02,  7.1410e-02,  1.2970e-02,\n",
      "          -2.0456e-01, -6.6965e-02, -2.0603e-01, -9.1713e-02, -3.4539e-01,\n",
      "          -3.6912e-02, -1.0074e-01,  4.4744e-02, -6.0368e-02, -5.4931e-02,\n",
      "           4.4131e-02, -1.6814e-01,  2.2751e-01,  8.4459e-02, -1.6547e-01,\n",
      "           6.6930e-02, -9.3058e-03,  1.5918e-01,  8.3836e-02,  4.2217e-04,\n",
      "           2.0224e-02, -4.6147e-04, -2.0684e-01,  5.5745e-02,  1.0588e-01,\n",
      "           1.2763e-01,  1.8342e-01, -8.1704e-02,  8.4416e-02,  9.4234e-02,\n",
      "           1.2081e-03, -1.0940e-01, -4.7022e-02, -3.7677e-02, -7.8592e-02,\n",
      "           1.2546e-01, -1.5677e-01, -1.5527e-01, -1.8301e-01,  1.5881e-01,\n",
      "           7.8024e-03, -1.0487e-01,  6.4805e-02,  5.6454e-02, -8.3148e-02,\n",
      "           3.7698e-02, -1.1747e-01, -8.6022e-02,  9.9278e-02,  1.4542e-01,\n",
      "          -6.5961e-02, -2.1247e-01, -8.6191e-03, -1.9447e-01, -5.3936e-02,\n",
      "          -4.7660e-02,  5.1735e-02,  7.2925e-02,  2.7632e-01, -8.3295e-02,\n",
      "          -5.4221e-02,  1.7116e-01, -1.4993e-01, -8.4582e-02, -3.7526e-02,\n",
      "          -1.2280e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2489,  0.5299,  0.0000, -1.2071,  1.4106, -0.1512, -1.8035,\n",
      "           2.0447, -1.2832,  1.5083,  1.2791,  0.0000, -1.0004, -1.4311,\n",
      "           0.1017, -0.2193, -0.1802,  0.0259, -0.1191, -2.2247, -0.5227,\n",
      "           0.0000,  0.8422,  2.2878,  0.0000,  0.8548, -1.1607, -0.1948,\n",
      "           0.8571,  1.3925, -0.4892, -1.0600, -2.0704,  0.1881, -0.1811,\n",
      "           0.0000,  0.1942,  0.1530,  1.5806, -1.1760,  0.1889, -0.9832,\n",
      "           0.2322, -2.0592,  0.2381,  0.1677, -1.2015, -0.3851, -0.3462,\n",
      "           0.8406,  2.8165, -0.4938, -2.8547, -2.7628, -1.3752,  0.4635,\n",
      "           0.8627, -0.8957, -0.3017,  0.7206, -1.3485, -0.4109, -0.8365,\n",
      "          -0.4494,  0.2387, -0.5841,  0.2053, -0.4021, -0.2636,  0.4516,\n",
      "          -0.9377, -0.2429,  0.5703, -0.6246, -0.4208,  1.8781,  0.1730,\n",
      "          -0.4623,  1.3600,  0.0674, -1.4221, -0.7752,  0.7518,  2.0056,\n",
      "          -0.6750,  0.4781, -0.5452, -0.1596, -0.5529, -0.6611, -0.8303,\n",
      "          -0.3574,  1.4634, -1.0209,  0.8588,  0.8980,  0.0210, -0.9805,\n",
      "          -0.9866,  0.4822,  1.7877, -1.2628,  1.8145, -1.8925,  1.8200,\n",
      "          -1.2832, -2.0177, -1.0768, -1.6754,  0.6733,  0.5961,  0.3619,\n",
      "          -1.2271, -0.3054,  0.4943,  0.0000,  0.4670,  0.0000, -0.0453,\n",
      "          -2.5435,  0.1648,  1.7560, -0.4439, -2.3331,  0.9718,  1.1267,\n",
      "           1.7020,  1.7699, -1.1450, -1.1997,  0.0000, -1.7083, -0.0966,\n",
      "          -0.1155, -0.0515,  1.2201, -1.7322,  1.3120, -1.1668, -0.1634,\n",
      "           1.1223, -1.2894, -1.0130, -0.2838, -1.4855, -1.1605, -0.3625,\n",
      "           1.7111,  1.1837,  1.3153,  0.4811,  0.0471,  0.5740,  0.0000,\n",
      "           0.0000,  0.8927,  1.4875,  0.7798, -0.8161, -1.3125,  0.0000,\n",
      "           0.5188,  0.3441, -0.2698, -0.1267, -0.5588,  1.1239, -0.6173,\n",
      "          -2.3981, -0.8625, -1.0177,  0.3885,  0.0000,  0.4106, -1.1126,\n",
      "          -1.7443,  0.2916,  0.7014, -0.3064,  0.4532, -0.8748,  0.0000,\n",
      "          -1.1968, -1.4094, -0.1818,  2.1097,  2.3375,  0.0654, -2.3133,\n",
      "           0.0000,  0.5668,  0.0000,  0.4832,  1.8093,  0.5468, -0.7563,\n",
      "           0.0000, -1.4683, -0.2163, -0.3950, -0.8112,  0.0659,  1.0411,\n",
      "          -2.5192,  0.4051, -0.5074, -0.9737,  0.0000, -0.7464, -0.2058,\n",
      "          -0.3083,  0.1000, -1.8334,  0.0000,  0.0000, -0.4646,  1.0757,\n",
      "          -0.3557,  0.2882,  1.2066,  0.1394,  0.0000,  0.4131,  0.8452,\n",
      "          -0.8260, -1.1558, -0.6052, -0.2333, -0.6832,  0.6836,  1.5170,\n",
      "           0.6385, -2.4290,  0.6909, -0.1677, -2.0026, -0.1713,  0.9716,\n",
      "          -1.9457, -1.5045, -0.6189, -0.7622, -0.9255,  0.8150, -0.6703,\n",
      "           0.9348,  0.8188, -0.7625, -0.8412,  0.6685,  0.0934,  0.4812,\n",
      "          -1.3846,  0.2449, -0.5482, -0.4981]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0390, 0.1241, 0.0649, 0.0569, 0.0668, 0.1699, 0.1624, 0.0628, 0.1104,\n",
      "         0.1427]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1822, -0.1966,  0.5943,  ...,  0.0884, -0.1281, -0.4098],\n",
      "        [ 0.0378, -0.5038,  0.5732,  ..., -0.3222, -0.0886, -0.2678],\n",
      "        [ 0.0689, -0.1241,  0.0573,  ..., -0.2873, -0.3183,  0.2320],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 4.2568e-02, -2.9637e-02, -7.9692e-02,  9.6868e-02,  2.0206e-02,\n",
      "           1.3529e-01, -6.9253e-02, -2.0241e-02,  3.2369e-02,  6.8711e-02,\n",
      "           2.5320e-01, -9.6680e-02, -4.8754e-02,  8.0999e-02,  2.0860e-01,\n",
      "          -4.5158e-02,  3.4357e-02,  6.0219e-03, -1.6481e-02, -5.6006e-02,\n",
      "          -2.8214e-02, -5.9644e-02,  9.7628e-02, -2.0573e-01, -1.4951e-01,\n",
      "          -2.6291e-02, -1.0269e-01, -1.8324e-01,  1.2616e-01, -3.7258e-02,\n",
      "           3.1664e-03,  9.9908e-02, -9.0601e-02, -2.9139e-01,  5.0629e-02,\n",
      "           1.7263e-01,  8.3585e-02, -7.9562e-02,  5.1461e-02,  1.5650e-01,\n",
      "           1.8001e-01,  6.1711e-02, -9.6417e-02,  1.6084e-02, -9.3876e-02,\n",
      "           1.7302e-01, -4.9269e-02,  1.9471e-02, -2.2296e-03, -3.8523e-02,\n",
      "          -6.1905e-02, -6.3965e-02, -1.2722e-01, -2.1744e-02, -1.5854e-03,\n",
      "          -1.3822e-01, -1.0198e-01, -8.6444e-02,  2.3391e-02,  1.8886e-01,\n",
      "           2.2389e-01, -6.7338e-02, -4.6727e-02, -4.7154e-06,  7.0242e-02,\n",
      "           1.7856e-01,  6.9097e-03,  2.0532e-01, -7.4945e-02,  2.2295e-01,\n",
      "           8.4740e-03,  2.3440e-01, -1.4006e-01,  6.1750e-02, -1.4640e-01,\n",
      "          -4.2002e-02, -1.2767e-01,  2.6834e-01,  1.0185e-01,  1.7058e-01,\n",
      "           6.3162e-02, -2.8412e-02, -4.5124e-02, -1.5892e-02,  1.0546e-01,\n",
      "           2.2730e-01,  2.1590e-01,  7.3597e-02,  4.5462e-02, -7.4254e-02,\n",
      "           1.7920e-01, -8.6222e-02,  5.9216e-02,  6.7121e-03, -1.3609e-01,\n",
      "          -1.5824e-01,  3.5669e-02, -2.9050e-03,  2.9170e-02,  4.0258e-02,\n",
      "          -1.9696e-01,  1.1861e-01,  6.9325e-02,  2.7325e-01,  1.8264e-01,\n",
      "          -1.7558e-01,  2.0731e-02,  1.4387e-01,  1.0485e-01,  2.2637e-01,\n",
      "           1.9671e-01,  5.6614e-02, -1.4373e-01, -1.8198e-01, -1.4783e-01,\n",
      "          -1.4848e-01, -5.6072e-02,  8.3193e-02, -2.7122e-02, -9.4285e-02,\n",
      "          -4.7615e-02, -1.3448e-01, -3.0685e-02,  1.3904e-01, -1.1459e-01,\n",
      "          -5.7333e-02,  1.0873e-01, -7.4759e-03,  1.0834e-01,  4.5517e-02,\n",
      "          -4.6739e-02,  5.8326e-02,  1.5428e-01,  2.5588e-01, -9.1916e-02,\n",
      "          -1.6009e-01,  1.8020e-01, -8.2185e-02, -8.3242e-02, -1.1361e-02,\n",
      "          -9.9421e-02,  1.8497e-01,  1.1410e-01, -6.9344e-02, -6.0761e-02,\n",
      "          -6.2580e-02, -8.9425e-02,  5.4214e-02,  2.7763e-02, -8.9842e-02,\n",
      "          -2.0038e-01,  1.9128e-01, -7.8668e-02,  2.1517e-01,  3.4884e-02,\n",
      "           2.2242e-01, -1.0736e-01,  8.2551e-02, -1.8407e-01,  1.0623e-01,\n",
      "           8.2238e-02, -9.8455e-02, -6.2221e-02,  1.6950e-01, -1.5780e-01,\n",
      "          -2.4896e-02,  7.8983e-02, -2.8685e-02,  5.5445e-02,  1.7179e-01,\n",
      "          -9.2682e-02, -9.7903e-03,  2.0873e-01, -1.7657e-02, -6.4647e-02,\n",
      "          -7.2139e-02,  4.0964e-02,  1.3600e-01,  1.8857e-01,  4.6205e-02,\n",
      "          -1.5588e-01,  5.6015e-02, -9.6300e-02, -4.2437e-03,  6.1459e-02,\n",
      "          -6.3028e-02, -3.7591e-02,  6.7100e-02,  9.0294e-02, -8.0718e-03,\n",
      "          -1.5766e-01, -5.7240e-02, -2.2725e-01, -3.5773e-02, -2.7260e-01,\n",
      "          -1.0032e-01, -3.0569e-02,  8.5346e-02, -1.8184e-02, -5.5053e-02,\n",
      "           6.7166e-02, -8.5326e-02,  1.5370e-01,  4.4557e-02, -9.1413e-02,\n",
      "           6.6439e-02, -2.7370e-02,  2.2064e-01,  5.6207e-02, -8.0261e-02,\n",
      "          -4.2667e-02, -8.3761e-02, -1.5370e-01,  7.0173e-03,  9.7712e-02,\n",
      "           1.4149e-01,  1.5246e-01, -9.2512e-03,  2.4793e-02,  5.2701e-02,\n",
      "           6.1355e-02, -6.9921e-02,  4.9097e-03, -8.7282e-02, -5.1546e-02,\n",
      "           5.6205e-02, -1.1479e-01, -2.1147e-01, -2.0137e-01,  1.4233e-01,\n",
      "           1.8311e-02, -1.1778e-01,  3.8616e-02, -2.7312e-02, -1.1291e-01,\n",
      "           3.3030e-02, -8.4802e-02, -3.7923e-02,  8.7341e-02,  1.3602e-01,\n",
      "          -1.4960e-01, -1.7192e-01, -4.2133e-02, -1.3545e-01, -2.4567e-02,\n",
      "          -5.9758e-02, -9.0050e-04,  1.0847e-02,  2.4384e-01, -9.1165e-02,\n",
      "          -3.4283e-02,  1.5505e-01, -1.1714e-01, -1.1255e-01,  6.7159e-03,\n",
      "          -1.0899e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00, -4.3055e-01,  3.1475e-01, -1.0845e+00, -1.1723e+00,\n",
      "           7.4202e-01, -1.9141e+00,  1.3514e+00,  1.9064e-01,  0.0000e+00,\n",
      "           1.9024e+00,  6.0243e-01,  2.2864e-01, -9.1596e-01,  0.0000e+00,\n",
      "          -6.8714e-02, -1.6329e+00, -9.4333e-01,  1.3611e+00,  0.0000e+00,\n",
      "          -1.4082e-01, -5.2304e-01, -1.1192e+00, -2.5945e+00, -7.5279e-02,\n",
      "           1.3912e+00,  0.0000e+00,  1.9964e+00,  1.2769e-01,  5.5371e-01,\n",
      "           9.1433e-01, -3.5034e-03,  2.2324e-01,  2.0150e+00, -6.4082e-02,\n",
      "          -1.4084e+00, -1.1203e-01, -8.1818e-01,  3.1460e-01,  8.5168e-02,\n",
      "           8.6163e-01, -9.0036e-01,  1.0092e+00,  0.0000e+00,  1.9435e+00,\n",
      "          -2.9999e-01,  7.0414e-01, -6.0087e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.3216e+00,  2.6763e+00,  6.6662e-01, -8.4644e-01,  2.2737e-01,\n",
      "          -3.0867e-01, -1.4346e+00, -9.6854e-02,  1.2744e+00,  2.1808e+00,\n",
      "          -1.0063e+00,  0.0000e+00, -2.8031e-01,  0.0000e+00, -6.2577e-02,\n",
      "           3.9472e-01,  5.7810e-01,  1.1647e+00,  1.5803e+00,  0.0000e+00,\n",
      "           4.2767e-01,  2.9647e-01, -3.1369e-02, -7.9778e-01,  0.0000e+00,\n",
      "           1.3920e-01,  5.2556e-01,  0.0000e+00,  1.0269e+00, -7.9271e-01,\n",
      "           7.5711e-01, -1.0063e+00,  7.5673e-01,  1.0587e+00, -1.2140e+00,\n",
      "          -1.1314e-01, -1.1073e+00,  5.4868e-01, -9.4470e-01, -1.9016e+00,\n",
      "           5.2889e-01,  9.8625e-01,  0.0000e+00,  9.4320e-01,  6.0839e-01,\n",
      "          -1.5824e-02,  3.5257e-01, -1.1753e+00,  1.3709e+00,  2.4476e+00,\n",
      "           2.4403e-01,  4.6392e-02, -4.6603e-01, -9.8942e-01,  1.6393e+00,\n",
      "          -1.0221e+00,  3.0283e+00,  6.1943e-01, -1.0218e-01,  0.0000e+00,\n",
      "           1.8976e-01,  0.0000e+00, -5.7014e-01,  7.1223e-01, -7.8033e-01,\n",
      "           6.3160e-01,  4.0426e-01,  2.2410e-01, -2.3274e+00,  2.9384e-02,\n",
      "          -8.1322e-01, -1.4098e+00, -1.8368e+00,  6.0345e-01, -9.5603e-01,\n",
      "          -1.9980e-01,  3.8979e-02,  2.1498e+00,  1.3964e+00, -2.0873e+00,\n",
      "          -9.2653e-01,  4.4930e-01, -1.1669e+00,  0.0000e+00, -4.6894e-01,\n",
      "          -7.4402e-01, -1.0649e+00, -9.7453e-01, -1.9426e-02,  2.3975e+00,\n",
      "           6.9834e-01, -1.1217e+00,  1.6915e+00, -1.3998e-01, -6.6916e-01,\n",
      "           3.4356e-02,  7.5928e-01,  4.2314e-01, -1.0328e+00, -9.5707e-02,\n",
      "           1.5602e+00,  0.0000e+00, -3.3918e-01,  6.5751e-01,  1.8405e+00,\n",
      "          -2.5227e-01, -2.1695e-01,  6.2319e-01, -2.3618e+00,  0.0000e+00,\n",
      "           3.0221e-01, -7.7686e-02,  1.5390e-01, -1.2114e+00, -2.2183e-02,\n",
      "           1.6815e+00,  1.8513e+00,  2.7031e-01, -1.2701e+00, -7.1366e-01,\n",
      "          -1.2241e+00, -1.0938e+00, -2.5899e+00,  5.0535e-01, -3.0575e+00,\n",
      "           0.0000e+00,  4.9854e-01,  8.2912e-01,  3.1703e-01,  0.0000e+00,\n",
      "           0.0000e+00,  2.3396e+00,  1.0568e+00,  0.0000e+00, -4.0329e-01,\n",
      "           7.2667e-01,  5.9908e-01,  3.5916e-01,  8.4178e-01,  0.0000e+00,\n",
      "           1.3637e+00,  2.1586e+00,  3.3745e-01, -1.0150e+00,  0.0000e+00,\n",
      "          -2.2147e+00,  1.6652e+00,  2.1520e+00,  3.6328e-01,  2.3835e+00,\n",
      "           3.2340e-02, -5.0149e-01, -1.2757e+00,  0.0000e+00, -4.0739e-01,\n",
      "           0.0000e+00,  9.5398e-01, -8.5142e-01,  8.3131e-01, -1.5597e+00,\n",
      "           6.3598e-01,  6.7653e-01,  2.3968e+00,  5.4803e-02,  1.8944e+00,\n",
      "           0.0000e+00,  5.8093e-01, -2.3167e+00,  1.5503e+00, -2.2249e-01,\n",
      "          -2.2714e-01,  1.7329e+00,  0.0000e+00, -1.5522e+00,  9.2258e-01,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00, -4.0632e-05,  3.7349e-01,\n",
      "          -1.5731e+00, -1.2322e-01,  9.6646e-01, -1.7356e+00,  1.6936e+00,\n",
      "          -1.4405e+00,  0.0000e+00, -1.7213e+00,  9.8058e-01, -1.7147e+00,\n",
      "           1.5598e+00, -2.7187e-01, -2.5964e+00,  1.2381e+00, -1.2289e+00,\n",
      "           1.8831e+00, -5.0840e-01,  5.4299e-01, -2.6163e-01, -1.0211e+00,\n",
      "           1.3328e+00,  3.0968e-01, -5.1691e-02, -2.2897e-01, -1.6109e+00,\n",
      "           1.8060e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0662, 0.1100, 0.1510, 0.0918, 0.1136, 0.0971, 0.1445, 0.0717, 0.0849,\n",
      "         0.0693]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1822, -0.1966,  0.5943,  ...,  0.0884, -0.1281, -0.4098],\n",
      "        [ 0.0378, -0.5038,  0.5732,  ..., -0.3222, -0.0886, -0.2678],\n",
      "        [ 0.0689, -0.1241,  0.0573,  ..., -0.2873, -0.3183,  0.2320],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0423, -0.0327, -0.0303,  0.1246,  0.0090,  0.1809, -0.0454,\n",
      "          -0.0167,  0.0280,  0.1122,  0.2866, -0.0889, -0.0326,  0.0703,\n",
      "           0.2459,  0.0033,  0.1062, -0.0155,  0.0519, -0.0853, -0.0389,\n",
      "          -0.0428,  0.1059, -0.2470, -0.1738, -0.0823, -0.1418, -0.1687,\n",
      "           0.1425, -0.0483, -0.0647,  0.1517, -0.1240, -0.3061,  0.0635,\n",
      "           0.1998,  0.1371, -0.0457,  0.0843,  0.1904,  0.2083,  0.0415,\n",
      "          -0.0752,  0.0696, -0.0981,  0.1530, -0.0509,  0.0511, -0.0397,\n",
      "          -0.0263, -0.0992, -0.0062, -0.1150, -0.0104,  0.0761, -0.1997,\n",
      "          -0.1040, -0.1051,  0.0255,  0.1698,  0.3071, -0.0620, -0.0199,\n",
      "          -0.0455,  0.0593,  0.2008,  0.0171,  0.2084, -0.0373,  0.1999,\n",
      "          -0.0088,  0.2648, -0.1489,  0.0711, -0.1441, -0.0384, -0.1516,\n",
      "           0.3243,  0.1314,  0.1474,  0.0682, -0.0618, -0.0119, -0.0496,\n",
      "           0.1303,  0.2389,  0.2413,  0.0395,  0.0342, -0.1178,  0.1630,\n",
      "          -0.0775,  0.0822,  0.0018, -0.1506, -0.2213,  0.0032, -0.0638,\n",
      "          -0.0192, -0.0045, -0.1687,  0.1104,  0.0082,  0.3333,  0.2145,\n",
      "          -0.2007, -0.0464,  0.1075,  0.1160,  0.2642,  0.2426,  0.0467,\n",
      "          -0.1998, -0.2314, -0.1587, -0.1221, -0.1087,  0.0880,  0.0007,\n",
      "          -0.0905, -0.0164, -0.1203,  0.0035,  0.1099, -0.0799, -0.0782,\n",
      "           0.1260,  0.0175,  0.1339,  0.0914, -0.0349,  0.1090,  0.1885,\n",
      "           0.2463, -0.1320, -0.1479,  0.1389, -0.1244, -0.1379, -0.0108,\n",
      "          -0.0880,  0.1980,  0.1530, -0.0765, -0.0918, -0.0720, -0.1624,\n",
      "           0.0055, -0.0011, -0.1768, -0.1652,  0.2029, -0.1008,  0.2378,\n",
      "           0.0442,  0.2539, -0.1179,  0.0446, -0.1745,  0.1209,  0.0923,\n",
      "          -0.0923,  0.0032,  0.1293, -0.1928, -0.0551,  0.1019, -0.0241,\n",
      "           0.0861,  0.2046, -0.0362, -0.0132,  0.2104, -0.0665, -0.1137,\n",
      "           0.0076,  0.0258,  0.1510,  0.2098,  0.1443, -0.1243,  0.0961,\n",
      "          -0.0864,  0.0536,  0.0458, -0.0946, -0.0310,  0.0392,  0.1495,\n",
      "           0.0182, -0.2115, -0.0602, -0.2348, -0.0527, -0.3224, -0.0318,\n",
      "          -0.0452,  0.0764,  0.0080, -0.0302,  0.0647, -0.1124,  0.2336,\n",
      "           0.0897, -0.1108,  0.1138, -0.0562,  0.1973,  0.0603, -0.0231,\n",
      "           0.0264, -0.0609, -0.1835,  0.0004,  0.0969,  0.1476,  0.1673,\n",
      "          -0.0310,  0.0592,  0.0699,  0.0127, -0.0935, -0.0123, -0.0598,\n",
      "          -0.0604,  0.0733, -0.1433, -0.1469, -0.1596,  0.1529, -0.0265,\n",
      "          -0.1298,  0.0926, -0.0240, -0.0937,  0.0466, -0.0777, -0.0667,\n",
      "           0.0490,  0.0993, -0.1684, -0.1779, -0.0316, -0.1933, -0.0225,\n",
      "          -0.0477,  0.0450,  0.0244,  0.2432, -0.0646, -0.0699,  0.1633,\n",
      "          -0.1497, -0.0966, -0.0593, -0.0859]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7131e-02,  4.0018e-01, -9.6450e-01, -6.8081e-01,  3.7529e-01,\n",
      "          -2.0182e-01,  1.4643e+00,  0.0000e+00, -3.5829e+00,  9.0702e-01,\n",
      "           4.2783e-01, -6.2939e-01,  2.6015e+00, -6.3064e-01, -5.4137e-01,\n",
      "           0.0000e+00,  8.5156e-01,  1.0940e+00,  4.5522e-01,  4.3621e-01,\n",
      "          -6.3308e-01, -3.8218e-01,  1.6394e+00,  1.5112e+00,  7.5313e-01,\n",
      "          -7.5921e-02,  0.0000e+00, -7.6036e-01,  1.6533e+00,  8.6129e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.0340e+00, -8.3128e-02, -1.5340e+00,\n",
      "           1.3956e+00,  0.0000e+00, -3.7438e+00,  1.9767e-01,  1.5998e+00,\n",
      "          -4.5900e-01, -1.3979e+00, -2.6933e-01, -1.7138e+00, -1.5231e+00,\n",
      "           6.6812e-01,  5.4033e-01,  3.7147e-01, -1.3402e+00,  1.4479e-01,\n",
      "          -6.2933e-01,  2.7501e+00,  6.1006e-01, -1.0283e+00, -2.4753e-02,\n",
      "           2.0435e-01, -8.8094e-01, -1.2504e+00,  0.0000e+00, -4.2651e-01,\n",
      "           1.0983e+00,  1.4066e+00, -2.0196e-01, -5.0086e-01, -2.9617e+00,\n",
      "           5.5183e-01,  1.2776e+00, -1.2871e+00,  4.0938e-01,  5.2671e-01,\n",
      "          -1.2661e+00, -2.9286e-02,  7.0727e-01, -3.6389e+00,  3.2458e-01,\n",
      "          -3.7948e-04, -1.6017e-01,  1.0609e+00, -5.7190e-02, -1.1735e-01,\n",
      "          -1.3993e+00,  2.1292e+00, -9.2386e-01,  1.0059e+00,  0.0000e+00,\n",
      "           4.3678e-01,  1.6610e+00, -9.7396e-01, -1.0477e-01, -5.8105e-01,\n",
      "          -2.2719e+00,  1.0995e+00, -6.2234e-01, -1.1358e+00,  4.6664e-01,\n",
      "          -1.1696e+00,  3.2197e-02,  6.2877e-01,  1.7190e+00, -7.7763e-01,\n",
      "           2.6964e+00, -1.4610e+00,  1.0759e+00,  1.4522e+00, -6.6579e-01,\n",
      "           0.0000e+00,  1.2104e+00,  1.2749e-01, -1.4728e+00, -1.4141e-02,\n",
      "          -2.4782e-01,  1.3379e-01, -1.0469e+00,  1.3102e+00, -1.6522e+00,\n",
      "          -2.9873e+00, -5.7049e-02, -4.9881e-01, -1.9346e-01,  0.0000e+00,\n",
      "          -1.4643e+00,  0.0000e+00, -1.4599e+00, -7.2551e-01, -9.5726e-01,\n",
      "          -1.3067e+00,  8.9505e-01,  1.6935e-01,  1.2842e+00, -7.5052e-01,\n",
      "           0.0000e+00,  5.3119e-01, -1.5823e+00,  0.0000e+00,  2.7636e-01,\n",
      "          -5.8899e-01,  6.5796e-01,  5.7597e-01, -1.1594e+00,  0.0000e+00,\n",
      "          -3.8772e-01,  6.7770e-01, -7.8889e-01,  0.0000e+00, -1.6842e+00,\n",
      "          -9.9899e-02, -5.4258e-01, -8.4407e-01, -7.5449e-01,  1.7773e-01,\n",
      "           0.0000e+00, -1.9909e-01, -1.9291e+00, -4.0632e-01,  4.4105e-01,\n",
      "          -1.9458e-01, -6.5169e-02, -1.3082e-01,  3.8729e-02,  5.3732e-01,\n",
      "          -2.6759e-02,  0.0000e+00,  4.8112e-01, -5.5078e-01, -5.2542e-01,\n",
      "          -8.9059e-01,  2.8177e-01,  8.2530e-02, -3.5819e-01, -4.7793e-01,\n",
      "           7.3566e-01, -3.0245e-02,  2.0106e-02, -1.0033e+00,  1.2775e+00,\n",
      "           0.0000e+00, -9.8535e-01, -2.0746e+00,  1.9677e+00,  8.6298e-02,\n",
      "          -3.1234e-02,  3.5044e-02,  6.7049e-01,  0.0000e+00, -7.4804e-01,\n",
      "          -3.4115e-01, -2.7811e+00, -7.8235e-01,  0.0000e+00,  1.0127e+00,\n",
      "           3.0718e+00,  4.9382e-01, -1.4442e-01, -5.9253e-01,  5.5946e-01,\n",
      "           0.0000e+00, -1.1872e+00,  5.3495e-01,  1.8108e+00, -9.4583e-01,\n",
      "          -1.6626e+00,  0.0000e+00,  1.2423e+00, -1.2217e-01,  2.3201e-01,\n",
      "          -5.7447e-01, -2.2915e+00,  6.8181e-01, -1.0723e+00, -4.7141e-01,\n",
      "           2.8670e+00, -5.7310e-01,  0.0000e+00,  7.9239e-01,  0.0000e+00,\n",
      "          -6.8290e-01, -1.0164e+00,  9.6704e-01, -2.4515e-01,  2.1681e+00,\n",
      "          -1.0827e+00, -4.2668e-01, -1.8432e+00, -4.9991e-01,  3.4011e-01,\n",
      "           0.0000e+00, -6.9669e-01, -6.2809e-01,  2.9230e-01, -1.5771e+00,\n",
      "          -1.1079e+00,  1.5812e+00, -6.1355e-01,  1.3104e+00, -2.9786e+00,\n",
      "           0.0000e+00,  5.8498e-01,  4.2617e-02, -1.5777e+00,  0.0000e+00,\n",
      "           7.4216e-01, -3.2458e+00, -3.0333e-01, -8.5146e-01,  1.1320e-02,\n",
      "           2.7594e-01,  2.7473e-01,  2.5200e-01,  2.6153e-01,  0.0000e+00,\n",
      "          -3.6585e-01, -1.5986e-01, -5.5303e-01, -5.1683e-02, -1.1460e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0431, 0.0483, 0.0834, 0.0702, 0.1264, 0.2441, 0.0829, 0.0911, 0.0973,\n",
      "         0.1132]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0384,  0.4024,  0.0009,  ...,  0.1362,  0.0986, -0.2318],\n",
      "        [ 0.1874,  0.2793, -0.2952,  ..., -0.1547,  0.2130, -0.2739],\n",
      "        [ 0.1570,  0.5368, -0.3115,  ...,  0.1943, -0.0045, -0.1805],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3774e-01,  6.2015e-02, -8.9840e-02,  7.1639e-02, -3.4287e-02,\n",
      "           3.2145e-02, -7.8958e-03, -1.4927e-02,  1.3850e-01, -2.1377e-01,\n",
      "           8.6445e-03, -4.7723e-02, -3.4315e-01, -5.6937e-03,  1.0431e-01,\n",
      "           7.5820e-03,  1.6140e-01,  5.8289e-02, -6.6990e-02,  5.2159e-02,\n",
      "           2.3421e-02, -1.3902e-01,  1.2574e-01, -6.6941e-02, -1.4373e-01,\n",
      "          -1.0619e-01,  2.3174e-01, -2.0891e-01, -4.1484e-02,  2.8179e-02,\n",
      "           6.9127e-02, -1.6283e-01, -3.9745e-02, -9.3747e-02,  1.2303e-01,\n",
      "          -8.2882e-02, -1.6901e-01, -1.0753e-01, -2.0965e-01, -1.7554e-02,\n",
      "          -1.7786e-01,  7.8349e-02, -9.0676e-02,  9.6608e-03, -5.7178e-02,\n",
      "           8.5187e-02,  1.1672e-01, -9.6030e-02,  1.3417e-01,  9.8248e-02,\n",
      "          -1.0520e-01,  3.6014e-03, -2.4235e-01, -3.6590e-02, -1.7961e-01,\n",
      "          -4.0170e-02, -1.4895e-01, -2.4573e-01, -9.7677e-02,  1.4940e-02,\n",
      "          -3.8785e-02,  8.0602e-03,  3.1570e-02,  3.0099e-02,  1.3101e-01,\n",
      "           6.6471e-02,  4.6827e-02,  1.2963e-01, -6.8193e-02,  1.9719e-01,\n",
      "           2.1521e-01,  3.3914e-02,  5.2613e-02, -2.5168e-02, -5.5546e-02,\n",
      "          -1.0085e-01,  7.2016e-02,  4.8518e-02, -7.0323e-02,  9.7718e-02,\n",
      "           5.0006e-02,  6.3918e-02, -4.2399e-02, -8.3998e-02,  1.0390e-01,\n",
      "           1.1572e-02, -2.0360e-02,  1.1725e-01, -3.3469e-02,  9.6212e-02,\n",
      "           7.6349e-02, -7.6454e-02, -1.1736e-01, -2.4257e-01, -1.2177e-02,\n",
      "           9.9631e-02,  2.0919e-01,  9.8654e-02,  2.6565e-01,  1.5040e-01,\n",
      "          -1.8610e-01,  3.3053e-02,  7.2559e-02, -1.3397e-01, -2.7784e-02,\n",
      "          -9.0410e-02,  1.6260e-01,  1.3886e-01,  1.1875e-01,  1.1207e-01,\n",
      "          -3.3305e-02,  2.5521e-01, -2.0051e-01, -1.3454e-01, -1.0106e-01,\n",
      "           1.0209e-01,  2.0109e-02, -5.5462e-02,  4.2574e-02, -1.1835e-02,\n",
      "           1.3127e-02,  6.5245e-02, -1.2079e-02,  2.9020e-02, -1.3667e-01,\n",
      "           2.0710e-01,  9.0563e-02,  1.7698e-02, -2.3153e-02,  3.6168e-02,\n",
      "           8.6268e-02, -1.3945e-01,  4.3599e-02,  2.8390e-04,  4.5864e-03,\n",
      "           6.7468e-02,  2.1302e-01,  8.3470e-02,  1.1236e-01, -6.7850e-02,\n",
      "           4.8425e-02,  1.8475e-01, -1.6252e-01,  1.8453e-01,  6.2694e-02,\n",
      "          -1.0996e-01,  7.9763e-02,  1.6510e-01,  2.1045e-01,  1.0094e-01,\n",
      "          -1.8850e-01,  3.6471e-02, -2.6683e-01,  1.6735e-01, -4.1973e-02,\n",
      "           1.3391e-01,  1.8633e-02,  1.4778e-01, -2.0447e-01, -1.9404e-01,\n",
      "          -9.6613e-02, -1.5329e-01, -2.1311e-01,  1.4726e-01, -1.8806e-01,\n",
      "          -1.4874e-01, -8.7070e-02, -2.0800e-01, -6.7001e-02,  7.2040e-02,\n",
      "          -6.8038e-02,  1.2664e-01,  2.2092e-01, -1.7310e-01,  1.1800e-01,\n",
      "          -1.6348e-01, -2.9077e-02, -5.6017e-02,  1.7637e-01, -3.6386e-02,\n",
      "          -2.6366e-01, -1.4825e-01, -7.8142e-02, -9.8247e-02, -7.5376e-02,\n",
      "          -1.6278e-01, -6.9833e-02, -1.6737e-01, -1.4315e-01, -7.0204e-02,\n",
      "           1.2616e-01,  7.6287e-02, -1.1054e-01, -1.6131e-01,  1.4702e-01,\n",
      "          -9.0798e-02,  1.5483e-01,  4.1641e-02,  1.1908e-01,  3.2448e-02,\n",
      "          -4.2665e-02,  4.5954e-02, -1.4273e-01, -3.3715e-02,  1.1948e-01,\n",
      "          -9.7333e-02,  1.7579e-02,  9.8121e-02, -9.5637e-02, -1.7600e-01,\n",
      "          -2.8546e-01, -6.4284e-02,  6.5757e-02,  6.8862e-02, -4.4437e-02,\n",
      "           7.7770e-02, -2.2359e-02,  7.5489e-02, -1.1263e-01,  8.9204e-02,\n",
      "           6.2887e-02, -2.8972e-02,  8.9343e-02,  9.6776e-02, -9.6228e-04,\n",
      "          -5.9804e-02,  1.9274e-01, -1.7733e-01, -2.3268e-01,  1.5188e-01,\n",
      "           8.3991e-02, -3.4395e-02,  2.6450e-02, -3.8207e-02,  2.2774e-02,\n",
      "           1.1931e-01, -1.1500e-01,  6.2886e-02,  2.2231e-01,  1.5162e-01,\n",
      "          -1.2649e-01, -1.2731e-01, -4.7776e-02,  1.3127e-01,  1.1906e-01,\n",
      "           2.8526e-02, -1.7252e-01, -1.3299e-01,  2.3051e-01, -4.5912e-02,\n",
      "           1.9795e-01, -4.0833e-02, -1.7345e-01, -1.3378e-02,  1.3459e-01,\n",
      "          -1.5855e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4729, -0.4587, -1.2333, -0.1186,  0.4614,  0.0260,  0.6619,\n",
      "           0.5339,  0.6709,  0.9340,  0.0000, -1.0164,  0.9456, -0.2517,\n",
      "          -1.6338,  0.5121,  1.8776, -0.7568, -1.5631, -2.6432, -1.1333,\n",
      "           0.1684,  2.9293,  0.5544, -0.1169,  3.2087,  1.8370,  0.5187,\n",
      "          -2.2265,  0.0000,  0.0288,  0.0000,  0.3250,  0.8596, -0.7987,\n",
      "          -1.4655,  0.6197, -0.7715,  1.9913,  0.1017,  0.4673, -2.2046,\n",
      "          -0.5666, -0.1149, -0.7131, -0.6889,  1.9272,  0.0000, -0.2869,\n",
      "          -1.8504,  1.4677,  0.0000,  0.6674, -0.2832,  0.5316,  0.2749,\n",
      "          -1.2428, -0.9508,  1.8137, -0.0118,  0.2052, -1.8186, -1.4011,\n",
      "          -0.8063,  1.1798,  0.2654, -0.1672, -0.2547, -0.0048, -0.4608,\n",
      "          -0.3251,  0.0000,  0.1474,  0.0000,  0.6585, -0.8063,  2.0664,\n",
      "           1.6791,  0.0878, -0.5454,  1.2268,  0.0000,  0.0000, -1.8363,\n",
      "          -0.0709, -1.7316,  0.0000, -0.8914,  0.0000,  0.8108, -1.2238,\n",
      "          -1.1441,  1.9848, -0.3662, -0.7340,  0.1564,  2.1409, -0.4057,\n",
      "          -0.3039, -1.8393, -1.2905, -0.7210, -0.7663,  0.0000,  0.0000,\n",
      "           1.1138, -1.0707,  2.2522, -0.2629, -0.2883, -0.0533,  0.6104,\n",
      "           0.0000, -0.2804, -1.9418,  1.1285,  1.0065, -2.4970, -0.5752,\n",
      "           0.0000, -1.6944, -0.4008, -0.3790, -0.0783, -0.5367, -1.1105,\n",
      "           1.3040,  0.1694,  0.3221,  0.0000,  2.0787, -2.6340,  0.3599,\n",
      "          -0.7230,  0.0000,  0.0603,  0.3265, -2.1012,  0.0000, -1.6773,\n",
      "          -0.6417,  0.2343, -1.1868, -1.2146, -0.6308, -0.0403,  0.4647,\n",
      "           1.7382,  1.5948,  0.0000,  0.0000, -0.5773, -0.4800, -0.0394,\n",
      "           0.3265, -0.1172,  0.0000, -0.0317, -1.9003, -1.8064, -1.4265,\n",
      "          -0.9004, -0.7060, -0.3890, -0.9806, -0.1290,  0.4064,  0.9700,\n",
      "           0.0000, -0.1476,  0.0000, -0.3729, -0.3158, -2.0087,  0.1300,\n",
      "          -0.3525, -0.8298, -0.7687, -0.0404, -0.9373,  0.7277,  1.0418,\n",
      "           0.0469,  0.4632,  0.3160, -0.1183, -0.5408, -0.6642,  0.7546,\n",
      "          -1.0640, -0.5870, -1.7884,  1.2674, -0.9263, -1.6148, -0.3333,\n",
      "          -1.1569, -1.9605, -0.0721, -0.3749,  2.6969, -0.9218, -2.6311,\n",
      "          -0.5863, -0.7156, -1.3863, -1.2539,  0.1718,  0.2191, -1.1106,\n",
      "           0.9448,  0.0000, -1.5191,  0.0000,  0.2378,  0.0000, -2.3444,\n",
      "           0.0478, -1.4794,  0.4270,  0.0131, -0.9014,  0.0000, -1.1654,\n",
      "          -1.3006, -0.1877,  1.2720,  1.2662,  0.0000, -0.0560,  1.7376,\n",
      "          -1.1752,  0.0000,  1.9994,  0.5274,  0.7884, -0.6784,  0.1042,\n",
      "          -0.6804, -2.2617,  0.1673, -0.3133, -1.0431,  0.0000, -1.0798,\n",
      "           0.0000,  1.4993, -0.5644, -1.3767,  1.2435,  0.0000,  1.7529,\n",
      "           1.9518,  0.3627,  0.4876,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0297, 0.1623, 0.1237, 0.0536, 0.1159, 0.1427, 0.0365, 0.1902, 0.0843,\n",
      "         0.0612]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0384,  0.4024,  0.0009,  ...,  0.1362,  0.0986, -0.2318],\n",
      "        [ 0.1874,  0.2793, -0.2952,  ..., -0.1547,  0.2130, -0.2739],\n",
      "        [ 0.1570,  0.5368, -0.3115,  ...,  0.1943, -0.0045, -0.1805],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1327,  0.1183, -0.0983,  0.1248, -0.0307,  0.0111, -0.0465,\n",
      "          -0.0036,  0.1717, -0.1124, -0.0289,  0.0035, -0.3054, -0.0220,\n",
      "           0.0320,  0.0085,  0.1787,  0.0558,  0.0437,  0.0703, -0.0123,\n",
      "          -0.1506,  0.1216, -0.0815, -0.1562, -0.0902,  0.2407, -0.1654,\n",
      "          -0.0415,  0.0178,  0.0906, -0.1914, -0.0292, -0.0814,  0.1510,\n",
      "          -0.0519, -0.1452, -0.0983, -0.2012, -0.0535, -0.2138,  0.1063,\n",
      "          -0.0577,  0.0253,  0.0021, -0.0316,  0.1078, -0.0853,  0.1240,\n",
      "           0.1489, -0.0785,  0.0595, -0.2339, -0.0749, -0.1697,  0.0213,\n",
      "          -0.1281, -0.2604, -0.0735, -0.0186, -0.1195,  0.0199,  0.0683,\n",
      "          -0.0505,  0.1252,  0.0324,  0.0855,  0.0914, -0.0793,  0.1216,\n",
      "           0.1443, -0.0509,  0.0485,  0.0722,  0.0195, -0.1364,  0.0842,\n",
      "          -0.0488, -0.0356,  0.0917,  0.0234,  0.0674, -0.0124, -0.0471,\n",
      "           0.0596, -0.0605, -0.0544,  0.0377, -0.0786,  0.0616,  0.0398,\n",
      "          -0.0334, -0.0788, -0.2359,  0.0088,  0.0706,  0.1130,  0.0906,\n",
      "           0.2618,  0.1380, -0.2079, -0.0597,  0.0451, -0.0929, -0.0209,\n",
      "          -0.0235,  0.1812,  0.0767,  0.0907,  0.0622, -0.0223,  0.2103,\n",
      "          -0.1718, -0.1016, -0.0655,  0.1039,  0.0294, -0.0395,  0.0031,\n",
      "           0.0202,  0.0413,  0.1109,  0.0712,  0.0190, -0.1200,  0.2200,\n",
      "           0.0759,  0.0569, -0.0109,  0.0974,  0.0406, -0.0299, -0.0493,\n",
      "          -0.0877,  0.0291,  0.0600,  0.1588,  0.0568,  0.1162, -0.1192,\n",
      "           0.0599,  0.1456, -0.1893,  0.1481,  0.0335, -0.0991,  0.0419,\n",
      "           0.1537,  0.1587,  0.0659, -0.1132, -0.0592, -0.2246,  0.1509,\n",
      "          -0.0851,  0.1312, -0.0202,  0.1517, -0.2060, -0.1841, -0.0792,\n",
      "          -0.1405, -0.1227,  0.0722, -0.1703, -0.1388, -0.1287, -0.2106,\n",
      "           0.0051,  0.0508, -0.0927,  0.1245,  0.1902, -0.2067,  0.0858,\n",
      "          -0.1461,  0.0294, -0.0386,  0.1961,  0.0211, -0.2184, -0.1288,\n",
      "          -0.0232, -0.0348, -0.0969, -0.1958, -0.0391, -0.1778, -0.1954,\n",
      "          -0.0979,  0.1445,  0.0446, -0.0572, -0.1332,  0.1340, -0.0889,\n",
      "           0.1315, -0.0180,  0.1470, -0.0299, -0.0970,  0.0431, -0.1531,\n",
      "          -0.0310,  0.0323,  0.0165, -0.0655,  0.1173, -0.0061, -0.0970,\n",
      "          -0.2874, -0.0484,  0.0792, -0.0144, -0.0968,  0.0657, -0.0168,\n",
      "          -0.0018, -0.0332,  0.0560,  0.0394,  0.0395,  0.0638,  0.0699,\n",
      "          -0.0562, -0.0899,  0.1515, -0.0653, -0.2258,  0.0852,  0.0902,\n",
      "          -0.0414,  0.0583, -0.0168,  0.0296,  0.1080, -0.1152,  0.0831,\n",
      "           0.2008,  0.0729, -0.1206, -0.0519,  0.0254,  0.1178,  0.1720,\n",
      "          -0.0144, -0.1593, -0.1291,  0.1588, -0.0550,  0.1950, -0.0513,\n",
      "          -0.1709,  0.0018,  0.1097, -0.1547]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000,  0.0895, -0.5447,  0.5406, -0.5667,  1.2814,  2.8250,\n",
      "          -0.2471,  0.0000, -0.7566, -0.5309, -0.1983,  0.1427,  0.9651,\n",
      "           0.0000, -0.0218,  1.9364,  0.6198,  0.7510,  1.0218,  0.0531,\n",
      "           0.0000,  0.0000,  0.3094, -0.6974, -1.7925,  0.9461, -1.6199,\n",
      "          -1.3355, -0.2374,  1.0223,  0.0413,  1.2296,  1.0356, -2.2231,\n",
      "          -0.1119,  0.8039,  2.8217, -0.9015,  0.7705,  0.0000,  1.3752,\n",
      "          -0.4474, -0.7736,  0.4121,  0.7250,  0.0000,  0.1300, -1.4964,\n",
      "          -0.5182, -1.6946,  0.3113,  0.0000,  0.0000,  0.5994,  0.8040,\n",
      "          -0.8518, -0.3592, -1.7294,  0.7365,  0.0000, -0.3920,  1.0847,\n",
      "          -0.1033, -0.0894,  0.0156,  0.0000, -1.0997,  0.2717,  0.3525,\n",
      "           1.9231,  0.4212,  1.1188, -1.2294,  0.8908,  0.1946,  0.0000,\n",
      "           1.5196,  1.8507,  0.3836, -0.3516,  0.5984,  0.0000, -0.4788,\n",
      "          -0.2580,  0.0000,  0.7318,  0.4439,  1.3635, -0.1761,  0.5853,\n",
      "          -2.1565, -2.1798,  0.3540,  0.0115,  2.7015, -1.7220,  1.2751,\n",
      "          -0.0441, -1.0986, -0.7011, -2.0435, -0.6697, -0.1609,  1.6321,\n",
      "          -1.0262, -0.6525, -2.4368,  0.6937,  0.0000, -1.1893,  0.1587,\n",
      "           0.0000, -0.9373,  0.4890,  0.0000, -1.6687,  0.2724,  0.7820,\n",
      "          -0.9479,  0.7601, -0.0156, -1.1622, -1.0948,  0.3940, -0.3331,\n",
      "           0.3810,  0.0000, -0.3103, -1.2434,  1.8613, -0.7283, -2.8891,\n",
      "           0.2187,  0.0062,  1.6982,  0.6946,  1.1920, -0.7223, -0.1734,\n",
      "           0.0000, -0.6610,  0.0000, -1.4532,  1.6867,  0.3418, -1.1808,\n",
      "          -1.0238,  0.0407,  1.0778, -1.9801,  0.3243,  0.3247,  0.3625,\n",
      "          -1.5382,  3.0205, -0.5187, -0.5636, -0.7016, -0.7323,  1.8931,\n",
      "          -0.7949, -0.5215,  0.3036, -0.6081, -2.1512,  0.0000,  0.1355,\n",
      "          -1.1577, -0.1446,  0.2199, -1.0645, -0.1098, -0.6668, -0.8938,\n",
      "           0.1084, -1.1213, -0.1853,  0.0000,  1.3490,  1.0814,  0.4878,\n",
      "           1.7313,  0.0225, -0.4737,  0.7006,  0.3860,  0.0000,  1.1606,\n",
      "          -0.5261,  0.4115,  0.0899,  0.0000, -0.7926,  1.4955, -0.7505,\n",
      "           1.2237, -0.9138,  0.6284,  1.7518,  1.1109,  0.7765,  0.0000,\n",
      "           1.7858, -1.3503, -1.0609, -0.4762, -0.3572, -0.5373, -0.1133,\n",
      "           0.5641, -1.8134,  1.3914, -3.2296,  2.5845,  1.3446, -0.3182,\n",
      "           0.7508, -1.3996,  0.0000, -0.8145,  0.9959,  2.1174,  0.4198,\n",
      "          -0.9089,  0.0000,  0.9678, -2.4500,  0.5261,  0.1760, -0.2966,\n",
      "          -2.2930,  0.0000,  1.9834, -0.0466,  0.9684, -0.0307, -0.2607,\n",
      "          -0.6886,  1.0013, -0.4163,  0.8741,  0.0000, -1.0517,  1.6173,\n",
      "           0.3171,  1.2640, -0.5036,  0.1782, -1.8397, -0.7278,  0.2624,\n",
      "          -0.5330, -1.6515, -0.4462,  0.1442]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1798, 0.0875, 0.0656, 0.1660, 0.0652, 0.0786, 0.0822, 0.0620, 0.1027,\n",
      "         0.1104]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0384,  0.4024,  0.0009,  ...,  0.1362,  0.0986, -0.2318],\n",
      "        [ 0.1874,  0.2793, -0.2952,  ..., -0.1547,  0.2130, -0.2739],\n",
      "        [ 0.1570,  0.5368, -0.3115,  ...,  0.1943, -0.0045, -0.1805],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.7042e-02,  1.7370e-01, -1.0741e-01,  1.0399e-01, -2.9795e-02,\n",
      "           9.8786e-03, -1.4993e-02, -2.6297e-02,  1.9935e-01, -1.5519e-01,\n",
      "          -2.0343e-02, -4.4807e-02, -2.9308e-01, -4.4351e-02,  1.6670e-02,\n",
      "          -2.6326e-02,  1.7542e-01, -1.1563e-02,  1.0707e-01,  8.1906e-02,\n",
      "          -3.4764e-02, -1.8611e-01,  7.5714e-02, -1.0720e-01, -1.0526e-01,\n",
      "          -1.0986e-01,  2.1102e-01, -1.2659e-01, -2.9928e-02, -3.6611e-02,\n",
      "           1.5895e-02, -1.4574e-01, -1.5530e-02,  4.0223e-02,  1.0011e-01,\n",
      "          -2.6335e-02, -2.0927e-01, -1.3163e-01, -2.6698e-01, -9.2195e-02,\n",
      "          -2.1819e-01,  8.4582e-02, -7.8534e-02, -3.7946e-03,  4.3297e-02,\n",
      "          -6.0813e-03,  4.3686e-02,  5.8016e-02,  1.4975e-01,  1.2578e-01,\n",
      "          -5.2128e-03,  7.2665e-03, -2.5611e-01, -1.3356e-01, -1.5422e-01,\n",
      "           3.0504e-02, -1.0700e-01, -2.5993e-01, -4.5655e-02,  3.8306e-03,\n",
      "          -8.7617e-02,  6.6867e-02,  9.0906e-02, -3.3203e-02,  1.5648e-01,\n",
      "           7.8595e-02,  1.4390e-01,  3.7975e-02, -5.6358e-02,  1.5189e-01,\n",
      "           1.2762e-01, -8.3274e-02,  2.9320e-02,  6.9500e-02, -3.0640e-03,\n",
      "          -1.4162e-01,  5.9444e-02, -8.4789e-02, -5.6618e-02,  1.2097e-01,\n",
      "           2.4888e-02,  4.8487e-02, -2.4846e-02, -5.1787e-02,  9.4094e-02,\n",
      "          -5.8488e-02, -7.4356e-03, -4.9440e-02, -1.0601e-01,  7.0122e-02,\n",
      "           6.0126e-02, -2.5512e-02,  1.5707e-02, -2.3679e-01, -2.2050e-02,\n",
      "           8.2068e-04,  1.7237e-01,  1.1432e-01,  2.6551e-01,  1.7141e-01,\n",
      "          -2.3450e-01, -1.2604e-01,  1.2670e-01, -1.4133e-01, -6.7074e-02,\n",
      "           5.3601e-02,  2.0272e-01,  3.4701e-02,  7.2880e-02,  1.3369e-02,\n",
      "          -1.9352e-02,  1.5428e-01, -1.5046e-01, -1.4745e-01, -1.7068e-02,\n",
      "           1.0600e-01,  4.5450e-03, -5.4715e-02,  6.2241e-03, -1.3523e-02,\n",
      "           6.1951e-02,  1.4571e-01,  4.1001e-02,  3.3075e-02, -5.7171e-02,\n",
      "           1.9517e-01,  1.5329e-01,  1.7710e-02, -1.6962e-02,  4.6329e-02,\n",
      "           1.1163e-01, -8.5192e-02, -1.2987e-02, -4.7998e-02,  2.1056e-02,\n",
      "           6.6322e-02,  1.9327e-01,  4.8127e-02,  1.0039e-01, -1.3800e-01,\n",
      "           8.7459e-02,  1.7366e-01, -1.4297e-01,  1.9226e-01,  4.7976e-02,\n",
      "          -6.8114e-02,  7.7821e-02,  1.9324e-01,  1.2408e-01,  1.2334e-01,\n",
      "          -1.7684e-02, -1.4728e-01, -2.0777e-01,  1.3717e-01, -6.2184e-02,\n",
      "           8.2061e-02,  6.6671e-05,  1.0463e-01, -2.2984e-01, -2.2193e-01,\n",
      "          -1.0248e-01, -1.4375e-01, -1.7515e-01,  1.1672e-01, -1.6293e-01,\n",
      "          -1.5630e-01, -1.0853e-01, -1.6433e-01,  4.0497e-02,  1.4437e-01,\n",
      "          -1.0153e-01,  4.1963e-02,  1.8781e-01, -2.2387e-01, -3.5577e-02,\n",
      "          -2.1534e-01,  5.2563e-02, -8.2713e-02,  1.9524e-01, -8.0204e-03,\n",
      "          -2.6478e-01, -1.2794e-01, -1.5019e-02,  8.7462e-03, -1.7102e-01,\n",
      "          -1.6192e-01, -1.1086e-01, -1.2955e-01, -1.1395e-01, -2.1554e-02,\n",
      "           6.5494e-02, -6.1443e-02, -1.1817e-01, -1.5805e-01,  1.9558e-01,\n",
      "          -3.9325e-02,  2.0762e-01, -6.4520e-02,  1.6476e-01,  1.1874e-02,\n",
      "          -1.2804e-01,  4.4116e-02, -1.7366e-01, -4.8088e-02,  1.0324e-01,\n",
      "          -7.2486e-02, -7.1505e-02,  4.6600e-02, -4.8096e-02, -1.1472e-01,\n",
      "          -2.9854e-01, -5.2056e-03,  6.0038e-02, -4.7344e-02, -4.1415e-02,\n",
      "           1.6332e-01, -8.6330e-02, -3.6232e-02, -1.7077e-02,  5.1101e-02,\n",
      "           5.2054e-02,  1.0751e-02,  2.7771e-02, -1.8456e-02, -2.1223e-02,\n",
      "          -9.5942e-02,  9.8660e-02, -9.5654e-02, -1.3598e-01,  1.5005e-01,\n",
      "           5.9737e-02, -3.9981e-02,  6.7013e-02, -2.7339e-02,  5.4022e-02,\n",
      "           9.2821e-02, -1.2157e-01,  9.0351e-02,  2.1630e-01,  8.6726e-02,\n",
      "          -1.7673e-01, -3.6688e-02, -4.2903e-02,  8.7320e-02,  1.8011e-01,\n",
      "          -7.1844e-02, -1.4300e-01, -9.6106e-02,  1.9055e-01,  2.2076e-02,\n",
      "           2.0645e-01, -1.2573e-02, -1.4955e-01,  6.9984e-02,  1.3470e-01,\n",
      "          -1.4208e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0956,  0.0000, -1.8337,  0.4809,  0.2274,  0.0975, -0.6967,\n",
      "           0.6577, -1.2318, -0.2294,  0.9108,  0.7511,  0.8134, -0.8888,\n",
      "           0.1355,  0.1056, -2.5532, -0.5229, -1.7250,  0.0000,  0.0000,\n",
      "           0.4350, -0.0323, -1.1795,  0.0687,  0.6069,  1.2300, -0.5314,\n",
      "          -0.6125,  0.0703, -2.4010,  1.0433,  1.3102,  1.9862,  0.0000,\n",
      "          -2.2997, -1.6468, -0.9119, -0.0351,  0.9289,  0.0000,  0.8081,\n",
      "           0.8568, -1.1940, -0.8257, -0.0559, -1.9333,  0.0000,  0.5479,\n",
      "          -0.0200, -0.4412,  0.5635,  0.5535, -1.5368, -0.2661,  1.1242,\n",
      "          -1.0357,  0.3514, -1.6144,  0.3718, -0.9785,  1.1598, -0.1423,\n",
      "           2.6404,  0.3129, -1.4200,  0.0762,  0.0000,  3.0868, -0.2395,\n",
      "           0.6227, -0.8378,  0.5394, -1.7551, -1.2018,  0.1878,  0.0000,\n",
      "           0.4013,  0.0000, -0.1119,  1.9246,  0.1258, -0.5208,  0.2860,\n",
      "          -1.0667,  0.4020, -1.4299,  0.4939, -1.3558, -0.0952,  2.1923,\n",
      "           0.4401,  1.7203, -1.2976,  0.0000,  0.9800,  0.2176, -0.3142,\n",
      "           0.0000, -0.7198, -0.2550, -2.4406,  1.8915,  0.2867,  1.4856,\n",
      "          -0.1764,  1.2915, -0.8873, -0.3402,  1.1379, -1.3496,  0.4941,\n",
      "          -0.8327, -0.2459,  0.5090,  1.7197,  1.4277,  0.3565,  0.3546,\n",
      "          -0.9255, -1.3410,  0.5749,  1.4328,  0.0000, -0.7709, -0.9057,\n",
      "           0.0000, -1.0266, -0.4843, -0.7461, -0.2362, -1.6527, -0.9425,\n",
      "           0.0000, -0.3653,  0.0387,  1.3937, -0.2998, -1.5879,  0.3058,\n",
      "          -0.2411,  0.0065, -0.1567,  0.7795, -1.6008, -0.4766,  0.0049,\n",
      "          -0.9579, -0.2038, -0.2416, -0.7144, -1.2642,  0.0261,  0.8586,\n",
      "           0.5159, -0.3446,  0.3436,  0.4519,  0.0000,  1.7733, -0.2013,\n",
      "          -0.0206, -2.4634,  0.3642,  0.2978, -0.5992,  0.0000,  0.0000,\n",
      "           0.7923, -0.5006,  0.1945, -0.9362,  1.7410, -0.4643, -0.5532,\n",
      "          -0.9516,  0.8084, -0.9924,  1.4189,  1.9492,  1.3586,  1.4811,\n",
      "           0.0000, -1.4785, -1.1177,  1.6498,  0.0000,  0.7438,  1.9179,\n",
      "           0.8057,  0.8518,  0.8906,  0.0000,  0.4236, -0.6398, -2.2620,\n",
      "          -1.3300,  0.0000,  0.9775,  0.0000, -2.0788,  0.0924,  0.2680,\n",
      "          -0.2513, -0.9038,  1.4557,  0.9092, -2.0556, -1.9611,  1.4636,\n",
      "          -2.3072, -2.1011, -1.2135,  1.1994, -2.3419, -0.0522, -0.2011,\n",
      "           2.1754, -0.4733,  1.8622,  0.3149, -0.6402, -0.3686,  0.4554,\n",
      "           0.5075,  2.4414,  0.8720,  1.4938, -0.8332, -0.1198,  3.2878,\n",
      "          -0.1959,  0.5155,  0.0000,  0.0795, -1.1154, -0.5618,  0.1133,\n",
      "          -0.4442, -1.6575, -1.2675,  0.1885,  2.1972,  0.0000, -0.6986,\n",
      "           0.9224,  0.7320,  1.3143,  1.7127,  1.5752, -0.8712,  0.7009,\n",
      "          -1.4341,  0.6464, -1.3900, -0.5865]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.2213, 0.0732, 0.0813, 0.0559, 0.0792, 0.1464, 0.0575, 0.0657, 0.1364,\n",
      "         0.0831]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0384,  0.4024,  0.0009,  ...,  0.1362,  0.0986, -0.2318],\n",
      "        [ 0.1874,  0.2793, -0.2952,  ..., -0.1547,  0.2130, -0.2739],\n",
      "        [ 0.1570,  0.5368, -0.3115,  ...,  0.1943, -0.0045, -0.1805],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0930,  0.1500, -0.0820,  0.1002,  0.0084,  0.0098, -0.0628,\n",
      "          -0.0427,  0.1647, -0.1673,  0.0055, -0.0733, -0.2548, -0.0306,\n",
      "           0.0235, -0.0415,  0.1562,  0.0611,  0.0709,  0.1297, -0.0738,\n",
      "          -0.1697,  0.1287, -0.0858, -0.1112, -0.0867,  0.2219, -0.1583,\n",
      "          -0.0237, -0.0523,  0.0264, -0.1499,  0.0337,  0.0219,  0.0651,\n",
      "           0.0285, -0.2008, -0.1506, -0.2063, -0.0859, -0.2263,  0.0624,\n",
      "          -0.1297, -0.0461,  0.0305,  0.0114,  0.0344,  0.0215,  0.1310,\n",
      "           0.1310, -0.0090,  0.0171, -0.2112, -0.1370, -0.1937,  0.0364,\n",
      "          -0.0927, -0.2435, -0.0375,  0.0079, -0.1192,  0.0859,  0.0742,\n",
      "           0.0065,  0.1506,  0.0652,  0.1359,  0.0918, -0.0707,  0.1996,\n",
      "           0.1235, -0.0584,  0.0507,  0.0800,  0.0109, -0.1002,  0.0978,\n",
      "          -0.0632, -0.0545,  0.1456,  0.0472,  0.0309, -0.0324,  0.0216,\n",
      "           0.1352, -0.0060,  0.0116, -0.0045, -0.1025,  0.0515,  0.0879,\n",
      "           0.0075, -0.0514, -0.2400, -0.0551, -0.0079,  0.1824,  0.1292,\n",
      "           0.2380,  0.1975, -0.2147, -0.1109,  0.1163, -0.1306,  0.0300,\n",
      "           0.0171,  0.2071,  0.0661,  0.0965,  0.0155,  0.0049,  0.1975,\n",
      "          -0.1614, -0.1493, -0.0636,  0.0781, -0.0094, -0.0545,  0.0207,\n",
      "          -0.0359,  0.0244,  0.1266, -0.0025,  0.0562, -0.0937,  0.1824,\n",
      "           0.1546, -0.0270,  0.0295,  0.0587,  0.0994, -0.1214, -0.0089,\n",
      "           0.0209,  0.0325,  0.0015,  0.1447,  0.0524,  0.0968, -0.1213,\n",
      "           0.0978,  0.1874, -0.2128,  0.1483, -0.0137, -0.0341,  0.0386,\n",
      "           0.1888,  0.1130,  0.1878, -0.0294, -0.0781, -0.2083,  0.1454,\n",
      "          -0.0452,  0.1124, -0.0290,  0.1270, -0.2491, -0.2013, -0.1067,\n",
      "          -0.1750, -0.1772,  0.1226, -0.1628, -0.1505, -0.0347, -0.1680,\n",
      "          -0.0276,  0.1227, -0.0513,  0.0203,  0.2089, -0.1763, -0.0402,\n",
      "          -0.2117,  0.0432, -0.0950,  0.1482,  0.0339, -0.2641, -0.1003,\n",
      "          -0.0165, -0.0080, -0.1161, -0.1441, -0.0974, -0.1335, -0.1248,\n",
      "          -0.0250,  0.0408, -0.0636, -0.1601, -0.1163,  0.1266, -0.0524,\n",
      "           0.1876, -0.0489,  0.1340, -0.0042, -0.1458,  0.0462, -0.2240,\n",
      "          -0.0311,  0.1168, -0.0953, -0.1229,  0.0677, -0.0055, -0.1407,\n",
      "          -0.2870, -0.0349,  0.0392, -0.0300, -0.0616,  0.1063, -0.0838,\n",
      "          -0.0355, -0.0627,  0.0505,  0.0570, -0.0193, -0.0185,  0.0536,\n",
      "          -0.0637, -0.0596,  0.1050, -0.1246, -0.1555,  0.1173,  0.0535,\n",
      "          -0.0186,  0.0260, -0.0123,  0.0577,  0.0989, -0.0821,  0.0914,\n",
      "           0.2393,  0.1018, -0.1764,  0.0125,  0.0246,  0.0650,  0.1966,\n",
      "          -0.0575, -0.1461, -0.0568,  0.1636, -0.0696,  0.2489, -0.0029,\n",
      "          -0.1338,  0.0230,  0.1151, -0.1614]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-6.9985e-01,  9.2465e-01, -5.8233e-01, -8.6698e-01,  2.7754e+00,\n",
      "           8.6818e-01,  1.6359e+00,  4.5628e-01,  1.7553e+00, -7.6921e-01,\n",
      "          -9.4069e-01,  4.6715e-01,  4.9051e-01,  0.0000e+00, -2.3469e-01,\n",
      "          -1.3566e+00,  0.0000e+00,  7.2113e-01, -9.1712e-01, -2.0874e+00,\n",
      "          -1.8409e+00, -1.5530e+00,  6.6536e-01,  1.2337e+00,  3.5419e-01,\n",
      "          -1.4245e-01, -8.1720e-01,  8.4959e-01, -1.3745e+00, -1.7852e+00,\n",
      "          -1.8340e-01,  6.3672e-01, -8.1563e-01, -9.7052e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.9874e+00,  1.6061e-01, -1.8844e+00, -1.6754e+00,\n",
      "           1.3878e+00,  0.0000e+00, -1.4931e-01, -2.0711e-01,  0.0000e+00,\n",
      "          -3.5946e-01, -1.5305e+00, -5.5614e-01, -6.0267e-01,  7.3024e-01,\n",
      "           6.7380e-01,  8.8932e-01,  1.4668e+00,  1.0821e+00, -4.1533e-01,\n",
      "          -7.7134e-04,  0.0000e+00,  3.4523e-01,  3.1865e-01,  2.0897e+00,\n",
      "           1.8265e+00,  6.6496e-01, -8.2808e-01,  1.2296e+00,  0.0000e+00,\n",
      "          -6.4050e-01, -1.3032e+00, -7.3851e-01, -2.9321e-01, -6.7288e-01,\n",
      "          -8.5463e-01,  1.7467e-01,  2.5374e+00,  1.4245e+00,  0.0000e+00,\n",
      "           5.9316e-01,  0.0000e+00, -1.6833e-01, -6.1716e-01, -9.3115e-01,\n",
      "           1.3524e+00,  7.6579e-01,  6.4106e-01, -5.5351e-01,  4.7656e-01,\n",
      "           4.5301e-01, -5.3450e-01, -6.8443e-02,  7.8275e-01, -1.0487e+00,\n",
      "           0.0000e+00, -9.4127e-01,  4.2484e-01, -3.9175e-01, -2.5853e+00,\n",
      "           1.3141e+00,  7.1611e-01, -2.6918e-01, -8.5767e-01, -7.6085e-01,\n",
      "           0.0000e+00, -2.0201e+00,  6.0875e-01,  2.2040e+00, -6.1306e-02,\n",
      "          -1.8057e+00,  2.4961e-01,  1.4447e+00, -9.9369e-01, -2.0863e-01,\n",
      "           1.5753e+00,  3.5435e+00,  1.0976e+00,  3.7534e-01,  4.1525e-01,\n",
      "           1.7962e+00, -6.5700e-02, -1.2571e+00, -1.5499e+00,  2.0287e+00,\n",
      "          -1.8266e-01,  0.0000e+00,  2.0257e+00,  1.1486e+00,  9.9642e-01,\n",
      "           1.6247e+00,  9.3364e-01,  3.9623e-01, -2.2930e-01,  0.0000e+00,\n",
      "           5.4825e-01, -3.5085e-01, -1.3642e+00,  7.3661e-01,  1.1442e+00,\n",
      "           0.0000e+00,  1.1067e+00, -2.3385e+00,  6.8820e-01, -8.9787e-01,\n",
      "           1.1716e+00, -1.5628e+00, -1.0440e+00, -6.7305e-01,  6.0565e-01,\n",
      "           0.0000e+00, -6.6479e-01,  7.8798e-01, -3.4589e-01, -3.3714e-01,\n",
      "           0.0000e+00, -7.3147e-01,  1.7527e+00,  9.5824e-01,  4.2263e-01,\n",
      "           5.8953e-01,  5.0368e-01,  1.4456e-01,  0.0000e+00, -4.2081e-01,\n",
      "          -1.9713e+00, -2.5101e-01,  2.9510e-01, -1.4348e-01, -1.6979e+00,\n",
      "           6.9672e-01, -1.5804e+00,  4.2253e-02, -1.4269e+00, -2.0319e-01,\n",
      "           1.2154e-01, -6.0229e-01,  2.4602e-01, -9.8177e-01,  4.5599e-01,\n",
      "           1.3120e+00,  8.6218e-01,  8.5794e-01,  0.0000e+00,  0.0000e+00,\n",
      "           4.6137e-01,  2.5687e-01, -6.2462e-01, -8.1826e-01, -4.7219e-01,\n",
      "           2.3070e+00,  1.4151e+00, -3.7758e-01,  1.5198e+00,  1.0736e+00,\n",
      "          -2.3851e-01, -7.7358e-01,  1.5690e+00,  1.0336e+00, -1.7919e-01,\n",
      "           0.0000e+00,  3.9181e-02, -1.4660e+00, -1.1825e+00, -1.3160e+00,\n",
      "           6.1922e-01,  0.0000e+00, -5.1618e-01, -4.4214e-01, -2.0560e-01,\n",
      "           4.0200e-01,  1.9244e+00,  7.8546e-01,  1.9746e+00, -1.2072e+00,\n",
      "           1.7691e+00,  0.0000e+00,  4.9860e-01, -1.1891e+00,  1.2818e+00,\n",
      "          -2.5184e+00,  5.7515e-01,  1.0145e+00, -4.6637e-01,  0.0000e+00,\n",
      "          -1.9188e-01,  1.0238e+00, -7.5838e-01,  0.0000e+00, -2.0689e+00,\n",
      "          -2.5217e-01,  9.6734e-01,  9.6002e-01, -7.1629e-01, -1.8406e+00,\n",
      "           0.0000e+00, -5.9036e-01,  6.0445e-01, -3.0049e+00,  9.2164e-01,\n",
      "          -8.2180e-01, -7.5941e-01,  1.6188e-01,  1.3831e+00, -4.2536e-01,\n",
      "          -6.2091e-01, -4.3697e-01,  5.0877e-01,  7.2971e-01,  0.0000e+00,\n",
      "           4.0312e-01, -1.2080e+00,  1.6613e+00, -4.7098e-01,  1.4431e-01,\n",
      "          -1.3367e+00,  3.5472e-01, -5.7275e-01, -3.5652e-01,  4.6884e-01,\n",
      "          -1.9610e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0472, 0.1557, 0.1301, 0.1268, 0.1061, 0.0915, 0.0835, 0.1117, 0.0637,\n",
      "         0.0836]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0384,  0.4024,  0.0009,  ...,  0.1362,  0.0986, -0.2318],\n",
      "        [ 0.1874,  0.2793, -0.2952,  ..., -0.1547,  0.2130, -0.2739],\n",
      "        [ 0.1570,  0.5368, -0.3115,  ...,  0.1943, -0.0045, -0.1805],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1383,  0.1642, -0.1335,  0.1393, -0.0570,  0.0155, -0.0229,\n",
      "          -0.0098,  0.2165, -0.1256, -0.0285, -0.0024, -0.3476, -0.0384,\n",
      "           0.0274,  0.0090,  0.2045,  0.0079,  0.0755,  0.0576,  0.0016,\n",
      "          -0.1747,  0.1040, -0.0999, -0.1562, -0.1136,  0.2329, -0.1590,\n",
      "          -0.0443,  0.0152,  0.0760, -0.1903, -0.0494, -0.0551,  0.1760,\n",
      "          -0.0666, -0.1747, -0.1045, -0.2616, -0.0769, -0.2332,  0.1145,\n",
      "          -0.0569,  0.0385,  0.0325, -0.0402,  0.1021, -0.0477,  0.1516,\n",
      "           0.1538, -0.0685,  0.0527, -0.2808, -0.0942, -0.1638,  0.0286,\n",
      "          -0.1470, -0.2784, -0.0722, -0.0081, -0.1152,  0.0348,  0.0930,\n",
      "          -0.0730,  0.1581,  0.0593,  0.1072,  0.0647, -0.0742,  0.1136,\n",
      "           0.1471, -0.0758,  0.0324,  0.0776,  0.0064, -0.1713,  0.0664,\n",
      "          -0.0665, -0.0472,  0.0989,  0.0083,  0.0610, -0.0140, -0.0965,\n",
      "           0.0527, -0.0840, -0.0680, -0.0015, -0.0985,  0.0661,  0.0458,\n",
      "          -0.0507, -0.0268, -0.2451,  0.0128,  0.0638,  0.1284,  0.1097,\n",
      "           0.2891,  0.1494, -0.2474, -0.0902,  0.0816, -0.1121, -0.0931,\n",
      "           0.0014,  0.2052,  0.0570,  0.0841,  0.0536, -0.0310,  0.1929,\n",
      "          -0.1712, -0.1349, -0.0474,  0.1170,  0.0333, -0.0545,  0.0018,\n",
      "           0.0164,  0.0695,  0.1275,  0.0927,  0.0201, -0.1014,  0.2444,\n",
      "           0.0984,  0.0752, -0.0267,  0.0934,  0.0607, -0.0280, -0.0462,\n",
      "          -0.1205,  0.0266,  0.0978,  0.2079,  0.0565,  0.1196, -0.1419,\n",
      "           0.0743,  0.1644, -0.1616,  0.1960,  0.0716, -0.1244,  0.0663,\n",
      "           0.1770,  0.1673,  0.0504, -0.0979, -0.1231, -0.2387,  0.1603,\n",
      "          -0.0999,  0.1206, -0.0115,  0.1434, -0.2139, -0.2227, -0.0931,\n",
      "          -0.1358, -0.1450,  0.0880, -0.1682, -0.1487, -0.1605, -0.2226,\n",
      "           0.0518,  0.0964, -0.1261,  0.1323,  0.1986, -0.2580,  0.0658,\n",
      "          -0.1690,  0.0412, -0.0400,  0.2466,  0.0028, -0.2497, -0.1547,\n",
      "          -0.0221, -0.0131, -0.1461, -0.2155, -0.0698, -0.1704, -0.1790,\n",
      "          -0.0857,  0.1404,  0.0317, -0.0722, -0.1683,  0.1903, -0.0794,\n",
      "           0.1639, -0.0356,  0.1809, -0.0100, -0.1072,  0.0540, -0.1395,\n",
      "          -0.0370,  0.0516,  0.0187, -0.0571,  0.1128, -0.0404, -0.0889,\n",
      "          -0.3124, -0.0451,  0.0950, -0.0305, -0.0733,  0.1258, -0.0397,\n",
      "          -0.0094, -0.0191,  0.0602,  0.0490,  0.0418,  0.0847,  0.0157,\n",
      "          -0.0315, -0.1163,  0.1582, -0.0618, -0.2151,  0.1269,  0.0750,\n",
      "          -0.0438,  0.0856, -0.0406,  0.0291,  0.1059, -0.1339,  0.0904,\n",
      "           0.2008,  0.0719, -0.1478, -0.0753, -0.0224,  0.1239,  0.1751,\n",
      "          -0.0298, -0.1710, -0.1456,  0.1931,  0.0131,  0.1994, -0.0482,\n",
      "          -0.1909,  0.0416,  0.1229, -0.1546]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.4416e-01,  1.2881e+00,  1.3519e+00,  0.0000e+00, -8.8902e-01,\n",
      "          -2.5246e+00,  2.8833e-01,  0.0000e+00,  0.0000e+00, -2.5839e-01,\n",
      "           1.5231e+00, -9.3685e-02,  0.0000e+00, -2.2728e-01,  1.5463e+00,\n",
      "           6.4158e-01,  6.5693e-02,  4.8800e-01, -8.9042e-01, -6.0416e-02,\n",
      "           0.0000e+00, -2.6668e+00, -1.3778e+00,  3.8664e-01, -1.4099e+00,\n",
      "           9.0255e-01,  0.0000e+00,  9.6371e-01,  1.3524e+00,  2.5797e+00,\n",
      "          -1.2594e+00, -4.5399e-01,  4.2893e-01,  5.3245e-01,  5.1394e-01,\n",
      "           6.2304e-01, -8.3261e-01,  3.4507e-02,  3.3492e-01, -1.2916e+00,\n",
      "           3.7966e-02,  4.2848e-01, -1.1591e+00,  1.0143e+00,  9.4384e-01,\n",
      "          -5.5562e-01,  3.1084e-01,  1.2927e+00, -9.0976e-01, -8.7553e-01,\n",
      "           0.0000e+00,  4.7764e-01, -5.8434e-01, -5.8195e-01,  1.9755e+00,\n",
      "           1.2964e+00,  4.6948e-01, -1.7258e-01, -2.3660e-01,  1.6408e+00,\n",
      "           1.2561e+00,  1.2899e+00,  9.6147e-01,  8.5182e-02,  7.2050e-01,\n",
      "           3.6007e-01, -7.9577e-01, -5.9437e-01, -1.5286e-01, -2.4447e-02,\n",
      "          -1.8403e-01,  2.6650e+00,  7.3412e-01, -1.4364e+00, -4.1319e-01,\n",
      "           1.6955e+00,  6.5975e-01,  5.3081e-01,  0.0000e+00,  1.6058e+00,\n",
      "          -5.9996e-01,  0.0000e+00,  1.2386e+00,  1.9853e+00, -1.5117e+00,\n",
      "           7.6494e-01, -1.1522e+00, -1.9401e+00, -1.1493e+00, -4.9240e-01,\n",
      "           6.4125e-01, -4.5066e-01, -3.8291e-01,  0.0000e+00, -1.4108e+00,\n",
      "           2.0436e+00,  2.3141e-03,  1.0068e+00, -7.9750e-02,  7.9198e-01,\n",
      "          -1.7513e+00, -6.3999e-01,  4.5131e-01,  0.0000e+00, -1.4609e+00,\n",
      "           1.0040e+00,  1.4011e+00, -5.2050e-01, -6.7440e-01, -1.6630e+00,\n",
      "          -7.0023e-03, -5.2443e-01,  0.0000e+00, -6.0028e-01,  1.0075e+00,\n",
      "          -4.4396e-01,  0.0000e+00, -1.4927e+00, -3.0599e-01, -6.1994e-01,\n",
      "           3.2481e-01, -1.3933e+00,  0.0000e+00, -6.7614e-01,  4.6634e-01,\n",
      "          -1.2859e+00,  5.9067e-01, -2.1420e-01, -6.4993e-01, -4.3013e-01,\n",
      "          -6.3344e-01,  1.1437e-01,  5.7964e-01,  1.0274e+00,  6.3354e-01,\n",
      "          -5.8570e-01,  4.9652e-02,  1.4238e+00,  0.0000e+00,  1.0773e+00,\n",
      "           2.7709e-02,  9.1281e-01,  4.3570e-02,  2.9005e-01,  1.2342e-01,\n",
      "          -1.4006e+00, -9.1245e-02, -3.3550e-01,  2.3086e+00, -7.1192e-01,\n",
      "           1.9715e-01,  0.0000e+00,  2.3151e-01, -9.2854e-01,  6.9644e-01,\n",
      "           0.0000e+00, -2.2728e+00, -4.9835e-01,  0.0000e+00, -1.1469e+00,\n",
      "           1.0637e+00,  2.8875e-01,  4.8779e-01,  1.2242e+00,  9.5716e-01,\n",
      "          -2.7758e+00, -4.9597e-01, -9.0553e-01,  3.0494e-01,  7.8283e-02,\n",
      "           9.0527e-01, -6.3852e-01, -2.1795e-01, -1.3967e+00,  0.0000e+00,\n",
      "           1.0597e+00, -8.4911e-02,  6.8611e-01,  3.5702e-03, -2.3202e-01,\n",
      "          -8.2570e-01, -3.6402e-01,  1.9974e+00,  1.0622e+00, -9.3119e-01,\n",
      "           0.0000e+00,  1.3469e+00,  0.0000e+00, -8.1142e-01,  9.3780e-01,\n",
      "           0.0000e+00, -2.2558e+00, -2.8188e-01,  6.8067e-01,  1.6867e+00,\n",
      "           4.2937e-01,  0.0000e+00,  8.8951e-01,  2.8451e-01, -3.1978e-01,\n",
      "           0.0000e+00,  6.9542e-01, -1.1153e+00, -1.2618e+00,  1.8751e+00,\n",
      "          -1.1382e+00, -9.9776e-01, -1.6456e+00,  0.0000e+00, -8.8905e-01,\n",
      "           2.5391e+00, -5.0115e-01,  9.3758e-01, -9.0694e-01,  9.5295e-01,\n",
      "          -2.7947e-01, -1.5584e+00, -2.4189e-01,  3.2016e-01, -8.2365e-01,\n",
      "           2.1437e+00,  8.0677e-01, -8.0283e-01,  3.1924e-01,  0.0000e+00,\n",
      "          -2.3326e+00, -7.5090e-01, -1.0747e+00,  1.1961e+00,  9.3323e-01,\n",
      "           0.0000e+00,  1.8051e+00,  3.6486e-01, -1.8720e+00,  1.2918e+00,\n",
      "          -7.8272e-02,  5.8345e-02,  0.0000e+00,  2.0089e+00,  4.7254e-01,\n",
      "           1.0873e+00,  1.9475e+00,  3.3251e-01, -7.4911e-02,  1.4110e-01,\n",
      "           2.1635e-01, -8.3317e-01,  0.0000e+00, -1.6011e+00,  1.8089e+00,\n",
      "          -5.6107e-01,  7.8974e-02, -6.8357e-01, -1.0923e+00,  1.0381e+00,\n",
      "           9.8337e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0523, 0.1071, 0.1321, 0.0927, 0.0819, 0.0495, 0.1944, 0.1127, 0.0672,\n",
      "         0.1100]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0384,  0.4024,  0.0009,  ...,  0.1362,  0.0986, -0.2318],\n",
      "        [ 0.1874,  0.2793, -0.2952,  ..., -0.1547,  0.2130, -0.2739],\n",
      "        [ 0.1570,  0.5368, -0.3115,  ...,  0.1943, -0.0045, -0.1805],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1311,  0.1756, -0.1843,  0.1371, -0.0716,  0.0205, -0.0170,\n",
      "          -0.0568,  0.2150, -0.1389,  0.0324, -0.0592, -0.3279, -0.0448,\n",
      "           0.0394, -0.0067,  0.1903, -0.0029,  0.0160,  0.0566,  0.0121,\n",
      "          -0.1399,  0.1063, -0.0741, -0.1514, -0.0833,  0.1449, -0.1731,\n",
      "          -0.0234,  0.0138,  0.0632, -0.1759, -0.0413, -0.0694,  0.1752,\n",
      "          -0.0076, -0.1763, -0.1165, -0.2471, -0.0876, -0.2149,  0.0685,\n",
      "          -0.1104,  0.0263,  0.0757, -0.0093,  0.0784, -0.0581,  0.1506,\n",
      "           0.1252, -0.0690,  0.0344, -0.2761, -0.0955, -0.1675,  0.0271,\n",
      "          -0.1553, -0.2104, -0.0563,  0.0335, -0.1124,  0.0549,  0.0783,\n",
      "          -0.0481,  0.1796,  0.0754,  0.0847,  0.0962, -0.0697,  0.1364,\n",
      "           0.1155, -0.0378,  0.0184,  0.0815, -0.0454, -0.1686,  0.0523,\n",
      "          -0.0068, -0.0651,  0.1178, -0.0160, -0.0217, -0.0559, -0.1089,\n",
      "           0.0579, -0.0281, -0.0765,  0.0107, -0.0879,  0.0338,  0.0747,\n",
      "          -0.0409, -0.0297, -0.1955, -0.0184,  0.0482,  0.1395,  0.1554,\n",
      "           0.2263,  0.1874, -0.2491, -0.0927,  0.1182, -0.0634, -0.1225,\n",
      "          -0.0415,  0.2135,  0.0702,  0.0929,  0.0669,  0.0014,  0.1790,\n",
      "          -0.1364, -0.1823, -0.0798,  0.0632,  0.0142, -0.0689,  0.0037,\n",
      "          -0.0287,  0.0612,  0.0650,  0.0367,  0.0344, -0.1088,  0.2288,\n",
      "           0.1134,  0.0466,  0.0195,  0.0856,  0.0495, -0.0432, -0.0079,\n",
      "          -0.0770,  0.0100,  0.0963,  0.2430,  0.0416,  0.1063, -0.1223,\n",
      "           0.0843,  0.1890, -0.1323,  0.2093,  0.0844, -0.1356,  0.0558,\n",
      "           0.1789,  0.1489,  0.0702, -0.1270, -0.0991, -0.2188,  0.1769,\n",
      "          -0.0861,  0.1243, -0.0279,  0.1421, -0.1772, -0.2299, -0.0946,\n",
      "          -0.1369, -0.1839,  0.1243, -0.1019, -0.0998, -0.0882, -0.2368,\n",
      "           0.0731,  0.1321, -0.1107,  0.1359,  0.2128, -0.2559,  0.0525,\n",
      "          -0.1604,  0.0205, -0.0121,  0.2749,  0.0101, -0.2541, -0.1412,\n",
      "          -0.0324, -0.0031, -0.1054, -0.1870, -0.1265, -0.0972, -0.1033,\n",
      "          -0.0662,  0.0963,  0.0553, -0.1427, -0.1470,  0.1943, -0.1040,\n",
      "           0.1323, -0.0062,  0.1775,  0.0341, -0.1111,  0.0851, -0.1031,\n",
      "           0.0117,  0.0952,  0.0217, -0.0721,  0.1610, -0.0692, -0.0797,\n",
      "          -0.2559, -0.1097,  0.0995, -0.0164, -0.0364,  0.1633, -0.0669,\n",
      "           0.0225, -0.0655,  0.0817,  0.0790, -0.0115,  0.0889, -0.0181,\n",
      "           0.0082, -0.0889,  0.1897, -0.0917, -0.2103,  0.1460,  0.0056,\n",
      "          -0.0085,  0.0727, -0.1097, -0.0052,  0.0676, -0.1073,  0.0704,\n",
      "           0.1832,  0.0868, -0.1374, -0.0960, -0.0626,  0.0743,  0.1305,\n",
      "          -0.0112, -0.1765, -0.1223,  0.2009,  0.0438,  0.2063, -0.0436,\n",
      "          -0.1871,  0.0250,  0.0894, -0.1421]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7284e-01, -4.3056e-01,  3.1479e-01,  0.0000e+00, -1.1724e+00,\n",
      "           0.0000e+00, -1.9141e+00,  1.3513e+00,  1.9061e-01,  6.1738e-01,\n",
      "           1.9024e+00,  6.0240e-01,  2.2863e-01,  0.0000e+00, -3.1815e+00,\n",
      "          -6.8682e-02,  0.0000e+00, -9.4335e-01,  1.3610e+00,  0.0000e+00,\n",
      "           0.0000e+00, -5.2307e-01, -1.1193e+00, -2.5946e+00, -7.5315e-02,\n",
      "           1.3912e+00, -6.1908e-01,  1.9965e+00,  1.2767e-01,  0.0000e+00,\n",
      "           9.1436e-01, -3.4778e-03,  2.2320e-01,  2.0150e+00, -6.4055e-02,\n",
      "          -1.4084e+00, -1.1202e-01, -8.1810e-01,  3.1461e-01,  8.5203e-02,\n",
      "           8.6169e-01, -9.0028e-01,  1.0091e+00,  0.0000e+00,  1.9436e+00,\n",
      "          -2.9999e-01,  7.0426e-01, -6.0091e-01, -1.0204e+00,  1.1161e+00,\n",
      "          -1.3217e+00,  2.6763e+00,  6.6662e-01, -8.4645e-01,  2.2739e-01,\n",
      "          -3.0871e-01, -1.4345e+00, -9.6823e-02,  1.2745e+00,  0.0000e+00,\n",
      "          -1.0063e+00,  3.6139e-02, -2.8030e-01,  0.0000e+00, -6.2588e-02,\n",
      "           3.9461e-01,  5.7808e-01,  1.1647e+00,  1.5803e+00, -1.4151e+00,\n",
      "           4.2764e-01,  2.9646e-01, -3.1376e-02, -7.9776e-01, -2.1462e-01,\n",
      "           1.3921e-01,  5.2556e-01,  1.3986e+00,  1.0269e+00,  0.0000e+00,\n",
      "           7.5716e-01, -1.0062e+00,  7.5679e-01,  1.0587e+00, -1.2140e+00,\n",
      "          -1.1311e-01, -1.1073e+00,  0.0000e+00, -9.4472e-01, -1.9015e+00,\n",
      "           5.2891e-01,  9.8627e-01,  1.7014e+00,  9.4321e-01,  6.0837e-01,\n",
      "          -1.5834e-02,  3.5266e-01, -1.1753e+00,  1.3709e+00,  2.4476e+00,\n",
      "           2.4401e-01,  4.6320e-02, -4.6608e-01, -9.8940e-01,  1.6393e+00,\n",
      "          -1.0221e+00,  3.0282e+00,  0.0000e+00, -1.0215e-01, -1.2353e+00,\n",
      "           1.8977e-01,  0.0000e+00,  0.0000e+00,  7.1222e-01, -7.8032e-01,\n",
      "           6.3167e-01,  4.0423e-01,  2.2413e-01, -2.3273e+00,  2.9378e-02,\n",
      "          -8.1325e-01, -1.4099e+00, -1.8368e+00,  6.0345e-01, -9.5606e-01,\n",
      "          -1.9981e-01,  3.9025e-02,  0.0000e+00,  1.3963e+00, -2.0873e+00,\n",
      "          -9.2653e-01,  4.4936e-01, -1.1669e+00,  4.2504e-01, -4.6893e-01,\n",
      "          -7.4408e-01, -1.0649e+00, -9.7455e-01, -1.9442e-02,  0.0000e+00,\n",
      "           0.0000e+00, -1.1217e+00,  1.6915e+00, -1.4003e-01, -6.6918e-01,\n",
      "           3.4326e-02,  7.5927e-01,  4.2311e-01,  0.0000e+00, -9.5686e-02,\n",
      "           1.5602e+00,  5.8701e-01, -3.3916e-01,  6.5750e-01,  1.8405e+00,\n",
      "          -2.5230e-01,  0.0000e+00,  6.2320e-01,  0.0000e+00,  1.0554e+00,\n",
      "           3.0222e-01, -7.7657e-02,  1.5395e-01, -1.2114e+00, -2.2107e-02,\n",
      "           1.6816e+00,  1.8513e+00,  2.7036e-01, -1.2701e+00, -7.1360e-01,\n",
      "          -1.2242e+00, -1.0938e+00, -2.5899e+00,  5.0538e-01, -3.0576e+00,\n",
      "          -2.8690e-01,  4.9849e-01,  0.0000e+00,  3.1703e-01, -7.9276e-01,\n",
      "           2.7085e-01,  2.3396e+00,  0.0000e+00,  8.3814e-01, -4.0326e-01,\n",
      "           7.2668e-01,  5.9911e-01,  3.5918e-01,  8.4179e-01, -1.8294e+00,\n",
      "           1.3636e+00,  2.1587e+00,  3.3738e-01, -1.0150e+00, -1.1709e+00,\n",
      "          -2.2147e+00,  0.0000e+00,  2.1521e+00,  3.6326e-01,  2.3835e+00,\n",
      "           3.2323e-02, -5.0151e-01, -1.2757e+00, -5.4226e-01, -4.0737e-01,\n",
      "          -1.4464e+00,  9.5397e-01, -8.5143e-01,  8.3128e-01,  0.0000e+00,\n",
      "           6.3600e-01,  6.7648e-01,  2.3968e+00,  0.0000e+00,  1.8943e+00,\n",
      "           1.3072e+00,  5.8091e-01, -2.3167e+00,  1.5503e+00, -2.2246e-01,\n",
      "          -2.2714e-01,  1.7329e+00,  2.7727e-01, -1.5521e+00,  9.2260e-01,\n",
      "          -1.2246e+00, -8.4758e-01, -1.8008e+00, -8.2872e-05,  3.7348e-01,\n",
      "          -1.5731e+00, -1.2326e-01,  9.6639e-01,  0.0000e+00,  1.6937e+00,\n",
      "          -1.4405e+00,  6.3403e-01, -1.7214e+00,  9.8056e-01, -1.7148e+00,\n",
      "           1.5598e+00, -2.7186e-01, -2.5964e+00,  1.2381e+00, -1.2288e+00,\n",
      "           1.8833e+00,  0.0000e+00,  5.4292e-01, -2.6159e-01, -1.0212e+00,\n",
      "           1.3329e+00,  3.0977e-01, -5.1662e-02,  0.0000e+00, -1.6110e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0628, 0.1252, 0.1255, 0.0743, 0.1628, 0.0922, 0.1239, 0.0683, 0.0841,\n",
      "         0.0808]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0384,  0.4024,  0.0009,  ...,  0.1362,  0.0986, -0.2318],\n",
      "        [ 0.1874,  0.2793, -0.2952,  ..., -0.1547,  0.2130, -0.2739],\n",
      "        [ 0.1570,  0.5368, -0.3115,  ...,  0.1943, -0.0045, -0.1805],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1549,  0.1576, -0.1249,  0.1543, -0.0502,  0.0301, -0.0166,\n",
      "          -0.0225,  0.2062, -0.1485,  0.0019, -0.0541, -0.3484, -0.0523,\n",
      "           0.0569,  0.0033,  0.2247,  0.0266,  0.0416,  0.0852, -0.0047,\n",
      "          -0.1521,  0.1265, -0.0654, -0.1698, -0.1120,  0.2076, -0.1923,\n",
      "          -0.0372,  0.0017,  0.0561, -0.2194, -0.0554, -0.0538,  0.1680,\n",
      "          -0.0501, -0.1710, -0.1203, -0.2412, -0.0862, -0.2353,  0.0655,\n",
      "          -0.0943,  0.0233,  0.0350, -0.0131,  0.1027, -0.0775,  0.1347,\n",
      "           0.1572, -0.0935,  0.0429, -0.2665, -0.0737, -0.1872,  0.0068,\n",
      "          -0.1497, -0.2701, -0.0874,  0.0126, -0.1191,  0.0509,  0.0841,\n",
      "          -0.0589,  0.1788,  0.0619,  0.1079,  0.0916, -0.0612,  0.1500,\n",
      "           0.1598, -0.0523,  0.0393,  0.0578, -0.0204, -0.1799,  0.0951,\n",
      "          -0.0259, -0.0724,  0.0961,  0.0173,  0.0020, -0.0201, -0.0968,\n",
      "           0.0888, -0.0288, -0.0759,  0.0441, -0.0797,  0.0532,  0.0713,\n",
      "          -0.0463, -0.0696, -0.2382, -0.0146,  0.0528,  0.1688,  0.1401,\n",
      "           0.2567,  0.1694, -0.2446, -0.0847,  0.0910, -0.1068, -0.0904,\n",
      "          -0.0371,  0.2028,  0.0675,  0.1176,  0.0726, -0.0068,  0.2269,\n",
      "          -0.1813, -0.1594, -0.0893,  0.1073,  0.0282, -0.0740,  0.0272,\n",
      "          -0.0051,  0.0583,  0.0948,  0.0619,  0.0156, -0.1064,  0.2458,\n",
      "           0.0948,  0.0514,  0.0030,  0.0961,  0.0671, -0.0691, -0.0067,\n",
      "          -0.0815,  0.0122,  0.0980,  0.2188,  0.0407,  0.1232, -0.1218,\n",
      "           0.0956,  0.1769, -0.1718,  0.2052,  0.0583, -0.1145,  0.0528,\n",
      "           0.1824,  0.1667,  0.0834, -0.1124, -0.0718, -0.2485,  0.1741,\n",
      "          -0.0933,  0.1368, -0.0103,  0.1564, -0.2074, -0.2419, -0.1103,\n",
      "          -0.1631, -0.1691,  0.0961, -0.1471, -0.1473, -0.1030, -0.2343,\n",
      "           0.0295,  0.1152, -0.0821,  0.1281,  0.2295, -0.2664,  0.0709,\n",
      "          -0.1583, -0.0032, -0.0495,  0.2399,  0.0268, -0.2542, -0.1468,\n",
      "          -0.0237, -0.0313, -0.1362, -0.2153, -0.1084, -0.1580, -0.1396,\n",
      "          -0.0729,  0.1234,  0.0516, -0.1088, -0.1650,  0.1891, -0.0886,\n",
      "           0.1403, -0.0185,  0.1679,  0.0255, -0.1073,  0.0592, -0.1496,\n",
      "          -0.0021,  0.1008, -0.0020, -0.0525,  0.1244, -0.0541, -0.1050,\n",
      "          -0.2853, -0.0773,  0.0914, -0.0027, -0.0667,  0.1140, -0.0680,\n",
      "           0.0169, -0.0645,  0.0907,  0.0603, -0.0069,  0.0666,  0.0488,\n",
      "          -0.0254, -0.0951,  0.2032, -0.0992, -0.2106,  0.1478,  0.0529,\n",
      "          -0.0166,  0.0900, -0.0490,  0.0230,  0.1138, -0.1134,  0.0769,\n",
      "           0.2041,  0.0969, -0.1364, -0.0807, -0.0267,  0.1036,  0.1581,\n",
      "           0.0076, -0.1792, -0.1258,  0.2230,  0.0293,  0.2185, -0.0578,\n",
      "          -0.1961,  0.0298,  0.0958, -0.1692]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.7153e-02,  0.0000e+00, -9.6453e-01, -6.8083e-01,  3.7527e-01,\n",
      "          -2.0185e-01,  1.4644e+00, -8.3720e-02, -3.5829e+00,  9.0696e-01,\n",
      "           4.2782e-01, -6.2933e-01,  0.0000e+00, -6.3062e-01, -5.4141e-01,\n",
      "          -1.5815e-01,  8.5154e-01,  1.0940e+00,  4.5521e-01,  4.3616e-01,\n",
      "          -6.3306e-01, -3.8214e-01,  0.0000e+00,  1.5112e+00,  7.5310e-01,\n",
      "          -7.6007e-02, -1.8858e-01, -7.6029e-01,  1.6532e+00,  8.6128e-01,\n",
      "           1.2313e+00,  1.2194e+00,  0.0000e+00, -8.3131e-02, -1.5340e+00,\n",
      "           1.3955e+00,  2.8048e-01, -3.7439e+00,  1.9765e-01,  1.5998e+00,\n",
      "          -4.5899e-01, -1.3979e+00, -2.6927e-01, -1.7138e+00, -1.5231e+00,\n",
      "           6.6813e-01,  5.4032e-01,  3.7145e-01, -1.3402e+00,  1.4477e-01,\n",
      "          -6.2929e-01,  2.7501e+00,  6.1010e-01, -1.0283e+00,  0.0000e+00,\n",
      "           2.0441e-01, -8.8097e-01, -1.2505e+00, -2.3752e-01, -4.2651e-01,\n",
      "           1.0984e+00,  1.4067e+00, -2.0199e-01, -5.0086e-01, -2.9617e+00,\n",
      "           5.5180e-01,  0.0000e+00, -1.2871e+00,  4.0947e-01,  5.2674e-01,\n",
      "          -1.2661e+00, -2.9395e-02,  7.0723e-01, -3.6389e+00,  3.2470e-01,\n",
      "          -3.7095e-04, -1.6017e-01,  1.0609e+00, -5.7160e-02, -1.1738e-01,\n",
      "          -1.3993e+00,  0.0000e+00,  0.0000e+00,  1.0059e+00, -2.0753e-01,\n",
      "           4.3672e-01,  1.6610e+00,  0.0000e+00, -1.0472e-01, -5.8100e-01,\n",
      "          -2.2719e+00,  1.0995e+00, -6.2238e-01, -1.1358e+00,  4.6671e-01,\n",
      "          -1.1696e+00,  3.2241e-02,  6.2874e-01,  1.7190e+00, -7.7764e-01,\n",
      "           2.6964e+00, -1.4611e+00,  0.0000e+00,  1.4522e+00, -6.6584e-01,\n",
      "          -7.6209e-01,  1.2105e+00,  1.2750e-01, -1.4729e+00, -1.4175e-02,\n",
      "          -2.4779e-01,  1.3378e-01, -1.0469e+00,  1.3101e+00, -1.6522e+00,\n",
      "          -2.9873e+00, -5.7065e-02, -4.9887e-01, -1.9343e-01,  4.4581e-01,\n",
      "          -1.4643e+00,  7.0176e-01, -1.4599e+00, -7.2559e-01, -9.5730e-01,\n",
      "          -1.3068e+00,  0.0000e+00,  1.6939e-01,  1.2842e+00, -7.5056e-01,\n",
      "          -8.2445e-01,  0.0000e+00, -1.5823e+00,  9.8389e-01,  2.7637e-01,\n",
      "          -5.8899e-01,  6.5796e-01,  5.7594e-01, -1.1594e+00, -1.0090e+00,\n",
      "          -3.8771e-01,  6.7769e-01, -7.8891e-01, -1.0034e-01, -1.6843e+00,\n",
      "          -9.9869e-02, -5.4258e-01, -8.4413e-01, -7.5453e-01,  1.7777e-01,\n",
      "           1.9971e+00, -1.9912e-01, -1.9292e+00, -4.0635e-01,  0.0000e+00,\n",
      "          -1.9457e-01, -6.5130e-02, -1.3083e-01,  3.8756e-02,  5.3728e-01,\n",
      "          -2.6735e-02,  2.2061e+00,  0.0000e+00,  0.0000e+00, -5.2542e-01,\n",
      "          -8.9061e-01,  2.8176e-01,  8.2530e-02, -3.5824e-01,  0.0000e+00,\n",
      "           7.3570e-01, -3.0225e-02,  2.0110e-02, -1.0033e+00,  1.2774e+00,\n",
      "          -1.0974e+00, -9.8538e-01, -2.0746e+00,  1.9677e+00,  8.6240e-02,\n",
      "          -3.1208e-02,  0.0000e+00,  6.7051e-01,  9.7994e-01, -7.4800e-01,\n",
      "          -3.4112e-01, -2.7810e+00, -7.8240e-01,  1.2088e+00,  1.0126e+00,\n",
      "           3.0718e+00,  4.9384e-01,  0.0000e+00, -5.9259e-01,  5.5953e-01,\n",
      "           0.0000e+00, -1.1872e+00,  5.3492e-01,  1.8108e+00, -9.4576e-01,\n",
      "          -1.6626e+00,  0.0000e+00,  0.0000e+00, -1.2212e-01,  2.3209e-01,\n",
      "          -5.7451e-01,  0.0000e+00,  6.8177e-01, -1.0724e+00, -4.7133e-01,\n",
      "           2.8670e+00, -5.7310e-01, -3.4144e-01,  7.9246e-01,  3.2537e-02,\n",
      "          -6.8289e-01, -1.0165e+00,  9.6702e-01, -2.4516e-01,  2.1682e+00,\n",
      "          -1.0827e+00, -4.2676e-01, -1.8431e+00, -4.9994e-01,  3.4010e-01,\n",
      "           0.0000e+00, -6.9667e-01, -6.2811e-01,  2.9227e-01, -1.5772e+00,\n",
      "          -1.1079e+00,  1.5811e+00,  0.0000e+00,  1.3103e+00, -2.9786e+00,\n",
      "           4.0330e+00,  5.8499e-01,  4.2654e-02, -1.5777e+00, -2.8575e-01,\n",
      "           7.4209e-01, -3.2458e+00, -3.0335e-01, -8.5139e-01,  0.0000e+00,\n",
      "           2.7588e-01,  2.7472e-01,  2.5199e-01,  2.6152e-01,  3.8690e-01,\n",
      "          -3.6585e-01, -1.5989e-01, -5.5308e-01, -5.1738e-02, -1.1461e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0535, 0.0597, 0.1052, 0.0616, 0.1208, 0.2263, 0.0801, 0.0967, 0.0710,\n",
      "         0.1250]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1097, -0.0178, -0.4476,  0.2117, -0.2604, -0.1983, -0.0865,\n",
      "          -0.1110,  0.1931,  0.1112,  0.0765,  0.0291, -0.2350,  0.1796,\n",
      "           0.0423,  0.0399, -0.1112,  0.0886,  0.1463,  0.1989, -0.1637,\n",
      "           0.0462,  0.1134,  0.0163, -0.0267,  0.1650, -0.0934, -0.1441,\n",
      "          -0.2239,  0.1157,  0.2445, -0.1995,  0.1156, -0.1567,  0.2895,\n",
      "           0.0472, -0.0638, -0.0279,  0.1229, -0.0728, -0.1246, -0.0550,\n",
      "           0.0275,  0.1049, -0.0879, -0.0252,  0.1095, -0.2122,  0.0579,\n",
      "           0.0723,  0.0661,  0.1616, -0.3868, -0.5027, -0.1731,  0.1009,\n",
      "           0.0706, -0.2728, -0.0783, -0.0616, -0.1751, -0.1756,  0.1444,\n",
      "          -0.3124,  0.0884, -0.1072,  0.0632, -0.1529, -0.1750, -0.1347,\n",
      "           0.2152, -0.0217,  0.1056,  0.1421,  0.2266, -0.0702,  0.1547,\n",
      "           0.0168, -0.1155,  0.1209,  0.0469,  0.0729, -0.2215,  0.1600,\n",
      "          -0.1076, -0.0125, -0.1418,  0.1181, -0.2024,  0.0798,  0.0410,\n",
      "          -0.0689,  0.1167, -0.0759, -0.0038, -0.0152,  0.0433,  0.2458,\n",
      "           0.1280,  0.3159, -0.1399, -0.1375,  0.3577,  0.1900,  0.1631,\n",
      "          -0.1019,  0.2540,  0.1102,  0.1960, -0.1052,  0.2480,  0.0937,\n",
      "           0.0219,  0.2390, -0.0985, -0.0547, -0.1007, -0.0750,  0.0695,\n",
      "           0.1650,  0.0925, -0.1123, -0.0523, -0.0122,  0.0330, -0.0342,\n",
      "          -0.0497, -0.1855,  0.2071,  0.0601,  0.2631,  0.0652,  0.0459,\n",
      "           0.0794,  0.0083,  0.0359,  0.0543,  0.0720,  0.0819, -0.1463,\n",
      "           0.0236,  0.0827, -0.3701,  0.2625,  0.2160,  0.0143,  0.1070,\n",
      "           0.2901,  0.1141,  0.2941, -0.0570,  0.1109, -0.1506,  0.3199,\n",
      "          -0.0479,  0.2973,  0.0680, -0.0973, -0.0029,  0.1885, -0.2359,\n",
      "          -0.1872, -0.1989, -0.0072, -0.1516, -0.1021, -0.1171, -0.3402,\n",
      "           0.4075,  0.1124, -0.1557,  0.2656,  0.1458, -0.0441,  0.0265,\n",
      "          -0.0324,  0.0302, -0.1931,  0.3981, -0.1632, -0.2109, -0.0655,\n",
      "          -0.0207, -0.0050,  0.1454, -0.1624, -0.2625, -0.0062,  0.0242,\n",
      "          -0.3854,  0.0164, -0.0633, -0.1238, -0.0376,  0.1460, -0.0609,\n",
      "           0.2248, -0.2422,  0.1543, -0.0567, -0.1251, -0.1370, -0.0508,\n",
      "           0.0940, -0.1220, -0.0390, -0.0827,  0.2812,  0.1821, -0.0615,\n",
      "          -0.0179,  0.2075,  0.0450,  0.0629, -0.1628,  0.1200,  0.1039,\n",
      "          -0.0796,  0.1339,  0.0258,  0.2991,  0.0785,  0.1468, -0.3147,\n",
      "          -0.0294, -0.1097,  0.0675,  0.0327, -0.2581,  0.1118, -0.0616,\n",
      "          -0.1366,  0.0242, -0.1083,  0.0207, -0.0208, -0.0606,  0.2750,\n",
      "           0.2903,  0.1429, -0.0546,  0.2622,  0.0031,  0.0986,  0.0212,\n",
      "          -0.2045, -0.1576,  0.1116, -0.0806, -0.1327,  0.3625,  0.1383,\n",
      "          -0.1981,  0.0132,  0.0977, -0.0340]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4729, -0.4587, -1.2333, -0.1185,  0.4614,  0.0259,  0.6619,\n",
      "           0.5339,  0.6709,  0.9340,  1.7075, -1.0164,  0.0000, -0.2518,\n",
      "          -1.6338,  0.5121,  1.8776, -0.7568, -1.5631, -2.6432, -1.1334,\n",
      "           0.1684,  2.9292,  0.5544, -0.1170,  3.2087,  1.8371,  0.5186,\n",
      "          -2.2265, -1.2860,  0.0288,  1.0130,  0.3249,  0.8595, -0.7987,\n",
      "          -1.4655,  0.6197, -0.7715,  1.9913,  0.0000,  0.4672, -2.2045,\n",
      "           0.0000,  0.0000, -0.7131, -0.6889,  1.9271,  0.0000, -0.2869,\n",
      "          -1.8504,  1.4677,  0.0000,  0.6674, -0.2832,  0.5316,  0.2749,\n",
      "          -1.2428, -0.9508,  1.8137,  0.0000,  0.2052, -1.8186, -1.4011,\n",
      "          -0.8062,  1.1798,  0.2654,  0.0000, -0.2548, -0.0048,  0.0000,\n",
      "          -0.3250,  0.0000,  0.1474, -0.1263,  0.6585, -0.8063,  2.0664,\n",
      "           0.0000,  0.0878, -0.5455,  1.2268,  0.0862,  0.3267, -1.8363,\n",
      "          -0.0710, -1.7317, -1.4584, -0.8914,  0.6229,  0.8108, -1.2238,\n",
      "           0.0000,  1.9849, -0.3662, -0.7341,  0.1564,  2.1408, -0.4057,\n",
      "          -0.3040, -1.8392, -1.2905,  0.0000, -0.7663,  0.0000,  0.0000,\n",
      "           1.1138, -1.0706,  2.2523, -0.2628, -0.2883, -0.0533,  0.6104,\n",
      "           0.0000, -0.2804, -1.9418,  1.1285,  0.0000, -2.4970, -0.5752,\n",
      "           0.0000, -1.6943, -0.4008, -0.3790, -0.0783,  0.0000, -1.1105,\n",
      "           1.3041,  0.1695,  0.3221,  1.3583,  2.0787, -2.6340,  0.3599,\n",
      "          -0.7230,  0.4292,  0.0603,  0.3265, -2.1012, -0.4969, -1.6773,\n",
      "          -0.6418,  0.2343,  0.0000, -1.2146, -0.6308, -0.0404,  0.4648,\n",
      "           1.7382,  1.5948,  0.0000, -1.2625, -0.5773,  0.0000, -0.0395,\n",
      "           0.3265, -0.1171,  1.3536, -0.0318, -1.9003, -1.8063, -1.4265,\n",
      "          -0.9003, -0.7060,  0.0000, -0.9807, -0.1289,  0.4064,  0.9701,\n",
      "           0.5179, -0.1475,  1.5129, -0.3729, -0.3158, -2.0086,  0.1299,\n",
      "          -0.3526, -0.8299, -0.7687, -0.0404, -0.9374,  0.7277,  1.0417,\n",
      "           0.0469,  0.0000,  0.3160, -0.1183, -0.5407,  0.0000,  0.7547,\n",
      "          -1.0640, -0.5870, -1.7884,  1.2674, -0.9263, -1.6147, -0.3332,\n",
      "           0.0000, -1.9606, -0.0721, -0.3749,  2.6970, -0.9217, -2.6311,\n",
      "          -0.5862, -0.7157, -1.3862, -1.2539,  0.1718,  0.2190, -1.1106,\n",
      "           0.9447, -0.6922, -1.5191,  0.3621,  0.2379, -1.4262, -2.3444,\n",
      "           0.0478, -1.4794,  0.4270,  0.0131, -0.9015,  0.3011, -1.1654,\n",
      "          -1.3006, -0.1877,  1.2720,  0.0000, -2.1878, -0.0560,  1.7376,\n",
      "          -1.1751,  0.0000,  1.9994,  0.0000,  0.7885, -0.6785,  0.1043,\n",
      "          -0.6804,  0.0000,  0.1673,  0.0000, -1.0431, -0.3819, -1.0798,\n",
      "           0.5577,  1.4993, -0.5644, -1.3767,  1.2435,  0.5827,  1.7529,\n",
      "           1.9517,  0.3627,  0.4874,  0.3900]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0308, 0.1914, 0.1070, 0.0559, 0.1395, 0.1001, 0.0405, 0.1909, 0.0770,\n",
      "         0.0670]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.3189e-01, -6.3215e-02, -3.6687e-01,  1.3786e-01, -2.1785e-01,\n",
      "          -2.7701e-01, -9.0962e-02, -1.0686e-01,  2.3280e-01,  7.0848e-02,\n",
      "           6.7810e-02,  1.1817e-01, -2.4020e-01,  2.9503e-01,  6.0513e-02,\n",
      "           8.9512e-02, -1.2439e-01,  1.4044e-01,  2.1095e-01,  2.3433e-01,\n",
      "          -2.5532e-01,  3.8531e-02,  1.9731e-01,  2.3292e-03, -2.2872e-02,\n",
      "           9.8344e-02, -3.6949e-02, -1.2502e-01, -1.9947e-01,  4.7410e-02,\n",
      "           1.9919e-01, -1.4046e-01,  1.0853e-01, -1.0230e-01,  2.5743e-01,\n",
      "           9.3532e-02, -1.7989e-02, -4.6142e-02,  1.1844e-01, -6.1136e-02,\n",
      "          -1.2236e-01, -6.2273e-02,  3.9595e-02,  7.2309e-02, -5.2866e-02,\n",
      "          -1.1133e-02,  1.5209e-01, -1.5882e-01,  1.5476e-01,  1.3099e-01,\n",
      "           7.8969e-02,  2.2011e-01, -3.7550e-01, -4.6877e-01, -1.0762e-01,\n",
      "           9.5175e-02,  1.1643e-01, -2.8269e-01, -1.1249e-01, -2.8379e-02,\n",
      "          -1.5819e-01, -2.4976e-01,  1.9884e-01, -2.6326e-01,  9.3046e-02,\n",
      "           5.4575e-03,  4.2900e-02, -1.8058e-01, -2.0066e-01, -1.4858e-01,\n",
      "           2.2276e-01, -2.4388e-02,  1.1268e-01,  1.7096e-01,  3.1692e-01,\n",
      "          -1.0132e-01,  1.0633e-01, -7.2627e-02, -1.2306e-01,  1.0326e-01,\n",
      "           4.9799e-02,  1.0699e-01, -1.3758e-01,  6.2596e-02, -9.0320e-02,\n",
      "          -4.8888e-02, -8.4666e-02,  8.2069e-02, -2.1605e-01,  8.1299e-02,\n",
      "           1.0512e-01, -1.0610e-01,  1.6319e-01, -8.6050e-02, -5.6652e-02,\n",
      "          -3.6958e-02,  3.5467e-02,  2.1650e-01,  1.3003e-01,  2.0066e-01,\n",
      "          -8.2499e-02, -2.0486e-02,  3.6998e-01,  1.0358e-01,  1.7702e-01,\n",
      "          -2.9311e-02,  2.6588e-01,  4.5798e-02,  1.5553e-01, -1.2580e-01,\n",
      "           2.5882e-01,  4.8888e-02, -7.2353e-03,  2.8499e-01, -1.2694e-01,\n",
      "          -5.6908e-02, -6.0737e-02, -1.4692e-01,  1.7544e-01,  1.6462e-01,\n",
      "           8.3195e-02, -8.2024e-02, -3.6598e-02, -1.9894e-02,  5.4457e-02,\n",
      "           9.9754e-04,  6.6116e-03, -1.8654e-01,  2.2389e-01,  7.5886e-02,\n",
      "           2.0266e-01,  5.5453e-02, -2.1337e-03,  1.0308e-01,  4.1006e-02,\n",
      "           3.6828e-04,  1.7174e-02,  8.8924e-02,  9.5071e-02, -1.3273e-01,\n",
      "           5.8242e-02,  8.7899e-02, -4.1884e-01,  3.0155e-01,  2.0180e-01,\n",
      "           1.2656e-02,  1.1228e-01,  3.1085e-01,  1.2361e-01,  1.7134e-01,\n",
      "          -2.7000e-02,  2.5229e-02, -1.5126e-01,  2.5473e-01, -8.9990e-02,\n",
      "           3.0281e-01,  1.0875e-01, -1.0323e-01, -6.1962e-03,  2.0251e-01,\n",
      "          -1.9751e-01, -8.7409e-02, -1.8149e-01, -4.1280e-02, -8.7936e-02,\n",
      "          -1.8653e-01, -1.3448e-01, -2.5746e-01,  3.7872e-01,  1.5297e-01,\n",
      "          -7.7414e-02,  2.5893e-01,  1.3085e-01, -5.8585e-02, -1.3374e-03,\n",
      "          -1.7991e-02,  4.3933e-02, -1.5749e-01,  3.3672e-01, -8.6279e-02,\n",
      "          -2.6682e-01, -1.7065e-01,  4.0201e-02,  6.0268e-02,  6.2033e-02,\n",
      "          -1.6511e-01, -1.8703e-01, -8.2508e-02,  2.3843e-02, -3.6878e-01,\n",
      "          -2.3885e-02, -1.6526e-01, -1.3102e-01, -1.3917e-01,  1.3312e-01,\n",
      "           2.4921e-02,  2.8150e-01, -2.5153e-01,  1.7912e-01, -7.2784e-02,\n",
      "          -8.1566e-02, -1.8764e-01, -7.2590e-02,  2.5407e-02, -3.0624e-02,\n",
      "          -6.2458e-02, -9.3869e-02,  1.5657e-01,  1.7245e-01, -1.3235e-01,\n",
      "          -5.5813e-02,  3.0136e-01, -1.0585e-02,  9.0640e-02, -1.1606e-01,\n",
      "           1.4992e-01,  7.0325e-02, -1.7829e-01,  5.7235e-02,  5.7925e-02,\n",
      "           2.3759e-01,  3.3281e-02,  1.7789e-01, -3.1542e-01, -1.7168e-01,\n",
      "          -7.3779e-02,  7.1443e-02, -3.0411e-02, -1.7721e-01,  2.5713e-02,\n",
      "          -3.3331e-02,  7.2910e-03,  1.9761e-03, -2.9592e-02,  5.4865e-02,\n",
      "          -1.0185e-02, -6.0983e-02,  2.4444e-01,  2.8140e-01,  9.1833e-02,\n",
      "           3.2374e-02,  3.1192e-01,  2.9127e-02,  8.2388e-02,  8.9993e-02,\n",
      "          -1.7257e-01, -7.2019e-02,  1.2533e-01, -1.5867e-01, -1.6125e-01,\n",
      "           3.8014e-01,  1.1444e-01, -1.8495e-01,  4.1773e-03,  1.2393e-01,\n",
      "          -8.3205e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.4244e+00,  1.0416e+00,  1.5391e+00,  1.3684e-01, -6.1804e-01,\n",
      "          -1.7847e+00,  2.1753e+00,  1.0115e+00, -1.8051e+00,  8.6487e-01,\n",
      "          -9.0378e-01,  3.3971e-01, -4.8835e-01,  7.5382e-01, -2.9329e-01,\n",
      "          -5.6256e-01,  1.8234e+00,  2.4530e-01, -1.0824e+00,  2.2739e-01,\n",
      "          -1.3268e+00,  5.7131e-01, -1.0312e+00,  0.0000e+00,  7.6798e-02,\n",
      "           2.1414e+00, -9.4698e-01, -4.3009e-01,  1.4557e+00,  0.0000e+00,\n",
      "           1.9503e-01, -1.7233e+00,  1.8430e-01,  1.1851e+00,  3.2525e-01,\n",
      "           9.6512e-01,  1.2360e+00, -2.3252e+00,  1.9369e-01, -3.9692e-01,\n",
      "           0.0000e+00, -1.0100e+00,  4.3064e-01,  0.0000e+00,  1.1079e-01,\n",
      "           7.4929e-01, -1.9832e+00, -6.5824e-02, -2.8236e-01,  1.1127e+00,\n",
      "           1.0202e+00,  1.8362e+00, -1.2955e+00,  1.8635e+00,  1.3146e+00,\n",
      "           6.1974e-01, -6.2965e-01, -2.7262e-01,  1.9946e-01, -5.1038e-01,\n",
      "           3.7050e-01,  4.2321e-01,  2.2934e+00,  2.1153e-01,  1.0820e-01,\n",
      "          -7.2262e-01,  0.0000e+00, -4.8704e-01, -3.5942e-01,  0.0000e+00,\n",
      "          -2.5327e-01,  1.1913e+00,  0.0000e+00,  5.6891e-01, -4.9171e-01,\n",
      "          -2.1634e+00,  6.1399e-01,  1.9225e+00, -2.6670e-01,  5.9191e-01,\n",
      "           3.2833e-01,  8.6603e-01,  4.3202e-01, -5.3080e-01, -2.1352e+00,\n",
      "           1.2276e+00, -2.6697e-01,  2.6441e-01,  2.2816e+00, -2.9131e-01,\n",
      "          -1.9131e+00,  8.9881e-01,  0.0000e+00,  3.1002e+00,  8.5202e-01,\n",
      "           1.2162e+00,  4.7073e-01, -1.2933e+00, -1.5364e-02,  0.0000e+00,\n",
      "          -4.4463e-01,  0.0000e+00,  2.5247e-01, -2.3886e-01,  2.9315e-01,\n",
      "          -3.3860e-01,  1.3180e+00,  0.0000e+00,  1.2096e+00,  3.0927e-01,\n",
      "           1.2021e+00,  8.6048e-01,  3.3203e-01,  0.0000e+00,  1.1312e+00,\n",
      "          -3.2693e-01,  1.4599e+00, -3.0920e-01, -3.3484e-01, -2.8370e-01,\n",
      "           3.6177e-01, -1.3880e+00, -1.2571e-01, -7.5745e-01, -1.0173e+00,\n",
      "           1.2918e+00, -6.8994e-01, -3.1482e-01,  0.0000e+00, -4.0080e-01,\n",
      "          -1.8637e+00,  1.8765e+00,  4.5548e-01, -1.1091e+00, -5.2424e-01,\n",
      "          -2.4197e+00,  1.4645e+00,  2.5516e-01, -2.4110e-01,  5.4318e-01,\n",
      "          -1.9699e+00, -5.1946e-01, -4.1952e-01, -1.0538e-01, -2.1188e+00,\n",
      "          -1.0135e-01,  8.7059e-01, -7.0720e-01,  8.5128e-02,  1.9518e+00,\n",
      "           4.1492e-01,  1.1435e+00,  1.9433e+00,  7.4465e-01,  6.5773e-01,\n",
      "           8.8012e-02, -2.6392e-01,  5.0910e-01,  4.6449e-01,  9.6070e-01,\n",
      "          -2.0598e-01, -1.2877e+00,  4.5745e-01, -4.0285e-01, -1.3215e+00,\n",
      "           6.5060e-01,  1.3774e+00, -3.9396e-01,  7.4735e-01,  9.1073e-01,\n",
      "          -1.0366e+00,  0.0000e+00,  0.0000e+00,  1.0240e+00,  0.0000e+00,\n",
      "          -2.4681e+00,  1.3610e+00,  5.2442e-01,  2.3411e+00,  3.3862e-01,\n",
      "          -4.5619e-01, -9.0415e-01, -4.4768e-01,  0.0000e+00,  3.0063e-01,\n",
      "           2.3707e+00, -4.1655e-02,  1.2664e+00,  7.8895e-01, -8.2067e-01,\n",
      "          -5.6127e-01,  1.2378e-01, -1.7461e-03, -2.4577e+00,  8.6641e-01,\n",
      "           8.6326e-02, -1.8475e-01, -6.0651e-01, -3.3743e-01, -4.0168e-01,\n",
      "           4.7065e-01,  1.1265e+00,  1.6983e+00, -8.3678e-01, -9.2338e-01,\n",
      "          -4.7856e-01,  8.6177e-01,  2.1783e+00, -4.9710e-02,  5.7515e-01,\n",
      "           0.0000e+00,  5.5478e-01,  1.4430e+00,  0.0000e+00, -2.5191e-01,\n",
      "           0.0000e+00, -1.9715e+00, -1.0760e+00,  2.5185e+00,  9.9492e-01,\n",
      "          -8.8402e-01, -1.6653e+00, -9.3183e-01,  3.5659e-01,  0.0000e+00,\n",
      "           1.8892e+00,  1.6780e+00,  8.7776e-01, -5.1640e-01,  0.0000e+00,\n",
      "           5.4320e-01, -7.0326e-01,  0.0000e+00, -3.9567e-01, -1.0516e-01,\n",
      "           7.2587e-02,  1.1441e+00,  0.0000e+00,  8.7899e-01,  4.2593e-01,\n",
      "           0.0000e+00, -1.1344e+00, -2.3814e-02, -2.0385e+00, -1.0440e+00,\n",
      "           1.2268e+00, -4.2721e-01,  9.2114e-01, -1.0568e+00, -2.2825e-01,\n",
      "           0.0000e+00,  1.3664e+00, -5.2079e-01,  1.7561e+00,  6.2631e-01,\n",
      "          -8.7996e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0526, 0.1022, 0.0882, 0.0426, 0.1350, 0.1714, 0.0439, 0.0925, 0.2078,\n",
      "         0.0638]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.1036e-01, -5.6947e-02, -4.1045e-01,  1.3202e-01, -2.0243e-01,\n",
      "          -2.4277e-01, -1.1039e-01, -1.0800e-01,  1.8031e-01,  4.3247e-02,\n",
      "           9.3262e-02,  7.7572e-02, -2.4054e-01,  2.6190e-01,  6.2251e-02,\n",
      "           3.7645e-02, -1.6779e-01,  1.4465e-01,  1.2124e-01,  1.9178e-01,\n",
      "          -1.8191e-01,  3.5945e-02,  1.6133e-01, -2.8543e-02, -3.0072e-03,\n",
      "           1.6485e-01,  1.3001e-03, -1.5913e-01, -2.0980e-01,  1.1501e-01,\n",
      "           2.4903e-01, -1.5620e-01,  1.3020e-01, -1.7125e-01,  2.6375e-01,\n",
      "           8.4717e-02, -8.7720e-02, -5.1595e-02,  1.3488e-01, -1.7489e-02,\n",
      "          -1.2224e-01, -3.5894e-03,  2.2084e-02,  8.4382e-02, -1.3029e-01,\n",
      "           3.6413e-02,  1.2702e-01, -1.9760e-01,  1.1515e-01,  7.3648e-02,\n",
      "           8.5100e-02,  1.3994e-01, -3.8594e-01, -5.1378e-01, -1.6062e-01,\n",
      "           8.7378e-02,  7.9277e-02, -2.7431e-01, -9.0218e-02, -5.2501e-02,\n",
      "          -1.4091e-01, -2.2962e-01,  1.4070e-01, -2.3636e-01,  7.1158e-02,\n",
      "          -6.9222e-02,  5.6844e-02, -1.0611e-01, -1.9805e-01, -7.8467e-02,\n",
      "           2.3316e-01,  1.9979e-02,  1.2479e-01,  1.2674e-01,  2.6530e-01,\n",
      "          -2.7173e-02,  1.2076e-01, -1.8545e-04, -1.0265e-01,  1.5937e-01,\n",
      "           7.4515e-02,  1.3071e-01, -2.0264e-01,  1.4428e-01, -8.4622e-02,\n",
      "           7.6251e-04, -6.8811e-02,  1.2827e-01, -1.9890e-01,  1.1037e-01,\n",
      "           6.9704e-02, -9.2841e-02,  1.2314e-01, -1.0171e-01, -2.4463e-02,\n",
      "          -2.6845e-03,  7.7801e-02,  2.1012e-01,  1.6222e-01,  2.9371e-01,\n",
      "          -8.9430e-02, -1.4225e-02,  3.5938e-01,  1.2972e-01,  2.3092e-01,\n",
      "          -9.5900e-02,  2.6471e-01,  1.4547e-01,  1.5380e-01, -8.6607e-02,\n",
      "           2.3480e-01,  1.0177e-01, -9.1060e-03,  2.4952e-01, -1.2943e-01,\n",
      "          -5.3009e-02, -8.5711e-02, -8.1905e-02,  9.7906e-02,  1.5193e-01,\n",
      "           6.9554e-02, -1.0824e-01, -7.8608e-02,  3.5037e-02, -1.9198e-02,\n",
      "          -4.3240e-02, -1.5318e-02, -1.8852e-01,  2.2315e-01,  3.2115e-02,\n",
      "           2.4888e-01,  2.5108e-02,  2.1333e-02,  1.4869e-01,  3.0289e-02,\n",
      "          -2.1301e-02,  2.1619e-04,  1.2205e-01,  9.5834e-02, -1.2379e-01,\n",
      "           3.0595e-03,  1.2841e-01, -4.0058e-01,  2.6395e-01,  2.0852e-01,\n",
      "           8.6120e-03,  1.3752e-01,  2.9890e-01,  1.5027e-01,  2.6364e-01,\n",
      "          -1.1663e-01,  1.3402e-01, -1.6551e-01,  3.0495e-01, -1.6838e-02,\n",
      "           3.1084e-01,  7.2101e-02, -8.4569e-02, -4.4877e-02,  2.1500e-01,\n",
      "          -2.0445e-01, -1.0788e-01, -2.1214e-01,  3.3798e-02, -1.6432e-01,\n",
      "          -1.2639e-01, -1.0875e-01, -3.2726e-01,  3.2484e-01,  1.0120e-01,\n",
      "          -1.5621e-01,  2.5235e-01,  1.6643e-01,  5.5715e-03,  3.1803e-02,\n",
      "          -7.2081e-02,  4.0405e-02, -1.8702e-01,  3.3401e-01, -1.5483e-01,\n",
      "          -2.6894e-01, -9.9462e-02, -2.2930e-02, -3.6535e-03,  1.3806e-01,\n",
      "          -1.3551e-01, -1.8864e-01, -4.2325e-02, -1.4577e-02, -3.8777e-01,\n",
      "           4.8823e-03, -1.2863e-01, -1.3076e-01, -7.6320e-02,  7.0477e-02,\n",
      "          -3.9660e-02,  2.8137e-01, -2.2212e-01,  1.4417e-01, -8.7754e-02,\n",
      "          -8.0912e-02, -1.5525e-01, -8.0824e-02,  1.7225e-02, -9.4022e-02,\n",
      "          -9.4537e-02, -9.7209e-02,  2.3147e-01,  1.8752e-01, -1.4839e-01,\n",
      "          -8.5348e-02,  2.4286e-01, -1.5544e-02,  9.2047e-02, -1.4128e-01,\n",
      "           1.3382e-01,  1.4056e-01, -1.1260e-01,  5.6665e-02, -1.7548e-02,\n",
      "           2.5973e-01,  8.4268e-02,  1.7790e-01, -2.9244e-01, -7.3378e-02,\n",
      "          -7.5254e-02,  1.0869e-02, -2.8762e-02, -2.7184e-01,  8.3024e-02,\n",
      "          -2.7142e-02, -9.2057e-02, -3.5239e-02, -5.5773e-02,  4.2763e-02,\n",
      "          -8.6860e-03, -7.3296e-02,  2.6577e-01,  3.2687e-01,  1.5644e-01,\n",
      "          -4.1925e-02,  2.4887e-01,  3.1183e-02,  1.2035e-01,  6.7683e-02,\n",
      "          -2.1968e-01, -1.3897e-01,  1.0093e-01, -1.3547e-01, -2.0340e-01,\n",
      "           3.6253e-01,  1.5268e-01, -1.5855e-01, -4.5825e-02,  1.4321e-01,\n",
      "          -5.9732e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000, -0.3597, -0.4696,  1.1527,  0.3812,  2.6351,  0.1639,\n",
      "          -0.0385,  0.3315,  0.0000,  0.7295,  1.8916, -0.6233, -1.1194,\n",
      "          -1.3207,  2.4520, -0.0279,  1.4250,  1.8467, -2.0803,  0.1876,\n",
      "           0.1307,  0.7499,  1.1016,  1.1320,  0.8123, -0.2377,  0.0000,\n",
      "          -1.2094, -0.4006,  0.1285,  0.0000, -0.0707, -1.7911,  1.2641,\n",
      "          -1.4627,  1.0689,  0.6843, -0.5993,  0.6646, -0.1788, -0.3936,\n",
      "          -0.1727, -0.9371, -2.0860,  0.2887,  0.2097,  0.4927,  0.2232,\n",
      "           1.6631,  0.8513, -0.3937,  0.4601,  2.2647, -1.5047,  0.6641,\n",
      "           0.1324, -1.2937, -0.7795,  0.5992,  0.2503,  1.6622, -0.6522,\n",
      "           0.3835,  2.5050, -0.3037,  0.1736, -0.3170,  0.7453, -1.1971,\n",
      "          -0.3070, -0.2161,  0.4024, -0.8008,  0.4465, -0.0631, -0.2009,\n",
      "           0.9347,  1.5665, -1.0027, -0.0217,  0.6160,  1.4675,  0.0000,\n",
      "           0.9116,  0.5221,  0.0000, -1.1618, -0.1508,  0.0868, -0.2916,\n",
      "           1.7803, -0.2158,  0.9197,  1.2295, -0.2082,  0.2790, -0.0261,\n",
      "          -0.0464,  0.2522,  0.0000,  0.0000,  1.8285,  1.2369,  0.0509,\n",
      "           0.0000,  0.8288,  0.0000,  1.3284, -0.4892, -0.7767,  1.0460,\n",
      "           2.3337, -1.0829,  0.1445,  0.0000, -0.6953,  0.0079,  0.0262,\n",
      "          -0.8281,  1.6277,  1.1131,  0.2440, -0.9016,  0.4761, -0.8965,\n",
      "          -2.0728, -0.5229,  2.5296,  0.6367, -0.7005,  0.0000,  2.0616,\n",
      "           0.0000,  2.0393, -0.1832, -4.1690, -0.8987, -0.3152,  0.6690,\n",
      "           0.8844,  0.5310, -0.0672, -0.5670, -0.2394,  0.0000, -0.6907,\n",
      "          -0.5719,  0.0000, -0.3711, -1.2238,  0.0000, -1.4056, -0.0085,\n",
      "           0.1151,  0.7724, -0.3974, -2.1274,  0.0453, -1.5163,  0.5610,\n",
      "          -0.7436, -1.5014,  0.7595, -1.1893, -0.7730,  1.2488,  0.0000,\n",
      "           0.2158,  0.6520,  0.0000, -0.7707,  0.5587,  0.0000,  1.8658,\n",
      "           0.8350, -0.5824, -0.4504, -1.1928,  0.5087,  1.2599, -0.7737,\n",
      "          -1.3403, -0.6861, -0.5621,  1.5455, -0.7148, -1.4529,  1.5761,\n",
      "          -0.1185,  1.4890, -0.8686,  0.9912, -0.1336, -0.7816,  0.0000,\n",
      "          -1.0722,  0.7238,  1.4339, -0.8704,  1.2378,  1.6350, -0.5934,\n",
      "          -1.1572, -1.7128, -0.3193,  1.6364, -2.0851,  2.1936,  0.0000,\n",
      "           1.3111,  0.0000,  1.1241, -0.4208, -0.9119, -0.1505,  0.5589,\n",
      "           2.0326,  0.7515, -0.7506,  1.1064,  0.0000, -0.0179,  0.0000,\n",
      "           1.2338,  0.4028, -0.0096, -0.5288, -1.0263,  0.0000, -1.0080,\n",
      "          -0.5575, -1.1318, -1.1796, -0.8787, -0.9407,  0.6818,  0.3851,\n",
      "          -0.5334,  1.1771,  0.0000,  0.3575, -0.7427,  1.6650,  0.6003,\n",
      "           0.0916, -1.4178,  2.3501, -1.3437,  1.0245,  0.0000,  1.3613,\n",
      "           0.0000, -0.2871, -0.6424,  0.8342]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0501, 0.0431, 0.0540, 0.3430, 0.0536, 0.1013, 0.0465, 0.0963, 0.0607,\n",
      "         0.1513]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0341, -0.1127, -0.4843,  0.1738, -0.2927, -0.1653, -0.0887,\n",
      "          -0.1583,  0.2618,  0.0319,  0.0570, -0.0462, -0.2746,  0.1776,\n",
      "          -0.0481,  0.1041, -0.0450,  0.1786,  0.1690,  0.2827, -0.2414,\n",
      "           0.0527,  0.1499,  0.0613, -0.0389,  0.2368,  0.0008, -0.2250,\n",
      "          -0.1728,  0.1022,  0.2213, -0.1275,  0.1210, -0.1820,  0.3477,\n",
      "          -0.0251, -0.0660,  0.0065,  0.0497, -0.0786, -0.0892,  0.0082,\n",
      "           0.0924,  0.0203,  0.0461, -0.0874,  0.2166, -0.2041,  0.1676,\n",
      "           0.0270, -0.1177,  0.2011, -0.3775, -0.4956, -0.3288,  0.0779,\n",
      "           0.0065, -0.2783, -0.1755,  0.0577, -0.2565, -0.2624,  0.1228,\n",
      "          -0.1908,  0.1183,  0.0077,  0.0214, -0.1724, -0.1441, -0.1767,\n",
      "           0.2441,  0.0437,  0.1392,  0.1242,  0.2064, -0.1604,  0.1688,\n",
      "           0.0730, -0.0686,  0.1130, -0.0610,  0.0249, -0.1002,  0.0588,\n",
      "          -0.0524, -0.0801, -0.1182, -0.0070, -0.1694, -0.0034,  0.1465,\n",
      "           0.0167,  0.0750, -0.1495, -0.0075,  0.0923, -0.0083,  0.1945,\n",
      "           0.2832,  0.2675, -0.0752, -0.0085,  0.4430,  0.1628,  0.1353,\n",
      "          -0.1402,  0.2258,  0.0550,  0.1289, -0.1200,  0.2124,  0.1303,\n",
      "           0.0707,  0.2431, -0.0709, -0.0212, -0.1560, -0.0514,  0.0997,\n",
      "           0.1561,  0.2116,  0.0630, -0.0674,  0.0216, -0.0100, -0.0143,\n",
      "          -0.0937, -0.2986,  0.3213,  0.0456,  0.1220,  0.0893,  0.0442,\n",
      "           0.0888, -0.0289,  0.1587,  0.1654,  0.0785,  0.0917, -0.1621,\n",
      "           0.0963,  0.1518, -0.4464,  0.3452,  0.2109, -0.0294,  0.1203,\n",
      "           0.4229,  0.0076,  0.2312, -0.2034,  0.0979, -0.2006,  0.3422,\n",
      "          -0.0328,  0.3744,  0.1281,  0.0317,  0.0460,  0.0963, -0.2380,\n",
      "          -0.1570, -0.2526, -0.0693, -0.1742, -0.1106, -0.1882, -0.2655,\n",
      "           0.3335,  0.1145, -0.1869,  0.3256,  0.1931, -0.1746,  0.0811,\n",
      "          -0.0129,  0.0710, -0.1739,  0.4111, -0.1269, -0.2386, -0.0349,\n",
      "          -0.0114,  0.0988,  0.1447, -0.2525, -0.2970, -0.0236, -0.0176,\n",
      "          -0.3639, -0.0466, -0.0694, -0.0758, -0.1464,  0.1704, -0.0413,\n",
      "           0.1964, -0.2512,  0.1125, -0.0574, -0.0392, -0.2152, -0.0615,\n",
      "           0.2209, -0.1409,  0.0510, -0.0548,  0.3234,  0.1035, -0.1419,\n",
      "           0.0662,  0.2110,  0.0136,  0.1166, -0.1691, -0.0198,  0.0667,\n",
      "          -0.0480,  0.1182,  0.0519,  0.2942, -0.0216,  0.1890, -0.2377,\n",
      "          -0.1819, -0.0354,  0.1637, -0.0608, -0.2992,  0.0717, -0.0850,\n",
      "          -0.1622,  0.0281, -0.1329,  0.0341, -0.1399, -0.1291,  0.2260,\n",
      "           0.3745,  0.1797,  0.0332,  0.2743,  0.0237, -0.0106,  0.1598,\n",
      "          -0.2204, -0.1005,  0.0372, -0.1381, -0.1109,  0.4438,  0.0801,\n",
      "          -0.2172, -0.0315,  0.1306, -0.1749]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.4807,  0.0000, -0.0791,  0.0786, -1.0453,  1.5709, -1.3435,\n",
      "          -0.8189, -1.5025, -0.0109, -0.8054,  0.6312, -0.3209,  0.2648,\n",
      "           0.2177,  0.4439, -1.2142,  0.3911,  0.0189,  0.0000,  1.2534,\n",
      "           0.5347, -0.3960, -1.4199,  0.7903,  0.0000,  0.0000,  1.7009,\n",
      "           0.0928,  0.0000, -1.2571,  0.0000, -1.4947, -1.8113,  0.0000,\n",
      "           0.9393,  1.3741,  0.5569, -0.2287, -0.9382, -0.3453,  0.0000,\n",
      "           0.0000,  0.0974,  2.0176,  0.0000,  3.1612,  0.2594,  0.3027,\n",
      "          -0.1953,  0.5660,  2.5284, -0.2654,  0.2514,  0.8751,  0.7946,\n",
      "          -1.3288,  0.8033,  0.0000,  0.3616, -1.0643,  1.4504, -1.4774,\n",
      "           1.5715,  0.2498, -0.2990,  0.3203,  0.5597, -2.5534,  0.8500,\n",
      "          -2.2032, -2.1707, -0.0588, -2.4480,  0.0000, -1.4959, -0.8984,\n",
      "           0.5555,  0.0000,  1.5126,  0.4243, -0.1814,  1.8365, -1.6224,\n",
      "           0.4723, -0.3796,  0.1475, -0.8664,  1.7651, -2.0149,  0.0683,\n",
      "          -1.7418, -0.3681, -0.0400,  0.6249, -1.0619,  0.8979,  0.9262,\n",
      "          -0.5504, -1.0298, -1.7115, -0.1930, -0.1669, -0.1741,  0.0000,\n",
      "          -0.9869, -2.1847, -1.5888,  0.4125, -0.4917,  1.8719, -1.0880,\n",
      "           0.8186,  0.0000, -1.5335,  1.0319, -1.3569,  0.0000,  0.1713,\n",
      "           1.0238,  2.2931, -1.8022,  1.4729,  0.7482,  1.1249, -1.2703,\n",
      "          -0.5954, -1.7045, -1.0301, -2.1487, -0.6830,  1.6953, -0.6253,\n",
      "           1.3630, -0.0268,  0.5167,  0.0672, -0.7012,  0.4206,  1.0126,\n",
      "           0.5932,  0.5773, -1.5705,  0.9066, -1.9634,  0.0000, -0.3798,\n",
      "           0.4298,  0.7551, -0.7729, -2.1891,  2.0221,  0.0000, -1.5410,\n",
      "          -1.1788,  1.3548, -2.7064,  0.8786,  0.0919, -1.7679, -1.7314,\n",
      "           0.0000, -0.6556, -0.6259, -0.4005,  0.0000, -1.5330,  0.0125,\n",
      "           0.1566, -0.7752,  0.7994,  1.7203,  1.5353,  0.8192,  0.5493,\n",
      "           0.5815, -0.2828,  0.0199,  0.8442, -1.7642,  0.5855, -2.0272,\n",
      "           2.0509,  0.6256,  0.8773, -0.2667,  0.2750,  0.8488,  2.6775,\n",
      "           0.0765,  1.9889, -0.4201, -0.1269, -0.0386, -0.2603,  0.0000,\n",
      "           1.1234, -1.3253, -1.7800, -0.4483, -1.0789, -0.8865,  0.0458,\n",
      "           0.2779, -0.2420,  1.4970, -2.1576,  0.2541,  0.0000, -1.1003,\n",
      "          -0.1944, -0.0857,  0.0000,  0.0000,  1.0953, -0.6613,  0.9769,\n",
      "          -0.2663,  1.4005,  0.6166, -0.7415, -0.3844,  0.9200,  0.0000,\n",
      "           0.0000, -3.0744,  0.0000,  0.5994, -0.3638,  0.0034,  0.8232,\n",
      "           1.1293,  0.4634,  3.0105, -1.7149, -0.6222, -1.6101,  0.8884,\n",
      "           0.8385, -1.5565,  1.1300,  0.5392, -2.4357, -0.0425,  1.1802,\n",
      "           0.0000,  0.0000, -0.7830,  3.3353,  0.6228,  0.0000,  1.3982,\n",
      "           1.8402, -2.4592,  0.4276,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0689, 0.0469, 0.1477, 0.1766, 0.0807, 0.1326, 0.1042, 0.0778, 0.0716,\n",
      "         0.0930]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-7.7453e-02, -5.0783e-02, -4.2537e-01,  1.9731e-01, -2.6644e-01,\n",
      "          -1.9413e-01, -1.2005e-01, -1.2716e-01,  2.2632e-01,  7.4765e-02,\n",
      "           3.8269e-02,  1.1151e-02, -2.6119e-01,  1.7261e-01, -1.2163e-02,\n",
      "           7.5226e-02, -5.2264e-02,  1.3332e-01,  1.7490e-01,  2.3879e-01,\n",
      "          -2.2470e-01,  1.7818e-02,  1.4434e-01,  2.2655e-02, -3.3211e-02,\n",
      "           1.8263e-01, -1.9461e-02, -1.7111e-01, -2.0177e-01,  9.3099e-02,\n",
      "           2.3879e-01, -1.9760e-01,  1.1124e-01, -1.5695e-01,  2.8285e-01,\n",
      "           2.7034e-02, -4.4442e-02, -1.1898e-02,  6.9710e-02, -8.5677e-02,\n",
      "          -1.0428e-01, -1.6347e-02,  5.8853e-02,  7.5905e-02, -2.5709e-02,\n",
      "          -7.9442e-02,  1.7049e-01, -1.9345e-01,  1.0042e-01,  8.9476e-02,\n",
      "           1.0341e-02,  2.1436e-01, -3.7160e-01, -4.7872e-01, -2.4893e-01,\n",
      "           9.5715e-02,  4.4152e-02, -3.1048e-01, -1.2135e-01, -2.2686e-02,\n",
      "          -2.3813e-01, -2.0739e-01,  1.3680e-01, -2.5099e-01,  8.6866e-02,\n",
      "          -5.1753e-02,  5.4417e-02, -1.4802e-01, -1.7349e-01, -1.3728e-01,\n",
      "           2.3567e-01, -1.0700e-02,  1.1799e-01,  1.7306e-01,  2.2538e-01,\n",
      "          -1.2175e-01,  1.5376e-01,  3.8278e-04, -7.8064e-02,  1.1712e-01,\n",
      "          -7.3938e-03,  8.6764e-02, -1.5878e-01,  1.5221e-01, -7.6661e-02,\n",
      "          -9.9752e-02, -1.2196e-01,  4.4680e-02, -1.9139e-01,  6.8609e-02,\n",
      "           7.6622e-02, -1.5257e-02,  7.5588e-02, -1.2757e-01, -1.2333e-02,\n",
      "           5.4725e-02,  1.1505e-03,  1.9932e-01,  2.2728e-01,  2.6976e-01,\n",
      "          -1.1479e-01, -1.0365e-01,  3.5239e-01,  1.9101e-01,  1.7597e-01,\n",
      "          -7.5735e-02,  2.4531e-01,  7.1431e-02,  1.5573e-01, -1.2309e-01,\n",
      "           2.1923e-01,  1.1506e-01,  1.9994e-02,  2.6866e-01, -5.3204e-02,\n",
      "          -2.2843e-02, -1.1253e-01, -4.7659e-02,  6.3708e-02,  1.6696e-01,\n",
      "           1.3852e-01, -1.3619e-03, -4.1565e-02, -2.6984e-02,  1.4318e-02,\n",
      "           1.6008e-02, -5.7692e-02, -2.1092e-01,  2.2967e-01,  9.3216e-02,\n",
      "           1.7648e-01,  1.1576e-01,  1.4836e-02,  6.2972e-02,  1.7822e-02,\n",
      "           5.3054e-02,  1.0909e-01,  5.9758e-02,  9.3912e-02, -1.6967e-01,\n",
      "           5.9206e-02,  8.4142e-02, -4.3782e-01,  2.8109e-01,  1.9170e-01,\n",
      "           1.8579e-03,  8.1733e-02,  3.3018e-01,  7.3207e-02,  2.6627e-01,\n",
      "          -1.1066e-01,  6.1720e-02, -1.7857e-01,  3.0243e-01, -8.1174e-02,\n",
      "           3.3941e-01,  1.0013e-01, -1.3130e-02, -1.4484e-02,  1.0833e-01,\n",
      "          -2.1420e-01, -1.9378e-01, -2.1314e-01, -5.5992e-02, -1.9796e-01,\n",
      "          -1.1806e-01, -1.7999e-01, -2.8351e-01,  3.6580e-01,  9.4354e-02,\n",
      "          -1.5706e-01,  2.8199e-01,  1.4398e-01, -1.0334e-01,  4.9949e-02,\n",
      "          -4.3000e-02,  8.2006e-02, -1.5412e-01,  3.9900e-01, -1.3018e-01,\n",
      "          -2.3562e-01, -7.0632e-02,  1.5102e-02,  4.3368e-02,  1.2833e-01,\n",
      "          -2.0525e-01, -2.5225e-01, -4.0438e-02, -5.0743e-02, -3.8017e-01,\n",
      "           3.1374e-02, -8.0682e-02, -8.2874e-02, -7.3570e-02,  1.6982e-01,\n",
      "          -7.6701e-02,  2.1223e-01, -2.3232e-01,  1.5174e-01, -7.2495e-02,\n",
      "          -1.1079e-01, -1.5465e-01, -8.5007e-02,  1.5034e-01, -1.6421e-01,\n",
      "           2.2399e-03, -7.4563e-02,  2.8482e-01,  1.6391e-01, -7.9762e-02,\n",
      "          -3.1163e-02,  2.3595e-01,  5.4105e-02,  4.8783e-02, -1.8445e-01,\n",
      "           4.7206e-02,  8.2498e-02, -7.1752e-02,  1.6320e-01,  5.5639e-02,\n",
      "           2.7255e-01,  5.2413e-02,  1.2663e-01, -2.6645e-01, -1.4743e-01,\n",
      "          -7.9369e-02,  1.0504e-01, -5.6992e-03, -2.6898e-01,  5.1123e-02,\n",
      "          -2.7603e-02, -1.5196e-01,  2.6080e-02, -1.0810e-01,  3.5297e-02,\n",
      "          -7.3635e-02, -1.0769e-01,  2.4598e-01,  3.2299e-01,  1.4594e-01,\n",
      "          -2.2847e-03,  2.8857e-01,  4.5190e-02,  6.2277e-02,  1.0557e-01,\n",
      "          -2.0735e-01, -1.2598e-01,  6.1500e-02, -1.2569e-01, -1.6022e-01,\n",
      "           4.0260e-01,  9.4804e-02, -2.3426e-01,  6.5817e-03,  1.3916e-01,\n",
      "          -1.2075e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3266,  0.7352, -0.9452, -0.3623, -1.3015, -0.8539,  0.0000,\n",
      "           0.0000,  0.3587, -1.5745, -1.9674,  0.0910, -0.8009, -1.7183,\n",
      "           0.9993,  0.3138, -1.1412,  0.2352, -0.1461,  0.0000,  0.8330,\n",
      "           0.0633, -1.2429,  0.0000,  1.0022,  1.7434,  0.9176, -2.3960,\n",
      "          -1.3112, -0.0614,  0.4824, -1.8292, -1.6566,  0.0000,  0.6405,\n",
      "           1.2241,  1.9995,  1.3507,  0.9455,  0.0000,  0.4598, -0.2469,\n",
      "           0.4163, -0.3024, -1.0197,  0.2656, -0.8586,  1.8091,  0.0000,\n",
      "          -0.6807,  1.6452,  0.4635, -0.2668,  0.4691, -1.5339, -0.9967,\n",
      "          -0.4925,  1.1979,  0.0000,  0.2922,  1.9185,  2.2214,  0.1441,\n",
      "          -0.2233, -0.3472, -2.2627, -1.0402,  0.0171, -0.1279, -0.2939,\n",
      "           0.3436,  1.3694, -0.4772, -0.1983,  0.5678,  0.0000,  0.1850,\n",
      "           1.2136,  1.2911,  2.1499,  1.7922, -0.7611, -0.3145,  0.0000,\n",
      "           0.6873, -2.8945, -0.5431,  0.6542, -0.7163, -0.4120, -0.3751,\n",
      "          -0.2793, -1.1251, -1.9744,  0.0467,  0.6492,  0.8806,  1.0265,\n",
      "          -1.3441,  0.0000,  0.1133,  1.0082, -0.5711,  0.2830,  1.0388,\n",
      "          -1.3967,  1.0443, -1.3437,  2.2655, -0.9139, -0.9102,  0.2443,\n",
      "           0.9563,  1.3116,  0.7256,  0.1110,  1.4344, -1.1508,  0.5874,\n",
      "           1.4354,  1.0562,  1.3404,  2.2596,  0.0000,  1.4245,  0.2079,\n",
      "           1.2335,  0.1997, -0.8279, -0.0444,  0.5050, -0.8031,  1.1872,\n",
      "          -1.6745,  0.0000, -0.8110,  0.0000,  0.0516, -1.4944, -2.9437,\n",
      "          -1.1604,  0.8148,  0.1409, -0.5420, -0.4785, -0.9400, -0.4416,\n",
      "           0.1467, -1.1890,  0.5509, -0.3140, -1.5847,  0.5867,  0.3411,\n",
      "           1.4543, -0.5289,  1.8075,  0.7835, -0.6566,  0.6045, -1.5715,\n",
      "          -0.2736,  0.1030,  1.7061, -0.3375,  2.2748,  1.8563, -0.6959,\n",
      "           0.0000, -1.2749,  0.6632, -0.6655,  1.0536, -3.1898,  0.3470,\n",
      "           1.3769,  0.9171,  0.7906, -0.4100,  0.0000,  0.2203,  0.5642,\n",
      "           0.4295, -0.2809, -1.2904,  0.0000,  0.0000, -0.1542,  2.7339,\n",
      "          -1.3093,  1.1629, -0.6784,  0.3089,  0.6201,  1.1955,  0.4711,\n",
      "          -0.3436,  0.2899, -2.1749,  0.0000,  1.5570,  1.8078,  0.8519,\n",
      "           0.0000, -1.3613,  1.0747, -1.6383,  0.0000,  0.0870, -0.9085,\n",
      "           1.3843, -2.2437,  1.2338,  1.5145, -1.8163,  0.5520,  0.0000,\n",
      "           0.0000, -0.3985,  1.2059,  0.0000, -0.4329,  0.0000,  1.0488,\n",
      "          -0.8089, -0.9416, -1.2262, -0.1000, -1.7449, -0.2465, -0.4214,\n",
      "          -0.5115,  0.3160, -0.3400, -0.4039, -1.3846,  0.5533,  0.7619,\n",
      "          -0.2579, -1.8730,  0.2600,  1.4880,  1.6242, -0.8159,  0.1416,\n",
      "          -0.5875, -3.0991, -0.6843,  0.0000,  2.3935,  0.0000, -1.3237,\n",
      "           1.2458, -0.8195, -1.6719, -0.8123]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0523, 0.1453, 0.1506, 0.1355, 0.1511, 0.1084, 0.0615, 0.0704, 0.0559,\n",
      "         0.0690]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0964, -0.0107, -0.3935,  0.2004, -0.2712, -0.2324, -0.1378,\n",
      "          -0.1379,  0.2741,  0.1279,  0.0017,  0.1070, -0.2502,  0.2290,\n",
      "           0.0165,  0.1040, -0.0464,  0.1886,  0.2299,  0.2522, -0.2600,\n",
      "          -0.0259,  0.1739,  0.0277, -0.0907,  0.0945,  0.0143, -0.1868,\n",
      "          -0.2153,  0.0408,  0.1754, -0.1710,  0.0945, -0.0960,  0.2693,\n",
      "           0.0362,  0.0128, -0.0629,  0.0509, -0.0902, -0.1435, -0.0062,\n",
      "           0.0833,  0.0506, -0.0306, -0.0804,  0.1886, -0.1542,  0.1247,\n",
      "           0.1194,  0.0239,  0.2343, -0.3606, -0.4311, -0.1757,  0.1454,\n",
      "           0.0675, -0.3080, -0.1431, -0.0229, -0.2276, -0.2552,  0.1622,\n",
      "          -0.2319,  0.0818, -0.0110,  0.0461, -0.1450, -0.1536, -0.1288,\n",
      "           0.2418, -0.0479,  0.1231,  0.2443,  0.2932, -0.1274,  0.1278,\n",
      "          -0.0344, -0.1060,  0.0975, -0.0085,  0.0910, -0.1340,  0.1535,\n",
      "          -0.0760, -0.1146, -0.1730,  0.0183, -0.1843,  0.0561,  0.0843,\n",
      "          -0.0047,  0.0706, -0.1199,  0.0215,  0.0207, -0.0292,  0.2160,\n",
      "           0.1986,  0.1910, -0.1441, -0.1025,  0.3674,  0.1364,  0.1705,\n",
      "          -0.0309,  0.2609, -0.0146,  0.1551, -0.1593,  0.2656,  0.0754,\n",
      "           0.0029,  0.2694, -0.0774, -0.0487, -0.0498, -0.0712,  0.1287,\n",
      "           0.1906,  0.1058,  0.0140, -0.0212, -0.0369,  0.0144,  0.0336,\n",
      "          -0.0247, -0.2117,  0.1879,  0.0789,  0.1667,  0.1202, -0.0257,\n",
      "           0.0546,  0.0100,  0.0211,  0.1031,  0.0781,  0.1057, -0.1159,\n",
      "           0.1134,  0.1458, -0.4346,  0.2713,  0.1714,  0.0087,  0.0681,\n",
      "           0.3254,  0.1073,  0.2436, -0.1043,  0.0429, -0.1906,  0.2824,\n",
      "          -0.1053,  0.2957,  0.1240, -0.0018, -0.0242,  0.1494, -0.2200,\n",
      "          -0.1932, -0.1869, -0.0628, -0.1872, -0.1223, -0.2203, -0.2776,\n",
      "           0.3710,  0.0960, -0.1595,  0.2758,  0.1138, -0.1169,  0.0157,\n",
      "          -0.0211,  0.0862, -0.1400,  0.3886, -0.0764, -0.2426, -0.1445,\n",
      "          -0.0078,  0.1229,  0.0612, -0.2084, -0.1908, -0.1092, -0.0639,\n",
      "          -0.3434, -0.0034, -0.0838, -0.0834, -0.1240,  0.1713, -0.0307,\n",
      "           0.2033, -0.2472,  0.1652, -0.1288, -0.1501, -0.1784, -0.0889,\n",
      "           0.0784, -0.0806,  0.0352, -0.0350,  0.2581,  0.1639, -0.0380,\n",
      "          -0.0327,  0.2689,  0.0509,  0.0731, -0.1718,  0.0858,  0.0366,\n",
      "          -0.1229,  0.1567,  0.0892,  0.2631,  0.0283,  0.1833, -0.3061,\n",
      "          -0.1781, -0.0905,  0.1353, -0.0296, -0.2475,  0.0290, -0.0296,\n",
      "          -0.0831,  0.0682, -0.0817,  0.0855, -0.0489, -0.0862,  0.2433,\n",
      "           0.3000,  0.1464,  0.0025,  0.3092,  0.0363,  0.0852,  0.1273,\n",
      "          -0.2025, -0.1079,  0.0536, -0.1279, -0.1344,  0.3984,  0.0768,\n",
      "          -0.2279,  0.0539,  0.1027, -0.1223]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.4807,  2.1409, -0.0791,  0.0786, -1.0453,  1.5709, -1.3435,\n",
      "          -0.8189,  0.0000, -0.0109, -0.8054,  0.6312, -0.3209,  0.2648,\n",
      "           0.2177,  0.0000, -1.2142,  0.3911,  0.0189, -0.0039,  1.2534,\n",
      "           0.5347, -0.3960, -1.4199,  0.7903,  0.2989,  0.0000,  1.7009,\n",
      "           0.0928,  1.0515, -1.2571, -1.7873, -1.4947, -1.8113, -0.6484,\n",
      "           0.9393,  1.3741,  0.5569, -0.2287, -0.9382, -0.3453,  0.8288,\n",
      "          -0.3888,  0.0974,  2.0176, -0.5203,  3.1612,  0.2594,  0.3027,\n",
      "           0.0000,  0.5660,  2.5284, -0.2654,  0.2514,  0.8751,  0.7946,\n",
      "          -1.3288,  0.8033,  0.0000,  0.3616,  0.0000,  1.4504, -1.4774,\n",
      "           1.5715,  0.2498,  0.0000,  0.3203,  0.0000, -2.5534,  0.8500,\n",
      "          -2.2032, -2.1707, -0.0588, -2.4480, -0.1723, -1.4959, -0.8984,\n",
      "           0.5555, -3.3391,  1.5126,  0.4243, -0.1814,  1.8365, -1.6224,\n",
      "           0.4723, -0.3796,  0.0000, -0.8664,  1.7651, -2.0149,  0.0683,\n",
      "          -1.7418, -0.3681, -0.0400,  0.0000, -1.0619,  0.8979,  0.9262,\n",
      "           0.0000, -1.0298, -1.7115, -0.1930, -0.1669, -0.1741, -0.7175,\n",
      "          -0.9869, -2.1847, -1.5888,  0.4125, -0.4917,  1.8719, -1.0880,\n",
      "           0.8186,  0.0000, -1.5335,  1.0319, -1.3569,  0.3800,  0.1713,\n",
      "           1.0238,  2.2931, -1.8022,  1.4729,  0.7482,  1.1249, -1.2703,\n",
      "          -0.5954, -1.7045, -1.0301, -2.1487, -0.6830,  1.6953, -0.6253,\n",
      "           1.3630, -0.0268,  0.0000,  0.0672, -0.7012,  0.4206,  0.0000,\n",
      "           0.0000,  0.5773, -1.5705,  0.0000,  0.0000, -1.0128, -0.3798,\n",
      "           0.4298,  0.7551, -0.7729, -2.1891,  2.0221,  0.9017, -1.5410,\n",
      "          -1.1788,  1.3548, -2.7064,  0.8786,  0.0919, -1.7679, -1.7314,\n",
      "          -2.8990,  0.0000,  0.0000, -0.4005,  0.7299, -1.5330,  0.0000,\n",
      "           0.1566, -0.7752,  0.7994,  1.7203,  1.5353,  0.8192,  0.5493,\n",
      "           0.5815, -0.2828,  0.0199,  0.8442,  0.0000,  0.5855, -2.0272,\n",
      "           2.0509,  0.6256,  0.8773, -0.2667,  0.2750,  0.8488,  2.6775,\n",
      "           0.0000,  1.9889, -0.4201, -0.1269, -0.0386, -0.2603,  1.9229,\n",
      "           1.1234, -1.3253, -1.7800, -0.4483, -1.0789, -0.8865,  0.0458,\n",
      "           0.2779, -0.2420,  1.4970, -2.1576,  0.2541,  1.4273, -1.1003,\n",
      "          -0.1944, -0.0857, -3.2877, -0.0321,  1.0953, -0.6613,  0.0000,\n",
      "           0.0000,  1.4005,  0.6166, -0.7415, -0.3844,  0.9200, -1.2025,\n",
      "           1.4237, -3.0744,  1.4113,  0.5994, -0.3638,  0.0034,  0.8232,\n",
      "           1.1293,  0.0000,  3.0105, -1.7149, -0.6222,  0.0000,  0.8884,\n",
      "           0.8385, -1.5565,  1.1300,  0.5392, -2.4357, -0.0425,  1.1802,\n",
      "           0.0000,  2.3391, -0.7830,  0.0000,  0.6228, -0.5928,  1.3982,\n",
      "           1.8402, -2.4592,  0.4276,  1.8516]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0458, 0.0454, 0.1987, 0.1926, 0.0901, 0.1110, 0.1164, 0.0539, 0.0638,\n",
      "         0.0823]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0682, -0.0456, -0.4270,  0.2119, -0.2885, -0.2017, -0.1386,\n",
      "          -0.1340,  0.2477,  0.0995,  0.0080,  0.0359, -0.2752,  0.1774,\n",
      "          -0.0224,  0.0938, -0.0267,  0.1548,  0.1857,  0.2376, -0.2353,\n",
      "          -0.0024,  0.1502,  0.0255, -0.0631,  0.1748,  0.0033, -0.1863,\n",
      "          -0.2097,  0.0940,  0.2411, -0.2202,  0.0925, -0.1670,  0.2919,\n",
      "           0.0138, -0.0115, -0.0115,  0.0488, -0.0890, -0.1048,  0.0051,\n",
      "           0.0875,  0.0853, -0.0194, -0.1079,  0.2054, -0.2038,  0.1020,\n",
      "           0.1057, -0.0044,  0.2436, -0.3753, -0.4531, -0.2548,  0.1097,\n",
      "           0.0346, -0.3306, -0.1419, -0.0240, -0.2622, -0.2388,  0.1308,\n",
      "          -0.2473,  0.0738, -0.0502,  0.0445, -0.1385, -0.1707, -0.1433,\n",
      "           0.2485, -0.0154,  0.1219,  0.2125,  0.2314, -0.1427,  0.1460,\n",
      "          -0.0043, -0.0692,  0.1049, -0.0323,  0.0983, -0.1524,  0.1659,\n",
      "          -0.0883, -0.1451, -0.1534,  0.0265, -0.1807,  0.0716,  0.0646,\n",
      "           0.0073,  0.0453, -0.1370,  0.0115,  0.0838, -0.0337,  0.1871,\n",
      "           0.2532,  0.2424, -0.1267, -0.1116,  0.3359,  0.2115,  0.1752,\n",
      "          -0.0656,  0.2458,  0.0439,  0.1499, -0.1306,  0.2250,  0.1150,\n",
      "           0.0166,  0.2919, -0.0361, -0.0190, -0.0962, -0.0271,  0.0550,\n",
      "           0.1880,  0.1449,  0.0260, -0.0242, -0.0515,  0.0015,  0.0425,\n",
      "          -0.0678, -0.2006,  0.2129,  0.1122,  0.1455,  0.1618, -0.0092,\n",
      "           0.0333,  0.0152,  0.0540,  0.1388,  0.0552,  0.1058, -0.1669,\n",
      "           0.0722,  0.0863, -0.4517,  0.2759,  0.1911, -0.0071,  0.0651,\n",
      "           0.3287,  0.0802,  0.2568, -0.1445,  0.0514, -0.1920,  0.3014,\n",
      "          -0.1071,  0.3459,  0.1164,  0.0232, -0.0147,  0.0936, -0.2050,\n",
      "          -0.2138, -0.2065, -0.0777, -0.2247, -0.1077, -0.2305, -0.2864,\n",
      "           0.3759,  0.0673, -0.1778,  0.3072,  0.1276, -0.1246,  0.0723,\n",
      "          -0.0357,  0.1003, -0.1227,  0.4207, -0.1178, -0.2348, -0.0893,\n",
      "           0.0138,  0.0681,  0.1221, -0.2252, -0.2359, -0.0658, -0.0951,\n",
      "          -0.3908,  0.0600, -0.0526, -0.0491, -0.0811,  0.1886, -0.1028,\n",
      "           0.1846, -0.2248,  0.1609, -0.0985, -0.1255, -0.1560, -0.0822,\n",
      "           0.1601, -0.1910,  0.0483, -0.0473,  0.3112,  0.1660, -0.0472,\n",
      "          -0.0381,  0.2465,  0.0793,  0.0412, -0.2069,  0.0335,  0.0791,\n",
      "          -0.0632,  0.1990,  0.0816,  0.2692,  0.0621,  0.1403, -0.2732,\n",
      "          -0.1744, -0.0848,  0.1341, -0.0028, -0.2924,  0.0243, -0.0091,\n",
      "          -0.1626,  0.0474, -0.1189,  0.0423, -0.0871, -0.1283,  0.2407,\n",
      "           0.3238,  0.1480,  0.0200,  0.2898,  0.0514,  0.0720,  0.1207,\n",
      "          -0.2070, -0.1269,  0.0264, -0.1346, -0.1640,  0.4024,  0.0691,\n",
      "          -0.2618,  0.0174,  0.1445, -0.1414]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1546,  0.0000,  1.6541, -1.0092, -1.1129,  0.4009,  0.0000,\n",
      "          -1.2220, -0.9018,  0.0000, -0.2105,  0.3157,  0.1259, -0.9577,\n",
      "          -0.3084,  0.3243, -1.8653, -2.1360,  0.0000, -0.5289,  0.7697,\n",
      "           0.2832,  0.0000,  0.0000,  1.1923,  1.4257, -1.6558,  1.0546,\n",
      "           0.9844,  0.0000,  0.3065, -0.9453, -0.7690, -1.5227, -0.3681,\n",
      "           0.0000,  0.0000, -0.3508,  0.3282,  0.6278,  0.0000, -1.1764,\n",
      "           0.3723,  1.2540, -1.7947,  1.9480, -1.4986, -0.4423, -0.2786,\n",
      "           1.1462,  0.8643,  0.0354, -0.0721, -1.0043, -0.2964, -0.8048,\n",
      "          -1.8690,  0.5102,  1.5725,  2.0571, -0.8823, -0.7339,  1.9471,\n",
      "          -0.9057,  0.0000,  0.1079,  0.6386, -0.6167,  0.0200,  0.4298,\n",
      "          -1.5889, -0.0276, -0.6440,  1.4263, -0.4465,  0.5574, -3.6193,\n",
      "          -0.6177, -1.4060, -0.3102,  0.8706,  1.3116,  0.8809, -0.9602,\n",
      "           0.6946,  0.6943,  0.0462, -2.9890,  0.8147,  0.0000, -1.4902,\n",
      "           0.3246, -1.2887,  2.3923,  1.8839,  0.2150, -1.1106,  1.0774,\n",
      "           1.5504, -2.1244,  0.0142,  0.0000, -1.1343, -1.8833,  0.0000,\n",
      "           1.4169, -1.9888, -0.9155,  0.4129,  1.8161,  0.0000,  0.1789,\n",
      "          -0.4971,  1.2996, -0.1464, -0.1103,  0.3376, -1.6420,  0.8515,\n",
      "          -1.2943,  0.0000, -0.0993,  0.8788,  0.0000,  0.2248,  0.8197,\n",
      "           0.0000, -1.0701,  0.1244,  0.0000, -1.2483,  2.3285,  1.4194,\n",
      "           0.3275, -0.0094, -0.6380, -0.0640, -0.5993, -0.4515,  1.0986,\n",
      "           0.0000, -1.1797, -2.2946, -0.8851,  0.2168,  0.0000,  0.0000,\n",
      "          -0.0829,  0.0000, -0.7187,  0.3220, -1.3513,  1.8157, -1.9308,\n",
      "           0.5128, -0.3340, -0.2291, -0.7580,  0.9342, -0.0183,  0.2296,\n",
      "          -1.1460,  2.2613, -1.7643,  0.0000, -0.6916,  0.5296,  2.1350,\n",
      "          -1.6400, -2.7422,  1.2531, -2.0850, -0.0057, -1.1597, -0.9213,\n",
      "          -0.7980, -0.3056, -0.4303,  0.1176, -1.5136,  0.1503, -0.4529,\n",
      "           0.1990,  0.9699,  0.4837, -0.0758, -1.5016, -0.2136,  0.4030,\n",
      "          -1.4620,  1.0706,  0.6060,  0.5035, -0.5076,  0.7245, -0.0432,\n",
      "           1.8718,  0.0434, -0.8383, -0.2755,  0.1187, -0.2976,  0.2835,\n",
      "           0.0000, -0.0091,  0.0000,  0.0000,  2.0159, -0.7490,  1.8921,\n",
      "           0.0000,  0.1561,  1.5052,  0.0000, -0.5909, -0.0219,  0.0000,\n",
      "          -1.3817,  0.4088,  0.6369, -0.6889,  1.8592,  0.6068,  0.4731,\n",
      "           0.0296,  1.5296, -0.3648, -0.2609,  0.8420, -0.2541,  0.7771,\n",
      "          -0.5508,  1.2382,  0.0928,  2.0768,  0.5537, -1.7043,  0.0000,\n",
      "           0.0000,  1.8031, -0.8491,  0.2572, -1.0493, -0.8528,  0.1357,\n",
      "          -1.7791,  0.3810,  1.9830,  0.0000,  0.5472, -1.7502,  0.3681,\n",
      "           0.0000,  1.5688, -2.7253,  0.4069]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0644, 0.1647, 0.1372, 0.0766, 0.1208, 0.1017, 0.0776, 0.0654, 0.1199,\n",
      "         0.0717]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1078, -0.0113, -0.3627,  0.1518, -0.2278, -0.2349, -0.1429,\n",
      "          -0.1351,  0.2356,  0.0689,  0.0534,  0.0911, -0.2492,  0.2459,\n",
      "           0.0499,  0.0788, -0.0809,  0.1628,  0.1754,  0.2404, -0.2542,\n",
      "          -0.0267,  0.1881,  0.0053, -0.0501,  0.1040,  0.0094, -0.1655,\n",
      "          -0.1987,  0.0440,  0.1861, -0.1740,  0.1099, -0.1105,  0.2245,\n",
      "           0.0891, -0.0282, -0.0828,  0.0541, -0.0692, -0.1199, -0.0310,\n",
      "           0.0271,  0.0558, -0.0557, -0.0250,  0.1517, -0.1473,  0.1208,\n",
      "           0.1252,  0.0829,  0.2030, -0.3581, -0.4498, -0.1710,  0.1178,\n",
      "           0.0783, -0.2969, -0.1130, -0.0252, -0.1965, -0.2210,  0.1568,\n",
      "          -0.1999,  0.0707, -0.0035,  0.0610, -0.0986, -0.1877, -0.0599,\n",
      "           0.2362, -0.0221,  0.1098,  0.2219,  0.2777, -0.0931,  0.1014,\n",
      "          -0.0414, -0.1082,  0.1352,  0.0293,  0.1173, -0.1659,  0.1554,\n",
      "          -0.0584, -0.0909, -0.1020,  0.0616, -0.1973,  0.0976,  0.0982,\n",
      "          -0.0487,  0.0857, -0.1172, -0.0297,  0.0167,  0.0231,  0.2145,\n",
      "           0.1790,  0.2120, -0.1148, -0.0751,  0.3522,  0.1301,  0.1956,\n",
      "          -0.0157,  0.2750,  0.0521,  0.1474, -0.1344,  0.2473,  0.0866,\n",
      "          -0.0240,  0.2613, -0.0927, -0.0472, -0.0498, -0.0902,  0.1132,\n",
      "           0.1529,  0.0702, -0.0334, -0.0605, -0.0219,  0.0101,  0.0313,\n",
      "           0.0063, -0.1932,  0.1870,  0.0781,  0.1846,  0.0763, -0.0107,\n",
      "           0.1053,  0.0432, -0.0392,  0.0704,  0.0890,  0.0959, -0.1227,\n",
      "           0.0637,  0.1325, -0.4332,  0.2738,  0.1675,  0.0007,  0.0764,\n",
      "           0.3080,  0.1372,  0.2411, -0.1000,  0.0500, -0.1741,  0.2626,\n",
      "          -0.1012,  0.3127,  0.0974, -0.0295, -0.0612,  0.1356, -0.1939,\n",
      "          -0.1528, -0.2179, -0.0068, -0.1852, -0.1293, -0.1554, -0.2748,\n",
      "           0.3422,  0.1215, -0.1280,  0.2437,  0.1233, -0.0662,  0.0057,\n",
      "          -0.0667,  0.0798, -0.1287,  0.3667, -0.0945, -0.2818, -0.1604,\n",
      "           0.0074,  0.0710,  0.0887, -0.1685, -0.1891, -0.0844, -0.0498,\n",
      "          -0.3441,  0.0148, -0.1215, -0.1414, -0.0945,  0.1518, -0.0354,\n",
      "           0.2573, -0.2209,  0.1724, -0.0870, -0.1286, -0.1460, -0.1160,\n",
      "           0.0527, -0.0724, -0.0548, -0.0793,  0.2244,  0.1649, -0.0861,\n",
      "          -0.0904,  0.2626,  0.0385,  0.0618, -0.1416,  0.1282,  0.0528,\n",
      "          -0.1289,  0.0985,  0.0772,  0.2478,  0.0266,  0.1533, -0.3038,\n",
      "          -0.1604, -0.0807,  0.0859, -0.0576, -0.2334,  0.0373, -0.0177,\n",
      "          -0.0515,  0.0128, -0.0768,  0.0717, -0.0315, -0.0869,  0.2376,\n",
      "           0.2969,  0.1547, -0.0059,  0.2908,  0.0395,  0.0930,  0.1033,\n",
      "          -0.1944, -0.1162,  0.0758, -0.1273, -0.1774,  0.3973,  0.0927,\n",
      "          -0.2161,  0.0217,  0.1347, -0.1115]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1249, -0.3706, -1.9359,  1.3419,  0.1083,  0.1241, -0.6881,\n",
      "          -0.1786, -1.8068, -0.7761, -1.4821, -0.3090, -0.6027,  0.0000,\n",
      "          -0.1451, -0.1255, -1.8147, -0.7160,  1.3279, -0.3128,  0.9630,\n",
      "           0.0000, -0.0428, -0.3418, -1.1281, -0.8205,  0.2746, -0.9491,\n",
      "           0.3632,  2.2332,  0.1384,  0.0000, -0.3392, -1.7037,  0.1840,\n",
      "          -0.2828,  0.5668, -0.3879, -0.3375,  0.8395, -0.4100, -2.0180,\n",
      "          -0.4084,  2.3766,  0.5772, -0.6361,  0.8399, -0.3720, -1.4907,\n",
      "          -0.9643,  0.8641, -1.5650,  0.3979,  0.5435,  0.1708,  0.5034,\n",
      "           0.4277, -0.5956, -1.0138, -1.6083,  0.0000,  0.3917,  0.9602,\n",
      "           0.0000,  0.8475,  1.5858,  0.4893,  0.3940,  1.0133,  1.0951,\n",
      "          -1.1825,  1.2107, -2.2646,  0.0783,  1.6002,  1.1468, -0.5928,\n",
      "           0.2456, -0.5499,  0.0270, -2.3359,  0.9360,  1.5187,  0.5053,\n",
      "           0.0000, -0.3659, -1.2479, -0.9401,  0.0000,  1.2144,  0.0000,\n",
      "           1.6503,  2.2243, -1.4596, -0.1413,  1.3328, -0.1942, -0.5736,\n",
      "           0.4517, -0.7857,  0.0926, -1.2352,  2.0039, -1.5228,  0.4042,\n",
      "          -1.8462, -2.5043,  1.7461, -2.4833, -0.2972,  0.0000,  2.9358,\n",
      "          -0.5028,  0.1500,  0.0934,  1.0653, -2.5372,  0.2834,  2.1088,\n",
      "           0.0000,  3.7334, -0.6415,  0.0000, -1.1387, -2.4267,  2.2445,\n",
      "           0.0000,  0.6185,  0.0829, -0.2120, -0.6737, -0.0143,  0.3366,\n",
      "          -0.3800,  0.4558, -0.4536,  0.5571, -1.2538, -0.1580,  0.2311,\n",
      "           1.0447, -0.9928,  1.3969, -0.2195,  1.3924,  0.0000,  0.7134,\n",
      "          -0.2055,  0.0000,  0.6922, -0.2327,  0.2494, -0.0081, -1.2221,\n",
      "          -0.7670,  2.1041, -1.0207,  0.1863,  0.2113,  0.2467, -1.7194,\n",
      "          -1.0825, -0.4287,  0.0650,  0.0000,  0.3907, -0.8797, -1.3897,\n",
      "           0.0000, -0.5680, -0.7541,  1.6357,  0.1039,  1.8216, -0.6390,\n",
      "          -0.2868, -0.8053, -0.9423, -1.3860, -0.5041,  0.0137,  0.3057,\n",
      "           0.3939,  1.8213,  0.0000,  0.1407, -1.0472, -0.9014, -1.3158,\n",
      "          -0.5231, -3.1703,  0.0979, -0.1173, -0.1523,  1.3631,  0.6064,\n",
      "          -0.0834, -0.5276,  1.8041,  0.6379,  1.1610, -0.6540, -0.2160,\n",
      "           0.7169, -1.0929, -0.5013,  0.8113, -0.3299, -0.0420, -1.7680,\n",
      "          -0.3099, -1.4710, -0.3065, -1.5566,  0.0000, -0.2566, -0.3588,\n",
      "           1.6117, -0.0881, -1.0715, -0.9379,  0.0000, -1.3429, -0.8289,\n",
      "          -0.6347,  0.0559,  1.1946, -1.0190, -1.9223, -0.1253, -1.2628,\n",
      "           0.0000,  2.0410, -0.3064,  0.0000,  2.5505,  0.5956,  0.3978,\n",
      "          -1.6446,  0.1769,  2.2438, -0.6507, -0.6549,  0.9270, -0.1637,\n",
      "           0.7699,  0.0491,  0.5938, -0.4881, -1.1813, -1.2769,  0.1084,\n",
      "          -1.2285,  0.3958, -1.6534,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.2530, 0.0799, 0.0370, 0.0924, 0.0883, 0.0636, 0.1664, 0.0824, 0.0524,\n",
      "         0.0845]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1067,  0.0180, -0.3158,  0.1675, -0.1636, -0.1508, -0.1291,\n",
      "          -0.1343,  0.1932, -0.0196,  0.0736, -0.0613, -0.2082,  0.1091,\n",
      "          -0.0164,  0.0293, -0.0279,  0.0685,  0.2201,  0.2738, -0.2757,\n",
      "          -0.0058,  0.1840, -0.0055,  0.0680,  0.0907, -0.0407, -0.1404,\n",
      "          -0.1747, -0.0243,  0.1533, -0.1623,  0.1506,  0.0131,  0.1279,\n",
      "           0.1581, -0.0967, -0.0522,  0.0703, -0.1425, -0.1013, -0.0496,\n",
      "          -0.0864,  0.0046,  0.0015, -0.0169,  0.0367, -0.0567,  0.0762,\n",
      "           0.1013,  0.1125,  0.1768, -0.2956, -0.4965, -0.2253,  0.0721,\n",
      "           0.0823, -0.2841, -0.0415, -0.0145, -0.2346, -0.0314,  0.1703,\n",
      "          -0.2100,  0.1680, -0.0103,  0.1184, -0.1509, -0.1627, -0.0382,\n",
      "           0.1698, -0.0609,  0.0902,  0.1477,  0.1992, -0.0868,  0.1709,\n",
      "          -0.0740, -0.0907,  0.1825,  0.0477,  0.0313, -0.1436,  0.2144,\n",
      "           0.0321, -0.0206, -0.0124,  0.0008, -0.2309,  0.0777,  0.1365,\n",
      "          -0.0161,  0.1255, -0.1335, -0.1411, -0.0357,  0.1017,  0.2271,\n",
      "           0.2100,  0.3154, -0.1269, -0.1850,  0.3582,  0.1192,  0.1986,\n",
      "          -0.0161,  0.2544,  0.0763,  0.1472, -0.1609,  0.1988,  0.1188,\n",
      "          -0.0133,  0.1640, -0.0436, -0.0362, -0.1570, -0.0898,  0.1073,\n",
      "           0.0547,  0.0992, -0.0056, -0.0916,  0.0012,  0.0739,  0.0183,\n",
      "           0.0511, -0.2276,  0.2302,  0.1043,  0.2517, -0.0097,  0.0783,\n",
      "           0.1574,  0.0664, -0.0504,  0.0769,  0.0206,  0.0720, -0.1787,\n",
      "           0.1043,  0.0811, -0.4164,  0.2595,  0.1056,  0.0725,  0.0428,\n",
      "           0.2780,  0.0406,  0.3578,  0.0526, -0.0353, -0.1485,  0.2343,\n",
      "          -0.0789,  0.2811,  0.0626, -0.0486, -0.1035,  0.0172, -0.2224,\n",
      "          -0.2303, -0.2175, -0.0080, -0.1603, -0.1521, -0.0549, -0.1916,\n",
      "           0.2827,  0.2013, -0.0429,  0.0992,  0.1789, -0.0717, -0.1093,\n",
      "          -0.1260,  0.1113, -0.2127,  0.2899, -0.0755, -0.2744, -0.0282,\n",
      "           0.0714,  0.0263,  0.0380, -0.0976, -0.2649,  0.0046,  0.0224,\n",
      "          -0.2654, -0.0642, -0.2470, -0.2105, -0.0432,  0.1587, -0.0231,\n",
      "           0.2869, -0.2155,  0.1346, -0.0215, -0.1729, -0.0544, -0.1656,\n",
      "           0.1292, -0.0219, -0.1515, -0.1596,  0.1389,  0.1485, -0.1509,\n",
      "          -0.0979,  0.2173,  0.0184, -0.0236, -0.1059,  0.0855, -0.0015,\n",
      "          -0.1182,  0.1082,  0.0217,  0.2258, -0.0241, -0.0204, -0.2151,\n",
      "          -0.1474, -0.0243,  0.0036, -0.0678, -0.1045,  0.0862, -0.0350,\n",
      "          -0.1028, -0.0255, -0.0725,  0.0488, -0.0392, -0.0289,  0.2317,\n",
      "           0.2922,  0.1251, -0.1077,  0.3285,  0.0550,  0.0363,  0.1377,\n",
      "          -0.1826, -0.0938,  0.1695, -0.0893, -0.1373,  0.4144,  0.1671,\n",
      "          -0.1896,  0.0749,  0.1376, -0.1115]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7281e-01,  0.0000e+00,  0.0000e+00, -1.0845e+00, -1.1724e+00,\n",
      "           7.4195e-01,  0.0000e+00,  1.3513e+00,  1.9059e-01,  6.1739e-01,\n",
      "           0.0000e+00,  6.0240e-01,  2.2862e-01, -9.1594e-01, -3.1816e+00,\n",
      "          -6.8653e-02, -1.6329e+00,  0.0000e+00,  1.3610e+00, -1.4345e+00,\n",
      "          -1.4081e-01, -5.2315e-01, -1.1193e+00, -2.5946e+00, -7.5390e-02,\n",
      "           0.0000e+00, -6.1912e-01,  1.9965e+00,  1.2767e-01,  5.5373e-01,\n",
      "           9.1440e-01, -3.4863e-03,  2.2315e-01,  0.0000e+00, -6.4016e-02,\n",
      "           0.0000e+00, -1.1201e-01, -8.1804e-01,  3.1462e-01,  8.5226e-02,\n",
      "           8.6173e-01, -9.0019e-01,  1.0091e+00, -1.5629e+00,  1.9436e+00,\n",
      "          -2.9996e-01,  7.0436e-01, -6.0099e-01, -1.0204e+00,  1.1161e+00,\n",
      "          -1.3217e+00,  2.6764e+00,  6.6661e-01, -8.4646e-01,  2.2740e-01,\n",
      "           0.0000e+00, -1.4344e+00, -9.6802e-02,  1.2745e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6133e-02, -2.8030e-01,  2.6584e-01, -6.2597e-02,\n",
      "           3.9454e-01,  5.7805e-01,  1.1647e+00,  1.5804e+00, -1.4151e+00,\n",
      "           4.2761e-01,  2.9645e-01, -3.1391e-02, -7.9776e-01,  0.0000e+00,\n",
      "           1.3922e-01,  5.2558e-01,  1.3986e+00,  1.0269e+00, -7.9272e-01,\n",
      "           7.5720e-01, -1.0061e+00,  7.5684e-01,  1.0587e+00, -1.2140e+00,\n",
      "          -1.1307e-01, -1.1073e+00,  5.4868e-01, -9.4472e-01, -1.9015e+00,\n",
      "           5.2890e-01,  9.8628e-01,  1.7013e+00,  9.4320e-01,  6.0833e-01,\n",
      "          -1.5862e-02,  3.5273e-01, -1.1753e+00,  1.3710e+00,  2.4476e+00,\n",
      "           2.4401e-01,  4.6267e-02, -4.6614e-01, -9.8940e-01,  1.6393e+00,\n",
      "          -1.0222e+00,  3.0282e+00,  6.1948e-01, -1.0212e-01, -1.2353e+00,\n",
      "           1.8979e-01, -5.0277e-01, -5.7015e-01,  0.0000e+00, -7.8031e-01,\n",
      "           6.3176e-01,  4.0421e-01,  2.2415e-01,  0.0000e+00,  2.9366e-02,\n",
      "          -8.1327e-01, -1.4099e+00, -1.8369e+00,  6.0344e-01, -9.5611e-01,\n",
      "          -1.9985e-01,  0.0000e+00,  2.1498e+00,  1.3962e+00, -2.0873e+00,\n",
      "           0.0000e+00,  4.4941e-01, -1.1669e+00,  4.2507e-01, -4.6892e-01,\n",
      "          -7.4413e-01, -1.0649e+00, -9.7455e-01, -1.9443e-02,  2.3975e+00,\n",
      "           6.9837e-01,  0.0000e+00,  1.6915e+00, -1.4005e-01, -6.6922e-01,\n",
      "           3.4311e-02,  7.5925e-01,  4.2310e-01, -1.0327e+00, -9.5687e-02,\n",
      "           1.5601e+00,  5.8701e-01, -3.3916e-01,  6.5751e-01,  1.8406e+00,\n",
      "          -2.5231e-01, -2.1701e-01,  6.2320e-01, -2.3618e+00,  1.0554e+00,\n",
      "           3.0225e-01, -7.7636e-02,  1.5403e-01,  0.0000e+00, -2.2029e-02,\n",
      "           1.6816e+00,  1.8513e+00,  2.7038e-01, -1.2701e+00, -7.1353e-01,\n",
      "          -1.2242e+00, -1.0938e+00, -2.5899e+00,  5.0537e-01, -3.0577e+00,\n",
      "          -2.8691e-01,  4.9846e-01,  8.2916e-01,  3.1704e-01, -7.9275e-01,\n",
      "           2.7088e-01,  2.3395e+00,  1.0569e+00,  8.3813e-01, -4.0321e-01,\n",
      "           7.2673e-01,  5.9914e-01,  3.5919e-01,  8.4184e-01, -1.8294e+00,\n",
      "           1.3636e+00,  2.1587e+00,  3.3730e-01, -1.0150e+00, -1.1710e+00,\n",
      "          -2.2147e+00,  1.6652e+00,  2.1522e+00,  3.6326e-01,  2.3835e+00,\n",
      "           0.0000e+00, -5.0153e-01, -1.2757e+00, -5.4228e-01, -4.0740e-01,\n",
      "          -1.4465e+00,  9.5395e-01, -8.5143e-01,  8.3120e-01, -1.5597e+00,\n",
      "           6.3603e-01,  6.7646e-01,  2.3968e+00,  5.4844e-02,  1.8943e+00,\n",
      "           1.3073e+00,  5.8090e-01, -2.3167e+00,  1.5502e+00, -2.2250e-01,\n",
      "          -2.2714e-01,  1.7329e+00,  2.7726e-01, -1.5520e+00,  9.2262e-01,\n",
      "          -1.2245e+00, -8.4763e-01, -1.8008e+00, -1.0631e-04,  3.7348e-01,\n",
      "          -1.5731e+00, -1.2330e-01,  9.6635e-01, -1.7356e+00,  1.6937e+00,\n",
      "          -1.4405e+00,  6.3402e-01,  0.0000e+00,  9.8054e-01, -1.7149e+00,\n",
      "           1.5599e+00,  0.0000e+00, -2.5965e+00,  1.2381e+00,  0.0000e+00,\n",
      "           1.8834e+00,  0.0000e+00,  5.4288e-01, -2.6156e-01,  0.0000e+00,\n",
      "           1.3329e+00,  3.0985e-01, -5.1643e-02,  0.0000e+00, -1.6111e+00,\n",
      "           1.8060e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0566, 0.1186, 0.1457, 0.0912, 0.1172, 0.1135, 0.1391, 0.0804, 0.0781,\n",
      "         0.0598]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-3.5397e-02,  4.0112e-01, -5.5517e-04,  ...,  1.3619e-01,\n",
      "          9.8475e-02, -2.3302e-01],\n",
      "        [-3.1416e-01,  1.5044e-01,  1.4079e-02,  ...,  2.9539e-01,\n",
      "          3.3237e-02, -1.9101e-01],\n",
      "        [ 4.3432e-02,  1.9253e-01, -2.8195e-01,  ..., -9.9182e-02,\n",
      "          2.5700e-01, -3.1909e-01],\n",
      "        ...,\n",
      "        [-2.0195e-01, -5.2928e-01, -3.6750e-01,  ..., -3.2558e-01,\n",
      "          2.9783e-01,  1.9242e-02],\n",
      "        [-1.5544e-02, -3.2747e-01, -4.0905e-01,  ..., -5.4329e-01,\n",
      "          4.8448e-01, -1.5262e-01],\n",
      "        [ 1.7494e-01,  2.0669e-01, -6.6568e-01,  ..., -2.6396e-01,\n",
      "          1.2658e-01, -1.3075e-01]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1190, -0.0354, -0.3779,  0.1878, -0.2556, -0.2218, -0.1356,\n",
      "          -0.1192,  0.2189,  0.0884,  0.0354,  0.0698, -0.2546,  0.2021,\n",
      "           0.0261,  0.0915, -0.0662,  0.1196,  0.1909,  0.2297, -0.2444,\n",
      "           0.0049,  0.1713,  0.0158, -0.0123,  0.1169, -0.0389, -0.1499,\n",
      "          -0.2235,  0.0612,  0.2225, -0.1948,  0.1053, -0.1146,  0.2335,\n",
      "           0.0650, -0.0053, -0.0236,  0.0931, -0.0891, -0.0920, -0.0372,\n",
      "           0.0369,  0.0861, -0.0657, -0.0515,  0.1490, -0.1726,  0.0810,\n",
      "           0.1195,  0.0781,  0.2359, -0.3545, -0.4629, -0.1795,  0.0994,\n",
      "           0.0803, -0.3133, -0.1040, -0.0479, -0.2155, -0.1932,  0.1639,\n",
      "          -0.2643,  0.0847, -0.0422,  0.0505, -0.1539, -0.1868, -0.1251,\n",
      "           0.2418, -0.0368,  0.1048,  0.1934,  0.2626, -0.1012,  0.1326,\n",
      "          -0.0407, -0.0984,  0.1157,  0.0238,  0.1166, -0.1688,  0.1814,\n",
      "          -0.0787, -0.1039, -0.1169,  0.0681, -0.2048,  0.1065,  0.0767,\n",
      "          -0.0542,  0.0956, -0.1061, -0.0327,  0.0372,  0.0042,  0.2075,\n",
      "           0.1951,  0.2309, -0.1153, -0.1152,  0.3331,  0.1797,  0.1921,\n",
      "          -0.0381,  0.2512,  0.0624,  0.1626, -0.1421,  0.2340,  0.0956,\n",
      "          -0.0103,  0.2932, -0.0576, -0.0385, -0.0836, -0.0752,  0.1017,\n",
      "           0.1664,  0.0932, -0.0430, -0.0414, -0.0525,  0.0471,  0.0299,\n",
      "          -0.0333, -0.1846,  0.1822,  0.1107,  0.2075,  0.1114,  0.0146,\n",
      "           0.0749,  0.0498, -0.0158,  0.0793,  0.0569,  0.0906, -0.1465,\n",
      "           0.0606,  0.0649, -0.4378,  0.2694,  0.1844,  0.0164,  0.0606,\n",
      "           0.2812,  0.1186,  0.2604, -0.0641,  0.0373, -0.1714,  0.2641,\n",
      "          -0.1189,  0.3192,  0.1085, -0.0488, -0.0359,  0.1299, -0.2086,\n",
      "          -0.1943, -0.1958, -0.0543, -0.1948, -0.1338, -0.1791, -0.2641,\n",
      "           0.3763,  0.1093, -0.1169,  0.2536,  0.1129, -0.0621,  0.0220,\n",
      "          -0.0409,  0.0895, -0.1476,  0.3804, -0.1238, -0.2463, -0.1159,\n",
      "           0.0322,  0.0336,  0.0991, -0.1640, -0.2106, -0.0614, -0.0460,\n",
      "          -0.3774,  0.0375, -0.1166, -0.1086, -0.0650,  0.1717, -0.0536,\n",
      "           0.2410, -0.2186,  0.1647, -0.0780, -0.1325, -0.1295, -0.0882,\n",
      "           0.1007, -0.1239, -0.0464, -0.0617,  0.2265,  0.1733, -0.0685,\n",
      "          -0.0679,  0.2763,  0.0614,  0.0397, -0.1586,  0.0838,  0.0761,\n",
      "          -0.1007,  0.1624,  0.0655,  0.2582,  0.0467,  0.1186, -0.2929,\n",
      "          -0.1537, -0.0830,  0.0768, -0.0167, -0.2151,  0.0371, -0.0074,\n",
      "          -0.1102,  0.0189, -0.0866,  0.0494, -0.0416, -0.0751,  0.2496,\n",
      "           0.2765,  0.1350, -0.0107,  0.3098,  0.0445,  0.1023,  0.0786,\n",
      "          -0.1811, -0.1133,  0.0965, -0.1341, -0.1679,  0.3896,  0.1136,\n",
      "          -0.2396,  0.0492,  0.1369, -0.0943]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7207e-02,  4.0015e-01, -9.6454e-01, -6.8090e-01,  3.7521e-01,\n",
      "          -2.0188e-01,  1.4644e+00, -8.3686e-02, -3.5829e+00,  9.0688e-01,\n",
      "           4.2785e-01, -6.2927e-01,  2.6015e+00, -6.3061e-01, -5.4137e-01,\n",
      "          -1.5812e-01,  8.5153e-01,  1.0940e+00,  4.5523e-01,  4.3615e-01,\n",
      "          -6.3305e-01, -3.8208e-01,  1.6395e+00,  1.5111e+00,  7.5307e-01,\n",
      "          -7.6072e-02, -1.8858e-01, -7.6022e-01,  1.6532e+00,  8.6130e-01,\n",
      "           1.2313e+00,  1.2194e+00, -1.0340e+00, -8.3091e-02,  0.0000e+00,\n",
      "           0.0000e+00,  2.8053e-01, -3.7438e+00,  1.9765e-01,  1.5998e+00,\n",
      "          -4.5890e-01, -1.3979e+00,  0.0000e+00,  0.0000e+00, -1.5231e+00,\n",
      "           6.6815e-01,  5.4040e-01,  3.7148e-01, -1.3402e+00,  0.0000e+00,\n",
      "          -6.2934e-01,  0.0000e+00,  6.1010e-01,  0.0000e+00, -2.4754e-02,\n",
      "           2.0437e-01, -8.8100e-01, -1.2505e+00, -2.3753e-01, -4.2652e-01,\n",
      "           0.0000e+00,  0.0000e+00, -2.0200e-01, -5.0082e-01, -2.9618e+00,\n",
      "           5.5181e-01,  1.2777e+00, -1.2871e+00,  4.0953e-01,  5.2678e-01,\n",
      "           0.0000e+00, -2.9391e-02,  7.0719e-01, -3.6389e+00,  3.2474e-01,\n",
      "          -4.2707e-04, -1.6019e-01,  1.0610e+00,  0.0000e+00, -1.1743e-01,\n",
      "          -1.3994e+00,  2.1292e+00, -9.2389e-01,  1.0059e+00, -2.0751e-01,\n",
      "           4.3667e-01,  1.6609e+00, -9.7394e-01, -1.0472e-01, -5.8098e-01,\n",
      "          -2.2720e+00,  1.0994e+00, -6.2237e-01, -1.1358e+00,  4.6677e-01,\n",
      "          -1.1695e+00,  3.2311e-02,  6.2873e-01,  1.7190e+00, -7.7769e-01,\n",
      "           2.6964e+00, -1.4611e+00,  1.0759e+00,  1.4522e+00, -6.6590e-01,\n",
      "          -7.6210e-01,  1.2105e+00,  0.0000e+00, -1.4729e+00, -1.4145e-02,\n",
      "           0.0000e+00,  1.3382e-01, -1.0469e+00,  0.0000e+00, -1.6523e+00,\n",
      "          -2.9873e+00, -5.7059e-02, -4.9888e-01, -1.9343e-01,  4.4575e-01,\n",
      "          -1.4643e+00,  7.0183e-01, -1.4599e+00, -7.2557e-01, -9.5733e-01,\n",
      "          -1.3068e+00,  8.9511e-01,  1.6937e-01,  1.2843e+00, -7.5060e-01,\n",
      "          -8.2446e-01,  5.3118e-01, -1.5822e+00,  9.8387e-01,  2.7635e-01,\n",
      "          -5.8896e-01,  6.5798e-01,  5.7590e-01, -1.1594e+00, -1.0090e+00,\n",
      "          -3.8771e-01,  6.7769e-01, -7.8898e-01, -1.0037e-01, -1.6843e+00,\n",
      "          -9.9815e-02, -5.4259e-01, -8.4415e-01, -7.5448e-01,  1.7776e-01,\n",
      "           1.9972e+00, -1.9911e-01, -1.9292e+00, -4.0634e-01,  4.4105e-01,\n",
      "          -1.9457e-01, -6.5086e-02, -1.3089e-01,  3.8777e-02,  5.3728e-01,\n",
      "          -2.6736e-02,  2.2061e+00,  4.8110e-01, -5.5067e-01, -5.2541e-01,\n",
      "          -8.9068e-01,  2.8169e-01,  8.2540e-02,  0.0000e+00, -4.7794e-01,\n",
      "           7.3572e-01, -3.0274e-02,  2.0071e-02, -1.0032e+00,  1.2774e+00,\n",
      "          -1.0973e+00, -9.8538e-01, -2.0747e+00,  1.9677e+00,  8.6238e-02,\n",
      "          -3.1190e-02,  0.0000e+00,  6.7051e-01,  9.7995e-01, -7.4795e-01,\n",
      "          -3.4113e-01, -2.7811e+00, -7.8243e-01,  1.2088e+00,  1.0127e+00,\n",
      "           3.0718e+00,  4.9387e-01, -1.4441e-01, -5.9261e-01,  5.5952e-01,\n",
      "           2.1637e+00,  0.0000e+00,  5.3489e-01,  0.0000e+00, -9.4570e-01,\n",
      "          -1.6626e+00, -1.0152e+00,  1.2423e+00, -1.2213e-01,  2.3214e-01,\n",
      "          -5.7449e-01, -2.2916e+00,  6.8170e-01, -1.0725e+00, -4.7129e-01,\n",
      "           2.8671e+00, -5.7313e-01, -3.4144e-01,  7.9248e-01,  3.2418e-02,\n",
      "          -6.8292e-01,  0.0000e+00,  9.6700e-01,  0.0000e+00,  2.1682e+00,\n",
      "          -1.0827e+00, -4.2671e-01, -1.8431e+00, -4.9997e-01,  3.4006e-01,\n",
      "           7.0479e-01, -6.9661e-01,  0.0000e+00,  2.9222e-01, -1.5773e+00,\n",
      "          -1.1079e+00,  1.5811e+00,  0.0000e+00,  1.3102e+00, -2.9786e+00,\n",
      "           4.0329e+00,  0.0000e+00,  4.2691e-02, -1.5778e+00, -2.8574e-01,\n",
      "           7.4211e-01, -3.2458e+00,  0.0000e+00, -8.5143e-01,  1.1332e-02,\n",
      "           2.7585e-01,  2.7465e-01,  2.5204e-01,  0.0000e+00,  3.8683e-01,\n",
      "          -3.6583e-01, -1.5988e-01, -5.5308e-01,  0.0000e+00, -1.1460e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0668, 0.0677, 0.0989, 0.0683, 0.1231, 0.2198, 0.0934, 0.0820, 0.0586,\n",
      "         0.1213]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3566, -0.0176,  0.0801,  ..., -0.1211, -0.0343, -0.4698],\n",
      "        [ 0.1218,  0.1535,  0.2774,  ...,  0.1162,  0.0567,  0.0468],\n",
      "        [-0.3689, -0.1759,  0.0533,  ..., -0.1656, -0.2911,  0.1219],\n",
      "        ...,\n",
      "        [ 0.3124, -0.2896,  0.0238,  ..., -0.3403,  0.3177, -0.2268],\n",
      "        [ 0.3870,  0.1648, -0.5450,  ..., -0.1785,  0.0346, -0.1702],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0370, -0.0896, -0.0028,  0.0244,  0.4174,  0.0659, -0.3431,\n",
      "          -0.0200, -0.0527, -0.0712, -0.0223,  0.1143,  0.2082, -0.0337,\n",
      "           0.0966, -0.0166, -0.0600,  0.0335, -0.0561,  0.0511, -0.1362,\n",
      "          -0.1130,  0.0117, -0.1122, -0.0314, -0.2454, -0.0112, -0.1966,\n",
      "           0.1243, -0.0531, -0.0266, -0.0455,  0.0387,  0.2524, -0.0654,\n",
      "           0.1059, -0.2203, -0.1287, -0.0824, -0.3240, -0.2090, -0.0596,\n",
      "          -0.1762, -0.2136,  0.1262, -0.1092, -0.1538,  0.2467,  0.0791,\n",
      "           0.0055,  0.0452, -0.1467,  0.0164, -0.1941, -0.3096,  0.0842,\n",
      "          -0.0655, -0.0480, -0.0499,  0.1424, -0.0987,  0.0263,  0.1175,\n",
      "           0.2878,  0.1761,  0.1624,  0.1582,  0.1680, -0.1888, -0.0072,\n",
      "          -0.1902,  0.0509, -0.0775, -0.0593, -0.1562,  0.0957,  0.0068,\n",
      "          -0.0608,  0.0254,  0.1230, -0.1313, -0.0614, -0.2538,  0.0623,\n",
      "           0.0027,  0.1412,  0.2129, -0.0999, -0.1766,  0.0105,  0.0723,\n",
      "           0.1181, -0.1947, -0.1537, -0.2107, -0.3594,  0.1564,  0.1287,\n",
      "           0.0781,  0.3948, -0.0311, -0.1566,  0.2675,  0.1468, -0.0501,\n",
      "           0.0866, -0.0667, -0.1302, -0.0102,  0.0444, -0.1606,  0.1152,\n",
      "          -0.0061, -0.0398,  0.1359, -0.0600, -0.1678,  0.0246,  0.1238,\n",
      "          -0.1868,  0.1342, -0.0052, -0.3012, -0.0568, -0.3424,  0.0519,\n",
      "           0.3333, -0.0686,  0.2827,  0.1887,  0.2089, -0.1584, -0.1155,\n",
      "           0.0507, -0.0259, -0.1870,  0.1499,  0.1170,  0.2596,  0.0183,\n",
      "           0.2717,  0.1124, -0.0277,  0.1603, -0.1358, -0.0569,  0.2707,\n",
      "           0.1010, -0.0827,  0.2403, -0.1101, -0.1513,  0.0896,  0.2336,\n",
      "          -0.1811,  0.1528, -0.0051,  0.1568, -0.2373,  0.0317, -0.0174,\n",
      "          -0.1912,  0.0965,  0.1918, -0.3794, -0.1198,  0.1575, -0.0875,\n",
      "          -0.1559,  0.3182, -0.1104, -0.1089,  0.1978,  0.1481, -0.0480,\n",
      "          -0.1876,  0.2009, -0.1473, -0.0151,  0.2641, -0.3370,  0.0642,\n",
      "           0.0178,  0.0686, -0.1195,  0.1133, -0.1235, -0.1833, -0.1388,\n",
      "          -0.1022, -0.0489, -0.2957, -0.2245, -0.0843,  0.0621,  0.0975,\n",
      "           0.1545,  0.0858,  0.2500,  0.0150, -0.1361, -0.0491,  0.0263,\n",
      "          -0.0558,  0.1100,  0.0103, -0.2002, -0.0894,  0.3469,  0.0036,\n",
      "           0.1571, -0.0491, -0.3113, -0.1910, -0.0907,  0.1095,  0.1842,\n",
      "           0.1063, -0.2866, -0.0728,  0.0754,  0.0907,  0.2078,  0.1107,\n",
      "          -0.1742,  0.2859, -0.0748, -0.1213, -0.2049,  0.0117, -0.1504,\n",
      "          -0.0271, -0.1400,  0.0311,  0.2577, -0.1994, -0.0718, -0.1731,\n",
      "           0.1587,  0.1120,  0.0940, -0.0265, -0.1864,  0.1447,  0.2418,\n",
      "          -0.1022,  0.0546, -0.0621, -0.1377, -0.0746,  0.1681,  0.1622,\n",
      "           0.1209, -0.1263, -0.0500, -0.1949]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4728,  0.0000, -1.2333, -0.1186,  0.0000,  0.0259,  0.6619,\n",
      "           0.5340,  0.6709,  0.0000,  0.0000, -1.0164,  0.9456, -0.2518,\n",
      "          -1.6339,  0.5122,  0.0000, -0.7568, -1.5631, -2.6431, -1.1333,\n",
      "           0.1684,  2.9292,  0.5545, -0.1171,  3.2087,  1.8371,  0.0000,\n",
      "          -2.2264,  0.0000,  0.0288,  1.0130,  0.3249,  0.8596, -0.7987,\n",
      "          -1.4655,  0.6197, -0.7714,  0.0000,  0.0000,  0.4673, -2.2045,\n",
      "          -0.5665, -0.1150, -0.7131, -0.6890,  1.9272,  0.1100, -0.2870,\n",
      "          -1.8504,  1.4677,  0.4622,  0.6674, -0.2831,  0.5316,  0.2749,\n",
      "          -1.2427, -0.9508,  1.8137, -0.0118,  0.2052,  0.0000, -1.4010,\n",
      "          -0.8063,  1.1798,  0.2654,  0.0000, -0.2547, -0.0048, -0.4607,\n",
      "          -0.3250,  0.0000,  0.1474, -0.1262,  0.0000, -0.8062,  2.0664,\n",
      "           1.6791,  0.0878,  0.0000,  0.0000,  0.0862,  0.3267, -1.8363,\n",
      "          -0.0710, -1.7317,  0.0000, -0.8914,  0.6230,  0.8108, -1.2238,\n",
      "          -1.1442,  1.9849, -0.3662, -0.7340,  0.1565,  0.0000, -0.4058,\n",
      "          -0.3040, -1.8393, -1.2906, -0.7211, -0.7663,  0.2367,  0.0000,\n",
      "           1.1138, -1.0706,  2.2523, -0.2628, -0.2883, -0.0533,  0.6104,\n",
      "          -0.2544, -0.2804,  0.0000,  1.1284,  1.0064, -2.4970, -0.5752,\n",
      "           0.0296, -1.6943, -0.4008,  0.0000, -0.0782, -0.5367, -1.1106,\n",
      "           0.0000,  0.1694,  0.3222,  1.3583,  2.0787,  0.0000,  0.3600,\n",
      "          -0.7231,  0.4292,  0.0603,  0.3265, -2.1013, -0.4968, -1.6774,\n",
      "          -0.6417,  0.2343, -1.1868, -1.2145, -0.6307, -0.0403,  0.4648,\n",
      "           1.7382,  1.5949,  1.4319, -1.2625, -0.5774, -0.4801, -0.0395,\n",
      "           0.0000, -0.1171,  1.3536, -0.0318, -1.9004, -1.8063,  0.0000,\n",
      "          -0.9002, -0.7060, -0.3891, -0.9806, -0.1289,  0.4064,  0.9700,\n",
      "           0.5179, -0.1475,  1.5130, -0.3729, -0.3158,  0.0000,  0.1298,\n",
      "          -0.3526, -0.8298, -0.7688, -0.0404, -0.9374,  0.7277,  1.0417,\n",
      "           0.0470,  0.4631,  0.3160, -0.1183, -0.5407,  0.0000,  0.7547,\n",
      "          -1.0639,  0.0000, -1.7884,  0.0000, -0.9263, -1.6147,  0.0000,\n",
      "          -1.1569, -1.9605, -0.0720, -0.3749,  2.6970, -0.9216,  0.0000,\n",
      "          -0.5862, -0.7157,  0.0000, -1.2539,  0.1719,  0.2190, -1.1106,\n",
      "           0.9448, -0.6922,  0.0000,  0.3621,  0.2379, -1.4262, -2.3445,\n",
      "           0.0000, -1.4795,  0.4270,  0.0131, -0.9015,  0.0000, -1.1653,\n",
      "           0.0000, -0.1876,  1.2720,  1.2662, -2.1878,  0.0000,  1.7375,\n",
      "          -1.1751,  0.9562,  1.9993,  0.5275,  0.7885, -0.6785,  0.1043,\n",
      "          -0.6803, -2.2618,  0.1673, -0.3132, -1.0431, -0.3820, -1.0799,\n",
      "           0.0000,  1.4993, -0.5644, -1.3768,  1.2435,  0.5827,  1.7529,\n",
      "           1.9517,  0.3627,  0.4875,  0.3900]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0394, 0.1863, 0.0880, 0.0563, 0.1101, 0.1493, 0.0382, 0.1760, 0.0774,\n",
      "         0.0791]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3566, -0.0176,  0.0801,  ..., -0.1211, -0.0343, -0.4698],\n",
      "        [ 0.1218,  0.1535,  0.2774,  ...,  0.1162,  0.0567,  0.0468],\n",
      "        [-0.3689, -0.1759,  0.0533,  ..., -0.1656, -0.2911,  0.1219],\n",
      "        ...,\n",
      "        [ 0.3124, -0.2896,  0.0238,  ..., -0.3403,  0.3177, -0.2268],\n",
      "        [ 0.3870,  0.1648, -0.5450,  ..., -0.1785,  0.0346, -0.1702],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 6.4934e-02, -6.8038e-02,  8.7968e-03,  2.4219e-02,  4.1135e-01,\n",
      "           9.7031e-02, -3.5747e-01,  6.4879e-03, -2.8946e-03, -5.2124e-02,\n",
      "          -2.5521e-02,  8.8081e-02,  1.4804e-01,  1.7306e-02,  1.0935e-01,\n",
      "           2.9400e-02, -3.0596e-02,  4.8551e-02, -1.8798e-01,  1.1769e-02,\n",
      "          -1.6120e-01, -1.0184e-01, -2.3759e-02, -1.5051e-01, -3.4917e-02,\n",
      "          -2.2908e-01,  3.8695e-02, -1.8672e-01,  1.0176e-01, -1.7435e-02,\n",
      "           2.5273e-03,  3.3958e-03,  2.9672e-02,  1.7456e-01, -1.0291e-01,\n",
      "           1.0793e-01, -2.8116e-01, -1.3667e-01, -1.0411e-01, -2.7277e-01,\n",
      "          -1.5243e-01,  8.6674e-05, -1.6412e-01, -1.8881e-01,  1.3125e-01,\n",
      "          -7.5349e-02, -8.9243e-02,  2.0292e-01,  1.1148e-01, -3.8523e-02,\n",
      "           1.9429e-02, -2.1780e-01,  1.8187e-02, -2.0175e-01, -3.3496e-01,\n",
      "           6.3327e-02, -6.1435e-02, -2.2246e-04, -2.0023e-02,  1.7701e-01,\n",
      "          -4.8444e-02,  1.6461e-02,  6.6006e-02,  3.1130e-01,  1.3080e-01,\n",
      "           1.3645e-01,  1.1185e-01,  1.5120e-01, -1.9757e-01,  3.0253e-02,\n",
      "          -1.0809e-01,  1.4629e-01, -1.2569e-01, -4.3575e-02, -1.8973e-01,\n",
      "           1.0453e-01,  2.3148e-02, -2.3096e-02,  2.9119e-02,  1.0211e-01,\n",
      "          -1.8137e-01, -4.9446e-02, -2.4115e-01,  9.8397e-02,  4.3121e-02,\n",
      "           1.5572e-01,  2.3681e-01, -6.5658e-02, -1.4630e-01,  7.8651e-02,\n",
      "           3.1760e-02,  1.0437e-01, -1.8133e-01, -1.5398e-01, -1.6264e-01,\n",
      "          -2.4832e-01,  1.9338e-01,  1.4480e-01,  6.5717e-02,  3.7156e-01,\n",
      "          -6.0401e-02, -9.0658e-02,  2.8394e-01,  1.5916e-01, -2.1068e-02,\n",
      "           3.6821e-02,  9.4534e-03, -9.5161e-02, -6.6105e-02,  7.9872e-02,\n",
      "          -1.6607e-01,  1.1988e-01, -3.5003e-02, -1.3212e-02,  1.5076e-01,\n",
      "          -7.8944e-02, -1.1531e-01, -7.9636e-03,  7.5755e-02, -2.1601e-01,\n",
      "           1.3293e-01, -4.9545e-02, -2.8122e-01, -3.7990e-02, -3.8073e-01,\n",
      "           2.7906e-02,  3.6014e-01, -5.7700e-02,  3.2477e-01,  1.8856e-01,\n",
      "           1.5204e-01, -1.8666e-01, -3.5350e-02,  4.3639e-02, -5.7288e-02,\n",
      "          -2.3011e-01,  2.3031e-01,  1.3928e-01,  3.0297e-01,  9.9803e-03,\n",
      "           2.5317e-01,  2.0482e-01,  1.4780e-02,  1.6857e-01, -1.6365e-01,\n",
      "          -5.5374e-02,  3.1884e-01,  1.4495e-01, -8.9946e-02,  2.2428e-01,\n",
      "          -1.8694e-01, -1.0058e-01,  1.0846e-01,  2.7914e-01, -1.6070e-01,\n",
      "           1.9695e-01,  1.2320e-02,  1.7551e-01, -2.2930e-01,  8.3015e-02,\n",
      "           1.4587e-02, -1.3961e-01,  1.1122e-02,  2.4383e-01, -3.7147e-01,\n",
      "          -1.5192e-01,  1.2963e-01, -1.1265e-01, -1.9947e-01,  3.0455e-01,\n",
      "          -1.0424e-01, -1.1304e-01,  1.4789e-01,  2.0980e-01,  1.5148e-02,\n",
      "          -2.2359e-01,  1.6781e-01, -9.0545e-02,  2.6406e-02,  1.9088e-01,\n",
      "          -3.2479e-01,  9.0935e-02, -6.3950e-02, -1.6302e-02, -3.7420e-02,\n",
      "           8.6734e-02, -8.1895e-02, -1.6478e-01, -1.2538e-01, -1.3579e-01,\n",
      "           6.6623e-03, -2.7690e-01, -2.2708e-01, -8.2848e-02, -3.1251e-03,\n",
      "           8.5436e-02,  2.0533e-01,  1.2585e-01,  2.1007e-01,  1.4166e-03,\n",
      "          -1.3650e-01, -9.0335e-03,  1.6336e-02, -3.8586e-02,  7.8588e-02,\n",
      "           3.0682e-03, -2.0002e-01, -2.4269e-02,  2.9773e-01, -2.6397e-02,\n",
      "           1.2755e-01, -1.0848e-01, -2.8643e-01, -1.9340e-01, -7.6999e-02,\n",
      "           4.2989e-02,  2.3098e-01,  1.5628e-01, -3.4875e-01, -7.7047e-02,\n",
      "           1.1683e-01,  5.8916e-02,  2.2755e-01,  7.5943e-02, -1.7448e-01,\n",
      "           3.2956e-01, -6.6176e-02, -1.8498e-01, -2.9951e-01,  3.6699e-03,\n",
      "          -1.3671e-01, -8.9386e-02, -1.5008e-01, -1.4188e-02,  2.1230e-01,\n",
      "          -2.1144e-01, -1.0504e-01, -1.5628e-01,  1.6339e-01,  1.6425e-01,\n",
      "           1.1025e-01, -5.6986e-02, -2.4457e-01,  1.3192e-01,  2.5643e-01,\n",
      "          -1.0682e-01, -5.3836e-03, -9.5276e-02, -1.5863e-01, -1.5367e-01,\n",
      "           1.6346e-01,  1.6051e-01,  9.5512e-02, -1.3143e-01,  1.9780e-03,\n",
      "          -1.6416e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7280e-01,  0.0000e+00,  3.1484e-01, -1.0845e+00, -1.1724e+00,\n",
      "           7.4192e-01, -1.9141e+00,  1.3513e+00,  0.0000e+00,  6.1740e-01,\n",
      "           1.9024e+00,  0.0000e+00,  2.2861e-01, -9.1593e-01,  0.0000e+00,\n",
      "          -6.8610e-02, -1.6329e+00, -9.4338e-01,  1.3609e+00, -1.4345e+00,\n",
      "          -1.4077e-01, -5.2322e-01, -1.1193e+00, -2.5947e+00, -7.5417e-02,\n",
      "           1.3912e+00, -6.1917e-01,  1.9965e+00,  1.2767e-01,  5.5376e-01,\n",
      "           9.1447e-01, -3.4957e-03,  2.2310e-01,  2.0151e+00, -6.3957e-02,\n",
      "          -1.4084e+00, -1.1202e-01, -8.1796e-01,  3.1463e-01,  8.5218e-02,\n",
      "           8.6179e-01, -9.0012e-01,  1.0091e+00, -1.5630e+00,  1.9437e+00,\n",
      "          -2.9997e-01,  7.0447e-01, -6.0105e-01, -1.0204e+00,  1.1162e+00,\n",
      "          -1.3218e+00,  2.6764e+00,  6.6663e-01, -8.4648e-01,  2.2742e-01,\n",
      "          -3.0871e-01, -1.4344e+00, -9.6785e-02,  1.2746e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6159e-02, -2.8026e-01,  2.6582e-01,  0.0000e+00,\n",
      "           3.9444e-01,  5.7803e-01,  1.1648e+00,  1.5804e+00, -1.4151e+00,\n",
      "           4.2759e-01,  2.9646e-01, -3.1382e-02, -7.9774e-01, -2.1461e-01,\n",
      "           1.3923e-01,  5.2558e-01,  1.3986e+00,  1.0269e+00, -7.9275e-01,\n",
      "           7.5726e-01, -1.0060e+00,  0.0000e+00,  1.0587e+00, -1.2141e+00,\n",
      "          -1.1303e-01,  0.0000e+00,  0.0000e+00, -9.4473e-01,  0.0000e+00,\n",
      "           5.2893e-01,  9.8632e-01,  1.7013e+00,  9.4322e-01,  6.0829e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.1753e+00,  1.3710e+00,  2.4476e+00,\n",
      "           2.4399e-01,  4.6179e-02, -4.6620e-01, -9.8939e-01,  1.6394e+00,\n",
      "          -1.0223e+00,  3.0283e+00,  6.1949e-01, -1.0208e-01, -1.2353e+00,\n",
      "           1.8979e-01, -5.0280e-01, -5.7017e-01,  7.1222e-01, -7.8030e-01,\n",
      "           6.3182e-01,  4.0419e-01,  2.2418e-01, -2.3273e+00,  2.9371e-02,\n",
      "          -8.1334e-01, -1.4100e+00, -1.8369e+00,  0.0000e+00, -9.5617e-01,\n",
      "          -1.9988e-01,  0.0000e+00,  0.0000e+00,  1.3962e+00,  0.0000e+00,\n",
      "          -9.2653e-01,  4.4946e-01, -1.1670e+00,  4.2509e-01, -4.6891e-01,\n",
      "           0.0000e+00, -1.0649e+00, -9.7456e-01, -1.9452e-02,  2.3975e+00,\n",
      "           6.9837e-01, -1.1217e+00,  1.6915e+00, -1.4009e-01, -6.6924e-01,\n",
      "           3.4250e-02,  0.0000e+00,  4.2307e-01, -1.0327e+00, -9.5680e-02,\n",
      "           1.5601e+00,  0.0000e+00, -3.3908e-01,  6.5754e-01,  1.8406e+00,\n",
      "          -2.5233e-01, -2.1708e-01,  6.2322e-01, -2.3619e+00,  1.0554e+00,\n",
      "           0.0000e+00, -7.7623e-02,  1.5409e-01, -1.2114e+00,  0.0000e+00,\n",
      "           1.6816e+00,  1.8514e+00,  2.7040e-01, -1.2701e+00, -7.1349e-01,\n",
      "          -1.2242e+00, -1.0938e+00, -2.5899e+00,  5.0539e-01, -3.0578e+00,\n",
      "          -2.8693e-01,  4.9844e-01,  8.2921e-01,  3.1705e-01, -7.9275e-01,\n",
      "           2.7091e-01,  2.3395e+00,  1.0569e+00,  8.3811e-01, -4.0319e-01,\n",
      "           7.2678e-01,  0.0000e+00,  3.5920e-01,  0.0000e+00, -1.8295e+00,\n",
      "           1.3635e+00,  2.1587e+00,  3.3721e-01, -1.0150e+00, -1.1711e+00,\n",
      "          -2.2148e+00,  1.6653e+00,  2.1522e+00,  3.6326e-01,  2.3835e+00,\n",
      "           3.2339e-02, -5.0151e-01, -1.2757e+00, -5.4228e-01, -4.0739e-01,\n",
      "          -1.4465e+00,  9.5391e-01, -8.5146e-01,  8.3113e-01, -1.5597e+00,\n",
      "           0.0000e+00,  6.7640e-01,  2.3969e+00,  5.4881e-02,  1.8942e+00,\n",
      "           1.3074e+00,  0.0000e+00, -2.3167e+00,  0.0000e+00, -2.2249e-01,\n",
      "          -2.2715e-01,  1.7329e+00,  2.7721e-01, -1.5520e+00,  9.2264e-01,\n",
      "          -1.2245e+00, -8.4767e-01, -1.8009e+00, -1.4074e-04,  3.7347e-01,\n",
      "          -1.5732e+00, -1.2331e-01,  9.6632e-01, -1.7357e+00,  1.6937e+00,\n",
      "           0.0000e+00,  6.3406e-01, -1.7215e+00,  9.8052e-01, -1.7150e+00,\n",
      "           1.5599e+00, -2.7187e-01, -2.5965e+00,  1.2381e+00, -1.2287e+00,\n",
      "           1.8835e+00, -5.0836e-01,  5.4283e-01, -2.6151e-01, -1.0213e+00,\n",
      "           1.3329e+00,  3.0993e-01, -5.1617e-02, -2.2894e-01, -1.6112e+00,\n",
      "           1.8060e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0570, 0.1237, 0.1184, 0.0727, 0.1347, 0.1386, 0.1168, 0.0827, 0.0899,\n",
      "         0.0653]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3566, -0.0176,  0.0801,  ..., -0.1211, -0.0343, -0.4698],\n",
      "        [ 0.1218,  0.1535,  0.2774,  ...,  0.1162,  0.0567,  0.0468],\n",
      "        [-0.3689, -0.1759,  0.0533,  ..., -0.1656, -0.2911,  0.1219],\n",
      "        ...,\n",
      "        [ 0.3124, -0.2896,  0.0238,  ..., -0.3403,  0.3177, -0.2268],\n",
      "        [ 0.3870,  0.1648, -0.5450,  ..., -0.1785,  0.0346, -0.1702],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0548, -0.0552,  0.0103,  0.0330,  0.4119,  0.1106, -0.3602,\n",
      "           0.0151, -0.0247, -0.0220, -0.0379,  0.0936,  0.1801, -0.0157,\n",
      "           0.1158,  0.0280, -0.0192,  0.0429, -0.1059,  0.0174, -0.1558,\n",
      "          -0.0992, -0.0162, -0.1226, -0.0229, -0.2439, -0.0145, -0.1793,\n",
      "           0.1110, -0.0225, -0.0370, -0.0210,  0.0167,  0.2156, -0.0855,\n",
      "           0.1158, -0.2478, -0.1366, -0.0897, -0.3169, -0.1793, -0.0272,\n",
      "          -0.1735, -0.2133,  0.1628, -0.1352, -0.1203,  0.2026,  0.0671,\n",
      "          -0.0357,  0.0305, -0.1778,  0.0288, -0.1924, -0.3152,  0.0698,\n",
      "          -0.0448, -0.0154, -0.0155,  0.1903, -0.0743,  0.0343,  0.0889,\n",
      "           0.3057,  0.1889,  0.1594,  0.1333,  0.1626, -0.1682,  0.0034,\n",
      "          -0.1657,  0.0902, -0.1133, -0.0625, -0.1494,  0.0966,  0.0562,\n",
      "          -0.0376,  0.0085,  0.1081, -0.1749, -0.0749, -0.2593,  0.0746,\n",
      "           0.0344,  0.1559,  0.2177, -0.1105, -0.1469,  0.0296,  0.0456,\n",
      "           0.1102, -0.1662, -0.1433, -0.2049, -0.3331,  0.1668,  0.1435,\n",
      "           0.0725,  0.3820, -0.0439, -0.1466,  0.2890,  0.1838, -0.0742,\n",
      "           0.0540, -0.0361, -0.1596, -0.0589,  0.0609, -0.1518,  0.1317,\n",
      "          -0.0125, -0.0488,  0.1479, -0.0813, -0.1270,  0.0009,  0.1179,\n",
      "          -0.1856,  0.1643, -0.0688, -0.2752, -0.0722, -0.3695,  0.0330,\n",
      "           0.3616, -0.0833,  0.3389,  0.2112,  0.1831, -0.1623, -0.0602,\n",
      "           0.0162, -0.0557, -0.2097,  0.2299,  0.1239,  0.2900,  0.0053,\n",
      "           0.3017,  0.1664,  0.0162,  0.1772, -0.1662, -0.0653,  0.3061,\n",
      "           0.1374, -0.1074,  0.2135, -0.1150, -0.1450,  0.1169,  0.2647,\n",
      "          -0.1932,  0.1550,  0.0179,  0.1361, -0.2335,  0.0655,  0.0185,\n",
      "          -0.1438,  0.0594,  0.2366, -0.3738, -0.1377,  0.1798, -0.1096,\n",
      "          -0.1289,  0.3411, -0.1067, -0.1051,  0.1583,  0.1492, -0.0334,\n",
      "          -0.2232,  0.1716, -0.1019,  0.0072,  0.2364, -0.3235,  0.0642,\n",
      "          -0.0181,  0.0279, -0.0944,  0.0733, -0.1221, -0.1577, -0.1322,\n",
      "          -0.1045, -0.0217, -0.2764, -0.2173, -0.1041,  0.0315,  0.0969,\n",
      "           0.1767,  0.1058,  0.2474,  0.0123, -0.1684, -0.0236,  0.0321,\n",
      "          -0.0113,  0.1013,  0.0293, -0.2041, -0.0542,  0.3242,  0.0396,\n",
      "           0.1830, -0.0935, -0.2988, -0.2092, -0.0630,  0.0593,  0.1650,\n",
      "           0.1396, -0.3284, -0.0692,  0.1089,  0.0498,  0.2189,  0.0743,\n",
      "          -0.2053,  0.3392, -0.0725, -0.1464, -0.2559, -0.0066, -0.1678,\n",
      "          -0.0703, -0.1475,  0.0114,  0.2456, -0.2126, -0.0820, -0.1568,\n",
      "           0.1508,  0.1491,  0.1202, -0.0469, -0.2389,  0.1417,  0.2184,\n",
      "          -0.0916,  0.0354, -0.0613, -0.1430, -0.1041,  0.1840,  0.1703,\n",
      "           0.1110, -0.1148, -0.0581, -0.1871]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7240e-02,  0.0000e+00,  0.0000e+00, -6.8087e-01,  3.7521e-01,\n",
      "          -2.0185e-01,  1.4645e+00, -8.3692e-02, -3.5829e+00,  9.0690e-01,\n",
      "           4.2784e-01, -6.2928e-01,  2.6015e+00, -6.3056e-01, -5.4136e-01,\n",
      "          -1.5808e-01,  8.5146e-01,  0.0000e+00,  4.5521e-01,  4.3619e-01,\n",
      "           0.0000e+00, -3.8210e-01,  1.6394e+00,  1.5111e+00,  7.5305e-01,\n",
      "          -7.6042e-02, -1.8846e-01, -7.6024e-01,  1.6532e+00,  8.6127e-01,\n",
      "           1.2313e+00,  1.2194e+00,  0.0000e+00, -8.3095e-02, -1.5340e+00,\n",
      "           0.0000e+00,  2.8056e-01, -3.7438e+00,  1.9761e-01,  1.5998e+00,\n",
      "          -4.5897e-01, -1.3978e+00, -2.6925e-01, -1.7139e+00, -1.5231e+00,\n",
      "           6.6809e-01,  5.4037e-01,  3.7146e-01, -1.3402e+00,  1.4475e-01,\n",
      "          -6.2935e-01,  2.7501e+00,  6.1004e-01, -1.0284e+00, -2.4802e-02,\n",
      "           2.0439e-01, -8.8103e-01, -1.2505e+00, -2.3753e-01, -4.2646e-01,\n",
      "           0.0000e+00,  0.0000e+00, -2.0209e-01, -5.0076e-01, -2.9618e+00,\n",
      "           5.5177e-01,  1.2777e+00, -1.2871e+00,  4.0952e-01,  5.2674e-01,\n",
      "          -1.2661e+00, -2.9398e-02,  7.0722e-01,  0.0000e+00,  3.2474e-01,\n",
      "          -4.6096e-04, -1.6018e-01,  1.0610e+00, -5.7144e-02, -1.1744e-01,\n",
      "          -1.3994e+00,  2.1292e+00, -9.2396e-01,  1.0059e+00, -2.0746e-01,\n",
      "           4.3665e-01,  1.6610e+00,  0.0000e+00, -1.0470e-01, -5.8105e-01,\n",
      "          -2.2719e+00,  0.0000e+00, -6.2236e-01, -1.1359e+00,  4.6681e-01,\n",
      "          -1.1696e+00,  0.0000e+00,  6.2872e-01,  0.0000e+00, -7.7776e-01,\n",
      "           2.6964e+00, -1.4611e+00,  1.0759e+00,  1.4523e+00, -6.6592e-01,\n",
      "          -7.6211e-01,  1.2105e+00,  1.2744e-01, -1.4728e+00,  0.0000e+00,\n",
      "          -2.4785e-01,  1.3389e-01, -1.0468e+00,  1.3101e+00, -1.6522e+00,\n",
      "          -2.9873e+00, -5.7032e-02, -4.9889e-01, -1.9342e-01,  4.4576e-01,\n",
      "          -1.4644e+00,  0.0000e+00, -1.4600e+00, -7.2552e-01, -9.5730e-01,\n",
      "          -1.3068e+00,  8.9511e-01,  1.6937e-01,  1.2842e+00, -7.5068e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.5823e+00,  9.8383e-01,  2.7636e-01,\n",
      "          -5.8892e-01,  6.5800e-01,  5.7588e-01, -1.1593e+00,  0.0000e+00,\n",
      "          -3.8774e-01,  6.7771e-01, -7.8896e-01,  0.0000e+00, -1.6842e+00,\n",
      "          -9.9854e-02, -5.4262e-01, -8.4419e-01, -7.5446e-01,  1.7772e-01,\n",
      "           1.9973e+00, -1.9904e-01, -1.9292e+00, -4.0635e-01,  0.0000e+00,\n",
      "          -1.9453e-01,  0.0000e+00, -1.3086e-01,  3.8763e-02,  5.3725e-01,\n",
      "          -2.6666e-02,  2.2060e+00,  4.8104e-01,  0.0000e+00, -5.2536e-01,\n",
      "          -8.9069e-01,  2.8162e-01,  8.2519e-02, -3.5831e-01, -4.7789e-01,\n",
      "           7.3572e-01, -3.0292e-02,  2.0065e-02, -1.0031e+00,  1.2774e+00,\n",
      "          -1.0974e+00, -9.8535e-01, -2.0747e+00,  0.0000e+00,  8.6265e-02,\n",
      "          -3.1202e-02,  0.0000e+00,  6.7051e-01,  9.7994e-01,  0.0000e+00,\n",
      "          -3.4112e-01, -2.7810e+00, -7.8247e-01,  1.2088e+00,  1.0126e+00,\n",
      "           3.0717e+00,  0.0000e+00, -1.4439e-01, -5.9262e-01,  5.5958e-01,\n",
      "           2.1638e+00, -1.1872e+00,  5.3491e-01,  1.8107e+00, -9.4570e-01,\n",
      "          -1.6626e+00, -1.0152e+00,  1.2423e+00, -1.2216e-01,  2.3212e-01,\n",
      "          -5.7451e-01, -2.2916e+00,  0.0000e+00, -1.0725e+00, -4.7125e-01,\n",
      "           2.8671e+00, -5.7312e-01, -3.4144e-01,  7.9248e-01,  3.2368e-02,\n",
      "          -6.8294e-01, -1.0165e+00,  9.6695e-01, -2.4515e-01,  2.1681e+00,\n",
      "          -1.0827e+00, -4.2674e-01, -1.8430e+00, -5.0000e-01,  3.4000e-01,\n",
      "           7.0479e-01, -6.9661e-01, -6.2813e-01,  2.9214e-01, -1.5772e+00,\n",
      "          -1.1079e+00,  1.5811e+00, -6.1350e-01,  1.3103e+00, -2.9786e+00,\n",
      "           4.0329e+00,  5.8500e-01,  4.2679e-02, -1.5779e+00, -2.8572e-01,\n",
      "           7.4210e-01, -3.2458e+00, -3.0339e-01, -8.5149e-01,  1.1343e-02,\n",
      "           2.7581e-01,  2.7468e-01,  2.5199e-01,  2.6154e-01,  3.8686e-01,\n",
      "          -3.6585e-01, -1.5982e-01, -5.5310e-01, -5.1795e-02, -1.1460e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0508, 0.0477, 0.0881, 0.0573, 0.1215, 0.2702, 0.0769, 0.0930, 0.0644,\n",
      "         0.1300]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2005, -0.0599, -0.1219,  0.0881,  0.0987,  0.0038, -0.1014,\n",
      "          -0.0242, -0.0275,  0.0634,  0.0171, -0.1186,  0.1152,  0.1085,\n",
      "           0.0337, -0.1614,  0.1846, -0.0659, -0.3250,  0.0623, -0.2388,\n",
      "          -0.2561, -0.1872, -0.0357, -0.1899, -0.0512,  0.0055, -0.2146,\n",
      "           0.0335, -0.2220,  0.1903,  0.1109,  0.0814, -0.0659,  0.0212,\n",
      "           0.0187,  0.0978, -0.1190, -0.0139, -0.1767,  0.0491,  0.1856,\n",
      "           0.2531,  0.0880,  0.1884,  0.1012,  0.1237, -0.0495,  0.1390,\n",
      "           0.0184,  0.0802, -0.3536, -0.0064,  0.0281,  0.0460,  0.0394,\n",
      "          -0.0498, -0.0726,  0.1921,  0.1079,  0.2159, -0.1047, -0.1531,\n",
      "          -0.1676, -0.3253, -0.0859, -0.0763,  0.3084, -0.1556, -0.1172,\n",
      "          -0.2031,  0.4479, -0.1094,  0.1220, -0.2563, -0.0056,  0.1919,\n",
      "           0.1161, -0.1073, -0.2049, -0.0042,  0.0048,  0.0827, -0.1615,\n",
      "           0.3386,  0.1371,  0.1398,  0.0841,  0.1937,  0.1590,  0.1998,\n",
      "           0.1020, -0.1909, -0.0220,  0.0754, -0.1511,  0.1785,  0.2257,\n",
      "           0.1074, -0.0806, -0.0575, -0.0206,  0.0352, -0.1703,  0.1458,\n",
      "           0.0761, -0.1372,  0.0446, -0.2474,  0.1894, -0.0399, -0.1483,\n",
      "          -0.1548,  0.0193, -0.0708, -0.0560,  0.1534, -0.1801, -0.1137,\n",
      "           0.1494, -0.0304, -0.0607,  0.0041,  0.1474, -0.2524, -0.1001,\n",
      "           0.2088,  0.3140,  0.3386,  0.1542,  0.0533, -0.1212,  0.1030,\n",
      "          -0.0560,  0.0774, -0.0878,  0.1371, -0.1867, -0.1391, -0.1090,\n",
      "          -0.1042,  0.2563, -0.0426,  0.0887,  0.1898,  0.1756, -0.1959,\n",
      "           0.2678,  0.0090,  0.2101, -0.3651, -0.1041, -0.1313,  0.2842,\n",
      "          -0.2486,  0.1058,  0.0499,  0.1654, -0.1297,  0.2975, -0.0612,\n",
      "          -0.0092,  0.0533, -0.1649, -0.3111, -0.1584, -0.0477, -0.1329,\n",
      "          -0.0987,  0.2419,  0.0524, -0.2541, -0.1421,  0.1221, -0.1060,\n",
      "          -0.0140,  0.2887, -0.0260,  0.1601, -0.0585,  0.0547,  0.0956,\n",
      "          -0.3266,  0.0969,  0.0766,  0.0262, -0.1006,  0.1335, -0.1146,\n",
      "           0.2031, -0.0683,  0.2030, -0.0868,  0.1260,  0.0651, -0.0995,\n",
      "           0.0501,  0.2481, -0.0996, -0.1201, -0.1419,  0.0301, -0.0269,\n",
      "          -0.1564, -0.0276,  0.1314, -0.4828, -0.0272, -0.0145, -0.1928,\n",
      "          -0.2078,  0.0716,  0.0419, -0.0265,  0.1960,  0.0984,  0.1789,\n",
      "           0.0448, -0.2290, -0.1206,  0.1200,  0.0359,  0.1189,  0.0426,\n",
      "          -0.0032,  0.0228, -0.0867, -0.0331, -0.4105,  0.2560,  0.2391,\n",
      "          -0.0303, -0.2656,  0.0702,  0.0778,  0.2030,  0.0557,  0.0778,\n",
      "           0.1438,  0.1671,  0.0431, -0.1100, -0.0318, -0.0281,  0.3440,\n",
      "          -0.0884, -0.0402,  0.0143,  0.0074, -0.3041,  0.0314, -0.1279,\n",
      "           0.1088,  0.1076,  0.2425,  0.0751]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000,  0.0000,  1.6542, -1.0092, -1.1129,  0.0000,  0.6459,\n",
      "          -1.2220, -0.9019,  0.0944, -0.2105,  0.3157,  0.1259, -0.9577,\n",
      "          -0.3084,  0.3243, -1.8653, -2.1361,  0.6075, -0.5289,  0.7697,\n",
      "           0.2831, -1.2572, -0.9726,  0.0000,  1.4258, -1.6558,  0.0000,\n",
      "           0.9844, -1.2889,  0.3065,  0.0000, -0.7689, -1.5227, -0.3681,\n",
      "           0.4836, -0.9886, -0.3508,  0.3282,  0.6278,  0.6075, -1.1764,\n",
      "           0.3723,  1.2540, -1.7947,  1.9480, -1.4985, -0.4424, -0.2787,\n",
      "           1.1462,  0.8643,  0.0000,  0.0000, -1.0044, -0.2964, -0.8048,\n",
      "          -1.8690,  0.5102,  1.5725,  2.0571, -0.8823, -0.7338,  1.9472,\n",
      "           0.0000,  0.0000,  0.0000,  0.6386, -0.6167,  0.0200,  0.4298,\n",
      "          -1.5889, -0.0276, -0.6440,  0.0000,  0.0000,  0.5573, -3.6193,\n",
      "          -0.6177, -1.4061, -0.3102,  0.8707,  1.3116,  0.8809,  0.0000,\n",
      "           0.6946,  0.6943,  0.0461, -2.9891,  0.8146, -0.0183,  0.0000,\n",
      "           0.0000, -1.2887,  2.3923,  0.0000,  0.2150, -1.1106,  1.0774,\n",
      "           1.5504, -2.1244,  0.0142, -0.6630, -1.1343, -1.8833,  0.4069,\n",
      "           1.4168, -1.9889, -0.9156,  0.4130,  1.8161, -1.4320,  0.1788,\n",
      "          -0.4971,  1.2997, -0.1464, -0.1102,  0.0000, -1.6420,  0.0000,\n",
      "          -1.2943, -1.3453, -0.0992,  0.8787,  0.5349,  0.2247,  0.8197,\n",
      "          -0.2035, -1.0702,  0.1244, -0.4275,  0.0000,  2.3285,  1.4194,\n",
      "           0.3275,  0.0000, -0.6381, -0.0640, -0.5993, -0.4515,  1.0986,\n",
      "           0.5454, -1.1796, -2.2946, -0.8851,  0.2168, -0.1875,  0.9172,\n",
      "          -0.0829,  1.5433, -0.7187,  0.3219, -1.3513,  1.8157, -1.9307,\n",
      "           0.5128, -0.3340, -0.2291, -0.7580,  0.9342, -0.0182,  0.2297,\n",
      "          -1.1459,  2.2614, -1.7643, -0.3898, -0.6916,  0.5296,  2.1351,\n",
      "          -1.6401,  0.0000,  1.2531, -2.0849, -0.0058, -1.1598,  0.0000,\n",
      "          -0.7981, -0.3057, -0.4303,  0.1175, -1.5136,  0.0000, -0.4530,\n",
      "           0.1989,  0.9699,  0.0000, -0.0758, -1.5016, -0.2136,  0.4031,\n",
      "          -1.4620,  1.0706,  0.0000,  0.5036, -0.5077,  0.7244, -0.0432,\n",
      "           1.8719,  0.0434, -0.8384, -0.2755,  0.1187, -0.2977,  0.2834,\n",
      "           0.0000, -0.0091, -0.7145,  0.6959,  2.0159, -0.7490,  0.0000,\n",
      "           2.7888,  0.0000,  1.5052,  0.1008, -0.5909, -0.0219, -0.1423,\n",
      "           0.0000,  0.4088,  0.6369, -0.6889,  1.8591,  0.6068,  0.4732,\n",
      "           0.0000,  1.5296, -0.3648, -0.2609,  0.8421, -0.2541,  0.7770,\n",
      "          -0.5508,  1.2382,  0.0929,  2.0768,  0.5537, -1.7043,  2.7776,\n",
      "          -1.4946,  1.8031, -0.8491,  0.2572, -1.0493, -0.8528,  0.1357,\n",
      "          -1.7790,  0.3810,  1.9830,  0.5693,  0.5471, -1.7501,  0.3681,\n",
      "           0.1557,  1.5688, -2.7254,  0.4069]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0503, 0.1683, 0.1284, 0.0778, 0.1381, 0.1311, 0.0745, 0.0619, 0.1044,\n",
      "         0.0652]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.7851e-01, -5.3076e-02, -7.5182e-02,  9.5717e-02,  1.5133e-01,\n",
      "           7.9035e-02, -1.5497e-01, -2.0596e-02,  2.9902e-02,  1.0112e-01,\n",
      "          -6.0909e-02, -4.9560e-02,  1.1483e-01,  6.4157e-02,  2.9699e-02,\n",
      "          -7.2546e-02,  2.1166e-01, -5.6312e-02, -3.5682e-01,  3.2818e-04,\n",
      "          -2.1071e-01, -1.8381e-01, -1.9733e-01, -9.5891e-02, -1.6296e-01,\n",
      "          -1.0147e-01,  3.5354e-02, -1.5232e-01,  1.6845e-02, -1.5293e-01,\n",
      "           1.1963e-01,  1.1028e-01,  1.1083e-02, -4.1826e-02, -2.3579e-02,\n",
      "          -5.1444e-02,  2.6022e-02, -1.0570e-01, -9.9425e-03, -1.7187e-01,\n",
      "           9.0674e-02,  1.8052e-01,  2.3223e-01,  7.1484e-02,  1.7805e-01,\n",
      "           4.6439e-02,  2.0901e-01,  1.9240e-02,  1.5903e-01, -4.3404e-02,\n",
      "           1.1307e-01, -3.7264e-01,  6.7554e-02,  5.8657e-03, -4.0902e-02,\n",
      "           6.0985e-02, -1.8441e-02,  2.7576e-04,  2.0329e-01,  1.4970e-01,\n",
      "           1.9453e-01, -1.0280e-01, -9.9102e-02, -1.3689e-01, -2.6520e-01,\n",
      "          -1.1914e-01,  1.6956e-02,  1.8106e-01, -1.5292e-01, -1.6167e-01,\n",
      "          -1.5730e-01,  4.2871e-01, -2.2855e-01,  1.3268e-01, -2.4103e-01,\n",
      "           4.3195e-02,  2.1486e-01,  7.3586e-02, -6.9332e-02, -2.1425e-01,\n",
      "          -1.0888e-01, -8.2702e-02,  1.1317e-01, -9.8928e-02,  3.4034e-01,\n",
      "           1.1516e-01,  1.5580e-01,  5.2695e-02,  1.0854e-01,  1.9650e-01,\n",
      "           9.6652e-02,  8.5028e-02, -1.8654e-01,  3.0469e-05,  1.2010e-01,\n",
      "          -9.0916e-02,  2.2950e-01,  1.8112e-01,  1.9593e-02, -4.4811e-02,\n",
      "          -8.8774e-02, -3.6186e-02,  7.1489e-02, -1.3026e-01,  8.3697e-02,\n",
      "           3.7536e-02, -1.1555e-01, -7.2541e-02, -2.4856e-01,  1.4460e-01,\n",
      "          -1.6136e-01, -1.2547e-01, -1.9314e-01,  5.0428e-02,  3.5637e-02,\n",
      "          -8.2566e-02,  1.3939e-01, -1.7111e-01, -1.2763e-01,  1.2876e-01,\n",
      "           8.3113e-02, -8.1160e-02, -1.0865e-02,  6.9247e-02, -2.5950e-01,\n",
      "          -4.1712e-02,  2.2014e-01,  2.6612e-01,  3.7371e-01,  2.8197e-01,\n",
      "           1.0264e-02, -5.8771e-02,  1.5770e-01, -8.8800e-02,  2.3999e-02,\n",
      "          -1.4203e-01,  1.4675e-01, -1.2342e-01,  1.6271e-02, -5.4801e-02,\n",
      "          -2.2819e-02,  2.3718e-01,  7.4196e-03,  9.9015e-02,  1.0809e-01,\n",
      "           1.5762e-01, -6.3281e-02,  1.8553e-01, -2.1313e-02,  1.1000e-01,\n",
      "          -3.0708e-01, -1.1284e-01, -3.7685e-02,  2.2544e-01, -3.0363e-01,\n",
      "           1.6384e-01,  6.3153e-02,  2.1623e-01, -4.2031e-02,  2.8677e-01,\n",
      "          -5.1859e-03,  1.0826e-01,  3.4342e-02, -1.3554e-01, -2.9556e-01,\n",
      "          -1.4330e-01, -6.7504e-02, -1.1191e-01, -1.8279e-01,  2.3548e-01,\n",
      "           7.9511e-03, -2.5815e-01, -1.7241e-01,  1.6644e-01, -3.3890e-02,\n",
      "          -1.2115e-02,  2.9149e-01, -6.2258e-02,  9.7850e-02, -1.0630e-01,\n",
      "           6.0027e-02,  9.9922e-02, -3.5499e-01,  1.9345e-02,  3.6774e-02,\n",
      "          -2.9637e-02, -2.8546e-02,  8.2860e-02, -1.2378e-01,  1.1601e-01,\n",
      "           1.6292e-02,  1.2302e-01, -7.3888e-02,  1.0611e-01,  7.0711e-02,\n",
      "          -2.0141e-02,  5.2232e-02,  2.4798e-01, -1.1894e-01, -1.2184e-01,\n",
      "          -1.3771e-01, -1.0310e-02, -2.8096e-02, -9.9788e-02, -3.1950e-02,\n",
      "           1.1036e-01, -4.1674e-01, -2.0975e-02, -2.7055e-02, -1.1280e-01,\n",
      "          -9.3653e-02, -3.6428e-02, -1.0286e-02, -1.4748e-01,  1.7339e-01,\n",
      "           1.0573e-02,  2.0942e-01,  1.1976e-01, -2.8168e-01, -1.1914e-01,\n",
      "           1.2203e-01,  3.6292e-02,  1.2607e-01,  5.4693e-02, -7.4700e-02,\n",
      "           1.4314e-01, -4.8795e-02, -7.1664e-02, -4.4132e-01,  1.9158e-01,\n",
      "           1.4405e-01, -6.4172e-02, -1.8355e-01,  7.0817e-02,  7.4049e-02,\n",
      "           1.3876e-01,  5.2169e-03,  3.1899e-02,  8.5912e-02,  1.1702e-01,\n",
      "           1.0358e-01, -8.2715e-02, -1.1499e-01,  3.7768e-02,  3.3053e-01,\n",
      "          -3.7094e-02, -6.0870e-02, -5.4052e-02, -2.2721e-02, -2.5399e-01,\n",
      "          -5.9533e-03, -9.6307e-02,  7.7649e-02,  9.7527e-02,  2.2441e-01,\n",
      "           3.4831e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7784, -1.6518, -0.1831, -0.7320,  2.5183, -1.9078,\n",
      "          -0.0322,  0.9501,  0.0000,  1.4101, -0.7570, -0.0650,  0.0644,\n",
      "           1.0464,  0.0000,  0.0000, -0.7845, -0.6402, -1.4033, -0.4984,\n",
      "          -0.3792,  1.1427,  0.2330,  0.1891, -0.6129,  1.4038,  0.0000,\n",
      "          -1.0407,  0.4962, -0.5713,  0.6011, -1.6986,  0.2318,  0.0000,\n",
      "           0.1484,  0.6450, -2.2130,  1.0517,  0.1024, -0.6919, -0.4360,\n",
      "          -1.0640,  0.8179, -0.6326,  0.0000,  1.3726,  0.9364,  0.0000,\n",
      "           0.0000, -1.0081, -1.1723, -1.1126,  1.2530,  0.0000,  1.7089,\n",
      "           0.5930, -1.8923,  0.3414, -0.2938, -0.7703,  1.8691, -0.5939,\n",
      "          -1.6814, -0.8354,  1.2345, -0.3573,  0.2901, -0.7529, -1.1646,\n",
      "           2.2476,  0.7806,  0.0000,  1.2051, -0.3985,  0.0000,  0.2298,\n",
      "          -0.1575, -0.9149,  0.2960, -0.1448,  0.0000,  0.4654,  1.2970,\n",
      "           0.7706,  0.6606,  1.0454, -0.3681, -1.2411, -1.4363,  1.3105,\n",
      "          -1.5854, -0.1110,  3.2387,  0.3469,  1.0034, -0.8684,  0.7314,\n",
      "          -1.6815, -0.9244,  0.1907,  0.0287, -0.5967,  1.0585, -0.2309,\n",
      "           0.7758, -0.9058, -0.3680,  0.0000, -0.5477,  0.0000, -3.2785,\n",
      "          -0.1009, -1.8785,  1.6976,  1.6882,  2.0294, -1.6459, -0.8964,\n",
      "           2.5842, -1.3263,  1.4237, -0.6274,  0.4670,  0.0000, -0.9868,\n",
      "           0.0736, -0.9853, -0.6748,  0.0000,  0.0000,  1.1299,  1.1406,\n",
      "           1.4884,  0.3786,  0.6465,  0.0000,  0.2416,  0.3445, -1.2616,\n",
      "           0.0306,  0.8637,  0.5016,  0.9070, -1.2681,  0.0000, -0.4417,\n",
      "           0.8728, -0.0675,  0.0425,  0.0000,  0.6208,  0.1452, -0.1962,\n",
      "           0.0000, -1.6722, -0.4025,  0.2514, -2.0697,  0.0000,  1.1555,\n",
      "           0.1994,  0.9131,  0.8434,  0.4177,  0.0000,  0.1772, -1.1144,\n",
      "          -0.3224,  0.2510,  0.4444,  0.0000,  0.4446, -1.3451,  1.7354,\n",
      "           0.5172,  1.1775,  0.2897, -1.8322, -1.8661,  0.2595, -0.6474,\n",
      "          -1.1657,  0.3291, -0.7441,  0.5922,  0.0000, -1.5174, -2.3036,\n",
      "           0.1466, -1.6242, -1.3207, -0.0498,  1.2994,  0.9802, -1.4146,\n",
      "          -1.1401,  3.0139, -0.2259,  1.0331,  0.0290,  0.1194, -1.3193,\n",
      "          -1.0708,  0.0567,  1.7329,  0.5270,  1.9821, -0.9788, -1.3423,\n",
      "           1.5993, -0.4015,  2.4607, -0.5200,  0.7545,  0.2065, -0.8208,\n",
      "           0.0000, -3.5298,  0.1757, -0.7815,  0.0000,  0.0000,  0.2511,\n",
      "          -0.0646,  0.0000,  0.4266, -0.5195,  0.0465, -0.6251, -0.0712,\n",
      "           0.7485, -2.0270, -1.0490, -0.4312, -0.1124,  0.5162, -2.7968,\n",
      "          -1.4578, -0.6646,  1.0259,  0.1329,  2.7507,  1.0027,  0.5472,\n",
      "          -0.1735, -1.5055,  2.2320,  0.0000, -0.0478,  0.7226,  0.0000,\n",
      "           0.0000, -0.0138,  0.0000, -0.5807]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0503, 0.1845, 0.1264, 0.0929, 0.0746, 0.0920, 0.0911, 0.0969, 0.1004,\n",
      "         0.0909]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.8029e-01, -2.6242e-02, -8.4156e-02,  9.7035e-02,  1.3052e-01,\n",
      "           7.4036e-02, -1.5796e-01, -1.6507e-02,  3.0226e-02,  8.9909e-02,\n",
      "          -5.4207e-02, -6.7521e-02,  7.6984e-02,  5.3595e-02,  6.4652e-02,\n",
      "          -4.2477e-02,  1.7649e-01, -3.2656e-02, -3.7594e-01,  6.1241e-03,\n",
      "          -2.0638e-01, -1.5749e-01, -1.7778e-01, -1.0425e-01, -1.5403e-01,\n",
      "          -8.4838e-02,  2.6303e-02, -1.3550e-01, -9.3436e-03, -1.1141e-01,\n",
      "           9.9004e-02,  7.3532e-02, -7.2979e-03, -3.9467e-02, -3.1115e-02,\n",
      "          -3.8198e-02, -2.1613e-02, -1.3591e-01, -1.0002e-02, -1.5920e-01,\n",
      "           8.7862e-02,  1.5808e-01,  1.7675e-01,  7.1297e-02,  1.5412e-01,\n",
      "           6.2503e-02,  1.7803e-01,  1.8302e-02,  1.5623e-01, -3.9196e-02,\n",
      "           9.6633e-02, -3.5681e-01,  5.0122e-02, -2.7643e-02, -8.1397e-02,\n",
      "           6.0718e-02, -1.1567e-02,  3.8276e-02,  1.6701e-01,  1.5764e-01,\n",
      "           1.7264e-01, -7.8747e-02, -1.1171e-01, -8.5813e-02, -1.9790e-01,\n",
      "          -1.0900e-01, -6.4487e-03,  1.6699e-01, -1.6206e-01, -1.1801e-01,\n",
      "          -1.1966e-01,  4.0664e-01, -2.0377e-01,  1.2498e-01, -2.4706e-01,\n",
      "           4.5780e-02,  1.8830e-01,  5.7361e-02, -4.0083e-02, -1.8373e-01,\n",
      "          -1.1784e-01, -8.2274e-02,  5.1220e-02, -8.2059e-02,  3.0958e-01,\n",
      "           1.3879e-01,  1.4033e-01,  5.6871e-02,  8.8657e-02,  1.7221e-01,\n",
      "           7.7085e-02,  1.0071e-01, -1.7249e-01, -7.5216e-03,  1.2515e-01,\n",
      "          -7.4063e-02,  2.2761e-01,  1.9428e-01, -6.4528e-04, -4.5450e-03,\n",
      "          -9.7187e-02, -2.2321e-02,  8.5077e-02, -9.4764e-02,  7.0010e-02,\n",
      "           1.7759e-02, -7.6257e-02, -6.6017e-02, -2.2383e-01,  1.4692e-01,\n",
      "          -1.5910e-01, -9.7824e-02, -1.7935e-01,  4.3427e-02,  3.1149e-02,\n",
      "          -8.8194e-02,  1.1982e-01, -1.4128e-01, -1.4669e-01,  7.1005e-02,\n",
      "           1.0259e-01, -1.0979e-01, -4.9653e-02,  8.9467e-02, -2.5756e-01,\n",
      "          -5.2079e-02,  2.1815e-01,  2.2313e-01,  3.6685e-01,  2.4793e-01,\n",
      "           6.5303e-03, -8.5031e-02,  1.6443e-01, -6.2606e-02, -3.6085e-03,\n",
      "          -1.4412e-01,  1.7003e-01, -7.7688e-02,  7.7044e-02, -3.6746e-02,\n",
      "          -3.1944e-02,  2.3968e-01,  3.1699e-03,  9.2020e-02,  8.4483e-02,\n",
      "           1.0446e-01,  4.5438e-03,  1.6231e-01, -4.2726e-02,  1.1549e-01,\n",
      "          -3.0690e-01, -8.3766e-02, -1.9121e-02,  2.3002e-01, -2.7478e-01,\n",
      "           1.7047e-01,  4.8039e-02,  2.0306e-01, -4.8566e-02,  2.5175e-01,\n",
      "          -2.6405e-04,  1.1130e-01, -4.8711e-03, -6.8528e-02, -2.6092e-01,\n",
      "          -1.3428e-01, -4.1037e-02, -1.2089e-01, -1.4058e-01,  2.1232e-01,\n",
      "           6.0840e-03, -2.1708e-01, -1.3581e-01,  1.6700e-01, -3.5538e-02,\n",
      "          -6.9241e-02,  2.5715e-01, -4.7574e-02,  1.1081e-01, -9.1392e-02,\n",
      "           1.8194e-02,  1.1185e-01, -3.2142e-01, -1.4743e-02,  7.8365e-02,\n",
      "          -3.1564e-02, -3.3016e-02,  1.0213e-01, -8.9492e-02,  7.8240e-02,\n",
      "           1.9466e-02,  9.6843e-02, -1.0107e-01,  7.3321e-02,  4.9544e-02,\n",
      "          -4.0291e-02,  4.0892e-02,  2.3143e-01, -8.8667e-02, -8.3868e-02,\n",
      "          -1.1944e-01,  9.4384e-03, -2.7452e-02, -7.9802e-02, -3.7496e-02,\n",
      "           9.9563e-02, -3.7831e-01,  5.7202e-03, -5.7629e-02, -9.3346e-02,\n",
      "          -7.2534e-02, -5.4149e-02, -2.6232e-02, -1.3074e-01,  1.5078e-01,\n",
      "           1.7506e-02,  1.9002e-01,  1.4022e-01, -3.1055e-01, -9.9173e-02,\n",
      "           1.3191e-01,  1.4188e-02,  1.2945e-01,  3.4538e-03, -8.2816e-02,\n",
      "           1.7511e-01, -2.1744e-02, -1.1640e-01, -4.1285e-01,  1.5119e-01,\n",
      "           9.2545e-02, -4.6766e-02, -1.5826e-01,  2.3971e-02,  3.8913e-02,\n",
      "           8.5789e-02, -3.6363e-02,  2.0106e-02,  9.0428e-02,  9.7315e-02,\n",
      "           9.7637e-02, -9.8894e-02, -1.7035e-01,  4.3444e-02,  3.0089e-01,\n",
      "          -2.7842e-02, -5.9114e-02, -5.6000e-02, -1.3924e-02, -2.0679e-01,\n",
      "          -8.2463e-03, -8.7598e-02,  5.4975e-02,  6.7250e-02,  2.0617e-01,\n",
      "           1.4460e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.4798e+00,  5.7474e-01,  2.6151e-01,  1.1218e+00,  8.2718e-01,\n",
      "           3.2554e+00,  1.8557e+00, -1.0503e+00, -3.7233e-01,  2.5080e-01,\n",
      "          -8.4956e-01, -9.5414e-01,  1.6613e-01,  2.0222e+00, -1.1885e+00,\n",
      "          -7.2519e-01, -1.3162e+00,  1.8456e-01, -3.8192e-01,  8.0153e-01,\n",
      "          -2.0771e+00, -3.1589e-01,  3.4928e-01,  1.1872e+00,  7.3103e-02,\n",
      "          -7.6533e-01,  3.2823e-01,  3.7459e-02, -8.4298e-02,  2.5544e+00,\n",
      "           1.2115e+00,  1.5403e+00,  5.4441e-02,  5.8780e-01,  1.2293e+00,\n",
      "          -1.7426e+00, -9.4669e-01,  9.7360e-01, -7.6841e-01,  6.3985e-01,\n",
      "          -2.5154e-01,  1.3886e+00, -1.2413e+00,  4.1836e-01, -4.8602e-01,\n",
      "           2.3051e+00,  4.8861e-01, -1.9832e-02, -1.6411e+00, -8.6326e-01,\n",
      "           9.0645e-01,  2.9671e-01, -4.4090e-01, -4.4976e-01,  8.3849e-01,\n",
      "          -1.5512e+00,  8.5110e-01,  3.0564e-01,  2.1470e-01, -7.6751e-01,\n",
      "           2.1112e-01, -3.0148e-02,  2.3290e-02,  0.0000e+00, -1.5368e-01,\n",
      "           1.5452e+00,  0.0000e+00, -1.0463e+00, -7.8486e-01,  0.0000e+00,\n",
      "          -9.1096e-01, -1.7390e+00, -1.2453e-02,  9.1633e-01, -7.5280e-01,\n",
      "           2.0773e-01,  0.0000e+00,  1.7125e+00,  0.0000e+00,  1.6674e-01,\n",
      "           0.0000e+00,  2.8854e+00, -2.8159e-01, -1.8816e-01, -1.6392e+00,\n",
      "          -8.3831e-02,  1.2496e+00,  0.0000e+00,  0.0000e+00, -3.5327e+00,\n",
      "          -2.3312e-01,  2.2898e+00, -8.6689e-01, -1.3390e-01, -8.5871e-01,\n",
      "           9.4221e-01,  0.0000e+00, -2.2977e+00, -9.1420e-01,  3.4625e-01,\n",
      "           7.3459e-01, -1.2997e+00, -1.1103e+00, -9.7073e-01,  1.3524e+00,\n",
      "          -1.2140e+00, -5.0676e-02,  1.2830e+00,  1.6289e+00, -1.1977e+00,\n",
      "          -2.4155e-01, -4.3165e-01,  5.4817e-01,  1.2830e+00,  7.0576e-01,\n",
      "           1.2969e+00, -6.0205e-01,  1.0030e+00, -9.5386e-01,  1.2136e-01,\n",
      "           0.0000e+00, -9.2329e-02, -2.2894e+00, -8.9074e-01, -1.5041e+00,\n",
      "          -9.9449e-01,  0.0000e+00,  2.6034e-01,  2.9576e-01, -5.1863e-01,\n",
      "          -1.8473e-01,  1.7495e+00, -5.7555e-01, -7.9324e-01,  1.2943e-01,\n",
      "           3.7446e-01,  9.7764e-01,  1.1082e-01, -4.6486e-01,  0.0000e+00,\n",
      "          -2.1754e-01,  2.2633e+00,  4.2365e-01,  1.8558e+00,  1.1416e-01,\n",
      "           5.0873e-02,  3.6983e-03, -4.2921e-01, -2.7517e-01, -1.7890e-01,\n",
      "           1.7388e+00,  5.3901e-01, -9.6624e-01, -5.9885e-01, -3.4735e-01,\n",
      "          -4.8396e-01,  1.3695e-01,  1.4581e+00,  4.4825e-01,  1.0713e-01,\n",
      "          -4.0652e-01,  7.4943e-01,  2.4095e+00, -8.6325e-01,  3.7641e+00,\n",
      "          -5.4311e-01, -1.0611e+00,  1.2871e+00, -9.2703e-01,  1.1908e+00,\n",
      "          -1.1619e+00,  4.3242e-01, -3.6384e-01, -1.2688e+00,  4.1872e-01,\n",
      "          -6.6506e-01,  2.8995e-01,  8.0646e-01, -1.0966e+00, -2.1590e-01,\n",
      "           1.2736e+00, -7.5579e-01, -5.3087e-01,  0.0000e+00,  0.0000e+00,\n",
      "           3.9454e+00, -8.8329e-01,  1.2293e+00, -2.7600e-01,  5.2012e-01,\n",
      "          -9.9987e-01,  9.7692e-01, -9.9505e-01, -1.0391e-01,  2.4750e-01,\n",
      "          -2.7037e+00,  1.8139e+00,  1.7745e+00, -3.5693e-01, -1.3530e-01,\n",
      "          -4.7530e-01,  8.4498e-02,  3.7090e-02,  8.5960e-01,  2.2948e-01,\n",
      "          -4.9989e-02, -1.5247e+00,  0.0000e+00,  0.0000e+00,  3.7950e-01,\n",
      "           1.0843e+00,  4.1975e-01,  8.2106e-01,  1.9242e+00,  2.7040e-01,\n",
      "           7.7184e-01,  9.4970e-01, -3.8372e-01,  7.5055e-01,  1.3530e-01,\n",
      "           5.1711e-01,  1.1969e+00,  4.1590e-01,  6.2989e-01, -1.3609e+00,\n",
      "          -1.2798e+00,  0.0000e+00, -8.8295e-01, -3.4782e-01,  3.8996e+00,\n",
      "           0.0000e+00,  1.6093e+00, -8.6289e-01, -4.6863e-01, -2.7074e-01,\n",
      "          -4.1138e-01,  7.5251e-01,  1.5082e-02,  2.6987e+00,  2.4599e+00,\n",
      "          -2.1021e+00, -1.4118e+00,  1.8735e+00,  8.8813e-01,  0.0000e+00,\n",
      "           1.0690e+00,  5.7138e-01,  1.1434e-01,  1.0209e+00,  1.4518e+00,\n",
      "          -3.2913e-01,  1.5153e+00, -1.1415e+00, -1.2750e+00, -4.8211e-02,\n",
      "          -1.0210e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1986, 0.0887, 0.0453, 0.0834, 0.1050, 0.1506, 0.0973, 0.0493, 0.0555,\n",
      "         0.1262]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1961, -0.0605, -0.0569,  0.0589,  0.1440,  0.0685, -0.1629,\n",
      "          -0.0123, -0.0159,  0.0657, -0.0125, -0.0982,  0.1122,  0.0688,\n",
      "           0.0998, -0.0478,  0.1756, -0.0222, -0.3052,  0.0295, -0.1886,\n",
      "          -0.1806, -0.1865, -0.0556, -0.1845, -0.0369,  0.0118, -0.1396,\n",
      "           0.0223, -0.1535,  0.1488,  0.0656,  0.0562, -0.0697, -0.0515,\n",
      "          -0.0730,  0.0933, -0.0933,  0.0856, -0.1711,  0.1032,  0.1469,\n",
      "           0.1734,  0.0225,  0.2019,  0.0395,  0.1961,  0.0129,  0.1452,\n",
      "          -0.0387,  0.1042, -0.3492,  0.0104, -0.0210, -0.0372,  0.0058,\n",
      "          -0.0720,  0.0006,  0.1676,  0.1113,  0.1965, -0.0909, -0.1902,\n",
      "          -0.0634, -0.2194, -0.0541, -0.0315,  0.2163, -0.1702, -0.0823,\n",
      "          -0.1820,  0.4300, -0.1081,  0.0335, -0.2444,  0.0813,  0.1413,\n",
      "           0.0605, -0.0934, -0.1480, -0.0680,  0.0042,  0.0779, -0.0600,\n",
      "           0.3027,  0.1276,  0.1291,  0.0505,  0.1187,  0.1499,  0.1081,\n",
      "           0.1624, -0.2010,  0.0009,  0.0738, -0.0980,  0.2176,  0.1900,\n",
      "           0.0569, -0.0726,  0.0035,  0.0124, -0.0298, -0.0424,  0.1457,\n",
      "           0.0940, -0.1415,  0.0117, -0.2593,  0.1718, -0.1142, -0.1102,\n",
      "          -0.2124,  0.0062,  0.0118, -0.0631,  0.1707, -0.1100, -0.1438,\n",
      "           0.0688,  0.0374, -0.0989,  0.0096,  0.1118, -0.2481, -0.0148,\n",
      "           0.1608,  0.2418,  0.3644,  0.1918,  0.0312, -0.0810,  0.1266,\n",
      "          -0.0401,  0.1423, -0.1093,  0.1347, -0.0910,  0.0144, -0.1216,\n",
      "          -0.0693,  0.2572, -0.0491,  0.0561,  0.0585,  0.1712, -0.0591,\n",
      "           0.2000, -0.0191,  0.1718, -0.3056, -0.1025, -0.0439,  0.1605,\n",
      "          -0.2442,  0.1434,  0.0546,  0.2233, -0.0909,  0.2426, -0.0581,\n",
      "           0.0750, -0.0128, -0.0968, -0.3067, -0.0995, -0.0449, -0.0496,\n",
      "          -0.1783,  0.2046,  0.0364, -0.1808, -0.0903,  0.1776,  0.0089,\n",
      "          -0.0239,  0.2903, -0.0474,  0.1412, -0.0035,  0.0717,  0.0923,\n",
      "          -0.3163,  0.0385,  0.0815, -0.0169, -0.0351,  0.0502, -0.1640,\n",
      "           0.1541, -0.0069,  0.1233, -0.1145,  0.0809,  0.0112, -0.0261,\n",
      "          -0.0015,  0.2397, -0.0940, -0.0782, -0.0827,  0.0173,  0.0114,\n",
      "          -0.1060, -0.1518,  0.0751, -0.4114, -0.0327, -0.0167, -0.0433,\n",
      "          -0.1165,  0.0097, -0.0248, -0.0785,  0.1678,  0.0242,  0.1788,\n",
      "           0.1186, -0.2525, -0.1544,  0.1449,  0.0468,  0.1818, -0.0294,\n",
      "          -0.0785,  0.0857, -0.0730, -0.0619, -0.4241,  0.1819,  0.2147,\n",
      "          -0.0504, -0.2144,  0.1392,  0.0604,  0.1195, -0.0429,  0.0689,\n",
      "           0.1082,  0.1423,  0.0894, -0.1673, -0.0856,  0.0617,  0.2732,\n",
      "          -0.0219, -0.0029, -0.0988, -0.0051, -0.2653,  0.0105, -0.0656,\n",
      "           0.1013,  0.0466,  0.1937, -0.0337]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5730e+00,  7.8530e-01, -6.3271e-01, -3.0266e-01, -1.3593e+00,\n",
      "          -6.1294e-01,  6.0134e-01,  3.3400e-01,  6.8118e-01, -5.3697e-01,\n",
      "           4.0949e-01,  0.0000e+00, -1.7655e+00,  1.3916e+00,  9.8144e-01,\n",
      "           1.2538e-01, -2.5703e-01,  7.5016e-01,  0.0000e+00,  7.2881e-02,\n",
      "           7.2210e-01,  1.8782e-01,  7.7774e-01, -2.3323e-03,  4.0906e-01,\n",
      "           0.0000e+00,  1.2431e+00, -6.5880e-01,  0.0000e+00,  2.9415e-01,\n",
      "          -1.4795e+00, -1.1651e+00, -3.7515e-01,  0.0000e+00,  5.0531e-01,\n",
      "           1.6571e+00, -1.4002e+00,  9.0882e-01, -2.2073e-02,  7.3768e-01,\n",
      "          -5.5495e-01,  1.2113e-01,  1.2179e-02,  2.0672e-01, -8.1026e-01,\n",
      "          -7.5992e-01,  0.0000e+00, -2.7384e-01, -1.1653e+00,  2.0403e-01,\n",
      "          -2.3106e+00, -1.4554e-02, -1.1464e-03, -6.3929e-01, -1.3068e+00,\n",
      "           7.5600e-01,  1.0541e+00, -1.5647e+00,  4.9339e-01,  1.0325e+00,\n",
      "           3.5792e-02, -5.1839e-01, -8.0914e-01, -9.1935e-01,  1.9692e+00,\n",
      "           0.0000e+00, -8.5696e-01,  0.0000e+00, -4.9645e-01,  6.2169e-01,\n",
      "           7.8027e-01, -1.2184e-01, -4.7817e-01,  0.0000e+00,  5.5159e-03,\n",
      "           1.7745e+00,  1.8835e+00, -1.1991e-02,  5.1312e-01, -7.6207e-02,\n",
      "           3.4341e-01,  1.2539e+00,  0.0000e+00,  2.8827e+00, -1.5894e+00,\n",
      "           1.2817e+00,  1.0019e+00, -9.7274e-01,  7.2167e-01, -7.5173e-01,\n",
      "           1.6864e+00, -5.1075e-01, -1.0354e+00, -1.0249e+00, -2.7459e-01,\n",
      "          -1.4301e+00,  5.8782e-03, -1.4764e+00,  5.5488e-01,  0.0000e+00,\n",
      "           5.0218e-01, -7.9358e-01, -2.4270e+00, -1.3147e+00, -9.1942e-02,\n",
      "          -8.3112e-01, -1.7781e-01, -1.4729e+00, -6.8600e-01, -1.8141e+00,\n",
      "           1.5226e+00,  1.2834e+00,  7.2208e-01,  1.0284e+00,  7.7740e-01,\n",
      "           1.5975e+00,  6.2010e-01, -7.8021e-01, -5.5606e-01,  0.0000e+00,\n",
      "           7.1941e-01, -6.1044e-01, -1.3884e-01,  6.9992e-01,  1.4698e-01,\n",
      "          -5.7326e-01,  1.7843e+00, -6.1826e-01,  1.2172e+00, -2.1048e-01,\n",
      "          -2.5314e-01,  1.1772e-01, -4.7463e-01, -1.5363e+00,  1.3405e+00,\n",
      "           2.4302e-01,  8.8499e-01,  1.1779e+00, -6.4858e-01,  0.0000e+00,\n",
      "           1.2408e+00, -7.5345e-01,  1.2367e+00, -4.7743e-01, -6.9220e-01,\n",
      "          -3.5429e-01,  6.4104e-01, -6.5590e-01,  6.5532e-03,  4.0687e-01,\n",
      "          -9.8994e-01,  7.2538e-01, -4.6090e-01,  0.0000e+00,  5.8845e-01,\n",
      "          -8.1069e-01,  0.0000e+00, -9.1108e-01,  0.0000e+00,  1.9997e+00,\n",
      "           6.7347e-02,  5.9931e-01,  2.0007e-01, -9.0085e-01,  1.2113e+00,\n",
      "          -9.0157e-01, -1.3809e+00, -1.4390e-01,  0.0000e+00, -7.2253e-01,\n",
      "           6.6554e-01, -1.3620e+00,  1.2651e+00, -6.9504e-01, -9.8777e-01,\n",
      "           1.7756e+00, -8.4804e-01, -4.3152e-01, -3.7339e-01,  1.6946e+00,\n",
      "          -1.4651e+00, -5.9967e-01,  2.2689e+00,  2.4059e-01, -2.6466e+00,\n",
      "          -2.2273e-01,  5.4838e-01,  4.8541e-01, -4.0706e-01,  4.2219e-01,\n",
      "          -1.3379e+00,  0.0000e+00, -1.5128e+00,  0.0000e+00, -7.6985e-01,\n",
      "          -4.3928e-01,  2.7334e-01,  5.2827e-01,  3.8532e-01, -1.9406e+00,\n",
      "          -7.8172e-01, -9.5155e-01, -1.3876e+00, -1.0014e+00, -8.1115e-01,\n",
      "          -2.5609e-02,  5.7344e-01, -2.0933e-01,  0.0000e+00,  2.4376e+00,\n",
      "          -1.9343e-01,  5.6522e-01,  8.8636e-02, -4.8518e-02,  1.4956e+00,\n",
      "           0.0000e+00,  8.3917e-01,  1.1116e-02, -7.1432e-01,  1.5618e-01,\n",
      "           1.0334e+00,  2.2480e+00,  9.3530e-01,  0.0000e+00, -1.2135e+00,\n",
      "          -1.6839e-01, -8.3197e-01, -1.4654e+00,  1.3471e+00,  2.0868e-01,\n",
      "          -5.9804e-01,  0.0000e+00, -8.3108e-02, -1.0610e+00, -1.4467e+00,\n",
      "          -1.6250e+00, -1.3359e+00,  1.7484e+00,  0.0000e+00, -1.2872e+00,\n",
      "           0.0000e+00,  0.0000e+00, -1.0109e+00, -1.1053e+00, -2.9537e-01,\n",
      "          -9.4233e-01, -2.1632e+00, -8.3079e-02,  8.0245e-01,  6.4544e-01,\n",
      "           1.3655e+00,  1.7718e-02, -8.3641e-01,  1.2593e+00,  1.1477e+00,\n",
      "           1.2458e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0691, 0.1124, 0.1908, 0.1027, 0.0535, 0.1114, 0.1374, 0.0968, 0.0790,\n",
      "         0.0469]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2185, -0.0467, -0.1292,  0.0826,  0.0961,  0.0443, -0.1714,\n",
      "          -0.0352, -0.0227,  0.0924, -0.0601, -0.0838,  0.0717,  0.0723,\n",
      "           0.0863, -0.0855,  0.1605, -0.0046, -0.4032,  0.0078, -0.2248,\n",
      "          -0.2152, -0.1939, -0.1121, -0.1749, -0.0572,  0.0493, -0.1598,\n",
      "          -0.0289, -0.1018,  0.1397,  0.0565, -0.0151, -0.0756, -0.0248,\n",
      "          -0.0375,  0.0087, -0.1782,  0.0071, -0.1418,  0.0889,  0.1903,\n",
      "           0.1946,  0.0928,  0.0976,  0.1091,  0.1598, -0.0148,  0.1673,\n",
      "          -0.0422,  0.1323, -0.3762,  0.0307, -0.0264, -0.0838,  0.0839,\n",
      "          -0.0074,  0.0338,  0.1799,  0.1382,  0.1968, -0.1062, -0.1389,\n",
      "          -0.1048, -0.2307, -0.1321, -0.0642,  0.2361, -0.2082, -0.1061,\n",
      "          -0.1594,  0.4554, -0.1704,  0.1368, -0.2483,  0.0873,  0.2132,\n",
      "           0.0667, -0.0408, -0.1886, -0.0780, -0.0381,  0.0360, -0.1127,\n",
      "           0.3471,  0.1640,  0.1593,  0.0921,  0.1354,  0.1709,  0.1154,\n",
      "           0.1153, -0.2089, -0.0071,  0.1335, -0.1096,  0.2359,  0.2123,\n",
      "           0.0359, -0.0096, -0.0871, -0.0210,  0.0879, -0.1289,  0.1079,\n",
      "           0.0252, -0.1042, -0.0429, -0.2399,  0.1812, -0.1647, -0.1072,\n",
      "          -0.2108,  0.0399, -0.0230, -0.0657,  0.1252, -0.1413, -0.2032,\n",
      "           0.1222,  0.0909, -0.1324, -0.1010,  0.1233, -0.2827, -0.0759,\n",
      "           0.2091,  0.2249,  0.3689,  0.2402,  0.0265, -0.1024,  0.1492,\n",
      "          -0.0370,  0.0100, -0.1440,  0.1426, -0.0597,  0.0627, -0.0208,\n",
      "          -0.1022,  0.2433, -0.0664,  0.0476,  0.1351,  0.0782, -0.0303,\n",
      "           0.1862, -0.0175,  0.1542, -0.3524, -0.0620, -0.0720,  0.2389,\n",
      "          -0.2894,  0.1759,  0.0509,  0.1884, -0.0864,  0.2656, -0.0145,\n",
      "           0.1146,  0.0099, -0.0730, -0.3072, -0.1481, -0.0345, -0.1413,\n",
      "          -0.1067,  0.1742, -0.0150, -0.2010, -0.1499,  0.1744, -0.0890,\n",
      "          -0.1158,  0.3210, -0.0645,  0.1201, -0.1127,  0.0034,  0.1296,\n",
      "          -0.3404, -0.0136,  0.1140, -0.0393, -0.0396,  0.1332, -0.1209,\n",
      "           0.1153,  0.0086,  0.1380, -0.1090,  0.0801,  0.0498, -0.0910,\n",
      "           0.0228,  0.2401, -0.0894, -0.1089, -0.1352,  0.0132, -0.0505,\n",
      "          -0.1120, -0.0389,  0.1002, -0.4409, -0.0070, -0.0878, -0.1394,\n",
      "          -0.1414, -0.0174, -0.0132, -0.1078,  0.1730,  0.0412,  0.1728,\n",
      "           0.1343, -0.3398, -0.1263,  0.1454,  0.0236,  0.1113,  0.0133,\n",
      "          -0.0943,  0.1622, -0.0434, -0.1412, -0.4454,  0.1493,  0.1414,\n",
      "          -0.0302, -0.2044,  0.0288,  0.0481,  0.1132, -0.0375,  0.0450,\n",
      "           0.1236,  0.0866,  0.0861, -0.1170, -0.1546,  0.0657,  0.3096,\n",
      "          -0.0399, -0.0339, -0.0182,  0.0214, -0.2255,  0.0048, -0.1285,\n",
      "           0.0582,  0.0670,  0.2507,  0.0042]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.9315,  0.1981, -0.2680, -1.3968, -0.3499, -0.3723,  1.7075,\n",
      "          -0.8761,  0.4782, -1.2750, -0.4438,  0.8219,  0.0000, -0.3214,\n",
      "          -0.8350, -2.5098,  0.0065, -1.2705,  0.0000, -0.2902,  1.9490,\n",
      "           0.0000, -0.3320,  0.1981,  1.0460, -1.8537,  1.0810,  2.2839,\n",
      "          -1.9148,  0.4416, -0.5964,  0.0000, -0.7381,  0.5314,  0.0000,\n",
      "          -0.0068, -0.8335,  1.1430,  0.0000, -0.9542,  0.9392, -1.0912,\n",
      "          -1.9415,  0.5654,  0.0000,  0.2745,  0.3612,  1.6242, -1.3950,\n",
      "          -0.1441, -0.6361,  2.6879, -0.3790,  1.2495,  0.6295, -0.0790,\n",
      "           0.4047, -0.1979, -1.3494,  0.8814, -0.8591,  0.7192,  0.0000,\n",
      "           0.0000,  0.0000, -0.5013, -0.6768, -1.2385,  0.8278,  0.8240,\n",
      "          -3.3864, -0.4960,  0.5760, -2.2835,  1.6890, -1.3260,  1.1522,\n",
      "           0.2235, -0.7942,  0.0000, -0.2928,  0.7020,  0.7053, -0.5358,\n",
      "           0.8953, -0.1617,  0.1717,  0.5598, -1.7795, -0.3739, -1.5225,\n",
      "           1.5001,  0.4649, -0.2346,  0.0000,  1.3259, -0.6385,  2.1260,\n",
      "          -0.3409, -1.4912,  1.7553,  0.2136,  0.0000, -1.5479, -0.5421,\n",
      "           0.9556, -0.6681,  0.0000,  0.7863, -1.1940,  0.2063,  0.9912,\n",
      "          -0.7843, -0.8377, -0.0706, -0.1670,  0.0037, -1.4357, -0.2772,\n",
      "          -1.3750,  0.7376, -0.0540,  0.0213,  0.7269, -1.1064,  0.5140,\n",
      "           0.5383,  0.0000,  0.0000, -0.1410, -0.1132,  2.2817,  2.1683,\n",
      "           0.9354, -0.4084, -1.7017, -0.6360, -0.6852,  1.0649, -1.0624,\n",
      "           0.8270,  0.0000,  0.1861,  0.3011, -1.5468,  1.8178,  0.0000,\n",
      "          -1.6344, -1.8230,  0.5117, -0.8196,  1.5853, -0.2376,  0.4122,\n",
      "           0.9909, -0.5231, -0.0049, -0.8740, -1.2409,  0.0295, -0.5586,\n",
      "           0.0000, -0.6405,  1.7026, -1.7233,  0.0044, -1.2761, -1.5286,\n",
      "          -0.8302,  0.1230,  0.3193,  0.2626,  1.1056,  0.0000, -0.3618,\n",
      "           1.6512,  0.5925, -1.9771, -0.5420,  0.0000, -0.6069,  0.0000,\n",
      "          -0.1304, -2.1726, -0.3383,  0.9141,  1.0245,  0.2687,  0.0000,\n",
      "           0.4476,  0.8045,  1.0675,  0.0000,  0.8617,  0.2644, -0.3627,\n",
      "           2.3427, -2.2177,  3.1499,  0.0000, -0.1076, -0.1361, -0.8005,\n",
      "          -0.3647,  0.0167,  1.3158, -0.8852,  2.2652, -0.4025,  0.0000,\n",
      "          -0.7987,  0.1993,  0.8976,  1.6769,  0.5182, -1.7108,  0.7682,\n",
      "          -0.1998,  0.8788,  0.0000, -0.8521,  0.5221, -1.7924, -0.4366,\n",
      "          -0.1453, -0.6457,  0.0000, -0.7716, -0.2921, -1.3556,  1.2316,\n",
      "           0.0945, -0.4452, -0.8003,  0.8565, -0.2116,  0.4861, -0.4862,\n",
      "           0.9430,  0.3053,  0.3702, -1.5032,  0.0000,  1.2463, -1.3652,\n",
      "           1.6558, -0.2695, -1.4752, -0.7018,  0.0647, -0.2810, -1.4217,\n",
      "          -1.0864,  0.8887, -0.9786, -1.8455]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1552, 0.0525, 0.1176, 0.1516, 0.0738, 0.1093, 0.1286, 0.0503, 0.0851,\n",
      "         0.0758]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0189e-01, -8.6359e-02, -9.0705e-02,  5.7971e-02,  1.1427e-01,\n",
      "           4.0320e-02, -1.6260e-01, -5.6544e-02, -4.0908e-02,  6.5718e-02,\n",
      "          -5.7070e-02, -9.1432e-02,  8.2449e-02,  4.4942e-02,  1.1960e-01,\n",
      "          -7.3918e-02,  1.5572e-01,  1.1215e-02, -3.3925e-01,  3.5231e-02,\n",
      "          -1.9019e-01, -1.9867e-01, -1.6352e-01, -7.1439e-02, -1.5856e-01,\n",
      "          -7.2017e-04,  3.1845e-02, -1.4589e-01, -1.1143e-02, -1.0592e-01,\n",
      "           1.3351e-01,  3.3470e-02, -9.8015e-03, -1.0154e-01, -3.4794e-02,\n",
      "          -9.2144e-02,  7.9805e-02, -1.4062e-01,  9.1473e-02, -1.5144e-01,\n",
      "           1.1288e-01,  1.8748e-01,  1.9677e-01,  7.8290e-02,  1.1487e-01,\n",
      "           8.4131e-02,  1.9138e-01, -2.3616e-02,  1.6475e-01, -6.0931e-02,\n",
      "           1.7174e-01, -3.2095e-01,  4.8882e-03, -1.5670e-02, -4.7470e-02,\n",
      "           6.5043e-02, -5.0750e-02,  4.4907e-03,  1.8606e-01,  1.1629e-01,\n",
      "           1.9558e-01, -9.6730e-02, -1.7604e-01, -9.7671e-02, -2.3216e-01,\n",
      "          -9.7486e-02, -3.4735e-02,  2.3929e-01, -1.6945e-01, -9.7648e-02,\n",
      "          -1.8921e-01,  4.3506e-01, -1.2383e-01,  1.0249e-01, -2.2421e-01,\n",
      "           9.6006e-02,  1.8787e-01,  7.9544e-02, -6.6807e-02, -1.5719e-01,\n",
      "          -6.4470e-02, -1.4282e-02,  7.9432e-02, -8.8830e-02,  3.2922e-01,\n",
      "           1.4440e-01,  1.3551e-01,  4.2817e-02,  1.4041e-01,  1.5592e-01,\n",
      "           1.2154e-01,  1.2479e-01, -2.1628e-01, -4.8535e-03,  1.2776e-01,\n",
      "          -1.1361e-01,  2.2197e-01,  1.5855e-01,  7.1367e-02, -5.1893e-02,\n",
      "          -3.1472e-02,  1.8553e-02,  6.7489e-04, -8.2028e-02,  1.5301e-01,\n",
      "           4.6337e-02, -1.6017e-01, -2.1393e-02, -2.5997e-01,  1.5804e-01,\n",
      "          -1.5501e-01, -1.0889e-01, -2.4682e-01,  1.6932e-02, -8.9867e-03,\n",
      "          -6.5250e-02,  1.4564e-01, -9.1593e-02, -2.0231e-01,  1.4171e-01,\n",
      "           8.8347e-02, -1.0490e-01, -2.8229e-02,  1.0978e-01, -2.4714e-01,\n",
      "          -2.2663e-02,  1.5853e-01,  2.2632e-01,  3.4524e-01,  2.3159e-01,\n",
      "           2.0624e-02, -4.7452e-02,  1.3336e-01, -3.5939e-02,  9.7426e-02,\n",
      "          -1.4041e-01,  9.3159e-02, -6.9460e-02,  2.5196e-02, -8.1537e-02,\n",
      "          -1.0830e-01,  2.2933e-01, -9.9908e-02,  3.1739e-03,  1.0068e-01,\n",
      "           1.2132e-01, -4.4777e-02,  1.5808e-01,  1.7318e-02,  1.5890e-01,\n",
      "          -3.2666e-01, -6.7411e-02, -6.9052e-02,  1.4135e-01, -2.9336e-01,\n",
      "           1.6228e-01,  4.1254e-02,  2.2482e-01, -7.5779e-02,  2.5042e-01,\n",
      "          -3.1665e-02,  1.2930e-01,  1.2651e-02, -1.0359e-01, -3.1105e-01,\n",
      "          -9.9565e-02, -5.6624e-02, -8.9584e-02, -1.1978e-01,  1.5812e-01,\n",
      "          -3.4810e-02, -1.8439e-01, -1.0794e-01,  1.6212e-01, -8.1404e-02,\n",
      "          -6.5332e-02,  3.4695e-01, -8.9746e-02,  1.2672e-01, -6.4432e-02,\n",
      "           3.2626e-02,  8.7492e-02, -3.4891e-01,  4.4544e-03,  9.2183e-02,\n",
      "          -5.7123e-02, -2.3303e-02,  9.6582e-02, -1.9542e-01,  1.5161e-01,\n",
      "          -1.8413e-02,  1.6373e-01, -9.4331e-02,  7.8989e-02,  5.2396e-02,\n",
      "          -7.5581e-02, -4.9422e-02,  2.3930e-01, -1.1604e-01, -8.3983e-02,\n",
      "          -9.7663e-02, -4.9148e-03, -3.1745e-02, -1.1116e-01, -1.3257e-01,\n",
      "           9.8465e-02, -4.3000e-01, -3.3938e-02, -5.9402e-02, -6.9937e-02,\n",
      "          -1.2319e-01, -1.5629e-02, -3.7337e-02, -1.0748e-01,  1.8449e-01,\n",
      "           3.0596e-02,  1.7173e-01,  1.2406e-01, -2.9019e-01, -1.3705e-01,\n",
      "           1.5026e-01,  4.2550e-02,  1.3457e-01, -3.9257e-03, -9.9623e-02,\n",
      "           1.2491e-01, -6.7167e-02, -1.0375e-01, -4.3380e-01,  1.5057e-01,\n",
      "           2.1011e-01, -7.6551e-04, -2.1521e-01,  1.1424e-01,  5.5829e-02,\n",
      "           1.3746e-01, -4.8011e-02,  6.7961e-02,  1.3160e-01,  8.5715e-02,\n",
      "           7.7989e-02, -1.5754e-01, -1.0491e-01,  7.8591e-02,  2.7799e-01,\n",
      "          -2.0416e-02,  5.8246e-03, -6.2134e-02,  2.8097e-02, -2.4240e-01,\n",
      "           1.7731e-04, -1.0251e-01,  1.0246e-01,  4.5970e-02,  2.3358e-01,\n",
      "          -5.0012e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4292e+00,  1.2080e+00,  0.0000e+00,  0.0000e+00, -6.9396e-01,\n",
      "           7.3218e-01,  3.4447e+00,  2.1715e+00, -5.1738e-01,  0.0000e+00,\n",
      "          -1.7527e+00, -1.6483e+00,  4.0787e-01, -1.6263e+00, -7.0463e-01,\n",
      "           8.0871e-01,  9.2784e-04, -4.1694e-01,  8.5435e-01, -2.4287e-01,\n",
      "          -7.3096e-01,  1.4235e+00, -3.9937e-01,  1.4109e-01, -7.3649e-01,\n",
      "           6.9545e-01, -4.0028e-01,  4.7689e-01, -1.4252e-01, -1.1328e+00,\n",
      "          -3.9305e-01,  1.8407e+00,  1.5232e-01,  1.1740e-02, -1.3080e-01,\n",
      "          -1.9019e+00, -1.7573e+00, -1.9282e-01, -4.8682e-01, -1.1675e-01,\n",
      "          -4.4980e-02,  0.0000e+00, -9.6875e-02, -9.1830e-01,  6.0771e-01,\n",
      "           7.3098e-01, -2.4830e+00,  4.5994e-01,  1.4306e+00,  0.0000e+00,\n",
      "          -3.9197e-01,  1.0845e+00,  0.0000e+00,  1.3392e+00, -9.5384e-01,\n",
      "          -7.2948e-01, -2.0828e+00,  1.0601e+00,  9.5124e-01,  0.0000e+00,\n",
      "           2.3427e-02,  1.0908e-01, -1.0486e+00, -4.6741e-01, -1.0218e+00,\n",
      "          -1.0963e+00, -5.4275e-01,  8.9995e-01,  1.0766e+00, -4.9895e-01,\n",
      "          -3.8299e-01,  1.3740e+00,  2.6785e-01,  0.0000e+00,  3.0825e-01,\n",
      "           1.4130e-01, -1.8404e+00,  6.8918e-01, -8.9327e-01, -1.4996e-01,\n",
      "          -1.3409e+00,  1.5177e+00, -1.2653e+00,  2.2405e+00,  1.7002e+00,\n",
      "           0.0000e+00,  3.8395e-01, -7.2921e-03, -3.0023e-01, -6.2791e-01,\n",
      "           2.5973e+00, -1.4192e-01, -1.7494e+00, -7.9693e-01,  1.4785e+00,\n",
      "           5.2105e-01,  2.8282e+00,  8.9713e-01,  3.6072e+00,  1.5667e+00,\n",
      "           7.1957e-01, -2.8680e-01,  1.0117e+00, -9.7367e-03, -1.9877e+00,\n",
      "           2.6556e-01, -1.0213e+00, -1.2140e+00, -7.1060e-01,  9.2139e-01,\n",
      "           6.7410e-01, -3.2700e-01,  2.7382e-01, -8.7344e-02, -7.3733e-01,\n",
      "           1.8466e+00, -1.7537e+00, -8.6272e-01,  0.0000e+00, -3.1381e-01,\n",
      "          -1.2919e+00, -9.2682e-02, -7.0319e-02,  8.6532e-01, -1.1776e+00,\n",
      "           6.2110e-02,  6.3085e-01,  1.2931e-01,  1.2173e+00,  0.0000e+00,\n",
      "           3.8197e-01, -1.0394e-01, -7.5615e-01,  8.2225e-01, -2.4051e-01,\n",
      "           0.0000e+00,  8.8901e-01,  5.6194e-01, -1.4622e+00,  1.5521e-01,\n",
      "          -2.9137e-01, -2.3779e-01,  1.8256e+00, -8.7986e-01, -3.3531e-01,\n",
      "           1.5129e+00,  1.0750e+00,  8.1196e-01,  7.4952e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.0274e+00,  6.5381e-01, -1.1844e+00, -1.0411e+00,\n",
      "           2.0502e+00,  0.0000e+00, -7.9840e-01, -6.7033e-01,  3.7489e-01,\n",
      "          -1.4255e+00, -2.0203e-01,  1.0978e+00,  7.3720e-01,  2.3065e-01,\n",
      "           6.2290e-01, -7.7437e-01, -1.6640e+00,  2.3754e-01,  1.3301e+00,\n",
      "           1.1501e+00,  2.7801e-01, -1.7867e+00,  2.4560e-01,  1.9330e-01,\n",
      "           1.0533e+00, -8.9278e-01,  1.6159e+00,  2.5409e+00, -9.9090e-01,\n",
      "          -1.6619e+00, -2.2399e-01,  5.7717e-01,  1.1186e+00,  1.3507e+00,\n",
      "          -7.3746e-01,  1.5083e+00,  0.0000e+00, -1.2006e+00, -2.1254e+00,\n",
      "          -8.0013e-01,  8.1385e-01, -4.2017e-01, -8.9470e-01,  7.1819e-01,\n",
      "          -1.4232e-01,  1.0677e+00,  6.8379e-01,  0.0000e+00, -4.8528e-01,\n",
      "           1.9001e+00, -1.1439e+00,  1.4286e+00,  3.4572e-01, -1.3419e-01,\n",
      "           5.3000e-01,  7.6155e-01,  1.7791e+00, -3.4736e-01, -8.5105e-01,\n",
      "          -5.3780e-01, -2.4340e-01,  9.2225e-01, -2.6570e-01,  7.2851e-01,\n",
      "          -1.7462e+00, -1.5799e-01, -2.6661e-01,  2.0887e-01,  1.0303e+00,\n",
      "           3.9471e-01,  1.2763e-01, -1.2170e+00, -5.6340e-01,  0.0000e+00,\n",
      "           9.7838e-01,  2.5652e-01, -9.2322e-01,  1.8363e+00,  1.9218e-01,\n",
      "           1.1201e+00,  1.5441e+00, -2.6138e-01, -2.2040e+00, -2.2819e-02,\n",
      "          -5.6551e-01,  1.7090e-01,  0.0000e+00,  1.1061e+00, -6.2009e-01,\n",
      "           1.6880e-01,  0.0000e+00,  1.3164e-01, -6.3745e-01,  1.3647e+00,\n",
      "          -3.9684e-01,  6.6834e-01,  0.0000e+00,  1.3659e-01,  1.2186e+00,\n",
      "          -5.3169e-01, -2.1819e+00, -5.2126e-01,  4.3168e-01, -1.1545e-01,\n",
      "          -1.3090e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0847, 0.1948, 0.1483, 0.0853, 0.0632, 0.0476, 0.0736, 0.0577, 0.1200,\n",
      "         0.1247]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1705, -0.0271, -0.0495,  0.0886,  0.1333,  0.1032, -0.1761,\n",
      "          -0.0014,  0.0233,  0.1138, -0.0891, -0.0386,  0.0829,  0.0323,\n",
      "           0.0696,  0.0061,  0.1725, -0.0196, -0.3419, -0.0268, -0.1801,\n",
      "          -0.1207, -0.1931, -0.1181, -0.1397, -0.0996,  0.0369, -0.0833,\n",
      "          -0.0226, -0.0716,  0.0711,  0.0624, -0.0323, -0.0158, -0.0574,\n",
      "          -0.0806, -0.0219, -0.1216,  0.0210, -0.1448,  0.0995,  0.1347,\n",
      "           0.1499,  0.0507,  0.1297,  0.0233,  0.1977,  0.0536,  0.1450,\n",
      "          -0.0604,  0.1061, -0.3498,  0.0841, -0.0357, -0.1160,  0.0677,\n",
      "           0.0030,  0.0780,  0.1551,  0.1440,  0.1560, -0.0767, -0.0900,\n",
      "          -0.0687, -0.1562, -0.1114,  0.0122,  0.1003, -0.1647, -0.1320,\n",
      "          -0.1136,  0.3701, -0.2200,  0.0910, -0.2092,  0.0855,  0.1787,\n",
      "           0.0150, -0.0258, -0.1758, -0.1409, -0.0858,  0.0618, -0.0494,\n",
      "           0.2874,  0.1230,  0.1345,  0.0497,  0.0574,  0.1621,  0.0236,\n",
      "           0.1124, -0.1637,  0.0129,  0.1236, -0.0549,  0.2302,  0.1705,\n",
      "          -0.0384, -0.0092, -0.0778, -0.0365,  0.0732, -0.0605,  0.0474,\n",
      "           0.0301, -0.0793, -0.1129, -0.2081,  0.1248, -0.2009, -0.0887,\n",
      "          -0.1965,  0.0548,  0.0686, -0.0775,  0.1155, -0.1221, -0.1521,\n",
      "           0.0607,  0.1430, -0.1229, -0.0555,  0.0526, -0.2353, -0.0236,\n",
      "           0.1849,  0.1821,  0.3457,  0.2763, -0.0019, -0.0559,  0.1597,\n",
      "          -0.0714, -0.0030, -0.1427,  0.1393, -0.0291,  0.1475, -0.0130,\n",
      "          -0.0104,  0.1972,  0.0052,  0.0702,  0.0363,  0.0887,  0.0523,\n",
      "           0.1183, -0.0630,  0.0671, -0.2437, -0.0912,  0.0218,  0.1725,\n",
      "          -0.2693,  0.1706,  0.0583,  0.1925, -0.0190,  0.2274,  0.0095,\n",
      "           0.1556,  0.0062, -0.0596, -0.2458, -0.1214, -0.0408, -0.0816,\n",
      "          -0.1615,  0.1718, -0.0014, -0.1793, -0.1411,  0.1849, -0.0032,\n",
      "          -0.0675,  0.2515, -0.0672,  0.0679, -0.0891,  0.0373,  0.1222,\n",
      "          -0.2944, -0.0404,  0.0618, -0.0522,  0.0093,  0.0601, -0.0952,\n",
      "           0.0578,  0.0577,  0.0462, -0.0853,  0.0549,  0.0309,  0.0055,\n",
      "           0.0254,  0.2063, -0.0819, -0.0811, -0.1104, -0.0110, -0.0176,\n",
      "          -0.0568, -0.0546,  0.0761, -0.3320, -0.0145, -0.0642, -0.0392,\n",
      "          -0.0306, -0.0656, -0.0486, -0.1633,  0.1309, -0.0288,  0.1703,\n",
      "           0.1547, -0.3051, -0.1105,  0.1242,  0.0205,  0.1189,  0.0014,\n",
      "          -0.1248,  0.1964, -0.0139, -0.1181, -0.3874,  0.1012,  0.0629,\n",
      "          -0.0593, -0.1154,  0.0497,  0.0400,  0.0485, -0.0582,  0.0090,\n",
      "           0.0475,  0.0537,  0.1218, -0.0849, -0.1847,  0.0840,  0.2542,\n",
      "           0.0086, -0.0353, -0.0705, -0.0184, -0.1662, -0.0213, -0.0730,\n",
      "           0.0361,  0.0620,  0.1769, -0.0210]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7279e-01, -4.3056e-01,  3.1479e-01, -1.0845e+00, -1.1723e+00,\n",
      "           7.4194e-01, -1.9141e+00,  1.3514e+00,  0.0000e+00,  6.1741e-01,\n",
      "           1.9025e+00,  6.0240e-01,  0.0000e+00, -9.1592e-01, -3.1816e+00,\n",
      "          -6.8584e-02, -1.6329e+00, -9.4345e-01,  1.3609e+00, -1.4345e+00,\n",
      "          -1.4081e-01, -5.2317e-01, -1.1193e+00,  0.0000e+00, -7.5431e-02,\n",
      "           1.3912e+00, -6.1916e-01,  1.9965e+00,  1.2761e-01,  5.5376e-01,\n",
      "           9.1452e-01, -3.4670e-03,  2.2312e-01,  2.0151e+00, -6.3979e-02,\n",
      "           0.0000e+00, -1.1198e-01, -8.1795e-01,  3.1461e-01,  8.5277e-02,\n",
      "           8.6184e-01, -9.0010e-01,  1.0091e+00, -1.5630e+00,  1.9437e+00,\n",
      "          -2.9998e-01,  0.0000e+00, -6.0100e-01, -1.0205e+00,  1.1162e+00,\n",
      "          -1.3218e+00,  2.6764e+00,  6.6659e-01, -8.4649e-01,  0.0000e+00,\n",
      "          -3.0872e-01, -1.4343e+00, -9.6800e-02,  1.2746e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6167e-02, -2.8022e-01,  2.6583e-01, -6.2654e-02,\n",
      "           3.9444e-01,  5.7810e-01,  1.1648e+00,  1.5804e+00,  0.0000e+00,\n",
      "           4.2765e-01,  2.9653e-01, -3.1390e-02, -7.9771e-01, -2.1456e-01,\n",
      "           1.3923e-01,  5.2561e-01,  1.3985e+00,  1.0268e+00, -7.9278e-01,\n",
      "           7.5733e-01, -1.0060e+00,  7.5689e-01,  1.0587e+00, -1.2141e+00,\n",
      "          -1.1307e-01,  0.0000e+00,  0.0000e+00, -9.4473e-01, -1.9015e+00,\n",
      "           5.2892e-01,  9.8634e-01,  1.7013e+00,  9.4322e-01,  0.0000e+00,\n",
      "          -1.5898e-02,  3.5283e-01, -1.1753e+00,  1.3710e+00,  2.4476e+00,\n",
      "           2.4397e-01,  4.6144e-02, -4.6622e-01, -9.8939e-01,  1.6394e+00,\n",
      "          -1.0223e+00,  3.0283e+00,  6.1947e-01, -1.0214e-01, -1.2353e+00,\n",
      "           1.8980e-01, -5.0272e-01, -5.7013e-01,  0.0000e+00,  0.0000e+00,\n",
      "           6.3178e-01,  4.0416e-01,  2.2419e-01, -2.3273e+00,  0.0000e+00,\n",
      "          -8.1340e-01, -1.4100e+00, -1.8369e+00,  6.0340e-01, -9.5618e-01,\n",
      "          -1.9993e-01,  3.9046e-02,  2.1498e+00,  1.3962e+00, -2.0873e+00,\n",
      "          -9.2648e-01,  4.4946e-01, -1.1670e+00,  4.2508e-01, -4.6894e-01,\n",
      "          -7.4420e-01, -1.0649e+00, -9.7461e-01, -1.9450e-02,  2.3975e+00,\n",
      "           6.9841e-01, -1.1217e+00,  1.6915e+00, -1.4009e-01, -6.6928e-01,\n",
      "           3.4298e-02,  0.0000e+00,  4.2309e-01, -1.0328e+00, -9.5692e-02,\n",
      "           0.0000e+00,  5.8700e-01, -3.3913e-01,  6.5748e-01,  0.0000e+00,\n",
      "          -2.5235e-01, -2.1710e-01,  6.2322e-01, -2.3619e+00,  1.0554e+00,\n",
      "           3.0227e-01, -7.7638e-02,  1.5408e-01, -1.2114e+00, -2.1964e-02,\n",
      "           1.6816e+00,  1.8514e+00,  2.7043e-01, -1.2701e+00, -7.1353e-01,\n",
      "          -1.2242e+00, -1.0938e+00, -2.5899e+00,  5.0544e-01, -3.0577e+00,\n",
      "          -2.8698e-01,  4.9844e-01,  8.2927e-01,  3.1699e-01, -7.9274e-01,\n",
      "           2.7094e-01,  0.0000e+00,  1.0569e+00,  8.3811e-01, -4.0323e-01,\n",
      "           7.2680e-01,  5.9915e-01,  3.5924e-01,  8.4185e-01, -1.8295e+00,\n",
      "           1.3635e+00,  2.1587e+00,  3.3714e-01, -1.0150e+00, -1.1710e+00,\n",
      "          -2.2148e+00,  1.6653e+00,  2.1523e+00,  3.6334e-01,  2.3835e+00,\n",
      "           3.2356e-02, -5.0152e-01, -1.2757e+00, -5.4226e-01, -4.0734e-01,\n",
      "          -1.4465e+00,  0.0000e+00, -8.5146e-01,  8.3107e-01, -1.5596e+00,\n",
      "           6.3607e-01,  6.7639e-01,  2.3969e+00,  5.4833e-02,  1.8941e+00,\n",
      "           1.3074e+00,  5.8088e-01, -2.3167e+00,  1.5502e+00, -2.2250e-01,\n",
      "          -2.2713e-01,  1.7329e+00,  2.7721e-01, -1.5520e+00,  0.0000e+00,\n",
      "          -1.2245e+00, -8.4768e-01, -1.8009e+00, -1.4551e-04,  3.7346e-01,\n",
      "          -1.5732e+00, -1.2334e-01,  9.6626e-01, -1.7356e+00,  1.6937e+00,\n",
      "          -1.4405e+00,  6.3404e-01, -1.7215e+00,  9.8049e-01, -1.7150e+00,\n",
      "           1.5599e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2288e+00,\n",
      "           0.0000e+00, -5.0833e-01,  5.4287e-01, -2.6150e-01, -1.0214e+00,\n",
      "           1.3329e+00,  3.0991e-01, -5.1606e-02,  0.0000e+00, -1.6111e+00,\n",
      "           1.8059e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0510, 0.1064, 0.1643, 0.0752, 0.1307, 0.1017, 0.1664, 0.0587, 0.0756,\n",
      "         0.0701]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3572, -0.0175,  0.0810,  ..., -0.1201, -0.0327, -0.4702],\n",
      "        [ 0.1226,  0.1534,  0.2777,  ...,  0.1167,  0.0601,  0.0476],\n",
      "        [ 0.3786, -0.0908, -0.2562,  ...,  0.2572,  0.3418, -0.0590],\n",
      "        ...,\n",
      "        [ 0.3213,  0.2844, -0.6536,  ..., -0.1401,  0.1159,  0.0862],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1940, -0.0686, -0.1235,  0.0596,  0.1269,  0.0421, -0.1667,\n",
      "          -0.0461,  0.0018,  0.0725, -0.0505, -0.0471,  0.0895,  0.0952,\n",
      "           0.0394, -0.1184,  0.1739, -0.0191, -0.3820, -0.0018, -0.2087,\n",
      "          -0.2329, -0.1716, -0.1115, -0.1740, -0.0633,  0.0782, -0.1871,\n",
      "           0.0086, -0.1319,  0.1604,  0.0962,  0.0154, -0.1051, -0.0181,\n",
      "          -0.0344,  0.0286, -0.1318, -0.0140, -0.1273,  0.0909,  0.2174,\n",
      "           0.2335,  0.0785,  0.1106,  0.1068,  0.1878, -0.0183,  0.1699,\n",
      "          -0.0534,  0.1358, -0.3599,  0.0318,  0.0009, -0.0450,  0.0585,\n",
      "          -0.0199, -0.0202,  0.2034,  0.1316,  0.2062, -0.1320, -0.1251,\n",
      "          -0.1182, -0.2821, -0.1325, -0.0286,  0.2466, -0.1910, -0.1135,\n",
      "          -0.1582,  0.4598, -0.1844,  0.1445, -0.2415,  0.0888,  0.2204,\n",
      "           0.0948, -0.0613, -0.1877, -0.0659, -0.0317,  0.0836, -0.1033,\n",
      "           0.3545,  0.1217,  0.1799,  0.0870,  0.1295,  0.2043,  0.1305,\n",
      "           0.0749, -0.2187, -0.0131,  0.1225, -0.0987,  0.2297,  0.1722,\n",
      "           0.0677, -0.0277, -0.0787, -0.0068,  0.0793, -0.1623,  0.1272,\n",
      "           0.0176, -0.1167, -0.0182, -0.2571,  0.1731, -0.1568, -0.1082,\n",
      "          -0.2029,  0.0392, -0.0182, -0.0600,  0.1309, -0.1592, -0.1715,\n",
      "           0.1587,  0.0454, -0.0852, -0.0700,  0.1043, -0.2889, -0.0555,\n",
      "           0.2132,  0.2440,  0.3656,  0.2520,  0.0237, -0.0769,  0.1417,\n",
      "          -0.0386,  0.0365, -0.1500,  0.1327, -0.0974, -0.0038, -0.0339,\n",
      "          -0.0859,  0.2575, -0.0580,  0.0617,  0.1499,  0.1248, -0.0816,\n",
      "           0.2038,  0.0256,  0.1514, -0.3573, -0.0604, -0.0963,  0.2258,\n",
      "          -0.2934,  0.1792,  0.0578,  0.2124, -0.0813,  0.2790, -0.0098,\n",
      "           0.0967,  0.0055, -0.1075, -0.3332, -0.1393, -0.0623, -0.1361,\n",
      "          -0.1748,  0.1925, -0.0258, -0.2370, -0.1682,  0.1695, -0.0508,\n",
      "          -0.0604,  0.3290, -0.0626,  0.1071, -0.1337,  0.0221,  0.0908,\n",
      "          -0.3694,  0.0092,  0.0714, -0.0315, -0.0302,  0.1037, -0.1574,\n",
      "           0.1165,  0.0142,  0.1611, -0.0880,  0.1127,  0.0615, -0.0764,\n",
      "           0.0599,  0.2513, -0.1197, -0.1510, -0.1299,  0.0011, -0.0563,\n",
      "          -0.1270, -0.0323,  0.0873, -0.4401, -0.0093, -0.0405, -0.1688,\n",
      "          -0.1639, -0.0199,  0.0068, -0.1137,  0.1798,  0.0347,  0.2075,\n",
      "           0.1209, -0.2966, -0.1420,  0.1266,  0.0474,  0.1188,  0.0703,\n",
      "          -0.0670,  0.1338, -0.0731, -0.1014, -0.4712,  0.1861,  0.1894,\n",
      "          -0.0605, -0.2288,  0.0582,  0.0791,  0.1600, -0.0038,  0.0517,\n",
      "           0.1352,  0.1337,  0.0791, -0.1025, -0.0823,  0.0607,  0.3369,\n",
      "          -0.0667, -0.0608, -0.0417, -0.0008, -0.2830,  0.0115, -0.1165,\n",
      "           0.0807,  0.0712,  0.2686,  0.0342]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7274e-02,  4.0019e-01, -9.6462e-01, -6.8086e-01,  3.7519e-01,\n",
      "          -2.0183e-01,  1.4644e+00, -8.3701e-02, -3.5830e+00,  9.0691e-01,\n",
      "           4.2781e-01, -6.2922e-01,  2.6015e+00, -6.3049e-01, -5.4134e-01,\n",
      "          -1.5803e-01,  8.5144e-01,  1.0941e+00,  0.0000e+00,  4.3625e-01,\n",
      "          -6.3312e-01, -3.8219e-01,  1.6393e+00,  1.5111e+00,  7.5307e-01,\n",
      "          -7.6026e-02, -1.8834e-01, -7.6027e-01,  1.6531e+00,  8.6122e-01,\n",
      "           1.2312e+00,  1.2193e+00, -1.0340e+00, -8.3111e-02, -1.5340e+00,\n",
      "           1.3955e+00,  0.0000e+00, -3.7438e+00,  1.9759e-01,  1.5997e+00,\n",
      "          -4.5906e-01, -1.3978e+00, -2.6919e-01, -1.7139e+00,  0.0000e+00,\n",
      "           6.6800e-01,  5.4035e-01,  3.7142e-01, -1.3401e+00,  1.4470e-01,\n",
      "          -6.2933e-01,  0.0000e+00,  6.0997e-01, -1.0283e+00, -2.4842e-02,\n",
      "           2.0442e-01, -8.8109e-01, -1.2506e+00, -2.3751e-01, -4.2643e-01,\n",
      "           1.0985e+00,  1.4067e+00, -2.0216e-01, -5.0067e-01, -2.9618e+00,\n",
      "           5.5173e-01,  1.2777e+00, -1.2871e+00,  4.0953e-01,  0.0000e+00,\n",
      "          -1.2661e+00, -2.9405e-02,  7.0723e-01,  0.0000e+00,  3.2476e-01,\n",
      "          -4.8321e-04, -1.6019e-01,  1.0610e+00, -5.7263e-02, -1.1746e-01,\n",
      "          -1.3994e+00,  2.1293e+00, -9.2402e-01,  1.0059e+00, -2.0742e-01,\n",
      "           4.3667e-01,  1.6610e+00, -9.7389e-01, -1.0467e-01, -5.8115e-01,\n",
      "          -2.2719e+00,  1.0994e+00, -6.2234e-01, -1.1359e+00,  4.6684e-01,\n",
      "          -1.1697e+00,  3.2292e-02,  6.2876e-01,  1.7190e+00, -7.7786e-01,\n",
      "           2.6964e+00, -1.4611e+00,  1.0759e+00,  1.4523e+00, -6.6595e-01,\n",
      "          -7.6204e-01,  1.2105e+00,  1.2745e-01, -1.4728e+00, -1.4096e-02,\n",
      "          -2.4788e-01,  0.0000e+00, -1.0469e+00,  1.3101e+00,  0.0000e+00,\n",
      "          -2.9873e+00, -5.7022e-02, -4.9895e-01, -1.9341e-01,  4.4574e-01,\n",
      "          -1.4644e+00,  7.0182e-01, -1.4600e+00, -7.2545e-01, -9.5730e-01,\n",
      "          -1.3068e+00,  8.9515e-01,  1.6935e-01,  1.2842e+00, -7.5071e-01,\n",
      "          -8.2443e-01,  5.3111e-01, -1.5823e+00,  9.8381e-01,  2.7639e-01,\n",
      "          -5.8892e-01,  6.5803e-01,  5.7588e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -3.8779e-01,  0.0000e+00, -7.8900e-01, -1.0038e-01, -1.6842e+00,\n",
      "          -9.9894e-02, -5.4267e-01, -8.4424e-01, -7.5444e-01,  1.7771e-01,\n",
      "           1.9973e+00, -1.9900e-01, -1.9293e+00, -4.0635e-01,  4.4105e-01,\n",
      "          -1.9449e-01, -6.5145e-02,  0.0000e+00,  3.8760e-02,  5.3724e-01,\n",
      "          -2.6594e-02,  2.2061e+00,  4.8096e-01, -5.5070e-01, -5.2536e-01,\n",
      "          -8.9080e-01,  2.8154e-01,  8.2509e-02, -3.5829e-01, -4.7782e-01,\n",
      "           7.3575e-01, -3.0321e-02,  2.0100e-02,  0.0000e+00,  1.2774e+00,\n",
      "          -1.0974e+00, -9.8533e-01, -2.0747e+00,  1.9677e+00,  8.6291e-02,\n",
      "          -3.1230e-02,  0.0000e+00,  6.7052e-01,  9.7996e-01,  0.0000e+00,\n",
      "          -3.4111e-01, -2.7810e+00, -7.8254e-01,  0.0000e+00,  1.0126e+00,\n",
      "           3.0717e+00,  4.9385e-01,  0.0000e+00, -5.9264e-01,  5.5958e-01,\n",
      "           2.1638e+00, -1.1872e+00,  5.3489e-01,  1.8107e+00, -9.4572e-01,\n",
      "          -1.6625e+00, -1.0153e+00,  1.2423e+00,  0.0000e+00,  2.3212e-01,\n",
      "          -5.7453e-01, -2.2915e+00,  6.8177e-01, -1.0726e+00, -4.7121e-01,\n",
      "           2.8670e+00, -5.7308e-01, -3.4146e-01,  7.9248e-01,  3.2337e-02,\n",
      "          -6.8301e-01, -1.0166e+00,  9.6694e-01, -2.4509e-01,  0.0000e+00,\n",
      "          -1.0827e+00, -4.2680e-01,  0.0000e+00, -5.0003e-01,  3.3993e-01,\n",
      "           7.0478e-01, -6.9657e-01,  0.0000e+00,  2.9209e-01, -1.5771e+00,\n",
      "          -1.1078e+00,  1.5810e+00, -6.1361e-01,  0.0000e+00, -2.9786e+00,\n",
      "           4.0328e+00,  5.8496e-01,  4.2648e-02, -1.5780e+00, -2.8571e-01,\n",
      "           7.4210e-01, -3.2458e+00, -3.0337e-01, -8.5157e-01,  0.0000e+00,\n",
      "           2.7578e-01,  2.7467e-01,  2.5201e-01,  2.6148e-01,  3.8690e-01,\n",
      "          -3.6591e-01, -1.5978e-01, -5.5315e-01, -5.1794e-02, -1.1460e+00,\n",
      "          -1.1312e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0536, 0.0705, 0.0697, 0.0524, 0.1214, 0.2668, 0.0868, 0.1053, 0.0526,\n",
      "         0.1208]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0054,  0.1544, -0.1418,  ...,  0.5517,  0.1656, -0.1452],\n",
      "        [ 0.0491,  0.0847, -0.2441,  ..., -0.0551, -0.0096,  0.2363],\n",
      "        [-0.1029, -0.0511,  0.3607,  ..., -0.2280, -0.1832,  0.1082],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1501, -0.0716, -0.2391, -0.0755,  0.0846,  0.0525, -0.1276,\n",
      "          -0.0652, -0.0104, -0.2357,  0.1157, -0.1540, -0.2421, -0.1150,\n",
      "           0.0740,  0.0742, -0.0790,  0.0204, -0.2284, -0.0469, -0.1299,\n",
      "          -0.0351,  0.0091, -0.0290,  0.0163,  0.1174,  0.0953, -0.1711,\n",
      "          -0.0418,  0.0423,  0.0704,  0.0342,  0.0676, -0.2282,  0.0915,\n",
      "          -0.1161, -0.1631,  0.0217, -0.1443, -0.0298,  0.0151,  0.2342,\n",
      "           0.0090,  0.0066,  0.0555,  0.0218,  0.0096, -0.1236,  0.0855,\n",
      "          -0.0574, -0.1177, -0.0169, -0.0474, -0.1830, -0.3025, -0.0023,\n",
      "          -0.0514, -0.1490,  0.0184,  0.1135, -0.0468,  0.0278,  0.0279,\n",
      "           0.1171,  0.1034,  0.0349, -0.0411,  0.0319, -0.0432,  0.0853,\n",
      "           0.3056,  0.1973,  0.0866,  0.0029,  0.0957, -0.0210,  0.1522,\n",
      "           0.1257,  0.0671,  0.1710, -0.1192,  0.1347, -0.1128,  0.1245,\n",
      "           0.0377,  0.0469,  0.0873,  0.0832,  0.0307, -0.0050,  0.1955,\n",
      "          -0.0502, -0.1969, -0.0166,  0.1431,  0.1861, -0.0145,  0.0993,\n",
      "           0.2047,  0.1408,  0.0412,  0.1867,  0.0861, -0.0188,  0.0197,\n",
      "          -0.2809,  0.1356,  0.2281,  0.0240, -0.0854, -0.0604,  0.0733,\n",
      "          -0.1639, -0.0314,  0.0081,  0.0770, -0.0903,  0.0428, -0.2667,\n",
      "          -0.0204,  0.0946,  0.1742, -0.2554,  0.0375, -0.1420, -0.0945,\n",
      "           0.0031, -0.1290,  0.1099, -0.1423, -0.0061, -0.2084, -0.0429,\n",
      "           0.1804, -0.0663,  0.0547,  0.2747,  0.1205, -0.0491, -0.1193,\n",
      "          -0.1416,  0.2254, -0.1874,  0.0224,  0.1076, -0.0910, -0.0182,\n",
      "           0.2458,  0.0211,  0.1490, -0.3352,  0.0875, -0.0996,  0.1212,\n",
      "          -0.1228,  0.1656,  0.0545,  0.1151, -0.1277,  0.0788, -0.0822,\n",
      "           0.0061, -0.3116,  0.1857, -0.1940, -0.1639, -0.0289, -0.1323,\n",
      "          -0.0170,  0.0072, -0.2722,  0.0977,  0.2177,  0.0499,  0.1529,\n",
      "           0.0830,  0.0645, -0.0833,  0.2095,  0.0125, -0.0431, -0.0222,\n",
      "          -0.0692, -0.0275,  0.1856,  0.0063, -0.1646,  0.0571, -0.0821,\n",
      "          -0.0724, -0.0624,  0.1067, -0.1222, -0.1074, -0.0656, -0.2315,\n",
      "           0.0590,  0.0342, -0.0108,  0.0015,  0.0189, -0.0235,  0.0469,\n",
      "           0.1095, -0.0735, -0.0038,  0.0189,  0.1263, -0.0892, -0.1840,\n",
      "           0.0062, -0.0059, -0.0427,  0.1800,  0.0731, -0.1259,  0.0512,\n",
      "           0.0959, -0.1801,  0.1120,  0.1185, -0.0246, -0.0091, -0.0442,\n",
      "           0.0058,  0.0862,  0.1932, -0.1179, -0.2003,  0.0932, -0.1193,\n",
      "          -0.1052, -0.0690, -0.0294,  0.0420, -0.1207, -0.2247,  0.1702,\n",
      "           0.3896,  0.2364, -0.0534, -0.0246,  0.0434,  0.0335, -0.0133,\n",
      "          -0.2527, -0.1141, -0.1669, -0.1404, -0.1119,  0.2063,  0.1729,\n",
      "          -0.0863, -0.0957, -0.0421, -0.1189]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.5870, -1.5379, -0.7546,  1.1740, -0.8099, -0.6140, -1.0716,\n",
      "          -1.3126,  0.8379, -1.2589, -0.3344, -0.3279,  1.5496, -1.0904,\n",
      "          -1.3050, -1.7207, -0.1862, -2.1011, -1.3734, -0.3892, -1.3879,\n",
      "           1.1721,  0.5995,  1.4321,  1.9064, -1.1302, -0.2795, -0.5659,\n",
      "           1.8540,  0.5399, -0.2221,  0.1583,  0.8627,  1.5870,  0.1124,\n",
      "           0.4885,  0.0257, -0.8414, -1.0330,  0.0000, -0.9627, -0.3869,\n",
      "          -0.5587,  0.1232,  0.1159,  1.6972,  0.0000,  0.9721,  2.4062,\n",
      "           1.2867,  0.4630,  0.5022,  1.7768,  0.2837, -0.1928,  0.4508,\n",
      "           0.1344,  0.0000, -0.2590,  0.0000,  1.0238, -0.4098,  1.3337,\n",
      "          -0.6536,  0.0000, -0.3839,  0.9525, -1.6849, -1.1700, -0.7887,\n",
      "          -1.3198, -1.5125,  0.0232, -0.9737, -0.6340,  0.0000,  0.7243,\n",
      "           0.0447,  0.1145, -0.5422,  1.0743,  0.0000,  2.4652, -0.7317,\n",
      "          -0.5268,  0.3706,  0.4051,  0.1359, -0.3130, -0.2497,  1.2638,\n",
      "           1.4980,  0.8409,  1.5750,  0.9575,  0.3810,  1.4619,  0.0000,\n",
      "           0.3874,  2.5201, -0.4161, -0.4032,  1.5541, -1.8309, -0.1048,\n",
      "          -1.2293,  2.0139,  0.6360, -0.1234,  1.6547,  0.0000,  0.6146,\n",
      "          -1.2788,  2.0568, -1.7535,  0.0000,  0.2346,  0.5594, -0.0764,\n",
      "           0.9295,  0.8686,  2.4416, -0.6768,  1.7226,  0.0000, -0.1886,\n",
      "           0.6201, -1.1053,  1.2885,  0.4505,  0.7910,  0.6655,  1.3645,\n",
      "          -1.9301,  0.0000, -1.2125,  0.0000, -0.1499,  1.1243, -0.5444,\n",
      "           0.5539,  0.5128,  0.9022, -1.7464, -2.0190,  0.7695, -0.5769,\n",
      "          -0.1592, -0.6988, -1.1145,  2.0027, -0.0555,  0.8168, -0.9828,\n",
      "           0.0000, -0.6085,  0.1944,  1.3198,  1.4830, -1.1931,  1.6437,\n",
      "           1.4027, -0.1464, -0.0872, -0.4160,  0.0000, -0.8028,  0.9189,\n",
      "          -0.5722,  0.0329,  1.2193,  0.0000,  1.1169,  0.6357,  1.1492,\n",
      "          -0.3781,  0.0000,  0.1988,  0.7215,  1.4462,  0.0000,  0.0886,\n",
      "           0.1162, -1.1732,  0.5029,  1.3031, -0.2208,  0.0000,  0.0000,\n",
      "          -2.2103, -0.2570,  0.3610, -1.3158,  1.0577,  0.1565, -1.7943,\n",
      "          -1.4363, -0.8881,  0.5560,  0.3952,  0.0000,  0.0938,  0.6943,\n",
      "          -2.4305,  0.6164,  0.7793, -0.2191, -0.8150,  0.0000,  0.4205,\n",
      "          -0.2232, -1.4586,  0.0437, -0.1202,  0.7295,  1.5439,  1.4643,\n",
      "           0.3693, -0.9897,  0.0121, -1.2840,  0.7153, -0.6999, -0.4162,\n",
      "          -3.5972,  0.9404,  1.8601,  0.8238, -0.5736,  0.0000, -0.1284,\n",
      "           0.0671,  0.0376, -1.5636,  2.6762, -2.2634, -0.3978, -1.2051,\n",
      "          -0.4047, -1.1440,  1.1099, -0.0796,  0.0000,  0.1218,  1.4648,\n",
      "           1.4990,  1.5403, -1.9320, -0.9459, -0.9350,  0.0000,  0.8940,\n",
      "          -1.1449, -2.0696,  0.4555,  1.6399]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0610, 0.0658, 0.0839, 0.1343, 0.0785, 0.0637, 0.1332, 0.1113, 0.1478,\n",
      "         0.1204]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0054,  0.1544, -0.1418,  ...,  0.5517,  0.1656, -0.1452],\n",
      "        [ 0.0491,  0.0847, -0.2441,  ..., -0.0551, -0.0096,  0.2363],\n",
      "        [-0.1029, -0.0511,  0.3607,  ..., -0.2280, -0.1832,  0.1082],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.8294e-02, -4.3826e-02, -1.9463e-01, -1.2670e-02,  1.7962e-02,\n",
      "           1.1929e-01, -1.1398e-01, -9.6466e-02,  6.4244e-03, -1.2520e-01,\n",
      "           1.2626e-01, -1.6605e-01, -1.7451e-01, -1.6616e-01,  4.7884e-02,\n",
      "           1.2868e-01, -9.2484e-03, -4.1824e-02, -1.0690e-01, -4.9213e-02,\n",
      "          -1.2074e-01,  9.5256e-03, -6.5607e-02,  3.6476e-02,  1.2034e-02,\n",
      "           1.0687e-01, -2.5814e-02, -1.0800e-01, -3.0916e-02, -2.9737e-02,\n",
      "           1.6076e-02,  6.2570e-02,  8.9897e-02, -1.2968e-01,  9.3834e-02,\n",
      "          -9.3537e-02, -9.8386e-02,  7.5461e-05, -1.0907e-01, -1.1427e-01,\n",
      "          -3.5440e-03,  1.4998e-01,  5.0162e-03, -6.9979e-02,  8.6248e-02,\n",
      "          -2.3340e-03,  4.5088e-02, -1.2801e-01,  3.2646e-02, -1.0836e-02,\n",
      "          -1.6495e-01, -2.9466e-02, -3.7364e-02, -1.5641e-01, -2.9052e-01,\n",
      "          -1.4427e-02, -3.6543e-02, -1.2943e-01,  2.2934e-02,  1.6416e-01,\n",
      "          -1.0594e-01,  4.0430e-02,  2.9014e-02,  8.6865e-03,  1.2002e-01,\n",
      "           3.9353e-02, -1.1197e-02, -5.8730e-02,  3.9893e-02, -1.7078e-02,\n",
      "           2.3044e-01,  1.5467e-01,  7.8013e-02, -1.9285e-02,  6.3481e-02,\n",
      "          -8.7894e-02,  1.6403e-01,  9.4811e-02,  7.2101e-03,  1.3726e-01,\n",
      "          -1.0094e-01,  1.0958e-02, -9.4441e-02,  6.9571e-02,  1.6102e-02,\n",
      "           4.5603e-02, -1.5198e-02,  6.6239e-02,  2.5723e-02, -4.5014e-02,\n",
      "           1.6538e-01, -4.1806e-02, -1.2553e-01,  8.2824e-03,  9.7105e-02,\n",
      "           1.0853e-01, -1.4594e-02,  1.3303e-01,  1.0117e-01,  8.6659e-02,\n",
      "           5.5144e-02,  1.0809e-01,  1.3326e-01,  2.4093e-02, -2.9548e-02,\n",
      "          -2.6042e-01,  6.5844e-02,  9.9921e-02,  3.6513e-02, -1.2132e-01,\n",
      "           1.0929e-02,  8.3497e-02, -7.4626e-02, -5.7735e-02,  3.4776e-02,\n",
      "           9.6630e-02, -9.3139e-02, -2.1486e-02, -1.8953e-01, -2.5637e-02,\n",
      "           1.0381e-01,  1.9172e-01, -1.2105e-01,  3.6991e-02, -5.7965e-02,\n",
      "          -1.2512e-01, -5.1105e-02, -1.3666e-01,  1.6443e-01, -4.3059e-02,\n",
      "          -3.1864e-02, -1.1977e-01,  6.1996e-03,  1.2856e-01, -1.5630e-01,\n",
      "           6.2489e-02,  2.2079e-01,  1.7055e-02, -9.2992e-02, -1.0716e-01,\n",
      "          -8.1467e-02,  2.0349e-01, -1.3964e-01,  9.2619e-02,  9.1214e-02,\n",
      "          -3.3164e-02, -3.6324e-02,  2.4963e-01, -4.4079e-02,  1.1042e-01,\n",
      "          -2.3963e-01,  1.7354e-02, -2.0915e-02,  1.4392e-01, -1.0734e-01,\n",
      "           6.1011e-02,  6.9210e-02,  5.4670e-02, -1.3446e-02,  1.5855e-02,\n",
      "          -1.2507e-01, -2.6012e-02, -2.1311e-01,  8.3770e-02, -6.3338e-02,\n",
      "          -1.2202e-01, -1.4577e-02, -3.9790e-02,  5.3545e-02,  6.4995e-02,\n",
      "          -1.5659e-01,  9.6599e-02,  1.5712e-01,  9.9317e-03,  9.9970e-02,\n",
      "           1.3325e-01,  1.8956e-02, -6.3288e-02,  2.0318e-01,  1.8744e-02,\n",
      "           2.6129e-02, -1.6439e-02,  1.9976e-03,  3.2119e-02,  1.0387e-01,\n",
      "          -5.1580e-02, -1.5094e-01,  5.4813e-02,  4.3580e-02, -6.9600e-02,\n",
      "          -9.0760e-02,  3.9450e-02, -7.0740e-02, -1.2253e-01, -6.3132e-03,\n",
      "          -1.5920e-01, -1.9852e-02, -5.2215e-03,  5.1916e-03,  4.0385e-02,\n",
      "          -8.1693e-03,  1.6958e-02,  6.9071e-02,  2.0707e-01, -6.5005e-02,\n",
      "           7.3455e-02, -4.0380e-03,  8.8461e-02, -8.1115e-02, -8.6346e-02,\n",
      "           9.9153e-02,  1.6583e-02, -4.0950e-02,  1.2851e-01,  5.4241e-02,\n",
      "          -7.6418e-02, -3.5264e-02,  7.4934e-02, -1.2472e-01,  1.0380e-01,\n",
      "           1.7814e-01, -7.0972e-02,  4.0190e-02, -1.1170e-01, -1.5301e-02,\n",
      "           5.0253e-02,  1.3946e-01, -6.4935e-02, -1.0972e-01,  6.0851e-02,\n",
      "          -1.6140e-01, -7.5121e-02,  2.9458e-02, -7.6097e-02,  1.7431e-02,\n",
      "          -1.4576e-01, -1.7313e-01,  1.4802e-01,  2.9595e-01,  1.4539e-01,\n",
      "          -2.3983e-02, -6.2576e-02, -1.2826e-03, -4.3594e-02, -5.3007e-02,\n",
      "          -1.8327e-01, -1.5431e-01, -6.3850e-02, -6.8716e-02,  1.7773e-02,\n",
      "           1.5730e-01,  1.1040e-01, -2.1756e-02, -2.7851e-02, -7.6345e-02,\n",
      "          -8.3455e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9673e-02, -1.8078e+00,  1.3220e+00,  5.1611e-01,\n",
      "          -3.7607e-01,  9.9065e-04, -7.2273e-01,  2.1177e+00, -2.1357e-01,\n",
      "           2.8204e-01,  8.3055e-01, -1.1106e+00,  1.9964e-01,  3.1267e-01,\n",
      "           3.5180e-01, -6.8279e-01,  1.6928e-01,  0.0000e+00,  5.4579e-01,\n",
      "           1.8833e+00,  0.0000e+00, -3.7033e-02, -5.3536e-01, -1.0048e-01,\n",
      "           6.5107e-01, -1.6090e+00, -1.3622e+00,  0.0000e+00, -1.0345e+00,\n",
      "           3.8828e-02, -1.4545e+00, -2.0766e+00,  3.1545e-01, -2.8520e-01,\n",
      "          -2.0018e+00,  2.1901e-01,  9.9695e-01,  6.0144e-01,  9.5349e-01,\n",
      "          -2.2510e-01, -2.2112e+00, -7.0598e-01,  1.3960e+00,  8.9800e-02,\n",
      "          -1.1382e+00,  2.4233e-01,  7.4220e-01, -7.0946e-01, -1.3359e+00,\n",
      "           0.0000e+00, -1.3746e-01,  6.6250e-01,  1.1164e+00,  0.0000e+00,\n",
      "           3.3309e-01, -4.4968e-01, -8.8802e-01,  1.3377e-01,  6.2830e-01,\n",
      "          -7.0453e-01,  5.6343e-01, -6.9338e-01, -1.5469e+00,  2.8923e-01,\n",
      "           9.5786e-02, -1.7761e-01,  5.9495e-01, -2.1388e+00,  5.5968e-01,\n",
      "           1.8255e-01, -5.1254e-01, -3.4088e-01, -1.1321e+00, -6.4742e-01,\n",
      "           4.6098e-01,  0.0000e+00,  1.1893e-01,  5.1719e-01,  0.0000e+00,\n",
      "          -3.8510e-01,  2.1577e+00,  7.7734e-01, -8.4536e-01,  3.9782e-01,\n",
      "           4.1918e-01,  1.6047e+00, -5.6406e-01, -1.4129e+00, -1.4906e+00,\n",
      "           4.0441e-01, -3.5138e-01,  4.9399e-01, -2.3211e+00,  1.2379e+00,\n",
      "          -9.6286e-01,  1.3202e+00, -9.0728e-01,  2.3908e+00,  9.5491e-01,\n",
      "          -1.2008e+00,  5.9450e-01,  1.0664e+00, -1.7340e+00,  3.6515e-01,\n",
      "           4.0243e-01, -1.2704e+00,  4.5470e-01,  1.9688e+00,  1.4963e-01,\n",
      "          -8.3256e-01,  5.3420e-01,  8.0840e-01,  6.6390e-01, -1.0554e+00,\n",
      "           9.1769e-01, -7.0310e-01, -8.4502e-01,  2.5774e-01,  8.7973e-01,\n",
      "          -8.7723e-01, -1.3960e+00,  0.0000e+00, -1.8464e+00, -1.3005e+00,\n",
      "           0.0000e+00, -8.1168e-01,  6.4909e-01,  2.5565e-01, -1.4897e+00,\n",
      "           0.0000e+00,  3.7788e-01, -1.3453e+00,  7.2212e-01,  3.2008e+00,\n",
      "          -7.5259e-01, -3.8369e-01,  1.2823e+00,  2.2520e+00,  1.9421e-01,\n",
      "          -3.9042e-02,  3.0300e+00,  0.0000e+00, -1.8725e-01, -1.1120e+00,\n",
      "           1.2472e+00,  7.7537e-01, -7.7474e-01, -4.4867e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6526e-01, -2.8958e-01, -2.1307e+00, -5.8167e-01,\n",
      "           7.8595e-01, -1.8622e+00, -1.3048e+00,  1.9039e-01, -3.6287e+00,\n",
      "          -1.8688e+00,  1.1503e+00, -8.5975e-01,  9.5954e-01, -1.4611e+00,\n",
      "          -2.7093e-02,  1.9743e+00,  1.1269e+00, -4.8564e-01, -1.2413e+00,\n",
      "          -2.1247e-01, -1.3224e+00, -1.6392e+00,  0.0000e+00,  6.8270e-01,\n",
      "           0.0000e+00, -1.2609e-01,  6.0651e-01, -7.4913e-01,  2.5920e-01,\n",
      "           1.3326e+00, -2.5533e+00,  2.7791e-01, -5.8355e-01,  1.6233e+00,\n",
      "          -1.2403e+00, -1.8822e-03, -5.0254e-02,  9.0081e-01,  5.6550e-01,\n",
      "          -4.1988e-01,  3.8846e-01, -1.1559e-01,  8.0966e-01,  1.0504e+00,\n",
      "          -7.8930e-01, -1.4389e+00, -4.1528e-01, -7.5021e-01, -4.5419e-01,\n",
      "          -5.4748e-01,  7.2231e-01, -1.8530e+00,  1.3573e+00,  8.3787e-01,\n",
      "          -1.5240e+00, -3.5862e-01,  6.4773e-01,  2.0055e-01, -2.1783e+00,\n",
      "           8.3526e-01, -1.2911e+00, -1.2838e+00,  0.0000e+00, -1.5635e+00,\n",
      "           2.0757e+00,  1.3420e-01,  0.0000e+00, -3.0690e-02, -5.7956e-01,\n",
      "          -1.4281e+00,  1.9010e+00, -3.8087e-01,  1.4695e+00,  8.0544e-01,\n",
      "           3.6931e-01,  6.6970e-01,  0.0000e+00,  8.8897e-02,  1.0253e+00,\n",
      "           9.7853e-01, -1.4083e+00,  6.5953e-01, -1.1450e+00, -1.6456e+00,\n",
      "          -6.0036e-01,  8.7362e-03, -7.1086e-01,  3.7041e-01, -2.2388e-01,\n",
      "          -7.5249e-01,  5.7216e-01,  0.0000e+00, -6.6373e-01,  1.5464e+00,\n",
      "           5.7814e-01,  1.8918e+00, -8.6385e-01,  4.9351e-01, -3.8725e-01,\n",
      "           4.9982e-01, -9.7499e-01,  1.7727e+00,  0.0000e+00, -8.0770e-01,\n",
      "          -6.2210e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0751, 0.1093, 0.1278, 0.1437, 0.0876, 0.1290, 0.0864, 0.0504, 0.0688,\n",
      "         0.1219]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0054,  0.1544, -0.1418,  ...,  0.5517,  0.1656, -0.1452],\n",
      "        [ 0.0491,  0.0847, -0.2441,  ..., -0.0551, -0.0096,  0.2363],\n",
      "        [-0.1029, -0.0511,  0.3607,  ..., -0.2280, -0.1832,  0.1082],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.2875e-02, -7.1106e-02, -1.9304e-01, -4.6976e-02,  6.3988e-02,\n",
      "           1.6901e-01, -1.7367e-01, -9.6993e-02, -1.5085e-02, -1.4200e-01,\n",
      "           1.3550e-01, -1.7367e-01, -2.0892e-01, -1.9896e-01,  5.8742e-02,\n",
      "           1.7623e-01, -3.0032e-02, -5.2574e-02, -1.2224e-01, -9.1184e-02,\n",
      "          -1.5393e-01,  5.9175e-03, -9.2064e-02,  3.4483e-02,  4.1640e-02,\n",
      "           1.4524e-01,  1.1577e-02, -1.0334e-01, -3.5585e-02, -2.9906e-02,\n",
      "           1.7506e-02,  1.1110e-01,  1.3936e-01, -1.6380e-01,  9.3922e-02,\n",
      "          -1.2834e-01, -1.1674e-01,  7.2740e-03, -1.2081e-01, -1.2988e-01,\n",
      "          -1.8610e-03,  2.1613e-01,  1.2858e-02, -9.9927e-02,  6.4198e-02,\n",
      "           8.9956e-03,  5.8240e-02, -1.5078e-01,  3.0506e-02,  7.5545e-03,\n",
      "          -1.9384e-01, -4.5935e-02, -1.2573e-02, -1.8032e-01, -3.5674e-01,\n",
      "          -2.8611e-02, -3.3940e-02, -1.6785e-01,  4.8789e-02,  1.7955e-01,\n",
      "          -1.2871e-01,  4.5603e-02,  3.8595e-02,  7.0169e-04,  1.3408e-01,\n",
      "           4.2663e-02, -6.2464e-03, -8.2290e-02,  5.1600e-02, -2.6410e-02,\n",
      "           3.0541e-01,  1.9922e-01,  1.1794e-01, -4.1003e-02,  1.1214e-01,\n",
      "          -7.7933e-02,  2.0402e-01,  7.9009e-02,  1.1208e-02,  1.7453e-01,\n",
      "          -9.0820e-02,  8.4480e-02, -1.1707e-01,  1.1379e-01,  1.1058e-02,\n",
      "           3.7097e-02, -1.3417e-04,  1.0331e-01,  1.9922e-02, -2.6957e-02,\n",
      "           1.9346e-01, -7.5000e-02, -1.6528e-01, -9.7843e-03,  1.3318e-01,\n",
      "           1.4675e-01, -2.2858e-02,  1.4003e-01,  1.2914e-01,  7.4119e-02,\n",
      "           1.1157e-01,  1.6739e-01,  1.3427e-01,  1.4817e-03,  1.0245e-02,\n",
      "          -3.2537e-01,  6.1646e-02,  1.2806e-01,  3.3932e-02, -1.5243e-01,\n",
      "          -6.2612e-04,  1.1036e-01, -1.1924e-01, -5.1529e-02,  5.5099e-02,\n",
      "           1.4763e-01, -9.0341e-02, -3.4859e-02, -2.6518e-01, -2.0353e-02,\n",
      "           1.0363e-01,  2.7395e-01, -1.2244e-01,  5.0413e-02, -7.2486e-02,\n",
      "          -1.6650e-01, -7.5835e-02, -1.4222e-01,  1.7543e-01, -3.8612e-02,\n",
      "          -5.0063e-02, -1.2750e-01, -3.5294e-02,  1.5349e-01, -1.9282e-01,\n",
      "           2.1497e-02,  2.3287e-01,  2.8863e-02, -1.2508e-01, -1.3711e-01,\n",
      "          -1.3249e-01,  2.3876e-01, -1.8307e-01,  8.3916e-02,  9.1485e-02,\n",
      "          -2.2886e-02, -3.9649e-02,  2.9968e-01, -3.6822e-02,  1.1191e-01,\n",
      "          -2.8990e-01,  1.0140e-02, -1.5879e-02,  1.6042e-01, -1.3385e-01,\n",
      "           4.4749e-02,  7.8676e-02,  5.5057e-02, -4.7102e-02,  4.2425e-02,\n",
      "          -1.5463e-01, -6.1888e-03, -2.3342e-01,  1.0069e-01, -9.5739e-02,\n",
      "          -1.6571e-01, -3.2274e-02, -1.5706e-02,  3.4788e-02,  4.2923e-02,\n",
      "          -1.9753e-01,  1.0850e-01,  1.6965e-01,  7.2566e-02,  1.2742e-01,\n",
      "           1.7877e-01,  3.0276e-02, -7.9633e-02,  2.1232e-01,  2.5383e-02,\n",
      "           3.8778e-02, -3.5809e-02,  6.1450e-03,  1.4980e-02,  1.1155e-01,\n",
      "          -4.2077e-02, -1.2535e-01,  3.0716e-02,  1.3722e-02, -8.8142e-02,\n",
      "          -9.5227e-02,  3.7093e-02, -5.2761e-02, -1.4509e-01, -5.4079e-02,\n",
      "          -1.9838e-01, -3.6645e-02, -1.5171e-02, -6.4961e-03,  2.7718e-02,\n",
      "          -9.8171e-03,  2.1731e-02,  9.5367e-02,  2.3324e-01, -1.1068e-01,\n",
      "           8.9506e-02, -9.6750e-03,  5.8233e-02, -7.9544e-02, -1.1393e-01,\n",
      "           9.3788e-02,  5.9448e-02, -6.7245e-02,  1.6550e-01,  7.4636e-02,\n",
      "          -1.2458e-01, -9.2919e-03,  7.7437e-02, -1.4582e-01,  1.1406e-01,\n",
      "           2.0611e-01, -5.3378e-02,  4.1361e-02, -1.2764e-01, -3.9365e-02,\n",
      "           5.3225e-02,  1.3919e-01, -5.2831e-02, -1.3512e-01,  4.9107e-02,\n",
      "          -1.6492e-01, -9.9816e-02,  2.5698e-02, -6.0156e-02,  2.2353e-02,\n",
      "          -1.7553e-01, -2.3643e-01,  1.8972e-01,  3.6474e-01,  1.6534e-01,\n",
      "          -1.8718e-02, -7.9684e-02,  3.5353e-02, -2.2144e-02, -7.6202e-02,\n",
      "          -2.3952e-01, -2.0605e-01, -6.1479e-02, -1.2118e-01, -2.3616e-02,\n",
      "           1.7314e-01,  1.4333e-01, -1.8368e-03, -4.5001e-02, -7.7410e-02,\n",
      "          -8.5400e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5704e+00, -1.4751e+00,  0.0000e+00, -7.8612e-02,  3.5242e-01,\n",
      "           0.0000e+00, -2.0055e-01,  2.0886e+00,  1.3116e+00, -1.0355e+00,\n",
      "           6.8456e-01,  2.1684e+00,  1.1879e+00, -8.0527e-01, -1.0871e-01,\n",
      "          -1.1277e+00,  1.9604e+00, -2.9107e-01,  8.1651e-03,  4.2657e-01,\n",
      "          -1.9756e+00, -1.8380e+00, -1.2584e+00,  1.9421e-01, -1.6702e-01,\n",
      "           0.0000e+00, -2.9811e-01, -9.7430e-01,  0.0000e+00,  7.8335e-01,\n",
      "           3.4911e-01,  3.1160e-01,  5.3673e-01,  9.4171e-01,  0.0000e+00,\n",
      "           4.5403e-01, -2.8991e+00,  6.8022e-02,  3.9858e-02,  1.2313e+00,\n",
      "          -7.2220e-01,  0.0000e+00,  2.4850e-01,  0.0000e+00,  6.7020e-02,\n",
      "           3.1145e-01, -1.0371e+00, -1.1820e+00, -4.4448e-01, -1.6405e+00,\n",
      "          -1.5658e+00,  3.1694e+00,  8.6329e-01,  7.6400e-01,  2.2062e+00,\n",
      "           5.5908e-01,  5.9270e-01,  5.6768e-01, -7.5511e-01,  4.1292e-01,\n",
      "           6.2643e-01, -7.1986e-01, -3.6499e-01,  8.9445e-01, -1.3379e+00,\n",
      "           2.3299e+00, -2.4165e+00,  9.2202e-02,  1.1602e+00, -7.1805e-01,\n",
      "           7.5229e-02,  0.0000e+00,  1.9007e-01,  2.3378e-02,  4.0834e-01,\n",
      "          -9.0039e-01, -4.8587e-01,  0.0000e+00, -1.3789e+00, -2.4958e+00,\n",
      "          -3.6232e+00,  4.0177e-01,  4.9705e-01, -3.8131e-01, -2.3204e+00,\n",
      "          -1.0348e+00, -6.3278e-01,  1.8183e+00, -1.9081e+00,  0.0000e+00,\n",
      "          -4.3649e-01, -6.6948e-01, -1.9173e+00,  1.0180e+00, -1.3663e+00,\n",
      "           0.0000e+00,  2.1683e-01,  1.8014e-02,  3.0385e-01,  0.0000e+00,\n",
      "           0.0000e+00,  9.3370e-01,  2.2421e-01, -1.6317e+00,  2.2437e+00,\n",
      "          -1.4411e-01,  1.2458e-01, -1.0133e+00, -1.2048e+00, -1.4858e+00,\n",
      "          -1.5565e+00, -1.3434e+00,  1.5144e-01, -1.7880e+00, -1.1431e+00,\n",
      "          -1.0663e+00, -1.7870e+00, -1.2154e-01, -1.8687e+00,  9.4017e-02,\n",
      "           6.7211e-01,  5.5212e-01,  1.5533e+00,  4.8414e-01,  1.2915e-01,\n",
      "           5.8259e-01,  0.0000e+00,  5.8347e-02,  3.9295e-01, -5.9706e-02,\n",
      "          -8.6534e-02, -5.3667e-01,  7.0340e-01,  1.1582e+00,  3.2914e-01,\n",
      "          -2.5076e-01,  1.1896e-01, -1.3303e+00, -3.6605e-01, -7.7322e-01,\n",
      "          -5.9716e-01, -1.4722e+00, -1.1960e+00,  0.0000e+00,  5.0174e-01,\n",
      "           2.5931e-01,  1.2103e+00,  1.2552e+00,  6.3341e-01,  3.1607e-01,\n",
      "           7.8755e-02, -5.5375e-02, -7.0951e-01,  0.0000e+00,  1.2669e+00,\n",
      "           2.7982e-01,  1.1350e+00,  3.0537e-01,  2.6081e-01,  1.4425e+00,\n",
      "          -1.7508e-01,  6.8400e-01, -2.1236e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -9.4132e-01,  3.2966e-01,  2.5638e-01,  1.7293e+00,  0.0000e+00,\n",
      "           3.1422e+00,  2.0558e+00,  5.6326e-01,  1.0290e-01, -3.9339e-01,\n",
      "          -9.6601e-01, -4.0479e-01,  1.1921e+00, -2.6511e-01, -1.5079e+00,\n",
      "          -1.3462e-01, -1.3031e-02,  0.0000e+00, -1.5681e+00, -1.8519e+00,\n",
      "          -1.6858e-01,  6.9791e-03,  1.3399e+00,  1.2949e+00,  7.3877e-01,\n",
      "           9.6765e-01,  0.0000e+00, -5.3581e-01,  5.3536e-01, -4.7088e-02,\n",
      "          -1.2977e+00,  0.0000e+00,  3.1397e+00, -1.0836e+00, -4.6140e-02,\n",
      "           8.1004e-01, -2.1875e+00, -2.6963e+00,  1.4470e+00, -9.9690e-01,\n",
      "           9.7227e-01, -1.6692e+00, -6.1192e-01, -9.3232e-01, -1.1369e+00,\n",
      "           8.7206e-01,  7.9502e-02, -1.3192e+00, -7.9122e-01,  1.3114e+00,\n",
      "          -2.8297e-01,  1.3731e+00,  2.4507e-01, -2.3516e+00,  1.9031e+00,\n",
      "           1.0279e+00, -1.4199e+00,  1.7824e+00,  0.0000e+00, -5.7267e-01,\n",
      "          -5.7353e-01, -1.5895e+00,  1.5753e-03, -3.3780e-01, -2.9544e+00,\n",
      "          -6.4340e-01,  1.5656e+00,  9.3257e-02, -6.2721e-01,  1.6772e+00,\n",
      "           2.2888e+00, -2.1840e+00,  3.2578e-01,  1.5120e+00, -5.3494e-01,\n",
      "          -1.8333e+00, -1.1664e+00,  0.0000e+00,  1.4426e+00, -4.7779e-01,\n",
      "           1.4836e+00, -5.8511e-01,  7.7592e-01, -1.4378e+00, -2.5933e-01,\n",
      "           4.3552e-01,  3.1978e-01, -3.3685e-01,  1.6169e+00,  2.5978e-01,\n",
      "          -7.0530e-02]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0779, 0.1596, 0.0488, 0.1075, 0.1395, 0.0842, 0.1129, 0.0857, 0.0757,\n",
      "         0.1083]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0054,  0.1544, -0.1418,  ...,  0.5517,  0.1656, -0.1452],\n",
      "        [ 0.0491,  0.0847, -0.2441,  ..., -0.0551, -0.0096,  0.2363],\n",
      "        [-0.1029, -0.0511,  0.3607,  ..., -0.2280, -0.1832,  0.1082],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.1974e-01, -4.1299e-02, -2.3978e-01, -3.5679e-02,  2.1550e-02,\n",
      "           1.5383e-01, -1.2024e-01, -7.5662e-02,  3.4798e-02, -1.0920e-01,\n",
      "           1.2347e-01, -1.8860e-01, -1.9742e-01, -1.8256e-01,  4.2069e-02,\n",
      "           1.2712e-01, -1.6151e-02, -3.9938e-02, -1.4145e-01, -6.3499e-02,\n",
      "          -1.3355e-01, -8.6184e-03, -6.5011e-02,  7.0339e-02,  3.7478e-02,\n",
      "           1.2589e-01,  2.3557e-02, -1.2636e-01, -2.7661e-02,  1.2837e-02,\n",
      "           8.7245e-03,  6.7347e-02,  1.0288e-01, -1.4994e-01,  1.3112e-01,\n",
      "          -1.1195e-01, -1.2350e-01,  2.4260e-02, -1.3444e-01, -1.1319e-01,\n",
      "           7.4000e-03,  1.9238e-01,  8.2772e-03, -5.6076e-02,  1.0041e-01,\n",
      "           4.5115e-03, -4.8109e-03, -1.5459e-01,  4.2437e-02,  1.9022e-02,\n",
      "          -1.4989e-01, -1.8506e-02,  7.9389e-03, -1.5560e-01, -3.2429e-01,\n",
      "           6.5975e-03, -4.1616e-02, -1.1488e-01,  4.5858e-02,  1.3757e-01,\n",
      "          -1.3334e-01,  4.9245e-02,  5.7968e-02, -1.1257e-02,  1.7594e-01,\n",
      "           5.8982e-02, -6.9449e-05, -8.7968e-02,  4.5258e-02, -3.6259e-02,\n",
      "           2.8436e-01,  1.8713e-01,  1.1958e-01, -3.1974e-02,  9.1366e-02,\n",
      "          -1.1384e-01,  1.6562e-01,  8.5760e-02,  9.9008e-03,  1.7050e-01,\n",
      "          -7.6188e-02,  6.7806e-02, -1.0879e-01,  8.8255e-02,  5.6841e-03,\n",
      "           1.3327e-02, -8.5098e-03,  9.8172e-02, -1.4517e-02, -4.7336e-02,\n",
      "           2.1270e-01, -8.8958e-02, -1.7641e-01, -2.2093e-02,  1.7221e-01,\n",
      "           1.5611e-01, -4.2532e-02,  1.6080e-01,  1.4588e-01,  7.6735e-02,\n",
      "           5.5622e-02,  1.8466e-01,  1.3754e-01,  5.9790e-03, -3.5569e-02,\n",
      "          -3.2316e-01,  6.8691e-02,  1.4997e-01,  2.5823e-02, -1.1393e-01,\n",
      "          -1.6282e-02,  4.0689e-02, -1.3336e-01, -6.1414e-02,  3.1053e-03,\n",
      "           1.0370e-01, -6.9692e-02, -4.0326e-02, -2.3883e-01,  2.7742e-03,\n",
      "           1.1266e-01,  2.2756e-01, -1.6547e-01,  3.1494e-02, -5.5088e-02,\n",
      "          -1.4417e-01, -6.1161e-02, -8.1271e-02,  1.3065e-01, -4.6811e-02,\n",
      "          -2.1545e-02, -1.1302e-01, -4.1011e-02,  1.1920e-01, -1.7344e-01,\n",
      "           5.2738e-02,  2.5483e-01,  2.8885e-02, -1.1071e-01, -1.4744e-01,\n",
      "          -1.1925e-01,  2.2452e-01, -1.7615e-01,  7.4848e-02,  9.8384e-02,\n",
      "          -6.3985e-02, -1.6810e-02,  2.7589e-01, -2.8439e-02,  9.7192e-02,\n",
      "          -2.5514e-01,  7.1109e-03, -2.4625e-02,  1.0583e-01, -1.5761e-01,\n",
      "           5.6249e-02,  3.0746e-02,  7.5018e-02, -5.4524e-02,  5.0847e-02,\n",
      "          -1.3430e-01, -1.1475e-02, -1.9711e-01,  1.3470e-01, -1.0056e-01,\n",
      "          -1.4458e-01, -4.2984e-02, -5.2340e-02,  5.4326e-02,  7.4126e-02,\n",
      "          -2.1557e-01,  1.2500e-01,  1.8645e-01, -2.3779e-04,  9.9356e-02,\n",
      "           1.7677e-01,  4.0923e-02, -7.5134e-02,  1.9296e-01,  3.9448e-02,\n",
      "           2.0138e-02,  1.0135e-02, -6.2219e-03,  1.0963e-02,  7.6892e-02,\n",
      "          -3.5979e-02, -1.4920e-01,  2.8363e-02, -1.9381e-02, -6.5234e-02,\n",
      "          -9.7956e-02,  6.9879e-02, -7.3296e-02, -1.2582e-01, -2.2617e-02,\n",
      "          -1.9520e-01, -4.6491e-02, -5.9652e-02, -2.8798e-02,  7.0687e-02,\n",
      "          -3.2110e-02,  8.2705e-03,  9.1781e-02,  1.9064e-01, -7.4504e-02,\n",
      "           9.4573e-02,  7.3847e-03,  6.1731e-02, -7.1949e-02, -8.9959e-02,\n",
      "           7.5293e-02,  3.6683e-02, -5.5127e-02,  1.8914e-01,  7.2435e-02,\n",
      "          -1.0283e-01,  3.7071e-02,  8.0271e-02, -1.1178e-01,  1.1132e-01,\n",
      "           1.5325e-01, -4.7404e-02,  2.7961e-02, -1.2611e-01, -1.0904e-02,\n",
      "           7.2268e-02,  2.0045e-01, -4.2705e-02, -1.3842e-01,  1.1751e-01,\n",
      "          -1.8073e-01, -1.0757e-01,  3.3219e-02, -6.4669e-02, -1.1687e-02,\n",
      "          -1.9974e-01, -2.2482e-01,  1.2593e-01,  3.4186e-01,  1.8529e-01,\n",
      "           2.4079e-02, -2.7342e-02,  1.8024e-02, -2.7779e-02, -8.7014e-02,\n",
      "          -2.1451e-01, -1.5749e-01, -5.2155e-02, -9.8649e-02,  1.4491e-02,\n",
      "           1.9106e-01,  1.3114e-01, -4.3796e-02, -1.4511e-02, -8.6665e-02,\n",
      "          -7.8358e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.1394e+00,  6.9816e-01,  2.8344e+00, -5.9918e-02,  4.8509e-02,\n",
      "          -1.4803e+00,  1.4980e+00, -9.3244e-02,  7.9000e-01,  4.1873e-01,\n",
      "          -2.7166e-01,  0.0000e+00,  1.5317e+00,  7.1654e-01, -3.1219e-02,\n",
      "          -2.0741e-03, -1.5895e+00, -9.6657e-01, -3.4171e-01,  1.5507e+00,\n",
      "          -5.3384e-01,  0.0000e+00,  9.0631e-01,  9.0937e-01, -3.9827e-01,\n",
      "          -1.1145e+00, -2.1589e-02,  0.0000e+00, -5.7912e-01,  1.2717e+00,\n",
      "           0.0000e+00,  2.9282e-01, -3.4997e-01,  9.8290e-02, -8.5704e-01,\n",
      "          -5.2326e-01,  1.6802e-01,  0.0000e+00,  1.2453e+00,  7.2734e-01,\n",
      "          -6.2826e-01, -1.7317e-01, -6.9248e-01,  0.0000e+00, -2.2635e-01,\n",
      "           0.0000e+00, -8.1940e-01,  9.1804e-01,  6.8409e-01, -6.8689e-01,\n",
      "          -1.0982e+00, -1.0624e+00, -1.8355e+00,  2.0106e+00,  0.0000e+00,\n",
      "          -2.2707e-01,  1.2755e+00, -9.4828e-01, -6.1174e-01, -1.6809e-01,\n",
      "          -1.3703e+00, -1.1755e-01, -1.8911e+00,  1.5197e+00, -1.1910e+00,\n",
      "          -2.1566e-02, -6.2544e-01,  2.0726e-01,  1.1861e-01, -1.6722e+00,\n",
      "          -8.3465e-01,  0.0000e+00, -2.9273e+00,  1.1644e+00, -2.1583e+00,\n",
      "          -3.2701e-01,  8.0074e-01, -1.0019e+00, -1.1495e+00,  0.0000e+00,\n",
      "           3.4297e-01,  0.0000e+00, -9.9545e-01,  7.3416e-01,  4.5684e-02,\n",
      "           4.2138e-01,  4.5178e-01, -8.1737e-01,  9.0786e-01, -2.2890e+00,\n",
      "          -4.1592e-01,  3.8333e-01,  1.2402e+00,  1.3238e+00,  0.0000e+00,\n",
      "          -3.6308e-01, -1.0240e+00,  0.0000e+00,  1.1431e+00,  1.2412e+00,\n",
      "          -1.7252e+00,  0.0000e+00,  2.3661e-02, -1.1033e+00, -1.0519e+00,\n",
      "           2.0673e+00, -1.0334e+00, -1.4449e-02, -1.6000e+00, -2.1366e+00,\n",
      "          -1.4498e+00,  2.6594e-01,  1.2573e+00,  1.5808e+00,  1.7486e+00,\n",
      "          -1.4315e-01,  0.0000e+00, -1.5733e+00, -1.6978e+00,  8.3393e-02,\n",
      "           7.6526e-01,  1.2415e+00, -1.7326e-01, -6.1082e-02,  1.5751e-01,\n",
      "           4.7168e-02,  5.0024e-01, -7.3856e-01,  1.8372e+00,  0.0000e+00,\n",
      "          -5.8528e-02,  5.1267e-01,  3.1094e+00, -1.2286e-01,  7.7601e-01,\n",
      "           3.1666e-01,  4.9962e-01, -8.3289e-01, -1.5117e+00, -3.0417e+00,\n",
      "          -3.8987e-01,  1.4387e+00,  2.2827e-01,  5.3559e-01,  1.1804e-01,\n",
      "           1.6056e+00,  0.0000e+00,  1.1873e+00, -2.2844e+00,  8.1097e-01,\n",
      "          -1.1734e+00,  1.3331e-01,  2.5244e-02,  7.6395e-02,  3.9348e-01,\n",
      "          -5.0641e-01, -6.9401e-01,  9.4014e-01, -3.8690e-01, -2.2315e+00,\n",
      "          -6.9041e-01, -5.8100e-01, -9.1523e-02, -1.2243e-04,  0.0000e+00,\n",
      "           8.7853e-01, -7.7000e-01,  7.4847e-01, -2.2790e-01,  1.2547e+00,\n",
      "          -7.0893e-01,  1.7594e-01,  6.2524e-02, -8.1861e-01, -7.3383e-01,\n",
      "           1.1295e+00, -1.6392e-01,  3.8359e-01,  2.9641e-01,  4.8188e-01,\n",
      "           5.8284e-01, -9.1922e-02,  3.0258e-01,  0.0000e+00,  2.4508e-02,\n",
      "          -1.4589e+00,  2.8702e-01,  0.0000e+00, -1.0697e+00,  1.4948e-02,\n",
      "           6.9917e-01,  6.0864e-01, -2.2865e+00,  2.3980e-01,  7.7216e-01,\n",
      "          -4.4427e-01,  1.3062e+00, -1.5005e+00, -1.7263e+00, -3.0708e-01,\n",
      "          -1.4511e+00,  1.6058e-01,  7.1098e-01,  0.0000e+00, -1.6099e-01,\n",
      "           7.3886e-01, -3.8101e-01, -3.6746e-01, -2.0929e-01,  4.1903e-01,\n",
      "          -1.5330e+00,  9.8054e-01, -2.6619e+00,  0.0000e+00,  8.2888e-02,\n",
      "           0.0000e+00, -6.1946e-01,  0.0000e+00,  6.5840e-01,  9.6115e-03,\n",
      "          -9.1211e-01,  0.0000e+00, -7.2959e-02,  1.5352e-01,  5.4932e-03,\n",
      "          -1.3590e+00,  8.2046e-01,  2.0696e+00, -6.5869e-01,  0.0000e+00,\n",
      "          -9.2847e-01,  7.9988e-02, -9.5562e-01,  0.0000e+00,  1.0584e+00,\n",
      "           6.0085e-01, -1.5957e-01, -3.9593e-01,  1.6387e-01,  2.6475e-01,\n",
      "          -8.9040e-01, -1.3017e+00,  1.0961e+00, -9.4904e-01, -8.7025e-01,\n",
      "           8.0301e-01,  0.0000e+00,  1.1141e+00, -1.6178e+00, -4.4758e-01,\n",
      "          -1.2862e+00,  9.7575e-01, -4.2867e-01,  9.7187e-01,  6.2667e-01,\n",
      "          -6.2574e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0577, 0.0826, 0.0940, 0.1051, 0.1736, 0.0886, 0.0648, 0.1085, 0.1199,\n",
      "         0.1052]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0054,  0.1544, -0.1418,  ...,  0.5517,  0.1656, -0.1452],\n",
      "        [ 0.0491,  0.0847, -0.2441,  ..., -0.0551, -0.0096,  0.2363],\n",
      "        [-0.1029, -0.0511,  0.3607,  ..., -0.2280, -0.1832,  0.1082],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1098, -0.0714, -0.1816, -0.0272,  0.0655,  0.1143, -0.1212,\n",
      "          -0.0530, -0.0014, -0.1467,  0.0898, -0.1661, -0.1841, -0.1950,\n",
      "           0.0294,  0.1396, -0.0276, -0.0504, -0.1061, -0.0551, -0.1463,\n",
      "           0.0190, -0.0637,  0.0142,  0.0303,  0.1131,  0.0083, -0.1013,\n",
      "          -0.0381, -0.0232,  0.0080,  0.0839,  0.0888, -0.1474,  0.0968,\n",
      "          -0.1467, -0.1042,  0.0296, -0.1043, -0.1098, -0.0019,  0.1944,\n",
      "           0.0353, -0.0423,  0.0982, -0.0457,  0.0372, -0.1128,  0.0401,\n",
      "          -0.0095, -0.1631, -0.0227, -0.0006, -0.1526, -0.3032,  0.0123,\n",
      "          -0.0216, -0.1602,  0.0330,  0.1450, -0.0936,  0.0544,  0.0682,\n",
      "           0.0110,  0.1315,  0.0377,  0.0003, -0.1000,  0.0379, -0.0393,\n",
      "           0.2828,  0.1350,  0.0883, -0.0316,  0.1259, -0.0865,  0.1683,\n",
      "           0.1011,  0.0398,  0.1283, -0.0972,  0.0923, -0.0514,  0.0962,\n",
      "           0.0240,  0.0330,  0.0202,  0.0600,  0.0191, -0.0429,  0.1790,\n",
      "          -0.0408, -0.1400,  0.0232,  0.1410,  0.1295, -0.0456,  0.1097,\n",
      "           0.1313,  0.0689,  0.0823,  0.1267,  0.1026, -0.0178, -0.0354,\n",
      "          -0.2836,  0.0607,  0.1106,  0.0356, -0.1422, -0.0237,  0.0562,\n",
      "          -0.1176, -0.0183,  0.0502,  0.1094, -0.1019,  0.0059, -0.2286,\n",
      "          -0.0088,  0.1296,  0.2275, -0.1385,  0.0080, -0.0507, -0.1372,\n",
      "          -0.0500, -0.1240,  0.1281, -0.0582, -0.0294, -0.1390, -0.0403,\n",
      "           0.1175, -0.1241,  0.0787,  0.2143,  0.0387, -0.0935, -0.1139,\n",
      "          -0.1025,  0.1818, -0.1583,  0.0599,  0.0880, -0.0411, -0.0514,\n",
      "           0.2476, -0.0545,  0.0894, -0.2358,  0.0056, -0.0346,  0.1013,\n",
      "          -0.1464,  0.0827,  0.0789,  0.0626, -0.0519,  0.0754, -0.1080,\n",
      "           0.0053, -0.2350,  0.0625, -0.1127, -0.1597, -0.0433, -0.0571,\n",
      "           0.0245,  0.0328, -0.1972,  0.0805,  0.1623,  0.0284,  0.1406,\n",
      "           0.1739,  0.0321, -0.1083,  0.1935,  0.0448,  0.0726, -0.0087,\n",
      "           0.0077,  0.0423,  0.1044, -0.0324, -0.1440,  0.0335, -0.0103,\n",
      "          -0.0398, -0.0923,  0.0524, -0.0486, -0.1284, -0.0347, -0.1627,\n",
      "          -0.0096, -0.0229,  0.0017,  0.0112,  0.0117, -0.0277,  0.0892,\n",
      "           0.1680, -0.0807,  0.0716,  0.0155,  0.0446, -0.0797, -0.0987,\n",
      "           0.1019,  0.0515, -0.0520,  0.1558,  0.0742, -0.1407, -0.0013,\n",
      "           0.0631, -0.1274,  0.1104,  0.1332, -0.0390, -0.0092, -0.0784,\n",
      "          -0.0360,  0.0420,  0.1594, -0.0406, -0.0973,  0.0720, -0.1428,\n",
      "          -0.0840,  0.0245, -0.0122,  0.0477, -0.1257, -0.1979,  0.1795,\n",
      "           0.3274,  0.1626, -0.0231, -0.0143,  0.0444, -0.0263, -0.0483,\n",
      "          -0.2128, -0.1281, -0.0875, -0.1333, -0.0022,  0.1722,  0.1459,\n",
      "          -0.0363, -0.0193, -0.1105, -0.0900]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7277e-01, -4.3055e-01,  0.0000e+00, -1.0845e+00, -1.1723e+00,\n",
      "           7.4192e-01, -1.9142e+00,  1.3514e+00,  1.9059e-01,  6.1744e-01,\n",
      "           1.9026e+00,  6.0241e-01,  0.0000e+00, -9.1594e-01, -3.1817e+00,\n",
      "          -6.8558e-02, -1.6329e+00, -9.4347e-01,  0.0000e+00, -1.4346e+00,\n",
      "          -1.4078e-01, -5.2327e-01, -1.1193e+00, -2.5947e+00, -7.5491e-02,\n",
      "           1.3912e+00, -6.1921e-01,  1.9966e+00,  1.2763e-01,  5.5380e-01,\n",
      "           9.1460e-01, -3.4872e-03,  2.2306e-01,  2.0151e+00, -6.3924e-02,\n",
      "           0.0000e+00, -1.1198e-01, -8.1788e-01,  0.0000e+00,  8.5330e-02,\n",
      "           8.6190e-01, -9.0001e-01,  1.0091e+00, -1.5631e+00,  1.9438e+00,\n",
      "          -2.9998e-01,  7.0446e-01, -6.0108e-01, -1.0205e+00,  1.1162e+00,\n",
      "          -1.3219e+00,  2.6765e+00,  6.6663e-01, -8.4652e-01,  2.2732e-01,\n",
      "          -3.0876e-01, -1.4343e+00, -9.6771e-02,  1.2747e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6179e-02, -2.8017e-01,  2.6583e-01, -6.2666e-02,\n",
      "           3.9434e-01,  5.7809e-01,  1.1648e+00,  1.5804e+00, -1.4150e+00,\n",
      "           4.2763e-01,  2.9649e-01, -3.1374e-02, -7.9769e-01, -2.1455e-01,\n",
      "           0.0000e+00,  0.0000e+00,  1.3985e+00,  1.0268e+00, -7.9284e-01,\n",
      "           7.5740e-01, -1.0059e+00,  7.5697e-01,  1.0587e+00, -1.2142e+00,\n",
      "           0.0000e+00, -1.1073e+00,  5.4870e-01, -9.4471e-01, -1.9014e+00,\n",
      "           5.2896e-01,  9.8636e-01,  1.7013e+00,  9.4324e-01,  6.0824e-01,\n",
      "          -1.5913e-02,  3.5292e-01, -1.1754e+00,  1.3711e+00,  2.4476e+00,\n",
      "           2.4395e-01,  4.6052e-02, -4.6628e-01, -9.8940e-01,  1.6395e+00,\n",
      "          -1.0224e+00,  3.0283e+00,  6.1952e-01, -1.0211e-01, -1.2353e+00,\n",
      "           1.8981e-01, -5.0274e-01, -5.7013e-01,  7.1219e-01, -7.8035e-01,\n",
      "           6.3189e-01,  4.0415e-01,  2.2421e-01, -2.3272e+00,  2.9390e-02,\n",
      "          -8.1344e-01, -1.4101e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -1.9999e-01,  3.9069e-02,  2.1498e+00,  1.3961e+00,  0.0000e+00,\n",
      "          -9.2648e-01,  0.0000e+00, -1.1670e+00,  4.2511e-01, -4.6891e-01,\n",
      "          -7.4431e-01, -1.0649e+00, -9.7462e-01, -1.9451e-02,  2.3975e+00,\n",
      "           6.9844e-01, -1.1217e+00,  1.6915e+00, -1.4011e-01, -6.6928e-01,\n",
      "           0.0000e+00,  7.5924e-01,  4.2306e-01, -1.0328e+00, -9.5679e-02,\n",
      "           1.5601e+00,  5.8699e-01, -3.3907e-01,  6.5753e-01,  1.8405e+00,\n",
      "          -2.5238e-01, -2.1717e-01,  6.2327e-01, -2.3619e+00,  0.0000e+00,\n",
      "           3.0229e-01, -7.7614e-02,  0.0000e+00, -1.2114e+00,  0.0000e+00,\n",
      "           1.6817e+00,  1.8514e+00,  2.7044e-01, -1.2701e+00, -7.1349e-01,\n",
      "          -1.2243e+00, -1.0938e+00, -2.5899e+00,  5.0544e-01, -3.0579e+00,\n",
      "          -2.8698e-01,  4.9839e-01,  8.2928e-01,  3.1700e-01, -7.9274e-01,\n",
      "           2.7100e-01,  2.3396e+00,  1.0570e+00,  8.3810e-01,  0.0000e+00,\n",
      "           7.2686e-01,  5.9916e-01,  3.5926e-01,  8.4189e-01, -1.8296e+00,\n",
      "           1.3635e+00,  2.1587e+00,  3.3706e-01, -1.0151e+00, -1.1711e+00,\n",
      "           0.0000e+00,  1.6654e+00,  0.0000e+00,  3.6335e-01,  2.3835e+00,\n",
      "           3.2350e-02, -5.0153e-01, -1.2758e+00, -5.4228e-01, -4.0735e-01,\n",
      "          -1.4465e+00,  9.5388e-01, -8.5149e-01,  8.3097e-01, -1.5596e+00,\n",
      "           6.3611e-01,  6.7635e-01,  0.0000e+00,  5.4878e-02,  1.8941e+00,\n",
      "           1.3076e+00,  5.8085e-01, -2.3167e+00,  1.5502e+00, -2.2251e-01,\n",
      "          -2.2713e-01,  0.0000e+00,  2.7718e-01, -1.5519e+00,  9.2265e-01,\n",
      "          -1.2245e+00, -8.4775e-01,  0.0000e+00, -1.6838e-04,  3.7345e-01,\n",
      "          -1.5732e+00, -1.2336e-01,  9.6626e-01,  0.0000e+00,  1.6937e+00,\n",
      "          -1.4405e+00,  6.3406e-01, -1.7215e+00,  9.8046e-01, -1.7151e+00,\n",
      "           1.5600e+00, -2.7185e-01,  0.0000e+00,  1.2381e+00, -1.2287e+00,\n",
      "           1.8835e+00, -5.0831e-01,  0.0000e+00, -2.6145e-01, -1.0214e+00,\n",
      "           1.3330e+00,  3.1001e-01,  0.0000e+00, -2.2891e-01, -1.6112e+00,\n",
      "           1.8060e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0459, 0.1253, 0.1597, 0.0883, 0.1213, 0.0916, 0.1061, 0.0743, 0.0957,\n",
      "         0.0918]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0054,  0.1544, -0.1418,  ...,  0.5517,  0.1656, -0.1452],\n",
      "        [ 0.0491,  0.0847, -0.2441,  ..., -0.0551, -0.0096,  0.2363],\n",
      "        [-0.1029, -0.0511,  0.3607,  ..., -0.2280, -0.1832,  0.1082],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.9223e-02, -4.6215e-02, -1.7133e-01, -4.7968e-02,  8.4235e-02,\n",
      "           1.7286e-01, -1.6948e-01, -9.6338e-02, -1.6665e-02, -1.3457e-01,\n",
      "           1.3619e-01, -1.8078e-01, -2.0735e-01, -2.2242e-01,  5.8855e-02,\n",
      "           1.7690e-01, -1.6557e-02, -8.5332e-02, -1.1937e-01, -1.1152e-01,\n",
      "          -1.5227e-01,  7.7893e-03, -9.3195e-02,  3.1246e-02,  3.4903e-02,\n",
      "           1.3184e-01, -1.2055e-02, -7.8477e-02, -4.0574e-02, -4.8501e-02,\n",
      "          -1.3814e-02,  9.6750e-02,  1.2434e-01, -1.5563e-01,  8.2119e-02,\n",
      "          -1.0392e-01, -1.2098e-01, -4.3809e-03, -1.3308e-01, -1.3029e-01,\n",
      "          -1.1423e-02,  2.0634e-01, -1.3993e-02, -7.3429e-02,  9.1216e-02,\n",
      "          -5.3715e-03,  3.2193e-02, -1.4533e-01,  2.9563e-02,  3.0254e-02,\n",
      "          -1.6916e-01, -6.2153e-02, -4.4088e-03, -1.4928e-01, -3.3486e-01,\n",
      "          -2.3552e-02, -2.6242e-02, -1.5171e-01,  7.3562e-02,  1.6383e-01,\n",
      "          -1.1793e-01,  6.6423e-02,  3.8818e-02, -1.2996e-02,  1.4407e-01,\n",
      "           2.5403e-02,  1.1898e-02, -7.7680e-02,  4.5426e-02, -1.1120e-02,\n",
      "           2.9664e-01,  1.8356e-01,  1.0873e-01, -2.8196e-02,  1.0884e-01,\n",
      "          -8.2187e-02,  1.9124e-01,  8.1705e-02,  9.9730e-03,  1.5656e-01,\n",
      "          -9.8061e-02,  8.0211e-02, -1.2602e-01,  1.0819e-01,  5.6103e-03,\n",
      "           5.0583e-02,  3.5653e-03,  1.1067e-01,  1.1611e-02, -3.0312e-02,\n",
      "           1.8465e-01, -6.6572e-02, -1.4532e-01,  2.4838e-03,  1.1931e-01,\n",
      "           1.2597e-01, -1.0117e-02,  1.4900e-01,  7.8324e-02,  8.6008e-02,\n",
      "           1.1269e-01,  1.2693e-01,  1.0956e-01, -2.7381e-05, -2.4730e-02,\n",
      "          -3.0672e-01,  6.1354e-02,  1.1876e-01,  3.8322e-02, -1.5043e-01,\n",
      "           1.7802e-02,  9.3745e-02, -1.2535e-01, -6.2057e-02,  5.5810e-02,\n",
      "           1.3448e-01, -7.9671e-02, -3.0022e-02, -2.7634e-01, -3.4754e-02,\n",
      "           1.0325e-01,  2.4343e-01, -1.2168e-01,  2.3120e-02, -6.6611e-02,\n",
      "          -1.5683e-01, -5.3422e-02, -1.2024e-01,  1.6561e-01, -3.3783e-02,\n",
      "          -5.7635e-02, -1.2069e-01, -3.0414e-02,  1.3899e-01, -1.8704e-01,\n",
      "           1.5877e-02,  2.2747e-01,  2.2593e-02, -1.2864e-01, -1.3590e-01,\n",
      "          -1.4461e-01,  2.1216e-01, -1.4401e-01,  7.5548e-02,  9.2019e-02,\n",
      "          -2.3666e-02, -4.6995e-02,  2.8308e-01, -4.0987e-02,  8.1595e-02,\n",
      "          -2.7310e-01, -2.7287e-02, -4.8756e-03,  1.4540e-01, -1.4774e-01,\n",
      "           3.7489e-02,  6.7073e-02,  5.2241e-02, -5.4298e-02,  4.2588e-02,\n",
      "          -1.3520e-01,  9.1012e-03, -2.3353e-01,  1.0953e-01, -7.8697e-02,\n",
      "          -1.6117e-01, -1.0466e-02, -3.2679e-02,  6.6186e-02,  6.3186e-02,\n",
      "          -1.8470e-01,  8.7818e-02,  1.6489e-01,  8.3840e-02,  1.2640e-01,\n",
      "           1.8239e-01,  1.9640e-02, -6.3894e-02,  2.3516e-01,  5.7996e-02,\n",
      "           5.1490e-02, -6.8562e-02,  1.5958e-02,  2.3351e-02,  1.0694e-01,\n",
      "          -2.3106e-02, -1.3965e-01,  4.1999e-02,  3.1197e-02, -6.3568e-02,\n",
      "          -9.1179e-02,  5.3624e-02, -6.1124e-02, -1.3633e-01, -4.1119e-02,\n",
      "          -2.1635e-01, -5.0449e-02, -1.1937e-02,  2.3747e-04,  3.2665e-02,\n",
      "          -1.6251e-02,  3.8670e-02,  1.1898e-01,  2.2951e-01, -9.3132e-02,\n",
      "           9.9953e-02, -2.2614e-02,  3.9885e-02, -8.7361e-02, -1.0105e-01,\n",
      "           1.0656e-01,  4.2855e-02, -5.3682e-02,  1.5429e-01,  8.0583e-02,\n",
      "          -1.0020e-01, -2.4626e-02,  6.6995e-02, -1.6388e-01,  1.3754e-01,\n",
      "           1.8688e-01, -4.9673e-02,  2.5149e-02, -1.3587e-01, -1.2714e-02,\n",
      "           3.9493e-02,  1.5271e-01, -2.2266e-02, -1.2611e-01,  5.4834e-02,\n",
      "          -1.6328e-01, -7.0147e-02,  3.1337e-02, -6.5213e-02,  8.5825e-03,\n",
      "          -1.5402e-01, -2.5129e-01,  2.0535e-01,  3.4779e-01,  1.5062e-01,\n",
      "          -1.7099e-02, -8.4896e-02,  3.0018e-02, -2.2366e-02, -8.8758e-02,\n",
      "          -2.4042e-01, -2.1241e-01, -6.6983e-02, -1.2192e-01, -5.5170e-04,\n",
      "           1.4907e-01,  1.3537e-01, -1.1538e-02, -5.9722e-02, -9.6638e-02,\n",
      "          -6.0435e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7174e-02,  4.0014e-01, -9.6462e-01, -6.8082e-01,  3.7526e-01,\n",
      "          -2.0183e-01,  1.4644e+00, -8.3712e-02, -3.5830e+00,  9.0690e-01,\n",
      "           4.2778e-01, -6.2927e-01,  0.0000e+00, -6.3047e-01, -5.4133e-01,\n",
      "          -1.5804e-01,  8.5141e-01,  1.0940e+00,  4.5520e-01,  4.3624e-01,\n",
      "          -6.3313e-01, -3.8218e-01,  1.6394e+00,  1.5111e+00,  7.5305e-01,\n",
      "          -7.5946e-02, -1.8832e-01, -7.6022e-01,  1.6532e+00,  8.6119e-01,\n",
      "           1.2312e+00,  1.2193e+00, -1.0340e+00, -8.3068e-02, -1.5341e+00,\n",
      "           1.3955e+00,  2.8058e-01, -3.7438e+00,  1.9762e-01,  1.5997e+00,\n",
      "          -4.5903e-01, -1.3977e+00, -2.6921e-01, -1.7140e+00, -1.5231e+00,\n",
      "           6.6795e-01,  5.4031e-01,  3.7142e-01, -1.3402e+00,  1.4469e-01,\n",
      "           0.0000e+00,  2.7501e+00,  6.0999e-01, -1.0283e+00, -2.4813e-02,\n",
      "           2.0437e-01, -8.8108e-01, -1.2506e+00, -2.3748e-01, -4.2641e-01,\n",
      "           1.0984e+00,  1.4067e+00, -2.0216e-01, -5.0075e-01, -2.9619e+00,\n",
      "           5.5176e-01,  1.2777e+00, -1.2872e+00,  4.0953e-01,  5.2676e-01,\n",
      "          -1.2662e+00, -2.9474e-02,  7.0726e-01, -3.6390e+00,  3.2477e-01,\n",
      "          -4.4551e-04, -1.6021e-01,  1.0610e+00,  0.0000e+00, -1.1755e-01,\n",
      "          -1.3994e+00,  2.1294e+00,  0.0000e+00,  0.0000e+00, -2.0747e-01,\n",
      "           4.3664e-01,  1.6611e+00, -9.7394e-01, -1.0463e-01,  0.0000e+00,\n",
      "          -2.2719e+00,  1.0994e+00, -6.2234e-01, -1.1358e+00,  4.6679e-01,\n",
      "          -1.1697e+00,  3.2296e-02,  0.0000e+00,  1.7190e+00, -7.7783e-01,\n",
      "           2.6965e+00, -1.4611e+00,  1.0758e+00,  1.4523e+00, -6.6588e-01,\n",
      "          -7.6207e-01,  1.2105e+00,  1.2747e-01, -1.4728e+00, -1.4084e-02,\n",
      "          -2.4794e-01,  1.3392e-01, -1.0469e+00,  1.3100e+00, -1.6521e+00,\n",
      "          -2.9873e+00, -5.7038e-02, -4.9900e-01,  0.0000e+00,  4.4573e-01,\n",
      "          -1.4644e+00,  7.0184e-01, -1.4600e+00, -7.2545e-01, -9.5732e-01,\n",
      "          -1.3069e+00,  8.9514e-01,  1.6939e-01,  0.0000e+00, -7.5075e-01,\n",
      "          -8.2436e-01,  5.3109e-01, -1.5823e+00,  9.8387e-01,  2.7639e-01,\n",
      "          -5.8893e-01,  6.5803e-01,  5.7588e-01, -1.1592e+00, -1.0090e+00,\n",
      "          -3.8780e-01,  6.7774e-01,  0.0000e+00, -1.0038e-01, -1.6843e+00,\n",
      "          -9.9884e-02, -5.4267e-01, -8.4427e-01, -7.5452e-01,  1.7769e-01,\n",
      "           1.9973e+00, -1.9905e-01, -1.9293e+00, -4.0635e-01,  4.4108e-01,\n",
      "          -1.9446e-01, -6.5060e-02, -1.3083e-01,  0.0000e+00,  5.3727e-01,\n",
      "          -2.6576e-02,  2.2060e+00,  4.8100e-01, -5.5066e-01, -5.2535e-01,\n",
      "          -8.9080e-01,  2.8159e-01,  8.2550e-02, -3.5824e-01, -4.7783e-01,\n",
      "           7.3575e-01, -3.0398e-02,  2.0131e-02,  0.0000e+00,  1.2774e+00,\n",
      "          -1.0975e+00, -9.8537e-01, -2.0748e+00,  1.9678e+00,  8.6301e-02,\n",
      "          -3.1167e-02,  3.4998e-02,  6.7051e-01,  9.7987e-01, -7.4799e-01,\n",
      "          -3.4115e-01, -2.7810e+00, -7.8255e-01,  0.0000e+00,  1.0126e+00,\n",
      "           3.0719e+00,  4.9382e-01, -1.4435e-01, -5.9268e-01,  0.0000e+00,\n",
      "           2.1638e+00, -1.1873e+00,  5.3495e-01,  1.8107e+00, -9.4580e-01,\n",
      "          -1.6625e+00,  0.0000e+00,  0.0000e+00, -1.2221e-01,  2.3209e-01,\n",
      "          -5.7453e-01, -2.2916e+00,  6.8174e-01, -1.0726e+00, -4.7119e-01,\n",
      "           0.0000e+00, -5.7308e-01, -3.4147e-01,  7.9252e-01,  3.2280e-02,\n",
      "          -6.8300e-01, -1.0166e+00,  9.6694e-01, -2.4504e-01,  2.1681e+00,\n",
      "          -1.0827e+00,  0.0000e+00, -1.8430e+00,  0.0000e+00,  3.3990e-01,\n",
      "           7.0478e-01, -6.9663e-01, -6.2812e-01,  2.9219e-01,  0.0000e+00,\n",
      "          -1.1078e+00,  1.5810e+00, -6.1355e-01,  1.3103e+00, -2.9786e+00,\n",
      "           4.0329e+00,  5.8500e-01,  4.2673e-02, -1.5780e+00, -2.8578e-01,\n",
      "           7.4208e-01, -3.2458e+00, -3.0343e-01, -8.5154e-01,  1.1332e-02,\n",
      "           2.7582e-01,  2.7467e-01,  2.5207e-01,  2.6152e-01,  3.8692e-01,\n",
      "          -3.6588e-01, -1.5983e-01, -5.5322e-01,  0.0000e+00, -1.1460e+00,\n",
      "          -1.1312e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0581, 0.0584, 0.1096, 0.0510, 0.1314, 0.2611, 0.0577, 0.0799, 0.0574,\n",
      "         0.1354]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 3.5815e-01, -1.9247e-02,  8.0236e-02,  ..., -1.2145e-01,\n",
      "         -3.1416e-02, -4.7237e-01],\n",
      "        [ 1.2435e-01,  1.5096e-01,  2.7631e-01,  ...,  1.1423e-01,\n",
      "          6.0215e-02,  4.5594e-02],\n",
      "        [ 3.2242e-01, -3.8844e-02,  3.2152e-01,  ...,  8.8124e-02,\n",
      "         -1.2406e-05, -5.7762e-02],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.1776e-01,  2.1905e-02, -2.7278e-02,  4.6146e-02,  7.1875e-02,\n",
      "           3.2338e-02, -4.9234e-03, -1.6209e-02, -1.8522e-02,  6.2172e-02,\n",
      "           4.7267e-02, -5.9283e-02, -3.8363e-02,  1.9963e-02,  3.2208e-02,\n",
      "           9.0284e-02,  3.3027e-02,  4.5223e-02, -1.6735e-01, -6.9015e-02,\n",
      "          -1.1523e-01,  5.2558e-03, -2.2214e-02, -7.3987e-02, -1.8393e-01,\n",
      "          -3.8289e-02,  9.8646e-03, -1.1751e-01,  3.6002e-02, -4.7820e-02,\n",
      "           7.3168e-02, -4.4425e-02, -4.9017e-02, -9.1849e-02, -1.1228e-02,\n",
      "           3.4661e-02, -1.2881e-01, -4.4525e-02, -6.6132e-02, -7.4590e-03,\n",
      "           2.2049e-02,  2.2703e-02, -3.6125e-02, -9.2082e-02,  1.4321e-01,\n",
      "          -2.4701e-02,  1.3205e-01, -2.0677e-02,  9.2527e-02, -2.2289e-02,\n",
      "          -7.5458e-02, -1.0389e-01, -1.4542e-01, -7.9901e-02, -1.5385e-01,\n",
      "          -3.3711e-02, -8.0354e-02,  1.2283e-01, -1.7565e-02,  1.1372e-01,\n",
      "           3.3012e-02, -4.6935e-02, -9.9131e-02,  9.0889e-02, -1.1469e-03,\n",
      "           8.2727e-02, -1.2515e-02,  8.4724e-02, -4.6188e-02,  3.9608e-02,\n",
      "           6.1503e-02,  1.1969e-01, -2.1473e-02, -7.8104e-02, -1.0948e-01,\n",
      "          -1.7227e-02,  3.5999e-02,  5.0861e-02,  3.5387e-02, -4.7630e-02,\n",
      "          -1.3008e-01, -1.0905e-01, -5.5647e-02, -4.5707e-02,  7.3032e-02,\n",
      "           6.9227e-03,  1.0359e-01,  1.1575e-01, -1.9173e-02, -4.6560e-02,\n",
      "           1.0793e-02,  1.5688e-01, -5.4943e-02, -7.5876e-02,  1.2602e-02,\n",
      "           1.1287e-01,  1.6881e-01,  1.1107e-01, -1.4730e-02,  9.0228e-02,\n",
      "          -9.4149e-02,  1.9094e-02,  5.2348e-02,  6.1206e-02, -2.1572e-02,\n",
      "          -3.6284e-02,  8.5293e-02,  2.8575e-02, -2.4605e-02, -7.7458e-03,\n",
      "           6.7408e-02, -1.6138e-02, -7.0111e-02, -3.4774e-02,  6.4530e-02,\n",
      "          -9.2126e-02, -3.7682e-03, -5.6525e-02, -4.3568e-02, -1.7839e-01,\n",
      "           8.8278e-02, -1.0073e-01, -7.8118e-03,  3.2586e-02, -1.0322e-01,\n",
      "           1.0992e-03,  1.4182e-01, -4.6157e-02,  1.9143e-01,  6.8875e-02,\n",
      "          -1.3043e-03, -7.2597e-02,  1.0454e-01,  5.5574e-02,  3.1327e-02,\n",
      "          -3.7862e-02,  1.7002e-01,  1.9424e-02,  1.7375e-01, -8.6606e-04,\n",
      "          -1.2179e-02,  1.2452e-01,  1.8195e-02,  1.2977e-01,  2.0049e-02,\n",
      "          -3.4096e-02,  1.4035e-01,  9.1298e-02, -4.8327e-02,  1.1777e-02,\n",
      "          -8.6947e-02, -5.0548e-02,  7.1117e-02,  8.2111e-02, -1.1165e-02,\n",
      "           1.5292e-01,  1.7040e-02,  9.4237e-02, -1.1691e-01, -3.2247e-03,\n",
      "           1.6232e-02,  5.0076e-02, -9.8899e-02,  6.4258e-02, -8.3179e-02,\n",
      "          -3.9064e-02,  1.9436e-03, -6.2254e-02,  1.6347e-04,  1.4767e-01,\n",
      "          -5.5889e-02,  5.7229e-02,  6.0588e-02, -7.6766e-03,  1.2384e-01,\n",
      "          -4.1665e-02, -2.0374e-02,  7.2304e-02,  1.3895e-01, -9.9316e-03,\n",
      "          -2.5194e-02,  6.6803e-02, -2.6909e-02, -1.8693e-02,  1.1646e-01,\n",
      "           3.8362e-02, -4.0844e-02,  2.7402e-02,  3.8812e-02, -2.1162e-02,\n",
      "           4.2253e-02, -6.1789e-02, -1.2602e-01,  2.2222e-02, -6.9895e-03,\n",
      "           8.3422e-03,  7.7259e-02,  6.7935e-02, -5.7047e-02,  2.2648e-02,\n",
      "          -3.6217e-02,  2.4091e-02,  1.9871e-02,  1.2498e-01,  1.8017e-02,\n",
      "           2.1757e-02, -1.0761e-01,  1.1342e-01,  3.1958e-02, -1.1914e-02,\n",
      "          -9.4615e-03, -1.5198e-01, -1.0647e-01, -8.0598e-02,  8.3375e-02,\n",
      "           4.9440e-02,  5.8467e-02,  1.9808e-01, -1.7506e-01, -3.9890e-02,\n",
      "           1.1824e-01,  3.8525e-03,  1.5224e-01, -1.0555e-01,  3.6691e-02,\n",
      "           7.0344e-02,  1.2163e-01, -9.3575e-03, -2.2342e-01,  2.9608e-02,\n",
      "          -1.7766e-02, -5.2661e-02, -3.5176e-02, -4.9305e-02, -5.3401e-02,\n",
      "          -7.5533e-02, -6.6736e-02,  1.5528e-02,  1.1463e-01, -1.2066e-02,\n",
      "           4.7362e-02, -8.7723e-02, -2.0090e-01,  1.7945e-02,  7.7827e-02,\n",
      "           3.5448e-02, -1.9931e-02, -1.5116e-01, -1.8230e-02, -3.3709e-02,\n",
      "           1.9851e-02, -1.6680e-02, -7.2884e-02, -3.2659e-02,  2.5985e-02,\n",
      "          -4.1408e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4728, -0.4586, -1.2334, -0.1186,  0.4614,  0.0259,  0.6620,\n",
      "           0.5340,  0.6709,  0.0000,  1.7076, -1.0163,  0.9456, -0.2518,\n",
      "           0.0000,  0.5122,  1.8776, -0.7568, -1.5631, -2.6431,  0.0000,\n",
      "           0.1684,  2.9292,  0.5544, -0.1172,  3.2088,  1.8371,  0.5186,\n",
      "          -2.2265, -1.2859,  0.0288,  1.0131,  0.3250,  0.8597, -0.7987,\n",
      "          -1.4655,  0.6197, -0.7714,  0.0000,  0.1016,  0.4673, -2.2045,\n",
      "          -0.5665, -0.1150, -0.7131, -0.6890,  1.9273,  0.1099, -0.2870,\n",
      "          -1.8504,  1.4676,  0.4622,  0.6673, -0.2831,  0.5316,  0.2749,\n",
      "          -1.2427, -0.9509,  1.8137, -0.0119,  0.2052, -1.8186, -1.4010,\n",
      "           0.0000,  1.1798,  0.2654, -0.1671, -0.2547, -0.0048, -0.4607,\n",
      "          -0.3250, -0.3241,  0.1473, -0.1262,  0.0000, -0.8062,  2.0664,\n",
      "           1.6791,  0.0878, -0.5455,  1.2267,  0.0000,  0.3266, -1.8362,\n",
      "          -0.0711, -1.7317, -1.4585, -0.8914,  0.6229,  0.8108, -1.2238,\n",
      "          -1.1442,  1.9848, -0.3663, -0.7340,  0.1565,  2.1408, -0.4058,\n",
      "          -0.3040, -1.8393, -1.2906, -0.7211, -0.7664,  0.2368,  0.3817,\n",
      "           1.1138, -1.0706,  2.2523,  0.0000, -0.2883, -0.0532,  0.0000,\n",
      "          -0.2544, -0.2804, -1.9418,  1.1284,  1.0064, -2.4970, -0.5751,\n",
      "           0.0296, -1.6944, -0.4009, -0.3790, -0.0782, -0.5366, -1.1106,\n",
      "           1.3041,  0.1695,  0.3222,  1.3582,  0.0000, -2.6339,  0.3599,\n",
      "          -0.7230,  0.4292,  0.0602,  0.3265, -2.1012, -0.4968, -1.6774,\n",
      "          -0.6417,  0.2344, -1.1867, -1.2145, -0.6308, -0.0404,  0.4647,\n",
      "           1.7381,  1.5949,  1.4319, -1.2625, -0.5774, -0.4801, -0.0394,\n",
      "           0.3265, -0.1171,  1.3536, -0.0318, -1.9004, -1.8063, -1.4264,\n",
      "          -0.9002,  0.0000, -0.3891, -0.9806,  0.0000,  0.0000,  0.9700,\n",
      "           0.5179, -0.1475,  1.5129, -0.3729, -0.3158, -2.0086,  0.1298,\n",
      "          -0.3526, -0.8298, -0.7688,  0.0000, -0.9374,  0.0000,  1.0418,\n",
      "           0.0469,  0.0000,  0.3160, -0.1183, -0.5407, -0.6643,  0.7547,\n",
      "          -1.0640, -0.5870, -1.7883,  1.2674, -0.9262, -1.6147,  0.0000,\n",
      "          -1.1569, -1.9606, -0.0719,  0.0000,  2.6970,  0.0000, -2.6312,\n",
      "          -0.5862, -0.7157, -1.3862, -1.2539,  0.0000,  0.2190, -1.1106,\n",
      "           0.9448, -0.6922, -1.5192,  0.3621,  0.0000, -1.4261, -2.3445,\n",
      "           0.0477, -1.4795,  0.4271,  0.0131, -0.9015,  0.3011,  0.0000,\n",
      "           0.0000, -0.1877,  1.2720,  1.2662, -2.1878, -0.0560,  1.7375,\n",
      "          -1.1752,  0.9562,  1.9993,  0.5275,  0.7885, -0.6786,  0.1043,\n",
      "          -0.6803, -2.2618,  0.1673, -0.3132, -1.0431, -0.3820, -1.0799,\n",
      "           0.5577,  1.4993, -0.5644, -1.3768,  1.2434,  0.5827,  1.7528,\n",
      "           1.9517,  0.3627,  0.4875,  0.3900]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0312, 0.2102, 0.0870, 0.0644, 0.1246, 0.1275, 0.0344, 0.1364, 0.1056,\n",
      "         0.0787]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 3.5815e-01, -1.9247e-02,  8.0236e-02,  ..., -1.2145e-01,\n",
      "         -3.1416e-02, -4.7237e-01],\n",
      "        [ 1.2435e-01,  1.5096e-01,  2.7631e-01,  ...,  1.1423e-01,\n",
      "          6.0215e-02,  4.5594e-02],\n",
      "        [ 3.2242e-01, -3.8844e-02,  3.2152e-01,  ...,  8.8124e-02,\n",
      "         -1.2406e-05, -5.7762e-02],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2083e-01,  4.1665e-02,  8.2932e-03,  8.2658e-02,  1.3963e-01,\n",
      "           8.3852e-02, -5.5136e-02,  3.1997e-02,  3.0849e-02,  9.4088e-02,\n",
      "           1.4823e-02, -4.2901e-02, -2.4667e-02,  3.1808e-02,  3.3626e-02,\n",
      "           1.4120e-01,  6.9990e-02,  2.1652e-02, -2.5164e-01, -8.2728e-02,\n",
      "          -1.5768e-01,  2.4574e-02, -6.5827e-02, -1.2030e-01, -1.8640e-01,\n",
      "          -1.0602e-01,  2.3170e-02, -1.0001e-01,  2.8066e-02, -5.5944e-02,\n",
      "           5.1645e-02,  4.0248e-03, -3.6599e-02, -3.5806e-02, -4.0927e-02,\n",
      "           2.3166e-02, -1.9458e-01, -5.4215e-02, -8.8666e-02, -4.7778e-02,\n",
      "           3.8792e-02,  3.1138e-02, -1.8042e-02, -8.6809e-02,  1.8720e-01,\n",
      "          -4.6132e-02,  1.7492e-01,  4.2250e-02,  1.1246e-01, -2.2718e-02,\n",
      "          -9.9369e-02, -1.9395e-01, -7.5011e-02, -1.0216e-01, -1.9691e-01,\n",
      "          -2.7674e-02, -5.4723e-02,  1.5761e-01, -3.8763e-03,  1.6043e-01,\n",
      "           5.0376e-02, -3.5706e-02, -8.4959e-02,  1.0703e-01, -4.0482e-03,\n",
      "           6.1346e-02,  1.8415e-02,  3.1449e-02, -6.6529e-02, -2.6355e-03,\n",
      "           9.6742e-02,  1.6767e-01, -1.1413e-01, -6.1274e-02, -1.5848e-01,\n",
      "          -2.0722e-02,  5.6669e-02,  1.6865e-02,  5.1485e-02, -8.9012e-02,\n",
      "          -1.9376e-01, -1.2826e-01, -5.1939e-02, -1.5370e-02,  1.0526e-01,\n",
      "           2.6824e-02,  1.2726e-01,  1.1220e-01, -5.0737e-02,  1.0441e-02,\n",
      "          -3.6306e-02,  1.6459e-01, -6.1312e-02, -7.8901e-02,  4.6201e-02,\n",
      "           1.3925e-01,  2.0779e-01,  1.4838e-01, -6.6023e-02,  9.4991e-02,\n",
      "          -1.2632e-01,  1.3051e-02,  8.3745e-02,  5.8244e-02, -3.4734e-02,\n",
      "          -3.1648e-02,  1.0987e-01, -2.1274e-02, -5.7315e-02,  4.3855e-03,\n",
      "           5.5034e-03, -2.2121e-02, -8.0083e-02,  1.2237e-02,  1.3123e-01,\n",
      "          -1.1736e-01,  1.7629e-02, -8.9028e-02, -3.7428e-02, -2.2215e-01,\n",
      "           1.3009e-01, -1.1400e-01, -4.7007e-03,  3.6172e-02, -1.5326e-01,\n",
      "          -1.0200e-02,  2.0100e-01, -5.2253e-03,  2.6499e-01,  1.2545e-01,\n",
      "          -1.7298e-02, -1.0237e-01,  1.4471e-01,  1.8870e-02, -1.5746e-02,\n",
      "          -8.8624e-02,  2.2855e-01,  2.4605e-02,  2.4824e-01,  6.2182e-03,\n",
      "           4.6442e-02,  1.6539e-01,  8.4202e-02,  1.8440e-01, -2.7887e-02,\n",
      "          -5.1528e-03,  2.1051e-01,  9.8116e-02, -1.0738e-01, -3.3485e-03,\n",
      "          -1.1860e-01, -7.4653e-02,  1.2689e-01,  1.5657e-01, -4.7332e-02,\n",
      "           1.8366e-01,  3.4604e-02,  1.3034e-01, -1.0227e-01,  6.2599e-02,\n",
      "           3.7570e-02,  8.0923e-02, -1.0478e-01,  7.7499e-02, -1.1046e-01,\n",
      "          -8.5907e-02, -4.3092e-03, -7.1046e-02, -8.1659e-02,  1.9490e-01,\n",
      "          -1.9547e-02, -4.9365e-03,  1.9892e-02,  7.2152e-02,  1.6415e-01,\n",
      "          -5.3117e-02, -2.7374e-02,  7.3881e-02,  1.1832e-01, -2.8347e-02,\n",
      "          -1.8439e-02,  1.0769e-01, -7.7139e-02, -5.3051e-02,  1.1907e-01,\n",
      "           4.4328e-02, -7.6653e-03,  1.5867e-02,  5.6586e-02, -6.0296e-02,\n",
      "           8.1865e-02, -1.1206e-01, -1.3052e-01,  2.1580e-02, -3.6381e-02,\n",
      "           5.4435e-02,  1.2919e-01,  1.0781e-01, -5.4997e-02,  1.0762e-02,\n",
      "          -4.8915e-02,  2.3123e-02,  2.7024e-02,  1.1233e-01,  1.6125e-02,\n",
      "           2.8126e-02, -1.2019e-01,  1.1013e-01,  2.9887e-02, -8.6128e-03,\n",
      "           3.1761e-02, -1.6802e-01, -1.3177e-01, -1.2579e-01,  7.8660e-02,\n",
      "           2.7778e-03,  1.3333e-01,  2.3478e-01, -2.4245e-01, -4.9703e-02,\n",
      "           1.2291e-01, -2.8638e-03,  1.8116e-01, -1.0576e-01, -6.9273e-03,\n",
      "           1.5177e-01,  1.2165e-01, -4.7558e-02, -2.7903e-01,  3.4132e-02,\n",
      "          -5.9547e-02, -9.6075e-02, -1.8598e-02, -5.9769e-02, -5.4385e-02,\n",
      "          -1.0802e-01, -8.4047e-02, -1.5268e-02,  8.6036e-02,  1.1553e-02,\n",
      "           8.6043e-02, -7.2211e-02, -2.7301e-01,  2.6542e-02,  1.4581e-01,\n",
      "           3.6757e-02, -6.1889e-02, -1.7449e-01, -7.7894e-02, -6.8116e-02,\n",
      "           1.5465e-04,  3.9426e-03, -7.1795e-02, -1.8184e-02,  4.0467e-02,\n",
      "          -2.1395e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7277e-01, -4.3056e-01,  3.1482e-01, -1.0845e+00, -1.1724e+00,\n",
      "           7.4188e-01, -1.9142e+00,  1.3514e+00,  1.9056e-01,  6.1743e-01,\n",
      "           1.9026e+00,  0.0000e+00,  0.0000e+00, -9.1596e-01, -3.1818e+00,\n",
      "          -6.8532e-02, -1.6329e+00, -9.4349e-01,  1.3609e+00, -1.4346e+00,\n",
      "          -1.4075e-01, -5.2334e-01, -1.1193e+00, -2.5947e+00, -7.5560e-02,\n",
      "           1.3912e+00, -6.1924e-01,  1.9967e+00,  1.2762e-01,  5.5382e-01,\n",
      "           9.1464e-01, -3.5164e-03,  2.2302e-01,  2.0152e+00, -6.3872e-02,\n",
      "          -1.4085e+00, -1.1196e-01, -8.1782e-01,  3.1463e-01,  8.5334e-02,\n",
      "           8.6196e-01, -8.9993e-01,  1.0091e+00, -1.5632e+00,  1.9438e+00,\n",
      "          -3.0001e-01,  7.0455e-01, -6.0116e-01, -1.0205e+00,  1.1162e+00,\n",
      "          -1.3220e+00,  2.6765e+00,  6.6664e-01, -8.4655e-01,  2.2737e-01,\n",
      "          -3.0883e-01, -1.4342e+00,  0.0000e+00,  1.2748e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6176e-02, -2.8016e-01,  2.6583e-01, -6.2664e-02,\n",
      "           3.9426e-01,  5.7806e-01,  1.1649e+00,  1.5804e+00, -1.4150e+00,\n",
      "           4.2761e-01,  2.9647e-01, -3.1349e-02, -7.9769e-01, -2.1451e-01,\n",
      "           1.3925e-01,  5.2564e-01,  0.0000e+00,  1.0269e+00, -7.9288e-01,\n",
      "           7.5749e-01, -1.0058e+00,  7.5705e-01,  1.0588e+00,  0.0000e+00,\n",
      "          -1.1303e-01, -1.1073e+00,  5.4872e-01, -9.4472e-01, -1.9014e+00,\n",
      "           5.2899e-01,  9.8641e-01,  1.7013e+00,  9.4325e-01,  6.0820e-01,\n",
      "          -1.5954e-02,  0.0000e+00,  0.0000e+00,  1.3711e+00,  2.4477e+00,\n",
      "           2.4393e-01,  4.5923e-02,  0.0000e+00, -9.8940e-01,  1.6395e+00,\n",
      "          -1.0225e+00,  3.0284e+00,  0.0000e+00, -1.0207e-01, -1.2352e+00,\n",
      "           0.0000e+00, -5.0277e-01, -5.7017e-01,  0.0000e+00, -7.8036e-01,\n",
      "           6.3201e-01,  4.0411e-01,  2.2421e-01, -2.3272e+00,  2.9351e-02,\n",
      "          -8.1348e-01, -1.4103e+00, -1.8369e+00,  6.0335e-01, -9.5626e-01,\n",
      "          -2.0003e-01,  3.9139e-02,  2.1498e+00,  1.3961e+00, -2.0873e+00,\n",
      "          -9.2648e-01,  0.0000e+00, -1.1671e+00,  4.2513e-01, -4.6892e-01,\n",
      "          -7.4439e-01, -1.0649e+00, -9.7462e-01, -1.9475e-02,  2.3975e+00,\n",
      "           0.0000e+00, -1.1217e+00,  1.6915e+00, -1.4014e-01, -6.6929e-01,\n",
      "           0.0000e+00,  7.5923e-01,  4.2303e-01, -1.0329e+00, -9.5665e-02,\n",
      "           1.5600e+00,  5.8700e-01, -3.3902e-01,  6.5755e-01,  1.8406e+00,\n",
      "           0.0000e+00, -2.1723e-01,  6.2328e-01, -2.3620e+00,  1.0554e+00,\n",
      "           3.0232e-01, -7.7589e-02,  1.5414e-01, -1.2114e+00, -2.1915e-02,\n",
      "           1.6817e+00,  1.8515e+00,  2.7046e-01, -1.2702e+00, -7.1345e-01,\n",
      "          -1.2243e+00, -1.0938e+00, -2.5899e+00,  5.0548e-01, -3.0580e+00,\n",
      "           0.0000e+00,  4.9832e-01,  8.2931e-01,  3.1701e-01, -7.9276e-01,\n",
      "           2.7103e-01,  2.3395e+00,  1.0571e+00,  8.3814e-01, -4.0319e-01,\n",
      "           7.2690e-01,  5.9916e-01,  3.5926e-01,  8.4194e-01,  0.0000e+00,\n",
      "           1.3635e+00,  2.1588e+00,  3.3697e-01, -1.0151e+00, -1.1712e+00,\n",
      "          -2.2148e+00,  1.6655e+00,  2.1523e+00,  3.6334e-01,  2.3835e+00,\n",
      "           3.2331e-02, -5.0152e-01, -1.2758e+00, -5.4232e-01, -4.0737e-01,\n",
      "          -1.4466e+00,  9.5384e-01, -8.5153e-01,  8.3086e-01, -1.5596e+00,\n",
      "           6.3614e-01,  6.7629e-01,  2.3970e+00,  5.4887e-02,  1.8940e+00,\n",
      "           1.3077e+00,  5.8083e-01, -2.3167e+00,  1.5502e+00, -2.2254e-01,\n",
      "          -2.2713e-01,  1.7330e+00,  2.7715e-01, -1.5519e+00,  9.2269e-01,\n",
      "          -1.2245e+00, -8.4783e-01, -1.8010e+00, -1.8392e-04,  3.7340e-01,\n",
      "          -1.5733e+00, -1.2340e-01,  9.6629e-01, -1.7357e+00,  1.6938e+00,\n",
      "          -1.4404e+00,  6.3408e-01, -1.7216e+00,  9.8043e-01, -1.7152e+00,\n",
      "           0.0000e+00, -2.7184e-01,  0.0000e+00,  1.2382e+00, -1.2287e+00,\n",
      "           0.0000e+00, -5.0832e-01,  5.4284e-01, -2.6141e-01, -1.0215e+00,\n",
      "           0.0000e+00,  3.1009e-01, -5.1578e-02, -2.2887e-01, -1.6114e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0523, 0.1150, 0.1392, 0.0709, 0.1356, 0.1349, 0.1377, 0.0682, 0.0736,\n",
      "         0.0725]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 3.5815e-01, -1.9247e-02,  8.0236e-02,  ..., -1.2145e-01,\n",
      "         -3.1416e-02, -4.7237e-01],\n",
      "        [ 1.2435e-01,  1.5096e-01,  2.7631e-01,  ...,  1.1423e-01,\n",
      "          6.0215e-02,  4.5594e-02],\n",
      "        [ 3.2242e-01, -3.8844e-02,  3.2152e-01,  ...,  8.8124e-02,\n",
      "         -1.2406e-05, -5.7762e-02],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1385,  0.0259, -0.0067,  0.0662,  0.1143,  0.0504, -0.0169,\n",
      "           0.0041, -0.0132,  0.0906,  0.0392, -0.0567, -0.0379,  0.0299,\n",
      "           0.0295,  0.1279,  0.0455,  0.0509, -0.2188, -0.0903, -0.1564,\n",
      "           0.0163, -0.0372, -0.1079, -0.2218, -0.0677,  0.0257, -0.1360,\n",
      "           0.0423, -0.0612,  0.0835, -0.0307, -0.0578, -0.0939, -0.0212,\n",
      "           0.0328, -0.1765, -0.0504, -0.0859, -0.0150,  0.0287,  0.0363,\n",
      "          -0.0273, -0.1108,  0.1789, -0.0422,  0.1755, -0.0030,  0.1159,\n",
      "          -0.0242, -0.1027, -0.1447, -0.1547, -0.0994, -0.1957, -0.0372,\n",
      "          -0.0873,  0.1579, -0.0221,  0.1474,  0.0459, -0.0553, -0.1083,\n",
      "           0.1121, -0.0116,  0.0967, -0.0035,  0.0804, -0.0549,  0.0245,\n",
      "           0.0922,  0.1493, -0.0522, -0.0950, -0.1348, -0.0238,  0.0511,\n",
      "           0.0462,  0.0556, -0.0813, -0.1715, -0.1309, -0.0556, -0.0481,\n",
      "           0.0967,  0.0043,  0.1379,  0.1417, -0.0346, -0.0391, -0.0023,\n",
      "           0.1907, -0.0644, -0.1021,  0.0291,  0.1494,  0.2114,  0.1347,\n",
      "          -0.0271,  0.1010, -0.1245,  0.0258,  0.0699,  0.0598, -0.0241,\n",
      "          -0.0444,  0.1084,  0.0142, -0.0380, -0.0140,  0.0659, -0.0211,\n",
      "          -0.0886, -0.0166,  0.1037, -0.1185, -0.0014, -0.0783, -0.0442,\n",
      "          -0.2241,  0.1206, -0.1172,  0.0045,  0.0393, -0.1341, -0.0078,\n",
      "           0.1923, -0.0409,  0.2442,  0.1019, -0.0075, -0.0876,  0.1319,\n",
      "           0.0521,  0.0238, -0.0643,  0.2110,  0.0232,  0.2361,  0.0035,\n",
      "           0.0019,  0.1535,  0.0419,  0.1702,  0.0084, -0.0316,  0.1895,\n",
      "           0.1041, -0.0759, -0.0010, -0.0992, -0.0713,  0.1006,  0.1166,\n",
      "          -0.0217,  0.1930,  0.0255,  0.1203, -0.1451,  0.0241,  0.0308,\n",
      "           0.0746, -0.1084,  0.0642, -0.1112, -0.0683, -0.0102, -0.0741,\n",
      "          -0.0286,  0.1879, -0.0583,  0.0500,  0.0535,  0.0147,  0.1649,\n",
      "          -0.0467, -0.0332,  0.0823,  0.1517, -0.0243, -0.0221,  0.0956,\n",
      "          -0.0430, -0.0321,  0.1371,  0.0572, -0.0220,  0.0232,  0.0485,\n",
      "          -0.0381,  0.0626, -0.0986, -0.1402,  0.0308, -0.0231,  0.0323,\n",
      "           0.1151,  0.0894, -0.0765,  0.0161, -0.0489,  0.0198,  0.0249,\n",
      "           0.1448,  0.0222,  0.0307, -0.1302,  0.1272,  0.0475, -0.0164,\n",
      "          -0.0036, -0.1815, -0.1448, -0.1147,  0.1039,  0.0365,  0.1032,\n",
      "           0.2453, -0.2257, -0.0598,  0.1379,  0.0092,  0.1873, -0.1162,\n",
      "           0.0277,  0.1051,  0.1438, -0.0120, -0.2834,  0.0290, -0.0224,\n",
      "          -0.0763, -0.0379, -0.0539, -0.0607, -0.0941, -0.0808,  0.0097,\n",
      "           0.1301, -0.0180,  0.0678, -0.0881, -0.2606,  0.0236,  0.1184,\n",
      "           0.0442, -0.0320, -0.1854, -0.0525, -0.0590,  0.0145, -0.0137,\n",
      "          -0.0835, -0.0314,  0.0369, -0.0398]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7243e-02,  4.0013e-01, -9.6463e-01, -6.8083e-01,  3.7527e-01,\n",
      "          -2.0184e-01,  1.4644e+00, -8.3740e-02,  0.0000e+00,  9.0689e-01,\n",
      "           4.2778e-01, -6.2923e-01,  0.0000e+00, -6.3042e-01, -5.4133e-01,\n",
      "           0.0000e+00,  8.5138e-01,  1.0941e+00,  0.0000e+00,  4.3626e-01,\n",
      "          -6.3315e-01, -3.8228e-01,  1.6394e+00,  1.5111e+00,  7.5303e-01,\n",
      "          -7.5944e-02, -1.8824e-01, -7.6023e-01,  1.6531e+00,  8.6119e-01,\n",
      "           1.2312e+00,  1.2192e+00, -1.0341e+00, -8.3053e-02, -1.5341e+00,\n",
      "           1.3955e+00,  2.8053e-01, -3.7437e+00,  1.9763e-01,  1.5997e+00,\n",
      "          -4.5909e-01, -1.3977e+00, -2.6911e-01, -1.7140e+00, -1.5231e+00,\n",
      "           6.6788e-01,  5.4031e-01,  3.7136e-01, -1.3401e+00,  1.4469e-01,\n",
      "          -6.2926e-01,  2.7502e+00,  6.0993e-01, -1.0283e+00, -2.4869e-02,\n",
      "           0.0000e+00, -8.8111e-01, -1.2507e+00, -2.3747e-01, -4.2639e-01,\n",
      "           1.0985e+00,  1.4067e+00, -2.0221e-01, -5.0069e-01, -2.9619e+00,\n",
      "           0.0000e+00,  1.2777e+00, -1.2872e+00,  4.0952e-01,  5.2675e-01,\n",
      "          -1.2663e+00, -2.9501e-02,  7.0727e-01, -3.6390e+00,  3.2478e-01,\n",
      "          -5.0060e-04, -1.6017e-01,  1.0610e+00, -5.7271e-02, -1.1754e-01,\n",
      "          -1.3994e+00,  2.1295e+00, -9.2395e-01,  1.0059e+00, -2.0742e-01,\n",
      "           4.3662e-01,  0.0000e+00, -9.7390e-01, -1.0458e-01, -5.8117e-01,\n",
      "          -2.2719e+00,  1.0994e+00, -6.2231e-01, -1.1358e+00,  4.6686e-01,\n",
      "          -1.1697e+00,  3.2316e-02,  6.2869e-01,  1.7190e+00, -7.7794e-01,\n",
      "           2.6965e+00, -1.4612e+00,  1.0758e+00,  1.4524e+00, -6.6591e-01,\n",
      "          -7.6201e-01,  1.2105e+00,  1.2749e-01, -1.4727e+00, -1.4045e-02,\n",
      "          -2.4798e-01,  1.3392e-01, -1.0470e+00,  1.3100e+00, -1.6521e+00,\n",
      "          -2.9874e+00,  0.0000e+00, -4.9906e-01, -1.9344e-01,  4.4574e-01,\n",
      "          -1.4644e+00,  0.0000e+00, -1.4600e+00, -7.2540e-01, -9.5735e-01,\n",
      "          -1.3069e+00,  8.9516e-01,  0.0000e+00,  1.2842e+00, -7.5081e-01,\n",
      "          -8.2427e-01,  5.3107e-01, -1.5823e+00,  9.8382e-01,  2.7640e-01,\n",
      "          -5.8896e-01,  6.5811e-01,  5.7581e-01, -1.1592e+00, -1.0090e+00,\n",
      "          -3.8783e-01,  0.0000e+00, -7.8900e-01, -1.0045e-01, -1.6842e+00,\n",
      "          -9.9940e-02, -5.4269e-01, -8.4428e-01, -7.5453e-01,  0.0000e+00,\n",
      "           1.9973e+00, -1.9903e-01,  0.0000e+00, -4.0635e-01,  0.0000e+00,\n",
      "          -1.9444e-01, -6.5130e-02, -1.3075e-01,  3.8782e-02,  5.3728e-01,\n",
      "           0.0000e+00,  2.2060e+00,  4.8098e-01, -5.5067e-01, -5.2540e-01,\n",
      "          -8.9092e-01,  2.8154e-01,  8.2532e-02, -3.5820e-01, -4.7777e-01,\n",
      "           7.3576e-01, -3.0460e-02,  2.0122e-02, -1.0030e+00,  1.2773e+00,\n",
      "          -1.0975e+00, -9.8540e-01, -2.0748e+00,  1.9678e+00,  8.6328e-02,\n",
      "          -3.1124e-02,  0.0000e+00,  6.7051e-01,  9.7991e-01, -7.4803e-01,\n",
      "          -3.4113e-01, -2.7810e+00, -7.8261e-01,  1.2088e+00,  1.0127e+00,\n",
      "           3.0719e+00,  4.9377e-01,  0.0000e+00,  0.0000e+00,  5.5963e-01,\n",
      "           2.1638e+00, -1.1872e+00,  5.3496e-01,  1.8107e+00, -9.4586e-01,\n",
      "           0.0000e+00,  0.0000e+00,  1.2423e+00, -1.2223e-01,  2.3206e-01,\n",
      "           0.0000e+00, -2.2915e+00,  6.8184e-01, -1.0726e+00, -4.7115e-01,\n",
      "           2.8670e+00, -5.7307e-01,  0.0000e+00,  7.9254e-01,  3.2240e-02,\n",
      "          -6.8311e-01, -1.0167e+00,  9.6689e-01, -2.4502e-01,  2.1681e+00,\n",
      "          -1.0827e+00,  0.0000e+00, -1.8430e+00, -5.0000e-01,  3.3982e-01,\n",
      "           7.0478e-01, -6.9665e-01, -6.2813e-01,  2.9215e-01, -1.5771e+00,\n",
      "          -1.1078e+00,  0.0000e+00, -6.1369e-01,  1.3103e+00, -2.9786e+00,\n",
      "           4.0329e+00,  5.8497e-01,  4.2627e-02, -1.5781e+00, -2.8578e-01,\n",
      "           7.4210e-01,  0.0000e+00, -3.0341e-01,  0.0000e+00,  1.1311e-02,\n",
      "           2.7580e-01,  2.7464e-01,  2.5209e-01,  0.0000e+00,  3.8695e-01,\n",
      "          -3.6592e-01, -1.5977e-01, -5.5330e-01, -5.1811e-02, -1.1460e+00,\n",
      "          -1.1312e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0561, 0.0558, 0.1126, 0.0768, 0.1485, 0.2672, 0.0805, 0.0551, 0.0550,\n",
      "         0.0924]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0589, -0.4115, -0.2436,  ..., -0.4234,  0.0266,  0.0222],\n",
      "        [ 0.1569, -0.1228, -0.1448,  ..., -0.6371,  0.1136, -0.2500],\n",
      "        [ 0.3260,  0.0159,  0.1563,  ...,  0.0793,  0.2700, -0.1546],\n",
      "        ...,\n",
      "        [ 0.1112,  0.0566, -0.2179,  ..., -0.4324,  0.2154, -0.1306],\n",
      "        [ 0.2450,  0.3141, -0.6573,  ..., -0.2230, -0.0386, -0.0387],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.8674e-02,  1.4987e-01,  1.9004e-02, -6.5599e-02, -1.2610e-01,\n",
      "          -2.9787e-01,  1.0747e-01, -4.6299e-02,  3.6387e-02, -2.8833e-02,\n",
      "           2.3563e-01, -3.0903e-01,  9.1287e-02,  2.2319e-02,  1.7092e-01,\n",
      "          -5.6150e-02, -4.6030e-02, -5.5391e-02,  4.4748e-02,  1.4667e-01,\n",
      "          -1.4147e-01,  5.1370e-02, -2.3954e-01, -4.8857e-03, -9.6723e-02,\n",
      "          -1.4546e-01,  7.7146e-02,  8.1822e-02,  1.1224e-01,  3.5743e-02,\n",
      "          -7.1150e-02, -3.1406e-02,  3.3378e-03,  2.7381e-01,  4.4301e-02,\n",
      "           5.6921e-02, -1.6862e-01, -2.2648e-01, -1.4223e-02, -1.3017e-01,\n",
      "           1.1992e-02, -1.0787e-01,  2.0320e-01, -5.3442e-02,  2.0986e-01,\n",
      "          -1.2765e-01,  5.6970e-03, -2.2545e-01,  2.5117e-01,  1.2429e-01,\n",
      "          -7.7712e-02,  5.9574e-02, -1.1674e-01, -3.7781e-02,  2.9074e-02,\n",
      "          -3.6989e-03,  1.5034e-01,  8.1634e-02,  5.6315e-02, -4.9487e-02,\n",
      "           2.5255e-02, -7.4778e-02,  7.8347e-02,  1.2357e-01,  2.4552e-02,\n",
      "          -2.5701e-01,  9.7708e-02, -2.0157e-01,  3.6124e-02,  1.2921e-01,\n",
      "           3.8829e-02,  1.2065e-01,  7.7536e-02,  3.7166e-02,  1.3276e-01,\n",
      "           7.4225e-02, -1.6258e-01,  1.6347e-01,  9.5763e-02, -3.5104e-02,\n",
      "           6.8167e-02, -1.2616e-01,  5.8706e-03, -3.8330e-02, -5.3220e-02,\n",
      "           4.0773e-01,  1.0905e-01, -1.1162e-01, -1.5009e-01, -5.7830e-02,\n",
      "           4.2994e-03,  2.0666e-01,  9.7317e-02, -1.3099e-01, -1.1734e-01,\n",
      "          -2.3920e-01,  1.5557e-01,  2.5667e-01, -1.4378e-01,  1.8450e-02,\n",
      "          -9.8018e-02, -2.8280e-01,  2.3553e-01, -6.7205e-02, -2.0580e-02,\n",
      "           1.4673e-01,  8.3808e-02, -7.6565e-03,  2.7612e-01,  1.7201e-01,\n",
      "           5.7080e-02, -3.8004e-02, -1.4275e-01, -9.5486e-02,  5.4057e-02,\n",
      "           7.3983e-05, -9.6403e-02, -4.3278e-02,  4.0354e-02, -1.9625e-01,\n",
      "          -1.2484e-01, -9.6241e-03, -1.7343e-01,  6.7189e-02, -2.4566e-01,\n",
      "           2.2519e-02, -1.3231e-01, -2.5218e-01, -4.0619e-02,  1.1500e-01,\n",
      "          -1.3326e-02, -1.8059e-01,  1.6047e-01,  1.2150e-01, -1.8504e-02,\n",
      "           8.3807e-02, -1.1899e-01,  1.1184e-01, -1.0598e-01, -5.4759e-02,\n",
      "           6.4963e-03,  2.3418e-01, -2.2706e-01,  1.5924e-01, -8.6129e-02,\n",
      "          -2.9348e-02,  1.3871e-02,  4.6353e-02,  5.9672e-02,  1.8126e-01,\n",
      "          -2.6347e-02,  4.6374e-04,  1.2180e-01, -1.9371e-01,  3.0742e-02,\n",
      "           9.6458e-02,  3.2701e-02,  8.4671e-02, -2.8696e-01,  4.6924e-03,\n",
      "           1.2995e-01, -2.1610e-01, -1.5905e-01,  1.3873e-01, -1.4791e-01,\n",
      "          -3.1138e-02,  2.0824e-01, -6.1387e-02,  2.4109e-01,  2.6176e-02,\n",
      "           1.0491e-01,  1.0899e-01,  1.5874e-01,  1.2178e-01, -8.0771e-02,\n",
      "          -2.6423e-01, -1.5655e-01,  1.6289e-01,  1.6045e-01,  2.2303e-01,\n",
      "          -3.0057e-01, -6.2613e-02,  1.8118e-01, -6.4061e-03, -1.5317e-01,\n",
      "           1.7909e-01, -1.9309e-01, -1.8751e-01, -1.5900e-02,  1.3660e-01,\n",
      "           1.2630e-03,  1.0797e-01, -1.1633e-01,  7.1603e-02, -2.2143e-02,\n",
      "          -2.1157e-01, -3.8589e-02, -4.8001e-02,  1.2201e-01,  1.1170e-02,\n",
      "          -1.6434e-01,  9.9637e-02, -1.9181e-01, -3.5832e-02,  2.2174e-01,\n",
      "           6.3355e-03, -1.8237e-01, -9.4779e-02, -1.0631e-01, -3.0862e-02,\n",
      "          -1.8069e-01,  1.7013e-01,  1.0049e-01,  3.5789e-02, -1.9345e-01,\n",
      "           2.5282e-03, -3.5402e-02, -1.1716e-02, -2.1993e-01,  3.6295e-02,\n",
      "          -1.3513e-01, -2.1438e-01, -2.2360e-03, -7.0027e-02, -1.0853e-01,\n",
      "          -1.3908e-01,  1.2177e-01, -1.8093e-01,  1.3606e-01, -6.3424e-02,\n",
      "           3.3178e-02,  1.3631e-01, -2.4399e-02, -1.8955e-01, -5.5057e-02,\n",
      "          -1.7042e-02, -7.3201e-02,  1.7093e-01,  1.1814e-01,  1.8254e-01,\n",
      "          -7.9145e-02, -1.3227e-01, -1.3899e-01, -7.5102e-02,  9.9111e-02,\n",
      "          -7.8311e-02,  1.4526e-01, -1.1385e-01,  8.2492e-02,  1.1413e-02,\n",
      "           8.4392e-02,  2.2008e-01,  1.0422e-02, -2.3593e-01, -1.3190e-01,\n",
      "           1.4833e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4728,  0.0000, -1.2334, -0.1186,  0.4613,  0.0259,  0.6620,\n",
      "           0.5340,  0.6709,  0.9340,  1.7076, -1.0163,  0.9456, -0.2517,\n",
      "          -1.6339,  0.5123,  1.8776,  0.0000, -1.5631, -2.6431, -1.1334,\n",
      "           0.0000,  2.9292,  0.0000, -0.1173,  3.2089,  0.0000,  0.5186,\n",
      "           0.0000, -1.2859,  0.0289,  0.0000,  0.3250,  0.8597, -0.7987,\n",
      "          -1.4655,  0.6197, -0.7714,  1.9913,  0.1016,  0.0000, -2.2044,\n",
      "           0.0000, -0.1150, -0.7130, -0.6890,  1.9273,  0.0000, -0.2870,\n",
      "          -1.8505,  1.4677,  0.4622,  0.6672, -0.2830,  0.0000,  0.2749,\n",
      "          -1.2427, -0.9509,  1.8137, -0.0119,  0.2052, -1.8187, -1.4010,\n",
      "          -0.8063,  0.0000,  0.2653, -0.1672, -0.2547, -0.0048, -0.4607,\n",
      "           0.0000, -0.3240,  0.1474,  0.0000,  0.6585, -0.8061,  2.0663,\n",
      "           1.6791,  0.0000, -0.5455,  1.2267,  0.0862,  0.3266, -1.8363,\n",
      "           0.0000, -1.7318, -1.4586, -0.8914,  0.6229,  0.8108, -1.2238,\n",
      "          -1.1442,  1.9848, -0.3663, -0.7340,  0.1565,  2.1409, -0.4057,\n",
      "          -0.3040,  0.0000, -1.2906, -0.7212, -0.7665,  0.2369,  0.3817,\n",
      "           1.1138, -1.0706,  2.2522, -0.2628,  0.0000, -0.0532,  0.6104,\n",
      "          -0.2544, -0.2804, -1.9418,  1.1285,  1.0064, -2.4969, -0.5751,\n",
      "           0.0297, -1.6945, -0.4010, -0.3791, -0.0782, -0.5366, -1.1107,\n",
      "           1.3041,  0.1695,  0.3222,  1.3582,  2.0787, -2.6339,  0.3598,\n",
      "          -0.7230,  0.4292,  0.0602,  0.3265, -2.1012, -0.4969, -1.6773,\n",
      "          -0.6417,  0.2344, -1.1867, -1.2145, -0.6308, -0.0404,  0.4647,\n",
      "           1.7381,  1.5949,  1.4319, -1.2625, -0.5774,  0.0000, -0.0394,\n",
      "           0.3265, -0.1171,  1.3537, -0.0318, -1.9004, -1.8063, -1.4264,\n",
      "          -0.9001, -0.7060, -0.3892,  0.0000, -0.1289,  0.4064,  0.9700,\n",
      "           0.5179,  0.0000,  1.5130, -0.3729, -0.3158, -2.0086,  0.1297,\n",
      "          -0.3526, -0.8299,  0.0000, -0.0404, -0.9374,  0.7277,  1.0418,\n",
      "           0.0469,  0.0000,  0.3159, -0.1183, -0.5408, -0.6643,  0.7547,\n",
      "          -1.0640, -0.5870, -1.7883,  1.2674, -0.9262,  0.0000, -0.3332,\n",
      "          -1.1569, -1.9606, -0.0719, -0.3748,  2.6970, -0.9216, -2.6312,\n",
      "          -0.5861, -0.7157, -1.3862, -1.2538,  0.0000,  0.2190, -1.1107,\n",
      "           0.9448,  0.0000, -1.5192,  0.3621,  0.2380, -1.4261, -2.3445,\n",
      "           0.0476, -1.4795,  0.4271,  0.0132, -0.9015,  0.3011, -1.1653,\n",
      "          -1.3006, -0.1877,  1.2720,  1.2662, -2.1879, -0.0560,  0.0000,\n",
      "           0.0000,  0.9562,  1.9993,  0.5275,  0.7885, -0.6787,  0.1043,\n",
      "          -0.6803, -2.2618,  0.0000, -0.3132, -1.0431,  0.0000,  0.0000,\n",
      "           0.5577,  1.4992, -0.5645,  0.0000,  1.2434,  0.5827,  1.7527,\n",
      "           1.9516,  0.3627,  0.4875,  0.3900]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0207, 0.2641, 0.0847, 0.0661, 0.1087, 0.1082, 0.0313, 0.1973, 0.0685,\n",
      "         0.0503]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.0589, -0.4115, -0.2436,  ..., -0.4234,  0.0266,  0.0222],\n",
      "        [ 0.1569, -0.1228, -0.1448,  ..., -0.6371,  0.1136, -0.2500],\n",
      "        [ 0.3260,  0.0159,  0.1563,  ...,  0.0793,  0.2700, -0.1546],\n",
      "        ...,\n",
      "        [ 0.1112,  0.0566, -0.2179,  ..., -0.4324,  0.2154, -0.1306],\n",
      "        [ 0.2450,  0.3141, -0.6573,  ..., -0.2230, -0.0386, -0.0387],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.1164e-02,  6.5689e-02, -8.4386e-02, -7.4592e-02, -1.1875e-02,\n",
      "          -3.2812e-01,  9.4019e-02, -4.6614e-02, -1.2967e-02, -1.9026e-01,\n",
      "           2.7530e-01, -1.8478e-01,  2.8606e-02,  1.9400e-01,  2.3149e-01,\n",
      "          -1.4353e-01, -5.3332e-02, -4.2379e-02,  3.9471e-02,  1.0881e-01,\n",
      "          -1.5949e-01, -3.1086e-02, -1.5839e-01, -4.1723e-02,  1.0045e-02,\n",
      "          -4.5712e-02,  1.4720e-01, -2.1311e-02,  5.5159e-02,  5.0331e-02,\n",
      "           6.4322e-02, -9.7237e-02,  1.5795e-02,  8.0572e-02,  2.9160e-02,\n",
      "           8.9140e-02, -3.1356e-01, -3.0036e-01, -8.3368e-02, -3.6689e-03,\n",
      "          -2.1690e-03, -7.3181e-02,  1.0770e-01, -2.1482e-02,  1.4308e-01,\n",
      "           4.4646e-02, -6.2273e-02, -9.9657e-02,  2.0227e-01,  1.7003e-01,\n",
      "          -3.7390e-02,  1.4568e-01, -2.0516e-01, -1.0487e-01,  3.2985e-04,\n",
      "          -1.0260e-01,  8.3591e-02,  1.4630e-02,  7.4685e-02, -4.2586e-02,\n",
      "           9.2525e-02, -8.3810e-02,  1.0840e-01,  1.3348e-01, -5.4193e-02,\n",
      "          -2.0468e-01,  4.8310e-02, -1.1016e-01, -4.0221e-02,  1.9925e-01,\n",
      "           6.3976e-02,  1.7813e-01,  6.1510e-02, -3.3599e-02,  1.2935e-01,\n",
      "           9.4820e-02, -1.3758e-01,  9.8608e-02,  5.3750e-02, -6.0193e-02,\n",
      "           1.1094e-01, -1.9576e-02,  1.6345e-02, -1.0656e-01, -3.6709e-02,\n",
      "           3.1516e-01,  2.7490e-01, -7.4389e-02, -1.4012e-01,  7.3219e-02,\n",
      "           4.9795e-02,  6.2963e-02,  1.5103e-02, -1.6207e-01, -7.1210e-02,\n",
      "          -9.7504e-02,  1.5324e-01,  2.2240e-01, -1.0384e-01,  1.2908e-01,\n",
      "          -1.9823e-02, -1.0117e-01,  2.0119e-01, -4.3057e-02,  4.0275e-02,\n",
      "           1.0741e-01,  1.2932e-01,  6.1364e-02,  2.6297e-01,  1.3194e-01,\n",
      "           3.4789e-02, -3.4338e-02, -7.2571e-02, -5.7433e-02, -7.1238e-02,\n",
      "           4.5924e-02, -4.6009e-02, -4.3416e-02, -8.1887e-02, -1.2759e-01,\n",
      "          -1.0150e-01, -5.2981e-03, -1.2914e-01,  1.3391e-01, -2.4144e-01,\n",
      "           9.1137e-02, -6.3622e-02, -2.0494e-01,  3.5852e-02,  7.5068e-02,\n",
      "           7.0594e-02, -2.7158e-01,  6.2709e-02,  2.0759e-01, -3.0016e-02,\n",
      "           4.2608e-02, -8.5875e-02,  4.7539e-02, -1.0501e-01, -1.0633e-01,\n",
      "          -2.9919e-02,  3.1935e-01, -2.3649e-01,  2.1869e-01,  5.8856e-03,\n",
      "           6.1552e-02,  6.7441e-02,  1.1098e-01,  1.2649e-01,  1.7658e-01,\n",
      "          -1.1281e-01, -3.9020e-02, -2.6961e-02, -7.7574e-02,  7.9911e-02,\n",
      "           1.5792e-01, -4.1061e-02,  1.3879e-01, -2.6831e-01,  7.5263e-02,\n",
      "           1.3754e-01, -2.2165e-01, -2.2142e-01,  1.9139e-01, -2.9177e-01,\n",
      "          -1.4845e-01,  1.2354e-01, -1.3645e-01,  2.5106e-01,  9.2903e-02,\n",
      "           9.4425e-02,  1.0079e-01,  2.2573e-01,  1.4633e-01, -2.4469e-02,\n",
      "          -1.8143e-01, -1.2978e-01,  1.3967e-01,  1.2405e-01,  1.7729e-01,\n",
      "          -3.2302e-01, -1.4948e-01,  1.1181e-01,  5.6438e-02, -1.4293e-01,\n",
      "           1.4679e-01, -2.7482e-01, -2.7432e-01,  8.0495e-02, -6.0183e-02,\n",
      "           4.5631e-02,  2.8777e-02, -2.2988e-01,  8.2789e-02, -5.3289e-02,\n",
      "          -9.8007e-02,  9.7461e-02, -1.1018e-01,  1.4572e-01,  2.0508e-02,\n",
      "          -8.4568e-02,  6.2639e-02, -1.8879e-01, -1.3841e-01,  1.8034e-01,\n",
      "          -1.1972e-01, -2.3418e-01, -9.5326e-03, -8.4633e-02, -2.0242e-01,\n",
      "          -1.2774e-01,  9.6914e-02, -4.2645e-02,  2.3686e-02, -9.3973e-02,\n",
      "           3.5879e-02,  5.7034e-02,  2.7891e-02, -2.6841e-01,  2.3091e-02,\n",
      "          -2.1799e-02, -7.5346e-02,  1.0662e-02, -8.7245e-02, -6.5057e-02,\n",
      "          -1.5477e-01, -6.3307e-03, -1.1223e-01, -4.5679e-03, -9.0524e-02,\n",
      "          -2.1576e-02,  1.3097e-01, -4.3136e-02, -1.5185e-01, -7.5088e-02,\n",
      "           4.1412e-02, -1.3091e-01,  1.7081e-01,  2.2358e-01,  1.2747e-01,\n",
      "          -1.2789e-01, -1.5663e-01, -1.5258e-01,  3.3135e-02,  3.8960e-02,\n",
      "          -1.1042e-01,  6.5458e-02, -5.0361e-02, -4.1874e-02, -1.4151e-01,\n",
      "           1.4846e-01,  2.0751e-01,  6.9534e-03, -3.4404e-01, -8.4036e-03,\n",
      "          -6.1829e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7286e-02,  0.0000e+00, -9.6469e-01,  0.0000e+00,  3.7530e-01,\n",
      "          -2.0182e-01,  1.4643e+00, -8.3757e-02, -3.5831e+00,  9.0688e-01,\n",
      "           4.2778e-01, -6.2920e-01,  2.6016e+00, -6.3032e-01, -5.4130e-01,\n",
      "          -1.5802e-01,  0.0000e+00,  1.0942e+00,  4.5517e-01,  4.3628e-01,\n",
      "           0.0000e+00, -3.8235e-01,  1.6393e+00,  0.0000e+00,  7.5300e-01,\n",
      "           0.0000e+00, -1.8818e-01, -7.6023e-01,  1.6531e+00,  8.6118e-01,\n",
      "           1.2312e+00,  1.2192e+00, -1.0341e+00, -8.3079e-02, -1.5341e+00,\n",
      "           1.3955e+00,  2.8053e-01, -3.7437e+00,  1.9761e-01,  1.5997e+00,\n",
      "          -4.5915e-01,  0.0000e+00, -2.6903e-01, -1.7141e+00, -1.5232e+00,\n",
      "           6.6785e-01,  5.4030e-01,  0.0000e+00, -1.3401e+00,  1.4466e-01,\n",
      "          -6.2924e-01,  2.7503e+00,  6.0989e-01, -1.0284e+00,  0.0000e+00,\n",
      "           2.0437e-01,  0.0000e+00,  0.0000e+00, -2.3743e-01, -4.2637e-01,\n",
      "           1.0986e+00,  1.4067e+00, -2.0228e-01, -5.0065e-01, -2.9620e+00,\n",
      "           5.5173e-01,  1.2776e+00, -1.2872e+00,  4.0950e-01,  5.2673e-01,\n",
      "          -1.2663e+00,  0.0000e+00,  7.0724e-01, -3.6391e+00,  3.2480e-01,\n",
      "          -5.2020e-04, -1.6013e-01,  1.0611e+00, -5.7387e-02, -1.1756e-01,\n",
      "          -1.3994e+00,  2.1296e+00, -9.2400e-01,  1.0058e+00, -2.0739e-01,\n",
      "           4.3652e-01,  1.6611e+00,  0.0000e+00, -1.0453e-01, -5.8124e-01,\n",
      "          -2.2719e+00,  1.0994e+00, -6.2233e-01, -1.1359e+00,  4.6693e-01,\n",
      "          -1.1698e+00,  3.2379e-02,  6.2877e-01,  1.7190e+00, -7.7802e-01,\n",
      "           2.6966e+00, -1.4613e+00,  0.0000e+00,  1.4525e+00, -6.6593e-01,\n",
      "          -7.6202e-01,  1.2105e+00,  1.2750e-01, -1.4726e+00, -1.4029e-02,\n",
      "          -2.4799e-01,  1.3393e-01, -1.0470e+00,  1.3099e+00,  0.0000e+00,\n",
      "          -2.9874e+00, -5.7028e-02, -4.9910e-01, -1.9342e-01,  4.4574e-01,\n",
      "          -1.4645e+00,  7.0184e-01, -1.4601e+00, -7.2538e-01, -9.5738e-01,\n",
      "          -1.3069e+00,  8.9520e-01,  1.6939e-01,  1.2842e+00, -7.5085e-01,\n",
      "          -8.2425e-01,  5.3104e-01, -1.5824e+00,  0.0000e+00,  2.7638e-01,\n",
      "          -5.8896e-01,  6.5818e-01,  5.7577e-01, -1.1591e+00, -1.0091e+00,\n",
      "          -3.8788e-01,  6.7774e-01, -7.8901e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -9.9989e-02, -5.4270e-01, -8.4431e-01, -7.5452e-01,  1.7765e-01,\n",
      "           1.9974e+00, -1.9903e-01, -1.9293e+00, -4.0634e-01,  4.4109e-01,\n",
      "           0.0000e+00, -6.5162e-02, -1.3070e-01,  3.8789e-02,  5.3729e-01,\n",
      "          -2.6501e-02,  2.2060e+00,  4.8097e-01, -5.5069e-01, -5.2541e-01,\n",
      "          -8.9100e-01,  2.8150e-01,  8.2520e-02, -3.5818e-01, -4.7773e-01,\n",
      "           7.3580e-01, -3.0516e-02,  2.0127e-02, -1.0029e+00,  1.2773e+00,\n",
      "          -1.0976e+00, -9.8545e-01, -2.0748e+00,  1.9678e+00,  8.6349e-02,\n",
      "          -3.1120e-02,  3.4978e-02,  6.7052e-01,  0.0000e+00, -7.4807e-01,\n",
      "           0.0000e+00, -2.7810e+00, -7.8268e-01,  0.0000e+00,  1.0126e+00,\n",
      "           3.0719e+00,  4.9372e-01, -1.4431e-01, -5.9272e-01,  0.0000e+00,\n",
      "           2.1639e+00, -1.1873e+00,  5.3494e-01,  1.8107e+00, -9.4592e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  1.2423e+00, -1.2224e-01,  2.3204e-01,\n",
      "          -5.7456e-01, -2.2915e+00,  6.8189e-01, -1.0727e+00, -4.7115e-01,\n",
      "           2.8670e+00,  0.0000e+00, -3.4146e-01,  7.9259e-01,  0.0000e+00,\n",
      "          -6.8318e-01, -1.0168e+00,  9.6687e-01, -2.4503e-01,  2.1681e+00,\n",
      "          -1.0827e+00, -4.2681e-01, -1.8431e+00, -5.0002e-01,  3.3973e-01,\n",
      "           7.0475e-01, -6.9665e-01, -6.2813e-01,  2.9214e-01, -1.5771e+00,\n",
      "          -1.1078e+00,  1.5811e+00, -6.1378e-01,  1.3103e+00, -2.9786e+00,\n",
      "           0.0000e+00,  5.8497e-01,  4.2620e-02, -1.5782e+00, -2.8579e-01,\n",
      "           7.4212e-01, -3.2459e+00,  0.0000e+00, -8.5159e-01,  1.1307e-02,\n",
      "           2.7573e-01,  0.0000e+00,  2.5210e-01,  2.6148e-01,  3.8698e-01,\n",
      "          -3.6594e-01, -1.5967e-01, -5.5334e-01, -5.1833e-02,  0.0000e+00,\n",
      "          -1.1311e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0570, 0.0715, 0.0860, 0.0572, 0.1169, 0.2456, 0.0668, 0.0838, 0.0737,\n",
      "         0.1415]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0123, -0.0270, -0.3768, -0.0911, -0.0743, -0.0535, -0.2143,\n",
      "          -0.0061,  0.2106, -0.0919,  0.3399,  0.0637, -0.1096,  0.0242,\n",
      "           0.0697, -0.3132,  0.0951, -0.1261, -0.2933,  0.1540,  0.0434,\n",
      "           0.0380,  0.2862,  0.0466, -0.0333,  0.1337, -0.0367, -0.2480,\n",
      "          -0.0321,  0.0791,  0.1377, -0.1889,  0.0635,  0.0953,  0.1599,\n",
      "           0.1494, -0.0644,  0.0094,  0.0624,  0.0502,  0.1784, -0.0672,\n",
      "           0.0285, -0.0613, -0.2090,  0.1173,  0.0220, -0.1333,  0.1338,\n",
      "          -0.2761,  0.1448,  0.0096, -0.1115,  0.1620, -0.0534, -0.2106,\n",
      "           0.0846,  0.1163,  0.0924,  0.1248,  0.0374, -0.0093, -0.1738,\n",
      "           0.0061,  0.1762, -0.1753, -0.3517,  0.0936, -0.0213,  0.1803,\n",
      "          -0.1378,  0.0982, -0.0142, -0.0166, -0.1302,  0.2789, -0.0705,\n",
      "           0.1221,  0.1464,  0.1817, -0.0502,  0.0022, -0.3055,  0.0034,\n",
      "           0.0115,  0.0530,  0.0278,  0.0369, -0.1751, -0.0566, -0.0192,\n",
      "           0.0247,  0.0206,  0.0616, -0.0065,  0.0991, -0.1342,  0.2509,\n",
      "           0.1626,  0.1834, -0.1408, -0.2103,  0.0485,  0.0675, -0.1694,\n",
      "          -0.1213,  0.0065, -0.1555, -0.0549, -0.0221,  0.2026,  0.0032,\n",
      "          -0.0748, -0.2013, -0.0128, -0.2633, -0.0092,  0.0358, -0.1426,\n",
      "          -0.1449, -0.0387, -0.1386, -0.1488, -0.1201, -0.0155,  0.0192,\n",
      "          -0.1259, -0.2154, -0.0554,  0.0248,  0.1170, -0.1280,  0.0722,\n",
      "           0.0632,  0.1189,  0.1085,  0.2034,  0.1701, -0.1863, -0.2520,\n",
      "          -0.1531,  0.0189, -0.0043,  0.0765, -0.0064,  0.0813, -0.1024,\n",
      "           0.1228, -0.1121, -0.1118, -0.1401,  0.0386, -0.0736, -0.1871,\n",
      "           0.1971,  0.1357, -0.2150,  0.0050, -0.1787,  0.0518,  0.2458,\n",
      "          -0.1059, -0.1208,  0.3487, -0.1927,  0.0139, -0.0746, -0.0124,\n",
      "          -0.0197, -0.1904,  0.0210, -0.0530,  0.0270,  0.1358, -0.0343,\n",
      "          -0.2098,  0.2207,  0.1263,  0.1676, -0.0605, -0.0414, -0.2572,\n",
      "           0.1101, -0.1453, -0.1604,  0.1195,  0.1398,  0.0375, -0.0157,\n",
      "          -0.3005, -0.0852,  0.1377, -0.0787,  0.0337, -0.0266, -0.0645,\n",
      "          -0.1394, -0.1107,  0.0167, -0.0252, -0.0831,  0.1984, -0.1000,\n",
      "           0.0875,  0.0109, -0.2254,  0.0620,  0.1532,  0.0498,  0.0240,\n",
      "           0.1216, -0.3160, -0.2147,  0.0504, -0.2589,  0.1039,  0.0427,\n",
      "           0.3155, -0.1136,  0.1017,  0.1905, -0.1724,  0.0860,  0.0104,\n",
      "          -0.2994,  0.1732, -0.0851, -0.0743, -0.0258,  0.0343, -0.0088,\n",
      "           0.0888, -0.0856,  0.2338,  0.0249, -0.0566, -0.0290, -0.1987,\n",
      "           0.0481,  0.0455,  0.0128, -0.0610,  0.0517,  0.0060,  0.0832,\n",
      "           0.0080, -0.2499, -0.1720,  0.0202, -0.0328,  0.2605,  0.2172,\n",
      "           0.0270, -0.1856, -0.0727, -0.1901]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4728,  0.0000,  0.0000, -0.1186,  0.4613,  0.0000,  0.6620,\n",
      "           0.5339,  0.6709,  0.9340,  1.7077, -1.0163,  0.9457, -0.2516,\n",
      "          -1.6339,  0.5123,  1.8776, -0.7567,  0.0000, -2.6431,  0.0000,\n",
      "           0.0000,  2.9292,  0.5544, -0.1173,  3.2089,  0.0000,  0.5186,\n",
      "          -2.2264, -1.2858,  0.0289,  1.0131,  0.0000,  0.8597, -0.7986,\n",
      "          -1.4655,  0.6197,  0.0000,  1.9913,  0.1017,  0.4672, -2.2044,\n",
      "          -0.5664, -0.1150, -0.7130, -0.6890,  1.9274,  0.1099, -0.2870,\n",
      "           0.0000,  1.4677,  0.4623,  0.6672,  0.0000,  0.5316,  0.2750,\n",
      "          -1.2427, -0.9509,  1.8137, -0.0119,  0.2052, -1.8188, -1.4011,\n",
      "          -0.8064,  1.1799,  0.2653, -0.1672, -0.2546, -0.0047, -0.4607,\n",
      "          -0.3250, -0.3240,  0.1474, -0.1262,  0.6584, -0.8061,  2.0662,\n",
      "           1.6792,  0.0000, -0.5456,  1.2267,  0.0862,  0.3265, -1.8363,\n",
      "          -0.0711, -1.7318, -1.4587, -0.8914,  0.6229,  0.8108, -1.2238,\n",
      "          -1.1442,  1.9848, -0.3663,  0.0000,  0.1564,  2.1410,  0.0000,\n",
      "          -0.3040, -1.8393, -1.2906, -0.7212, -0.7665,  0.2370,  0.3818,\n",
      "           1.1139, -1.0706,  2.2522,  0.0000, -0.2883, -0.0532,  0.6104,\n",
      "          -0.2545, -0.2804, -1.9418,  1.1285,  1.0063,  0.0000, -0.5751,\n",
      "           0.0297, -1.6946, -0.4010, -0.3791,  0.0000, -0.5366, -1.1107,\n",
      "           1.3041,  0.1695,  0.3223,  1.3582,  2.0788, -2.6340,  0.0000,\n",
      "          -0.7230,  0.4291,  0.0601,  0.3265, -2.1012, -0.4969, -1.6773,\n",
      "          -0.6416,  0.2344,  0.0000, -1.2146, -0.6309, -0.0404,  0.4646,\n",
      "           1.7381,  1.5949,  1.4320, -1.2625,  0.0000, -0.4801, -0.0394,\n",
      "           0.3266, -0.1171,  1.3537, -0.0318, -1.9003, -1.8063, -1.4264,\n",
      "           0.0000, -0.7059, -0.3892, -0.9807,  0.0000,  0.4064,  0.9700,\n",
      "           0.0000, -0.1475,  1.5131, -0.3729, -0.3158, -2.0085,  0.1296,\n",
      "          -0.3527, -0.8299, -0.7687, -0.0403, -0.9375,  0.7276,  1.0418,\n",
      "           0.0469,  0.4631,  0.3159,  0.0000, -0.5408,  0.0000,  0.0000,\n",
      "          -1.0640, -0.5870, -1.7883,  1.2674, -0.9262, -1.6147, -0.3333,\n",
      "          -1.1569, -1.9606, -0.0719, -0.3748,  2.6971,  0.0000, -2.6312,\n",
      "          -0.5862, -0.7157, -1.3861, -1.2538,  0.1719,  0.0000, -1.1107,\n",
      "           0.9448, -0.6922, -1.5193,  0.3622,  0.2380, -1.4262, -2.3445,\n",
      "           0.0476, -1.4795,  0.4271,  0.0132, -0.9015,  0.3010, -1.1653,\n",
      "          -1.3007, -0.1877,  1.2720,  1.2662, -2.1880, -0.0559,  0.0000,\n",
      "          -1.1752,  0.9561,  1.9993,  0.5275,  0.7886, -0.6787,  0.1044,\n",
      "          -0.6804, -2.2618,  0.1673, -0.3132, -1.0432, -0.3820, -1.0799,\n",
      "           0.5577,  1.4992, -0.5645,  0.0000,  1.2434,  0.5827,  0.0000,\n",
      "           1.9516,  0.0000,  0.4875,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0277, 0.2470, 0.0821, 0.0564, 0.1136, 0.1163, 0.0334, 0.1661, 0.0876,\n",
      "         0.0698]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0491, -0.0112, -0.4448, -0.1263, -0.0385,  0.0247, -0.1473,\n",
      "          -0.1171,  0.1795, -0.1630,  0.2776,  0.0411, -0.0841,  0.0055,\n",
      "           0.1026, -0.2076,  0.1825, -0.1044, -0.2515,  0.1644,  0.0235,\n",
      "           0.0120,  0.3020,  0.0482,  0.0270,  0.0354, -0.0055, -0.2047,\n",
      "          -0.0539,  0.0553,  0.1772, -0.2038,  0.1319,  0.0422,  0.2439,\n",
      "           0.1066, -0.0685,  0.0571, -0.0880,  0.0452,  0.1335, -0.0570,\n",
      "           0.0013, -0.0539, -0.1558,  0.0618,  0.0287, -0.0957,  0.1880,\n",
      "          -0.1903,  0.0921,  0.0742, -0.1764,  0.0887, -0.0721, -0.0886,\n",
      "           0.0810,  0.0912,  0.1324,  0.1373, -0.0112, -0.0013, -0.1502,\n",
      "          -0.0710,  0.1601, -0.0672, -0.3147,  0.0848, -0.0143,  0.1388,\n",
      "          -0.1229,  0.1165, -0.0327, -0.0581, -0.2330,  0.3012, -0.0415,\n",
      "           0.1617,  0.0998,  0.1265, -0.1491, -0.0231, -0.2809, -0.0362,\n",
      "          -0.0384,  0.0644, -0.0604,  0.0355, -0.2062, -0.0674,  0.0047,\n",
      "           0.0640,  0.0062,  0.0547, -0.0311,  0.0850, -0.1298,  0.2515,\n",
      "           0.1407,  0.1791, -0.1329, -0.0927,  0.0379,  0.0690, -0.2810,\n",
      "          -0.1807, -0.0392, -0.0434, -0.1019,  0.0075,  0.2580,  0.0531,\n",
      "          -0.0193, -0.2737,  0.0567, -0.2995,  0.0423,  0.0296, -0.1327,\n",
      "          -0.0611,  0.0019, -0.0756, -0.1535, -0.0499,  0.0206, -0.0581,\n",
      "          -0.0254, -0.1437, -0.0362, -0.0640,  0.0139, -0.2139,  0.1249,\n",
      "           0.0915, -0.0012,  0.1935,  0.3698,  0.0843, -0.2121, -0.1928,\n",
      "          -0.0904,  0.0692,  0.0133,  0.1300,  0.0180,  0.0506, -0.1046,\n",
      "           0.0297, -0.0584, -0.1326, -0.1186,  0.0263, -0.1038, -0.1725,\n",
      "           0.1213,  0.1119, -0.0927,  0.1061, -0.1186, -0.0252,  0.1388,\n",
      "          -0.1382, -0.1810,  0.3103, -0.1970, -0.0662, -0.1030,  0.0209,\n",
      "          -0.0246, -0.0091, -0.0552, -0.0386,  0.0659,  0.1177, -0.0933,\n",
      "          -0.1937,  0.2373,  0.1677,  0.2703, -0.1176,  0.0196, -0.2769,\n",
      "           0.1060, -0.1310, -0.1295,  0.0495,  0.0867,  0.0466,  0.0297,\n",
      "          -0.2551, -0.0957,  0.1832, -0.1340,  0.0251, -0.0276, -0.0010,\n",
      "          -0.1641, -0.0403,  0.0285,  0.0211, -0.1298,  0.2409, -0.1040,\n",
      "           0.1636, -0.0327, -0.1454,  0.0772,  0.2075,  0.0323, -0.0527,\n",
      "           0.0688, -0.3915, -0.1719,  0.1066, -0.2248,  0.1216,  0.0489,\n",
      "           0.3176, -0.1072,  0.1327,  0.2103, -0.1693,  0.0872,  0.0089,\n",
      "          -0.1528,  0.1053,  0.0561, -0.0752, -0.1263,  0.1382, -0.1659,\n",
      "           0.0271, -0.0316,  0.1720,  0.0162, -0.0363,  0.0338, -0.1767,\n",
      "           0.0695,  0.1107,  0.0808, -0.0389,  0.0895, -0.0746,  0.0665,\n",
      "           0.0455, -0.3226, -0.1377,  0.0677,  0.0526,  0.3045,  0.1707,\n",
      "          -0.0102, -0.1543, -0.0403, -0.1153]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0625e+00, -6.9692e-02, -1.8077e+00,  1.3220e+00,  5.1612e-01,\n",
      "          -3.7615e-01,  1.0093e-03, -7.2276e-01,  2.1177e+00, -2.1365e-01,\n",
      "           2.8202e-01,  8.3061e-01, -1.1106e+00,  1.9967e-01,  3.1268e-01,\n",
      "           3.5186e-01, -6.8280e-01,  1.6926e-01,  8.7446e-01,  5.4575e-01,\n",
      "           0.0000e+00,  0.0000e+00, -3.6941e-02, -5.3539e-01, -1.0041e-01,\n",
      "           6.5107e-01,  0.0000e+00, -1.3621e+00, -2.1267e+00, -1.0345e+00,\n",
      "           3.8849e-02, -1.4546e+00, -2.0766e+00,  0.0000e+00, -2.8521e-01,\n",
      "          -2.0017e+00,  0.0000e+00,  9.9694e-01,  6.0147e-01,  9.5349e-01,\n",
      "           0.0000e+00, -2.2112e+00, -7.0603e-01,  1.3960e+00,  8.9784e-02,\n",
      "          -1.1383e+00,  2.4236e-01,  7.4215e-01, -7.0948e-01, -1.3359e+00,\n",
      "           1.6085e+00, -1.3741e-01,  6.6253e-01,  1.1164e+00,  5.6731e-01,\n",
      "           3.3308e-01, -4.4964e-01, -8.8806e-01,  1.3377e-01,  6.2832e-01,\n",
      "          -7.0456e-01,  0.0000e+00, -6.9337e-01, -1.5469e+00,  2.8926e-01,\n",
      "           9.5774e-02, -1.7757e-01,  5.9499e-01, -2.1387e+00,  5.5966e-01,\n",
      "           1.8253e-01, -5.1256e-01, -3.4090e-01, -1.1320e+00, -6.4740e-01,\n",
      "           4.6102e-01, -1.0491e+00,  1.1886e-01,  5.1714e-01, -1.8629e-01,\n",
      "          -3.8510e-01,  2.1578e+00,  7.7739e-01, -8.4541e-01,  3.9783e-01,\n",
      "           4.1921e-01,  0.0000e+00, -5.6406e-01, -1.4129e+00,  0.0000e+00,\n",
      "           4.0447e-01, -3.5137e-01,  4.9395e-01, -2.3210e+00,  1.2379e+00,\n",
      "           0.0000e+00,  1.3203e+00, -9.0735e-01,  2.3908e+00,  9.5501e-01,\n",
      "          -1.2008e+00,  5.9447e-01,  1.0664e+00,  0.0000e+00,  0.0000e+00,\n",
      "           4.0243e-01, -1.2704e+00,  4.5479e-01,  1.9688e+00,  1.4963e-01,\n",
      "          -8.3254e-01,  5.3416e-01,  8.0843e-01,  6.6388e-01, -1.0554e+00,\n",
      "           9.1773e-01, -7.0306e-01, -8.4505e-01,  2.5770e-01,  8.7974e-01,\n",
      "          -8.7715e-01, -1.3961e+00, -3.6480e-01, -1.8464e+00, -1.3005e+00,\n",
      "           1.0695e+00, -8.1167e-01,  6.4918e-01,  0.0000e+00, -1.4896e+00,\n",
      "           2.5019e+00,  3.7789e-01, -1.3454e+00,  7.2214e-01,  3.2009e+00,\n",
      "          -7.5265e-01, -3.8370e-01,  1.2824e+00,  2.2519e+00,  0.0000e+00,\n",
      "          -3.9000e-02,  3.0300e+00,  3.6278e-01,  0.0000e+00, -1.1120e+00,\n",
      "           1.2472e+00,  7.7531e-01, -7.7471e-01, -4.4800e-02, -1.3869e+00,\n",
      "           2.3361e+00,  0.0000e+00,  0.0000e+00, -2.1307e+00, -5.8164e-01,\n",
      "           7.8596e-01, -1.8621e+00, -1.3047e+00,  1.9036e-01, -3.6287e+00,\n",
      "          -1.8687e+00,  1.1504e+00,  0.0000e+00,  9.5954e-01, -1.4611e+00,\n",
      "          -2.7069e-02,  1.9743e+00,  1.1269e+00, -4.8566e-01, -1.2413e+00,\n",
      "           0.0000e+00, -1.3224e+00, -1.6391e+00, -7.7179e-01,  6.8269e-01,\n",
      "          -1.3797e+00, -1.2610e-01,  6.0647e-01, -7.4908e-01,  0.0000e+00,\n",
      "           1.3326e+00, -2.5533e+00,  2.7793e-01, -5.8353e-01,  1.6234e+00,\n",
      "          -1.2403e+00, -1.8453e-03, -5.0219e-02,  9.0085e-01,  5.6543e-01,\n",
      "          -4.1988e-01,  3.8843e-01, -1.1562e-01,  8.0969e-01,  1.0504e+00,\n",
      "          -7.8923e-01, -1.4389e+00, -4.1536e-01, -7.5022e-01, -4.5415e-01,\n",
      "           0.0000e+00,  7.2233e-01, -1.8530e+00,  1.3574e+00,  8.3787e-01,\n",
      "          -1.5240e+00, -3.5867e-01,  6.4768e-01,  0.0000e+00, -2.1783e+00,\n",
      "           8.3531e-01, -1.2911e+00, -1.2838e+00,  2.6101e-01, -1.5635e+00,\n",
      "           0.0000e+00,  1.3418e-01,  2.5769e+00, -3.0754e-02, -5.7956e-01,\n",
      "          -1.4281e+00,  1.9010e+00, -3.8089e-01,  1.4695e+00,  8.0544e-01,\n",
      "           3.6930e-01,  0.0000e+00, -7.0031e-01,  8.8838e-02,  1.0254e+00,\n",
      "           9.7850e-01, -1.4083e+00,  6.5956e-01, -1.1449e+00, -1.6455e+00,\n",
      "          -6.0039e-01,  8.7765e-03, -7.1081e-01,  3.7045e-01, -2.2393e-01,\n",
      "          -7.5248e-01,  5.7222e-01,  5.3059e-01, -6.6371e-01,  0.0000e+00,\n",
      "           5.7816e-01,  1.8919e+00, -8.6390e-01,  4.9353e-01, -3.8721e-01,\n",
      "           4.9988e-01, -9.7498e-01,  1.7727e+00, -1.0636e+00, -8.0775e-01,\n",
      "          -6.2207e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0790, 0.1121, 0.1200, 0.1524, 0.1058, 0.1405, 0.0750, 0.0550, 0.0531,\n",
      "         0.1071]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0063, -0.0711, -0.3789, -0.1179, -0.0272, -0.0141, -0.1812,\n",
      "          -0.0342,  0.2083, -0.0699,  0.2963,  0.0273, -0.0793,  0.0155,\n",
      "           0.0602, -0.2538,  0.1282, -0.0897, -0.2596,  0.2123,  0.0216,\n",
      "          -0.0024,  0.3653,  0.0816,  0.0164,  0.0963, -0.0012, -0.2295,\n",
      "          -0.0337,  0.1119,  0.1488, -0.1807,  0.1204,  0.0628,  0.2439,\n",
      "           0.0767, -0.0652,  0.1051, -0.0274,  0.0818,  0.1565, -0.0746,\n",
      "          -0.0261, -0.0649, -0.2071,  0.1106,  0.0317, -0.1194,  0.1921,\n",
      "          -0.2507,  0.1297,  0.0998, -0.1453,  0.1358, -0.0777, -0.1884,\n",
      "           0.1371,  0.0726,  0.1024,  0.1173, -0.0016, -0.0078, -0.1437,\n",
      "          -0.0293,  0.2021, -0.1411, -0.3741,  0.0319, -0.0022,  0.1298,\n",
      "          -0.1164,  0.0869,  0.0132, -0.0402, -0.1746,  0.2985, -0.0802,\n",
      "           0.0558,  0.1398,  0.2022, -0.1282,  0.0444, -0.3003, -0.0334,\n",
      "          -0.0698,  0.0656, -0.0592,  0.0389, -0.2328, -0.0183, -0.0371,\n",
      "           0.0269,  0.0355,  0.0283, -0.0334,  0.1209, -0.1819,  0.2652,\n",
      "           0.2218,  0.0862, -0.0996, -0.1945, -0.0014,  0.0401, -0.1742,\n",
      "          -0.1854,  0.0123, -0.1087, -0.0626,  0.0124,  0.2626,  0.0756,\n",
      "          -0.0702, -0.1988,  0.0113, -0.2572,  0.0398, -0.0160, -0.1358,\n",
      "          -0.1336,  0.0033, -0.0810, -0.0922, -0.0713,  0.0365,  0.0120,\n",
      "          -0.0704, -0.1622, -0.0417, -0.0448,  0.1007, -0.1990,  0.0878,\n",
      "           0.0621,  0.1086,  0.1682,  0.2965,  0.1360, -0.1538, -0.2309,\n",
      "          -0.1605,  0.0180, -0.0167,  0.0780,  0.0044,  0.1036, -0.0930,\n",
      "          -0.0079, -0.0561, -0.1097, -0.0444, -0.0120, -0.0386, -0.2303,\n",
      "           0.1525,  0.1610, -0.1649,  0.0854, -0.1819,  0.0093,  0.2362,\n",
      "          -0.1319, -0.1642,  0.3076, -0.2083, -0.0295, -0.1191,  0.0482,\n",
      "          -0.0825, -0.1487, -0.0201, -0.0201,  0.1185,  0.1220, -0.0445,\n",
      "          -0.2089,  0.2222,  0.1251,  0.1043, -0.1077,  0.0337, -0.2587,\n",
      "           0.1558, -0.1556, -0.1607,  0.1061,  0.1840,  0.0136, -0.0442,\n",
      "          -0.2911, -0.1248,  0.1052, -0.0502,  0.0563, -0.0593, -0.0553,\n",
      "          -0.1184, -0.0771,  0.0417, -0.0468, -0.1376,  0.1881, -0.1311,\n",
      "           0.1068, -0.0036, -0.2031,  0.0862,  0.1667,  0.0994, -0.0578,\n",
      "           0.0904, -0.3724, -0.2056,  0.1020, -0.2161,  0.1143,  0.1093,\n",
      "           0.3083, -0.0540,  0.0852,  0.1265, -0.1725,  0.0107,  0.0717,\n",
      "          -0.2947,  0.1141, -0.0024, -0.0739, -0.0681,  0.0768,  0.0280,\n",
      "           0.0588, -0.0746,  0.2770,  0.0126, -0.0049,  0.0111, -0.1554,\n",
      "           0.0661,  0.0693,  0.0358,  0.0452,  0.1229, -0.0594,  0.0484,\n",
      "           0.0597, -0.2816, -0.1436,  0.0231, -0.0388,  0.2502,  0.2206,\n",
      "          -0.0430, -0.1883, -0.0177, -0.1864]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-9.9200e-01, -1.1823e+00,  4.6338e-01,  9.8967e-02,  0.0000e+00,\n",
      "           1.2256e+00,  0.0000e+00, -1.1818e+00,  1.8898e-01, -4.6331e-02,\n",
      "          -1.6648e-01,  1.5215e+00, -6.3648e-01, -8.0149e-01,  0.0000e+00,\n",
      "          -4.1381e-01,  4.1346e-01, -3.7484e-01,  5.7197e-01,  1.8718e+00,\n",
      "           0.0000e+00, -3.1099e-01,  2.1271e-01,  2.4674e+00,  1.0309e+00,\n",
      "           9.9340e-01,  1.8115e-01,  0.0000e+00,  0.0000e+00, -9.3164e-01,\n",
      "          -1.2572e+00, -6.8082e-01,  1.3860e+00,  1.0390e+00,  0.0000e+00,\n",
      "           2.8106e-01,  8.4565e-01, -7.2982e-01,  4.0053e-01,  4.5644e-01,\n",
      "           0.0000e+00, -7.6636e-02,  1.0659e+00,  5.3540e-01,  8.1668e-01,\n",
      "          -1.7466e+00,  3.9126e-01,  4.8975e-01,  8.8362e-01, -7.7731e-01,\n",
      "           4.8444e-01, -3.1683e-01, -2.3708e-01,  9.1346e-01,  1.0606e+00,\n",
      "           1.0280e+00,  1.5453e+00, -1.1803e+00, -1.0914e+00, -1.9286e-01,\n",
      "           2.0156e+00,  8.6698e-01,  4.4454e-01, -2.9874e+00,  8.1725e-01,\n",
      "           6.4662e-01,  2.3232e+00,  9.3940e-01, -2.2228e+00,  9.0560e-01,\n",
      "          -8.2944e-01,  8.9167e-01,  1.0736e+00, -6.1757e-01, -9.8179e-03,\n",
      "          -1.8000e+00,  2.0936e+00,  2.7706e+00,  2.2190e+00, -8.6334e-01,\n",
      "          -9.3163e-01,  5.4122e-01, -7.5770e-01, -1.1755e+00, -3.0807e-01,\n",
      "           0.0000e+00,  9.7832e-01,  1.0733e+00, -4.5745e-01,  1.4986e+00,\n",
      "           0.0000e+00,  1.6149e-01, -4.3418e-01,  3.9176e-01,  1.6242e-01,\n",
      "           5.7644e-02, -6.1304e-01,  1.3907e-02, -9.3956e-01,  8.6700e-01,\n",
      "          -3.9238e-01,  2.0786e+00,  2.7298e-01, -2.0206e+00,  1.2453e+00,\n",
      "           1.1644e+00, -8.4998e-01,  1.7590e-02, -6.8784e-01,  0.0000e+00,\n",
      "           2.0225e-01, -5.0306e-01,  1.5884e+00,  4.8017e-02, -1.6781e+00,\n",
      "           4.8734e-01, -1.5662e+00, -2.1155e+00,  7.7738e-01,  1.2662e+00,\n",
      "           6.2644e-01, -7.3469e-01,  0.0000e+00,  1.8075e+00, -9.9820e-01,\n",
      "          -2.6099e-01, -5.8745e-01, -1.4302e+00,  2.2156e-01,  3.7504e-01,\n",
      "           1.3021e+00,  1.8991e+00, -1.9039e+00, -1.7387e+00,  3.5269e-01,\n",
      "           5.4479e-01,  2.8889e-03,  4.4777e-01, -8.8915e-01, -2.1370e-01,\n",
      "          -6.1436e-01, -9.8223e-02, -6.4724e-01, -5.8072e-01,  1.6433e-01,\n",
      "           3.2018e-01, -1.2087e-01, -9.5278e-01, -4.1237e-03,  1.1192e-01,\n",
      "           1.3591e+00, -2.0070e-01,  4.5956e-02,  2.0592e+00, -4.1252e-01,\n",
      "           2.9744e-01,  1.6472e-01,  1.9154e+00, -3.5386e-01, -8.3795e-01,\n",
      "          -3.2509e-01,  3.5264e-01, -6.2097e-01,  1.2953e-01, -1.7457e+00,\n",
      "          -2.1004e-01, -4.7035e-01,  7.3578e-01,  1.9973e+00, -2.5587e-01,\n",
      "          -4.7095e-01,  1.0272e+00, -1.1898e-02,  1.8365e+00, -2.0402e+00,\n",
      "          -5.4798e-01,  3.1036e-01,  1.4375e+00, -5.4875e-01,  1.3189e-01,\n",
      "           2.2869e+00, -1.9355e+00,  1.7896e+00, -1.9694e+00,  8.1485e-01,\n",
      "           1.2092e+00, -7.2807e-01,  4.3782e-01,  3.5973e-01,  0.0000e+00,\n",
      "          -3.8567e-01,  9.4400e-01,  0.0000e+00, -7.2211e-04,  9.4899e-01,\n",
      "          -1.9036e+00,  1.6077e-01, -1.9472e+00, -3.5736e-01,  8.0678e-02,\n",
      "           4.4198e-02, -5.2665e-02, -1.0126e-01, -1.3480e+00, -9.0920e-01,\n",
      "          -4.5434e-01,  1.8000e+00,  4.7142e-01,  5.6219e-01, -1.6284e+00,\n",
      "          -4.0266e-01, -1.7266e+00,  0.0000e+00,  0.0000e+00, -6.9406e-01,\n",
      "          -3.6756e-01,  0.0000e+00,  5.1056e-01, -9.5891e-01,  6.8311e-02,\n",
      "           2.6271e+00, -1.3235e-01,  6.5790e-01, -8.6743e-01,  2.1614e+00,\n",
      "           1.5852e-01, -8.8014e-01,  1.0487e+00,  1.0281e+00, -5.3458e-01,\n",
      "          -9.9952e-01, -1.0588e+00, -2.3350e-01,  6.6790e-01, -3.8122e-01,\n",
      "           0.0000e+00, -4.2654e-01,  1.3374e+00,  5.9338e-01,  7.3766e-01,\n",
      "          -1.1930e+00,  8.5424e-01,  2.0389e-01,  1.4684e+00,  1.4919e+00,\n",
      "          -3.0322e-01, -8.0066e-01, -1.6123e+00,  2.5682e-01,  1.1273e+00,\n",
      "          -3.7404e-02, -8.3740e-01, -2.1775e-01,  1.0117e+00, -1.3792e-01,\n",
      "           1.6397e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0478, 0.0801, 0.0740, 0.1048, 0.1782, 0.1755, 0.0737, 0.0941, 0.0925,\n",
      "         0.0793]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.6693e-02, -3.5139e-02, -3.9383e-01, -1.1152e-01, -8.6043e-02,\n",
      "          -5.7103e-02, -2.1492e-01, -4.2684e-02,  2.4580e-01, -1.1141e-01,\n",
      "           3.5413e-01,  2.5208e-02, -1.0946e-01,  2.0561e-02,  6.5666e-02,\n",
      "          -3.3295e-01,  7.5811e-02, -1.2950e-01, -2.9930e-01,  1.9263e-01,\n",
      "           3.0322e-03,  4.6054e-02,  3.4657e-01,  7.2927e-02, -3.0227e-02,\n",
      "           1.2021e-01, -4.3388e-02, -2.5064e-01, -4.6410e-02,  9.3861e-02,\n",
      "           1.3378e-01, -1.9632e-01,  7.1907e-02,  7.5649e-02,  1.9587e-01,\n",
      "           1.4552e-01, -3.3684e-02,  4.3136e-02,  8.5965e-03,  7.3456e-02,\n",
      "           1.8722e-01, -7.4330e-02, -3.1948e-02, -7.7205e-02, -1.8276e-01,\n",
      "           9.4832e-02,  1.4111e-02, -1.4274e-01,  1.4738e-01, -2.9185e-01,\n",
      "           1.6114e-01,  6.0245e-02, -1.4060e-01,  1.6416e-01, -9.0755e-02,\n",
      "          -2.3259e-01,  1.1448e-01,  9.0107e-02,  1.0556e-01,  1.4516e-01,\n",
      "           1.6128e-02, -4.8339e-02, -1.9035e-01,  2.9225e-03,  1.8625e-01,\n",
      "          -1.7562e-01, -3.6452e-01,  5.4898e-02, -2.2969e-02,  1.6760e-01,\n",
      "          -1.0585e-01,  9.4775e-02, -2.4244e-02, -9.7720e-05, -1.3722e-01,\n",
      "           2.7398e-01, -6.1523e-02,  7.7965e-02,  1.6901e-01,  1.9666e-01,\n",
      "          -7.2450e-02,  3.5209e-02, -3.2960e-01,  5.1815e-03, -1.9690e-02,\n",
      "           4.3749e-02,  9.2982e-03,  4.2894e-02, -2.0356e-01, -3.4039e-02,\n",
      "          -1.0144e-02,  3.9197e-02, -4.1368e-04,  5.9074e-02, -4.1903e-02,\n",
      "           7.5689e-02, -1.6570e-01,  2.7812e-01,  1.9219e-01,  1.7445e-01,\n",
      "          -1.1756e-01, -2.0997e-01,  5.5237e-02,  5.8191e-02, -1.4533e-01,\n",
      "          -1.7236e-01,  4.2947e-02, -1.3077e-01, -2.8518e-02,  9.1548e-03,\n",
      "           2.5242e-01,  2.1463e-02, -7.0835e-02, -2.0747e-01, -2.0195e-02,\n",
      "          -2.4843e-01, -1.2746e-02, -2.6223e-03, -1.3729e-01, -1.7166e-01,\n",
      "          -2.9567e-02, -9.1336e-02, -1.1264e-01, -1.1469e-01, -4.2829e-04,\n",
      "           4.9741e-02, -1.0149e-01, -2.1911e-01, -4.4811e-02, -1.0534e-02,\n",
      "           1.1733e-01, -1.6364e-01,  7.6755e-02,  9.4226e-02,  1.4176e-01,\n",
      "           1.4463e-01,  2.4847e-01,  1.6396e-01, -1.8944e-01, -2.2532e-01,\n",
      "          -1.8376e-01,  1.2164e-02, -2.3470e-02,  8.2356e-02,  2.7405e-03,\n",
      "           8.1898e-02, -8.6083e-02,  1.0531e-01, -8.9519e-02, -8.3675e-02,\n",
      "          -1.0941e-01,  6.1803e-03, -5.0919e-02, -2.0957e-01,  1.6774e-01,\n",
      "           1.4897e-01, -2.1297e-01,  6.9047e-02, -2.0465e-01,  4.7504e-02,\n",
      "           2.5852e-01, -1.3407e-01, -1.7463e-01,  3.4405e-01, -2.1583e-01,\n",
      "          -1.0233e-02, -9.8018e-02, -3.1970e-02, -5.4289e-02, -1.7756e-01,\n",
      "           9.1519e-03, -3.6881e-02,  7.2957e-02,  1.1280e-01, -8.5892e-03,\n",
      "          -2.2038e-01,  2.0590e-01,  1.5080e-01,  1.5567e-01, -6.8578e-02,\n",
      "          -2.7381e-02, -2.6795e-01,  1.3026e-01, -1.3453e-01, -1.6703e-01,\n",
      "           1.4404e-01,  1.4482e-01,  7.1230e-02, -2.2251e-02, -3.2424e-01,\n",
      "          -1.2032e-01,  1.2520e-01, -8.1224e-02,  5.1604e-02, -3.3714e-03,\n",
      "          -6.2667e-02, -1.2923e-01, -9.6844e-02,  6.3612e-02, -2.7657e-02,\n",
      "          -9.5848e-02,  1.9681e-01, -1.0945e-01,  1.1188e-01,  3.8505e-04,\n",
      "          -2.2364e-01,  7.0521e-02,  1.6888e-01,  8.0215e-02,  8.3707e-03,\n",
      "           1.3628e-01, -3.4183e-01, -2.1152e-01,  5.5774e-02, -2.4851e-01,\n",
      "           1.2808e-01,  8.7804e-02,  3.0710e-01, -7.9385e-02,  1.0175e-01,\n",
      "           1.8199e-01, -1.8522e-01,  2.6817e-02,  4.5898e-02, -3.1665e-01,\n",
      "           1.5597e-01, -2.7937e-02, -9.4183e-02, -6.9571e-02,  3.9685e-02,\n",
      "           2.1970e-02,  1.0147e-01, -9.7180e-02,  2.5122e-01,  2.8904e-02,\n",
      "          -4.3592e-02, -3.7217e-02, -1.9691e-01,  4.7234e-02,  4.6506e-02,\n",
      "           1.3604e-02, -4.4360e-02,  8.2768e-02, -3.1491e-02,  1.0762e-01,\n",
      "           2.1015e-02, -2.7038e-01, -1.9632e-01,  2.1132e-02, -4.2687e-02,\n",
      "           2.7670e-01,  2.3291e-01, -1.1063e-03, -2.0466e-01, -3.7448e-02,\n",
      "          -1.9000e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1717,  2.2164,  0.0000,  0.1084,  1.0430,  0.5949, -2.4006,\n",
      "           1.0327,  0.3783,  0.8371,  0.5755, -0.8235,  0.3605, -1.1044,\n",
      "           0.3660,  1.3475, -1.4910,  1.4501,  0.0000, -1.0121,  3.2072,\n",
      "           2.6295,  0.4218,  0.5879, -0.0792, -0.7454,  2.1829, -0.6690,\n",
      "           1.0299,  1.1227, -0.0482,  0.1381,  0.0000,  1.5776, -0.4095,\n",
      "          -0.5378, -0.2042, -1.8282,  3.1514,  0.4606,  1.3960, -0.9188,\n",
      "          -0.1390, -0.9999,  2.4245, -1.2481,  0.1431, -0.3120, -0.2345,\n",
      "          -0.2284,  0.0000, -0.7112, -0.3607, -2.1675, -1.0360, -0.0527,\n",
      "          -0.7651,  0.6168,  0.3321, -0.4505,  0.1434,  1.6133,  1.1452,\n",
      "           0.0000,  0.0997,  0.2068, -0.4711,  0.2687, -2.3582, -0.0916,\n",
      "           0.4628,  0.1485,  1.4339, -0.5918, -0.0667,  0.7244, -1.0018,\n",
      "           0.2845,  1.5414, -0.0298,  0.7440,  0.9256, -1.3774,  0.0000,\n",
      "           1.5271,  0.0000, -0.4792, -2.2058,  0.3722, -0.0535,  0.7315,\n",
      "           0.1630, -0.3994,  0.1744, -1.6439, -0.3949, -1.1385, -0.5804,\n",
      "          -1.2142, -0.6414, -2.2939, -1.5493,  0.4523,  0.7300,  0.1954,\n",
      "          -1.3726,  0.0000, -0.4460, -1.0969,  0.7501, -1.2544,  1.9003,\n",
      "          -0.5994,  1.5085, -0.8129,  1.7867,  0.3488, -1.1691,  0.1064,\n",
      "           0.1202, -0.6061,  0.7912, -1.6117, -0.8294,  2.3661,  0.2559,\n",
      "           1.4513,  0.9298,  1.1321,  0.7115,  0.2847, -0.0146, -0.1305,\n",
      "          -0.1820,  0.5761,  1.4672, -0.4071, -0.8417, -0.7624,  0.3323,\n",
      "           0.9348, -0.6616,  0.0000,  0.6700, -0.0212, -0.6349,  0.4520,\n",
      "           0.9472,  0.1920,  0.0000,  3.6486,  0.6672, -0.9777, -2.5228,\n",
      "           2.5181, -0.6342, -0.7199, -1.1646, -0.6015,  0.1637, -1.6696,\n",
      "           0.1427,  0.1804,  0.2419, -2.4429,  0.0000, -0.6460,  1.0139,\n",
      "          -0.0749,  0.2802, -0.3944, -1.6190,  1.4116, -0.2716,  1.0259,\n",
      "          -0.0726,  0.3784,  0.4721, -1.3219,  0.9365,  0.4939,  0.0000,\n",
      "          -0.4106, -0.5028, -1.9862,  0.0471, -1.6682, -0.0473,  0.0000,\n",
      "           0.0000,  0.4969,  0.0000,  0.1948,  1.2822, -0.9252,  0.0000,\n",
      "           0.1659,  0.0000, -0.0583,  1.3623, -0.2734,  1.5468, -1.3526,\n",
      "           1.2104,  0.4850,  0.0000, -1.7813, -1.4654,  1.3109,  0.1644,\n",
      "           0.4907, -0.6394,  0.0000, -0.2070,  0.3968,  1.5839,  0.0000,\n",
      "           0.0000,  0.5399,  2.0493,  0.1220,  0.2846,  1.0993, -0.0714,\n",
      "           0.0000,  0.0000, -0.3306, -0.3474,  0.0000,  0.0000, -1.2105,\n",
      "          -0.3962, -2.0880, -0.8840, -1.8136, -0.5054,  0.6672, -0.9862,\n",
      "           0.0000,  2.0416,  0.0000, -1.2625, -1.1030,  2.8844, -0.4368,\n",
      "           0.7500, -0.7638,  0.6774,  0.6577,  0.0631, -0.9618, -1.5725,\n",
      "          -0.6506,  0.8922, -0.6516, -0.1559]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0303, 0.1175, 0.1670, 0.0926, 0.1214, 0.1165, 0.1220, 0.0868, 0.0849,\n",
      "         0.0612]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0009, -0.0616, -0.4301, -0.1652, -0.0472, -0.0747, -0.1763,\n",
      "          -0.0592,  0.1924, -0.1181,  0.3240,  0.0086, -0.0988,  0.0401,\n",
      "           0.0926, -0.2980,  0.1459, -0.0914, -0.2905,  0.1623,  0.0506,\n",
      "          -0.0215,  0.3523,  0.0625,  0.0035,  0.1111,  0.0026, -0.2402,\n",
      "          -0.0372,  0.0953,  0.1687, -0.1724,  0.1354,  0.0520,  0.2472,\n",
      "           0.1102, -0.0930,  0.0646, -0.0581,  0.0872,  0.1476, -0.0580,\n",
      "          -0.0179, -0.0661, -0.2253,  0.1347,  0.0176, -0.1469,  0.2034,\n",
      "          -0.2615,  0.1225,  0.0804, -0.1401,  0.1582, -0.0913, -0.1951,\n",
      "           0.0981,  0.0754,  0.1261,  0.1429, -0.0035, -0.0093, -0.1509,\n",
      "          -0.0138,  0.1899, -0.1412, -0.3765,  0.0713, -0.0092,  0.1612,\n",
      "          -0.1029,  0.1218, -0.0054, -0.0485, -0.2007,  0.3378, -0.0884,\n",
      "           0.0878,  0.1503,  0.2035, -0.1205,  0.0456, -0.3060, -0.0060,\n",
      "          -0.0740,  0.0566, -0.0381,  0.0579, -0.2278, -0.0146, -0.0057,\n",
      "           0.0468,  0.0075,  0.0190, -0.0332,  0.1449, -0.1597,  0.2533,\n",
      "           0.2275,  0.1270, -0.1175, -0.1794,  0.0277,  0.0303, -0.1749,\n",
      "          -0.1861,  0.0044, -0.0839, -0.0900,  0.0413,  0.2392,  0.0893,\n",
      "          -0.0517, -0.2100,  0.0084, -0.2811,  0.0596,  0.0044, -0.1529,\n",
      "          -0.1369,  0.0076, -0.1006, -0.1470, -0.0635,  0.0139, -0.0316,\n",
      "          -0.0513, -0.1557,  0.0140, -0.0595,  0.1127, -0.2108,  0.0870,\n",
      "           0.1074,  0.0945,  0.1664,  0.3241,  0.1400, -0.1546, -0.2376,\n",
      "          -0.1770,  0.0302, -0.0204,  0.0855, -0.0252,  0.1121, -0.0970,\n",
      "           0.0262, -0.0613, -0.0925, -0.0900,  0.0127, -0.0649, -0.2077,\n",
      "           0.1670,  0.1569, -0.1495,  0.1048, -0.1449,  0.0079,  0.2079,\n",
      "          -0.1306, -0.1907,  0.3418, -0.2353, -0.0569, -0.1435,  0.0262,\n",
      "          -0.0590, -0.1491, -0.0220, -0.0475,  0.1279,  0.1479, -0.0367,\n",
      "          -0.2470,  0.2018,  0.1340,  0.1522, -0.1349, -0.0013, -0.2417,\n",
      "           0.1183, -0.1811, -0.1273,  0.0673,  0.1687,  0.0168, -0.0055,\n",
      "          -0.2889, -0.1304,  0.1131, -0.0692,  0.0530, -0.0666, -0.0745,\n",
      "          -0.1331, -0.0652,  0.0251,  0.0045, -0.1127,  0.2190, -0.1326,\n",
      "           0.0903, -0.0235, -0.2228,  0.0617,  0.1585,  0.0828, -0.1007,\n",
      "           0.0452, -0.3834, -0.1773,  0.1286, -0.2569,  0.1268,  0.0635,\n",
      "           0.3196, -0.0744,  0.0929,  0.1526, -0.1669,  0.0364,  0.0821,\n",
      "          -0.2640,  0.1200,  0.0133, -0.0716, -0.0922,  0.0861,  0.0148,\n",
      "           0.0214, -0.1202,  0.2357, -0.0018, -0.0591, -0.0049, -0.1829,\n",
      "           0.0772,  0.1055,  0.0259, -0.0086,  0.0801, -0.0284,  0.0422,\n",
      "           0.0453, -0.2970, -0.1737,  0.0169, -0.0362,  0.2928,  0.2304,\n",
      "          -0.0130, -0.2148, -0.0145, -0.1901]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.4716e+00,  3.4691e-01, -8.7581e-01, -2.3151e-01,  0.0000e+00,\n",
      "          -1.1601e+00, -1.2104e-01,  0.0000e+00,  4.9740e-01,  1.3061e+00,\n",
      "          -1.0748e+00,  4.9382e-01, -1.9757e+00,  4.8263e-01, -7.7111e-01,\n",
      "           1.6687e+00,  5.8723e-02, -3.5916e-01, -3.7859e-01, -1.0451e-01,\n",
      "           6.6540e-01,  2.5375e-03, -1.4457e+00,  4.0634e-02,  8.8104e-03,\n",
      "          -3.7847e-01,  0.0000e+00,  8.6306e-02, -1.5942e+00, -3.7554e-01,\n",
      "           0.0000e+00,  1.3233e+00, -3.4935e-01,  0.0000e+00,  1.2827e-01,\n",
      "          -1.6012e+00, -1.3510e+00,  1.1951e-01,  1.5899e+00,  1.4371e+00,\n",
      "          -1.2944e+00,  7.1762e-02, -1.3176e+00,  2.0681e-01,  7.7588e-02,\n",
      "           5.0709e-01, -5.1803e-01, -4.3647e-01,  1.0917e+00,  8.4819e-01,\n",
      "           0.0000e+00,  1.5746e+00,  3.0878e-01, -3.2396e-01, -5.6567e-01,\n",
      "           2.3915e-01, -1.8462e+00, -7.9423e-01,  1.2292e+00, -5.7716e-01,\n",
      "          -6.4576e-01,  2.8622e+00,  3.4220e-01,  8.2885e-01,  0.0000e+00,\n",
      "           4.0950e-02, -1.0662e+00, -2.0710e+00,  8.6367e-01, -7.1253e-01,\n",
      "          -1.6412e+00, -5.5528e-01,  9.7802e-01, -1.3059e+00, -7.4452e-01,\n",
      "           6.9895e-01,  2.0434e-01,  1.3211e+00,  2.7580e-01, -1.7646e-01,\n",
      "          -3.4059e-01,  9.4448e-02, -7.6606e-01, -8.8466e-01, -1.5038e+00,\n",
      "           0.0000e+00, -1.2194e+00,  4.4501e-02,  1.7788e+00,  1.1108e+00,\n",
      "          -4.4548e-01,  5.3901e-01,  1.2554e+00,  8.8761e-01, -1.3327e+00,\n",
      "           2.8336e-02,  4.9813e-02,  1.8373e-01,  5.0643e-01, -7.6299e-01,\n",
      "          -1.5076e-01, -9.0490e-02, -4.1646e-01,  0.0000e+00, -6.4867e-01,\n",
      "           1.0857e+00, -8.7378e-02,  3.3850e-01, -1.3470e+00,  0.0000e+00,\n",
      "           5.6648e-01,  0.0000e+00, -1.3639e-01, -1.8953e-01,  1.1820e+00,\n",
      "          -8.2020e-01, -1.1876e-01, -1.0209e+00, -4.0662e-01,  7.4331e-01,\n",
      "          -6.2566e-02, -4.1428e-01, -1.7344e+00,  8.0140e-01,  1.3293e+00,\n",
      "          -2.5109e-01,  1.4823e+00,  1.5357e-01, -8.8555e-01,  2.4923e+00,\n",
      "           2.3810e+00, -5.3554e-01,  1.3745e+00,  1.8772e+00,  2.5539e-01,\n",
      "           3.3790e-01,  2.0764e+00,  5.9510e-02, -7.3883e-01,  5.5297e-01,\n",
      "          -6.7804e-01, -2.3676e+00,  6.9405e-01,  1.1855e+00, -1.7279e+00,\n",
      "           5.5861e-01,  9.5106e-01, -7.7306e-01,  7.4545e-01,  3.9836e-01,\n",
      "          -9.9162e-02,  1.8741e+00, -7.0239e-01, -6.6723e-01,  1.7345e+00,\n",
      "           2.3170e+00,  1.5703e+00,  1.0971e+00,  2.2210e-01,  0.0000e+00,\n",
      "           4.1042e-01, -7.3451e-02, -3.0049e-01,  8.0845e-01, -1.7173e+00,\n",
      "           6.7290e-01,  2.0316e+00, -1.6314e-01, -1.3007e+00,  1.3104e-01,\n",
      "          -2.4389e+00,  0.0000e+00, -7.1144e-01, -1.6987e+00,  5.0582e-01,\n",
      "           3.8471e-01,  1.8789e+00,  1.2444e+00, -1.7214e+00,  0.0000e+00,\n",
      "          -1.0452e+00, -1.0844e+00, -2.2903e-01,  1.3325e+00,  6.2146e-01,\n",
      "           6.7460e-01,  1.0229e-01,  2.1505e-01, -3.0007e-01,  6.8298e-01,\n",
      "           0.0000e+00, -8.5746e-01, -1.2638e+00,  0.0000e+00, -1.2105e+00,\n",
      "           3.4204e-01, -3.3611e-01,  5.3235e-01,  6.9819e-01,  1.6362e+00,\n",
      "           2.5722e+00,  0.0000e+00, -2.2637e-01,  9.3406e-02,  9.7911e-01,\n",
      "           1.1166e+00,  7.6349e-01,  3.4132e-01,  2.1673e+00, -2.3658e-01,\n",
      "           1.4653e+00,  1.9457e+00, -2.2732e-02, -1.2271e+00,  0.0000e+00,\n",
      "           1.0186e+00, -4.7777e-02,  2.0615e-01,  6.7283e-01,  3.3361e-01,\n",
      "          -1.0597e+00,  1.3840e+00, -3.0653e-02, -1.2718e+00, -1.9681e+00,\n",
      "           1.5288e-01, -7.6484e-01, -3.7202e-01, -1.2055e+00, -9.2829e-01,\n",
      "           2.3514e-01,  0.0000e+00, -1.3084e+00,  3.5911e-02,  0.0000e+00,\n",
      "           8.0276e-01,  6.5027e-01,  0.0000e+00, -5.4373e-01, -8.4159e-01,\n",
      "          -4.7779e-01, -4.0308e-01, -3.8089e-01,  5.0136e-01, -7.8732e-01,\n",
      "           1.3316e+00,  6.3400e-01,  7.5072e-01, -8.4247e-01,  8.9403e-01,\n",
      "           0.0000e+00, -1.0111e+00, -5.8860e-01, -7.5731e-01,  0.0000e+00,\n",
      "          -1.0856e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0760, 0.1308, 0.1252, 0.0885, 0.0788, 0.0875, 0.0565, 0.1780, 0.0922,\n",
      "         0.0865]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0446, -0.0137, -0.4149, -0.1012, -0.0503, -0.0220, -0.1222,\n",
      "          -0.0951,  0.1708, -0.0971,  0.2759, -0.0221, -0.0995,  0.0256,\n",
      "           0.1031, -0.2182,  0.1637, -0.0747, -0.2652,  0.1630,  0.0439,\n",
      "          -0.0303,  0.3073,  0.0628, -0.0114,  0.0578, -0.0187, -0.2329,\n",
      "          -0.0217,  0.0827,  0.1615, -0.1839,  0.0996,  0.0243,  0.2355,\n",
      "           0.1169, -0.0886,  0.0537, -0.0938,  0.0512,  0.0961, -0.0642,\n",
      "          -0.0410, -0.0409, -0.1454,  0.1358,  0.0121, -0.1363,  0.1946,\n",
      "          -0.1963,  0.0868,  0.0728, -0.1690,  0.0991, -0.0797, -0.1222,\n",
      "           0.0730,  0.0902,  0.0909,  0.1390, -0.0068,  0.0115, -0.1375,\n",
      "          -0.0353,  0.1853, -0.1058, -0.3198,  0.0960, -0.0225,  0.1549,\n",
      "          -0.0920,  0.1172,  0.0096, -0.0267, -0.2399,  0.2464, -0.0566,\n",
      "           0.1122,  0.0963,  0.1958, -0.1580, -0.0436, -0.2891, -0.0451,\n",
      "          -0.0596,  0.0775, -0.0730,  0.0577, -0.1887, -0.0405, -0.0005,\n",
      "           0.0512,  0.0247,  0.0439, -0.0308,  0.1186, -0.1226,  0.2664,\n",
      "           0.1664,  0.1555, -0.1415, -0.1309,  0.0368,  0.0687, -0.2291,\n",
      "          -0.1739,  0.0058, -0.0414, -0.0921,  0.0358,  0.2482,  0.0835,\n",
      "          -0.0186, -0.2455,  0.0026, -0.2795,  0.0526,  0.0064, -0.1162,\n",
      "          -0.1046,  0.0034, -0.1167, -0.1572, -0.0371,  0.0079, -0.0359,\n",
      "          -0.0052, -0.1451,  0.0338, -0.0536,  0.0862, -0.2208,  0.1329,\n",
      "           0.1040,  0.0431,  0.1546,  0.3650,  0.0978, -0.1526, -0.1960,\n",
      "          -0.1237,  0.0772,  0.0006,  0.1147,  0.0193,  0.0752, -0.0932,\n",
      "           0.0041, -0.0321, -0.0754, -0.1164,  0.0239, -0.0560, -0.1363,\n",
      "           0.1251,  0.1598, -0.1228,  0.0922, -0.1159, -0.0485,  0.1503,\n",
      "          -0.1547, -0.2004,  0.3169, -0.1695, -0.0434, -0.0895,  0.0147,\n",
      "          -0.0162, -0.0181, -0.0380, -0.0142,  0.1238,  0.0761, -0.0686,\n",
      "          -0.2024,  0.2016,  0.1431,  0.1880, -0.1253,  0.0087, -0.2254,\n",
      "           0.1068, -0.1339, -0.1001,  0.0466,  0.0596,  0.0439,  0.0308,\n",
      "          -0.2443, -0.0998,  0.1445, -0.1309,  0.0310, -0.0346, -0.0789,\n",
      "          -0.1262, -0.0312,  0.0154,  0.0140, -0.1360,  0.2215, -0.1408,\n",
      "           0.1402,  0.0170, -0.1631,  0.0630,  0.2142,  0.0473, -0.0927,\n",
      "           0.0607, -0.3915, -0.1538,  0.1258, -0.2120,  0.1432,  0.0344,\n",
      "           0.3192, -0.1029,  0.1138,  0.1522, -0.1813,  0.0821, -0.0010,\n",
      "          -0.1674,  0.1137,  0.0579, -0.0905, -0.1312,  0.1365, -0.0738,\n",
      "           0.0299, -0.0605,  0.1439, -0.0033, -0.0363,  0.0135, -0.1588,\n",
      "           0.0940,  0.1086,  0.0461, -0.0190,  0.0505, -0.0736,  0.0328,\n",
      "           0.0397, -0.2917, -0.1397,  0.0703,  0.0201,  0.2568,  0.1655,\n",
      "          -0.0700, -0.1707, -0.0157, -0.1463]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.5256, -2.0606, -1.2198, -0.0504,  0.1062,  0.5891,  0.2238,\n",
      "           0.4854, -0.8762, -0.3504,  0.0000, -0.3706,  0.2670,  0.2643,\n",
      "           1.1536,  0.0000,  0.2347,  0.6379,  0.3195,  0.1215, -0.9001,\n",
      "          -1.5587,  0.4008,  1.9364,  1.1132,  0.8857, -0.2460,  1.1806,\n",
      "           0.3944,  3.8464, -2.4708,  1.3818, -0.8854,  1.3478, -0.3063,\n",
      "          -0.4142,  0.2815,  0.0000,  0.6691, -2.2860,  1.5055, -0.6472,\n",
      "          -0.8468, -1.5493,  0.5091,  0.2317,  0.1320,  0.0000,  0.0000,\n",
      "          -1.1212,  0.5370, -0.3246, -0.4431,  2.8998, -0.0914,  0.0000,\n",
      "          -1.8156, -0.6670, -0.1905,  0.9219,  3.3492,  1.1957,  1.3118,\n",
      "          -0.4432,  0.2157, -0.3717, -1.7704, -1.8204, -0.0644, -1.4523,\n",
      "          -0.9729,  0.3808, -0.3285,  0.2727,  1.0644, -0.1053,  1.2333,\n",
      "          -0.1782,  1.1886, -0.3455,  0.2540, -0.0158,  0.0482,  1.3486,\n",
      "          -0.0919,  1.7751, -0.0378,  0.0000, -0.7181, -0.5514,  0.3124,\n",
      "           0.2910, -2.2282, -1.9777, -0.3219, -0.0572,  1.6041, -0.8920,\n",
      "          -0.5400,  1.0997,  1.3076,  0.4732,  4.1068,  0.7968,  0.9061,\n",
      "           0.1797, -0.5268, -0.4613, -0.7488, -1.3485,  1.7867,  0.6538,\n",
      "          -0.8742, -1.3974,  0.0230,  1.2552,  1.0174, -0.8245,  2.6897,\n",
      "          -2.3132,  1.4688, -0.7871,  1.1695,  0.5497, -0.7035, -0.8366,\n",
      "          -0.0438,  2.7589, -0.3720, -1.4577, -0.5376, -0.8763,  0.3862,\n",
      "           0.0000,  0.0000,  0.2223,  1.6544,  0.0000,  0.7437, -0.2761,\n",
      "          -1.0226,  0.2490,  1.7291, -2.0650,  0.6234, -0.5220,  1.5558,\n",
      "           1.1535, -0.4160, -0.1229, -0.9402,  0.0000, -0.6044, -0.0816,\n",
      "           0.6718,  0.4157, -1.0145,  0.0000,  0.1042,  0.0000,  0.6930,\n",
      "          -0.4695, -0.2877,  0.5987, -1.5337,  0.9151,  0.7506,  1.6087,\n",
      "          -1.2059, -2.6986,  0.1455, -0.4821,  1.0243, -1.0261, -0.6828,\n",
      "           2.7124, -0.3884, -0.2028, -1.1382, -0.4367,  0.9204,  0.0000,\n",
      "           0.7404,  0.6455, -2.3418,  0.3244,  1.6566, -1.8792,  0.6852,\n",
      "           1.0696,  0.0000,  0.3235, -1.5544,  0.5397, -1.1001, -0.3412,\n",
      "          -0.3604,  0.0000,  0.0918,  2.1640,  1.4372,  0.2411, -1.1510,\n",
      "           0.6124,  0.9138,  0.7950,  0.1033, -0.2968, -1.6451,  0.0000,\n",
      "           0.8093,  1.0760, -0.6333,  0.3043,  1.5483,  0.5874, -2.7273,\n",
      "          -0.9208, -1.2349,  0.3479,  1.0470, -0.7772,  1.2000,  0.7222,\n",
      "          -0.0620, -0.4361,  1.3137,  0.7916,  0.5704, -0.8642,  1.9289,\n",
      "          -1.1689,  0.2351, -1.3321, -0.7688, -0.5350, -1.2934, -1.1776,\n",
      "          -0.0880, -0.9944, -1.2108,  1.2547, -1.1848,  0.0723,  0.6952,\n",
      "          -2.5282, -0.0098,  1.8061,  0.4248,  0.0323, -1.5316, -0.8406,\n",
      "           0.5965, -1.5532, -1.4292,  0.9721]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0523, 0.0755, 0.0659, 0.1294, 0.0986, 0.1695, 0.1705, 0.1074, 0.0876,\n",
      "         0.0433]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0018, -0.0316, -0.4137, -0.1193, -0.0603, -0.0558, -0.2363,\n",
      "          -0.0440,  0.2225, -0.1368,  0.3616,  0.0234, -0.1557,  0.0572,\n",
      "           0.0961, -0.3440,  0.0544, -0.0938, -0.3741,  0.1821,  0.0365,\n",
      "          -0.0326,  0.3205,  0.0458, -0.0390,  0.1468,  0.0097, -0.2834,\n",
      "          -0.0315,  0.1165,  0.1649, -0.2103,  0.0670,  0.0156,  0.1881,\n",
      "           0.1716, -0.1194,  0.0055,  0.0123,  0.0815,  0.1808, -0.0432,\n",
      "          -0.0385, -0.0702, -0.2281,  0.1662,  0.0303, -0.1681,  0.1791,\n",
      "          -0.3137,  0.1904,  0.0076, -0.1673,  0.1385, -0.1148, -0.2031,\n",
      "           0.0900,  0.0791,  0.0734,  0.1356,  0.0341, -0.0472, -0.2322,\n",
      "           0.0572,  0.1673, -0.2055, -0.3632,  0.1287, -0.0494,  0.2228,\n",
      "          -0.0756,  0.1431, -0.0034, -0.0009, -0.1574,  0.2867, -0.0498,\n",
      "           0.1194,  0.1422,  0.2374, -0.0805,  0.0473, -0.3648,  0.0028,\n",
      "           0.0159,  0.0840,  0.0477,  0.0613, -0.1798, -0.0307, -0.0235,\n",
      "           0.0383, -0.0142,  0.0424, -0.0208,  0.1454, -0.1294,  0.2762,\n",
      "           0.2306,  0.2035, -0.1380, -0.1747,  0.0635,  0.0924, -0.0902,\n",
      "          -0.1449,  0.0758, -0.0589, -0.0528,  0.0341,  0.2249,  0.0400,\n",
      "          -0.1050, -0.2151, -0.0294, -0.2549,  0.0063,  0.0188, -0.1859,\n",
      "          -0.1845, -0.0487, -0.1465, -0.1945, -0.0779, -0.0933,  0.0261,\n",
      "          -0.0787, -0.2512, -0.0144, -0.0105,  0.1040, -0.1855,  0.0860,\n",
      "           0.1116,  0.1423,  0.1038,  0.2493,  0.2338, -0.2078, -0.2335,\n",
      "          -0.2043,  0.0716, -0.0499,  0.0722,  0.0183,  0.0470, -0.0704,\n",
      "           0.1216, -0.0781, -0.0744, -0.1962,  0.0552, -0.1107, -0.1764,\n",
      "           0.1962,  0.2016, -0.2312,  0.0535, -0.2277,  0.0196,  0.2364,\n",
      "          -0.1203, -0.1977,  0.4057, -0.2335,  0.0025, -0.0817, -0.0361,\n",
      "          -0.0389, -0.1792, -0.0343, -0.0065,  0.0805,  0.1297, -0.0365,\n",
      "          -0.2585,  0.2367,  0.1537,  0.1780, -0.0732, -0.0965, -0.2542,\n",
      "           0.0869, -0.1282, -0.0987,  0.1207,  0.1397,  0.0611, -0.0844,\n",
      "          -0.3285, -0.0807,  0.1527, -0.0927,  0.0311, -0.0525, -0.1277,\n",
      "          -0.0973, -0.0572,  0.0243, -0.0482, -0.1021,  0.2221, -0.1264,\n",
      "           0.0915,  0.0181, -0.2713,  0.0587,  0.2144,  0.0387, -0.0173,\n",
      "           0.0776, -0.3706, -0.2164,  0.0632, -0.2554,  0.1341,  0.0951,\n",
      "           0.3614, -0.1221,  0.1145,  0.1708, -0.1876,  0.1030,  0.0106,\n",
      "          -0.2843,  0.1723, -0.1013, -0.1450, -0.1238,  0.0561,  0.0120,\n",
      "           0.0729, -0.1291,  0.2192,  0.0050, -0.0632, -0.0482, -0.1864,\n",
      "           0.1024,  0.1023, -0.0369, -0.0626,  0.0748, -0.0134,  0.1004,\n",
      "          -0.0214, -0.2609, -0.2202,  0.0167, -0.1006,  0.2928,  0.2525,\n",
      "          -0.0008, -0.2462, -0.0126, -0.2219]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.7280e-01,  0.0000e+00,  3.1480e-01, -1.0845e+00, -1.1723e+00,\n",
      "           0.0000e+00,  0.0000e+00,  1.3513e+00,  1.9047e-01,  6.1739e-01,\n",
      "           1.9026e+00,  6.0244e-01,  0.0000e+00, -9.1596e-01,  0.0000e+00,\n",
      "          -6.8524e-02, -1.6329e+00, -9.4349e-01,  1.3609e+00, -1.4346e+00,\n",
      "          -1.4074e-01, -5.2333e-01, -1.1193e+00, -2.5947e+00, -7.5588e-02,\n",
      "           1.3913e+00, -6.1923e-01,  0.0000e+00,  1.2765e-01,  5.5384e-01,\n",
      "           9.1469e-01, -3.5206e-03,  2.2301e-01,  2.0152e+00, -6.3876e-02,\n",
      "          -1.4085e+00, -1.1195e-01, -8.1780e-01,  3.1465e-01,  8.5297e-02,\n",
      "           8.6198e-01, -8.9993e-01,  1.0091e+00, -1.5631e+00,  0.0000e+00,\n",
      "          -3.0002e-01,  7.0455e-01, -6.0117e-01, -1.0205e+00,  1.1162e+00,\n",
      "          -1.3220e+00,  0.0000e+00,  6.6661e-01, -8.4650e-01,  2.2739e-01,\n",
      "          -3.0880e-01, -1.4342e+00,  0.0000e+00,  0.0000e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6134e-02, -2.8016e-01,  2.6585e-01, -6.2743e-02,\n",
      "           3.9425e-01,  5.7804e-01,  1.1648e+00,  1.5805e+00, -1.4151e+00,\n",
      "           4.2762e-01,  0.0000e+00,  0.0000e+00, -7.9765e-01, -2.1448e-01,\n",
      "           1.3922e-01,  5.2560e-01,  1.3985e+00,  0.0000e+00, -7.9290e-01,\n",
      "           7.5747e-01, -1.0058e+00,  7.5711e-01,  1.0587e+00, -1.2142e+00,\n",
      "          -1.1308e-01, -1.1073e+00,  0.0000e+00, -9.4471e-01, -1.9014e+00,\n",
      "           0.0000e+00,  9.8646e-01,  1.7013e+00,  9.4324e-01,  6.0815e-01,\n",
      "          -1.5974e-02,  0.0000e+00, -1.1754e+00,  0.0000e+00,  2.4477e+00,\n",
      "           2.4392e-01,  4.5889e-02,  0.0000e+00, -9.8935e-01,  1.6396e+00,\n",
      "          -1.0225e+00,  3.0284e+00,  6.1955e-01, -1.0212e-01, -1.2352e+00,\n",
      "           1.8982e-01, -5.0278e-01, -5.7016e-01,  7.1220e-01, -7.8037e-01,\n",
      "           6.3196e-01,  0.0000e+00,  2.2418e-01, -2.3272e+00,  2.9388e-02,\n",
      "          -8.1351e-01, -1.4102e+00, -1.8370e+00,  6.0335e-01,  0.0000e+00,\n",
      "          -2.0000e-01,  3.9115e-02,  2.1498e+00,  0.0000e+00, -2.0873e+00,\n",
      "          -9.2643e-01,  4.4951e-01, -1.1670e+00,  4.2509e-01, -4.6890e-01,\n",
      "          -7.4436e-01, -1.0649e+00, -9.7464e-01, -1.9484e-02,  2.3976e+00,\n",
      "           6.9848e-01, -1.1217e+00,  1.6915e+00, -1.4013e-01,  0.0000e+00,\n",
      "           3.4232e-02,  7.5927e-01,  4.2307e-01, -1.0329e+00, -9.5698e-02,\n",
      "           0.0000e+00,  0.0000e+00, -3.3903e-01,  6.5758e-01,  1.8406e+00,\n",
      "          -2.5242e-01, -2.1720e-01,  6.2335e-01, -2.3620e+00,  1.0554e+00,\n",
      "           3.0236e-01, -7.7548e-02,  1.5414e-01, -1.2115e+00, -2.1959e-02,\n",
      "           1.6817e+00,  1.8514e+00,  2.7045e-01, -1.2701e+00, -7.1340e-01,\n",
      "          -1.2243e+00, -1.0938e+00, -2.5900e+00,  5.0547e-01, -3.0579e+00,\n",
      "          -2.8702e-01,  4.9836e-01,  8.2935e-01,  3.1706e-01, -7.9275e-01,\n",
      "           2.7106e-01,  2.3395e+00,  0.0000e+00,  8.3814e-01, -4.0320e-01,\n",
      "           7.2690e-01,  5.9912e-01,  3.5927e-01,  8.4203e-01, -1.8296e+00,\n",
      "           1.3635e+00,  2.1588e+00,  3.3693e-01, -1.0151e+00, -1.1712e+00,\n",
      "          -2.2148e+00,  1.6655e+00,  2.1523e+00,  3.6336e-01,  2.3835e+00,\n",
      "           3.2309e-02,  0.0000e+00, -1.2759e+00, -5.4234e-01,  0.0000e+00,\n",
      "          -1.4466e+00,  9.5383e-01, -8.5153e-01,  8.3086e-01, -1.5596e+00,\n",
      "           6.3617e-01,  6.7629e-01,  0.0000e+00,  5.4910e-02,  1.8941e+00,\n",
      "           1.3077e+00,  0.0000e+00, -2.3168e+00,  1.5503e+00, -2.2252e-01,\n",
      "           0.0000e+00,  1.7330e+00,  2.7711e-01, -1.5519e+00,  9.2276e-01,\n",
      "           0.0000e+00, -8.4787e-01, -1.8010e+00, -2.0185e-04,  3.7341e-01,\n",
      "          -1.5732e+00,  0.0000e+00,  0.0000e+00, -1.7357e+00,  1.6938e+00,\n",
      "          -1.4404e+00,  6.3406e-01, -1.7216e+00,  9.8047e-01, -1.7151e+00,\n",
      "           1.5600e+00,  0.0000e+00, -2.5965e+00,  1.2382e+00, -1.2286e+00,\n",
      "           1.8836e+00, -5.0834e-01,  5.4289e-01, -2.6139e-01, -1.0215e+00,\n",
      "           1.3330e+00,  3.1008e-01,  0.0000e+00, -2.2891e-01, -1.6113e+00,\n",
      "           1.8060e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0568, 0.1153, 0.1587, 0.0853, 0.1529, 0.0982, 0.1085, 0.0759, 0.0854,\n",
      "         0.0630]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2642,  0.0041, -0.0859,  ...,  0.1502,  0.0316,  0.0553],\n",
      "        [ 0.2285, -0.0950, -0.5262,  ...,  0.0272, -0.0379,  0.1292],\n",
      "        [-0.0157, -0.2790, -0.6106,  ..., -0.2102, -0.0385, -0.2712],\n",
      "        ...,\n",
      "        [ 0.2082,  0.3466, -0.7304,  ..., -0.2953, -0.0143, -0.1623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.2048e-03, -6.2266e-02, -4.1484e-01, -1.5122e-01, -5.4461e-02,\n",
      "          -6.3152e-02, -1.7923e-01, -5.9853e-02,  1.9189e-01, -1.0495e-01,\n",
      "           3.0570e-01,  9.5845e-03, -8.6281e-02,  3.8030e-02,  8.2910e-02,\n",
      "          -2.7855e-01,  1.4218e-01, -8.7992e-02, -2.5873e-01,  1.7447e-01,\n",
      "           3.3528e-02,  1.0976e-02,  3.7024e-01,  6.7643e-02,  6.4697e-03,\n",
      "           1.0256e-01, -6.1465e-03, -2.3760e-01, -3.6106e-02,  1.0103e-01,\n",
      "           1.6887e-01, -1.5908e-01,  1.2824e-01,  6.2379e-02,  2.4357e-01,\n",
      "           9.8120e-02, -4.9031e-02,  8.1380e-02, -5.5816e-02,  9.1867e-02,\n",
      "           1.3595e-01, -5.3989e-02, -1.7656e-02, -7.1889e-02, -2.0756e-01,\n",
      "           1.2028e-01,  1.4930e-02, -1.3142e-01,  1.9412e-01, -2.4879e-01,\n",
      "           1.0874e-01,  1.1033e-01, -1.3730e-01,  1.5492e-01, -7.9699e-02,\n",
      "          -1.9025e-01,  1.0672e-01,  8.8161e-02,  1.2497e-01,  1.3975e-01,\n",
      "          -4.9674e-03, -1.7031e-02, -1.3699e-01, -2.8321e-02,  1.9094e-01,\n",
      "          -1.3001e-01, -3.7262e-01,  5.0066e-02, -1.4673e-02,  1.4789e-01,\n",
      "          -9.8409e-02,  1.0591e-01, -1.5557e-05, -4.5882e-02, -1.9632e-01,\n",
      "           3.2037e-01, -8.0824e-02,  6.5240e-02,  1.6181e-01,  2.0149e-01,\n",
      "          -1.1835e-01,  5.0354e-02, -2.8962e-01,  2.0688e-03, -8.5873e-02,\n",
      "           3.5076e-02, -5.3271e-02,  5.9451e-02, -2.2926e-01, -1.0868e-02,\n",
      "           1.1556e-03,  4.4323e-02,  1.4123e-02,  2.4209e-02, -3.8050e-02,\n",
      "           1.2042e-01, -1.7475e-01,  2.5463e-01,  2.2379e-01,  1.2270e-01,\n",
      "          -1.0819e-01, -1.6426e-01,  1.7893e-02,  1.9202e-02, -1.8513e-01,\n",
      "          -2.0555e-01, -9.2069e-03, -8.8658e-02, -8.5287e-02,  3.2226e-02,\n",
      "           2.5534e-01,  8.9351e-02, -3.8979e-02, -2.0814e-01,  8.0617e-03,\n",
      "          -2.7351e-01,  5.0249e-02,  8.9387e-04, -1.3016e-01, -1.2088e-01,\n",
      "          -7.1906e-04, -7.5097e-02, -1.1250e-01, -6.7395e-02,  4.5289e-02,\n",
      "          -1.8400e-02, -4.5711e-02, -1.4572e-01, -8.6470e-04, -5.8564e-02,\n",
      "           1.2082e-01, -1.9771e-01,  8.1512e-02,  1.1394e-01,  9.6652e-02,\n",
      "           1.5997e-01,  3.2388e-01,  1.1203e-01, -1.4425e-01, -2.1635e-01,\n",
      "          -1.6852e-01,  1.9079e-02, -2.0047e-02,  8.7217e-02, -2.2295e-02,\n",
      "           1.2349e-01, -1.0026e-01,  7.9769e-03, -4.4684e-02, -9.0099e-02,\n",
      "          -6.6182e-02,  9.7677e-03, -3.9135e-02, -2.0275e-01,  1.4972e-01,\n",
      "           1.4683e-01, -1.4030e-01,  1.1153e-01, -1.5663e-01,  1.7725e-02,\n",
      "           2.0691e-01, -1.4595e-01, -1.8870e-01,  3.1990e-01, -2.2913e-01,\n",
      "          -6.2696e-02, -1.4897e-01,  2.6411e-02, -8.8078e-02, -1.5162e-01,\n",
      "          -1.0765e-02, -4.6933e-02,  1.1937e-01,  1.3676e-01, -2.1964e-02,\n",
      "          -2.2510e-01,  2.0218e-01,  1.3361e-01,  1.3198e-01, -1.4326e-01,\n",
      "           2.6315e-02, -2.4495e-01,  1.3168e-01, -1.8171e-01, -1.4820e-01,\n",
      "           8.7537e-02,  1.7080e-01,  1.7552e-02,  7.5021e-03, -2.8990e-01,\n",
      "          -1.3386e-01,  1.0953e-01, -7.8298e-02,  6.3926e-02, -5.3090e-02,\n",
      "          -5.0887e-02, -1.3222e-01, -6.8812e-02,  3.9312e-02, -5.7993e-03,\n",
      "          -1.1201e-01,  2.0724e-01, -1.4234e-01,  1.0034e-01, -2.3541e-02,\n",
      "          -2.0371e-01,  7.3827e-02,  1.5290e-01,  1.0759e-01, -1.0548e-01,\n",
      "           6.3321e-02, -3.7509e-01, -1.8627e-01,  1.2607e-01, -2.5247e-01,\n",
      "           1.1780e-01,  8.1076e-02,  3.0395e-01, -6.9866e-02,  7.7366e-02,\n",
      "           1.5104e-01, -1.6721e-01,  1.7169e-02,  8.4055e-02, -2.7515e-01,\n",
      "           1.1915e-01,  3.5251e-02, -6.4814e-02, -9.8478e-02,  8.2079e-02,\n",
      "           2.5095e-02,  3.6545e-02, -1.0525e-01,  2.4935e-01,  2.1025e-02,\n",
      "          -3.6420e-02, -7.9652e-04, -1.7972e-01,  7.3449e-02,  8.3881e-02,\n",
      "           5.2456e-02,  2.4843e-04,  9.1767e-02, -3.8899e-02,  5.6044e-02,\n",
      "           5.5200e-02, -3.0762e-01, -1.6270e-01,  2.4077e-02, -3.0150e-02,\n",
      "           2.7546e-01,  2.1297e-01, -2.4428e-02, -1.9877e-01, -1.0043e-02,\n",
      "          -1.7385e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0872,  0.4001, -0.9647, -0.6808,  0.3753, -0.2019,  1.4644,\n",
      "          -0.0837, -3.5830,  0.9068,  0.4278, -0.6292,  2.6017, -0.6303,\n",
      "          -0.5413, -0.1580,  0.8513,  0.0000,  0.4552,  0.4363, -0.6332,\n",
      "          -0.3823,  1.6394,  1.5111,  0.7530, -0.0760, -0.1882, -0.7601,\n",
      "           1.6532,  0.8612,  1.2313,  1.2191, -1.0341, -0.0831, -1.5340,\n",
      "           1.3955,  0.2806, -3.7437,  0.1976,  1.5997,  0.0000, -1.3976,\n",
      "          -0.2690,  0.0000, -1.5232,  0.6679,  0.5403,  0.3713, -1.3401,\n",
      "           0.1446, -0.6293,  0.0000,  0.0000, -1.0284, -0.0249,  0.2043,\n",
      "          -0.8811, -1.2508, -0.2374, -0.4263,  1.0987,  1.4067, -0.2023,\n",
      "          -0.5007, -2.9620,  0.5517,  1.2777,  0.0000,  0.4096,  0.5268,\n",
      "          -1.2664, -0.0295,  0.7072, -3.6392,  0.3248,  0.0000, -0.1601,\n",
      "           0.0000, -0.0573, -0.1176, -1.3994,  2.1297, -0.9240,  1.0058,\n",
      "          -0.2074,  0.4364,  1.6611,  0.0000, -0.1045,  0.0000, -2.2719,\n",
      "           1.0994, -0.6223, -1.1358,  0.4670, -1.1699,  0.0325,  0.6288,\n",
      "           0.0000, -0.7781,  2.6966, -1.4613,  1.0758,  1.4525, -0.6660,\n",
      "           0.0000,  1.2106,  0.1275,  0.0000,  0.0000, -0.2480,  0.0000,\n",
      "          -1.0470,  1.3099, -1.6520, -2.9875, -0.0570, -0.4992,  0.0000,\n",
      "           0.0000, -1.4645,  0.7019, -1.4601, -0.7254, -0.9574, -1.3070,\n",
      "           0.8953,  0.1694,  1.2842, -0.7509, -0.8242,  0.5310, -1.5824,\n",
      "           0.9838,  0.2763, -0.5890,  0.6582,  0.5757, -1.1591, -1.0091,\n",
      "           0.0000,  0.6777, -0.7890, -0.1005, -1.6843, -0.1000, -0.5427,\n",
      "          -0.8443, -0.7546,  0.1777,  1.9975, -0.1991, -1.9293,  0.0000,\n",
      "           0.4411, -0.1944, -0.0651,  0.0000,  0.0388,  0.5373, -0.0265,\n",
      "           2.2059,  0.4810, -0.5506, -0.5254, -0.8911,  0.2815,  0.0826,\n",
      "          -0.3582, -0.4777,  0.7358, -0.0305,  0.0201, -1.0028,  1.2773,\n",
      "          -1.0976, -0.9855, -2.0749,  1.9679,  0.0864, -0.0311,  0.0350,\n",
      "           0.6705,  0.9799, -0.7480, -0.3411, -2.7811, -0.7828,  1.2088,\n",
      "           1.0126,  3.0719,  0.4937, -0.1443,  0.0000,  0.5597,  2.1638,\n",
      "          -1.1873,  0.5350,  0.0000, -0.9459, -1.6624, -1.0153,  1.2423,\n",
      "          -0.1222,  0.2321, -0.5746, -2.2915,  0.6818, -1.0728, -0.4711,\n",
      "           2.8670, -0.5731, -0.3414,  0.7926,  0.0322, -0.6832, -1.0168,\n",
      "           0.9669, -0.2450,  2.1682, -1.0827, -0.4268, -1.8430, -0.5000,\n",
      "           0.3396,  0.0000, -0.6966, -0.6281,  0.2922, -1.5772, -1.1078,\n",
      "           1.5811, -0.6137,  1.3103, -2.9787,  4.0330,  0.5850,  0.0427,\n",
      "          -1.5782,  0.0000,  0.7421, -3.2460, -0.3034, -0.8515,  0.0113,\n",
      "           0.2757,  0.2747,  0.2522,  0.2615,  0.3869, -0.3659, -0.1597,\n",
      "          -0.5534,  0.0000, -1.1460, -1.1312]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0597, 0.0550, 0.0743, 0.0580, 0.1658, 0.2230, 0.0943, 0.0941, 0.0569,\n",
      "         0.1189]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2633,  0.0030, -0.0860,  ...,  0.1509,  0.0313,  0.0530],\n",
      "        [ 0.2276, -0.0966, -0.5263,  ...,  0.0289, -0.0382,  0.1234],\n",
      "        [ 0.3629,  0.3139, -0.3310,  ...,  0.2262, -0.2929, -0.2319],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0982,  0.0703, -0.1993, -0.0256, -0.0172,  0.0844, -0.0034,\n",
      "          -0.1728,  0.0619, -0.0468,  0.0561,  0.0142, -0.0330,  0.0192,\n",
      "           0.0107,  0.0122,  0.0724,  0.0496, -0.1122,  0.0311, -0.0014,\n",
      "          -0.0360,  0.0949,  0.0116,  0.0456,  0.0295,  0.0466, -0.1107,\n",
      "          -0.0055,  0.0498,  0.1479, -0.0813,  0.0759, -0.0618,  0.0874,\n",
      "           0.0530, -0.1180,  0.0562, -0.1156, -0.0344, -0.0482,  0.0028,\n",
      "          -0.0791, -0.0350, -0.0407,  0.0298,  0.0046, -0.0642,  0.1108,\n",
      "           0.0728, -0.1092,  0.0314, -0.1099, -0.0423, -0.0929,  0.0184,\n",
      "           0.0056,  0.0965,  0.1072,  0.0471, -0.0030, -0.0776, -0.1131,\n",
      "          -0.0469,  0.0225,  0.0549, -0.1155,  0.1196, -0.0539,  0.0773,\n",
      "          -0.0420,  0.0602,  0.0136, -0.0030, -0.1154,  0.0465,  0.0715,\n",
      "           0.0866,  0.0285,  0.1115, -0.0655, -0.0314, -0.0894, -0.0339,\n",
      "          -0.0902,  0.0420, -0.0655,  0.0659, -0.0061, -0.0552,  0.0624,\n",
      "          -0.0199,  0.0161,  0.0684, -0.0467,  0.0463,  0.0063,  0.1234,\n",
      "          -0.0175,  0.0826, -0.0329,  0.0993, -0.0094,  0.1065, -0.1449,\n",
      "          -0.1642,  0.0013,  0.1407, -0.1335, -0.0987,  0.1278,  0.1500,\n",
      "           0.0453, -0.1628,  0.0311, -0.0691,  0.0268, -0.0271, -0.0902,\n",
      "           0.0548, -0.0355, -0.0788, -0.0460,  0.0218, -0.0461,  0.0094,\n",
      "           0.0798, -0.0009,  0.0568, -0.0024,  0.0281, -0.0809,  0.1087,\n",
      "           0.0438, -0.0900,  0.0645,  0.1746, -0.0814, -0.1267, -0.0412,\n",
      "          -0.0713,  0.1109,  0.0161,  0.0751,  0.1287, -0.0565, -0.0453,\n",
      "           0.0488,  0.0407, -0.0262, -0.1799,  0.0363, -0.0492,  0.0619,\n",
      "           0.0240,  0.1353,  0.0018,  0.0543, -0.0173, -0.0946, -0.0193,\n",
      "          -0.0595, -0.1316,  0.1766, -0.0573, -0.0815,  0.0243, -0.0455,\n",
      "          -0.0135,  0.0153, -0.0878,  0.0060,  0.0717,  0.0349, -0.0291,\n",
      "          -0.1105,  0.0907,  0.0551,  0.1890, -0.1433,  0.0297, -0.0904,\n",
      "          -0.0122,  0.0069,  0.0444, -0.0017, -0.0419,  0.0332,  0.0217,\n",
      "          -0.1087,  0.0090,  0.0443, -0.1109, -0.0637, -0.0478, -0.0574,\n",
      "          -0.0360,  0.0406,  0.0139,  0.0808, -0.0674,  0.1360, -0.0974,\n",
      "           0.1373,  0.0037, -0.0043, -0.0248,  0.2294, -0.0912, -0.1030,\n",
      "          -0.0048, -0.2300, -0.0896,  0.0851,  0.0027,  0.0020,  0.0542,\n",
      "           0.1036, -0.1122,  0.0047,  0.0856, -0.0599,  0.0563, -0.0979,\n",
      "           0.0655, -0.0155,  0.1357, -0.0465, -0.1817,  0.1566, -0.1008,\n",
      "          -0.0658,  0.0758, -0.0352, -0.0248,  0.0216,  0.0117,  0.0021,\n",
      "           0.0859,  0.1443,  0.1054, -0.0069,  0.0053, -0.0592, -0.0814,\n",
      "           0.0272, -0.1554, -0.0328,  0.0445,  0.0135,  0.1293,  0.0815,\n",
      "          -0.1072, -0.0219, -0.0133, -0.0239]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4729, -0.4586, -1.2335, -0.1185,  0.4614,  0.0259,  0.6620,\n",
      "           0.5340,  0.6709,  0.9340,  1.7077, -1.0162,  0.9458, -0.2516,\n",
      "          -1.6339,  0.5123,  1.8775, -0.7566, -1.5631, -2.6432, -1.1334,\n",
      "           0.1684,  2.9293,  0.5544, -0.1172,  3.2090,  1.8371,  0.5186,\n",
      "          -2.2264, -1.2858,  0.0290,  1.0132,  0.3250,  0.8597, -0.7986,\n",
      "          -1.4655,  0.6198, -0.7714,  1.9913,  0.1017,  0.4672, -2.2043,\n",
      "          -0.5664, -0.1150, -0.7130, -0.6890,  1.9275,  0.1099, -0.2869,\n",
      "          -1.8505,  1.4678,  0.4623,  0.6673, -0.2830,  0.5317,  0.2749,\n",
      "          -1.2426,  0.0000,  0.0000, -0.0119,  0.0000, -1.8188, -1.4011,\n",
      "          -0.8063,  1.1799,  0.2653, -0.1671, -0.2547, -0.0046, -0.4607,\n",
      "          -0.3251, -0.3240,  0.1474, -0.1262,  0.6585, -0.8061,  2.0663,\n",
      "           1.6792,  0.0878, -0.5456,  1.2268,  0.0863,  0.3266, -1.8363,\n",
      "          -0.0712, -1.7319, -1.4585, -0.8913,  0.6229,  0.0000, -1.2238,\n",
      "          -1.1442,  1.9848,  0.0000,  0.0000,  0.1565,  0.0000, -0.4057,\n",
      "          -0.3040, -1.8393, -1.2906, -0.7212, -0.7664,  0.0000,  0.3818,\n",
      "           1.1139, -1.0705,  2.2522, -0.2629, -0.2883, -0.0532,  0.6105,\n",
      "          -0.2544, -0.2804, -1.9418,  1.1285,  1.0063, -2.4969, -0.5751,\n",
      "           0.0297, -1.6947, -0.4011,  0.0000, -0.0782,  0.0000, -1.1108,\n",
      "           1.3042,  0.1696,  0.3223,  1.3582,  2.0789,  0.0000,  0.0000,\n",
      "          -0.7230,  0.4292,  0.0000,  0.3265, -2.1013, -0.4969, -1.6774,\n",
      "          -0.6416,  0.2344, -1.1866, -1.2146, -0.6309, -0.0404,  0.0000,\n",
      "           1.7382,  1.5948,  1.4319, -1.2626, -0.5774, -0.4800, -0.0394,\n",
      "           0.3266, -0.1170,  1.3537, -0.0318, -1.9003, -1.8063, -1.4265,\n",
      "          -0.9000, -0.7059, -0.3892, -0.9808, -0.1289,  0.4065,  0.9700,\n",
      "           0.5178, -0.1474,  1.5132, -0.3729, -0.3158, -2.0085,  0.1295,\n",
      "          -0.3526, -0.8300, -0.7688, -0.0403, -0.9374,  0.7276,  1.0418,\n",
      "           0.0469,  0.4631,  0.3160, -0.1183, -0.5409, -0.6644,  0.7547,\n",
      "          -1.0641, -0.5869, -1.7883,  1.2675, -0.9262, -1.6147, -0.3333,\n",
      "          -1.1569, -1.9606, -0.0718, -0.3749,  2.6972, -0.9215, -2.6313,\n",
      "          -0.5862, -0.7158, -1.3861, -1.2537,  0.1719,  0.2189, -1.1107,\n",
      "           0.9448, -0.6922, -1.5193,  0.3622,  0.2378, -1.4262, -2.3445,\n",
      "           0.0000, -1.4795,  0.0000,  0.0132, -0.9015,  0.3010, -1.1653,\n",
      "          -1.3008, -0.1877,  1.2721,  1.2663,  0.0000, -0.0560,  1.7375,\n",
      "          -1.1752,  0.9562,  0.0000,  0.5274,  0.7887, -0.6787,  0.1044,\n",
      "          -0.6803, -2.2618,  0.1673, -0.3133,  0.0000, -0.3820, -1.0799,\n",
      "           0.5577,  1.4993,  0.0000, -1.3768,  1.2434,  0.5827,  1.7527,\n",
      "           1.9516,  0.3627,  0.0000,  0.3900]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0359, 0.2103, 0.1262, 0.0537, 0.1349, 0.1111, 0.0318, 0.1519, 0.0790,\n",
      "         0.0651]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2633,  0.0030, -0.0860,  ...,  0.1509,  0.0313,  0.0530],\n",
      "        [ 0.2276, -0.0966, -0.5263,  ...,  0.0289, -0.0382,  0.1234],\n",
      "        [ 0.3629,  0.3139, -0.3310,  ...,  0.2262, -0.2929, -0.2319],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3878e-01,  6.1531e-02, -2.7268e-01, -7.6056e-02,  3.2830e-02,\n",
      "           1.8081e-01, -1.7651e-02, -2.1496e-01,  7.3591e-02, -9.6051e-02,\n",
      "           4.1621e-02,  1.0519e-01,  6.3188e-03,  2.3581e-03,  9.3176e-03,\n",
      "           5.5490e-02,  1.4801e-01,  4.3186e-02, -9.8499e-02,  5.8694e-02,\n",
      "           8.4285e-04, -1.9328e-02,  1.3694e-01,  5.7788e-03,  1.3606e-01,\n",
      "           9.9257e-03,  1.0860e-01, -9.0859e-02, -3.1470e-02,  4.8958e-02,\n",
      "           2.1788e-01, -9.6787e-02,  1.6655e-01, -4.7303e-02,  1.5657e-01,\n",
      "           1.3142e-02, -1.3915e-01,  1.3745e-01, -1.4742e-01, -4.3543e-02,\n",
      "          -3.0493e-02,  9.7153e-03, -3.5025e-02, -5.3784e-02, -1.0402e-01,\n",
      "          -4.1203e-02,  3.7746e-02, -1.2380e-02,  1.6490e-01,  1.0239e-01,\n",
      "          -1.3298e-01,  7.2890e-02, -1.3660e-01, -5.6926e-02, -1.0494e-01,\n",
      "           8.8560e-02,  3.5481e-02,  1.1084e-01,  1.6990e-01,  4.2559e-02,\n",
      "          -1.3141e-02, -8.0203e-02, -1.2071e-01, -1.2726e-01,  9.8482e-03,\n",
      "           1.1303e-01, -1.6072e-01,  1.1212e-01, -3.5544e-02,  3.8602e-02,\n",
      "          -1.0792e-01,  6.1607e-02, -4.2821e-03, -7.5879e-02, -1.5076e-01,\n",
      "           1.5746e-01,  6.6476e-02,  1.3679e-01,  4.8155e-02,  6.3129e-02,\n",
      "          -9.9943e-02,  1.8695e-02, -6.9052e-02, -5.2500e-02, -1.2436e-01,\n",
      "           4.2939e-02, -1.0397e-01,  6.0654e-02, -6.6197e-02, -7.9317e-02,\n",
      "           5.3994e-02, -8.3417e-03,  2.7912e-02,  7.3355e-02, -5.3294e-02,\n",
      "           5.6461e-02, -3.4080e-02,  1.2612e-01, -1.8451e-02,  4.6751e-02,\n",
      "          -3.4952e-03,  1.6062e-01, -5.7355e-02,  1.0534e-01, -2.5164e-01,\n",
      "          -2.1767e-01, -8.4812e-02,  1.7067e-01, -1.9792e-01, -1.3948e-01,\n",
      "           1.7483e-01,  1.8822e-01,  4.7581e-02, -2.1691e-01,  1.3144e-01,\n",
      "          -1.1878e-01,  6.8344e-02, -1.4902e-02, -1.4156e-01,  1.3543e-01,\n",
      "          -2.3580e-02, -4.1067e-02, -2.1160e-02,  2.9326e-02, -1.0903e-02,\n",
      "          -4.4377e-02,  9.0056e-02,  3.2859e-02, -1.2085e-02, -3.4718e-02,\n",
      "          -4.3374e-02, -1.1116e-01,  1.1828e-01,  1.5869e-02, -1.5207e-01,\n",
      "           1.4578e-01,  2.4303e-01, -1.1251e-01, -2.0838e-01, -5.9022e-02,\n",
      "          -4.4632e-02,  1.1355e-01,  4.0515e-02,  9.6053e-02,  1.3626e-01,\n",
      "          -6.6256e-02, -8.5806e-02,  2.6099e-04,  2.6499e-02, -1.3135e-01,\n",
      "          -1.6074e-01,  2.5033e-02, -1.0467e-01, -9.0886e-03,  1.6271e-02,\n",
      "           1.2049e-01,  6.5041e-02,  8.8161e-02, -1.4818e-02, -1.0446e-01,\n",
      "          -3.7918e-02, -4.8151e-02, -1.2291e-01,  1.8634e-01, -1.1252e-01,\n",
      "          -1.5508e-01, -1.8361e-02,  1.1543e-02, -5.7270e-02,  6.4981e-03,\n",
      "          -1.3990e-01, -1.8093e-02,  4.7857e-02,  1.1055e-01, -8.4846e-02,\n",
      "          -1.2418e-01,  1.6784e-01,  7.2681e-02,  2.7817e-01, -1.9272e-01,\n",
      "           1.1093e-01, -1.6087e-01,  1.7709e-02, -8.1338e-03,  4.8737e-03,\n",
      "          -1.7837e-02,  4.1440e-02, -6.4239e-03,  2.8909e-03, -1.3602e-01,\n",
      "           3.7026e-03,  7.2865e-02, -9.3004e-02, -7.5492e-02, -1.0146e-01,\n",
      "           2.1492e-02, -8.7539e-02,  3.7075e-02,  2.2169e-02,  9.2884e-02,\n",
      "          -1.0643e-01,  1.8576e-01, -1.0089e-01,  1.8212e-01, -5.8199e-02,\n",
      "           1.3237e-02,  1.6530e-03,  2.5477e-01, -9.7278e-02, -1.1973e-01,\n",
      "          -2.6291e-02, -3.0393e-01, -1.3733e-01,  1.1542e-01, -4.5708e-03,\n",
      "          -4.0173e-02,  1.0960e-01,  1.3855e-01, -1.1482e-01,  8.8265e-03,\n",
      "           1.0997e-01, -4.9730e-02,  5.7750e-02, -6.9722e-02,  7.9324e-02,\n",
      "          -5.3337e-02,  1.6857e-01, -1.7460e-02, -2.1138e-01,  2.0876e-01,\n",
      "          -1.8717e-01, -1.1342e-01,  1.2550e-01,  4.0112e-02, -1.5668e-02,\n",
      "           4.7281e-02,  7.8300e-02, -4.0315e-03,  8.5117e-02,  1.9359e-01,\n",
      "           1.7805e-01,  4.3314e-02,  8.3833e-02, -9.2818e-02, -1.0197e-01,\n",
      "           7.0133e-02, -2.3223e-01, -1.3284e-02,  3.6990e-02,  4.7465e-02,\n",
      "           2.0555e-01,  1.0720e-01, -8.2557e-02, -1.8825e-03, -3.5636e-02,\n",
      "          -1.6085e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9604e-02, -1.8078e+00,  0.0000e+00,  5.1614e-01,\n",
      "          -3.7613e-01,  1.0997e-03, -7.2278e-01,  2.1178e+00,  0.0000e+00,\n",
      "           2.8208e-01,  8.3062e-01, -1.1106e+00,  1.9971e-01,  3.1270e-01,\n",
      "           3.5187e-01, -6.8280e-01,  1.6933e-01,  8.7454e-01,  5.4579e-01,\n",
      "           1.8834e+00,  6.0197e-01, -3.6995e-02, -5.3541e-01, -1.0046e-01,\n",
      "           6.5103e-01, -1.6089e+00, -1.3622e+00,  0.0000e+00, -1.0345e+00,\n",
      "           3.8846e-02, -1.4546e+00, -2.0765e+00,  3.1550e-01, -2.8522e-01,\n",
      "          -2.0017e+00,  2.1906e-01,  9.9691e-01,  6.0151e-01,  9.5349e-01,\n",
      "          -2.2516e-01, -2.2112e+00, -7.0605e-01,  0.0000e+00,  8.9642e-02,\n",
      "          -1.1383e+00,  2.4245e-01,  7.4214e-01, -7.0949e-01, -1.3359e+00,\n",
      "           0.0000e+00,  0.0000e+00,  6.6255e-01,  0.0000e+00,  5.6733e-01,\n",
      "           3.3304e-01, -4.4958e-01,  0.0000e+00,  1.3381e-01,  0.0000e+00,\n",
      "          -7.0464e-01,  5.6349e-01, -6.9336e-01, -1.5470e+00,  2.8929e-01,\n",
      "           9.5737e-02, -1.7755e-01,  5.9499e-01, -2.1387e+00,  5.5969e-01,\n",
      "           1.8248e-01,  0.0000e+00, -3.4091e-01, -1.1321e+00, -6.4740e-01,\n",
      "           4.6113e-01, -1.0491e+00,  1.1888e-01,  5.1717e-01, -1.8631e-01,\n",
      "          -3.8505e-01,  2.1578e+00,  7.7741e-01, -8.4540e-01,  3.9785e-01,\n",
      "           4.1921e-01,  1.6047e+00, -5.6404e-01, -1.4129e+00, -1.4905e+00,\n",
      "           4.0443e-01, -3.5146e-01,  4.9397e-01, -2.3210e+00,  1.2379e+00,\n",
      "          -9.6287e-01,  1.3203e+00, -9.0734e-01,  2.3908e+00,  9.5500e-01,\n",
      "          -1.2008e+00,  5.9442e-01,  1.0664e+00,  0.0000e+00,  3.6525e-01,\n",
      "           4.0241e-01, -1.2704e+00,  4.5472e-01,  1.9688e+00,  1.4970e-01,\n",
      "          -8.3260e-01,  5.3413e-01,  8.0843e-01,  6.6386e-01, -1.0554e+00,\n",
      "           9.1775e-01, -7.0308e-01, -8.4509e-01,  2.5773e-01,  8.7974e-01,\n",
      "          -8.7716e-01, -1.3961e+00, -3.6486e-01, -1.8464e+00, -1.3005e+00,\n",
      "           1.0694e+00, -8.1171e-01,  6.4928e-01,  2.5562e-01, -1.4896e+00,\n",
      "           2.5020e+00,  3.7786e-01, -1.3453e+00,  7.2215e-01,  3.2009e+00,\n",
      "          -7.5267e-01, -3.8366e-01,  1.2823e+00,  2.2520e+00,  1.9420e-01,\n",
      "          -3.9003e-02,  3.0300e+00,  3.6285e-01, -1.8718e-01, -1.1120e+00,\n",
      "           0.0000e+00,  7.7535e-01, -7.7474e-01, -4.4789e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6521e-01, -2.8965e-01,  0.0000e+00,  0.0000e+00,\n",
      "           7.8592e-01,  0.0000e+00, -1.3047e+00,  1.9037e-01, -3.6288e+00,\n",
      "          -1.8687e+00,  1.1504e+00, -8.5971e-01,  9.5954e-01, -1.4611e+00,\n",
      "          -2.7092e-02,  1.9743e+00,  1.1269e+00,  0.0000e+00, -1.2413e+00,\n",
      "          -2.1245e-01, -1.3225e+00, -1.6391e+00, -7.7177e-01,  6.8274e-01,\n",
      "          -1.3797e+00, -1.2604e-01,  6.0641e-01, -7.4900e-01,  2.5914e-01,\n",
      "           1.3326e+00, -2.5533e+00,  2.7792e-01, -5.8360e-01,  1.6234e+00,\n",
      "          -1.2404e+00,  0.0000e+00,  0.0000e+00,  9.0078e-01,  0.0000e+00,\n",
      "          -4.1985e-01,  3.8843e-01,  0.0000e+00,  8.0970e-01,  1.0504e+00,\n",
      "          -7.8928e-01, -1.4390e+00, -4.1533e-01, -7.5020e-01, -4.5420e-01,\n",
      "          -5.4748e-01,  7.2236e-01, -1.8531e+00,  1.3574e+00,  8.3788e-01,\n",
      "          -1.5240e+00, -3.5866e-01,  6.4769e-01,  2.0050e-01, -2.1783e+00,\n",
      "           8.3532e-01, -1.2911e+00, -1.2838e+00,  2.6111e-01, -1.5635e+00,\n",
      "           2.0757e+00,  1.3418e-01,  2.5769e+00, -3.0832e-02, -5.7953e-01,\n",
      "          -1.4281e+00,  1.9010e+00, -3.8086e-01,  1.4695e+00,  8.0535e-01,\n",
      "           3.6927e-01,  6.6972e-01, -7.0028e-01,  8.8927e-02,  1.0254e+00,\n",
      "           9.7851e-01,  0.0000e+00,  6.5955e-01, -1.1450e+00, -1.6455e+00,\n",
      "          -6.0037e-01,  0.0000e+00,  0.0000e+00,  3.7047e-01, -2.2392e-01,\n",
      "          -7.5242e-01,  5.7224e-01,  5.3061e-01, -6.6373e-01,  1.5464e+00,\n",
      "           5.7814e-01,  1.8919e+00, -8.6391e-01,  4.9356e-01,  0.0000e+00,\n",
      "           4.9996e-01, -9.7497e-01,  1.7727e+00, -1.0636e+00, -8.0774e-01,\n",
      "          -6.2202e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0652, 0.1091, 0.1110, 0.1489, 0.0946, 0.1514, 0.0680, 0.0524, 0.0515,\n",
      "         0.1480]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2633,  0.0030, -0.0860,  ...,  0.1509,  0.0313,  0.0530],\n",
      "        [ 0.2276, -0.0966, -0.5263,  ...,  0.0289, -0.0382,  0.1234],\n",
      "        [ 0.3629,  0.3139, -0.3310,  ...,  0.2262, -0.2929, -0.2319],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1185,  0.0499, -0.2286, -0.0729,  0.0267,  0.1580, -0.0388,\n",
      "          -0.1992,  0.0583, -0.0715,  0.0326,  0.0935, -0.0205,  0.0417,\n",
      "          -0.0047,  0.0412,  0.0807,  0.0824, -0.1234,  0.0396,  0.0076,\n",
      "          -0.0321,  0.1345, -0.0112,  0.1279,  0.0644,  0.1351, -0.1191,\n",
      "          -0.0101,  0.0875,  0.2216, -0.0675,  0.1424, -0.0726,  0.1124,\n",
      "           0.0267, -0.1470,  0.1269, -0.1201, -0.0227, -0.0462,  0.0404,\n",
      "          -0.0590, -0.0678, -0.1276,  0.0154,  0.0321, -0.0308,  0.1523,\n",
      "           0.0979, -0.1409,  0.0573, -0.1183, -0.0550, -0.1189,  0.0454,\n",
      "           0.0252,  0.1165,  0.1466,  0.0285,  0.0125, -0.1156, -0.1374,\n",
      "          -0.0604, -0.0062,  0.0892, -0.1629,  0.1389, -0.0649,  0.0742,\n",
      "          -0.0607,  0.0702,  0.0228, -0.0512, -0.1102,  0.1322,  0.0834,\n",
      "           0.0987,  0.0669,  0.1214, -0.0579,  0.0665, -0.0719, -0.0186,\n",
      "          -0.1218,  0.0281, -0.0636,  0.0920, -0.0270, -0.0509,  0.0636,\n",
      "          -0.0299,  0.0174,  0.0640, -0.0454,  0.0826, -0.0219,  0.1089,\n",
      "           0.0124,  0.0429,  0.0252,  0.1846, -0.0636,  0.1035, -0.1482,\n",
      "          -0.2214, -0.0457,  0.1953, -0.2010, -0.1406,  0.1487,  0.2215,\n",
      "           0.0383, -0.1738,  0.0938, -0.0728,  0.0533, -0.0199, -0.1560,\n",
      "           0.1174, -0.0594, -0.0583, -0.0230,  0.0361, -0.0614, -0.0067,\n",
      "           0.0923,  0.0164,  0.0175, -0.0111,  0.0116, -0.0666,  0.0945,\n",
      "           0.0436, -0.1011,  0.0704,  0.1769, -0.0871, -0.1766, -0.0482,\n",
      "          -0.0964,  0.1206,  0.0122,  0.0610,  0.1427, -0.0656, -0.0646,\n",
      "           0.0360,  0.0603, -0.0864, -0.2034,  0.0552, -0.0870,  0.0343,\n",
      "           0.0353,  0.1611,  0.0349,  0.0704, -0.0498, -0.0867, -0.0217,\n",
      "          -0.0354, -0.1352,  0.2048, -0.1208, -0.1459, -0.0106, -0.0189,\n",
      "          -0.0991, -0.0825, -0.1361, -0.0039,  0.0570,  0.1147, -0.0361,\n",
      "          -0.1397,  0.1519,  0.0490,  0.2174, -0.2113,  0.0766, -0.1235,\n",
      "          -0.0064, -0.0149,  0.0439,  0.0039,  0.0622, -0.0169, -0.0396,\n",
      "          -0.1487,  0.0253,  0.0281, -0.0824, -0.0771, -0.1277, -0.0300,\n",
      "          -0.0449,  0.0466,  0.0194,  0.0702, -0.0757,  0.1663, -0.1340,\n",
      "           0.1379, -0.0435, -0.0134, -0.0154,  0.2585, -0.0976, -0.1497,\n",
      "          -0.0540, -0.2780, -0.1490,  0.1120,  0.0159, -0.0678,  0.1485,\n",
      "           0.1245, -0.1295, -0.0499,  0.0850, -0.0322,  0.0526, -0.0738,\n",
      "           0.0464, -0.0386,  0.1409, -0.0403, -0.2340,  0.1852, -0.0779,\n",
      "          -0.1181,  0.0871,  0.0366, -0.0095,  0.0511,  0.0422,  0.0135,\n",
      "           0.1107,  0.1930,  0.1596,  0.0324,  0.0707, -0.0541, -0.1165,\n",
      "           0.0389, -0.2047, -0.0268,  0.0074, -0.0381,  0.1759,  0.1189,\n",
      "          -0.0989, -0.0219, -0.0086, -0.0380]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.8116, -1.5251, -0.0641,  3.1034,  0.3410,  0.6573, -2.4771,\n",
      "           0.0314, -1.1458, -0.3492, -0.5560,  0.5501,  0.6333, -0.2521,\n",
      "           0.6377,  0.3409,  0.0000, -0.6023,  0.0000,  0.9290, -0.1758,\n",
      "           0.3038, -0.2806,  0.4112,  1.7210,  0.4407,  0.8445, -1.7673,\n",
      "          -2.3431,  1.7924, -1.4638,  1.6922, -0.3875, -0.1059, -0.0961,\n",
      "           0.0000, -1.0658,  1.3130,  0.6995, -0.6168,  0.3626,  0.8395,\n",
      "          -1.6957,  2.6163,  0.7770,  1.7333, -0.8485, -1.7385,  1.7531,\n",
      "          -0.5163, -1.6925,  0.8042,  1.1032,  1.3144, -0.0298, -1.5817,\n",
      "           0.3820,  0.0000, -0.9081,  0.9056,  0.0000,  0.8298,  0.0000,\n",
      "           1.2211, -1.7786,  0.0615, -0.3007, -0.2088,  0.0080,  1.1048,\n",
      "          -0.5939,  0.0349, -1.3456, -0.5902,  0.7398,  0.9373,  0.0236,\n",
      "          -2.4286, -0.6730, -2.0145, -0.2704, -0.7112,  0.0585,  0.1271,\n",
      "           0.0000, -0.9061,  0.3481,  1.2987, -0.0960,  0.3746, -1.7918,\n",
      "          -2.6733,  0.5870,  0.7757,  1.6876,  1.6583, -3.3326, -0.0100,\n",
      "           1.1583, -0.6507,  0.8214,  0.0000,  2.4443,  0.0000,  1.0153,\n",
      "           1.5563, -1.4521,  0.7431, -1.1456,  0.5656, -1.5227,  2.4473,\n",
      "          -0.2221,  1.1430,  0.2414,  0.0000,  0.0000,  0.7833, -0.5863,\n",
      "           0.1585, -1.4917,  1.5629,  0.0000,  0.0000, -1.8083, -0.4454,\n",
      "           2.3879,  0.0162,  1.1458, -0.8307,  1.5634,  0.6958, -0.3970,\n",
      "           0.1026,  0.1566, -0.1204, -0.4631,  1.0691, -0.5009, -1.0821,\n",
      "          -0.9634,  1.1383, -0.4437, -0.6930, -0.5123, -0.9693,  1.8985,\n",
      "           0.1667, -0.2781, -1.2036,  0.0000,  0.0000, -0.9005,  0.7583,\n",
      "           0.4029,  0.6488, -0.4378,  1.1371,  0.9374, -1.7980,  0.6179,\n",
      "          -1.2909,  0.0000, -1.4018,  0.6755, -0.0326, -0.2552,  0.6879,\n",
      "           0.0000, -1.2037,  0.0000, -0.3255,  1.1282,  0.3836, -1.0071,\n",
      "          -0.3763,  1.5025,  0.5942,  0.7149, -1.7175, -0.8101,  0.0000,\n",
      "           0.7901,  1.1623,  0.6668,  0.2896,  0.3354, -1.0895, -1.2162,\n",
      "          -0.4394,  0.2605,  0.0000, -0.0305, -0.1908,  0.2808, -1.1422,\n",
      "           1.2348, -1.5505, -0.9765,  1.9273, -2.2696,  1.8839, -1.2349,\n",
      "          -0.9173,  0.9326, -0.3641, -1.5162,  0.8079,  0.9455,  0.5486,\n",
      "           0.2822,  0.8096, -0.8654, -0.7111, -0.8306,  0.5920,  0.7996,\n",
      "           2.0351,  0.7736,  0.3345, -1.6120,  0.8017, -0.5341, -0.2580,\n",
      "           0.0000,  2.1466, -0.9352,  0.1404,  1.0891, -0.5057, -2.1987,\n",
      "          -0.3620, -0.6731, -2.5297, -0.8903,  0.6450,  0.2250, -0.1352,\n",
      "           0.1319, -0.1352, -1.8620,  0.0000,  0.0000,  1.1409, -0.0090,\n",
      "          -0.5979,  0.0000,  0.0257,  0.0000, -0.5120,  0.0000, -0.8869,\n",
      "          -0.6100,  0.2898,  0.7639,  0.9523]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0720, 0.1033, 0.1073, 0.0554, 0.1299, 0.1330, 0.0710, 0.1061, 0.0885,\n",
      "         0.1335]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2633,  0.0030, -0.0860,  ...,  0.1509,  0.0313,  0.0530],\n",
      "        [ 0.2276, -0.0966, -0.5263,  ...,  0.0289, -0.0382,  0.1234],\n",
      "        [ 0.3629,  0.3139, -0.3310,  ...,  0.2262, -0.2929, -0.2319],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.1611e-01,  6.4358e-02, -2.1045e-01, -3.4043e-02,  6.6107e-03,\n",
      "           1.3461e-01, -1.3355e-02, -1.7467e-01,  6.3587e-02, -4.5451e-02,\n",
      "           3.6429e-02,  6.3265e-02, -7.8881e-03,  1.4701e-02,  1.8824e-03,\n",
      "           4.0946e-02,  9.9200e-02,  5.1923e-02, -9.0240e-02,  4.7962e-02,\n",
      "           1.2790e-03, -1.5868e-02,  1.1538e-01,  9.0183e-03,  8.6727e-02,\n",
      "           2.6817e-02,  7.5901e-02, -1.0215e-01, -9.0214e-03,  5.8182e-02,\n",
      "           1.7898e-01, -7.3247e-02,  1.0687e-01, -4.5742e-02,  1.0777e-01,\n",
      "           2.9252e-02, -1.1143e-01,  1.0422e-01, -1.1053e-01, -3.9162e-02,\n",
      "          -4.8264e-02,  9.1574e-03, -5.1259e-02, -4.4126e-02, -7.2085e-02,\n",
      "           4.1787e-04,  2.0587e-02, -3.1448e-02,  1.2856e-01,  8.9107e-02,\n",
      "          -1.2330e-01,  5.6851e-02, -1.1157e-01, -4.6115e-02, -8.9194e-02,\n",
      "           5.2521e-02,  2.1875e-02,  1.1269e-01,  1.2197e-01,  3.6857e-02,\n",
      "           1.4015e-05, -7.6070e-02, -1.0642e-01, -8.5011e-02,  1.5955e-02,\n",
      "           7.5324e-02, -1.3543e-01,  1.0978e-01, -4.7718e-02,  5.2088e-02,\n",
      "          -7.4074e-02,  4.9320e-02,  1.7618e-02, -3.5515e-02, -1.1938e-01,\n",
      "           8.4554e-02,  6.5103e-02,  9.3379e-02,  4.5851e-02,  9.4605e-02,\n",
      "          -7.2266e-02, -1.6473e-03, -6.4361e-02, -3.8876e-02, -1.0652e-01,\n",
      "           3.3535e-02, -8.3664e-02,  6.6689e-02, -3.0033e-02, -6.1336e-02,\n",
      "           5.3226e-02, -2.0114e-02,  3.2544e-02,  7.1558e-02, -4.5096e-02,\n",
      "           4.8171e-02, -1.9974e-02,  1.2035e-01, -1.7363e-02,  5.2136e-02,\n",
      "          -1.0849e-02,  1.2785e-01, -4.3305e-02,  9.9665e-02, -1.8662e-01,\n",
      "          -1.8627e-01, -4.6586e-02,  1.4460e-01, -1.6072e-01, -1.2382e-01,\n",
      "           1.4596e-01,  1.6731e-01,  4.5609e-02, -1.7496e-01,  7.4546e-02,\n",
      "          -8.3042e-02,  4.3060e-02, -2.0205e-02, -1.0582e-01,  9.7074e-02,\n",
      "          -3.8674e-02, -5.9565e-02, -1.4921e-02,  2.0508e-02, -2.0212e-02,\n",
      "          -6.7145e-03,  8.0960e-02,  1.6070e-02,  1.6593e-02, -5.6152e-03,\n",
      "           1.0219e-02, -7.6796e-02,  1.0425e-01,  2.5253e-02, -1.0362e-01,\n",
      "           8.4830e-02,  1.8494e-01, -9.7316e-02, -1.5386e-01, -4.3857e-02,\n",
      "          -5.7002e-02,  1.0345e-01,  2.7749e-02,  7.5798e-02,  1.2960e-01,\n",
      "          -5.1788e-02, -6.7667e-02,  1.4231e-02,  3.8336e-02, -7.6455e-02,\n",
      "          -1.5789e-01,  3.1952e-02, -5.9247e-02,  3.0873e-02,  1.7274e-02,\n",
      "           1.2865e-01,  2.7569e-02,  5.5236e-02, -2.5436e-02, -9.1360e-02,\n",
      "          -2.2283e-02, -5.4401e-02, -1.1312e-01,  1.6902e-01, -7.5103e-02,\n",
      "          -1.1202e-01,  6.0481e-03, -1.4191e-02, -4.8717e-02, -1.0274e-02,\n",
      "          -1.0132e-01, -3.0001e-03,  5.1008e-02,  6.6246e-02, -4.7201e-02,\n",
      "          -1.0344e-01,  1.2784e-01,  5.2062e-02,  2.0165e-01, -1.6550e-01,\n",
      "           8.2241e-02, -1.1524e-01,  9.9059e-03, -5.1135e-05,  1.4786e-02,\n",
      "           2.9275e-03,  7.2824e-03,  4.8934e-03,  8.5816e-03, -1.2001e-01,\n",
      "           1.1156e-02,  4.7366e-02, -9.4899e-02, -6.5075e-02, -7.5742e-02,\n",
      "          -1.9417e-02, -5.3663e-02,  3.1553e-02,  1.7576e-02,  7.2173e-02,\n",
      "          -8.4160e-02,  1.4677e-01, -1.0867e-01,  1.5101e-01, -1.6406e-02,\n",
      "           6.4274e-03, -6.9853e-03,  2.3099e-01, -8.0152e-02, -1.0811e-01,\n",
      "          -7.2680e-03, -2.5048e-01, -1.2080e-01,  9.4398e-02,  3.0385e-03,\n",
      "          -2.9946e-02,  9.0319e-02,  1.1419e-01, -1.1202e-01, -8.8561e-03,\n",
      "           7.9672e-02, -5.1936e-02,  5.3393e-02, -8.6288e-02,  5.4924e-02,\n",
      "          -2.8545e-02,  1.4092e-01, -2.8072e-02, -1.8855e-01,  1.7080e-01,\n",
      "          -1.1364e-01, -7.9335e-02,  1.0271e-01,  1.3379e-02, -9.8159e-03,\n",
      "           4.6255e-02,  4.5290e-02,  3.4245e-03,  8.5145e-02,  1.5230e-01,\n",
      "           1.4395e-01,  2.8250e-02,  4.3978e-02, -7.3381e-02, -9.1155e-02,\n",
      "           4.8199e-02, -1.8296e-01, -1.5484e-02,  3.7873e-02,  2.0823e-02,\n",
      "           1.4458e-01,  8.4035e-02, -1.0193e-01, -3.2947e-03, -2.4497e-02,\n",
      "          -2.3076e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7278e-01, -4.3054e-01,  3.1485e-01, -1.0845e+00, -1.1723e+00,\n",
      "           7.4186e-01,  0.0000e+00,  1.3513e+00,  1.9046e-01,  6.1739e-01,\n",
      "           1.9027e+00,  0.0000e+00,  0.0000e+00, -9.1599e-01, -3.1818e+00,\n",
      "          -6.8498e-02, -1.6330e+00,  0.0000e+00,  1.3608e+00, -1.4347e+00,\n",
      "          -1.4071e-01, -5.2341e-01, -1.1194e+00, -2.5948e+00, -7.5620e-02,\n",
      "           1.3913e+00, -6.1930e-01,  1.9968e+00,  1.2765e-01,  5.5390e-01,\n",
      "           9.1479e-01, -3.5416e-03,  2.2297e-01,  2.0153e+00, -6.3827e-02,\n",
      "          -1.4085e+00,  0.0000e+00,  0.0000e+00,  3.1467e-01,  8.5344e-02,\n",
      "           8.6206e-01, -8.9984e-01,  1.0090e+00,  0.0000e+00,  1.9438e+00,\n",
      "          -3.0005e-01,  7.0468e-01, -6.0126e-01, -1.0205e+00,  1.1163e+00,\n",
      "          -1.3221e+00,  2.6765e+00,  0.0000e+00, -8.4654e-01,  2.2743e-01,\n",
      "          -3.0889e-01, -1.4341e+00, -9.6713e-02,  1.2748e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6135e-02,  0.0000e+00,  2.6586e-01, -6.2769e-02,\n",
      "           3.9414e-01,  5.7805e-01,  1.1649e+00,  1.5805e+00, -1.4151e+00,\n",
      "           4.2760e-01,  2.9651e-01, -3.1344e-02, -7.9764e-01,  0.0000e+00,\n",
      "           1.3923e-01,  5.2562e-01,  1.3985e+00,  1.0269e+00,  0.0000e+00,\n",
      "           7.5753e-01, -1.0057e+00,  7.5716e-01,  1.0587e+00, -1.2143e+00,\n",
      "          -1.1304e-01, -1.1074e+00,  5.4875e-01, -9.4469e-01, -1.9014e+00,\n",
      "           5.2901e-01,  9.8653e-01,  1.7014e+00,  9.4329e-01,  6.0813e-01,\n",
      "          -1.5961e-02,  3.5302e-01, -1.1755e+00,  1.3711e+00,  2.4477e+00,\n",
      "           2.4388e-01,  4.5780e-02, -4.6632e-01, -9.8937e-01,  1.6397e+00,\n",
      "          -1.0226e+00,  3.0284e+00,  6.1958e-01, -1.0209e-01, -1.2353e+00,\n",
      "           1.8983e-01, -5.0281e-01, -5.7019e-01,  7.1223e-01, -7.8037e-01,\n",
      "           6.3204e-01,  4.0412e-01,  2.2419e-01, -2.3271e+00,  2.9395e-02,\n",
      "          -8.1356e-01, -1.4104e+00, -1.8370e+00,  6.0333e-01, -9.5624e-01,\n",
      "          -2.0005e-01,  3.9188e-02,  0.0000e+00,  1.3962e+00, -2.0874e+00,\n",
      "          -9.2643e-01,  4.4955e-01, -1.1671e+00,  4.2512e-01, -4.6889e-01,\n",
      "          -7.4447e-01, -1.0649e+00, -9.7464e-01, -1.9515e-02,  2.3976e+00,\n",
      "           6.9852e-01,  0.0000e+00,  1.6916e+00, -1.4015e-01, -6.6927e-01,\n",
      "           3.4172e-02,  7.5927e-01,  4.2306e-01, -1.0330e+00, -9.5693e-02,\n",
      "           1.5601e+00,  5.8696e-01, -3.3894e-01,  6.5761e-01,  1.8406e+00,\n",
      "          -2.5245e-01, -2.1729e-01,  6.2339e-01, -2.3621e+00,  1.0554e+00,\n",
      "           3.0239e-01, -7.7529e-02,  1.5421e-01, -1.2115e+00, -2.1929e-02,\n",
      "           1.6818e+00,  1.8515e+00,  2.7050e-01, -1.2702e+00,  0.0000e+00,\n",
      "          -1.2243e+00, -1.0939e+00, -2.5900e+00,  5.0550e-01, -3.0581e+00,\n",
      "          -2.8705e-01,  4.9831e-01,  8.2938e-01,  3.1707e-01, -7.9276e-01,\n",
      "           2.7111e-01,  2.3395e+00,  1.0571e+00,  8.3815e-01, -4.0315e-01,\n",
      "           7.2696e-01,  5.9910e-01,  3.5931e-01,  8.4212e-01, -1.8297e+00,\n",
      "           1.3634e+00,  2.1588e+00,  0.0000e+00, -1.0151e+00, -1.1713e+00,\n",
      "           0.0000e+00,  1.6657e+00,  2.1524e+00,  3.6339e-01,  0.0000e+00,\n",
      "           3.2292e-02, -5.0150e-01, -1.2759e+00, -5.4236e-01, -4.0729e-01,\n",
      "          -1.4466e+00,  9.5378e-01, -8.5158e-01,  8.3076e-01, -1.5596e+00,\n",
      "           0.0000e+00,  6.7624e-01,  2.3970e+00,  5.4944e-02,  1.8940e+00,\n",
      "           0.0000e+00,  5.8083e-01, -2.3168e+00,  1.5503e+00, -2.2254e-01,\n",
      "          -2.2714e-01,  1.7330e+00,  2.7707e-01, -1.5519e+00,  9.2278e-01,\n",
      "          -1.2244e+00, -8.4794e-01, -1.8011e+00, -2.4262e-04,  3.7340e-01,\n",
      "           0.0000e+00, -1.2340e-01,  9.6623e-01, -1.7358e+00,  1.6938e+00,\n",
      "          -1.4404e+00,  6.3406e-01, -1.7217e+00,  0.0000e+00, -1.7152e+00,\n",
      "           1.5601e+00, -2.7187e-01, -2.5965e+00,  1.2383e+00, -1.2286e+00,\n",
      "           1.8838e+00, -5.0835e-01,  5.4286e-01, -2.6135e-01, -1.0216e+00,\n",
      "           1.3331e+00,  3.1018e-01, -5.1592e-02, -2.2886e-01, -1.6114e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0604, 0.1566, 0.1549, 0.0759, 0.1377, 0.1055, 0.1197, 0.0642, 0.0663,\n",
      "         0.0588]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2633,  0.0030, -0.0860,  ...,  0.1509,  0.0313,  0.0530],\n",
      "        [ 0.2276, -0.0966, -0.5263,  ...,  0.0289, -0.0382,  0.1234],\n",
      "        [ 0.3629,  0.3139, -0.3310,  ...,  0.2262, -0.2929, -0.2319],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4626e-01,  7.5870e-02, -2.6728e-01, -6.5668e-02,  2.3048e-02,\n",
      "           1.8449e-01, -1.6701e-02, -2.2418e-01,  8.3602e-02, -7.1585e-02,\n",
      "           4.2034e-02,  1.0599e-01,  3.6337e-03,  1.4117e-02, -4.4342e-03,\n",
      "           5.2226e-02,  1.3026e-01,  6.0798e-02, -1.0954e-01,  5.5181e-02,\n",
      "           3.5504e-03, -1.8920e-02,  1.4172e-01,  7.4554e-03,  1.3519e-01,\n",
      "           3.6397e-02,  1.1620e-01, -1.1052e-01, -2.0390e-02,  6.8480e-02,\n",
      "           2.3319e-01, -8.7137e-02,  1.5892e-01, -5.3544e-02,  1.4407e-01,\n",
      "           2.6456e-02, -1.5198e-01,  1.5135e-01, -1.4246e-01, -5.2920e-02,\n",
      "          -4.9216e-02,  1.3534e-02, -5.4695e-02, -6.1850e-02, -1.1241e-01,\n",
      "          -2.7431e-02,  3.2795e-02, -2.5670e-02,  1.6728e-01,  1.1728e-01,\n",
      "          -1.5610e-01,  7.2031e-02, -1.3464e-01, -5.4354e-02, -1.2305e-01,\n",
      "           7.4868e-02,  3.3142e-02,  1.3253e-01,  1.7096e-01,  4.2829e-02,\n",
      "          -1.3231e-03, -1.0280e-01, -1.3693e-01, -1.1919e-01,  5.5285e-03,\n",
      "           1.0625e-01, -1.7398e-01,  1.3092e-01, -4.8826e-02,  4.7664e-02,\n",
      "          -1.0786e-01,  5.8850e-02,  1.0159e-02, -6.2847e-02, -1.3779e-01,\n",
      "           1.3708e-01,  7.5496e-02,  1.2301e-01,  6.7476e-02,  9.6790e-02,\n",
      "          -8.4561e-02,  2.8200e-02, -6.5701e-02, -4.8140e-02, -1.4030e-01,\n",
      "           3.9803e-02, -9.9876e-02,  8.0933e-02, -4.9304e-02, -7.6839e-02,\n",
      "           6.3290e-02, -2.1793e-02,  3.5687e-02,  8.6425e-02, -6.0179e-02,\n",
      "           6.3030e-02, -3.2352e-02,  1.3681e-01, -2.4694e-02,  4.1699e-02,\n",
      "           9.5382e-03,  1.7061e-01, -6.5626e-02,  1.1868e-01, -2.3543e-01,\n",
      "          -2.3752e-01, -7.3845e-02,  1.8702e-01, -2.1141e-01, -1.6258e-01,\n",
      "           1.7825e-01,  2.1858e-01,  5.2857e-02, -2.1488e-01,  1.2099e-01,\n",
      "          -1.0006e-01,  6.4690e-02, -2.6654e-02, -1.5392e-01,  1.3538e-01,\n",
      "          -4.2092e-02, -6.0875e-02, -5.7590e-03,  2.3929e-02, -2.6358e-02,\n",
      "          -1.8921e-02,  9.7264e-02,  3.1129e-02,  5.8296e-03, -1.3634e-02,\n",
      "          -6.4349e-03, -9.3617e-02,  1.2130e-01,  1.8418e-02, -1.3566e-01,\n",
      "           1.2727e-01,  2.2332e-01, -1.2086e-01, -2.1275e-01, -5.9340e-02,\n",
      "          -7.3182e-02,  1.2000e-01,  3.9211e-02,  8.8835e-02,  1.5624e-01,\n",
      "          -7.1473e-02, -8.9514e-02,  1.7859e-02,  3.4882e-02, -1.2026e-01,\n",
      "          -1.8858e-01,  2.8944e-02, -9.1696e-02,  1.3148e-02,  2.0069e-02,\n",
      "           1.5224e-01,  5.0896e-02,  7.6060e-02, -2.4188e-02, -1.0983e-01,\n",
      "          -2.9877e-02, -4.8092e-02, -1.3121e-01,  2.0593e-01, -1.1156e-01,\n",
      "          -1.6276e-01, -5.1216e-03, -8.6025e-03, -6.8999e-02, -3.5163e-02,\n",
      "          -1.3966e-01, -1.4729e-02,  5.7012e-02,  1.0926e-01, -6.5508e-02,\n",
      "          -1.3657e-01,  1.6433e-01,  6.1946e-02,  2.6889e-01, -2.1142e-01,\n",
      "           1.1798e-01, -1.5022e-01,  1.4219e-02,  1.4483e-03,  1.4870e-02,\n",
      "          -4.3454e-03,  4.2054e-02, -5.4829e-03, -3.9538e-03, -1.5290e-01,\n",
      "           1.0910e-02,  4.9105e-02, -9.2471e-02, -8.7719e-02, -1.1238e-01,\n",
      "          -7.6283e-03, -7.6346e-02,  3.5068e-02,  2.7299e-02,  9.9581e-02,\n",
      "          -1.0463e-01,  1.8825e-01, -1.2629e-01,  1.8573e-01, -4.4327e-02,\n",
      "           8.9769e-03, -1.1289e-02,  2.7904e-01, -1.0783e-01, -1.3053e-01,\n",
      "          -2.2360e-02, -3.1315e-01, -1.5500e-01,  1.1935e-01,  9.9119e-03,\n",
      "          -5.6302e-02,  1.2841e-01,  1.3671e-01, -1.2829e-01, -1.6924e-02,\n",
      "           9.5234e-02, -4.9770e-02,  5.4783e-02, -8.6689e-02,  6.9534e-02,\n",
      "          -5.3269e-02,  1.7763e-01, -2.1948e-02, -2.3202e-01,  2.1490e-01,\n",
      "          -1.4393e-01, -1.1919e-01,  1.3112e-01,  3.7042e-02, -1.7657e-02,\n",
      "           5.5265e-02,  6.8778e-02,  5.6414e-03,  9.6331e-02,  2.0427e-01,\n",
      "           1.8578e-01,  4.8406e-02,  7.2577e-02, -9.0790e-02, -1.2617e-01,\n",
      "           6.7994e-02, -2.2900e-01, -1.8643e-02,  2.9037e-02,  2.4462e-02,\n",
      "           2.0077e-01,  1.1937e-01, -1.0859e-01,  7.1608e-05, -3.7201e-02,\n",
      "          -3.1940e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7171e-02,  4.0004e-01,  0.0000e+00, -6.8086e-01,  3.7535e-01,\n",
      "          -2.0188e-01,  1.4644e+00, -8.3648e-02, -3.5830e+00,  9.0675e-01,\n",
      "           0.0000e+00, -6.2916e-01,  2.6018e+00, -6.3026e-01, -5.4126e-01,\n",
      "          -1.5793e-01,  8.5131e-01,  1.0942e+00,  4.5524e-01,  4.3619e-01,\n",
      "           0.0000e+00, -3.8236e-01,  1.6395e+00,  1.5110e+00,  7.5311e-01,\n",
      "          -7.5982e-02, -1.8815e-01, -7.6008e-01,  1.6532e+00,  8.6121e-01,\n",
      "           1.2313e+00,  0.0000e+00, -1.0341e+00, -8.3049e-02, -1.5340e+00,\n",
      "           1.3954e+00,  2.8065e-01, -3.7437e+00,  1.9768e-01,  1.5998e+00,\n",
      "          -4.5908e-01, -1.3976e+00, -2.6897e-01, -1.7141e+00, -1.5232e+00,\n",
      "           6.6783e-01,  5.4036e-01,  3.7131e-01, -1.3401e+00,  1.4459e-01,\n",
      "          -6.2930e-01,  2.7503e+00,  6.0996e-01, -1.0284e+00, -2.4906e-02,\n",
      "           2.0418e-01, -8.8115e-01, -1.2509e+00, -2.3741e-01,  0.0000e+00,\n",
      "           1.0988e+00,  1.4069e+00, -2.0230e-01, -5.0074e-01, -2.9621e+00,\n",
      "           5.5163e-01,  1.2778e+00, -1.2873e+00,  4.0980e-01,  5.2678e-01,\n",
      "          -1.2664e+00, -2.9602e-02,  7.0723e-01, -3.6392e+00,  3.2496e-01,\n",
      "          -4.8152e-04, -1.6011e-01,  1.0611e+00, -5.7330e-02, -1.1775e-01,\n",
      "          -1.3995e+00,  2.1297e+00, -9.2403e-01,  1.0059e+00, -2.0744e-01,\n",
      "           4.3635e-01,  1.6611e+00, -9.7390e-01, -1.0445e-01, -5.8120e-01,\n",
      "          -2.2720e+00,  1.0995e+00, -6.2238e-01, -1.1358e+00,  4.6702e-01,\n",
      "          -1.1699e+00,  3.2676e-02,  6.2884e-01,  1.7190e+00, -7.7822e-01,\n",
      "           2.6966e+00, -1.4614e+00,  0.0000e+00,  1.4526e+00, -6.6597e-01,\n",
      "          -7.6207e-01,  0.0000e+00,  1.2741e-01,  0.0000e+00, -1.3982e-02,\n",
      "          -2.4800e-01,  1.3396e-01,  0.0000e+00,  1.3099e+00, -1.6521e+00,\n",
      "          -2.9875e+00, -5.6995e-02,  0.0000e+00, -1.9341e-01,  4.4571e-01,\n",
      "          -1.4646e+00,  7.0193e-01,  0.0000e+00,  0.0000e+00, -9.5749e-01,\n",
      "          -1.3072e+00,  8.9536e-01,  1.6943e-01,  1.2843e+00, -7.5090e-01,\n",
      "          -8.2423e-01,  5.3096e-01, -1.5824e+00,  9.8381e-01,  2.7625e-01,\n",
      "          -5.8897e-01,  6.5833e-01,  0.0000e+00, -1.1590e+00, -1.0091e+00,\n",
      "          -3.8789e-01,  0.0000e+00, -7.8913e-01,  0.0000e+00, -1.6843e+00,\n",
      "          -1.0005e-01, -5.4271e-01, -8.4422e-01, -7.5472e-01,  1.7768e-01,\n",
      "           0.0000e+00, -1.9912e-01, -1.9293e+00, -4.0632e-01,  4.4118e-01,\n",
      "          -1.9443e-01, -6.5040e-02, -1.3068e-01,  3.8876e-02,  5.3731e-01,\n",
      "          -2.6520e-02,  2.2059e+00,  4.8099e-01, -5.5055e-01, -5.2546e-01,\n",
      "          -8.9111e-01,  2.8152e-01,  8.2660e-02, -3.5811e-01, -4.7777e-01,\n",
      "           7.3586e-01, -3.0647e-02,  2.0125e-02, -1.0028e+00,  1.2774e+00,\n",
      "          -1.0976e+00, -9.8559e-01, -2.0750e+00,  1.9680e+00,  8.6369e-02,\n",
      "           0.0000e+00,  3.4999e-02,  6.7055e-01,  9.7991e-01, -7.4790e-01,\n",
      "          -3.4108e-01,  0.0000e+00, -7.8285e-01,  1.2088e+00,  1.0126e+00,\n",
      "           3.0720e+00,  4.9380e-01, -1.4437e-01, -5.9280e-01,  0.0000e+00,\n",
      "           2.1638e+00, -1.1873e+00,  0.0000e+00,  1.8107e+00, -9.4596e-01,\n",
      "          -1.6624e+00, -1.0153e+00,  1.2422e+00, -1.2224e-01,  2.3206e-01,\n",
      "          -5.7455e-01, -2.2916e+00,  6.8175e-01, -1.0729e+00, -4.7112e-01,\n",
      "           2.8670e+00, -5.7312e-01, -3.4130e-01,  7.9266e-01,  3.2028e-02,\n",
      "          -6.8319e-01, -1.0170e+00,  9.6683e-01, -2.4507e-01,  2.1683e+00,\n",
      "          -1.0826e+00, -4.2675e-01, -1.8431e+00, -5.0004e-01,  3.3953e-01,\n",
      "           7.0481e-01,  0.0000e+00, -6.2811e-01,  2.9225e-01, -1.5773e+00,\n",
      "          -1.1079e+00,  1.5811e+00, -6.1370e-01,  1.3102e+00, -2.9787e+00,\n",
      "           4.0331e+00,  5.8505e-01,  4.2840e-02, -1.5782e+00, -2.8581e-01,\n",
      "           7.4210e-01, -3.2460e+00, -3.0351e-01,  0.0000e+00,  1.1315e-02,\n",
      "           2.7565e-01,  2.7465e-01,  2.5220e-01,  2.6150e-01,  0.0000e+00,\n",
      "          -3.6587e-01, -1.5971e-01, -5.5341e-01, -5.1932e-02, -1.1460e+00,\n",
      "          -1.1312e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0408, 0.0520, 0.0984, 0.0773, 0.1176, 0.2402, 0.0713, 0.0882, 0.0641,\n",
      "         0.1500]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2861, -0.5116,  0.3510,  ...,  0.0031, -0.0202,  0.1263],\n",
      "        [-0.0351, -0.5498,  0.4856,  ..., -0.4026,  0.0038, -0.2242],\n",
      "        [-0.0147, -0.3882,  0.6640,  ...,  0.0285, -0.0507, -0.1775],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 4.0260e-02, -8.1786e-02,  4.7141e-02,  8.9503e-02, -7.8130e-03,\n",
      "           4.8403e-02, -7.8528e-02, -9.3826e-02, -1.2225e-02,  2.0174e-02,\n",
      "           8.4634e-02, -1.0822e-01,  3.0208e-02, -5.3154e-02,  7.5248e-02,\n",
      "          -4.8051e-02, -1.9528e-02,  1.0774e-01, -4.9458e-02, -4.8767e-03,\n",
      "          -7.2906e-02, -1.2511e-01,  1.8113e-02,  4.4397e-02,  3.2753e-02,\n",
      "           7.0381e-02, -6.0666e-02, -1.0528e-01, -6.0177e-02,  1.8529e-03,\n",
      "           2.9527e-02,  6.2440e-05,  5.3057e-03, -6.0820e-02, -1.3884e-01,\n",
      "           8.3518e-02,  1.0072e-02, -5.3589e-02, -1.6639e-02, -6.6427e-02,\n",
      "           6.4089e-02, -9.2954e-03, -1.5395e-01, -2.6380e-02, -3.2707e-02,\n",
      "           1.1159e-01, -5.5753e-02, -6.2551e-02, -2.4606e-02, -6.4232e-02,\n",
      "          -1.2754e-01, -5.9425e-02, -5.4000e-02, -1.4428e-03, -2.5528e-02,\n",
      "           3.8437e-02,  5.8927e-03,  1.8510e-02,  1.2787e-02,  1.0499e-01,\n",
      "           3.0455e-02, -5.0449e-02,  4.9389e-02,  6.5073e-02,  3.4317e-02,\n",
      "          -8.8851e-03, -5.0441e-02,  1.7316e-01, -4.1362e-03,  1.2479e-01,\n",
      "           1.1759e-02,  1.2789e-01, -4.6805e-02, -2.2327e-02, -1.0177e-01,\n",
      "           9.9260e-03,  8.8148e-02,  6.2777e-02,  1.0056e-01,  1.5181e-01,\n",
      "           2.8944e-02, -3.1958e-02, -1.0513e-01,  3.2517e-02,  7.9330e-02,\n",
      "           4.0563e-02,  1.3214e-01,  7.4345e-02, -2.4419e-02,  3.4807e-02,\n",
      "           4.7815e-02, -3.1344e-02, -7.7999e-02,  7.6102e-02, -1.2203e-01,\n",
      "           1.1230e-01, -1.2816e-02,  7.6700e-02,  6.4794e-02,  9.8572e-02,\n",
      "          -5.9606e-02,  2.7560e-02,  4.4824e-02, -6.5177e-02, -1.6166e-02,\n",
      "           6.2581e-02, -4.4203e-02,  6.8696e-02,  3.0728e-02,  1.1828e-01,\n",
      "           1.2041e-02,  5.4424e-02, -1.0699e-01, -2.9419e-02, -3.5832e-02,\n",
      "          -4.9105e-02, -2.4940e-02, -6.7139e-02,  4.2523e-02, -6.2613e-02,\n",
      "           1.1599e-02, -1.2765e-01, -1.1295e-01,  3.5632e-02, -1.3701e-01,\n",
      "          -3.1159e-02, -8.5837e-03, -2.7748e-02,  5.2580e-03,  6.3629e-02,\n",
      "           5.9235e-02,  2.3160e-02,  5.5295e-02,  7.4946e-02, -1.1885e-02,\n",
      "          -1.0879e-01,  1.4419e-01, -1.6278e-02, -7.1416e-02,  1.1107e-02,\n",
      "          -4.7951e-02, -4.6847e-04, -2.3795e-02, -8.7547e-02,  1.0468e-01,\n",
      "           1.6869e-02,  1.2371e-02,  2.7806e-02,  5.5335e-02, -4.0063e-02,\n",
      "          -1.6213e-01,  8.6566e-02,  3.8105e-02,  6.7234e-02,  6.3550e-02,\n",
      "           9.0156e-02, -7.2109e-02,  7.6516e-02, -5.9603e-02,  2.8887e-02,\n",
      "           1.0711e-02, -5.4088e-02, -7.2395e-02,  1.3353e-01, -7.9935e-02,\n",
      "           1.2385e-02,  6.3159e-03,  6.4659e-02,  3.6334e-02,  1.4895e-01,\n",
      "           1.7044e-02,  1.2784e-02,  9.0747e-02,  1.6680e-02,  1.8105e-03,\n",
      "           5.0078e-02,  1.0335e-01,  2.3147e-02,  7.7128e-02,  3.5630e-02,\n",
      "          -1.0695e-01, -2.9047e-02, -1.6733e-02, -5.8678e-02,  1.4122e-01,\n",
      "           2.9181e-02, -6.7765e-02,  3.5388e-02, -3.7307e-02, -1.4550e-02,\n",
      "           6.6837e-03, -5.7345e-02, -1.2586e-01, -3.8280e-03, -1.0088e-01,\n",
      "          -2.2954e-01,  4.7227e-03,  1.3457e-02, -1.1671e-01,  2.5285e-02,\n",
      "           8.3360e-02, -2.2109e-02, -9.0615e-02,  6.8727e-02, -1.2225e-01,\n",
      "          -1.4573e-01, -1.5804e-02,  1.9470e-01, -6.1266e-02, -6.6932e-02,\n",
      "          -1.3781e-02,  5.6729e-03,  1.8060e-02,  5.8298e-02,  7.0697e-03,\n",
      "           8.3652e-02, -3.7076e-03,  2.9343e-02,  3.4832e-02,  5.6761e-03,\n",
      "          -4.8194e-02,  3.1881e-02,  4.4194e-02,  8.9728e-02,  8.1243e-02,\n",
      "           7.6757e-02, -2.2434e-02, -7.5183e-02, -1.9034e-01,  9.2833e-02,\n",
      "          -1.1500e-01,  5.0152e-02, -1.3646e-02,  3.5595e-02,  5.7755e-02,\n",
      "          -9.7449e-02,  9.6686e-03, -9.0941e-02,  2.4685e-02,  1.1307e-01,\n",
      "           1.9196e-02, -1.0883e-01, -9.3676e-02,  1.9237e-02, -5.6952e-02,\n",
      "           8.9166e-03,  6.7136e-03,  6.5765e-04,  8.4182e-02, -1.1100e-01,\n",
      "          -3.3608e-02,  1.1156e-01, -1.0530e-01, -5.8671e-02,  4.0438e-02,\n",
      "          -4.0571e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4731, -0.4586, -1.2335, -0.1183,  0.4615,  0.0258,  0.6620,\n",
      "           0.5340,  0.6709,  0.9339,  1.7078, -1.0163,  0.0000, -0.2517,\n",
      "          -1.6339,  0.5124,  1.8775, -0.7566, -1.5631,  0.0000, -1.1334,\n",
      "           0.1683,  2.9293,  0.5544,  0.0000,  3.2091,  1.8371,  0.5187,\n",
      "          -2.2264, -1.2858,  0.0291,  1.0133,  0.3249,  0.8598, -0.7985,\n",
      "           0.0000,  0.6197, -0.7713,  1.9914,  0.1018,  0.4674,  0.0000,\n",
      "          -0.5665, -0.1150, -0.7130, -0.6890,  1.9276,  0.0000, -0.2869,\n",
      "          -1.8505,  1.4678,  0.4623,  0.6673, -0.2831,  0.0000,  0.2748,\n",
      "          -1.2425, -0.9510,  1.8138, -0.0118,  0.0000, -1.8186, -1.4011,\n",
      "          -0.8063,  1.1799,  0.2653, -0.1670, -0.2548, -0.0046, -0.4608,\n",
      "          -0.3251, -0.3240,  0.1474, -0.1263,  0.6585, -0.8062,  2.0663,\n",
      "           1.6793,  0.0878, -0.5457,  1.2268,  0.0864,  0.3267, -1.8364,\n",
      "          -0.0713, -1.7319, -1.4585, -0.8912,  0.6230,  0.8108, -1.2238,\n",
      "          -1.1442,  1.9849, -0.3663, -0.7340,  0.1565,  2.1411, -0.4056,\n",
      "          -0.3040,  0.0000, -1.2906, -0.7213, -0.7664,  0.2370,  0.3819,\n",
      "           1.1139, -1.0704,  0.0000, -0.2628, -0.2882, -0.0532,  0.6105,\n",
      "          -0.2545, -0.2804, -1.9418,  1.1284,  1.0063, -2.4970, -0.5750,\n",
      "           0.0000, -1.6947, -0.4011, -0.3791, -0.0783,  0.0000, -1.1108,\n",
      "           1.3043,  0.1696,  0.3223,  0.0000,  2.0789, -2.6340,  0.3598,\n",
      "          -0.7230,  0.4292,  0.0601,  0.3266, -2.1014,  0.0000, -1.6774,\n",
      "          -0.6417,  0.2344, -1.1867, -1.2147, -0.6310, -0.0405,  0.4647,\n",
      "           0.0000,  0.0000,  1.4319,  0.0000, -0.5774, -0.4800, -0.0394,\n",
      "           0.3267, -0.1170,  1.3538, -0.0316, -1.9004, -1.8063,  0.0000,\n",
      "           0.0000, -0.7058, -0.3892, -0.9809, -0.1289,  0.4064,  0.9701,\n",
      "           0.5179, -0.1474,  1.5133, -0.3729, -0.3158, -2.0086,  0.1295,\n",
      "          -0.3525, -0.8300, -0.7688, -0.0403, -0.9374,  0.7277,  1.0419,\n",
      "           0.0469,  0.4632,  0.3161, -0.1182, -0.5411, -0.6644,  0.0000,\n",
      "          -1.0641, -0.5870, -1.7883,  0.0000, -0.9262, -1.6147,  0.0000,\n",
      "          -1.1570, -1.9606, -0.0719,  0.0000,  0.0000, -0.9215, -2.6313,\n",
      "           0.0000, -0.7159, -1.3861, -1.2536,  0.1719,  0.2189, -1.1108,\n",
      "           0.9449, -0.6921, -1.5193,  0.3621,  0.2377, -1.4263,  0.0000,\n",
      "           0.0476, -1.4796,  0.4271,  0.0132, -0.9015,  0.3010, -1.1652,\n",
      "          -1.3010, -0.1877,  1.2721,  0.0000, -2.1879,  0.0000,  0.0000,\n",
      "          -1.1752,  0.9562,  1.9992,  0.5273,  0.7889, -0.6787,  0.1045,\n",
      "          -0.6803, -2.2618,  0.1673,  0.0000, -1.0432, -0.3819, -1.0800,\n",
      "           0.5578,  1.4994, -0.5646, -1.3769,  1.2434,  0.5826,  1.7527,\n",
      "           1.9516,  0.3627,  0.4874,  0.3900]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0330, 0.2546, 0.1175, 0.0624, 0.0694, 0.1203, 0.0377, 0.1628, 0.0714,\n",
      "         0.0710]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2861, -0.5116,  0.3510,  ...,  0.0031, -0.0202,  0.1263],\n",
      "        [-0.0351, -0.5498,  0.4856,  ..., -0.4026,  0.0038, -0.2242],\n",
      "        [-0.0147, -0.3882,  0.6640,  ...,  0.0285, -0.0507, -0.1775],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5638e-02, -2.0335e-01,  1.8102e-01,  1.6067e-01,  6.1283e-02,\n",
      "           1.6312e-01, -6.6237e-02, -4.8558e-02, -2.2199e-02,  1.1698e-01,\n",
      "           9.2972e-02, -1.1429e-01,  1.1194e-01, -1.1333e-01,  1.0557e-01,\n",
      "          -3.0677e-02, -5.7515e-02,  1.5162e-01,  4.0350e-02, -4.4323e-02,\n",
      "          -1.5421e-01, -1.6392e-01,  2.4321e-02,  3.1157e-02,  9.2540e-02,\n",
      "           1.5736e-01, -8.9991e-02, -1.7639e-01, -4.3596e-02, -7.9879e-02,\n",
      "           8.4928e-03,  6.5687e-02, -3.2694e-02, -4.0078e-02, -2.0175e-01,\n",
      "           1.2428e-01,  6.4165e-02, -3.0185e-03,  8.6111e-02, -7.6651e-02,\n",
      "           1.9075e-01,  2.2308e-02, -2.0811e-01, -2.8180e-02, -8.2276e-02,\n",
      "           1.2808e-01, -6.3809e-02, -1.8510e-02, -1.3427e-01, -1.1320e-01,\n",
      "          -1.7774e-01, -1.3936e-01, -2.1916e-02, -1.1151e-02,  7.1324e-02,\n",
      "           6.8263e-02,  7.3827e-02, -1.9451e-02,  3.2179e-02,  1.7774e-01,\n",
      "           2.6891e-02, -1.2036e-01,  9.6489e-02,  7.9745e-02,  3.2879e-02,\n",
      "          -1.0091e-02, -8.2915e-03,  1.9181e-01,  6.1187e-02,  1.4293e-01,\n",
      "          -4.7625e-03,  1.6858e-01, -1.1251e-01, -5.7092e-02, -5.0363e-02,\n",
      "           4.4415e-02,  8.3081e-02,  9.5454e-02,  1.8254e-01,  1.5097e-01,\n",
      "           1.0794e-01,  4.3799e-02,  2.6440e-02,  1.6287e-02,  1.9348e-01,\n",
      "           7.5968e-02,  1.7586e-01,  1.0214e-01,  9.8854e-03,  1.7575e-02,\n",
      "          -2.9457e-02, -1.1977e-01, -1.3782e-01,  1.8919e-01, -2.3057e-01,\n",
      "           1.6178e-01, -6.0641e-02,  1.0912e-01,  1.0254e-01,  1.1590e-01,\n",
      "          -9.1656e-02,  5.4139e-02,  9.4726e-03, -1.6082e-01, -6.4796e-03,\n",
      "           1.4135e-01, -1.2704e-01, -2.5741e-02, -1.3506e-02,  9.9864e-02,\n",
      "           3.3486e-02,  8.6764e-02, -1.8331e-01, -9.7855e-03, -5.5698e-02,\n",
      "          -9.8247e-02,  3.0138e-04, -6.7341e-02,  7.3552e-02, -4.6480e-02,\n",
      "           3.7875e-02, -1.1118e-01, -4.7832e-02,  4.3401e-02, -1.8763e-01,\n",
      "          -5.4007e-02, -8.4547e-02, -5.6515e-02, -2.4227e-02,  1.1705e-01,\n",
      "           6.6181e-02,  1.4684e-01,  9.9812e-02,  9.2979e-02,  1.3044e-02,\n",
      "          -1.8953e-01,  1.4541e-01, -3.2278e-02, -7.7993e-02, -1.7534e-02,\n",
      "          -4.7488e-02, -1.4953e-01, -3.0658e-02, -1.7513e-01,  8.7057e-02,\n",
      "           5.2266e-02, -3.5243e-03, -9.6794e-03,  5.0265e-02, -1.6452e-01,\n",
      "          -8.8374e-02,  8.5990e-02,  8.4740e-02,  1.0272e-01,  9.7710e-02,\n",
      "           7.5275e-02, -1.0227e-01,  1.0570e-01, -7.5569e-02,  1.3604e-01,\n",
      "           1.0347e-01, -4.6903e-02,  1.7084e-02,  1.5143e-01, -1.1008e-01,\n",
      "           3.4338e-02,  3.8429e-02,  2.0031e-01,  6.6992e-02,  1.5488e-01,\n",
      "           8.3003e-02,  9.8392e-02,  8.7285e-02,  8.3184e-03, -2.8918e-03,\n",
      "           1.8677e-01,  1.4971e-01, -1.2828e-02,  2.7948e-02,  1.6271e-01,\n",
      "          -1.9315e-01, -5.7551e-02,  4.9165e-02, -6.8014e-02,  7.2507e-02,\n",
      "           7.6981e-02,  2.4657e-02, -4.6786e-02, -1.2700e-01,  5.9274e-02,\n",
      "           1.1843e-02, -5.7927e-02, -1.0850e-01, -6.8047e-02, -2.1343e-01,\n",
      "          -3.4252e-01, -4.6472e-02,  1.3867e-02, -1.9378e-01, -1.5992e-02,\n",
      "           1.7926e-01, -1.0115e-01, -4.2822e-02,  6.1213e-02, -1.9482e-01,\n",
      "          -1.7237e-01,  3.3911e-03,  2.4763e-01, -5.4765e-02, -3.9150e-02,\n",
      "           2.8877e-02,  8.2101e-02,  3.6745e-02,  1.4140e-01,  4.0749e-02,\n",
      "           5.2350e-02,  5.7122e-02, -4.5542e-02,  7.8887e-02,  6.5850e-02,\n",
      "          -8.9966e-02,  4.6085e-02, -5.8427e-03,  1.7474e-01,  7.5166e-02,\n",
      "           1.4157e-01, -1.2170e-01, -7.2867e-02, -1.9250e-01,  1.0101e-01,\n",
      "          -1.0633e-01,  1.3910e-01,  6.4384e-02,  1.0278e-01,  6.0296e-02,\n",
      "          -1.1389e-01,  2.4738e-02, -1.2309e-01, -2.9667e-02,  1.4215e-01,\n",
      "           4.8930e-02, -1.6620e-01, -1.1323e-01, -2.6829e-03, -6.1667e-02,\n",
      "           4.4359e-02,  1.2163e-02,  4.3300e-02,  1.4265e-01, -1.8968e-01,\n",
      "          -1.0446e-01,  2.0605e-01, -1.6941e-01, -1.2842e-01,  2.8601e-02,\n",
      "          -8.6252e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9631e-02,  0.0000e+00,  1.3220e+00,  0.0000e+00,\n",
      "          -3.7612e-01,  0.0000e+00, -7.2290e-01,  0.0000e+00, -2.1366e-01,\n",
      "           2.8210e-01,  0.0000e+00, -1.1106e+00,  1.9968e-01,  3.1265e-01,\n",
      "           0.0000e+00, -6.8282e-01,  0.0000e+00,  8.7459e-01,  5.4574e-01,\n",
      "           1.8834e+00,  6.0191e-01, -3.7004e-02, -5.3537e-01, -1.0048e-01,\n",
      "           6.5106e-01, -1.6090e+00, -1.3621e+00, -2.1266e+00, -1.0345e+00,\n",
      "           3.8777e-02, -1.4546e+00, -2.0765e+00,  3.1555e-01, -2.8514e-01,\n",
      "          -2.0018e+00,  2.1901e-01,  9.9692e-01,  6.0147e-01,  9.5345e-01,\n",
      "          -2.2513e-01, -2.2111e+00, -7.0606e-01,  1.3960e+00,  8.9651e-02,\n",
      "          -1.1384e+00,  2.4250e-01,  7.4211e-01, -7.0953e-01,  0.0000e+00,\n",
      "           1.6085e+00, -1.3740e-01,  0.0000e+00,  0.0000e+00,  5.6732e-01,\n",
      "           3.3293e-01, -4.4954e-01, -8.8800e-01,  0.0000e+00,  6.2828e-01,\n",
      "          -7.0465e-01,  5.6359e-01, -6.9327e-01, -1.5470e+00,  2.8935e-01,\n",
      "           9.5714e-02, -1.7752e-01,  5.9501e-01, -2.1386e+00,  5.5966e-01,\n",
      "           1.8252e-01, -5.1258e-01, -3.4093e-01, -1.1320e+00,  0.0000e+00,\n",
      "           4.6115e-01, -1.0491e+00,  1.1889e-01,  5.1714e-01,  0.0000e+00,\n",
      "          -3.8500e-01,  0.0000e+00,  7.7745e-01, -8.4539e-01,  3.9775e-01,\n",
      "           4.1916e-01,  0.0000e+00, -5.6413e-01, -1.4130e+00, -1.4906e+00,\n",
      "           0.0000e+00, -3.5140e-01,  4.9396e-01, -2.3210e+00,  1.2379e+00,\n",
      "          -9.6290e-01,  1.3204e+00, -9.0733e-01,  0.0000e+00,  9.5503e-01,\n",
      "           0.0000e+00,  5.9435e-01,  1.0664e+00, -1.7340e+00,  3.6528e-01,\n",
      "           4.0237e-01, -1.2704e+00,  0.0000e+00,  0.0000e+00,  1.4965e-01,\n",
      "           0.0000e+00,  5.3406e-01,  8.0846e-01,  6.6392e-01,  0.0000e+00,\n",
      "           9.1773e-01, -7.0311e-01, -8.4511e-01,  2.5777e-01,  8.7972e-01,\n",
      "          -8.7712e-01, -1.3962e+00, -3.6482e-01, -1.8463e+00, -1.3006e+00,\n",
      "           1.0694e+00, -8.1164e-01,  6.4931e-01,  2.5562e-01, -1.4897e+00,\n",
      "           2.5020e+00,  3.7786e-01, -1.3453e+00,  7.2217e-01,  3.2010e+00,\n",
      "          -7.5276e-01, -3.8364e-01,  1.2823e+00,  2.2520e+00,  1.9417e-01,\n",
      "          -3.9066e-02,  3.0300e+00,  3.6288e-01, -1.8712e-01, -1.1120e+00,\n",
      "           1.2471e+00,  7.7539e-01, -7.7473e-01,  0.0000e+00, -1.3868e+00,\n",
      "           2.3359e+00,  7.6521e-01, -2.8960e-01, -2.1306e+00, -5.8165e-01,\n",
      "           0.0000e+00, -1.8621e+00, -1.3047e+00,  1.9034e-01, -3.6288e+00,\n",
      "          -1.8687e+00,  1.1504e+00,  0.0000e+00,  9.5955e-01, -1.4611e+00,\n",
      "          -2.7098e-02,  1.9744e+00,  1.1270e+00, -4.8564e-01, -1.2413e+00,\n",
      "          -2.1248e-01, -1.3225e+00, -1.6391e+00, -7.7173e-01,  6.8269e-01,\n",
      "          -1.3798e+00, -1.2612e-01,  6.0638e-01, -7.4904e-01,  0.0000e+00,\n",
      "           1.3326e+00, -2.5534e+00,  2.7792e-01, -5.8357e-01,  1.6234e+00,\n",
      "          -1.2403e+00, -1.8416e-03, -5.0233e-02,  9.0081e-01,  5.6549e-01,\n",
      "          -4.1986e-01,  0.0000e+00, -1.1564e-01,  8.0974e-01,  1.0503e+00,\n",
      "          -7.8924e-01, -1.4389e+00, -4.1543e-01, -7.5025e-01, -4.5415e-01,\n",
      "          -5.4744e-01,  7.2243e-01, -1.8531e+00,  1.3574e+00,  0.0000e+00,\n",
      "          -1.5240e+00, -3.5866e-01,  6.4770e-01,  0.0000e+00, -2.1782e+00,\n",
      "           8.3539e-01, -1.2911e+00, -1.2838e+00,  2.6102e-01, -1.5635e+00,\n",
      "           2.0758e+00,  1.3412e-01,  2.5769e+00, -3.0886e-02, -5.7954e-01,\n",
      "          -1.4281e+00,  1.9010e+00, -3.8090e-01,  1.4696e+00,  8.0535e-01,\n",
      "           3.6922e-01,  6.6975e-01, -7.0029e-01,  8.8946e-02,  0.0000e+00,\n",
      "           9.7839e-01, -1.4083e+00,  6.5959e-01, -1.1450e+00, -1.6456e+00,\n",
      "          -6.0031e-01,  8.7629e-03, -7.1081e-01,  3.7047e-01, -2.2400e-01,\n",
      "          -7.5245e-01,  5.7222e-01,  5.3060e-01, -6.6369e-01,  0.0000e+00,\n",
      "           5.7824e-01,  1.8919e+00, -8.6392e-01,  4.9355e-01, -3.8714e-01,\n",
      "           5.0000e-01, -9.7498e-01,  1.7727e+00, -1.0635e+00, -8.0781e-01,\n",
      "          -6.2199e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0726, 0.1300, 0.1286, 0.1214, 0.1040, 0.1451, 0.0642, 0.0574, 0.0518,\n",
      "         0.1248]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2861, -0.5116,  0.3510,  ...,  0.0031, -0.0202,  0.1263],\n",
      "        [-0.0351, -0.5498,  0.4856,  ..., -0.4026,  0.0038, -0.2242],\n",
      "        [-0.0147, -0.3882,  0.6640,  ...,  0.0285, -0.0507, -0.1775],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.1555e-02, -1.6727e-01,  1.2904e-01,  1.3495e-01,  2.0806e-02,\n",
      "           1.0046e-01, -1.0576e-01, -8.7963e-02, -3.1234e-02,  5.6214e-02,\n",
      "           1.0397e-01, -1.3410e-01,  6.5023e-02, -7.4139e-02,  1.0484e-01,\n",
      "          -5.1480e-02, -4.5562e-02,  1.6145e-01, -3.5067e-02, -2.5684e-02,\n",
      "          -1.2808e-01, -1.7317e-01,  2.7725e-02,  5.0255e-02,  7.1287e-02,\n",
      "           1.3158e-01, -8.0400e-02, -1.5965e-01, -8.0131e-02, -2.3543e-02,\n",
      "           3.8083e-02,  4.3505e-02,  7.1705e-03, -7.4517e-02, -2.0990e-01,\n",
      "           1.1463e-01,  2.6092e-02, -5.0919e-02,  2.1552e-02, -8.2375e-02,\n",
      "           1.2586e-01,  5.3089e-03, -2.1365e-01, -5.0089e-02, -7.6356e-02,\n",
      "           1.5667e-01, -6.6378e-02, -5.1369e-02, -6.8263e-02, -9.5471e-02,\n",
      "          -1.8551e-01, -9.8011e-02, -5.9660e-02, -7.5206e-03, -6.9063e-03,\n",
      "           6.3710e-02,  3.8303e-02,  2.1288e-04,  2.5872e-02,  1.4204e-01,\n",
      "           3.8683e-02, -9.4387e-02,  9.0259e-02,  9.3193e-02,  3.2614e-02,\n",
      "          -1.0932e-02, -5.1552e-02,  2.3554e-01,  1.6806e-02,  1.6878e-01,\n",
      "           2.0320e-02,  1.7840e-01, -8.1354e-02, -4.9709e-02, -1.0093e-01,\n",
      "           3.8210e-02,  1.0712e-01,  7.4581e-02,  1.6857e-01,  1.8938e-01,\n",
      "           8.1671e-02,  1.4171e-02, -7.9691e-02,  5.2419e-02,  1.4845e-01,\n",
      "           5.3603e-02,  2.0025e-01,  1.1072e-01, -1.8741e-02,  5.2162e-02,\n",
      "           3.1292e-02, -8.5131e-02, -1.2442e-01,  1.2999e-01, -1.8958e-01,\n",
      "           1.7321e-01, -3.9925e-02,  9.9387e-02,  1.0689e-01,  1.2670e-01,\n",
      "          -7.9709e-02,  5.1011e-02,  3.8852e-02, -1.2742e-01, -5.0068e-04,\n",
      "           1.1476e-01, -9.7102e-02,  5.6921e-02,  2.1196e-02,  1.4797e-01,\n",
      "           9.0484e-03,  8.7118e-02, -1.6763e-01, -1.2920e-02, -4.1080e-02,\n",
      "          -7.3345e-02, -1.8056e-02, -7.7668e-02,  5.6721e-02, -7.0248e-02,\n",
      "           1.7647e-02, -1.5768e-01, -1.1452e-01,  5.4989e-02, -2.0144e-01,\n",
      "          -4.1705e-02, -3.9654e-02, -4.5123e-02, -1.2928e-02,  1.0151e-01,\n",
      "           7.9087e-02,  9.3762e-02,  6.8051e-02,  9.3780e-02,  1.4013e-03,\n",
      "          -1.8453e-01,  1.6661e-01, -2.3105e-02, -8.5494e-02,  4.9735e-03,\n",
      "          -6.6219e-02, -6.0923e-02, -3.0186e-02, -1.6134e-01,  1.2796e-01,\n",
      "           3.0282e-02,  1.4326e-02,  2.2171e-02,  8.2803e-02, -1.0263e-01,\n",
      "          -1.7673e-01,  1.1814e-01,  5.5802e-02,  9.5405e-02,  9.4301e-02,\n",
      "           1.1572e-01, -1.0113e-01,  1.0371e-01, -9.2353e-02,  9.4499e-02,\n",
      "           5.0060e-02, -6.7045e-02, -6.3016e-02,  1.6993e-01, -1.2478e-01,\n",
      "           1.6739e-02,  1.3521e-02,  1.3947e-01,  3.8861e-02,  1.7537e-01,\n",
      "           4.4235e-02,  4.8388e-02,  1.1133e-01,  3.1312e-02,  7.3329e-03,\n",
      "           1.1577e-01,  1.5407e-01,  1.6201e-02,  6.6601e-02,  8.1511e-02,\n",
      "          -1.7270e-01, -3.9716e-02,  5.5992e-03, -9.2730e-02,  1.5771e-01,\n",
      "           5.9397e-02, -3.3939e-02,  4.7602e-03, -9.7242e-02,  2.4810e-03,\n",
      "           1.7592e-02, -8.6429e-02, -1.4936e-01, -2.4423e-02, -1.8049e-01,\n",
      "          -3.3204e-01,  5.8701e-03,  1.6462e-02, -1.7886e-01,  1.0043e-02,\n",
      "           1.4389e-01, -6.1311e-02, -1.1114e-01,  7.5962e-02, -1.9398e-01,\n",
      "          -2.0545e-01, -1.6366e-02,  2.6534e-01, -7.0927e-02, -9.2255e-02,\n",
      "          -2.5792e-02,  5.0383e-02,  2.8171e-02,  1.0357e-01,  1.9711e-02,\n",
      "           8.3598e-02,  3.2782e-02,  1.2451e-02,  6.7198e-02,  9.9215e-03,\n",
      "          -7.7527e-02,  6.1307e-02,  2.7945e-02,  1.5904e-01,  1.0137e-01,\n",
      "           1.1912e-01, -8.1560e-02, -9.2356e-02, -2.5002e-01,  1.1282e-01,\n",
      "          -1.3401e-01,  9.5628e-02,  1.1988e-03,  9.3518e-02,  8.0884e-02,\n",
      "          -1.3056e-01,  2.1498e-02, -1.2404e-01,  1.1008e-02,  1.5046e-01,\n",
      "           3.0232e-02, -1.4272e-01, -1.2422e-01,  2.9395e-02, -8.2096e-02,\n",
      "           1.5399e-02,  1.3679e-02,  1.3329e-02,  1.2206e-01, -1.9330e-01,\n",
      "          -7.1586e-02,  1.7760e-01, -1.5027e-01, -1.0142e-01,  5.5586e-02,\n",
      "          -6.5966e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00,  4.0001e-01, -9.6476e-01, -6.8084e-01,  3.7535e-01,\n",
      "          -2.0189e-01,  1.4644e+00, -8.3683e-02,  0.0000e+00,  9.0676e-01,\n",
      "           4.2787e-01, -6.2917e-01,  2.6018e+00,  0.0000e+00, -5.4126e-01,\n",
      "          -1.5801e-01,  8.5129e-01,  1.0942e+00,  4.5519e-01,  4.3620e-01,\n",
      "          -6.3321e-01, -3.8239e-01,  1.6395e+00,  1.5110e+00,  7.5314e-01,\n",
      "          -7.5868e-02, -1.8816e-01, -7.6009e-01,  0.0000e+00,  8.6124e-01,\n",
      "           1.2314e+00,  1.2191e+00, -1.0341e+00, -8.3077e-02, -1.5340e+00,\n",
      "           1.3954e+00,  2.8064e-01, -3.7437e+00,  1.9759e-01,  1.5999e+00,\n",
      "          -4.5914e-01, -1.3977e+00, -2.6893e-01, -1.7142e+00,  0.0000e+00,\n",
      "           6.6778e-01,  5.4033e-01,  3.7123e-01, -1.3402e+00,  1.4457e-01,\n",
      "          -6.2932e-01,  2.7503e+00,  6.0993e-01, -1.0284e+00, -2.4913e-02,\n",
      "           2.0416e-01, -8.8117e-01, -1.2509e+00, -2.3738e-01, -4.2618e-01,\n",
      "           1.0988e+00,  1.4069e+00, -2.0236e-01, -5.0071e-01, -2.9621e+00,\n",
      "           5.5160e-01,  1.2778e+00, -1.2873e+00,  4.0985e-01,  5.2683e-01,\n",
      "          -1.2663e+00, -2.9545e-02,  7.0721e-01, -3.6393e+00,  3.2494e-01,\n",
      "          -5.2722e-04,  0.0000e+00,  1.0612e+00, -5.7372e-02, -1.1780e-01,\n",
      "          -1.3995e+00,  2.1298e+00, -9.2405e-01,  1.0058e+00, -2.0743e-01,\n",
      "           0.0000e+00,  1.6611e+00, -9.7390e-01, -1.0444e-01, -5.8114e-01,\n",
      "          -2.2721e+00,  1.0994e+00, -6.2241e-01, -1.1358e+00,  4.6697e-01,\n",
      "          -1.1699e+00,  3.2718e-02,  0.0000e+00,  1.7190e+00, -7.7828e-01,\n",
      "           2.6966e+00, -1.4614e+00,  1.0758e+00,  1.4527e+00, -6.6600e-01,\n",
      "          -7.6216e-01,  1.2106e+00,  1.2741e-01, -1.4727e+00, -1.3995e-02,\n",
      "          -2.4800e-01,  1.3392e-01, -1.0470e+00,  1.3099e+00, -1.6521e+00,\n",
      "          -2.9875e+00, -5.7021e-02, -4.9920e-01, -1.9344e-01,  4.4567e-01,\n",
      "          -1.4646e+00,  0.0000e+00, -1.4600e+00, -7.2544e-01, -9.5743e-01,\n",
      "          -1.3072e+00,  8.9541e-01,  1.6943e-01,  1.2843e+00,  0.0000e+00,\n",
      "          -8.2429e-01,  5.3092e-01, -1.5824e+00,  9.8378e-01,  2.7625e-01,\n",
      "          -5.8901e-01,  6.5833e-01,  5.7562e-01, -1.1590e+00, -1.0092e+00,\n",
      "          -3.8789e-01,  6.7773e-01, -7.8912e-01, -1.0050e-01, -1.6843e+00,\n",
      "          -1.0004e-01, -5.4276e-01, -8.4422e-01, -7.5476e-01,  1.7769e-01,\n",
      "           1.9975e+00,  0.0000e+00, -1.9293e+00, -4.0632e-01,  4.4105e-01,\n",
      "          -1.9436e-01, -6.5046e-02, -1.3065e-01,  3.8975e-02,  5.3730e-01,\n",
      "          -2.6583e-02,  2.2059e+00,  4.8100e-01, -5.5057e-01, -5.2556e-01,\n",
      "          -8.9112e-01,  2.8155e-01,  8.2715e-02, -3.5806e-01, -4.7777e-01,\n",
      "           7.3593e-01, -3.0655e-02,  2.0129e-02,  0.0000e+00,  1.2774e+00,\n",
      "           0.0000e+00, -9.8559e-01, -2.0750e+00,  1.9680e+00,  8.6389e-02,\n",
      "          -3.1130e-02,  3.4956e-02,  6.7059e-01,  9.7982e-01, -7.4787e-01,\n",
      "          -3.4104e-01, -2.7812e+00, -7.8285e-01,  1.2088e+00,  1.0126e+00,\n",
      "           3.0720e+00,  4.9385e-01, -1.4435e-01, -5.9285e-01,  5.5976e-01,\n",
      "           2.1639e+00, -1.1873e+00,  5.3499e-01,  1.8107e+00, -9.4598e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  1.2423e+00,  0.0000e+00,  2.3206e-01,\n",
      "          -5.7459e-01, -2.2916e+00,  6.8182e-01, -1.0729e+00, -4.7108e-01,\n",
      "           2.8670e+00,  0.0000e+00, -3.4131e-01,  7.9266e-01,  3.2002e-02,\n",
      "          -6.8326e-01, -1.0169e+00,  9.6678e-01, -2.4506e-01,  2.1683e+00,\n",
      "          -1.0826e+00, -4.2683e-01, -1.8431e+00, -5.0005e-01,  3.3945e-01,\n",
      "           7.0484e-01, -6.9658e-01, -6.2808e-01,  2.9220e-01, -1.5773e+00,\n",
      "          -1.1079e+00,  1.5811e+00, -6.1377e-01,  1.3102e+00, -2.9788e+00,\n",
      "           4.0332e+00,  5.8510e-01,  4.2836e-02, -1.5783e+00, -2.8591e-01,\n",
      "           7.4205e-01, -3.2461e+00, -3.0350e-01,  0.0000e+00,  1.1325e-02,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.8685e-01,\n",
      "          -3.6586e-01, -1.5960e-01,  0.0000e+00, -5.1907e-02, -1.1461e+00,\n",
      "          -1.1312e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0432, 0.0585, 0.0867, 0.0797, 0.1222, 0.2662, 0.0694, 0.0845, 0.0690,\n",
      "         0.1206]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2626,  0.0019, -0.0881,  ...,  0.1537,  0.0292,  0.0504],\n",
      "        [ 0.2273, -0.0985, -0.5289,  ...,  0.0331, -0.0405,  0.1179],\n",
      "        [ 0.1356, -0.4342,  0.2090,  ..., -0.1256,  0.2478,  0.3428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1159, -0.1846, -0.1066, -0.1780, -0.1101,  0.0047, -0.1669,\n",
      "          -0.0520, -0.0884, -0.0739,  0.0868, -0.0540,  0.0538,  0.2461,\n",
      "           0.1070,  0.0812, -0.1382, -0.0899, -0.2922, -0.0145,  0.0645,\n",
      "          -0.0909,  0.2435,  0.0363,  0.1245, -0.0404,  0.1081, -0.1508,\n",
      "          -0.1944,  0.1081,  0.3184, -0.2245,  0.0823, -0.2052,  0.1007,\n",
      "          -0.1019, -0.1424,  0.1101, -0.2260,  0.0786, -0.0688,  0.2106,\n",
      "          -0.1723, -0.1011, -0.1212,  0.1602,  0.0032, -0.1741,  0.0576,\n",
      "          -0.0145,  0.1032, -0.0767, -0.0659, -0.0060,  0.0361,  0.0801,\n",
      "          -0.1147,  0.1412,  0.1223, -0.0892,  0.0522, -0.1510, -0.2416,\n",
      "           0.0224,  0.0601,  0.0118, -0.1047,  0.0450, -0.2200,  0.2268,\n",
      "           0.0423,  0.3201, -0.0800,  0.0111, -0.1093,  0.2409, -0.0767,\n",
      "           0.1182, -0.1030,  0.0962, -0.0486,  0.1775, -0.0636,  0.0320,\n",
      "           0.0291,  0.1273,  0.0536, -0.0721,  0.0428,  0.0369, -0.1871,\n",
      "          -0.1347, -0.0259, -0.0928,  0.1835,  0.1679,  0.0235, -0.0590,\n",
      "           0.1301,  0.0552, -0.0146,  0.2222,  0.1561, -0.0510,  0.0932,\n",
      "          -0.2958,  0.1331,  0.2692, -0.2028,  0.0150, -0.1695,  0.0751,\n",
      "           0.0502, -0.1131,  0.0951, -0.0853, -0.1026, -0.0197,  0.0263,\n",
      "           0.1250, -0.0608, -0.0858, -0.0709,  0.0508, -0.1818,  0.0034,\n",
      "           0.0178,  0.0356,  0.1054, -0.1921, -0.1007, -0.1640,  0.2149,\n",
      "           0.1713, -0.1892, -0.0006,  0.1934,  0.0547,  0.0289,  0.0537,\n",
      "          -0.2004,  0.1536, -0.0286,  0.0380, -0.0426, -0.0953, -0.1707,\n",
      "           0.1002,  0.1306,  0.1393, -0.2928,  0.2377,  0.0514,  0.1121,\n",
      "           0.1365,  0.0836,  0.0511,  0.1592, -0.1109,  0.0792,  0.0660,\n",
      "          -0.0153, -0.1792,  0.1908, -0.1933, -0.0712, -0.1431, -0.1119,\n",
      "          -0.1074, -0.0016,  0.0760,  0.1357, -0.0347,  0.1870, -0.0711,\n",
      "          -0.0716,  0.0462,  0.0826,  0.2564, -0.1123, -0.0377,  0.0874,\n",
      "          -0.1543,  0.0807, -0.0264, -0.1119,  0.1486,  0.1284, -0.0026,\n",
      "          -0.1263, -0.0523, -0.0386, -0.0243,  0.0306, -0.2111, -0.0682,\n",
      "          -0.0263,  0.1145,  0.0220, -0.1712, -0.0053,  0.1533,  0.0196,\n",
      "          -0.0832, -0.1521,  0.0369,  0.1200,  0.2107, -0.0070, -0.2867,\n",
      "          -0.0133, -0.0338, -0.0394,  0.1965, -0.0433,  0.2065,  0.0795,\n",
      "           0.0127, -0.2558, -0.1124,  0.0903, -0.0643,  0.2239,  0.0180,\n",
      "           0.0130,  0.0608, -0.0585, -0.0844, -0.2061,  0.1574, -0.1040,\n",
      "          -0.1024, -0.1201, -0.0877,  0.0094,  0.0982,  0.1205, -0.0327,\n",
      "           0.1039,  0.2241, -0.1148, -0.0958, -0.0708, -0.0186, -0.1231,\n",
      "           0.1746, -0.3432,  0.0405,  0.1101, -0.0556, -0.0181,  0.0212,\n",
      "          -0.0789, -0.1878,  0.1486,  0.0633]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4732, -0.4587, -1.2334, -0.1183,  0.4615,  0.0258,  0.0000,\n",
      "           0.5340,  0.6709,  0.9340,  1.7077, -1.0162,  0.9460, -0.2517,\n",
      "           0.0000,  0.5124,  1.8775, -0.7567, -1.5631,  0.0000, -1.1335,\n",
      "           0.1683,  2.9293,  0.5544, -0.1171,  3.2092,  0.0000,  0.5186,\n",
      "          -2.2264, -1.2857,  0.0291,  0.0000,  0.3250,  0.0000, -0.7986,\n",
      "           0.0000,  0.6197,  0.0000,  1.9913,  0.1018,  0.4674, -2.2043,\n",
      "          -0.5664, -0.1150, -0.7129, -0.6891,  1.9275,  0.0000, -0.2868,\n",
      "          -1.8505,  1.4678,  0.4622,  0.6673,  0.0000,  0.0000,  0.0000,\n",
      "          -1.2425, -0.9510,  1.8137, -0.0118,  0.2051, -1.8186, -1.4011,\n",
      "          -0.8064,  1.1799,  0.2652,  0.0000, -0.2549, -0.0046, -0.4608,\n",
      "          -0.3250,  0.0000,  0.1474, -0.1262,  0.6585, -0.8062,  2.0663,\n",
      "           1.6793,  0.0878,  0.0000,  1.2268,  0.0864,  0.3266,  0.0000,\n",
      "          -0.0712, -1.7320, -1.4586, -0.8912,  0.6230,  0.0000, -1.2239,\n",
      "          -1.1443,  1.9849, -0.3663, -0.7340,  0.1565,  2.1410, -0.4056,\n",
      "          -0.3041, -1.8393, -1.2905, -0.7213,  0.0000,  0.2370,  0.3819,\n",
      "           1.1138, -1.0704,  2.2523, -0.2628, -0.2883, -0.0532,  0.6105,\n",
      "          -0.2544, -0.2803, -1.9418,  1.1284,  0.0000, -2.4970, -0.5750,\n",
      "           0.0297, -1.6948, -0.4011, -0.3791, -0.0783, -0.5366, -1.1108,\n",
      "           1.3043,  0.1695,  0.3223,  1.3583,  2.0788, -2.6340,  0.3598,\n",
      "          -0.7230,  0.4291,  0.0601,  0.3266, -2.1014, -0.4968, -1.6774,\n",
      "          -0.6417,  0.2343, -1.1867, -1.2148, -0.6309, -0.0405,  0.4646,\n",
      "           1.7382,  1.5946,  1.4319, -1.2626, -0.5774, -0.4800, -0.0394,\n",
      "           0.3267, -0.1169,  1.3538, -0.0317, -1.9003, -1.8063, -1.4266,\n",
      "          -0.9001, -0.7057, -0.3891, -0.9809, -0.1288,  0.4064,  0.9701,\n",
      "           0.5179, -0.1475,  1.5133, -0.3729, -0.3158, -2.0086,  0.1295,\n",
      "          -0.3525, -0.8301, -0.7688, -0.0403, -0.9374,  0.7276,  1.0419,\n",
      "           0.0469,  0.4632,  0.3161,  0.0000, -0.5411, -0.6643,  0.7547,\n",
      "          -1.0641, -0.5870, -1.7882,  1.2675, -0.9262, -1.6147, -0.3333,\n",
      "          -1.1570, -1.9607, -0.0719, -0.3750,  2.6973, -0.9216, -2.6313,\n",
      "          -0.5862, -0.7159, -1.3861, -1.2536,  0.1719,  0.2188, -1.1107,\n",
      "           0.9448, -0.6921, -1.5193,  0.3621,  0.2377, -1.4264,  0.0000,\n",
      "           0.0475, -1.4796,  0.4272,  0.0000, -0.9016,  0.3010, -1.1652,\n",
      "          -1.3010, -0.1877,  1.2722,  1.2664,  0.0000, -0.0561,  1.7375,\n",
      "          -1.1752,  0.9561,  1.9992,  0.5273,  0.7889,  0.0000,  0.1045,\n",
      "          -0.6803, -2.2619,  0.1673, -0.3134, -1.0432,  0.0000, -1.0800,\n",
      "           0.5578,  1.4994, -0.5646, -1.3769,  1.2434,  0.5826,  1.7527,\n",
      "           1.9515,  0.3627,  0.4874,  0.3900]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0253, 0.2243, 0.0789, 0.0660, 0.1048, 0.1044, 0.0474, 0.1714, 0.1014,\n",
      "         0.0762]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2626,  0.0019, -0.0881,  ...,  0.1537,  0.0292,  0.0504],\n",
      "        [ 0.2273, -0.0985, -0.5289,  ...,  0.0331, -0.0405,  0.1179],\n",
      "        [ 0.1356, -0.4342,  0.2090,  ..., -0.1256,  0.2478,  0.3428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0592e-01, -1.4705e-01, -1.4233e-01, -1.5685e-01, -1.2896e-02,\n",
      "           9.2115e-02, -1.2950e-01, -6.9887e-02, -6.2326e-02, -8.5641e-02,\n",
      "           3.5977e-02,  1.7648e-02,  8.5020e-02,  1.3772e-01,  8.4350e-02,\n",
      "           1.0783e-01,  2.5391e-02, -9.2332e-02, -1.6384e-01,  3.3226e-02,\n",
      "           4.0159e-02, -2.7006e-02,  2.1358e-01,  3.7342e-02,  1.5997e-01,\n",
      "          -7.3881e-02,  9.4769e-02, -7.9285e-02, -1.4933e-01,  4.9922e-02,\n",
      "           2.7054e-01, -1.8878e-01,  1.4769e-01, -9.5220e-02,  1.5447e-01,\n",
      "          -1.1162e-01, -8.5771e-02,  1.4443e-01, -1.9194e-01,  4.1579e-02,\n",
      "          -2.4555e-02,  1.4407e-01, -6.1018e-02, -8.4297e-02, -1.0531e-01,\n",
      "           3.6628e-02,  3.6911e-02, -5.5982e-02,  8.7240e-02,  1.9794e-02,\n",
      "           5.8971e-02, -3.4461e-03, -7.0270e-02, -2.8315e-02,  5.2790e-02,\n",
      "           1.3554e-01, -5.5923e-02,  1.1042e-01,  1.4133e-01, -6.9604e-02,\n",
      "           9.9743e-03, -7.8506e-02, -1.4594e-01, -9.0374e-02,  5.7676e-02,\n",
      "           7.3052e-02, -9.3096e-02, -1.3808e-03, -1.3438e-01,  9.4266e-02,\n",
      "          -3.7967e-02,  2.1445e-01, -6.9231e-02, -5.9370e-02, -1.5268e-01,\n",
      "           2.5481e-01, -6.6771e-02,  1.5756e-01, -8.8158e-02,  1.1016e-02,\n",
      "          -1.0634e-01,  1.1161e-01, -2.4606e-02, -1.4781e-02, -8.6710e-03,\n",
      "           9.2850e-02, -4.4677e-02, -7.7654e-02, -3.5631e-02, -2.6774e-02,\n",
      "          -1.4127e-01, -6.5397e-02,  1.2031e-02, -3.7005e-02,  1.2336e-01,\n",
      "           1.0284e-01, -4.9847e-02, -2.6874e-02,  8.5961e-02,  1.6443e-02,\n",
      "          -1.9725e-02,  1.7619e-01,  5.4630e-02, -2.3050e-02, -1.0526e-01,\n",
      "          -2.4606e-01, -3.8296e-04,  1.7906e-01, -2.0440e-01, -1.7867e-02,\n",
      "          -3.2865e-02,  5.1194e-02,  3.4929e-02, -1.5249e-01,  1.6389e-01,\n",
      "          -1.6003e-01, -4.0569e-02,  1.3693e-02, -6.6982e-03,  1.8656e-01,\n",
      "          -1.9599e-02, -2.0331e-02, -3.1475e-02,  4.8802e-02, -5.0714e-02,\n",
      "          -4.9243e-02,  1.8324e-02,  6.0029e-02, -1.7232e-02, -1.6685e-01,\n",
      "          -1.5449e-01, -1.7073e-01,  1.7013e-01,  7.9840e-02, -2.0470e-01,\n",
      "           1.1115e-01,  2.4430e-01, -1.7095e-02, -5.8179e-02,  8.2001e-03,\n",
      "          -7.7515e-02,  1.0556e-01,  1.7130e-02,  8.3897e-02, -2.3091e-02,\n",
      "          -5.1704e-02, -1.6430e-01, -1.2420e-02,  6.2269e-02, -2.7826e-02,\n",
      "          -1.5012e-01,  1.4681e-01, -1.4421e-02, -8.3578e-03,  7.4585e-02,\n",
      "           2.2674e-02,  1.0833e-01,  1.4937e-01, -5.9701e-02,  3.6276e-02,\n",
      "           3.1717e-02, -2.0335e-02, -1.0467e-01,  1.1657e-01, -1.4975e-01,\n",
      "          -9.6175e-02, -1.3570e-01, -2.6271e-03, -9.4126e-02,  5.0394e-02,\n",
      "           8.5111e-03,  6.7078e-02, -5.0600e-02,  1.7695e-01, -1.2618e-01,\n",
      "          -3.0422e-02,  1.2997e-01,  9.0476e-02,  2.6536e-01, -1.0998e-01,\n",
      "           7.3211e-02, -1.4197e-02, -6.7755e-02,  4.1692e-02, -7.4700e-02,\n",
      "          -9.5628e-02,  1.4755e-01,  4.4287e-02,  9.1269e-03, -8.6828e-02,\n",
      "          -4.1655e-02,  2.8344e-02, -1.9301e-02,  1.9140e-02, -1.7016e-01,\n",
      "           6.6454e-02, -9.2555e-02,  8.0293e-02,  1.8870e-02, -1.0765e-01,\n",
      "          -4.5161e-02,  1.4247e-01,  2.3043e-02, -5.5484e-03, -1.4084e-01,\n",
      "           6.3632e-02,  1.2842e-01,  1.6496e-01,  9.3353e-05, -2.0833e-01,\n",
      "          -3.4890e-04, -1.0780e-01, -6.0051e-02,  1.6265e-01, -6.1339e-02,\n",
      "           1.3094e-01,  7.3521e-02,  6.8306e-02, -1.6541e-01, -3.1825e-02,\n",
      "           1.0671e-01, -6.0091e-02,  1.5829e-01,  2.7263e-02,  3.8572e-02,\n",
      "           1.1375e-02,  2.9473e-03, -1.2449e-02, -1.4378e-01,  1.8594e-01,\n",
      "          -2.0812e-01, -8.6986e-02, -4.2417e-03,  1.1707e-02,  3.0403e-02,\n",
      "           9.8842e-02,  1.6129e-01, -4.3865e-02,  3.6738e-02,  1.7242e-01,\n",
      "           2.3492e-02, -3.2446e-02,  4.1059e-02, -7.3347e-02, -8.8663e-02,\n",
      "           1.6930e-01, -3.3219e-01,  5.4861e-02,  1.0018e-01,  5.9730e-02,\n",
      "           6.5092e-02,  1.6864e-02, -3.7749e-02, -9.0392e-02,  6.4506e-02,\n",
      "           8.3418e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9613e-02,  0.0000e+00,  0.0000e+00,  5.1607e-01,\n",
      "          -3.7613e-01,  1.1421e-03, -7.2297e-01,  2.1178e+00, -2.1360e-01,\n",
      "           2.8210e-01,  8.3066e-01, -1.1107e+00,  1.9969e-01,  3.1261e-01,\n",
      "           3.5190e-01, -6.8285e-01,  1.6924e-01,  8.7454e-01,  5.4570e-01,\n",
      "           1.8834e+00,  6.0189e-01, -3.6949e-02, -5.3539e-01, -1.0047e-01,\n",
      "           6.5109e-01, -1.6089e+00, -1.3622e+00, -2.1267e+00, -1.0345e+00,\n",
      "           3.8810e-02,  0.0000e+00, -2.0765e+00,  3.1549e-01, -2.8511e-01,\n",
      "          -2.0018e+00,  2.1893e-01,  9.9698e-01,  6.0141e-01,  9.5347e-01,\n",
      "          -2.2512e-01, -2.2111e+00, -7.0606e-01,  1.3960e+00,  8.9706e-02,\n",
      "          -1.1384e+00,  2.4252e-01,  7.4207e-01, -7.0957e-01, -1.3359e+00,\n",
      "           1.6085e+00, -1.3738e-01,  6.6258e-01,  1.1164e+00,  5.6732e-01,\n",
      "           3.3298e-01,  0.0000e+00, -8.8800e-01,  1.3378e-01,  6.2831e-01,\n",
      "          -7.0470e-01,  5.6354e-01, -6.9322e-01, -1.5471e+00,  2.8930e-01,\n",
      "           9.5700e-02,  0.0000e+00,  5.9499e-01, -2.1387e+00,  5.5968e-01,\n",
      "           1.8256e-01, -5.1254e-01, -3.4094e-01, -1.1319e+00, -6.4749e-01,\n",
      "           0.0000e+00, -1.0491e+00,  1.1889e-01,  5.1717e-01, -1.8641e-01,\n",
      "          -3.8501e-01,  2.1579e+00,  7.7744e-01, -8.4544e-01,  3.9777e-01,\n",
      "           4.1920e-01,  1.6047e+00, -5.6412e-01, -1.4131e+00, -1.4906e+00,\n",
      "           4.0444e-01, -3.5145e-01,  4.9401e-01, -2.3210e+00,  1.2379e+00,\n",
      "          -9.6291e-01,  1.3204e+00, -9.0736e-01,  2.3909e+00,  9.5509e-01,\n",
      "          -1.2009e+00,  5.9426e-01,  1.0664e+00, -1.7339e+00,  3.6529e-01,\n",
      "           4.0237e-01, -1.2704e+00,  4.5476e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -8.3257e-01,  5.3403e-01,  8.0847e-01,  6.6387e-01, -1.0553e+00,\n",
      "           9.1776e-01, -7.0307e-01, -8.4515e-01,  0.0000e+00,  8.7973e-01,\n",
      "          -8.7709e-01, -1.3962e+00, -3.6479e-01,  0.0000e+00, -1.3006e+00,\n",
      "           1.0694e+00,  0.0000e+00,  6.4933e-01,  2.5560e-01, -1.4897e+00,\n",
      "           2.5020e+00,  3.7786e-01, -1.3453e+00,  7.2222e-01,  0.0000e+00,\n",
      "          -7.5272e-01, -3.8358e-01,  1.2823e+00,  2.2520e+00,  1.9419e-01,\n",
      "          -3.9052e-02,  3.0300e+00,  3.6291e-01, -1.8713e-01, -1.1120e+00,\n",
      "           1.2471e+00,  0.0000e+00, -7.7473e-01, -4.4843e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6515e-01, -2.8960e-01, -2.1306e+00, -5.8166e-01,\n",
      "           7.8597e-01, -1.8621e+00, -1.3047e+00,  1.9034e-01, -3.6288e+00,\n",
      "          -1.8687e+00,  1.1504e+00, -8.5969e-01,  9.5955e-01, -1.4611e+00,\n",
      "          -2.7064e-02,  1.9744e+00,  1.1270e+00, -4.8566e-01, -1.2414e+00,\n",
      "          -2.1245e-01, -1.3225e+00, -1.6391e+00, -7.7169e-01,  6.8269e-01,\n",
      "          -1.3798e+00, -1.2614e-01,  6.0643e-01, -7.4904e-01,  2.5917e-01,\n",
      "           1.3326e+00, -2.5534e+00,  2.7792e-01, -5.8353e-01,  0.0000e+00,\n",
      "          -1.2403e+00, -1.8006e-03, -5.0176e-02,  9.0086e-01,  5.6554e-01,\n",
      "          -4.1986e-01,  3.8843e-01, -1.1562e-01,  8.0976e-01,  1.0504e+00,\n",
      "          -7.8924e-01, -1.4389e+00, -4.1541e-01, -7.5025e-01,  0.0000e+00,\n",
      "           0.0000e+00,  7.2240e-01, -1.8531e+00,  0.0000e+00,  8.3784e-01,\n",
      "          -1.5240e+00, -3.5871e-01,  6.4770e-01,  2.0040e-01,  0.0000e+00,\n",
      "           8.3537e-01, -1.2911e+00, -1.2838e+00,  2.6099e-01,  0.0000e+00,\n",
      "           2.0757e+00,  1.3410e-01,  0.0000e+00, -3.0947e-02, -5.7954e-01,\n",
      "          -1.4281e+00,  1.9011e+00, -3.8088e-01,  1.4695e+00,  8.0530e-01,\n",
      "           3.6925e-01,  0.0000e+00, -7.0037e-01,  0.0000e+00,  1.0253e+00,\n",
      "           9.7835e-01, -1.4083e+00,  6.5958e-01, -1.1450e+00, -1.6455e+00,\n",
      "          -6.0023e-01,  8.8160e-03, -7.1085e-01,  3.7050e-01, -2.2407e-01,\n",
      "          -7.5245e-01,  5.7220e-01,  5.3060e-01, -6.6367e-01,  1.5465e+00,\n",
      "           5.7823e-01,  1.8919e+00, -8.6386e-01,  4.9356e-01, -3.8714e-01,\n",
      "           5.0001e-01,  0.0000e+00,  1.7728e+00, -1.0636e+00, -8.0782e-01,\n",
      "          -6.2205e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0633, 0.1225, 0.1429, 0.1316, 0.1096, 0.1446, 0.0855, 0.0494, 0.0663,\n",
      "         0.0843]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2626,  0.0019, -0.0881,  ...,  0.1537,  0.0292,  0.0504],\n",
      "        [ 0.2273, -0.0985, -0.5289,  ...,  0.0331, -0.0405,  0.1179],\n",
      "        [ 0.1356, -0.4342,  0.2090,  ..., -0.1256,  0.2478,  0.3428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0726e-01, -1.9430e-01, -9.4809e-02, -1.8879e-01, -4.8504e-02,\n",
      "           3.1798e-02, -1.7986e-01, -6.3079e-02, -9.8154e-02, -3.5514e-02,\n",
      "           5.3762e-02, -5.9386e-02,  1.2167e-01,  2.1889e-01,  1.1339e-01,\n",
      "           1.0866e-01, -3.6206e-02, -1.3105e-01, -2.5066e-01, -1.4503e-04,\n",
      "           6.1409e-02, -2.3437e-02,  2.7796e-01,  7.8271e-02,  1.5480e-01,\n",
      "          -5.5986e-02,  8.2953e-02, -1.2254e-01, -1.7923e-01,  7.6596e-02,\n",
      "           3.4542e-01, -2.4884e-01,  1.4391e-01, -1.3055e-01,  1.4621e-01,\n",
      "          -1.1321e-01, -1.1119e-01,  1.4969e-01, -2.4738e-01,  4.9549e-02,\n",
      "          -6.7346e-02,  2.0926e-01, -1.4657e-01, -1.2617e-01, -9.6356e-02,\n",
      "           1.1266e-01,  1.2800e-02, -1.2259e-01,  7.0322e-02,  1.9685e-02,\n",
      "           1.0781e-01, -2.7852e-02, -6.0944e-02, -2.4799e-02,  6.9236e-02,\n",
      "           1.2317e-01, -1.2896e-01,  1.6355e-01,  1.6435e-01, -1.1502e-01,\n",
      "           2.7033e-02, -1.3198e-01, -2.0032e-01, -7.2690e-02,  6.6330e-02,\n",
      "           5.7062e-02, -1.0316e-01,  9.3796e-03, -2.1634e-01,  1.3058e-01,\n",
      "          -2.7668e-02,  2.9686e-01, -6.9241e-02, -1.4642e-05, -1.8813e-01,\n",
      "           2.5475e-01, -8.6468e-02,  1.9334e-01, -1.3099e-01,  8.5492e-02,\n",
      "          -1.1525e-01,  1.1887e-01, -2.1165e-02,  6.3214e-03,  5.5617e-03,\n",
      "           1.3509e-01, -4.5316e-02, -1.0411e-01,  4.7761e-02, -2.9835e-02,\n",
      "          -1.9766e-01, -9.5063e-02,  2.2790e-02, -2.3941e-02,  1.7035e-01,\n",
      "           1.2294e-01, -6.0806e-02, -5.4769e-02,  1.0271e-01,  2.3741e-02,\n",
      "          -3.7196e-02,  1.6480e-01,  1.0107e-01, -1.1560e-02, -5.7694e-02,\n",
      "          -3.0757e-01,  8.8878e-02,  2.3491e-01, -2.6207e-01,  1.4305e-02,\n",
      "          -9.4884e-02,  4.3708e-02,  3.9156e-02, -1.6634e-01,  1.5468e-01,\n",
      "          -1.9208e-01, -1.0306e-01,  3.0949e-03,  2.7161e-02,  2.1812e-01,\n",
      "          -5.2637e-02, -7.0269e-02, -4.4821e-02,  5.9653e-02, -1.0131e-01,\n",
      "           1.7621e-02,  1.4399e-02,  6.6908e-02,  1.8200e-02, -1.9498e-01,\n",
      "          -1.3222e-01, -2.0991e-01,  2.3433e-01,  1.2260e-01, -2.0564e-01,\n",
      "           1.0173e-01,  2.5858e-01, -7.0745e-03, -2.5083e-02,  1.1430e-02,\n",
      "          -1.4747e-01,  1.4419e-01,  1.2874e-02,  1.0798e-01, -4.0284e-02,\n",
      "          -5.3364e-02, -2.0362e-01,  4.5677e-02,  7.4980e-02,  4.5431e-02,\n",
      "          -2.4513e-01,  2.1080e-01,  4.2059e-02,  4.0078e-02,  1.0680e-01,\n",
      "           7.7666e-02,  1.0187e-01,  1.7940e-01, -7.6462e-02,  5.8447e-02,\n",
      "           8.1732e-02, -1.8327e-02, -1.4933e-01,  1.5601e-01, -1.4359e-01,\n",
      "          -8.3340e-02, -1.5337e-01, -6.5676e-02, -9.2114e-02,  2.6395e-02,\n",
      "           6.0651e-02,  1.0944e-01, -5.1909e-02,  1.8796e-01, -1.2362e-01,\n",
      "          -3.6588e-02,  1.3397e-01,  1.0520e-01,  2.9462e-01, -1.1783e-01,\n",
      "           7.0458e-02,  7.2159e-02, -1.4947e-01,  9.7197e-02, -6.5583e-02,\n",
      "          -1.0687e-01,  1.3985e-01,  8.9638e-02,  2.1614e-03, -1.0969e-01,\n",
      "          -4.2252e-02, -3.7323e-02, -2.3345e-02,  2.3003e-02, -2.1597e-01,\n",
      "           1.3778e-02, -8.4821e-02,  8.5704e-02,  2.8960e-02, -1.5309e-01,\n",
      "          -1.5443e-02,  1.3754e-01,  3.7593e-02, -6.8206e-02, -1.3770e-01,\n",
      "           7.8387e-02,  1.5768e-01,  2.0729e-01,  2.7480e-03, -2.8155e-01,\n",
      "           3.7172e-02, -6.8239e-02, -3.5075e-02,  2.1028e-01, -7.7924e-02,\n",
      "           2.2987e-01,  6.5131e-02,  6.9635e-02, -2.0866e-01, -6.2668e-02,\n",
      "           1.0868e-01, -8.9489e-02,  2.0245e-01,  1.1190e-02,  4.7957e-02,\n",
      "           4.1150e-02, -2.1404e-02, -2.9016e-02, -1.8844e-01,  2.3948e-01,\n",
      "          -1.7394e-01, -9.4787e-02, -3.7624e-02, -3.9017e-02,  3.3887e-02,\n",
      "           1.3428e-01,  1.7794e-01, -4.5364e-02,  3.3131e-02,  2.0096e-01,\n",
      "          -2.3379e-02, -1.0358e-01, -7.6092e-03, -9.5833e-02, -1.5252e-01,\n",
      "           2.2328e-01, -4.0641e-01,  3.9087e-02,  1.3391e-01,  3.2749e-02,\n",
      "           3.4655e-02,  4.9695e-04, -1.0182e-01, -1.2202e-01,  8.6903e-02,\n",
      "           1.2333e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7032e-02,  3.9998e-01, -9.6476e-01, -6.8089e-01,  3.7535e-01,\n",
      "          -2.0191e-01,  1.4645e+00, -8.3636e-02, -3.5830e+00,  0.0000e+00,\n",
      "           4.2790e-01, -6.2913e-01,  2.6020e+00, -6.3026e-01, -5.4128e-01,\n",
      "          -1.5797e-01,  8.5129e-01,  1.0942e+00,  4.5521e-01,  4.3617e-01,\n",
      "           0.0000e+00, -3.8238e-01,  1.6396e+00,  1.5109e+00,  7.5316e-01,\n",
      "          -7.5905e-02, -1.8816e-01, -7.6000e-01,  0.0000e+00,  0.0000e+00,\n",
      "           1.2314e+00,  1.2191e+00, -1.0341e+00,  0.0000e+00, -1.5340e+00,\n",
      "           0.0000e+00,  2.8071e-01, -3.7437e+00,  1.9764e-01,  1.5999e+00,\n",
      "          -4.5904e-01, -1.3977e+00, -2.6891e-01, -1.7142e+00, -1.5232e+00,\n",
      "           6.6775e-01,  5.4040e-01,  3.7118e-01, -1.3402e+00,  1.4451e-01,\n",
      "          -6.2936e-01,  2.7504e+00,  6.0997e-01, -1.0285e+00, -2.4920e-02,\n",
      "           2.0409e-01, -8.8119e-01, -1.2510e+00, -2.3737e-01, -4.2611e-01,\n",
      "           0.0000e+00,  1.4070e+00, -2.0239e-01, -5.0074e-01, -2.9622e+00,\n",
      "           5.5157e-01,  1.2779e+00, -1.2873e+00,  4.0997e-01,  5.2685e-01,\n",
      "          -1.2663e+00, -2.9580e-02,  0.0000e+00, -3.6394e+00,  3.2499e-01,\n",
      "          -5.6764e-04, -1.6006e-01,  1.0612e+00, -5.7375e-02, -1.1787e-01,\n",
      "          -1.3995e+00,  2.1299e+00, -9.2406e-01,  1.0058e+00, -2.0747e-01,\n",
      "           4.3625e-01,  1.6611e+00, -9.7388e-01, -1.0441e-01, -5.8111e-01,\n",
      "          -2.2721e+00,  1.0995e+00, -6.2242e-01, -1.1357e+00,  4.6700e-01,\n",
      "          -1.1700e+00,  3.2835e-02,  6.2884e-01,  1.7190e+00, -7.7838e-01,\n",
      "           2.6966e+00, -1.4615e+00,  1.0759e+00,  0.0000e+00, -6.6602e-01,\n",
      "          -7.6220e-01,  1.2107e+00,  1.2735e-01, -1.4727e+00, -1.3927e-02,\n",
      "          -2.4804e-01,  0.0000e+00, -1.0470e+00,  1.3099e+00, -1.6522e+00,\n",
      "          -2.9876e+00, -5.6996e-02, -4.9925e-01, -1.9343e-01,  4.4562e-01,\n",
      "          -1.4647e+00,  7.0192e-01, -1.4600e+00, -7.2550e-01, -9.5752e-01,\n",
      "          -1.3074e+00,  8.9549e-01,  1.6949e-01,  1.2844e+00, -7.5096e-01,\n",
      "          -8.2424e-01,  5.3085e-01, -1.5824e+00,  9.8379e-01,  2.7617e-01,\n",
      "          -5.8903e-01,  6.5838e-01,  5.7556e-01, -1.1590e+00, -1.0092e+00,\n",
      "          -3.8792e-01,  6.7771e-01, -7.8920e-01, -1.0056e-01, -1.6843e+00,\n",
      "          -1.0007e-01, -5.4278e-01, -8.4421e-01, -7.5483e-01,  1.7771e-01,\n",
      "           0.0000e+00, -1.9911e-01, -1.9293e+00, -4.0627e-01,  4.4105e-01,\n",
      "           0.0000e+00, -6.4983e-02, -1.3060e-01,  0.0000e+00,  5.3733e-01,\n",
      "          -2.6609e-02,  2.2058e+00,  4.8100e-01, -5.5046e-01, -5.2561e-01,\n",
      "          -8.9121e-01,  2.8155e-01,  8.2763e-02, -3.5809e-01,  0.0000e+00,\n",
      "           7.3602e-01, -3.0712e-02,  2.0128e-02, -1.0027e+00,  1.2774e+00,\n",
      "          -1.0975e+00, -9.8567e-01, -2.0751e+00,  1.9680e+00,  8.6361e-02,\n",
      "          -3.1062e-02,  3.4994e-02,  0.0000e+00,  9.7982e-01, -7.4777e-01,\n",
      "          -3.4105e-01, -2.7813e+00, -7.8295e-01,  1.2088e+00,  1.0125e+00,\n",
      "           3.0721e+00,  4.9394e-01, -1.4434e-01, -5.9293e-01,  5.5981e-01,\n",
      "           2.1639e+00, -1.1873e+00,  5.3502e-01,  1.8107e+00, -9.4601e-01,\n",
      "          -1.6624e+00, -1.0153e+00,  1.2423e+00, -1.2219e-01,  0.0000e+00,\n",
      "          -5.7457e-01, -2.2916e+00,  0.0000e+00, -1.0730e+00, -4.7106e-01,\n",
      "           2.8670e+00, -5.7311e-01, -3.4127e-01,  7.9265e-01,  3.1840e-02,\n",
      "           0.0000e+00,  0.0000e+00,  9.6675e-01, -2.4508e-01,  2.1683e+00,\n",
      "          -1.0826e+00, -4.2685e-01, -1.8431e+00, -5.0006e-01,  3.3935e-01,\n",
      "           7.0487e-01, -6.9655e-01, -6.2811e-01,  2.9225e-01, -1.5773e+00,\n",
      "          -1.1080e+00,  1.5812e+00, -6.1373e-01,  1.3101e+00, -2.9788e+00,\n",
      "           0.0000e+00,  5.8509e-01,  4.2866e-02, -1.5783e+00, -2.8595e-01,\n",
      "           7.4207e-01, -3.2462e+00, -3.0357e-01,  0.0000e+00,  1.1333e-02,\n",
      "           0.0000e+00,  2.7466e-01,  2.5213e-01,  2.6154e-01,  3.8679e-01,\n",
      "          -3.6585e-01, -1.5962e-01,  0.0000e+00, -5.1974e-02, -1.1461e+00,\n",
      "          -1.1312e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0478, 0.0647, 0.1143, 0.0639, 0.1140, 0.2488, 0.0702, 0.0793, 0.0742,\n",
      "         0.1227]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0297,  0.4015, -0.0028,  ...,  0.1338,  0.0976, -0.2278],\n",
      "        [ 0.1996,  0.2765, -0.2993,  ..., -0.1574,  0.2049, -0.2681],\n",
      "        [-0.2764, -0.0884, -0.3502,  ...,  0.1256,  0.1992,  0.0233],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0412,  0.0472, -0.3250,  0.0330, -0.0385, -0.1539, -0.1262,\n",
      "          -0.0774,  0.1431, -0.0954,  0.0305, -0.0403, -0.1667, -0.1142,\n",
      "           0.0088, -0.1068,  0.1862,  0.1517, -0.1031,  0.1138,  0.0681,\n",
      "          -0.1328,  0.1468, -0.0803, -0.1907,  0.1111,  0.0692, -0.2009,\n",
      "           0.0048,  0.0214,  0.0905, -0.2498,  0.0363, -0.1891, -0.0134,\n",
      "           0.1510, -0.1192, -0.1367, -0.1014,  0.0027, -0.1796,  0.0690,\n",
      "          -0.2695, -0.0087,  0.1798,  0.1352,  0.1221, -0.0427,  0.1550,\n",
      "           0.0760, -0.0213, -0.0818, -0.2045, -0.1800, -0.0969, -0.1506,\n",
      "           0.0016,  0.0007,  0.0885, -0.0174, -0.1488, -0.2215, -0.1931,\n",
      "          -0.0686,  0.0437, -0.0066,  0.0418,  0.3217, -0.2464,  0.2174,\n",
      "          -0.0074,  0.1341,  0.0858,  0.2389, -0.1306,  0.0210,  0.1725,\n",
      "           0.0246, -0.0911,  0.1537, -0.0639, -0.0792, -0.1803,  0.1706,\n",
      "          -0.0024,  0.0378,  0.0379,  0.0986, -0.0098, -0.0415, -0.0367,\n",
      "           0.1253,  0.0153, -0.1804, -0.0827,  0.0395,  0.1979,  0.1247,\n",
      "           0.1858,  0.3602, -0.1717,  0.0221,  0.0525,  0.1386,  0.0701,\n",
      "          -0.0559,  0.2445,  0.1845, -0.0243,  0.1299,  0.0367,  0.1694,\n",
      "          -0.0115, -0.1895,  0.0141, -0.0945, -0.1428, -0.0045, -0.2067,\n",
      "          -0.1133, -0.0398, -0.0060, -0.1298,  0.1168, -0.2935,  0.0872,\n",
      "           0.0656, -0.1186,  0.1803, -0.0027, -0.0647, -0.0978,  0.1256,\n",
      "           0.0350,  0.0346, -0.0149,  0.3161,  0.0923,  0.0684,  0.0944,\n",
      "          -0.0808,  0.0803, -0.1330,  0.2426, -0.0140, -0.0060, -0.1061,\n",
      "           0.1891,  0.0036,  0.1861, -0.1588,  0.0584, -0.0225,  0.2401,\n",
      "          -0.0497,  0.1869, -0.1080,  0.1284, -0.0941, -0.1545, -0.0373,\n",
      "          -0.0856, -0.1611,  0.2288, -0.1553,  0.0510,  0.0277, -0.2588,\n",
      "           0.1544,  0.0627, -0.0232,  0.0648,  0.1393, -0.0486, -0.0330,\n",
      "          -0.1592,  0.1186,  0.1874,  0.3770, -0.0104, -0.0802, -0.0482,\n",
      "          -0.0306,  0.0420,  0.1247, -0.1019, -0.1700,  0.0446, -0.0806,\n",
      "          -0.0791,  0.0636,  0.0258, -0.2533, -0.1099,  0.0665, -0.1422,\n",
      "          -0.0163, -0.0284,  0.1097, -0.0404, -0.1444,  0.2150, -0.2103,\n",
      "           0.0481, -0.0832, -0.2326, -0.2402,  0.3060,  0.0334, -0.0558,\n",
      "          -0.0927, -0.1816,  0.0640, -0.0899, -0.0174,  0.1971, -0.0160,\n",
      "           0.0686, -0.0213,  0.1155,  0.2183, -0.0042,  0.0411, -0.1311,\n",
      "           0.0124,  0.1084,  0.0899, -0.0771, -0.4034,  0.0532, -0.0763,\n",
      "          -0.0258, -0.0575, -0.1017, -0.0859,  0.0849, -0.2112,  0.0798,\n",
      "           0.2661,  0.1812, -0.0380, -0.2403,  0.0816, -0.0635,  0.1069,\n",
      "           0.0121, -0.1565, -0.3012,  0.0941, -0.0458,  0.1851, -0.0472,\n",
      "          -0.2203, -0.1346,  0.1464, -0.0049]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4733, -0.4588, -1.2334, -0.1182,  0.4616,  0.0258,  0.0000,\n",
      "           0.5340,  0.6708,  0.9339,  1.7078, -1.0163,  0.9461, -0.2517,\n",
      "           0.0000,  0.5124,  1.8774, -0.7566, -1.5631, -2.6432, -1.1335,\n",
      "           0.1683,  2.9294,  0.5543, -0.1170,  3.2092,  1.8370,  0.5187,\n",
      "          -2.2264, -1.2857,  0.0292,  1.0133,  0.3250,  0.8598, -0.7985,\n",
      "          -1.4655,  0.6198, -0.7713,  1.9914,  0.1019,  0.4675, -2.2043,\n",
      "          -0.5664, -0.1150, -0.7129,  0.0000,  1.9277,  0.0000, -0.2868,\n",
      "           0.0000,  1.4678,  0.4622,  0.6673, -0.2831,  0.5317,  0.2749,\n",
      "          -1.2424, -0.9510,  1.8138, -0.0118,  0.2050, -1.8185, -1.4012,\n",
      "          -0.8063,  1.1799,  0.2652,  0.0000, -0.2550, -0.0045, -0.4608,\n",
      "          -0.3251, -0.3240,  0.1474, -0.1263,  0.6585, -0.8063,  2.0663,\n",
      "           1.6794,  0.0878, -0.5457,  1.2269,  0.0865,  0.3267,  0.0000,\n",
      "          -0.0713, -1.7320,  0.0000, -0.8911,  0.6230,  0.0000, -1.2238,\n",
      "          -1.1442,  1.9850, -0.3662, -0.7340,  0.1565,  2.1412, -0.4056,\n",
      "          -0.3041, -1.8394,  0.0000, -0.7213, -0.7663,  0.2370,  0.3819,\n",
      "           1.1138, -1.0703,  2.2522, -0.2628, -0.2883, -0.0532,  0.6106,\n",
      "          -0.2545, -0.2803, -1.9419,  1.1284,  0.0000, -2.4972, -0.5750,\n",
      "           0.0000, -1.6948, -0.4011, -0.3792, -0.0784, -0.5367, -1.1109,\n",
      "           1.3044,  0.1695,  0.3222,  1.3584,  2.0789,  0.0000,  0.3597,\n",
      "          -0.7230,  0.4291,  0.0601,  0.0000, -2.1016, -0.4969, -1.6774,\n",
      "          -0.6418,  0.2343, -1.1869, -1.2149, -0.6310, -0.0406,  0.4647,\n",
      "           1.7383,  1.5945,  1.4318, -1.2627, -0.5773,  0.0000, -0.0394,\n",
      "           0.0000, -0.1169,  0.0000,  0.0000, -1.9004, -1.8062, -1.4267,\n",
      "          -0.9002, -0.7057, -0.3891, -0.9810, -0.1289,  0.4064,  0.9701,\n",
      "           0.5179, -0.1475,  1.5135, -0.3730, -0.3158, -2.0087,  0.1295,\n",
      "          -0.3525, -0.8301, -0.7689, -0.0402,  0.0000,  0.7276,  0.0000,\n",
      "           0.0469,  0.0000,  0.3162, -0.1182, -0.5412, -0.6643,  0.7548,\n",
      "           0.0000, -0.5870, -1.7883,  1.2675,  0.0000, -1.6147, -0.3333,\n",
      "           0.0000, -1.9606, -0.0720, -0.3752,  2.6974, -0.9216, -2.6314,\n",
      "          -0.5862, -0.7161, -1.3860,  0.0000,  0.1718,  0.2188, -1.1108,\n",
      "           0.9448, -0.6921, -1.5194,  0.3621,  0.2376, -1.4264, -2.3446,\n",
      "           0.0000, -1.4796,  0.0000,  0.0133, -0.9016,  0.3010, -1.1652,\n",
      "          -1.3011, -0.1876,  1.2723,  1.2664, -2.1880, -0.0561,  1.7374,\n",
      "           0.0000,  0.9561,  1.9991,  0.5272,  0.0000, -0.6786,  0.1045,\n",
      "          -0.6803, -2.2619,  0.1673, -0.3136, -1.0432, -0.3820, -1.0800,\n",
      "           0.5578,  1.4995, -0.5646, -1.3770,  1.2434,  0.5826,  1.7528,\n",
      "           1.9515,  0.0000,  0.4874,  0.3901]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0304, 0.1880, 0.1221, 0.0646, 0.1042, 0.1371, 0.0363, 0.1750, 0.0695,\n",
      "         0.0729]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0297,  0.4015, -0.0028,  ...,  0.1338,  0.0976, -0.2278],\n",
      "        [ 0.1996,  0.2765, -0.2993,  ..., -0.1574,  0.2049, -0.2681],\n",
      "        [-0.2764, -0.0884, -0.3502,  ...,  0.1256,  0.1992,  0.0233],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0277,  0.0427, -0.2786,  0.0643, -0.0085, -0.1477, -0.1566,\n",
      "          -0.0425,  0.1406, -0.0418, -0.0378,  0.0213, -0.1654, -0.1071,\n",
      "          -0.0549, -0.0956,  0.1992,  0.1567, -0.0041,  0.1126,  0.0429,\n",
      "          -0.1371,  0.1244, -0.1186, -0.1952,  0.1353,  0.1391, -0.1683,\n",
      "           0.0246,  0.0202,  0.1130, -0.2842,  0.0380, -0.1732,  0.0088,\n",
      "           0.1374, -0.1033, -0.1361, -0.0954, -0.0144, -0.2002,  0.1040,\n",
      "          -0.1881,  0.0105,  0.1674,  0.0422,  0.1359, -0.0174,  0.1460,\n",
      "           0.1283, -0.0049, -0.0327, -0.2006, -0.1866, -0.1071, -0.1152,\n",
      "           0.0011, -0.0846,  0.0665, -0.0677, -0.1928, -0.2072, -0.1287,\n",
      "          -0.1015,  0.0228, -0.0361,  0.0942,  0.2814, -0.2403,  0.1725,\n",
      "          -0.0077,  0.0635,  0.1068,  0.2656, -0.0558, -0.0258,  0.1675,\n",
      "          -0.0487, -0.0500,  0.1332, -0.0458, -0.0092, -0.1375,  0.2029,\n",
      "          -0.0097, -0.0341,  0.0320,  0.0585, -0.0415, -0.0117, -0.0760,\n",
      "           0.1486,  0.0006, -0.2185, -0.0464,  0.0304,  0.1219,  0.0773,\n",
      "           0.2261,  0.3308, -0.1712, -0.0468, -0.0033,  0.1445,  0.1206,\n",
      "           0.0064,  0.2499,  0.1429, -0.0190,  0.0982,  0.0320,  0.1744,\n",
      "          -0.0330, -0.1059,  0.0484, -0.0615, -0.1243,  0.0362, -0.2242,\n",
      "          -0.0629, -0.0281,  0.0662, -0.0555,  0.0790, -0.2668,  0.0963,\n",
      "           0.0688, -0.0898,  0.1431,  0.0610, -0.0776,  0.0313,  0.0267,\n",
      "          -0.0240,  0.0466, -0.0167,  0.2487,  0.0603,  0.1323,  0.0169,\n",
      "          -0.0725,  0.0469, -0.1610,  0.1924, -0.0488,  0.0127, -0.0985,\n",
      "           0.1740, -0.0070,  0.1593, -0.0830,  0.0097, -0.0378,  0.2146,\n",
      "          -0.0805,  0.1655, -0.1018,  0.1520, -0.1506, -0.1399, -0.0123,\n",
      "          -0.0908, -0.0967,  0.1474, -0.1769,  0.0097, -0.0295, -0.2556,\n",
      "           0.1619, -0.0131, -0.0379,  0.0678,  0.1258, -0.0804, -0.0182,\n",
      "          -0.1754,  0.1380,  0.1450,  0.3470,  0.0226, -0.0632, -0.0338,\n",
      "           0.0191,  0.0517,  0.0803, -0.1342, -0.1179, -0.0262, -0.1734,\n",
      "          -0.0938,  0.1264, -0.0014, -0.1502, -0.0914,  0.0666, -0.1536,\n",
      "           0.0013, -0.0552,  0.1485, -0.0998, -0.1794,  0.1640, -0.2280,\n",
      "           0.0047, -0.1366, -0.1407, -0.2596,  0.2802,  0.1161, -0.0319,\n",
      "          -0.1580, -0.1179,  0.0756, -0.1450, -0.0899,  0.1633,  0.0074,\n",
      "           0.0057,  0.0464,  0.0842,  0.1691,  0.0723, -0.0020, -0.1014,\n",
      "          -0.0436,  0.0570,  0.0587, -0.0239, -0.3969, -0.0022,  0.0220,\n",
      "          -0.0507, -0.0292, -0.0491, -0.0454,  0.0811, -0.2316,  0.0894,\n",
      "           0.2837,  0.1325, -0.0176, -0.1680,  0.1444, -0.0419,  0.1631,\n",
      "          -0.0338, -0.1506, -0.2904,  0.0346, -0.1163,  0.1817, -0.0728,\n",
      "          -0.2018, -0.1218,  0.1545, -0.0417]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9591e-02, -1.8078e+00,  1.3220e+00,  0.0000e+00,\n",
      "          -3.7621e-01,  1.1279e-03,  0.0000e+00,  2.1178e+00, -2.1361e-01,\n",
      "           2.8207e-01,  8.3060e-01,  0.0000e+00,  1.9978e-01,  3.1260e-01,\n",
      "           3.5187e-01, -6.8291e-01,  1.6927e-01,  0.0000e+00,  5.4568e-01,\n",
      "           1.8834e+00,  6.0193e-01, -3.6925e-02, -5.3544e-01,  0.0000e+00,\n",
      "           6.5110e-01, -1.6089e+00, -1.3622e+00, -2.1267e+00, -1.0345e+00,\n",
      "           3.8858e-02, -1.4546e+00, -2.0765e+00,  3.1556e-01, -2.8506e-01,\n",
      "          -2.0017e+00,  2.1891e-01,  9.9700e-01,  6.0141e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.2111e+00, -7.0604e-01,  1.3960e+00,  8.9636e-02,\n",
      "          -1.1384e+00,  2.4256e-01,  7.4203e-01, -7.0953e-01, -1.3359e+00,\n",
      "           1.6085e+00, -1.3743e-01,  6.6255e-01,  0.0000e+00,  5.6736e-01,\n",
      "           3.3300e-01, -4.4959e-01, -8.8797e-01,  1.3380e-01,  6.2825e-01,\n",
      "          -7.0472e-01,  0.0000e+00, -6.9330e-01, -1.5472e+00,  0.0000e+00,\n",
      "           9.5709e-02, -1.7745e-01,  5.9500e-01,  0.0000e+00,  5.5974e-01,\n",
      "           1.8259e-01, -5.1253e-01, -3.4096e-01, -1.1320e+00,  0.0000e+00,\n",
      "           4.6115e-01, -1.0491e+00,  1.1889e-01,  5.1713e-01, -1.8641e-01,\n",
      "          -3.8503e-01,  2.1579e+00,  7.7746e-01, -8.4545e-01,  3.9780e-01,\n",
      "           4.1927e-01,  1.6046e+00, -5.6408e-01,  0.0000e+00, -1.4906e+00,\n",
      "           4.0444e-01, -3.5148e-01,  4.9403e-01, -2.3210e+00,  1.2379e+00,\n",
      "          -9.6294e-01,  1.3203e+00, -9.0732e-01,  2.3908e+00,  9.5511e-01,\n",
      "          -1.2009e+00,  5.9429e-01,  1.0664e+00, -1.7339e+00,  3.6537e-01,\n",
      "           4.0235e-01,  0.0000e+00,  4.5472e-01,  1.9688e+00,  0.0000e+00,\n",
      "          -8.3256e-01,  5.3400e-01,  8.0846e-01,  6.6389e-01, -1.0554e+00,\n",
      "           9.1777e-01, -7.0302e-01, -8.4516e-01,  2.5774e-01,  8.7973e-01,\n",
      "          -8.7708e-01, -1.3962e+00, -3.6480e-01, -1.8463e+00, -1.3006e+00,\n",
      "           0.0000e+00, -8.1161e-01,  6.4932e-01,  2.5566e-01, -1.4897e+00,\n",
      "           2.5020e+00,  3.7783e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -7.5276e-01, -3.8360e-01,  1.2823e+00,  2.2520e+00,  1.9422e-01,\n",
      "          -3.9068e-02,  3.0300e+00,  3.6290e-01, -1.8720e-01, -1.1120e+00,\n",
      "           1.2471e+00,  7.7542e-01,  0.0000e+00, -4.4822e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6515e-01, -2.8968e-01, -2.1305e+00, -5.8171e-01,\n",
      "           7.8597e-01,  0.0000e+00, -1.3047e+00,  1.9038e-01, -3.6288e+00,\n",
      "          -1.8687e+00,  1.1504e+00, -8.5966e-01,  9.5955e-01,  0.0000e+00,\n",
      "          -2.7071e-02,  1.9744e+00,  1.1270e+00, -4.8569e-01, -1.2414e+00,\n",
      "          -2.1245e-01, -1.3225e+00,  0.0000e+00,  0.0000e+00,  6.8263e-01,\n",
      "          -1.3798e+00, -1.2606e-01,  6.0647e-01,  0.0000e+00,  2.5911e-01,\n",
      "           1.3327e+00, -2.5533e+00,  2.7790e-01, -5.8358e-01,  1.6235e+00,\n",
      "          -1.2404e+00, -1.7557e-03, -5.0147e-02,  9.0084e-01,  5.6555e-01,\n",
      "          -4.1984e-01,  3.8846e-01, -1.1560e-01,  8.0972e-01,  1.0504e+00,\n",
      "           0.0000e+00, -1.4389e+00, -4.1542e-01,  0.0000e+00, -4.5410e-01,\n",
      "          -5.4742e-01,  7.2240e-01, -1.8531e+00,  1.3574e+00,  8.3780e-01,\n",
      "          -1.5240e+00, -3.5878e-01,  0.0000e+00,  2.0041e-01,  0.0000e+00,\n",
      "           8.3531e-01, -1.2911e+00, -1.2838e+00,  2.6099e-01, -1.5635e+00,\n",
      "           2.0757e+00,  1.3411e-01,  2.5769e+00, -3.0908e-02, -5.7956e-01,\n",
      "          -1.4281e+00,  1.9011e+00, -3.8092e-01,  1.4695e+00,  8.0527e-01,\n",
      "           3.6924e-01,  6.6980e-01,  0.0000e+00,  8.9032e-02,  1.0254e+00,\n",
      "           9.7831e-01, -1.4083e+00,  0.0000e+00, -1.1450e+00, -1.6455e+00,\n",
      "          -6.0026e-01,  8.8277e-03, -7.1086e-01,  3.7044e-01, -2.2405e-01,\n",
      "          -7.5244e-01,  5.7220e-01,  5.3063e-01, -6.6376e-01,  1.5465e+00,\n",
      "           5.7823e-01,  1.8919e+00, -8.6386e-01,  4.9353e-01, -3.8713e-01,\n",
      "           0.0000e+00,  0.0000e+00,  1.7728e+00, -1.0636e+00, -8.0782e-01,\n",
      "          -6.2201e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0602, 0.1041, 0.1252, 0.1397, 0.0750, 0.1737, 0.0889, 0.0550, 0.0576,\n",
      "         0.1207]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0297,  0.4015, -0.0028,  ...,  0.1338,  0.0976, -0.2278],\n",
      "        [ 0.1996,  0.2765, -0.2993,  ..., -0.1574,  0.2049, -0.2681],\n",
      "        [-0.2764, -0.0884, -0.3502,  ...,  0.1256,  0.1992,  0.0233],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.5459e-02,  1.5910e-02, -2.9860e-01,  6.6754e-02, -8.9834e-03,\n",
      "          -1.4041e-01, -1.4665e-01, -3.1904e-02,  1.5675e-01, -5.8674e-02,\n",
      "          -1.5032e-02,  2.5173e-03, -1.4848e-01, -1.4894e-01, -3.6692e-02,\n",
      "          -9.7074e-02,  2.2402e-01,  1.6355e-01, -2.2755e-02,  1.4100e-01,\n",
      "           6.9270e-02, -1.3114e-01,  1.3697e-01, -1.1189e-01, -1.9373e-01,\n",
      "           1.2869e-01,  1.0293e-01, -1.7568e-01,  2.7119e-02,  9.3139e-03,\n",
      "           6.5575e-02, -2.6735e-01,  3.8934e-02, -1.5289e-01, -1.3252e-02,\n",
      "           1.2139e-01, -8.2698e-02, -1.3990e-01, -6.1614e-02, -1.5062e-02,\n",
      "          -1.9834e-01,  7.0363e-02, -2.4520e-01, -6.8599e-03,  1.9859e-01,\n",
      "           8.6401e-02,  1.4784e-01,  8.8271e-03,  1.5357e-01,  1.1519e-01,\n",
      "          -1.6225e-02, -5.0886e-02, -1.8621e-01, -1.8182e-01, -9.0073e-02,\n",
      "          -1.7194e-01,  3.1151e-02, -3.5242e-02,  8.2398e-02, -7.1117e-02,\n",
      "          -1.7286e-01, -2.2795e-01, -1.5910e-01, -1.4214e-01,  4.3312e-02,\n",
      "          -6.6100e-03,  1.1888e-01,  2.9734e-01, -2.5669e-01,  1.8472e-01,\n",
      "          -4.2062e-02,  9.6964e-02,  1.0674e-01,  2.5910e-01, -8.3334e-02,\n",
      "          -1.2103e-04,  1.8594e-01, -4.0622e-02, -7.2308e-02,  1.4041e-01,\n",
      "          -4.3765e-02, -3.9329e-02, -1.3407e-01,  2.0429e-01,  2.3640e-03,\n",
      "           8.2438e-03,  1.9931e-02,  8.1959e-02, -5.7506e-02, -3.7953e-02,\n",
      "          -7.6535e-02,  1.5330e-01,  4.7858e-02, -2.1148e-01, -8.7771e-02,\n",
      "           1.1861e-02,  1.7957e-01,  1.0217e-01,  2.2730e-01,  3.4707e-01,\n",
      "          -1.6928e-01,  1.1205e-03, -1.6759e-03,  1.2610e-01,  1.1025e-01,\n",
      "          -2.0715e-02,  2.4178e-01,  1.5635e-01, -1.9033e-02,  9.1774e-02,\n",
      "           2.9260e-02,  1.8405e-01, -2.1469e-02, -1.5029e-01,  6.0820e-02,\n",
      "          -8.7805e-02, -1.5819e-01,  3.4699e-03, -2.1753e-01, -9.0158e-02,\n",
      "          -3.8457e-02,  4.2681e-02, -6.0286e-02,  1.0183e-01, -2.8096e-01,\n",
      "           9.1236e-02,  5.4238e-02, -1.1416e-01,  1.4012e-01,  3.9176e-02,\n",
      "          -7.1265e-02, -4.1293e-02,  8.1974e-02, -2.5281e-02,  6.1964e-02,\n",
      "          -9.9314e-03,  2.8339e-01,  7.7003e-02,  1.2448e-01,  8.4909e-02,\n",
      "          -6.4233e-02,  2.8846e-02, -1.4297e-01,  2.3233e-01, -4.9239e-02,\n",
      "           2.5391e-02, -1.3389e-01,  1.6510e-01, -3.1471e-02,  1.5403e-01,\n",
      "          -4.5212e-02,  2.3221e-02, -1.2352e-02,  2.3205e-01, -9.4122e-02,\n",
      "           1.6338e-01, -1.1191e-01,  1.1847e-01, -1.1328e-01, -1.4762e-01,\n",
      "          -1.4058e-02, -7.1620e-02, -1.0140e-01,  1.4591e-01, -1.7535e-01,\n",
      "           3.2458e-02,  1.7791e-02, -2.5280e-01,  1.4931e-01,  1.0450e-02,\n",
      "           5.0351e-03,  3.8268e-02,  1.1638e-01, -6.2844e-02, -4.8076e-02,\n",
      "          -1.4093e-01,  1.3932e-01,  1.6988e-01,  3.8115e-01,  2.7657e-02,\n",
      "          -1.9455e-02, -4.9396e-02,  2.3986e-02,  6.7848e-02,  8.2400e-02,\n",
      "          -1.3089e-01, -1.2875e-01,  1.8906e-04, -1.3358e-01, -6.9554e-02,\n",
      "           8.2186e-02, -9.4799e-03, -2.0138e-01, -1.1225e-01,  7.4738e-02,\n",
      "          -1.0743e-01, -2.0589e-02, -5.9644e-02,  1.5024e-01, -8.0935e-02,\n",
      "          -1.8132e-01,  2.0020e-01, -2.3495e-01,  1.4132e-02, -1.1554e-01,\n",
      "          -2.2219e-01, -2.7691e-01,  2.6837e-01,  8.0260e-02, -6.5114e-03,\n",
      "          -1.0609e-01, -1.4019e-01,  6.9099e-02, -1.3678e-01, -2.4451e-02,\n",
      "           1.7006e-01,  6.9244e-03,  2.4448e-02,  3.0328e-02,  1.0153e-01,\n",
      "           2.1100e-01,  2.9697e-02, -1.5663e-02, -1.0772e-01, -4.3955e-02,\n",
      "           1.0361e-01,  6.9785e-02, -2.5414e-02, -4.1178e-01,  1.0171e-02,\n",
      "          -3.0781e-02, -2.2498e-02, -3.6919e-02, -1.7992e-02, -6.2317e-02,\n",
      "           1.0630e-01, -2.1565e-01,  9.3868e-02,  2.5190e-01,  1.5420e-01,\n",
      "          -2.1690e-02, -2.0081e-01,  1.5210e-01, -8.0032e-02,  1.3105e-01,\n",
      "           1.8281e-02, -1.3327e-01, -3.0670e-01,  6.1259e-02, -5.6850e-02,\n",
      "           1.8622e-01, -5.8206e-02, -2.1930e-01, -1.2437e-01,  1.5534e-01,\n",
      "          -2.1498e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6966e-02,  3.9996e-01, -9.6482e-01, -6.8092e-01,  3.7535e-01,\n",
      "           0.0000e+00,  1.4646e+00, -8.3598e-02, -3.5831e+00,  9.0671e-01,\n",
      "           4.2791e-01, -6.2909e-01,  2.6021e+00, -6.3020e-01, -5.4128e-01,\n",
      "          -1.5795e-01,  8.5127e-01,  1.0942e+00,  4.5522e-01,  4.3616e-01,\n",
      "          -6.3320e-01, -3.8239e-01,  1.6398e+00,  1.5109e+00,  7.5320e-01,\n",
      "          -7.5924e-02, -1.8818e-01, -7.5991e-01,  1.6532e+00,  8.6125e-01,\n",
      "           1.2315e+00,  1.2191e+00, -1.0341e+00, -8.3034e-02, -1.5340e+00,\n",
      "           0.0000e+00,  2.8079e-01, -3.7437e+00,  1.9767e-01,  1.6000e+00,\n",
      "          -4.5897e-01, -1.3978e+00, -2.6889e-01, -1.7143e+00, -1.5233e+00,\n",
      "           0.0000e+00,  5.4045e-01,  3.7116e-01, -1.3402e+00,  0.0000e+00,\n",
      "          -6.2939e-01,  2.7504e+00,  6.1003e-01, -1.0286e+00, -2.4953e-02,\n",
      "           2.0400e-01, -8.8123e-01, -1.2511e+00, -2.3734e-01,  0.0000e+00,\n",
      "           1.0989e+00,  1.4071e+00, -2.0240e-01, -5.0079e-01, -2.9623e+00,\n",
      "           5.5151e-01,  1.2780e+00,  0.0000e+00,  0.0000e+00,  5.2685e-01,\n",
      "          -1.2663e+00, -2.9630e-02,  7.0718e-01,  0.0000e+00,  3.2510e-01,\n",
      "          -6.2518e-04, -1.6007e-01,  1.0614e+00, -5.7363e-02, -1.1798e-01,\n",
      "          -1.3996e+00,  0.0000e+00, -9.2412e-01,  0.0000e+00, -2.0751e-01,\n",
      "           4.3617e-01,  1.6611e+00, -9.7387e-01, -1.0434e-01, -5.8107e-01,\n",
      "          -2.2722e+00,  1.0995e+00, -6.2242e-01, -1.1357e+00,  4.6706e-01,\n",
      "          -1.1700e+00,  3.2943e-02,  6.2886e-01,  1.7191e+00, -7.7849e-01,\n",
      "           0.0000e+00, -1.4616e+00,  1.0759e+00,  1.4527e+00, -6.6608e-01,\n",
      "          -7.6222e-01,  1.2108e+00,  1.2730e-01, -1.4728e+00, -1.3876e-02,\n",
      "          -2.4808e-01,  1.3394e-01, -1.0470e+00,  1.3099e+00, -1.6523e+00,\n",
      "           0.0000e+00, -5.6943e-02, -4.9931e-01, -1.9339e-01,  4.4557e-01,\n",
      "          -1.4648e+00,  7.0200e-01, -1.4600e+00,  0.0000e+00, -9.5763e-01,\n",
      "          -1.3075e+00,  8.9562e-01,  1.6950e-01,  1.2845e+00, -7.5102e-01,\n",
      "          -8.2418e-01,  5.3080e-01, -1.5824e+00,  9.8384e-01,  2.7611e-01,\n",
      "          -5.8903e-01,  6.5845e-01,  0.0000e+00, -1.1590e+00, -1.0093e+00,\n",
      "          -3.8796e-01,  6.7773e-01, -7.8927e-01,  0.0000e+00, -1.6844e+00,\n",
      "          -1.0013e-01, -5.4279e-01, -8.4418e-01, -7.5493e-01,  1.7770e-01,\n",
      "           1.9976e+00, -1.9916e-01, -1.9293e+00, -4.0625e-01,  4.4110e-01,\n",
      "          -1.9440e-01, -6.4905e-02,  0.0000e+00,  3.8998e-02,  5.3736e-01,\n",
      "          -2.6616e-02,  2.2058e+00,  4.8100e-01, -5.5037e-01, -5.2566e-01,\n",
      "          -8.9129e-01,  2.8153e-01,  8.2856e-02, -3.5814e-01, -4.7783e-01,\n",
      "           0.0000e+00, -3.0776e-02,  2.0096e-02, -1.0027e+00,  1.2775e+00,\n",
      "           0.0000e+00, -9.8573e-01, -2.0752e+00,  1.9681e+00,  8.6370e-02,\n",
      "          -3.1047e-02,  3.4999e-02,  0.0000e+00,  9.7981e-01, -7.4766e-01,\n",
      "          -3.4102e-01, -2.7814e+00,  0.0000e+00,  1.2088e+00,  1.0125e+00,\n",
      "           3.0721e+00,  4.9400e-01, -1.4436e-01,  0.0000e+00,  5.5988e-01,\n",
      "           2.1640e+00, -1.1874e+00,  5.3503e-01,  0.0000e+00, -9.4605e-01,\n",
      "          -1.6624e+00, -1.0153e+00,  1.2422e+00, -1.2217e-01,  2.3206e-01,\n",
      "          -5.7460e-01, -2.2917e+00,  6.8173e-01, -1.0731e+00, -4.7102e-01,\n",
      "           0.0000e+00, -5.7316e-01, -3.4121e-01,  7.9271e-01,  3.1684e-02,\n",
      "          -6.8328e-01, -1.0171e+00,  9.6673e-01, -2.4513e-01,  2.1685e+00,\n",
      "          -1.0827e+00, -4.2684e-01, -1.8431e+00, -5.0013e-01,  3.3925e-01,\n",
      "           7.0488e-01, -6.9654e-01, -6.2812e-01,  2.9229e-01, -1.5775e+00,\n",
      "          -1.1081e+00,  1.5812e+00, -6.1368e-01,  1.3100e+00, -2.9789e+00,\n",
      "           4.0333e+00,  5.8511e-01,  4.2940e-02, -1.5784e+00,  0.0000e+00,\n",
      "           7.4203e-01, -3.2463e+00, -3.0363e-01, -8.5154e-01,  1.1320e-02,\n",
      "           2.7563e-01,  2.7464e-01,  2.5218e-01,  2.6152e-01,  3.8672e-01,\n",
      "          -3.6579e-01, -1.5963e-01, -5.5344e-01, -5.2049e-02, -1.1461e+00,\n",
      "          -1.1312e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0399, 0.0635, 0.1076, 0.0499, 0.1279, 0.2907, 0.0605, 0.1013, 0.0606,\n",
      "         0.0983]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0287,  0.4023, -0.0040,  ...,  0.1342,  0.0975, -0.2289],\n",
      "        [ 0.2783,  0.0176,  0.0677,  ...,  0.3888, -0.1904, -0.0165],\n",
      "        [ 0.4908, -0.1104, -0.2107,  ...,  0.3658,  0.1272, -0.0746],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3824e-01,  2.5732e-02, -1.1919e-01,  3.2866e-02, -5.2095e-02,\n",
      "          -3.5514e-02, -5.4358e-02, -1.2319e-01, -5.8508e-02, -9.8880e-02,\n",
      "          -1.2647e-02, -3.8619e-02, -5.5217e-02, -8.4610e-02,  1.7020e-02,\n",
      "          -7.6325e-02,  1.1608e-01,  7.5360e-02, -8.9610e-02,  7.6880e-03,\n",
      "           1.3999e-02, -1.6716e-01,  6.7603e-02, -7.1106e-02, -5.9154e-02,\n",
      "          -7.3102e-03,  7.8255e-02, -6.7094e-02, -1.7852e-02,  9.4904e-03,\n",
      "           3.6282e-02, -1.0321e-01, -4.8813e-02, -9.6642e-02, -5.3399e-02,\n",
      "           1.2136e-01, -3.4425e-02, -1.3039e-01, -9.7409e-02, -2.6435e-02,\n",
      "          -1.0625e-02, -6.7317e-03, -6.9121e-02,  4.0519e-02, -1.3098e-02,\n",
      "           1.3636e-02, -9.5609e-02, -2.9698e-02, -2.2789e-02,  2.5714e-02,\n",
      "           9.8508e-02, -6.6559e-02, -3.2043e-02, -9.7900e-02, -1.2138e-01,\n",
      "          -5.4382e-03,  1.3727e-03,  4.0584e-02,  1.2367e-02,  7.7180e-02,\n",
      "           1.7133e-02, -1.3816e-02, -2.8320e-02, -1.7254e-02,  1.4466e-02,\n",
      "          -3.6246e-02, -6.9904e-02,  1.8365e-01, -1.4747e-01,  3.2434e-02,\n",
      "          -6.0586e-02,  1.1284e-01,  3.2657e-02,  1.0693e-01,  1.3308e-03,\n",
      "           1.9824e-02,  1.1191e-01,  3.6522e-02, -6.5207e-02,  5.4138e-03,\n",
      "          -1.1912e-02, -6.8984e-02, -8.7242e-02,  1.1963e-02,  9.0447e-02,\n",
      "           2.7284e-02,  1.8799e-02,  3.8718e-03,  4.5720e-02,  4.4341e-02,\n",
      "           1.4410e-01,  2.3416e-02,  1.7583e-02, -5.7154e-02, -3.3243e-02,\n",
      "          -4.4646e-02,  1.6724e-01,  7.4740e-02,  4.7758e-02,  1.6332e-01,\n",
      "          -5.7261e-02, -7.6440e-02,  7.1689e-02, -5.3246e-02, -8.2735e-03,\n",
      "           6.9367e-03,  1.2051e-01,  5.3208e-02, -1.7774e-02,  1.2590e-01,\n",
      "           4.3185e-02,  1.8669e-02, -1.1713e-01, -1.0497e-01, -1.1797e-01,\n",
      "           5.9901e-02,  1.7331e-02, -6.8528e-02, -1.0866e-01,  4.9609e-02,\n",
      "           2.0583e-02, -3.9953e-02, -2.2101e-01,  1.9787e-02, -1.8482e-02,\n",
      "          -1.4485e-02,  5.9988e-02, -3.1670e-02,  4.1209e-02,  5.0250e-02,\n",
      "           2.5180e-02, -7.6292e-02,  1.0355e-01,  1.2523e-02, -5.9958e-02,\n",
      "          -6.9780e-03,  2.6677e-02,  6.5494e-02, -1.5219e-02,  5.7691e-02,\n",
      "          -1.5281e-01,  6.7993e-02, -1.5601e-01,  2.4114e-02,  7.1119e-02,\n",
      "          -7.5416e-02, -3.9619e-02,  5.6137e-02,  7.7654e-02,  1.6610e-01,\n",
      "          -4.3080e-03,  2.4306e-02, -1.2719e-01,  3.1204e-02, -5.4250e-02,\n",
      "           1.4575e-01, -5.4100e-02,  4.0587e-03, -2.5225e-02, -1.1468e-01,\n",
      "          -1.0726e-01, -2.9691e-02, -1.9378e-03,  1.4850e-01, -7.1663e-02,\n",
      "          -3.9869e-02,  4.9788e-02, -1.2483e-01,  7.1614e-02,  8.8625e-02,\n",
      "          -1.1962e-01,  3.6758e-02,  1.2880e-01, -4.9137e-02, -1.2846e-01,\n",
      "          -2.0753e-01,  8.3158e-02, -2.0359e-02,  1.2532e-01, -6.1284e-02,\n",
      "          -1.2224e-01, -9.5533e-04, -1.0281e-01,  7.4969e-02,  4.0733e-02,\n",
      "          -7.6312e-02, -1.2229e-01,  6.3695e-02, -6.6331e-02, -2.6708e-02,\n",
      "          -4.3033e-02,  2.0976e-02, -9.3888e-02, -5.0864e-02,  5.9186e-02,\n",
      "          -5.0923e-02,  7.3104e-02, -4.3409e-02,  3.9243e-02, -5.0074e-02,\n",
      "          -6.0153e-02,  7.6599e-02, -4.6099e-02, -3.4873e-02,  1.3014e-01,\n",
      "          -1.3062e-02, -1.0836e-01,  4.7685e-02, -1.0106e-01, -1.1159e-01,\n",
      "          -6.3172e-02, -1.0814e-02,  5.0326e-02,  3.5337e-02, -2.3588e-02,\n",
      "           1.2492e-01, -5.4333e-02, -4.3021e-02, -5.0872e-02,  3.0844e-02,\n",
      "           7.6540e-02, -2.0377e-03, -4.1791e-02,  7.9723e-02, -3.4124e-02,\n",
      "          -1.2394e-02,  5.5282e-02, -1.5184e-01, -1.1782e-01,  6.7725e-02,\n",
      "          -4.8939e-02, -5.3259e-02, -6.2760e-02, -1.0513e-01, -3.7791e-03,\n",
      "           6.7810e-02, -3.1696e-02,  4.2101e-02,  1.1856e-01,  5.0223e-02,\n",
      "           1.0511e-04, -3.2821e-02,  8.3816e-02,  5.0103e-02,  4.8657e-02,\n",
      "          -3.1607e-02, -7.0341e-02,  4.6480e-02,  1.0186e-01,  1.0788e-03,\n",
      "           9.2728e-02, -1.0766e-01, -1.0078e-01,  4.0721e-02,  3.6812e-02,\n",
      "          -2.9906e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4735, -0.4588,  0.0000, -0.1181,  0.4616,  0.0258,  0.6621,\n",
      "           0.5340,  0.6708,  0.9338,  1.7078, -1.0163,  0.9462,  0.0000,\n",
      "          -1.6338,  0.0000,  1.8774, -0.7566, -1.5631, -2.6433,  0.0000,\n",
      "           0.1682,  2.9295,  0.5543, -0.1169,  3.2092,  1.8370,  0.5188,\n",
      "          -2.2264, -1.2857,  0.0293,  1.0134,  0.3249,  0.8598, -0.7985,\n",
      "          -1.4655,  0.6198,  0.0000,  1.9915,  0.1019,  0.4675, -2.2043,\n",
      "          -0.5664, -0.1150, -0.7129, -0.6891,  1.9277,  0.1099, -0.2867,\n",
      "          -1.8506,  1.4678,  0.4622,  0.6674, -0.2832,  0.5317,  0.2749,\n",
      "          -1.2424, -0.9510,  1.8139, -0.0118,  0.2049, -1.8185, -1.4013,\n",
      "          -0.8064,  1.1799,  0.2652, -0.1669, -0.2551, -0.0045, -0.4608,\n",
      "          -0.3251, -0.3240,  0.0000, -0.1264,  0.0000, -0.8063,  0.0000,\n",
      "           1.6794,  0.0878, -0.5458,  1.2269,  0.0866,  0.3267, -1.8363,\n",
      "          -0.0713, -1.7321, -1.4585, -0.8910,  0.6230,  0.8108, -1.2238,\n",
      "          -1.1442,  1.9851, -0.3662, -0.7340,  0.1566,  2.1413, -0.4056,\n",
      "          -0.3042, -1.8394, -1.2905,  0.0000, -0.7663,  0.2371,  0.3819,\n",
      "           1.1139, -1.0702,  2.2523, -0.2628,  0.0000,  0.0000,  0.6106,\n",
      "           0.0000, -0.2803, -1.9420,  1.1284,  1.0063, -2.4973, -0.5749,\n",
      "           0.0297, -1.6949, -0.4011, -0.3792, -0.0785, -0.5368, -1.1110,\n",
      "           1.3045,  0.1695,  0.3222,  1.3584,  2.0790, -2.6341,  0.3596,\n",
      "          -0.7230,  0.4291,  0.0600,  0.3266, -2.1017, -0.4969, -1.6775,\n",
      "           0.0000,  0.2342, -1.1869, -1.2150, -0.6310,  0.0000,  0.4647,\n",
      "           1.7383,  1.5944,  1.4318, -1.2627, -0.5774, -0.4800, -0.0394,\n",
      "           0.3267, -0.1168,  1.3538, -0.0316, -1.9004, -1.8061, -1.4268,\n",
      "          -0.9003, -0.7056, -0.3891, -0.9811, -0.1289,  0.4063,  0.9702,\n",
      "           0.0000, -0.1475,  1.5136, -0.3730, -0.3159, -2.0087,  0.1294,\n",
      "           0.0000, -0.8302, -0.7690, -0.0402, -0.9374,  0.7277,  1.0420,\n",
      "           0.0469,  0.0000,  0.3163, -0.1182, -0.5414, -0.6643,  0.7548,\n",
      "          -1.0641, -0.5869, -1.7883,  1.2675, -0.9262, -1.6148, -0.3333,\n",
      "           0.0000, -1.9607, -0.0720, -0.3753,  2.6975, -0.9216, -2.6314,\n",
      "          -0.5862, -0.7162, -1.3860, -1.2536,  0.0000,  0.0000, -1.1109,\n",
      "           0.9448, -0.6921,  0.0000,  0.3622,  0.2375, -1.4265, -2.3446,\n",
      "           0.0474, -1.4797,  0.4272,  0.0133, -0.9017,  0.0000, -1.1652,\n",
      "          -1.3012,  0.0000,  0.0000,  1.2665, -2.1880, -0.0562,  0.0000,\n",
      "          -1.1752,  0.9561,  1.9991,  0.5272,  0.7890, -0.6786,  0.1045,\n",
      "          -0.6803, -2.2620,  0.1674, -0.3136, -1.0432, -0.3820, -1.0800,\n",
      "           0.5578,  0.0000, -0.5646, -1.3771,  1.2434,  0.5826,  0.0000,\n",
      "           1.9514,  0.3626,  0.4874,  0.3901]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0289, 0.2643, 0.0964, 0.0593, 0.0989, 0.1194, 0.0284, 0.1634, 0.0815,\n",
      "         0.0597]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0287,  0.4023, -0.0040,  ...,  0.1342,  0.0975, -0.2289],\n",
      "        [ 0.2783,  0.0176,  0.0677,  ...,  0.3888, -0.1904, -0.0165],\n",
      "        [ 0.4908, -0.1104, -0.2107,  ...,  0.3658,  0.1272, -0.0746],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1797,  0.0175, -0.0870,  0.0924,  0.0174, -0.0045, -0.0698,\n",
      "          -0.1161, -0.1025, -0.1975, -0.0517, -0.0153, -0.1138, -0.1639,\n",
      "          -0.0032, -0.0865,  0.1594,  0.1003, -0.1049,  0.0342,  0.0669,\n",
      "          -0.2374,  0.1615, -0.1669, -0.0553,  0.0059,  0.1480, -0.0496,\n",
      "           0.0614,  0.0342,  0.0379, -0.1031, -0.0078, -0.1521, -0.1352,\n",
      "           0.1853, -0.0269, -0.1410, -0.1136, -0.0751,  0.0086, -0.0312,\n",
      "          -0.1065,  0.0531,  0.0287, -0.0742, -0.1503,  0.0534, -0.1085,\n",
      "           0.1202,  0.1265, -0.0762, -0.0056, -0.1985, -0.1731, -0.0392,\n",
      "           0.0141,  0.0302, -0.0782,  0.1110,  0.0530,  0.0788,  0.0069,\n",
      "           0.0038,  0.0682,  0.0317, -0.0921,  0.2533, -0.1979,  0.0053,\n",
      "          -0.0533,  0.0747,  0.0686,  0.0927,  0.0491, -0.0740,  0.1228,\n",
      "           0.0443, -0.1013, -0.0064, -0.0239, -0.0323, -0.0798,  0.0906,\n",
      "           0.1135, -0.0337,  0.0055, -0.0668,  0.0180,  0.1080,  0.1981,\n",
      "           0.0386,  0.1067, -0.1550, -0.0562,  0.0036,  0.2487,  0.0942,\n",
      "           0.0872,  0.1986, -0.0122, -0.1018,  0.0163, -0.0645,  0.0169,\n",
      "           0.0401,  0.2291,  0.0970, -0.0418,  0.1862,  0.1124,  0.0461,\n",
      "          -0.2410, -0.1313, -0.1037,  0.1109,  0.0655, -0.1206, -0.1129,\n",
      "           0.0314,  0.0062,  0.0297, -0.2516, -0.0313,  0.0733, -0.0321,\n",
      "           0.1058, -0.0216, -0.0188,  0.0578,  0.0052, -0.0758,  0.1632,\n",
      "          -0.0607, -0.0446, -0.0377,  0.0048,  0.0668, -0.0069,  0.0707,\n",
      "          -0.2145,  0.0524, -0.2224,  0.0782, -0.0101, -0.0818, -0.0262,\n",
      "           0.0036,  0.1020,  0.2822,  0.1500,  0.0060, -0.1645, -0.0083,\n",
      "          -0.0673,  0.2092, -0.0826, -0.0006, -0.0615, -0.2277, -0.2100,\n",
      "          -0.0872,  0.0791,  0.2149, -0.1053, -0.0967,  0.0687, -0.1400,\n",
      "           0.0166,  0.1336, -0.1634,  0.0573,  0.2298, -0.1045, -0.1593,\n",
      "          -0.2868,  0.0478, -0.0086,  0.1624, -0.0017, -0.1526, -0.0005,\n",
      "          -0.1030,  0.1462,  0.0434, -0.1531, -0.1463,  0.0311, -0.1838,\n",
      "          -0.0618, -0.0727, -0.0278, -0.0370, -0.0740,  0.0270,  0.0316,\n",
      "           0.1768, -0.0881,  0.1262, -0.0780, -0.0208,  0.1436, -0.0284,\n",
      "          -0.1246,  0.1428,  0.0203, -0.0735, -0.0422, -0.0982, -0.1539,\n",
      "          -0.0583,  0.0337,  0.0509,  0.0999, -0.0614,  0.1411,  0.0213,\n",
      "          -0.1243,  0.0506,  0.0451,  0.0809,  0.0398, -0.0953,  0.1486,\n",
      "          -0.1017, -0.0409,  0.0674, -0.1960, -0.0990,  0.0976, -0.0303,\n",
      "          -0.1431, -0.1222, -0.0844,  0.0073,  0.1023,  0.0021,  0.0508,\n",
      "           0.1810,  0.0909,  0.0356, -0.0827,  0.2033,  0.0570,  0.0726,\n",
      "          -0.0565, -0.1321,  0.0668,  0.0764, -0.0284,  0.1126, -0.1517,\n",
      "          -0.1180,  0.1158, -0.0028, -0.0299]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9498e-02, -1.8078e+00,  0.0000e+00,  5.1606e-01,\n",
      "          -3.7619e-01,  0.0000e+00, -7.2292e-01,  2.1178e+00, -2.1360e-01,\n",
      "           2.8202e-01,  8.3059e-01, -1.1106e+00,  1.9982e-01,  3.1259e-01,\n",
      "           0.0000e+00, -6.8290e-01,  1.6931e-01,  8.7449e-01,  5.4571e-01,\n",
      "           1.8833e+00,  6.0194e-01, -3.6915e-02, -5.3544e-01, -1.0049e-01,\n",
      "           6.5101e-01, -1.6088e+00, -1.3622e+00, -2.1266e+00, -1.0346e+00,\n",
      "           3.8845e-02, -1.4546e+00,  0.0000e+00,  3.1549e-01, -2.8511e-01,\n",
      "          -2.0017e+00,  2.1887e-01,  9.9700e-01,  6.0137e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.2111e+00, -7.0609e-01,  1.3960e+00,  8.9579e-02,\n",
      "          -1.1384e+00,  2.4252e-01,  7.4200e-01, -7.0953e-01, -1.3358e+00,\n",
      "           1.6085e+00, -1.3744e-01,  6.6258e-01,  1.1165e+00,  5.6734e-01,\n",
      "           3.3308e-01,  0.0000e+00, -8.8797e-01,  0.0000e+00,  6.2828e-01,\n",
      "           0.0000e+00,  5.6352e-01, -6.9328e-01, -1.5472e+00,  2.8930e-01,\n",
      "           0.0000e+00, -1.7745e-01,  5.9498e-01, -2.1387e+00,  5.5975e-01,\n",
      "           1.8262e-01, -5.1255e-01, -3.4095e-01,  0.0000e+00, -6.4747e-01,\n",
      "           4.6111e-01, -1.0491e+00,  1.1891e-01,  5.1719e-01, -1.8645e-01,\n",
      "          -3.8499e-01,  2.1579e+00,  7.7740e-01, -8.4543e-01,  3.9781e-01,\n",
      "           4.1926e-01,  1.6046e+00, -5.6408e-01, -1.4131e+00, -1.4905e+00,\n",
      "           0.0000e+00, -3.5151e-01,  4.9405e-01, -2.3210e+00,  0.0000e+00,\n",
      "          -9.6289e-01,  0.0000e+00,  0.0000e+00,  2.3908e+00,  9.5513e-01,\n",
      "          -1.2009e+00,  5.9436e-01,  1.0664e+00, -1.7339e+00,  3.6530e-01,\n",
      "           4.0232e-01, -1.2704e+00,  4.5473e-01,  1.9688e+00,  1.4960e-01,\n",
      "          -8.3252e-01,  5.3400e-01,  0.0000e+00,  6.6395e-01, -1.0553e+00,\n",
      "           9.1778e-01, -7.0300e-01, -8.4515e-01,  0.0000e+00,  8.7975e-01,\n",
      "          -8.7702e-01, -1.3962e+00, -3.6485e-01, -1.8463e+00,  0.0000e+00,\n",
      "           1.0693e+00, -8.1162e-01,  6.4924e-01,  2.5567e-01, -1.4896e+00,\n",
      "           2.5020e+00,  3.7782e-01, -1.3453e+00,  7.2224e-01,  3.2009e+00,\n",
      "          -7.5276e-01, -3.8358e-01,  1.2823e+00,  2.2520e+00,  1.9421e-01,\n",
      "          -3.9116e-02,  3.0301e+00,  3.6283e-01, -1.8720e-01, -1.1119e+00,\n",
      "           1.2472e+00,  7.7543e-01, -7.7477e-01,  0.0000e+00, -1.3869e+00,\n",
      "           2.3360e+00,  7.6510e-01, -2.8969e-01, -2.1305e+00, -5.8171e-01,\n",
      "           7.8595e-01, -1.8620e+00, -1.3047e+00,  1.9037e-01, -3.6288e+00,\n",
      "          -1.8687e+00,  1.1504e+00, -8.5965e-01,  9.5955e-01, -1.4612e+00,\n",
      "          -2.7051e-02,  1.9745e+00,  1.1270e+00, -4.8574e-01, -1.2414e+00,\n",
      "          -2.1238e-01, -1.3225e+00, -1.6391e+00, -7.7172e-01,  6.8261e-01,\n",
      "          -1.3797e+00, -1.2606e-01,  6.0652e-01, -7.4901e-01,  2.5911e-01,\n",
      "           0.0000e+00, -2.5534e+00,  2.7787e-01, -5.8364e-01,  1.6235e+00,\n",
      "          -1.2404e+00, -1.7516e-03, -5.0175e-02,  9.0086e-01,  5.6559e-01,\n",
      "          -4.1985e-01,  3.8841e-01, -1.1561e-01,  0.0000e+00,  1.0504e+00,\n",
      "          -7.8927e-01, -1.4389e+00, -4.1545e-01, -7.5030e-01, -4.5408e-01,\n",
      "          -5.4748e-01,  7.2232e-01, -1.8531e+00,  1.3574e+00,  8.3776e-01,\n",
      "          -1.5240e+00, -3.5882e-01,  6.4765e-01,  2.0047e-01, -2.1782e+00,\n",
      "           8.3532e-01, -1.2911e+00,  0.0000e+00,  2.6102e-01, -1.5634e+00,\n",
      "           2.0757e+00,  1.3415e-01,  2.5769e+00, -3.0934e-02, -5.7956e-01,\n",
      "          -1.4282e+00,  0.0000e+00, -3.8088e-01,  1.4696e+00,  8.0524e-01,\n",
      "           3.6922e-01,  6.6984e-01, -7.0039e-01,  8.9034e-02,  1.0254e+00,\n",
      "           9.7829e-01, -1.4083e+00,  6.5955e-01, -1.1450e+00, -1.6455e+00,\n",
      "          -6.0026e-01,  8.8349e-03, -7.1089e-01,  3.7045e-01, -2.2407e-01,\n",
      "          -7.5242e-01,  5.7220e-01,  5.3066e-01, -6.6375e-01,  1.5465e+00,\n",
      "           5.7825e-01,  0.0000e+00,  0.0000e+00,  4.9357e-01, -3.8713e-01,\n",
      "           4.9998e-01, -9.7503e-01,  1.7728e+00, -1.0636e+00, -8.0776e-01,\n",
      "          -6.2196e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0586, 0.0854, 0.1468, 0.1467, 0.0990, 0.1740, 0.0627, 0.0565, 0.0627,\n",
      "         0.1076]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0287,  0.4023, -0.0040,  ...,  0.1342,  0.0975, -0.2289],\n",
      "        [ 0.2783,  0.0176,  0.0677,  ...,  0.3888, -0.1904, -0.0165],\n",
      "        [ 0.4908, -0.1104, -0.2107,  ...,  0.3658,  0.1272, -0.0746],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.8073e-01,  4.2228e-03, -1.3807e-01,  2.3235e-02, -4.8937e-02,\n",
      "          -3.9912e-02, -1.0624e-01, -1.5174e-01, -1.0696e-01, -1.4631e-01,\n",
      "          -4.6840e-02, -1.7640e-02, -7.5018e-02, -9.3572e-02,  1.4749e-02,\n",
      "          -1.0881e-01,  1.4613e-01,  1.2651e-01, -1.2121e-01, -2.4528e-03,\n",
      "           3.4054e-02, -2.4152e-01,  1.0028e-01, -1.4038e-01, -6.4245e-02,\n",
      "           2.1407e-02,  1.6807e-01, -8.6859e-02, -2.2270e-02,  3.3522e-02,\n",
      "           6.6794e-02, -1.1622e-01, -4.9532e-02, -1.4139e-01, -8.9899e-02,\n",
      "           1.4795e-01, -4.0822e-02, -1.7779e-01, -1.0726e-01, -8.2523e-03,\n",
      "          -9.3322e-03,  2.1833e-02, -7.2404e-02,  5.5986e-02, -7.5804e-02,\n",
      "           2.5785e-02, -1.2090e-01, -1.1636e-02, -3.1788e-02,  2.7146e-02,\n",
      "           1.7089e-01, -9.0068e-02, -2.5959e-02, -1.4167e-01, -1.7242e-01,\n",
      "          -9.0579e-03,  7.7004e-03,  4.1152e-02,  1.4423e-02,  7.4740e-02,\n",
      "           3.6533e-02, -3.4013e-02, -2.7833e-02, -1.3909e-02,  1.7636e-05,\n",
      "          -6.1385e-02, -1.0436e-01,  2.5755e-01, -2.1602e-01,  4.7400e-02,\n",
      "          -7.1163e-02,  1.6183e-01,  5.7576e-02,  1.3502e-01,  3.6889e-02,\n",
      "           6.5628e-02,  1.5896e-01,  3.5391e-02, -7.6815e-02,  3.3306e-03,\n",
      "           1.2153e-02, -2.5904e-02, -1.0299e-01,  3.9037e-02,  1.3709e-01,\n",
      "           1.9448e-02,  5.4195e-02,  2.1351e-02,  6.3685e-02,  9.4548e-02,\n",
      "           1.9480e-01,  2.3131e-02,  7.3637e-03, -1.0039e-01, -3.1830e-02,\n",
      "          -4.7397e-02,  2.2728e-01,  6.6271e-02,  1.0774e-01,  2.0508e-01,\n",
      "          -4.7021e-02, -8.1654e-02,  8.0980e-02, -1.1042e-01,  4.5592e-02,\n",
      "           1.4568e-02,  1.5569e-01,  8.5318e-02, -3.3540e-02,  1.7377e-01,\n",
      "           3.4517e-02,  4.4079e-02, -1.9482e-01, -1.1419e-01, -1.5685e-01,\n",
      "           1.0562e-01,  2.9552e-02, -8.5158e-02, -1.6986e-01,  9.3567e-02,\n",
      "           1.1022e-02, -3.4775e-02, -3.0395e-01,  4.0153e-02, -3.5455e-02,\n",
      "          -2.2718e-02,  7.7952e-02, -4.2618e-02,  3.5707e-02,  7.6716e-02,\n",
      "           2.9725e-02, -6.2667e-02,  1.2244e-01,  2.5216e-02, -6.8154e-02,\n",
      "          -4.3207e-02, -1.9455e-02,  1.1680e-01,  1.4995e-02,  8.6823e-02,\n",
      "          -2.2867e-01,  8.6320e-02, -2.4541e-01, -3.6249e-03,  8.5802e-02,\n",
      "          -1.0168e-01, -5.1002e-02,  7.3775e-02,  1.2640e-01,  2.3020e-01,\n",
      "           8.3916e-03,  5.3296e-02, -1.9550e-01,  2.9983e-02, -6.5299e-02,\n",
      "           2.0275e-01, -6.6230e-02,  3.4270e-03, -7.0555e-02, -1.2810e-01,\n",
      "          -1.4529e-01, -1.3454e-02,  1.6797e-02,  1.9372e-01, -1.4579e-01,\n",
      "          -7.4736e-02,  5.3344e-02, -1.6164e-01,  4.0667e-02,  5.6812e-02,\n",
      "          -1.8700e-01,  5.5685e-02,  1.6136e-01, -2.8012e-02, -1.6629e-01,\n",
      "          -3.0249e-01,  1.3507e-01, -4.7711e-02,  1.4091e-01, -1.0378e-01,\n",
      "          -1.7584e-01,  8.2403e-03, -1.4944e-01,  9.0159e-02,  6.2363e-02,\n",
      "          -1.2484e-01, -1.0577e-01,  5.9942e-02, -1.5144e-01, -3.3355e-02,\n",
      "          -4.6402e-02,  1.6978e-02, -1.0068e-01, -6.3417e-02,  5.1957e-02,\n",
      "          -6.1521e-02,  1.3419e-01, -5.7548e-02,  5.8568e-02, -1.1527e-01,\n",
      "          -7.6845e-02,  9.1831e-02, -7.4636e-02, -9.5760e-02,  1.5848e-01,\n",
      "          -3.2839e-02, -1.5230e-01,  3.8932e-02, -1.3414e-01, -1.7723e-01,\n",
      "          -1.3273e-01,  2.1787e-02,  6.2123e-02,  4.5061e-02, -3.0298e-02,\n",
      "           1.4568e-01, -2.8955e-02, -6.8412e-02, -6.7837e-02,  8.7957e-03,\n",
      "           8.6580e-02,  2.9939e-02, -8.0635e-02,  1.5201e-01, -8.0633e-02,\n",
      "          -2.2937e-02,  3.9656e-02, -2.1866e-01, -1.6616e-01,  7.0628e-02,\n",
      "          -1.2156e-02, -8.8173e-02, -1.0857e-01, -1.1097e-01,  1.5754e-02,\n",
      "           1.0694e-01, -3.8719e-02,  7.0221e-02,  1.7782e-01,  6.9604e-02,\n",
      "           1.1129e-03, -2.7712e-02,  1.7785e-01,  1.0644e-01,  7.8472e-02,\n",
      "          -6.4016e-02, -9.0066e-02,  7.7382e-02,  1.1409e-01, -6.4165e-02,\n",
      "           1.2732e-01, -1.4802e-01, -1.1841e-01,  5.2149e-02,  7.4966e-02,\n",
      "          -4.8955e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00,  0.0000e+00,  0.0000e+00,  1.3220e+00,  5.1606e-01,\n",
      "          -3.7619e-01,  1.1276e-03, -7.2292e-01,  2.1178e+00, -2.1360e-01,\n",
      "           2.8202e-01,  8.3059e-01, -1.1106e+00,  1.9982e-01,  3.1259e-01,\n",
      "           3.5181e-01, -6.8290e-01,  1.6931e-01,  8.7449e-01,  5.4571e-01,\n",
      "           1.8833e+00,  6.0194e-01, -3.6915e-02, -5.3544e-01, -1.0049e-01,\n",
      "           6.5101e-01,  0.0000e+00, -1.3622e+00, -2.1266e+00, -1.0346e+00,\n",
      "           3.8845e-02, -1.4546e+00, -2.0765e+00,  3.1549e-01, -2.8511e-01,\n",
      "          -2.0017e+00,  2.1887e-01,  0.0000e+00,  6.0137e-01,  9.5348e-01,\n",
      "          -2.2513e-01, -2.2111e+00, -7.0609e-01,  1.3960e+00,  8.9579e-02,\n",
      "          -1.1384e+00,  2.4252e-01,  7.4200e-01, -7.0953e-01, -1.3358e+00,\n",
      "           1.6085e+00, -1.3744e-01,  6.6258e-01,  1.1165e+00,  5.6734e-01,\n",
      "           3.3308e-01, -4.4962e-01, -8.8797e-01,  1.3384e-01,  6.2828e-01,\n",
      "          -7.0475e-01,  0.0000e+00, -6.9328e-01, -1.5472e+00,  2.8930e-01,\n",
      "           9.5750e-02,  0.0000e+00,  5.9498e-01, -2.1387e+00,  5.5975e-01,\n",
      "           1.8262e-01, -5.1255e-01, -3.4095e-01,  0.0000e+00, -6.4747e-01,\n",
      "           4.6111e-01, -1.0491e+00,  1.1891e-01,  5.1719e-01, -1.8645e-01,\n",
      "          -3.8499e-01,  2.1579e+00,  7.7740e-01, -8.4543e-01,  3.9781e-01,\n",
      "           4.1926e-01,  1.6046e+00, -5.6408e-01, -1.4131e+00,  0.0000e+00,\n",
      "           4.0443e-01, -3.5151e-01,  4.9405e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -9.6289e-01,  1.3202e+00, -9.0733e-01,  2.3908e+00,  9.5513e-01,\n",
      "          -1.2009e+00,  0.0000e+00,  0.0000e+00, -1.7339e+00,  3.6530e-01,\n",
      "           4.0232e-01, -1.2704e+00,  4.5473e-01,  1.9688e+00,  1.4960e-01,\n",
      "          -8.3252e-01,  5.3400e-01,  8.0849e-01,  6.6395e-01, -1.0553e+00,\n",
      "           9.1778e-01, -7.0300e-01, -8.4515e-01,  2.5775e-01,  8.7975e-01,\n",
      "          -8.7702e-01, -1.3962e+00, -3.6485e-01, -1.8463e+00, -1.3006e+00,\n",
      "           1.0693e+00, -8.1162e-01,  6.4924e-01,  2.5567e-01, -1.4896e+00,\n",
      "           2.5020e+00,  3.7782e-01, -1.3453e+00,  0.0000e+00,  3.2009e+00,\n",
      "          -7.5276e-01, -3.8358e-01,  1.2823e+00,  2.2520e+00,  1.9421e-01,\n",
      "          -3.9116e-02,  3.0301e+00,  3.6283e-01, -1.8720e-01, -1.1119e+00,\n",
      "           1.2472e+00,  0.0000e+00, -7.7477e-01, -4.4825e-02, -1.3869e+00,\n",
      "           2.3360e+00,  0.0000e+00, -2.8969e-01, -2.1305e+00, -5.8171e-01,\n",
      "           7.8595e-01, -1.8620e+00, -1.3047e+00,  1.9037e-01,  0.0000e+00,\n",
      "          -1.8687e+00,  1.1504e+00, -8.5965e-01,  9.5955e-01, -1.4612e+00,\n",
      "           0.0000e+00,  1.9745e+00,  1.1270e+00, -4.8574e-01, -1.2414e+00,\n",
      "           0.0000e+00, -1.3225e+00, -1.6391e+00, -7.7172e-01,  6.8261e-01,\n",
      "          -1.3797e+00, -1.2606e-01,  6.0652e-01, -7.4901e-01,  2.5911e-01,\n",
      "           1.3327e+00, -2.5534e+00,  0.0000e+00, -5.8364e-01,  1.6235e+00,\n",
      "          -1.2404e+00, -1.7516e-03,  0.0000e+00,  9.0086e-01,  5.6559e-01,\n",
      "          -4.1985e-01,  3.8841e-01, -1.1561e-01,  8.0971e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.4389e+00, -4.1545e-01, -7.5030e-01, -4.5408e-01,\n",
      "          -5.4748e-01,  7.2232e-01,  0.0000e+00,  1.3574e+00,  8.3776e-01,\n",
      "          -1.5240e+00, -3.5882e-01,  6.4765e-01,  2.0047e-01, -2.1782e+00,\n",
      "           8.3532e-01, -1.2911e+00,  0.0000e+00,  2.6102e-01, -1.5634e+00,\n",
      "           2.0757e+00,  1.3415e-01,  2.5769e+00, -3.0934e-02, -5.7956e-01,\n",
      "          -1.4282e+00,  1.9011e+00, -3.8088e-01,  1.4696e+00,  8.0524e-01,\n",
      "           3.6922e-01,  6.6984e-01, -7.0039e-01,  8.9034e-02,  1.0254e+00,\n",
      "           9.7829e-01, -1.4083e+00,  6.5955e-01,  0.0000e+00, -1.6455e+00,\n",
      "          -6.0026e-01,  8.8349e-03, -7.1089e-01,  3.7045e-01, -2.2407e-01,\n",
      "          -7.5242e-01,  5.7220e-01,  5.3066e-01, -6.6375e-01,  1.5465e+00,\n",
      "           5.7825e-01,  1.8919e+00, -8.6397e-01,  4.9357e-01, -3.8713e-01,\n",
      "           4.9998e-01, -9.7503e-01,  1.7728e+00, -1.0636e+00, -8.0776e-01,\n",
      "          -6.2196e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0658, 0.1058, 0.1444, 0.1122, 0.0970, 0.1738, 0.0817, 0.0597, 0.0580,\n",
      "         0.1016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0287,  0.4023, -0.0040,  ...,  0.1342,  0.0975, -0.2289],\n",
      "        [ 0.2783,  0.0176,  0.0677,  ...,  0.3888, -0.1904, -0.0165],\n",
      "        [ 0.4908, -0.1104, -0.2107,  ...,  0.3658,  0.1272, -0.0746],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1736,  0.0138, -0.1238,  0.0387, -0.0365, -0.0326, -0.0959,\n",
      "          -0.1409, -0.1005, -0.1434, -0.0469, -0.0212, -0.0728, -0.1066,\n",
      "           0.0075, -0.1033,  0.1478,  0.1152, -0.1016,  0.0095,  0.0307,\n",
      "          -0.2334,  0.1017, -0.1375, -0.0605,  0.0131,  0.1559, -0.0753,\n",
      "          -0.0100,  0.0240,  0.0530, -0.1124, -0.0403, -0.1239, -0.0935,\n",
      "           0.1501, -0.0374, -0.1699, -0.1050, -0.0258, -0.0125,  0.0082,\n",
      "          -0.0771,  0.0503, -0.0504,  0.0047, -0.1240,  0.0053, -0.0439,\n",
      "           0.0448,  0.1597, -0.0848, -0.0203, -0.1469, -0.1677, -0.0056,\n",
      "           0.0127,  0.0349,  0.0034,  0.0764,  0.0323, -0.0085, -0.0147,\n",
      "          -0.0180,  0.0147, -0.0441, -0.0906,  0.2425, -0.2035,  0.0362,\n",
      "          -0.0712,  0.1352,  0.0562,  0.1282,  0.0402,  0.0387,  0.1515,\n",
      "           0.0284, -0.0794,  0.0023,  0.0067, -0.0345, -0.0910,  0.0451,\n",
      "           0.1352,  0.0117,  0.0428,  0.0016,  0.0501,  0.0873,  0.1883,\n",
      "           0.0290,  0.0256, -0.1030, -0.0400, -0.0494,  0.2237,  0.0722,\n",
      "           0.0968,  0.1980, -0.0461, -0.0961,  0.0731, -0.1021,  0.0354,\n",
      "           0.0252,  0.1617,  0.0730, -0.0307,  0.1618,  0.0471,  0.0390,\n",
      "          -0.1939, -0.1145, -0.1425,  0.1023,  0.0318, -0.0905, -0.1516,\n",
      "           0.0809,  0.0142, -0.0206, -0.2819,  0.0265, -0.0098, -0.0224,\n",
      "           0.0836, -0.0405,  0.0280,  0.0765,  0.0292, -0.0657,  0.1231,\n",
      "           0.0096, -0.0618, -0.0388, -0.0162,  0.0994,  0.0102,  0.0783,\n",
      "          -0.2099,  0.0765, -0.2341,  0.0113,  0.0651, -0.0905, -0.0493,\n",
      "           0.0597,  0.1103,  0.2319,  0.0446,  0.0336, -0.1807,  0.0211,\n",
      "          -0.0688,  0.1921, -0.0671,  0.0010, -0.0679, -0.1421, -0.1509,\n",
      "          -0.0292,  0.0286,  0.1835, -0.1306, -0.0783,  0.0587, -0.1506,\n",
      "           0.0423,  0.0732, -0.1708,  0.0476,  0.1653, -0.0449, -0.1741,\n",
      "          -0.2902,  0.1210, -0.0464,  0.1351, -0.0789, -0.1648,  0.0093,\n",
      "          -0.1310,  0.1013,  0.0478, -0.1253, -0.1145,  0.0536, -0.1452,\n",
      "          -0.0275, -0.0537,  0.0012, -0.0901, -0.0628,  0.0513, -0.0409,\n",
      "           0.1357, -0.0664,  0.0700, -0.1041, -0.0765,  0.0937, -0.0717,\n",
      "          -0.0951,  0.1562, -0.0232, -0.1436,  0.0204, -0.1209, -0.1637,\n",
      "          -0.1158,  0.0241,  0.0577,  0.0450, -0.0332,  0.1422, -0.0317,\n",
      "          -0.0806, -0.0453,  0.0156,  0.0833,  0.0268, -0.0877,  0.1435,\n",
      "          -0.0851, -0.0260,  0.0430, -0.2036, -0.1415,  0.0722, -0.0186,\n",
      "          -0.0893, -0.1022, -0.0998,  0.0175,  0.1039, -0.0271,  0.0662,\n",
      "           0.1683,  0.0635,  0.0020, -0.0243,  0.1748,  0.0898,  0.0786,\n",
      "          -0.0606, -0.0894,  0.0796,  0.1072, -0.0477,  0.1247, -0.1426,\n",
      "          -0.1139,  0.0670,  0.0578, -0.0462]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0869,  0.3999, -0.9649, -0.6809,  0.0000,  0.0000,  1.4646,\n",
      "          -0.0835, -3.5832,  0.9066,  0.4280, -0.6291,  2.6023, -0.6301,\n",
      "          -0.5413, -0.1579,  0.8512,  1.0942,  0.4552,  0.0000, -0.6332,\n",
      "          -0.3824,  1.6399,  1.5108,  0.7532, -0.0760, -0.1882, -0.7598,\n",
      "           0.0000,  0.0000,  1.2315,  1.2191, -1.0341, -0.0830, -1.5341,\n",
      "           1.3954,  0.2809, -3.7438,  0.1977,  1.6001, -0.4589, -1.3978,\n",
      "           0.0000, -1.7144, -1.5233,  0.6677,  0.5405,  0.3712, -1.3402,\n",
      "           0.1445, -0.6294,  2.7505,  0.6101, -1.0286, -0.0250,  0.2039,\n",
      "          -0.8813, -1.2512, -0.2373, -0.4261,  1.0991,  1.4072, -0.2025,\n",
      "          -0.5009, -2.9624,  0.5514,  1.2781, -1.2873,  0.4101,  0.5268,\n",
      "          -1.2664, -0.0297,  0.7072, -3.6395,  0.0000,  0.0000, -0.1601,\n",
      "           1.0615,  0.0000, -0.1181, -1.3997,  2.1299, -0.9242,  1.0059,\n",
      "          -0.2075,  0.4361,  1.6611, -0.9739, -0.1043, -0.5811, -2.2723,\n",
      "           1.0996, -0.6224, -1.1357,  0.4671, -1.1700,  0.0331,  0.6289,\n",
      "           1.7191, -0.7786,  2.6967,  0.0000,  1.0759,  1.4528, -0.6661,\n",
      "          -0.7623,  1.2109,  0.1272, -1.4729, -0.0138, -0.2481,  0.1341,\n",
      "          -1.0471,  1.3099, -1.6523, -2.9877, -0.0569, -0.4994, -0.1934,\n",
      "           0.4456, -1.4649,  0.7021,  0.0000, -0.7256, -0.9577, -1.3077,\n",
      "           0.8958,  0.0000,  0.0000, -0.7510, -0.8242,  0.5307, -1.5824,\n",
      "           0.9839,  0.2761, -0.5891,  0.6585,  0.5755, -1.1590, -1.0094,\n",
      "          -0.3880,  0.6777, -0.7894, -0.1006, -1.6845, -0.1002, -0.5428,\n",
      "          -0.8442, -0.7550,  0.1777,  1.9977, -0.1992,  0.0000, -0.4062,\n",
      "           0.4411,  0.0000, -0.0649, -0.1305,  0.0390,  0.5374, -0.0266,\n",
      "           2.2058,  0.4810, -0.5503, -0.5258, -0.8914,  0.2815,  0.0829,\n",
      "          -0.3581, -0.4779,  0.7361, -0.0308,  0.0201, -1.0026,  1.2775,\n",
      "          -1.0976, -0.9858, -2.0753,  1.9681,  0.0864, -0.0310,  0.0350,\n",
      "           0.6706,  0.0000, -0.7476, -0.3410,  0.0000,  0.0000,  0.0000,\n",
      "           1.0125,  3.0722,  0.4941, -0.1444,  0.0000,  0.0000,  2.1641,\n",
      "          -1.1874,  0.5351,  1.8107, -0.9461, -1.6624, -1.0153,  1.2422,\n",
      "          -0.1221,  0.2320, -0.5746, -2.2918,  0.6816, -1.0733, -0.4710,\n",
      "           2.8670, -0.5732, -0.3412,  0.7927,  0.0315, -0.6833, -1.0172,\n",
      "           0.9667, -0.2451,  2.1686, -1.0826, -0.4269, -1.8431, -0.5002,\n",
      "           0.3391,  0.7049, -0.6965, -0.6281,  0.2923, -1.5775, -1.1082,\n",
      "           1.5812, -0.6136,  0.0000, -2.9789,  4.0335,  0.5851,  0.0430,\n",
      "          -1.5785, -0.2860,  0.7420, -3.2465, -0.3037, -0.8516,  0.0113,\n",
      "           0.0000,  0.2746,  0.2522,  0.2615,  0.3866, -0.3657, -0.1596,\n",
      "          -0.5535, -0.0522, -1.1461, -1.1313]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0580, 0.0578, 0.1123, 0.0663, 0.1352, 0.2577, 0.0510, 0.0714, 0.0531,\n",
      "         0.1372]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0288,  0.4029, -0.0047,  ...,  0.1345,  0.0973, -0.2314],\n",
      "        [ 0.2024,  0.2797, -0.3022,  ..., -0.1545,  0.2033, -0.2727],\n",
      "        [ 0.0197,  0.5314,  0.1410,  ..., -0.1513,  0.3358, -0.0984],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.4786e-02,  1.8798e-01, -1.0177e-01,  6.3501e-02,  7.9022e-03,\n",
      "          -9.7711e-02, -1.7005e-02, -9.0453e-02,  1.2883e-01, -1.7854e-03,\n",
      "           2.6745e-02, -3.1844e-03, -1.2284e-01, -6.4496e-02,  5.5012e-02,\n",
      "          -3.2049e-02,  1.1591e-01,  2.0756e-02, -1.3872e-01,  6.6546e-02,\n",
      "          -5.5171e-02, -1.2812e-01,  3.0978e-02, -1.7879e-02, -1.1118e-01,\n",
      "           6.9688e-02,  1.1730e-01, -9.2087e-02,  5.1414e-03, -1.0339e-01,\n",
      "           1.2127e-01, -1.5073e-01,  3.9605e-02, -4.5103e-02, -3.2352e-02,\n",
      "           5.5713e-02, -1.5866e-01, -9.0609e-02, -1.0815e-01, -1.1905e-01,\n",
      "          -9.0003e-02,  1.3762e-01, -5.8117e-02,  8.7078e-02,  6.7170e-02,\n",
      "           2.0604e-02,  6.3749e-02, -2.6162e-02,  2.2175e-02,  5.5357e-02,\n",
      "          -9.5394e-03, -5.1336e-02, -1.3511e-01, -1.4742e-01, -8.9217e-02,\n",
      "           4.6463e-02, -9.4037e-02, -8.8152e-02,  4.1238e-02, -3.0018e-02,\n",
      "          -1.1069e-01, -3.1254e-03, -7.5999e-02, -2.8008e-02, -2.0664e-02,\n",
      "           4.0629e-03,  7.6797e-02,  1.6620e-01, -1.3818e-01,  1.7415e-01,\n",
      "          -5.7545e-03,  9.3473e-02, -4.7323e-02,  1.0165e-01, -8.0064e-02,\n",
      "          -1.2908e-02,  1.0723e-01, -1.2966e-02,  3.8397e-02,  1.6602e-01,\n",
      "          -7.4364e-02, -6.4333e-02, -1.4167e-01,  8.5557e-02,  3.1960e-02,\n",
      "           1.8653e-02,  8.5285e-02, -4.5165e-03, -2.2019e-02,  5.5819e-02,\n",
      "          -3.8961e-02,  5.4727e-03, -5.5037e-03, -1.7427e-02,  2.2280e-02,\n",
      "          -4.2181e-03, -2.2757e-02,  9.3753e-02,  1.2225e-01,  2.2047e-01,\n",
      "          -1.6265e-01, -9.5037e-02,  8.4919e-02,  1.0920e-01,  3.4391e-02,\n",
      "           8.3867e-03,  1.7310e-01,  8.1758e-02, -6.0057e-03, -2.4863e-02,\n",
      "           2.2958e-02,  6.1063e-02, -8.9004e-02, -9.4439e-02, -1.4436e-03,\n",
      "          -6.8323e-02, -6.4742e-02,  4.0327e-02, -1.8112e-01, -1.1879e-02,\n",
      "           2.9877e-02,  7.1406e-02, -1.6838e-01, -3.3559e-02, -1.1296e-01,\n",
      "           6.3439e-02,  7.6188e-02, -1.6266e-02,  4.1982e-02, -2.3198e-02,\n",
      "           3.5709e-02, -5.3538e-02, -5.4697e-02, -2.0945e-02, -1.8220e-02,\n",
      "          -7.3362e-02,  1.2360e-01,  1.7034e-02, -1.6702e-02, -8.3308e-02,\n",
      "          -1.6128e-02,  1.5592e-01, -1.6230e-01,  9.0451e-02,  2.7420e-02,\n",
      "           7.1483e-03, -8.2359e-03,  1.3992e-01, -3.1556e-02,  1.9676e-01,\n",
      "          -1.3308e-01, -2.4322e-02, -2.7593e-02,  1.1094e-01,  6.3657e-02,\n",
      "           1.3266e-01, -3.4099e-02,  1.1313e-01, -6.1276e-02, -3.3114e-02,\n",
      "           1.2849e-02, -1.3389e-01, -1.5301e-01,  1.6735e-01, -8.1072e-02,\n",
      "           2.4640e-02, -6.6444e-02, -1.4791e-01,  1.3471e-01,  7.7200e-02,\n",
      "          -8.2786e-02, -5.3055e-02,  1.7069e-01, -6.6023e-02, -1.1855e-01,\n",
      "          -1.3914e-01,  9.0510e-02, -6.8277e-02,  1.6063e-01, -3.3589e-04,\n",
      "          -1.4052e-01, -8.7956e-03, -1.2050e-02,  9.1083e-02,  7.1479e-02,\n",
      "           2.2141e-04, -5.2568e-02,  2.8850e-02, -7.7431e-03, -4.6062e-02,\n",
      "           1.3216e-01,  4.7345e-03, -7.9626e-02, -5.7786e-02,  1.0115e-01,\n",
      "          -1.1826e-01,  3.3781e-02, -4.4671e-02,  2.0583e-02,  3.0865e-02,\n",
      "          -1.0284e-01,  1.1785e-01, -1.1969e-01,  2.6131e-02, -8.1649e-02,\n",
      "           5.4818e-02, -1.7418e-01,  2.2622e-01,  5.5455e-02, -4.9819e-03,\n",
      "          -1.1973e-01, -3.7019e-02, -7.2582e-04, -7.5898e-02, -1.3677e-01,\n",
      "           7.1742e-02,  3.5092e-02,  1.9218e-02, -6.0045e-02,  6.6762e-02,\n",
      "           2.7396e-02,  1.4916e-02,  1.6404e-01, -8.9921e-02,  3.0785e-03,\n",
      "           6.4408e-02, -1.1569e-02, -7.4285e-02, -1.9256e-01,  8.0448e-02,\n",
      "           2.0731e-02,  1.7465e-02,  5.4785e-02, -1.4554e-01, -3.0840e-02,\n",
      "          -3.4061e-02, -1.3183e-01,  7.0407e-02,  2.2475e-01,  1.1295e-01,\n",
      "          -3.2521e-02, -9.9374e-02, -7.3419e-02, -8.4707e-02,  1.9946e-01,\n",
      "          -1.5737e-01, -1.5279e-01, -1.2202e-01,  7.8419e-02, -1.1656e-01,\n",
      "           1.5227e-01, -4.1596e-02, -9.8342e-02, -8.5100e-02,  1.1170e-01,\n",
      "          -4.6901e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4736,  0.0000, -1.2334, -0.1180,  0.4617,  0.0000,  0.0000,\n",
      "           0.5340,  0.0000,  0.9338,  1.7079, -1.0164,  0.0000, -0.2517,\n",
      "          -1.6338,  0.5125,  1.8774, -0.7566, -1.5631, -2.6434, -1.1335,\n",
      "           0.1682,  2.9297,  0.5543, -0.1168,  3.2093,  1.8370,  0.5189,\n",
      "           0.0000, -1.2857,  0.0294,  1.0135,  0.3248,  0.8599, -0.7985,\n",
      "          -1.4655,  0.6198, -0.7713,  1.9915,  0.1020,  0.4675, -2.2044,\n",
      "          -0.5664, -0.1150, -0.7129, -0.6892,  1.9277,  0.1099, -0.2867,\n",
      "          -1.8506,  1.4678,  0.4622,  0.6675, -0.2833,  0.5316,  0.2749,\n",
      "          -1.2423, -0.9511,  1.8140, -0.0118,  0.2049, -1.8184, -1.4014,\n",
      "           0.0000,  1.1798,  0.2652, -0.1669, -0.2552, -0.0044,  0.0000,\n",
      "          -0.3251, -0.3241,  0.1474, -0.1264,  0.6586, -0.8064,  0.0000,\n",
      "           1.6795,  0.0878, -0.5459,  1.2270,  0.0867,  0.3268, -1.8364,\n",
      "          -0.0714, -1.7322, -1.4585, -0.8909,  0.0000,  0.8109, -1.2237,\n",
      "          -1.1442,  1.9851, -0.3661,  0.0000,  0.1566,  2.1414, -0.4056,\n",
      "          -0.3042, -1.8394, -1.2905, -0.7213, -0.7663,  0.2371,  0.3819,\n",
      "           1.1139, -1.0702,  0.0000, -0.2628, -0.2883, -0.0532,  0.6107,\n",
      "          -0.2546,  0.0000, -1.9421,  1.1284,  1.0063, -2.4974, -0.5749,\n",
      "           0.0000, -1.6950, -0.4011, -0.3792, -0.0786, -0.5368, -1.1111,\n",
      "           0.0000,  0.1696,  0.3222,  1.3585,  2.0791, -2.6341,  0.3594,\n",
      "          -0.7229,  0.4291,  0.0600,  0.3267, -2.1019,  0.0000, -1.6775,\n",
      "           0.0000,  0.2341, -1.1871, -1.2151, -0.6311, -0.0406,  0.4647,\n",
      "           0.0000,  1.5943,  1.4317, -1.2628,  0.0000, -0.4801, -0.0394,\n",
      "           0.3267, -0.1168,  1.3538, -0.0315, -1.9005, -1.8061, -1.4269,\n",
      "          -0.9004, -0.7056, -0.3891, -0.9812,  0.0000,  0.4063,  0.9703,\n",
      "           0.5179, -0.1475,  1.5138, -0.3730, -0.3159, -2.0088,  0.0000,\n",
      "          -0.3524, -0.8303, -0.7691, -0.0402, -0.9375,  0.7277,  1.0420,\n",
      "           0.0469,  0.0000,  0.3164, -0.1181, -0.5416, -0.6642,  0.7548,\n",
      "          -1.0642, -0.5869, -1.7884,  1.2675, -0.9263, -1.6148, -0.3332,\n",
      "          -1.1570,  0.0000, -0.0720, -0.3754,  2.6976, -0.9216, -2.6315,\n",
      "          -0.5862, -0.7163, -1.3860, -1.2536,  0.1718,  0.2188, -1.1109,\n",
      "           0.9448, -0.6920, -1.5194,  0.3622,  0.0000,  0.0000, -2.3447,\n",
      "           0.0474, -1.4798,  0.4273,  0.0132, -0.9017,  0.0000, -1.1653,\n",
      "           0.0000,  0.0000,  1.2724,  1.2666, -2.1880, -0.0563,  1.7374,\n",
      "          -1.1752,  0.9561,  1.9991,  0.5271,  0.7892, -0.6785,  0.1045,\n",
      "          -0.6803, -2.2621,  0.1674, -0.3138, -1.0432, -0.3819, -1.0801,\n",
      "           0.5579,  1.4996, -0.5646, -1.3772,  0.0000,  0.5826,  1.7529,\n",
      "           0.0000,  0.3625,  0.4874,  0.3902]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0314, 0.2179, 0.0812, 0.0628, 0.1067, 0.1302, 0.0352, 0.1754, 0.0824,\n",
      "         0.0767]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0288,  0.4029, -0.0047,  ...,  0.1345,  0.0973, -0.2314],\n",
      "        [ 0.2024,  0.2797, -0.3022,  ..., -0.1545,  0.2033, -0.2727],\n",
      "        [ 0.0197,  0.5314,  0.1410,  ..., -0.1513,  0.3358, -0.0984],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1045,  0.1896, -0.1353,  0.0984,  0.0084, -0.1122, -0.0561,\n",
      "          -0.0866,  0.1476,  0.0351, -0.0181,  0.0268, -0.1465, -0.0594,\n",
      "           0.0065, -0.0458,  0.1390,  0.0502, -0.0650,  0.0799, -0.0747,\n",
      "          -0.1498,  0.0360, -0.0513, -0.1511,  0.0881,  0.1664, -0.1007,\n",
      "           0.0092, -0.0823,  0.1477, -0.2277,  0.0267, -0.0788,  0.0181,\n",
      "           0.0814, -0.1677, -0.1186, -0.1352, -0.1154, -0.1361,  0.1573,\n",
      "          -0.0321,  0.0947,  0.0839, -0.0416,  0.0758, -0.0426,  0.0442,\n",
      "           0.1070, -0.0063, -0.0125, -0.1814, -0.1773, -0.1179,  0.0670,\n",
      "          -0.0812, -0.1481,  0.0253, -0.0540, -0.1646, -0.0322, -0.0641,\n",
      "          -0.0569, -0.0242, -0.0424,  0.1013,  0.1673, -0.1523,  0.1577,\n",
      "          -0.0139,  0.0441, -0.0068,  0.1886, -0.0414, -0.0685,  0.1213,\n",
      "          -0.0594,  0.0463,  0.1651, -0.0745, -0.0385, -0.1501,  0.1276,\n",
      "           0.0015, -0.0372,  0.0626, -0.0323, -0.0359,  0.0539, -0.0719,\n",
      "           0.0469, -0.0407, -0.0827,  0.0322, -0.0077, -0.0432,  0.0899,\n",
      "           0.1574,  0.2479, -0.1963, -0.1600,  0.0516,  0.1420,  0.0746,\n",
      "           0.0364,  0.2050,  0.0750,  0.0046, -0.0044,  0.0471,  0.0787,\n",
      "          -0.0863, -0.0607,  0.0099, -0.0362, -0.0602,  0.0616, -0.2113,\n",
      "           0.0139,  0.0403,  0.1076, -0.1193, -0.0444, -0.1290,  0.0935,\n",
      "           0.0958, -0.0030,  0.0594,  0.0385,  0.0061,  0.0390, -0.1097,\n",
      "          -0.0609, -0.0168, -0.0500,  0.1303,  0.0016,  0.0407, -0.1262,\n",
      "          -0.0235,  0.1408, -0.1951,  0.0813,  0.0112,  0.0018, -0.0088,\n",
      "           0.1668, -0.0175,  0.1926, -0.1258, -0.0550, -0.0470,  0.1377,\n",
      "           0.0238,  0.1472, -0.0547,  0.1566, -0.1091, -0.0679,  0.0172,\n",
      "          -0.1635, -0.1316,  0.1313, -0.1085,  0.0024, -0.1032, -0.1901,\n",
      "           0.1724,  0.0416, -0.1124, -0.0140,  0.1850, -0.1122, -0.0937,\n",
      "          -0.1762,  0.1152, -0.0368,  0.2040,  0.0331, -0.1472, -0.0077,\n",
      "           0.0106,  0.0917,  0.0614, -0.0542, -0.0729, -0.0079, -0.0913,\n",
      "          -0.0941,  0.1809, -0.0015, -0.0404, -0.0461,  0.1226, -0.1717,\n",
      "           0.0368, -0.0627,  0.0738, -0.0228, -0.1536,  0.1084, -0.1486,\n",
      "           0.0359, -0.1252,  0.1134, -0.2145,  0.2604,  0.1168, -0.0011,\n",
      "          -0.1705, -0.0370,  0.0316, -0.1274, -0.2041,  0.0901,  0.0232,\n",
      "          -0.0141, -0.0044,  0.0691,  0.0303,  0.0736,  0.1376, -0.0803,\n",
      "          -0.0244,  0.0291,  0.0044, -0.0294, -0.2474,  0.0257,  0.0693,\n",
      "          -0.0265,  0.0611, -0.1321, -0.0196, -0.0252, -0.1797,  0.0849,\n",
      "           0.2686,  0.0799, -0.0284, -0.0662, -0.0151, -0.0540,  0.2447,\n",
      "          -0.1783, -0.1626, -0.1512,  0.0518, -0.1608,  0.1711, -0.0730,\n",
      "          -0.1229, -0.0996,  0.1248, -0.0809]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9538e-02, -1.8078e+00,  1.3220e+00,  5.1612e-01,\n",
      "          -3.7611e-01,  1.1886e-03, -7.2296e-01,  2.1179e+00, -2.1358e-01,\n",
      "           2.8198e-01,  0.0000e+00,  0.0000e+00,  1.9981e-01,  3.1262e-01,\n",
      "           3.5182e-01, -6.8299e-01,  1.6925e-01,  8.7453e-01,  5.4565e-01,\n",
      "           1.8833e+00,  6.0191e-01, -3.6896e-02, -5.3540e-01, -1.0054e-01,\n",
      "           0.0000e+00, -1.6089e+00, -1.3622e+00, -2.1266e+00, -1.0346e+00,\n",
      "           3.8799e-02, -1.4545e+00, -2.0765e+00,  3.1553e-01, -2.8504e-01,\n",
      "          -2.0017e+00,  2.1883e-01,  9.9699e-01,  6.0136e-01,  9.5347e-01,\n",
      "          -2.2510e-01, -2.2111e+00, -7.0608e-01,  1.3959e+00,  8.9561e-02,\n",
      "          -1.1385e+00,  2.4254e-01,  7.4197e-01, -7.0953e-01, -1.3359e+00,\n",
      "           1.6085e+00, -1.3755e-01,  6.6251e-01,  1.1163e+00,  0.0000e+00,\n",
      "           3.3311e-01, -4.4960e-01, -8.8795e-01,  1.3375e-01,  6.2832e-01,\n",
      "          -7.0474e-01,  5.6359e-01, -6.9332e-01, -1.5472e+00,  2.8928e-01,\n",
      "           9.5728e-02,  0.0000e+00,  5.9497e-01, -2.1386e+00,  5.5967e-01,\n",
      "           1.8268e-01, -5.1253e-01,  0.0000e+00,  0.0000e+00, -6.4748e-01,\n",
      "           4.6110e-01, -1.0492e+00,  1.1890e-01,  5.1732e-01, -1.8640e-01,\n",
      "          -3.8495e-01,  2.1579e+00,  7.7744e-01, -8.4540e-01,  3.9786e-01,\n",
      "           4.1931e-01,  1.6046e+00, -5.6406e-01, -1.4131e+00, -1.4906e+00,\n",
      "           4.0439e-01, -3.5152e-01,  4.9400e-01, -2.3210e+00,  0.0000e+00,\n",
      "          -9.6303e-01,  0.0000e+00, -9.0735e-01,  2.3906e+00,  9.5519e-01,\n",
      "           0.0000e+00,  5.9440e-01,  1.0664e+00, -1.7340e+00,  3.6523e-01,\n",
      "           4.0224e-01, -1.2705e+00,  4.5476e-01,  1.9689e+00,  1.4970e-01,\n",
      "          -8.3263e-01,  5.3398e-01,  8.0843e-01,  6.6399e-01, -1.0553e+00,\n",
      "           9.1777e-01, -7.0301e-01, -8.4510e-01,  2.5772e-01,  8.7978e-01,\n",
      "          -8.7698e-01, -1.3962e+00, -3.6486e-01, -1.8463e+00, -1.3006e+00,\n",
      "           1.0694e+00, -8.1160e-01,  6.4926e-01,  2.5563e-01, -1.4896e+00,\n",
      "           2.5020e+00,  3.7778e-01, -1.3455e+00,  7.2222e-01,  3.2009e+00,\n",
      "          -7.5276e-01, -3.8364e-01,  1.2823e+00,  2.2520e+00,  1.9420e-01,\n",
      "          -3.9072e-02,  0.0000e+00,  0.0000e+00, -1.8714e-01, -1.1120e+00,\n",
      "           1.2472e+00,  0.0000e+00, -7.7474e-01, -4.4811e-02,  0.0000e+00,\n",
      "           2.3360e+00,  7.6508e-01, -2.8968e-01, -2.1305e+00, -5.8162e-01,\n",
      "           7.8591e-01,  0.0000e+00, -1.3048e+00,  1.9030e-01, -3.6287e+00,\n",
      "          -1.8688e+00,  1.1504e+00, -8.5971e-01,  9.5956e-01, -1.4612e+00,\n",
      "          -2.7095e-02,  1.9745e+00,  1.1269e+00, -4.8571e-01, -1.2415e+00,\n",
      "          -2.1238e-01, -1.3226e+00, -1.6391e+00, -7.7183e-01,  6.8267e-01,\n",
      "          -1.3797e+00,  0.0000e+00,  6.0656e-01,  0.0000e+00,  2.5912e-01,\n",
      "           1.3327e+00, -2.5533e+00,  2.7780e-01, -5.8370e-01,  0.0000e+00,\n",
      "          -1.2403e+00, -1.7230e-03, -5.0133e-02,  9.0089e-01,  5.6568e-01,\n",
      "          -4.1988e-01,  3.8845e-01, -1.1561e-01,  0.0000e+00,  1.0504e+00,\n",
      "          -7.8922e-01, -1.4389e+00, -4.1537e-01, -7.5028e-01, -4.5390e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.8532e+00,  1.3574e+00,  8.3762e-01,\n",
      "          -1.5239e+00,  0.0000e+00,  6.4758e-01,  2.0054e-01, -2.1782e+00,\n",
      "           8.3530e-01, -1.2911e+00, -1.2839e+00,  2.6107e-01, -1.5634e+00,\n",
      "           0.0000e+00,  1.3423e-01,  2.5770e+00, -3.0854e-02, -5.7957e-01,\n",
      "          -1.4282e+00,  1.9010e+00,  0.0000e+00,  1.4696e+00,  8.0516e-01,\n",
      "           3.6927e-01,  6.6977e-01, -7.0031e-01,  0.0000e+00,  1.0255e+00,\n",
      "           9.7828e-01, -1.4083e+00,  6.5955e-01, -1.1449e+00, -1.6455e+00,\n",
      "          -6.0024e-01,  8.8527e-03, -7.1094e-01,  3.7051e-01, -2.2391e-01,\n",
      "          -7.5230e-01,  5.7212e-01,  5.3067e-01, -6.6371e-01,  1.5465e+00,\n",
      "           5.7826e-01,  1.8919e+00, -8.6399e-01,  4.9362e-01, -3.8713e-01,\n",
      "           0.0000e+00,  0.0000e+00,  1.7727e+00, -1.0636e+00, -8.0778e-01,\n",
      "          -6.2199e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0523, 0.1085, 0.1028, 0.1604, 0.1181, 0.1678, 0.0907, 0.0553, 0.0473,\n",
      "         0.0968]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0288,  0.4029, -0.0047,  ...,  0.1345,  0.0973, -0.2314],\n",
      "        [ 0.2024,  0.2797, -0.3022,  ..., -0.1545,  0.2033, -0.2727],\n",
      "        [ 0.0197,  0.5314,  0.1410,  ..., -0.1513,  0.3358, -0.0984],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0949e-01,  2.1091e-01, -1.2420e-01,  5.3763e-02,  3.2238e-02,\n",
      "          -1.2558e-01, -4.9063e-02, -1.0314e-01,  1.4154e-01, -6.2145e-03,\n",
      "           1.2711e-02,  2.5464e-02, -1.6616e-01, -5.0456e-02,  6.3154e-02,\n",
      "          -3.9409e-02,  1.2913e-01,  5.7760e-02, -1.7491e-01,  7.2098e-02,\n",
      "          -5.9918e-02, -1.6995e-01,  5.8150e-02, -5.1610e-02, -1.3833e-01,\n",
      "           1.2353e-01,  1.9634e-01, -1.2165e-01,  1.3532e-02, -9.8444e-02,\n",
      "           1.7419e-01, -1.7899e-01,  5.4304e-02, -9.0280e-02, -3.8200e-02,\n",
      "           6.2504e-02, -2.0124e-01, -1.0563e-01, -1.2859e-01, -1.2418e-01,\n",
      "          -1.0652e-01,  2.0106e-01, -5.4193e-02,  1.1086e-01,  4.7368e-02,\n",
      "           3.5131e-02,  9.5925e-02, -2.8528e-02,  3.9242e-02,  6.6143e-02,\n",
      "           2.6447e-03, -5.8125e-02, -1.7804e-01, -1.9419e-01, -1.1828e-01,\n",
      "           4.7984e-02, -1.0888e-01, -1.2940e-01,  4.1505e-02, -6.1579e-02,\n",
      "          -1.3503e-01, -3.2027e-02, -1.0098e-01, -1.3698e-02, -4.2597e-02,\n",
      "          -7.5360e-03,  7.3437e-02,  2.1780e-01, -1.8478e-01,  2.2451e-01,\n",
      "           1.7133e-02,  1.2229e-01, -4.0784e-02,  1.3433e-01, -8.4087e-02,\n",
      "           1.0457e-02,  1.3719e-01, -1.6510e-02,  5.7403e-02,  2.1114e-01,\n",
      "          -8.0809e-02, -1.8752e-02, -1.7959e-01,  1.3350e-01,  2.9371e-02,\n",
      "          -2.0421e-03,  1.2198e-01,  6.6962e-03, -1.5686e-02,  9.5528e-02,\n",
      "          -5.5633e-02,  3.2886e-03, -3.3665e-02, -5.3771e-02,  4.0108e-02,\n",
      "           2.0587e-02, -4.0229e-02,  9.2462e-02,  1.9440e-01,  2.7132e-01,\n",
      "          -1.9184e-01, -8.5155e-02,  8.7490e-02,  1.3688e-01,  9.5560e-02,\n",
      "           4.8019e-03,  2.1791e-01,  1.2907e-01, -1.3223e-02, -9.4491e-03,\n",
      "           1.4773e-02,  9.8769e-02, -1.2857e-01, -9.4101e-02,  5.1427e-03,\n",
      "          -6.4385e-02, -7.6577e-02,  6.3877e-02, -2.4928e-01, -1.3119e-03,\n",
      "           2.2193e-02,  1.0769e-01, -2.0457e-01, -2.9230e-02, -1.6874e-01,\n",
      "           7.9447e-02,  9.3139e-02, -1.8328e-02,  4.3368e-02, -2.2231e-02,\n",
      "           2.9819e-02, -2.1450e-02, -9.9746e-02, -1.6451e-02, -1.3579e-02,\n",
      "          -1.0999e-01,  1.3850e-01,  3.9490e-02,  1.2871e-02, -9.2426e-02,\n",
      "          -4.4886e-02,  1.9718e-01, -2.2383e-01,  9.1534e-02,  2.6532e-02,\n",
      "           4.0445e-03,  9.9965e-04,  1.8016e-01, -1.1308e-02,  2.4251e-01,\n",
      "          -1.8937e-01, -1.0839e-02, -5.1753e-02,  1.4334e-01,  8.3526e-02,\n",
      "           1.7681e-01, -4.2981e-02,  1.5677e-01, -1.0913e-01, -3.0876e-02,\n",
      "           1.6116e-02, -1.6207e-01, -1.9142e-01,  2.0652e-01, -1.4081e-01,\n",
      "           2.0483e-02, -1.0827e-01, -1.9137e-01,  1.2959e-01,  3.8357e-02,\n",
      "          -1.2510e-01, -4.8638e-02,  2.0920e-01, -5.9152e-02, -1.2431e-01,\n",
      "          -1.9057e-01,  1.2635e-01, -7.9258e-02,  2.0111e-01, -1.9585e-02,\n",
      "          -1.9008e-01, -6.0379e-03, -2.3193e-02,  9.6743e-02,  1.0659e-01,\n",
      "          -2.0941e-02, -2.2010e-02,  9.0202e-03, -7.0764e-02, -7.4508e-02,\n",
      "           1.9474e-01,  7.8014e-03, -7.4378e-02, -6.4001e-02,  9.2103e-02,\n",
      "          -1.6778e-01,  6.1554e-02, -4.6814e-02,  3.2144e-02,  2.8469e-03,\n",
      "          -1.2198e-01,  1.4351e-01, -1.5785e-01,  1.3852e-02, -1.3562e-01,\n",
      "           7.1125e-02, -2.1523e-01,  2.8257e-01,  9.1090e-02, -3.0700e-02,\n",
      "          -1.9225e-01, -3.2775e-02, -5.3466e-04, -1.0011e-01, -1.9424e-01,\n",
      "           7.0900e-02,  8.7906e-02,  2.5100e-02, -6.7764e-02,  5.9276e-02,\n",
      "           3.0521e-02,  5.0735e-02,  2.0963e-01, -9.1837e-02, -1.2109e-02,\n",
      "           7.5113e-02, -3.6889e-02, -9.7203e-02, -2.7133e-01,  7.2462e-02,\n",
      "           8.0260e-02,  1.3159e-04,  3.1515e-02, -1.6664e-01, -3.0353e-02,\n",
      "          -4.2495e-02, -1.8132e-01,  9.6935e-02,  2.9912e-01,  1.4247e-01,\n",
      "          -3.7946e-02, -1.2523e-01, -6.1903e-02, -6.3043e-02,  2.6837e-01,\n",
      "          -2.2192e-01, -1.9385e-01, -1.6988e-01,  6.8903e-02, -1.9640e-01,\n",
      "           1.9054e-01, -4.9401e-02, -1.1470e-01, -1.3270e-01,  1.6443e-01,\n",
      "          -6.7293e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9538e-02, -1.8078e+00,  1.3220e+00,  5.1612e-01,\n",
      "          -3.7611e-01,  1.1886e-03, -7.2296e-01,  2.1179e+00, -2.1358e-01,\n",
      "           2.8198e-01,  8.3057e-01, -1.1106e+00,  1.9981e-01,  3.1262e-01,\n",
      "           3.5182e-01, -6.8299e-01,  1.6925e-01,  8.7453e-01,  5.4565e-01,\n",
      "           1.8833e+00,  6.0191e-01, -3.6896e-02, -5.3540e-01, -1.0054e-01,\n",
      "           6.5098e-01, -1.6089e+00, -1.3622e+00, -2.1266e+00, -1.0346e+00,\n",
      "           3.8799e-02, -1.4545e+00, -2.0765e+00,  3.1553e-01, -2.8504e-01,\n",
      "          -2.0017e+00,  2.1883e-01,  9.9699e-01,  6.0136e-01,  9.5347e-01,\n",
      "          -2.2510e-01, -2.2111e+00, -7.0608e-01,  0.0000e+00,  8.9561e-02,\n",
      "           0.0000e+00,  0.0000e+00,  7.4197e-01, -7.0953e-01, -1.3359e+00,\n",
      "           1.6085e+00, -1.3755e-01,  6.6251e-01,  0.0000e+00,  5.6730e-01,\n",
      "           3.3311e-01, -4.4960e-01, -8.8795e-01,  1.3375e-01,  6.2832e-01,\n",
      "          -7.0474e-01,  5.6359e-01,  0.0000e+00, -1.5472e+00,  2.8928e-01,\n",
      "           9.5728e-02,  0.0000e+00,  5.9497e-01, -2.1386e+00,  5.5967e-01,\n",
      "           1.8268e-01, -5.1253e-01, -3.4100e-01,  0.0000e+00, -6.4748e-01,\n",
      "           4.6110e-01, -1.0492e+00,  1.1890e-01,  5.1732e-01, -1.8640e-01,\n",
      "          -3.8495e-01,  2.1579e+00,  7.7744e-01,  0.0000e+00,  3.9786e-01,\n",
      "           4.1931e-01,  1.6046e+00, -5.6406e-01, -1.4131e+00, -1.4906e+00,\n",
      "           4.0439e-01, -3.5152e-01,  4.9400e-01, -2.3210e+00,  0.0000e+00,\n",
      "          -9.6303e-01,  1.3202e+00, -9.0735e-01,  2.3906e+00,  9.5519e-01,\n",
      "          -1.2007e+00,  5.9440e-01,  0.0000e+00, -1.7340e+00,  3.6523e-01,\n",
      "           4.0224e-01, -1.2705e+00,  4.5476e-01,  1.9689e+00,  1.4970e-01,\n",
      "          -8.3263e-01,  5.3398e-01,  8.0843e-01,  6.6399e-01, -1.0553e+00,\n",
      "           9.1777e-01, -7.0301e-01, -8.4510e-01,  2.5772e-01,  0.0000e+00,\n",
      "          -8.7698e-01, -1.3962e+00,  0.0000e+00, -1.8463e+00, -1.3006e+00,\n",
      "           1.0694e+00, -8.1160e-01,  6.4926e-01,  2.5563e-01, -1.4896e+00,\n",
      "           2.5020e+00,  3.7778e-01, -1.3455e+00,  7.2222e-01,  3.2009e+00,\n",
      "           0.0000e+00,  0.0000e+00,  1.2823e+00,  2.2520e+00,  1.9420e-01,\n",
      "          -3.9072e-02,  3.0300e+00,  3.6285e-01, -1.8714e-01, -1.1120e+00,\n",
      "           1.2472e+00,  7.7544e-01, -7.7474e-01, -4.4811e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6508e-01, -2.8968e-01, -2.1305e+00, -5.8162e-01,\n",
      "           7.8591e-01, -1.8621e+00, -1.3048e+00,  1.9030e-01, -3.6287e+00,\n",
      "          -1.8688e+00,  1.1504e+00,  0.0000e+00,  9.5956e-01, -1.4612e+00,\n",
      "          -2.7095e-02,  1.9745e+00,  1.1269e+00, -4.8571e-01, -1.2415e+00,\n",
      "          -2.1238e-01, -1.3226e+00, -1.6391e+00, -7.7183e-01,  0.0000e+00,\n",
      "          -1.3797e+00, -1.2603e-01,  6.0656e-01,  0.0000e+00,  2.5912e-01,\n",
      "           1.3327e+00, -2.5533e+00,  2.7780e-01, -5.8370e-01,  0.0000e+00,\n",
      "          -1.2403e+00, -1.7230e-03, -5.0133e-02,  9.0089e-01,  5.6568e-01,\n",
      "          -4.1988e-01,  3.8845e-01, -1.1561e-01,  8.0966e-01,  1.0504e+00,\n",
      "          -7.8922e-01, -1.4389e+00, -4.1537e-01, -7.5028e-01, -4.5390e-01,\n",
      "          -5.4747e-01,  7.2229e-01, -1.8532e+00,  1.3574e+00,  8.3762e-01,\n",
      "           0.0000e+00,  0.0000e+00,  6.4758e-01,  0.0000e+00, -2.1782e+00,\n",
      "           8.3530e-01, -1.2911e+00, -1.2839e+00,  2.6107e-01, -1.5634e+00,\n",
      "           2.0758e+00,  1.3423e-01,  2.5770e+00, -3.0854e-02, -5.7957e-01,\n",
      "          -1.4282e+00,  1.9010e+00, -3.8090e-01,  1.4696e+00,  8.0516e-01,\n",
      "           3.6927e-01,  6.6977e-01, -7.0031e-01,  8.9159e-02,  1.0255e+00,\n",
      "           9.7828e-01, -1.4083e+00,  6.5955e-01, -1.1449e+00, -1.6455e+00,\n",
      "          -6.0024e-01,  8.8527e-03, -7.1094e-01,  0.0000e+00, -2.2391e-01,\n",
      "          -7.5230e-01,  0.0000e+00,  5.3067e-01,  0.0000e+00,  1.5465e+00,\n",
      "           0.0000e+00,  1.8919e+00, -8.6399e-01,  4.9362e-01, -3.8713e-01,\n",
      "           5.0001e-01, -9.7495e-01,  1.7727e+00, -1.0636e+00,  0.0000e+00,\n",
      "          -6.2199e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0613, 0.1120, 0.1258, 0.1523, 0.0988, 0.1419, 0.0771, 0.0541, 0.0581,\n",
      "         0.1186]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0288,  0.4029, -0.0047,  ...,  0.1345,  0.0973, -0.2314],\n",
      "        [ 0.2024,  0.2797, -0.3022,  ..., -0.1545,  0.2033, -0.2727],\n",
      "        [ 0.0197,  0.5314,  0.1410,  ..., -0.1513,  0.3358, -0.0984],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0036e-01,  2.1541e-01, -1.0805e-01,  6.3026e-02,  4.3220e-02,\n",
      "          -1.2054e-01, -5.1770e-02, -9.4257e-02,  1.4855e-01,  3.9211e-03,\n",
      "           3.4557e-03,  3.7046e-02, -1.6243e-01, -5.8058e-02,  5.3917e-02,\n",
      "          -3.5044e-02,  1.3494e-01,  5.5536e-02, -1.6133e-01,  7.8112e-02,\n",
      "          -6.2025e-02, -1.6736e-01,  4.7693e-02, -5.7481e-02, -1.3746e-01,\n",
      "           1.3185e-01,  2.0941e-01, -1.1304e-01,  1.8982e-02, -1.0841e-01,\n",
      "           1.7509e-01, -1.8254e-01,  6.5418e-02, -7.3367e-02, -4.0914e-02,\n",
      "           5.4598e-02, -2.0123e-01, -1.0559e-01, -1.1941e-01, -1.3299e-01,\n",
      "          -1.1692e-01,  2.0838e-01, -4.4840e-02,  1.1278e-01,  4.8295e-02,\n",
      "           1.9783e-02,  1.0057e-01, -1.1502e-02,  3.4103e-02,  7.5478e-02,\n",
      "           1.1356e-02, -5.2524e-02, -1.7098e-01, -1.9883e-01, -1.1956e-01,\n",
      "           6.0166e-02, -1.1165e-01, -1.4562e-01,  4.2561e-02, -7.6974e-02,\n",
      "          -1.4214e-01, -2.6159e-02, -8.8209e-02, -2.8637e-02, -4.3462e-02,\n",
      "          -7.2359e-03,  9.1364e-02,  2.1295e-01, -1.8698e-01,  2.2165e-01,\n",
      "           1.0948e-02,  1.1127e-01, -4.3908e-02,  1.3108e-01, -7.1714e-02,\n",
      "           2.4438e-03,  1.3866e-01, -3.4828e-02,  6.5703e-02,  2.1271e-01,\n",
      "          -7.6244e-02, -9.7472e-03, -1.6881e-01,  1.3999e-01,  3.6795e-02,\n",
      "          -8.1924e-03,  1.2742e-01,  2.4493e-04, -2.8154e-02,  9.9776e-02,\n",
      "          -6.4095e-02,  7.1286e-03, -2.8348e-02, -5.4114e-02,  4.3065e-02,\n",
      "           1.1817e-02, -5.0966e-02,  8.5832e-02,  2.0622e-01,  2.6732e-01,\n",
      "          -1.9264e-01, -1.0214e-01,  8.2039e-02,  1.3247e-01,  1.0145e-01,\n",
      "           1.7811e-02,  2.1968e-01,  1.1631e-01, -1.1897e-02, -2.5298e-02,\n",
      "           1.2747e-02,  9.9489e-02, -1.3652e-01, -8.2395e-02,  1.7929e-02,\n",
      "          -6.7041e-02, -7.6589e-02,  6.8311e-02, -2.5269e-01,  6.3948e-03,\n",
      "           2.4315e-02,  1.2441e-01, -1.9634e-01, -3.6261e-02, -1.5971e-01,\n",
      "           8.5635e-02,  9.4995e-02, -1.3667e-02,  3.4698e-02, -1.5282e-02,\n",
      "           2.9255e-02, -5.7375e-03, -1.1607e-01, -2.8630e-02, -1.0964e-02,\n",
      "          -1.1621e-01,  1.2599e-01,  3.5853e-02,  2.4426e-02, -1.0685e-01,\n",
      "          -3.7124e-02,  1.9069e-01, -2.3023e-01,  8.7241e-02,  1.9475e-02,\n",
      "           1.1783e-02, -4.2755e-03,  1.7704e-01, -2.1542e-02,  2.4300e-01,\n",
      "          -1.6583e-01, -2.0967e-02, -4.9632e-02,  1.3748e-01,  8.1946e-02,\n",
      "           1.7027e-01, -3.9996e-02,  1.5405e-01, -1.1622e-01, -2.2730e-02,\n",
      "           2.1464e-02, -1.6338e-01, -1.8303e-01,  1.9400e-01, -1.4399e-01,\n",
      "           1.4152e-02, -1.1034e-01, -1.8724e-01,  1.2858e-01,  3.0529e-02,\n",
      "          -1.2143e-01, -5.7125e-02,  2.0680e-01, -6.2307e-02, -1.3046e-01,\n",
      "          -1.8945e-01,  1.3321e-01, -9.1544e-02,  1.8862e-01, -1.2701e-02,\n",
      "          -1.8514e-01, -1.5317e-03, -1.0076e-02,  1.0214e-01,  9.6865e-02,\n",
      "          -2.4036e-02, -4.4667e-03, -1.0319e-04, -7.6406e-02, -6.8666e-02,\n",
      "           2.0015e-01, -3.9670e-03, -5.8865e-02, -6.1249e-02,  9.6289e-02,\n",
      "          -1.5641e-01,  6.6691e-02, -5.4478e-02,  4.0532e-02, -4.9926e-03,\n",
      "          -1.3084e-01,  1.4029e-01, -1.6533e-01,  1.5654e-03, -1.4309e-01,\n",
      "           7.7482e-02, -2.2533e-01,  2.7852e-01,  1.0104e-01, -1.9981e-02,\n",
      "          -2.0087e-01, -1.8210e-02, -4.4653e-03, -1.1221e-01, -2.0095e-01,\n",
      "           5.9720e-02,  9.6693e-02,  1.4089e-02, -5.9392e-02,  5.5574e-02,\n",
      "           1.7153e-02,  5.7804e-02,  2.0218e-01, -8.5713e-02, -2.7017e-02,\n",
      "           7.1363e-02, -4.6361e-02, -8.7485e-02, -2.6171e-01,  7.0072e-02,\n",
      "           9.5039e-02,  3.0587e-03,  4.5899e-02, -1.5590e-01, -2.4194e-02,\n",
      "          -4.0248e-02, -1.8094e-01,  1.0029e-01,  3.0241e-01,  1.3948e-01,\n",
      "          -3.6044e-02, -1.1257e-01, -5.4020e-02, -7.2970e-02,  2.7901e-01,\n",
      "          -2.2908e-01, -1.9481e-01, -1.6243e-01,  6.2421e-02, -2.1113e-01,\n",
      "           1.9379e-01, -5.3691e-02, -1.1031e-01, -1.2661e-01,  1.6637e-01,\n",
      "          -7.1758e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6843e-02,  3.9986e-01, -9.6504e-01, -6.8097e-01,  3.7538e-01,\n",
      "          -2.0192e-01,  1.4647e+00,  0.0000e+00, -3.5832e+00,  9.0659e-01,\n",
      "           4.2800e-01, -6.2908e-01,  2.6024e+00, -6.3011e-01,  0.0000e+00,\n",
      "          -1.5794e-01,  8.5125e-01,  1.0942e+00,  4.5521e-01,  4.3614e-01,\n",
      "          -6.3326e-01, -3.8240e-01,  1.6400e+00,  1.5108e+00,  7.5324e-01,\n",
      "          -7.5974e-02, -1.8817e-01,  0.0000e+00,  1.6532e+00,  8.6128e-01,\n",
      "           1.2315e+00,  1.2191e+00, -1.0341e+00, -8.2997e-02, -1.5341e+00,\n",
      "           1.3954e+00,  2.8088e-01, -3.7438e+00,  0.0000e+00,  1.6002e+00,\n",
      "          -4.5888e-01, -1.3978e+00, -2.6885e-01, -1.7145e+00,  0.0000e+00,\n",
      "           6.6777e-01,  5.4056e-01,  3.7116e-01, -1.3403e+00,  1.4452e-01,\n",
      "          -6.2943e-01,  2.7506e+00,  6.1013e-01, -1.0287e+00, -2.5062e-02,\n",
      "           2.0384e-01, -8.8130e-01, -1.2513e+00, -2.3730e-01,  0.0000e+00,\n",
      "           1.0992e+00,  1.4073e+00, -2.0251e-01, -5.0097e-01, -2.9625e+00,\n",
      "           5.5139e-01,  1.2782e+00, -1.2873e+00,  4.1030e-01,  5.2683e-01,\n",
      "          -1.2664e+00, -2.9780e-02,  7.0716e-01, -3.6396e+00,  3.2521e-01,\n",
      "          -6.8380e-04, -1.6004e-01,  0.0000e+00,  0.0000e+00, -1.1820e-01,\n",
      "          -1.3997e+00,  2.1299e+00, -9.2425e-01,  1.0059e+00, -2.0754e-01,\n",
      "           4.3597e-01,  1.6611e+00, -9.7388e-01, -1.0423e-01, -5.8103e-01,\n",
      "          -2.2724e+00,  0.0000e+00, -6.2242e-01, -1.1357e+00,  4.6717e-01,\n",
      "          -1.1700e+00,  3.3219e-02,  6.2894e-01,  1.7192e+00, -7.7869e-01,\n",
      "           2.6967e+00, -1.4616e+00,  1.0759e+00,  0.0000e+00, -6.6614e-01,\n",
      "          -7.6229e-01,  1.2111e+00,  1.2717e-01, -1.4729e+00, -1.3774e-02,\n",
      "          -2.4814e-01,  1.3410e-01, -1.0472e+00,  0.0000e+00, -1.6524e+00,\n",
      "          -2.9878e+00, -5.6890e-02, -4.9947e-01, -1.9336e-01,  4.4548e-01,\n",
      "          -1.4650e+00,  7.0213e-01,  0.0000e+00, -7.2566e-01, -9.5780e-01,\n",
      "          -1.3078e+00,  8.9583e-01,  0.0000e+00,  1.2846e+00, -7.5111e-01,\n",
      "          -8.2414e-01,  5.3073e-01, -1.5825e+00,  9.8386e-01,  2.7604e-01,\n",
      "          -5.8912e-01,  6.5858e-01,  5.7537e-01, -1.1590e+00, -1.0094e+00,\n",
      "          -3.8801e-01,  6.7777e-01, -7.8943e-01, -1.0065e-01, -1.6846e+00,\n",
      "           0.0000e+00, -5.4289e-01, -8.4418e-01, -7.5508e-01,  1.7769e-01,\n",
      "           1.9978e+00, -1.9924e-01,  0.0000e+00, -4.0620e-01,  4.4118e-01,\n",
      "          -1.9442e-01, -6.4824e-02, -1.3047e-01,  3.9095e-02,  5.3736e-01,\n",
      "          -2.6616e-02,  2.2059e+00,  4.8102e-01, -5.5017e-01, -5.2582e-01,\n",
      "          -8.9143e-01,  2.8153e-01,  8.2990e-02, -3.5813e-01, -4.7792e-01,\n",
      "           0.0000e+00, -3.0886e-02,  2.0048e-02, -1.0025e+00,  1.2775e+00,\n",
      "          -1.0977e+00, -9.8588e-01, -2.0754e+00,  1.9682e+00,  8.6333e-02,\n",
      "          -3.0930e-02,  3.5001e-02,  6.7070e-01,  9.7981e-01, -7.4748e-01,\n",
      "          -3.4092e-01, -2.7816e+00, -7.8306e-01,  1.2089e+00,  0.0000e+00,\n",
      "           3.0723e+00,  4.9411e-01, -1.4439e-01, -5.9299e-01,  5.5997e-01,\n",
      "           2.1642e+00, -1.1874e+00,  5.3504e-01,  1.8108e+00, -9.4607e-01,\n",
      "          -1.6625e+00, -1.0153e+00,  1.2422e+00, -1.2214e-01,  2.3208e-01,\n",
      "          -5.7465e-01,  0.0000e+00,  6.8159e-01, -1.0733e+00, -4.7102e-01,\n",
      "           2.8671e+00, -5.7322e-01,  0.0000e+00,  7.9279e-01,  3.1339e-02,\n",
      "          -6.8331e-01,  0.0000e+00,  9.6669e-01,  0.0000e+00,  2.1686e+00,\n",
      "           0.0000e+00, -4.2685e-01, -1.8432e+00, -5.0027e-01,  3.3905e-01,\n",
      "           7.0490e-01, -6.9650e-01, -6.2812e-01,  2.9227e-01, -1.5776e+00,\n",
      "          -1.1082e+00,  1.5812e+00, -6.1357e-01,  1.3099e+00, -2.9789e+00,\n",
      "           4.0336e+00,  0.0000e+00,  0.0000e+00, -1.5786e+00, -2.8610e-01,\n",
      "           7.4198e-01, -3.2467e+00,  0.0000e+00, -8.5163e-01,  1.1334e-02,\n",
      "           2.7558e-01,  2.7459e-01,  2.5225e-01,  2.6154e-01,  3.8655e-01,\n",
      "          -3.6571e-01, -1.5962e-01, -5.5353e-01, -5.2205e-02, -1.1462e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0496, 0.0685, 0.0855, 0.0586, 0.1136, 0.2727, 0.0814, 0.0812, 0.0630,\n",
      "         0.1260]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0999, -0.1426, -0.2318,  0.0020, -0.1760, -0.1123, -0.2114,\n",
      "          -0.2227, -0.0160, -0.1156,  0.2310,  0.1237, -0.2573,  0.0958,\n",
      "           0.2684,  0.2455,  0.1457, -0.0640, -0.1136, -0.1187, -0.1448,\n",
      "          -0.0955,  0.2089,  0.1407, -0.1033,  0.2542,  0.0901, -0.1184,\n",
      "          -0.2795, -0.1185, -0.2570, -0.1565, -0.1107,  0.0537,  0.0231,\n",
      "          -0.1973, -0.2376, -0.1237, -0.1596,  0.0340,  0.1250, -0.1371,\n",
      "           0.0648, -0.0698, -0.0596,  0.1269,  0.1293, -0.0404,  0.1913,\n",
      "           0.0763, -0.1096,  0.1129, -0.0530, -0.1890, -0.1118, -0.0228,\n",
      "          -0.2430,  0.0501, -0.0925,  0.0268, -0.1684, -0.1090, -0.1956,\n",
      "          -0.0516,  0.2144,  0.2247,  0.1481, -0.0500,  0.0235,  0.1754,\n",
      "           0.1868,  0.4722, -0.0918,  0.1475,  0.1828, -0.1291, -0.1448,\n",
      "           0.3671, -0.2178,  0.0428, -0.3475, -0.0371, -0.2143,  0.1243,\n",
      "           0.1221,  0.0876, -0.1220, -0.1029, -0.0498,  0.0354,  0.2858,\n",
      "          -0.0655,  0.3292,  0.0091,  0.2178,  0.2570, -0.0145,  0.0802,\n",
      "           0.0584, -0.0470,  0.0335,  0.2140,  0.0592, -0.1668, -0.0753,\n",
      "          -0.2259, -0.0172,  0.1427, -0.1947, -0.1268, -0.0441,  0.0103,\n",
      "          -0.1357, -0.2690, -0.0765, -0.1432, -0.0369, -0.1547, -0.0247,\n",
      "           0.2112,  0.0144, -0.1314, -0.0543,  0.0634, -0.1995,  0.0417,\n",
      "           0.0344,  0.1357, -0.0674, -0.2230,  0.4417, -0.2445, -0.0364,\n",
      "           0.0939, -0.1677, -0.2107,  0.1916, -0.1779, -0.1652,  0.1357,\n",
      "           0.1335,  0.3758, -0.0983,  0.3237, -0.0824,  0.0273,  0.0544,\n",
      "           0.2484, -0.0061, -0.0243, -0.1128, -0.2787, -0.0352,  0.2363,\n",
      "          -0.0199,  0.2211, -0.0742,  0.3303,  0.2135, -0.1173, -0.0212,\n",
      "           0.1135, -0.2060,  0.0575, -0.0222, -0.1869, -0.0027, -0.0426,\n",
      "           0.0618,  0.2463, -0.0816,  0.2192,  0.1444, -0.0538, -0.0880,\n",
      "          -0.3075, -0.0790,  0.3016,  0.3722,  0.2143, -0.1286, -0.2710,\n",
      "           0.0944,  0.0957, -0.1001, -0.0271, -0.2528, -0.0239, -0.0253,\n",
      "          -0.0726,  0.0018,  0.1449, -0.1678, -0.0652, -0.0129, -0.2173,\n",
      "           0.0826, -0.0805, -0.3073,  0.1622, -0.1140,  0.1013,  0.0753,\n",
      "          -0.1062, -0.0775, -0.0430,  0.2068, -0.0642, -0.0797, -0.0181,\n",
      "          -0.0181,  0.1063,  0.0333,  0.1833,  0.2636,  0.1281,  0.2073,\n",
      "           0.2645,  0.0227,  0.1397,  0.3306, -0.0669,  0.1145,  0.1121,\n",
      "           0.0155,  0.1332,  0.4227, -0.3138, -0.0350,  0.1451, -0.1673,\n",
      "          -0.2193,  0.2657, -0.1286,  0.0092,  0.0179,  0.0967,  0.2042,\n",
      "           0.0188,  0.1295, -0.0295,  0.0716, -0.4370,  0.0133, -0.1324,\n",
      "          -0.1468, -0.3058, -0.0549, -0.0925,  0.3258,  0.4311,  0.1081,\n",
      "          -0.1020, -0.1388, -0.0123,  0.0824]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0447,  1.2545, -0.4664,  1.7172,  2.1264, -0.2519, -0.9080,\n",
      "          -0.0988,  1.1704, -2.1523, -0.5855, -1.1158, -2.9079,  0.3782,\n",
      "           2.3037,  0.7980,  0.0000, -0.6149, -0.2803,  0.1081,  0.1244,\n",
      "           0.2528, -0.6048,  0.6490,  0.0000, -0.0134, -0.9920, -1.4426,\n",
      "           0.0000,  0.0000,  2.7913,  0.0000, -1.2161, -1.0196,  0.0882,\n",
      "          -0.0185, -0.6008,  0.2673,  0.6425,  0.0000, -0.2679, -0.9844,\n",
      "           0.1589, -0.2239,  1.0190, -0.3816,  0.0000, -2.1849, -2.1085,\n",
      "           0.4285,  0.0000,  0.0000,  0.4625,  0.4323, -2.0464,  0.0000,\n",
      "           0.0000, -0.1242, -0.8171,  1.5115,  0.3691, -0.7989, -0.3513,\n",
      "          -0.4275,  0.1153, -1.0634,  1.2920, -1.1348, -1.4301,  0.7686,\n",
      "           0.7184, -0.2438, -0.7988,  0.0000, -1.2764,  0.6311,  0.2607,\n",
      "           0.1704, -1.4213, -2.2301,  1.6304,  0.1554,  1.0572, -0.0068,\n",
      "           1.0074,  1.7522, -0.5065,  0.2261,  1.5821,  0.0145,  0.8280,\n",
      "           0.0000, -0.3061, -2.0888, -0.1636,  0.7981,  0.9418,  0.3354,\n",
      "          -1.9782,  0.0000,  1.2574,  1.1964, -0.5282, -0.4682,  0.5846,\n",
      "           1.3579,  2.2055,  0.0000,  0.0000, -0.1462, -1.2139, -1.7617,\n",
      "           0.1692,  0.0000, -0.4877,  0.5293, -0.6108,  0.0000,  0.0000,\n",
      "           0.5734,  0.6995, -1.1987, -0.8502, -0.2661,  0.8869, -0.7542,\n",
      "           1.0484,  2.0804, -1.2004, -2.0669, -1.1239,  0.0000,  1.2993,\n",
      "          -0.7233, -1.7857, -2.8104, -2.1605, -0.1083, -0.7178,  0.1087,\n",
      "           1.0378, -1.4278, -1.6466,  1.4237,  2.6917,  0.0000,  1.2630,\n",
      "           3.2325,  1.2307,  1.2100, -0.6048, -1.7824, -0.0645, -1.6571,\n",
      "          -0.1896, -0.7709,  0.0000,  0.6388,  1.3776,  0.2800, -0.1718,\n",
      "          -1.0612, -1.4685,  0.4448,  0.4868,  0.0000,  0.0333,  0.0000,\n",
      "          -0.2388, -1.4670,  0.5140,  1.3974,  0.5181, -0.8871,  1.1624,\n",
      "           1.5167, -0.3158, -0.0258,  0.4781, -0.3760,  0.4144, -0.3534,\n",
      "           0.9599,  0.3760,  1.9493,  0.0000, -1.0729, -0.1612,  0.7115,\n",
      "           0.0965, -0.7704, -1.2740,  0.7383,  0.8757,  0.3841, -1.2635,\n",
      "           2.8157, -0.4362,  0.6855,  0.1763,  0.0000, -1.0701,  0.9878,\n",
      "          -0.5555, -0.1357, -2.0007,  0.2932,  0.8689,  0.0000,  2.1706,\n",
      "           0.3261,  0.6176, -0.7076, -0.5392,  0.5765,  1.1522, -2.6899,\n",
      "          -0.0532, -1.5535, -1.1537,  0.0000,  0.0947,  0.0000,  2.1901,\n",
      "          -1.9716,  0.0000,  0.6134, -0.2504,  1.7971,  1.2115,  0.4037,\n",
      "           0.0847, -0.0390,  0.5899,  0.9647, -1.0874,  1.6294, -1.3610,\n",
      "          -0.0792, -0.5930,  2.6465, -1.0669, -0.0632,  1.1017,  1.1765,\n",
      "           0.1782, -0.0546, -0.2369,  0.5078,  1.2424, -1.8118, -0.0663,\n",
      "          -1.0721, -1.6390, -0.9917, -0.5375]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0463, 0.1555, 0.0720, 0.0882, 0.0968, 0.0791, 0.1717, 0.1049, 0.1236,\n",
      "         0.0620]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 6.2586e-02, -7.7671e-02, -2.0855e-01,  4.0621e-02, -1.1172e-01,\n",
      "          -6.4426e-02, -1.6881e-01, -2.4280e-01,  5.7817e-02, -4.2563e-02,\n",
      "           2.1442e-01,  8.6207e-02, -3.0086e-01,  1.6240e-03,  1.7829e-01,\n",
      "           2.0346e-01,  7.2463e-02,  2.2830e-02, -4.7951e-02, -9.2096e-02,\n",
      "          -1.5760e-01, -8.7014e-02,  1.6676e-01,  9.6328e-02, -5.7122e-02,\n",
      "           2.4215e-01,  1.1611e-01, -6.4727e-02, -2.3709e-01, -6.0481e-02,\n",
      "          -1.7247e-01, -1.5106e-01, -1.0470e-01,  3.8000e-02,  1.2663e-01,\n",
      "          -2.1221e-01, -1.5882e-01, -1.9120e-02, -1.4077e-01,  4.1450e-02,\n",
      "           9.2548e-02, -7.2514e-02,  3.2527e-02, -1.3275e-01, -9.3985e-02,\n",
      "           1.2669e-01,  5.4949e-02, -1.2582e-01,  1.7805e-01,  1.0882e-01,\n",
      "          -1.2799e-01, -8.2747e-03, -7.2428e-03, -1.1580e-01, -1.9084e-01,\n",
      "           2.2334e-02, -1.8175e-01,  1.6352e-01, -5.0665e-02, -6.8140e-02,\n",
      "          -1.9488e-01, -2.0170e-01, -1.1413e-01, -2.5079e-02,  1.9837e-01,\n",
      "           2.3485e-01,  9.4349e-02, -1.0867e-01,  1.2549e-02,  1.9539e-01,\n",
      "           2.2685e-01,  4.3528e-01, -7.2860e-03,  6.1674e-02,  2.4766e-01,\n",
      "          -8.5676e-02, -1.0535e-01,  3.3204e-01, -1.9694e-01,  8.4644e-02,\n",
      "          -2.4118e-01,  4.4100e-02, -1.9481e-01,  1.1739e-01,  8.4384e-02,\n",
      "           1.2128e-01, -8.5970e-02, -3.5451e-02, -3.3103e-02, -6.2943e-02,\n",
      "           3.3189e-01, -5.0015e-02,  3.0576e-01, -7.6280e-02,  2.2726e-01,\n",
      "           2.4078e-01,  7.3351e-02,  7.5403e-02,  1.0406e-01, -9.2575e-02,\n",
      "          -3.7434e-02,  3.0434e-01,  1.4707e-01, -2.3891e-01, -1.7395e-02,\n",
      "          -3.1846e-01, -2.1259e-02,  1.6428e-01, -1.8824e-01, -1.0018e-01,\n",
      "           4.1822e-02, -2.6245e-02, -8.2688e-02, -2.2135e-01, -3.9188e-02,\n",
      "          -5.6741e-02, -8.1187e-03, -2.0749e-01, -6.5246e-02,  1.4294e-01,\n",
      "           2.0153e-02, -2.0668e-01, -4.3436e-02, -2.6862e-02, -1.3991e-01,\n",
      "          -2.3172e-02,  7.6678e-02,  1.1815e-01, -9.8492e-02, -1.4628e-01,\n",
      "           3.6411e-01, -2.3576e-01, -8.1673e-02,  1.3326e-01, -1.4699e-01,\n",
      "          -2.4102e-01,  1.9198e-01, -8.9694e-02, -1.6868e-01,  6.0885e-02,\n",
      "           1.0684e-01,  3.1308e-01, -1.2688e-01,  2.9060e-01, -9.2753e-02,\n",
      "          -2.5411e-02,  7.7772e-02,  3.0225e-01,  3.0624e-02, -1.2887e-02,\n",
      "          -1.3798e-01, -2.5877e-01, -3.6227e-02,  1.6566e-01, -1.6591e-02,\n",
      "           1.4216e-01, -1.1171e-01,  3.3225e-01,  1.3186e-01, -1.1482e-01,\n",
      "           1.5575e-04,  1.0120e-01, -1.4985e-01,  1.3340e-01,  3.0557e-02,\n",
      "          -1.2190e-01,  1.1334e-02,  6.5732e-02,  6.3803e-02,  2.3926e-01,\n",
      "          -1.6030e-01,  2.6261e-01,  9.4303e-02, -1.6807e-02, -3.4637e-03,\n",
      "          -2.5222e-01, -7.8181e-02,  3.0734e-01,  3.6939e-01,  2.1304e-01,\n",
      "          -1.3603e-01, -2.2008e-01,  4.8564e-02,  9.3300e-02, -3.2997e-02,\n",
      "          -2.4187e-02, -2.2182e-01, -8.3457e-02, -5.6748e-02, -6.0117e-03,\n",
      "          -4.2165e-02,  1.0137e-02, -1.0678e-01, -3.6700e-02, -1.0863e-01,\n",
      "          -2.4636e-01, -5.1932e-02, -1.3954e-01, -3.2651e-01,  1.4291e-01,\n",
      "          -6.2564e-02,  2.8825e-02,  6.7597e-02, -1.1581e-02, -2.6646e-02,\n",
      "          -3.4582e-03,  1.4147e-01, -1.7715e-01, -6.0556e-02, -4.6424e-02,\n",
      "          -5.0544e-03,  2.0585e-01, -8.1391e-03,  1.6790e-01,  2.8171e-01,\n",
      "          -2.0466e-02,  2.1058e-01,  2.8338e-01,  4.4985e-02,  1.4213e-01,\n",
      "           2.7408e-01, -1.3790e-01,  1.0605e-01,  9.3589e-02,  2.1569e-02,\n",
      "           5.0903e-02,  3.8766e-01, -2.5615e-01, -6.3557e-02,  1.3519e-01,\n",
      "          -1.1289e-01, -2.0074e-01,  1.9842e-01, -1.4825e-01, -1.9397e-02,\n",
      "          -6.1837e-02, -9.1755e-03,  2.6515e-01,  9.3300e-02,  1.6791e-01,\n",
      "          -3.4914e-02,  9.9139e-02, -3.5051e-01,  2.2247e-02, -1.6284e-01,\n",
      "          -1.0204e-01, -3.5611e-01,  1.7719e-02, -6.0455e-02,  1.6817e-01,\n",
      "           3.5011e-01,  1.2836e-01, -1.0860e-01, -2.0202e-01, -1.7374e-03,\n",
      "           5.2671e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.0942e+00, -1.6148e-01,  3.7310e-01, -9.3201e-02,  7.0853e-01,\n",
      "           9.5508e-01,  6.0224e-01, -3.0261e-01,  2.4143e-01,  3.9723e-01,\n",
      "           1.0980e+00,  0.0000e+00, -6.7431e-01,  6.7272e-01, -6.1263e-01,\n",
      "           1.0059e+00, -3.3602e-01,  5.9726e-01,  3.3618e-01, -1.3971e+00,\n",
      "          -2.1201e+00,  1.1745e-01,  3.5574e-01,  6.8892e-01, -9.2415e-01,\n",
      "          -9.8038e-01,  3.3727e-01,  5.0695e-01, -1.9475e-01,  8.5845e-01,\n",
      "          -6.9880e-01,  1.0669e-01, -6.2908e-01, -2.1701e-01,  2.1026e-01,\n",
      "          -9.2822e-03, -4.4829e-01, -1.3332e+00,  1.4292e+00,  1.1821e+00,\n",
      "          -3.2114e+00,  3.1799e-01,  0.0000e+00, -1.1649e-01, -1.7016e+00,\n",
      "           0.0000e+00,  3.8431e-01, -1.1723e+00,  2.0965e+00,  5.1757e-01,\n",
      "           1.8875e+00, -1.1039e+00,  1.2033e-02,  1.0405e-01,  7.3070e-01,\n",
      "          -1.4764e-01, -1.3009e-01, -1.7408e-01, -7.0786e-01,  1.5829e+00,\n",
      "           0.0000e+00,  8.4857e-01, -5.3501e-01, -1.4271e+00, -1.7302e+00,\n",
      "          -1.0932e+00, -1.0572e+00,  1.5331e+00, -9.7601e-01, -2.8618e+00,\n",
      "          -8.7952e-01,  6.2379e-01,  6.3040e-01,  6.8980e-01,  8.2703e-01,\n",
      "           7.2563e-01, -1.5638e+00, -6.8602e-01,  9.9717e-01,  0.0000e+00,\n",
      "          -2.5652e+00,  0.0000e+00, -2.4384e-01,  0.0000e+00,  1.3184e-02,\n",
      "           7.6373e-01, -2.0535e+00,  4.7642e-01, -1.5655e+00,  1.4045e+00,\n",
      "           3.8679e-01,  2.2182e+00,  1.1675e+00,  3.6210e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.1112e+00, -1.5580e+00, -4.7135e-01,  2.9089e-01,\n",
      "           2.5618e+00, -3.8789e-02,  9.1053e-01,  1.0135e+00, -1.6310e+00,\n",
      "          -2.8225e-01,  0.0000e+00, -7.3098e-02, -1.7932e+00, -1.2236e-01,\n",
      "          -2.1291e+00, -3.0124e-01,  8.0628e-01,  0.0000e+00,  1.7413e+00,\n",
      "           0.0000e+00, -5.6723e-01,  0.0000e+00,  1.7225e+00,  3.9730e-01,\n",
      "          -1.0821e+00,  9.2985e-01,  1.3168e-01, -1.6019e-02,  0.0000e+00,\n",
      "           1.4319e+00,  1.3252e+00, -2.0541e+00,  0.0000e+00,  1.5838e+00,\n",
      "           2.5890e-02, -3.2779e-01,  1.8961e+00, -1.4198e-01,  5.6127e-01,\n",
      "          -1.5777e+00,  9.2483e-01, -2.0431e+00,  5.8597e-02, -6.0083e-01,\n",
      "          -1.3204e+00, -1.6198e+00, -2.6011e+00, -4.6928e-01,  1.1786e+00,\n",
      "           1.6322e+00,  2.6976e+00,  2.6487e-01,  0.0000e+00,  2.2879e-01,\n",
      "          -7.2621e-01, -3.7259e-01,  2.9953e-01,  4.8225e-01, -3.8976e-01,\n",
      "           6.4539e-01,  7.7851e-01, -2.0627e+00, -7.0194e-01, -6.5970e-01,\n",
      "          -1.0566e-01, -2.0279e-01,  5.9192e-01,  1.0009e+00,  4.4586e-01,\n",
      "          -6.3661e-03,  1.4760e-01,  4.8649e-01,  1.4363e+00,  0.0000e+00,\n",
      "          -1.0582e+00,  7.6204e-01,  8.7996e-01,  3.1005e-01,  4.7289e-01,\n",
      "          -4.0976e-01,  1.2828e-01, -5.8219e-01, -8.4134e-01,  6.7623e-01,\n",
      "           0.0000e+00, -4.5110e-01, -1.5850e+00, -3.7758e-01,  0.0000e+00,\n",
      "          -1.4817e+00, -3.0928e+00,  1.2700e+00,  1.4640e-01,  2.0818e-01,\n",
      "          -2.2931e+00, -4.4149e-01,  2.2690e-01,  2.3421e-01, -5.8265e-01,\n",
      "           2.4109e-01, -1.6562e-01,  3.7288e-01,  0.0000e+00, -3.9393e-01,\n",
      "          -7.1967e-01,  1.0417e+00,  1.1621e+00, -1.1102e-01, -4.1160e-02,\n",
      "          -1.6270e+00,  1.7329e+00, -2.3601e-01, -5.5291e-01,  1.0346e+00,\n",
      "           6.0887e-01, -5.1558e-01,  5.3279e-02,  1.3250e+00, -1.3381e+00,\n",
      "           1.2869e-01, -1.7174e+00,  0.0000e+00,  4.2294e-02,  0.0000e+00,\n",
      "           2.0962e-01,  8.2810e-01,  4.4073e-01,  1.1008e+00,  9.4175e-01,\n",
      "           1.0811e+00,  0.0000e+00,  3.7849e-01, -3.6040e-01, -2.0731e-03,\n",
      "           1.9906e+00, -4.4544e-01, -1.7798e+00,  1.4101e+00, -1.8060e+00,\n",
      "          -1.9360e+00,  6.7361e-01, -1.1327e-01, -6.5182e-01,  8.8682e-01,\n",
      "           6.4463e-01,  2.6350e-01,  1.2353e+00,  2.4037e-01,  1.2993e+00,\n",
      "           7.2256e-01, -5.9335e-01,  1.7863e-01, -8.1824e-02, -2.4675e-02,\n",
      "          -1.5750e-01,  1.3647e+00, -9.0931e-01,  0.0000e+00,  8.9162e-01,\n",
      "          -6.9688e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0651, 0.1041, 0.0715, 0.0782, 0.1719, 0.1861, 0.0654, 0.0775, 0.1109,\n",
      "         0.0693]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0716, -0.1031, -0.2170,  0.0193, -0.1116, -0.0970, -0.2326,\n",
      "          -0.2352, -0.0310, -0.0816,  0.2350,  0.1344, -0.2507,  0.0728,\n",
      "           0.2382,  0.2348,  0.0957, -0.0371, -0.1037, -0.1221, -0.1402,\n",
      "          -0.0761,  0.1612,  0.1255, -0.0871,  0.2716,  0.1265, -0.0969,\n",
      "          -0.2594, -0.0975, -0.1869, -0.1704, -0.1123,  0.0452,  0.0551,\n",
      "          -0.2133, -0.1971, -0.0917, -0.1019,  0.0446,  0.1295, -0.1053,\n",
      "           0.0593, -0.1000, -0.0833,  0.1118,  0.1244, -0.0100,  0.2058,\n",
      "           0.1078, -0.0951,  0.0997, -0.0250, -0.1618, -0.1248,  0.0116,\n",
      "          -0.1927,  0.0695, -0.0746, -0.0507, -0.1605, -0.1257, -0.1528,\n",
      "          -0.0196,  0.2182,  0.2269,  0.1279, -0.0630, -0.0211,  0.1487,\n",
      "           0.2061,  0.4574, -0.0908,  0.1002,  0.2134, -0.0827, -0.1129,\n",
      "           0.3428, -0.2291,  0.0420, -0.3322, -0.0129, -0.2271,  0.1428,\n",
      "           0.0812,  0.0777, -0.0942, -0.0540, -0.0414,  0.0126,  0.2966,\n",
      "          -0.0443,  0.2867, -0.0462,  0.2420,  0.2812,  0.0320,  0.0253,\n",
      "           0.1183, -0.0871, -0.0036,  0.2585,  0.0744, -0.2075, -0.0486,\n",
      "          -0.2273, -0.0310,  0.1745, -0.1982, -0.0907, -0.0514, -0.0130,\n",
      "          -0.1112, -0.2424, -0.0922, -0.0812,  0.0218, -0.1545, -0.0332,\n",
      "           0.1963, -0.0145, -0.1187, -0.0637,  0.0822, -0.1710,  0.0044,\n",
      "           0.0196,  0.1247, -0.0864, -0.1986,  0.4232, -0.2122, -0.1185,\n",
      "           0.1025, -0.1886, -0.2326,  0.1646, -0.1173, -0.1570,  0.0994,\n",
      "           0.1140,  0.3572, -0.1599,  0.2662, -0.0927,  0.0198,  0.0403,\n",
      "           0.2476, -0.0058, -0.0027, -0.1173, -0.2564, -0.0278,  0.1546,\n",
      "           0.0099,  0.1810, -0.1008,  0.3452,  0.1539, -0.1237, -0.0331,\n",
      "           0.1461, -0.1752,  0.0746, -0.0082, -0.1494,  0.0170,  0.0356,\n",
      "           0.0462,  0.2328, -0.1066,  0.1889,  0.1190, -0.0195, -0.0312,\n",
      "          -0.2873, -0.0948,  0.2800,  0.3632,  0.2029, -0.1283, -0.2593,\n",
      "           0.0822,  0.0911, -0.0889, -0.0118, -0.2148, -0.0756, -0.0386,\n",
      "          -0.0508,  0.0375,  0.1151, -0.1559, -0.0158, -0.0873, -0.1892,\n",
      "           0.0799, -0.1254, -0.3333,  0.1423, -0.0856,  0.0723,  0.0531,\n",
      "          -0.1057, -0.0770, -0.0317,  0.2074, -0.1456, -0.0657, -0.0264,\n",
      "          -0.0441,  0.1711,  0.0547,  0.1886,  0.2771,  0.0986,  0.2255,\n",
      "           0.2812,  0.0189,  0.1082,  0.2768, -0.0995,  0.1297,  0.1058,\n",
      "           0.0248,  0.0870,  0.3921, -0.2730, -0.0300,  0.1259, -0.1301,\n",
      "          -0.2112,  0.2154, -0.1251,  0.0177,  0.0157,  0.0808,  0.2153,\n",
      "           0.0666,  0.1206, -0.0168,  0.0746, -0.3810,  0.0328, -0.0956,\n",
      "          -0.1449, -0.3144, -0.0377, -0.1137,  0.2686,  0.4070,  0.0812,\n",
      "          -0.0740, -0.2037, -0.0202,  0.0913]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.4108e+00,  1.2046e+00,  9.7292e-01,  1.7490e+00,  0.0000e+00,\n",
      "          -5.7352e-01, -2.7621e-01,  1.2993e+00, -1.9235e+00,  0.0000e+00,\n",
      "           0.0000e+00,  2.5608e-01,  2.5435e+00, -4.5152e-01,  0.0000e+00,\n",
      "           6.9001e-03,  1.0667e+00,  1.1262e+00, -2.3072e-01,  0.0000e+00,\n",
      "          -3.3893e-01, -3.9142e-01, -6.5329e-01,  1.1381e+00, -1.9864e-01,\n",
      "          -1.0427e+00,  0.0000e+00,  1.9119e+00, -1.2534e+00, -9.7195e-02,\n",
      "          -1.5307e+00,  1.0683e+00,  3.7037e-01,  6.9275e-01,  2.8296e-01,\n",
      "           2.6367e-01,  1.7797e+00,  1.5885e+00,  0.0000e+00, -3.8795e-01,\n",
      "          -9.8030e-01,  8.2198e-01, -1.6216e+00, -1.4916e-01, -4.7454e-01,\n",
      "           2.4420e+00,  2.6339e-01,  0.0000e+00, -2.8282e-01,  0.0000e+00,\n",
      "          -1.7069e+00,  2.7233e-01, -1.5117e+00, -1.1756e+00,  0.0000e+00,\n",
      "          -6.2546e-01,  0.0000e+00, -4.5996e-01, -1.9706e+00, -6.9712e-01,\n",
      "           1.7349e+00,  1.2813e+00, -4.8728e-01, -1.9248e+00, -3.2332e-01,\n",
      "           2.4217e-01,  2.7842e+00, -6.0243e-01,  0.0000e+00, -8.3639e-01,\n",
      "          -1.4827e+00, -1.1658e+00,  7.1573e-01, -9.5038e-01, -1.0008e+00,\n",
      "          -6.6398e-01,  6.6287e-01,  0.0000e+00,  1.1974e+00, -4.1245e-01,\n",
      "           0.0000e+00,  5.8187e-02, -3.1966e-01,  1.0715e+00,  1.6596e+00,\n",
      "          -8.2373e-01,  4.2815e-01,  1.0539e+00, -9.9443e-03,  3.7157e-01,\n",
      "           2.7944e-03, -2.7304e+00,  0.0000e+00,  1.5108e+00,  3.5249e-01,\n",
      "          -6.1509e-01, -1.4923e+00,  4.8991e-01,  2.3308e-01, -8.1807e-01,\n",
      "          -2.5503e-01,  0.0000e+00, -2.5818e-01,  0.0000e+00,  2.6445e-01,\n",
      "          -1.6305e+00,  5.4859e-01, -8.2307e-01,  0.0000e+00,  3.5584e-01,\n",
      "          -4.2190e-01, -1.8700e-01, -1.0645e+00,  4.1284e-01, -1.1434e-01,\n",
      "          -6.6349e-01,  9.5991e-01, -1.6088e+00,  1.4028e+00,  4.6148e-01,\n",
      "          -5.6078e-02, -7.7892e-01,  1.9585e+00,  7.7081e-01,  0.0000e+00,\n",
      "          -1.7006e-01, -2.5836e-01, -1.0183e+00,  1.3480e+00,  1.6621e+00,\n",
      "           1.1782e+00,  8.1850e-01,  0.0000e+00, -1.2463e-01, -2.4703e+00,\n",
      "          -8.9972e-01,  2.7210e-01, -2.0262e+00, -4.1258e-01,  2.7588e-01,\n",
      "           4.9093e-01,  4.0604e-01,  0.0000e+00,  1.8034e+00,  7.3625e-01,\n",
      "           9.6338e-01,  3.8347e-01,  8.8303e-01,  1.7997e+00,  4.0662e-01,\n",
      "           7.2781e-02, -2.9217e-02,  0.0000e+00,  3.9949e-02,  1.1882e-01,\n",
      "           5.1080e-01, -1.8822e+00, -4.9237e-01,  6.2122e-01,  0.0000e+00,\n",
      "           1.0473e+00,  1.5961e+00,  7.2220e-01,  8.8898e-01,  3.0720e-01,\n",
      "          -4.5706e-01, -5.2548e-01, -3.1547e+00, -1.7068e+00, -1.3861e+00,\n",
      "          -1.3065e+00, -1.2185e+00,  1.6048e-01,  0.0000e+00, -1.3603e-02,\n",
      "           5.0219e-01, -3.6403e+00,  1.4778e+00,  1.5082e+00, -1.2040e+00,\n",
      "          -7.3574e-01,  1.3161e+00,  1.5892e+00,  2.4443e+00,  1.4076e-01,\n",
      "           7.5090e-01,  3.8451e-01,  9.0845e-01,  1.8069e-03, -1.2015e+00,\n",
      "           3.5640e-01,  1.1229e+00, -1.3018e+00, -1.6709e+00,  1.9593e-01,\n",
      "          -9.5554e-01,  1.0559e+00,  0.0000e+00,  1.0683e+00, -9.1263e-01,\n",
      "          -1.2372e+00,  1.6947e+00, -8.7105e-01,  0.0000e+00, -4.0811e-01,\n",
      "           7.6642e-01, -4.2574e-01,  9.8905e-01, -1.2651e+00,  0.0000e+00,\n",
      "           1.4429e-01, -7.8977e-01, -8.6592e-01, -6.7803e-01,  1.1198e-02,\n",
      "          -1.7491e+00,  3.0862e-01, -2.6416e-01, -1.2891e+00, -9.7355e-02,\n",
      "          -3.2190e-01,  1.4432e+00,  2.0126e-01, -3.8117e-01,  0.0000e+00,\n",
      "           2.5285e-01, -6.6129e-01, -9.5064e-01, -1.4052e+00,  2.2719e-01,\n",
      "           1.3671e+00,  8.3675e-01, -7.8910e-02, -4.8190e-01, -2.8515e-01,\n",
      "           1.6259e+00, -1.4469e+00, -6.0237e-01,  1.5098e+00, -3.3157e+00,\n",
      "           0.0000e+00,  9.8453e-01, -4.6269e-01, -3.0511e-01,  7.8416e-01,\n",
      "          -1.1189e-01, -7.5986e-01,  1.5271e+00,  7.0966e-02, -1.4001e+00,\n",
      "           0.0000e+00,  0.0000e+00,  1.9342e+00, -3.3555e+00, -3.7287e-01,\n",
      "           9.3595e-02]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0665, 0.1073, 0.1304, 0.1397, 0.0638, 0.1503, 0.0532, 0.0381, 0.0921,\n",
      "         0.1588]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0634, -0.0556, -0.2350, -0.0059, -0.1344, -0.0553, -0.1979,\n",
      "          -0.3120, -0.0232, -0.0926,  0.2811,  0.0411, -0.2920,  0.0123,\n",
      "           0.1921,  0.2092,  0.0981, -0.0445, -0.1375, -0.1161, -0.1192,\n",
      "          -0.1267,  0.1545,  0.0677, -0.0831,  0.2436,  0.0721, -0.0814,\n",
      "          -0.2258, -0.0791, -0.1632, -0.1555, -0.1013,  0.0036,  0.0602,\n",
      "          -0.1253, -0.1546, -0.1253, -0.1410,  0.0815,  0.1590, -0.1289,\n",
      "           0.0297, -0.1066, -0.0387,  0.1447,  0.0467, -0.0890,  0.2124,\n",
      "           0.0886, -0.1226,  0.0196, -0.0424, -0.0926, -0.1664,  0.0034,\n",
      "          -0.1590,  0.1090, -0.0213, -0.0292, -0.1692, -0.1671, -0.1368,\n",
      "           0.0010,  0.1489,  0.2092,  0.0641, -0.0691,  0.0558,  0.1711,\n",
      "           0.2380,  0.4093, -0.0732,  0.1180,  0.1731, -0.0365, -0.0984,\n",
      "           0.3624, -0.2332,  0.0682, -0.3181, -0.0879, -0.2739,  0.1501,\n",
      "           0.0984,  0.0866, -0.1059, -0.0101, -0.0612, -0.0868,  0.3009,\n",
      "          -0.0452,  0.3022, -0.0792,  0.2363,  0.1935,  0.0560,  0.0589,\n",
      "           0.0864,  0.0212, -0.0407,  0.2081,  0.1293, -0.1297, -0.1076,\n",
      "          -0.2680,  0.0085,  0.1722, -0.1859, -0.0336,  0.0187, -0.0122,\n",
      "          -0.0402, -0.2625, -0.1127, -0.0792,  0.0075, -0.1579,  0.0033,\n",
      "           0.1223,  0.0209, -0.1675, -0.1142,  0.0461, -0.1551, -0.0122,\n",
      "           0.0083,  0.0881, -0.0566, -0.1853,  0.3785, -0.1968, -0.0786,\n",
      "           0.0762, -0.1862, -0.2035,  0.2047, -0.0212, -0.2032,  0.0505,\n",
      "           0.0778,  0.3588, -0.1594,  0.2949, -0.0681, -0.0129,  0.0479,\n",
      "           0.3004, -0.0015,  0.0280, -0.2432, -0.1849, -0.0012,  0.1926,\n",
      "           0.0300,  0.1435, -0.1060,  0.3494,  0.1400, -0.1251, -0.0384,\n",
      "           0.0899, -0.1604,  0.2133,  0.0130, -0.0862,  0.0488,  0.0476,\n",
      "           0.1003,  0.1864, -0.2095,  0.2015,  0.2173,  0.0044, -0.0877,\n",
      "          -0.2313, -0.0753,  0.3153,  0.3930,  0.1926, -0.1603, -0.2916,\n",
      "          -0.0117,  0.0854, -0.0104,  0.0255, -0.2735, -0.0885, -0.0340,\n",
      "          -0.0631, -0.0100,  0.0954, -0.1792,  0.0073, -0.0494, -0.2346,\n",
      "           0.0159, -0.1286, -0.3004,  0.1881, -0.0688,  0.0774,  0.0787,\n",
      "           0.0111,  0.0332, -0.0258,  0.1903, -0.0830, -0.0130, -0.0377,\n",
      "          -0.0007,  0.1393,  0.1043,  0.1831,  0.2188,  0.1486,  0.1038,\n",
      "           0.2992, -0.0278,  0.1252,  0.3045, -0.1166,  0.2132,  0.0305,\n",
      "           0.0194,  0.1357,  0.3968, -0.2116, -0.1551,  0.1797, -0.2221,\n",
      "          -0.2140,  0.1278, -0.2325, -0.0330, -0.0354,  0.0063,  0.2072,\n",
      "           0.1593,  0.1395, -0.0243,  0.0167, -0.3545,  0.0420, -0.0927,\n",
      "          -0.1136, -0.3441, -0.0524, -0.0898,  0.2091,  0.3877,  0.0652,\n",
      "          -0.1166, -0.2224, -0.0445,  0.1493]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.9119e-01, -1.3354e+00,  2.1099e-01, -2.2618e+00,  6.4636e-04,\n",
      "          -1.7007e+00, -8.2231e-01, -3.5070e-01,  0.0000e+00, -3.1731e-01,\n",
      "          -5.1628e-01, -1.1944e+00, -1.0673e+00,  6.3668e-01, -1.0269e+00,\n",
      "           3.4041e-02,  2.2509e+00,  9.9592e-01, -3.4946e-01,  0.0000e+00,\n",
      "          -8.9269e-02,  4.3754e-01,  1.5168e-01, -6.3569e-02,  6.1427e-01,\n",
      "          -8.8232e-01, -6.4895e-01, -7.3378e-01,  0.0000e+00,  3.6049e-01,\n",
      "          -1.2031e+00, -1.6627e+00,  0.0000e+00,  1.0810e+00,  0.0000e+00,\n",
      "           1.1339e-01,  7.0535e-02, -6.6598e-01, -1.2916e+00, -6.1794e-01,\n",
      "          -8.8200e-01,  1.1468e+00, -3.5137e-01, -1.3347e+00, -9.4534e-01,\n",
      "          -5.9038e-01,  1.2608e-01,  1.0110e-01, -1.6833e+00, -3.3103e-01,\n",
      "           7.8903e-01, -5.4585e-01, -1.1098e+00,  2.6849e+00, -1.3919e+00,\n",
      "           1.3366e+00, -2.3908e-01, -4.5462e-01, -5.1374e-01, -1.5783e+00,\n",
      "           3.2391e-01,  5.7432e-01, -3.6217e-01,  2.0314e+00,  2.5476e-01,\n",
      "           0.0000e+00, -1.1817e+00, -6.0143e-01,  1.7067e+00, -1.2018e-01,\n",
      "          -1.9143e-01, -8.5850e-01,  3.7878e-02, -4.5709e-01, -7.3669e-01,\n",
      "          -2.2809e-01, -2.1237e-01,  4.6161e-01,  0.0000e+00, -1.5064e-01,\n",
      "           5.7763e-01, -2.6082e-01,  8.9065e-01, -4.0329e-01, -3.5789e-01,\n",
      "           1.5703e+00,  0.0000e+00, -3.0962e-01, -4.1276e-01,  0.0000e+00,\n",
      "          -4.7683e-01,  2.3073e+00,  7.6895e-01,  0.0000e+00, -3.5877e-02,\n",
      "          -6.2503e-01,  2.6331e-02, -7.1168e-01, -3.7923e-01,  1.2894e+00,\n",
      "          -4.8416e-01,  6.5805e-01, -9.0989e-01,  2.9476e-01, -6.7460e-01,\n",
      "          -1.6351e+00, -9.7365e-01,  3.3132e-01,  0.0000e+00, -1.0295e+00,\n",
      "          -2.6866e-01,  9.2784e-01, -9.1704e-01,  8.7424e-01,  4.2044e-01,\n",
      "          -8.8492e-01, -1.0783e+00,  6.7065e-01,  7.2833e-01,  1.2682e+00,\n",
      "          -5.9006e-01, -1.1836e+00,  1.4784e+00,  1.0935e-02, -7.4200e-02,\n",
      "           6.9780e-01, -1.6769e+00, -2.9829e+00,  8.7541e-01, -5.9235e-01,\n",
      "           1.3423e-01, -6.6619e-01, -4.8746e-01, -2.3578e-01,  0.0000e+00,\n",
      "           5.9203e-01, -1.6902e+00,  0.0000e+00,  7.3946e-01, -4.4766e-01,\n",
      "          -1.3399e+00, -1.5561e+00, -2.3503e+00, -1.0212e+00, -5.1428e-01,\n",
      "           1.3421e+00,  6.0355e-01,  1.3350e+00, -1.8696e+00,  1.5140e+00,\n",
      "           0.0000e+00, -3.2010e-01,  9.3406e-01,  0.0000e+00, -2.4319e-01,\n",
      "           0.0000e+00,  8.9767e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           8.0079e-02,  1.3867e+00,  6.2122e-01,  1.6514e+00, -7.3496e-01,\n",
      "           7.5351e-01,  0.0000e+00, -9.3745e-01,  4.5690e-01, -2.5401e-02,\n",
      "          -6.1644e-01,  5.2288e-01, -2.0450e+00, -7.8586e-01,  1.5514e+00,\n",
      "           0.0000e+00,  5.0686e-01, -1.3200e-01,  9.3654e-01,  1.4383e+00,\n",
      "          -3.3950e+00,  7.0414e-01,  1.7652e+00, -1.4552e+00,  0.0000e+00,\n",
      "          -3.8979e-02,  2.0232e+00,  1.0557e+00,  0.0000e+00, -1.2685e+00,\n",
      "           3.9563e-01, -2.7743e-01, -2.2389e-01, -7.6048e-01,  1.1299e+00,\n",
      "           3.9220e-01,  1.1398e-01,  6.0585e-01, -3.4489e-01, -9.0643e-01,\n",
      "          -1.4949e+00,  0.0000e+00, -1.4187e+00, -5.7934e-02,  1.8545e+00,\n",
      "          -1.8651e+00, -3.5664e-01,  0.0000e+00, -2.9119e-01,  7.7784e-01,\n",
      "          -9.2175e-01,  5.6641e-01, -8.5528e-02,  0.0000e+00,  4.9222e-01,\n",
      "           4.7624e-01, -1.1378e+00, -6.6269e-01,  4.2814e-01,  1.0407e+00,\n",
      "          -8.7490e-02, -6.5458e-01,  1.7758e+00,  7.0420e-01,  6.8844e-01,\n",
      "           1.0312e+00,  5.6120e-02, -1.0737e+00,  1.1689e+00, -5.7928e-01,\n",
      "          -6.0991e-01,  2.5952e-01,  8.1841e-01,  6.5348e-01,  3.9904e-01,\n",
      "          -1.1064e+00,  0.0000e+00, -1.7438e+00, -1.0923e+00, -3.6891e-01,\n",
      "          -8.4189e-01, -1.7035e-01,  4.1766e-01, -1.5440e+00, -1.1297e+00,\n",
      "           3.3947e+00,  0.0000e+00, -1.8441e+00, -4.7456e-01, -2.8949e-01,\n",
      "           0.0000e+00, -7.4484e-02, -2.1764e+00, -9.2438e-01,  0.0000e+00,\n",
      "           2.7558e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0854, 0.0442, 0.1036, 0.2261, 0.1176, 0.0845, 0.0604, 0.0547, 0.1741,\n",
      "         0.0494]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.1163e-04, -3.9677e-02, -1.9629e-01, -2.8177e-03, -8.2672e-02,\n",
      "          -4.0110e-02, -2.0324e-01, -2.8161e-01, -6.9248e-02, -8.6329e-02,\n",
      "           2.5921e-01,  1.3149e-01, -3.1245e-01,  4.0827e-02,  1.8937e-01,\n",
      "           2.1201e-01,  6.4763e-02,  9.9676e-03, -1.3876e-01, -9.2934e-02,\n",
      "          -1.1333e-01, -1.1316e-01,  1.2290e-01, -2.7247e-02, -7.1608e-02,\n",
      "           2.7411e-01,  1.4702e-01, -4.4914e-02, -2.5369e-01, -5.4661e-02,\n",
      "          -6.2983e-02, -1.6783e-01, -1.0667e-01,  4.1017e-02,  6.5707e-02,\n",
      "          -2.0434e-01, -1.1093e-01, -7.9601e-02, -7.4916e-02,  8.0953e-02,\n",
      "           1.6920e-01, -1.1666e-01,  6.2073e-02, -1.2566e-01, -1.0148e-01,\n",
      "           1.1859e-01,  9.2762e-02, -2.9172e-02,  2.3066e-01,  5.2794e-02,\n",
      "          -9.9436e-02,  6.2737e-02, -2.7159e-02, -1.0093e-01, -1.3742e-01,\n",
      "          -1.9244e-02, -1.4565e-01,  6.5949e-02, -1.3194e-02, -1.2797e-01,\n",
      "          -1.3863e-01, -1.5789e-01, -7.4006e-02, -1.5784e-02,  1.3164e-01,\n",
      "           2.5961e-01,  6.4819e-02, -4.9794e-02,  4.0066e-02,  1.9870e-01,\n",
      "           2.6047e-01,  3.9120e-01, -1.2708e-01,  7.3826e-02,  2.4999e-01,\n",
      "           2.0341e-02, -1.2079e-01,  3.9098e-01, -2.4368e-01,  8.3841e-02,\n",
      "          -3.1771e-01, -6.3338e-02, -2.6287e-01,  1.5226e-01,  1.4527e-01,\n",
      "           8.4077e-02, -7.4970e-02, -1.8727e-02, -3.0759e-02, -6.5320e-02,\n",
      "           2.9005e-01, -4.8042e-02,  2.8115e-01, -5.7530e-02,  2.8934e-01,\n",
      "           1.9925e-01,  5.7508e-02, -5.2090e-02,  1.7775e-01, -5.9411e-02,\n",
      "          -1.0090e-01,  2.6963e-01,  1.2979e-01, -2.2445e-01, -3.1310e-02,\n",
      "          -2.5045e-01, -9.9736e-03,  2.1239e-01, -2.1785e-01, -1.3075e-02,\n",
      "          -5.8256e-02, -5.2881e-02, -5.3055e-02, -2.7817e-01, -1.1034e-01,\n",
      "          -7.2482e-02,  4.6503e-02, -1.4636e-01,  3.9244e-02,  1.3828e-01,\n",
      "          -3.9781e-02, -1.3440e-01, -1.1658e-01,  3.4133e-03, -1.2340e-01,\n",
      "          -1.4732e-02, -3.6303e-03,  9.7726e-02, -1.4268e-01, -1.8352e-01,\n",
      "           4.0717e-01, -2.3652e-01, -2.1080e-01,  9.8132e-02, -1.2870e-01,\n",
      "          -3.0638e-01,  1.2907e-01,  1.4361e-02, -1.5998e-01,  5.7055e-02,\n",
      "           1.1402e-01,  3.8303e-01, -2.2307e-01,  2.5717e-01, -1.2442e-01,\n",
      "           2.3499e-02,  2.1436e-02,  2.5681e-01, -1.3751e-02,  4.1611e-02,\n",
      "          -2.4012e-01, -1.9360e-01,  1.8669e-03,  1.0222e-01,  2.1838e-02,\n",
      "           1.2052e-01, -9.6835e-02,  3.8153e-01,  9.1418e-02, -1.3716e-01,\n",
      "          -2.5756e-02,  1.8184e-01, -1.3979e-01,  1.4822e-01,  4.6636e-02,\n",
      "          -1.0778e-01,  7.8705e-02,  1.1448e-01,  3.4976e-02,  1.2548e-01,\n",
      "          -2.1408e-01,  1.9447e-01,  1.7346e-01,  6.3090e-02,  1.0492e-03,\n",
      "          -2.5729e-01, -7.5440e-02,  3.0086e-01,  3.4866e-01,  1.7118e-01,\n",
      "          -1.4288e-01, -2.6840e-01,  1.2689e-03,  9.2249e-02,  7.3358e-03,\n",
      "           3.6904e-02, -2.1205e-01, -1.6607e-01, -7.9728e-02, -5.2551e-02,\n",
      "           4.3908e-02,  6.4950e-02, -1.7093e-01,  8.1234e-02, -1.6657e-01,\n",
      "          -2.0288e-01,  7.6851e-02, -1.4710e-01, -3.0228e-01,  1.1477e-01,\n",
      "          -8.1824e-02,  4.4175e-02,  3.6870e-02, -3.7236e-02,  3.5896e-02,\n",
      "          -6.0451e-02,  2.1206e-01, -1.8356e-01,  3.3280e-02, -1.5577e-02,\n",
      "          -7.4194e-02,  2.3204e-01,  1.3654e-01,  1.2867e-01,  2.1380e-01,\n",
      "           6.1609e-02,  1.8787e-01,  3.2144e-01, -9.0867e-03,  1.0298e-01,\n",
      "           2.6764e-01, -1.0657e-01,  1.9406e-01,  9.3168e-02, -1.1235e-02,\n",
      "           1.0439e-01,  3.1296e-01, -2.2808e-01, -8.6833e-02,  1.7537e-01,\n",
      "          -1.6089e-01, -1.7472e-01,  1.1448e-01, -1.7416e-01,  6.2532e-02,\n",
      "          -7.8162e-03,  5.3709e-02,  2.5917e-01,  1.9132e-01,  1.5041e-01,\n",
      "           1.5741e-02,  3.4271e-02, -3.5670e-01,  8.6153e-02, -1.6906e-02,\n",
      "          -1.2252e-01, -3.2022e-01, -4.4371e-02, -1.2717e-01,  1.0263e-01,\n",
      "           4.0309e-01,  1.0384e-01, -7.1980e-02, -2.7011e-01, -5.3272e-02,\n",
      "           1.6498e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2629,  1.6779,  0.2968, -0.5750,  3.4851, -1.4548,  0.0000,\n",
      "           0.2400, -0.9153,  0.0000,  2.6690, -0.6960,  0.0500,  0.0051,\n",
      "           0.2250,  1.8283, -0.6893, -0.5459,  0.4157,  0.0000,  0.0788,\n",
      "           1.5088,  0.8347, -1.4944,  0.0000, -1.7651, -1.4720,  0.6580,\n",
      "          -0.9665, -0.6423,  0.2613, -0.1120, -0.1565,  0.7976,  0.0000,\n",
      "          -0.1107,  0.1422, -0.0574,  1.3514,  0.9057,  0.5842,  0.7111,\n",
      "          -0.1831,  0.4925,  1.4446,  1.6110,  1.1102,  0.5098,  1.2336,\n",
      "          -0.2596,  2.7285,  0.8388,  1.5724,  0.8708, -1.4635, -0.0116,\n",
      "           0.6095,  0.2340,  0.1373,  3.0203,  0.5011, -0.2254, -1.2822,\n",
      "           0.5856,  0.0000, -0.2704, -2.0084,  0.0000, -0.9637, -0.1945,\n",
      "           1.4159, -1.8747, -0.1040,  0.9198, -0.3676, -1.7449,  2.0382,\n",
      "          -3.3838,  0.3085,  1.0931, -0.5338, -0.4038, -0.0606, -0.5079,\n",
      "          -0.5949, -0.3366, -0.3197,  1.2415,  2.6387, -0.3249,  0.0000,\n",
      "           1.0990, -0.0823,  0.0000,  0.0256,  0.4082,  0.1838, -2.0605,\n",
      "          -2.6009, -0.6283,  0.0000,  0.3701,  0.0000, -0.9721,  0.0000,\n",
      "          -0.4886,  0.8989,  0.7550,  1.5310,  1.1111, -0.3504, -0.3044,\n",
      "           0.0616,  0.2249,  1.4928,  0.5854,  0.0000, -0.9448,  0.3953,\n",
      "          -0.0963,  0.7853, -0.4964,  0.5333,  2.5223, -1.0734, -1.1791,\n",
      "           1.2512, -0.5784, -0.3873,  0.0000, -0.3120, -1.2743,  0.0000,\n",
      "           0.1772, -0.1305,  0.0000,  0.6265, -0.3392, -0.1624, -0.9016,\n",
      "          -0.3741,  0.0492,  0.5967,  0.5969,  0.4851,  0.0000, -1.7922,\n",
      "          -2.1644, -1.4011,  0.4160,  2.2391,  1.3648, -1.6435,  1.3130,\n",
      "           0.0485,  1.4269,  0.2921,  1.0294,  1.8282, -2.7867, -0.4636,\n",
      "          -1.1795, -0.1214,  1.5387, -1.6558,  1.8459, -0.7333, -0.7068,\n",
      "           0.7395,  1.2301, -2.0056,  0.4767,  0.0000,  0.1027,  0.0537,\n",
      "           1.4794,  0.5382,  0.7237, -0.2890, -0.3088,  0.7291,  1.3133,\n",
      "          -0.8679, -2.3117, -0.4018,  0.0831,  0.3727, -0.7966,  0.8793,\n",
      "          -1.4391, -0.0398,  2.2957,  1.1978, -1.7861, -0.0557,  0.5866,\n",
      "           0.0997, -2.8522,  0.7188,  0.0000, -1.5057, -1.2404,  1.0066,\n",
      "          -0.2653, -1.3836,  0.1335,  0.4568,  1.0248, -1.8637,  0.7868,\n",
      "          -0.5532,  0.7202, -0.3605, -0.9476,  1.1000, -1.1798, -2.1544,\n",
      "           1.1983,  0.4142,  1.2091,  0.4626, -0.1882,  0.8640, -1.3418,\n",
      "           0.3399,  0.3657,  2.4741,  0.0000, -0.9321,  0.4698,  1.0501,\n",
      "           1.4094, -1.3058,  0.1703, -1.1170,  0.5181,  0.2264,  0.8476,\n",
      "           1.1817, -0.1271,  0.4642, -1.6017, -2.6210,  0.8619,  0.6780,\n",
      "          -0.1252,  0.0653, -1.1062, -2.5209,  0.5182, -0.6576, -0.0836,\n",
      "           0.1525,  0.0000, -1.3010, -0.0928]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0271, 0.0566, 0.1347, 0.1206, 0.0670, 0.1512, 0.0643, 0.1347, 0.1842,\n",
      "         0.0594]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.8196e-02, -1.0516e-01, -1.5672e-01, -3.4365e-02, -9.6993e-02,\n",
      "          -7.7963e-02, -2.0511e-01, -2.8184e-01,  2.8105e-04, -1.1222e-01,\n",
      "           2.5321e-01,  1.2013e-01, -3.0220e-01,  8.4351e-02,  2.2019e-01,\n",
      "           2.1574e-01,  6.9205e-02,  4.4509e-02, -1.0943e-01, -7.1169e-02,\n",
      "          -1.0939e-01, -1.3080e-01,  2.1383e-01,  1.5314e-02, -8.1178e-02,\n",
      "           2.4421e-01,  1.2359e-01, -5.6282e-02, -2.6239e-01, -5.5201e-02,\n",
      "          -1.2957e-01, -1.6508e-01, -6.0728e-02,  3.6480e-02,  3.9765e-02,\n",
      "          -2.0753e-01, -1.9610e-01, -3.1033e-02, -1.5648e-01,  6.9321e-02,\n",
      "           1.2734e-01, -7.6181e-02,  8.2053e-02, -9.8837e-02, -1.0781e-01,\n",
      "           1.7598e-01,  1.2894e-01, -8.5458e-02,  2.1520e-01,  7.7000e-02,\n",
      "          -7.3985e-02,  8.5170e-02, -3.8547e-02, -1.7385e-01, -1.8400e-01,\n",
      "          -3.7249e-02, -1.9943e-01,  8.0104e-02, -6.9716e-02, -4.5787e-02,\n",
      "          -1.5609e-01, -1.8537e-01, -1.2652e-01, -3.5677e-02,  1.2124e-01,\n",
      "           2.5035e-01,  1.1429e-01, -6.7793e-02,  2.4428e-02,  2.3683e-01,\n",
      "           2.7959e-01,  4.2460e-01, -7.9246e-02,  1.3589e-01,  2.3930e-01,\n",
      "           1.4433e-02, -1.0177e-01,  3.7989e-01, -1.8586e-01,  1.1587e-01,\n",
      "          -3.3706e-01,  1.3556e-02, -2.4682e-01,  1.4154e-01,  1.5900e-01,\n",
      "           9.7623e-02, -1.0583e-01, -5.5896e-02, -2.4053e-02, -4.0180e-02,\n",
      "           3.0395e-01, -5.6876e-02,  3.3373e-01, -7.0736e-03,  2.5423e-01,\n",
      "           2.3976e-01,  4.0116e-02,  1.7169e-02,  1.3906e-01, -5.0915e-02,\n",
      "          -6.6862e-02,  2.9503e-01,  1.1125e-01, -1.8184e-01, -1.1947e-02,\n",
      "          -2.6386e-01,  2.5377e-02,  2.0106e-01, -2.2375e-01, -6.7899e-02,\n",
      "          -1.5901e-02, -5.4266e-02, -7.2706e-02, -2.8767e-01, -3.0210e-02,\n",
      "          -9.2768e-02,  6.5268e-03, -1.8163e-01, -6.6679e-03,  1.6326e-01,\n",
      "          -2.5984e-02, -1.4233e-01, -5.4353e-02,  1.1516e-03, -1.7837e-01,\n",
      "           1.5518e-03, -1.0014e-02,  5.6993e-02, -1.1811e-01, -1.9773e-01,\n",
      "           3.7595e-01, -2.6722e-01, -1.6311e-01,  1.2613e-01, -1.0738e-01,\n",
      "          -3.2589e-01,  1.7990e-01, -1.1789e-02, -1.7429e-01,  7.4843e-02,\n",
      "           1.1182e-01,  3.4796e-01, -1.6633e-01,  3.3448e-01, -1.2814e-01,\n",
      "           1.4730e-02,  9.5782e-02,  2.8397e-01,  2.3735e-02, -1.0588e-02,\n",
      "          -2.3009e-01, -2.0834e-01, -1.0400e-02,  1.7031e-01, -2.0447e-02,\n",
      "           1.6863e-01, -8.6108e-02,  3.8812e-01,  1.4776e-01, -1.0019e-01,\n",
      "          -5.6800e-02,  1.6098e-01, -2.1872e-01,  8.2597e-02,  5.2127e-04,\n",
      "          -1.4258e-01,  3.0001e-02,  1.7408e-02,  6.6496e-02,  1.4985e-01,\n",
      "          -1.9497e-01,  2.7685e-01,  1.6381e-01,  6.6513e-02, -6.1080e-03,\n",
      "          -2.8755e-01, -5.0331e-02,  3.3752e-01,  3.8031e-01,  2.1171e-01,\n",
      "          -1.4030e-01, -2.6157e-01,  9.9253e-04,  1.0151e-01,  3.7179e-04,\n",
      "          -2.5893e-03, -2.2920e-01, -6.2903e-02, -1.1415e-01, -3.7329e-02,\n",
      "          -3.7099e-02,  5.0847e-02, -1.5514e-01,  4.9177e-03, -1.2021e-01,\n",
      "          -1.9621e-01,  6.1959e-02, -1.1933e-01, -2.7154e-01,  1.3102e-01,\n",
      "          -1.1552e-01,  4.7418e-02,  7.3085e-02, -6.0942e-02, -7.1830e-03,\n",
      "          -8.2756e-02,  2.1684e-01, -7.9495e-02, -1.5458e-02, -6.8121e-02,\n",
      "          -6.7931e-02,  1.9890e-01,  4.6000e-02,  1.1644e-01,  2.5459e-01,\n",
      "           8.5625e-03,  2.3103e-01,  3.0880e-01,  1.0188e-02,  1.5973e-01,\n",
      "           3.0410e-01, -6.0097e-02,  1.1002e-01,  1.3563e-01, -1.2401e-02,\n",
      "           1.2817e-01,  3.8528e-01, -2.8832e-01, -1.2042e-01,  1.4914e-01,\n",
      "          -1.5923e-01, -1.6373e-01,  1.8306e-01, -1.6552e-01,  6.2396e-02,\n",
      "          -1.8117e-02,  4.6845e-02,  2.6233e-01,  1.7430e-01,  1.7320e-01,\n",
      "          -3.7410e-02,  8.4919e-02, -3.9121e-01,  5.7989e-02, -7.9038e-02,\n",
      "          -1.1737e-01, -3.5895e-01, -7.8010e-02, -1.2587e-01,  1.0778e-01,\n",
      "           4.3309e-01,  1.7271e-01, -8.9568e-02, -2.5691e-01, -1.4465e-02,\n",
      "           9.2907e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.8811e+00, -8.4214e-01, -1.6346e-01,  1.1776e+00,  1.1255e+00,\n",
      "           0.0000e+00,  1.4979e+00, -6.9749e-01,  4.4961e-01, -9.4411e-01,\n",
      "           2.0756e-01, -1.2031e+00,  1.1172e-01, -4.2978e-01, -7.8534e-01,\n",
      "          -9.6499e-01,  1.0815e+00, -4.7344e-01,  0.0000e+00,  6.0322e-01,\n",
      "           6.5887e-02, -7.3573e-01,  1.6539e-01,  2.2654e-03, -3.4089e-01,\n",
      "          -3.6534e-01, -5.2481e-01, -5.3994e-01,  1.1090e+00, -1.0297e+00,\n",
      "           1.6695e-02,  0.0000e+00, -4.0706e-01, -4.1543e-02,  1.1565e-01,\n",
      "          -6.8498e-01,  0.0000e+00,  1.2359e-01,  9.0442e-01,  6.4454e-01,\n",
      "          -1.2483e+00,  2.9134e-01,  4.1554e-01,  4.3102e-01, -9.0386e-01,\n",
      "           7.1036e-01, -1.7779e+00,  8.7801e-01, -5.2413e-01, -1.7651e+00,\n",
      "          -3.1575e-01,  6.6744e-01,  3.3431e-01,  2.3158e-01, -3.6699e-01,\n",
      "          -1.2665e+00,  1.9127e-02, -8.4816e-01, -4.5837e-01, -4.3945e-01,\n",
      "          -6.6856e-01,  4.1835e-02, -8.6801e-01,  6.3419e-01,  2.6420e+00,\n",
      "           2.8987e-02,  3.9821e-01,  0.0000e+00, -3.4038e-01,  6.7503e-02,\n",
      "           0.0000e+00, -1.1284e+00,  2.7774e+00,  5.5516e-01,  1.2280e+00,\n",
      "           4.9315e-01,  4.6124e-01,  0.0000e+00,  0.0000e+00,  2.7453e+00,\n",
      "           2.0053e+00, -1.4978e+00, -4.3434e-01, -8.0536e-01, -2.2385e-01,\n",
      "          -8.9286e-01,  8.3824e-02,  1.5276e-01, -8.3217e-01,  2.8784e-01,\n",
      "           1.7714e+00,  1.4689e+00,  3.9005e-01, -5.3544e-01,  0.0000e+00,\n",
      "          -8.3929e-02,  1.2337e+00,  6.6073e-01, -8.6009e-01,  0.0000e+00,\n",
      "          -7.9583e-01,  4.5628e-01,  1.8222e-01,  4.2265e-02, -7.5493e-01,\n",
      "          -5.9065e-01, -9.4545e-01,  8.3655e-01,  1.1728e+00,  0.0000e+00,\n",
      "          -1.2486e+00,  0.0000e+00,  1.2058e+00,  1.0444e+00,  1.6305e-01,\n",
      "          -5.6234e-01, -8.3208e-01, -6.3754e-01,  9.5780e-01,  5.4325e-01,\n",
      "           3.2420e-01, -1.4856e+00, -7.7000e-02, -1.6404e-01, -1.8428e+00,\n",
      "          -1.1557e-01, -3.1963e-01,  1.1820e+00, -1.1529e+00,  4.4949e-01,\n",
      "           3.0738e-01, -1.5447e+00,  1.8430e+00,  7.6429e-01,  1.8657e-01,\n",
      "          -8.7561e-01, -9.6390e-01, -1.1588e+00,  1.4901e+00, -5.0603e-02,\n",
      "          -5.5496e-01, -4.0887e-01,  1.0849e+00, -6.3416e-01, -2.5343e-01,\n",
      "          -1.6016e+00, -1.1938e+00, -2.7984e+00, -7.3868e-01,  1.1136e+00,\n",
      "          -2.0396e-02,  0.0000e+00, -2.9151e-01,  1.0808e+00, -4.8603e-01,\n",
      "          -6.6478e-01,  3.0591e-02,  0.0000e+00,  1.0498e-02, -3.6324e-01,\n",
      "           0.0000e+00,  0.0000e+00, -4.6804e-02, -1.7899e+00,  8.7710e-01,\n",
      "           0.0000e+00, -2.6156e+00,  0.0000e+00, -5.5470e-01,  8.6668e-01,\n",
      "           0.0000e+00, -1.2340e-01,  8.6420e-01,  7.3915e-01,  0.0000e+00,\n",
      "           3.7023e-01,  1.0582e-01, -4.0651e-01, -6.0764e-01,  6.5428e-01,\n",
      "          -2.3747e-01,  2.6693e-01,  7.2076e-01, -2.0743e+00, -1.0908e+00,\n",
      "          -1.3618e-01, -8.0148e-01, -1.5339e-01,  2.9234e-02,  1.1483e+00,\n",
      "           1.4057e+00,  1.1716e+00,  9.7129e-01,  2.5795e-01, -5.1459e-01,\n",
      "           1.3558e+00,  2.1942e-01,  2.6245e-01,  1.8970e+00,  3.4895e-01,\n",
      "           0.0000e+00, -3.9623e-01,  1.8970e+00,  1.8312e+00, -1.7622e+00,\n",
      "          -2.5489e-01,  5.1254e-01,  2.3270e+00,  6.9026e-01,  1.3125e+00,\n",
      "           4.7363e-01,  1.1807e-01, -4.8802e-01,  1.1905e-01,  1.0382e+00,\n",
      "           0.0000e+00,  4.5014e-01,  1.2202e+00, -5.6493e-01, -1.9669e+00,\n",
      "           1.1298e+00,  1.4641e-01,  2.0246e+00,  4.1301e-01, -6.1596e-02,\n",
      "           2.5921e-01, -5.5989e-01, -1.6746e+00, -6.6199e-01, -1.5938e+00,\n",
      "          -9.0754e-01,  1.9416e+00, -1.1841e+00,  2.7247e-01, -1.3077e+00,\n",
      "           2.2770e+00, -3.4601e-01,  0.0000e+00,  0.0000e+00, -2.4345e+00,\n",
      "          -1.2508e+00, -1.8881e+00, -3.9589e-01,  2.2103e+00, -1.9298e-01,\n",
      "           0.0000e+00,  1.1216e+00, -6.1201e-01, -1.1052e+00, -7.1200e-02,\n",
      "           4.0509e-01, -2.5614e-01, -6.9542e-01, -1.9103e+00,  2.2993e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1293, 0.1123, 0.1053, 0.1765, 0.0430, 0.0870, 0.0573, 0.1485, 0.0726,\n",
      "         0.0682]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.6589e-02, -6.7511e-02, -1.4361e-01,  3.0502e-02, -9.2990e-02,\n",
      "          -3.6283e-02, -2.0207e-01, -2.9937e-01,  3.6498e-02, -4.4426e-02,\n",
      "           2.4389e-01,  5.3310e-02, -2.7152e-01, -5.6729e-02,  1.3287e-01,\n",
      "           1.6744e-01,  2.2866e-02, -8.5531e-03, -3.5448e-02, -6.9793e-02,\n",
      "          -1.0287e-01, -8.7937e-02,  1.1837e-01,  1.8241e-02, -8.1215e-02,\n",
      "           2.4573e-01,  5.8721e-02,  1.5559e-02, -2.2789e-01, -6.4957e-02,\n",
      "          -9.0185e-02, -1.4633e-01, -1.1275e-01,  2.8262e-02,  9.2498e-02,\n",
      "          -1.9780e-01, -1.0286e-01, -5.5771e-02, -7.9260e-02,  5.4418e-02,\n",
      "           1.5446e-01, -1.2222e-01,  7.2147e-02, -1.3012e-01, -5.4489e-02,\n",
      "           8.3562e-02,  3.6993e-02, -6.0996e-02,  2.0874e-01,  1.2643e-01,\n",
      "          -1.1338e-01, -5.5878e-04, -1.2754e-03, -7.9855e-02, -1.9154e-01,\n",
      "           1.1694e-02, -1.2268e-01,  1.5672e-01, -6.2701e-02, -7.8299e-02,\n",
      "          -1.4481e-01, -2.0746e-01, -4.9779e-02, -2.9186e-02,  1.5394e-01,\n",
      "           2.4697e-01,  8.8851e-02, -1.5602e-01,  8.0474e-02,  1.7209e-01,\n",
      "           2.3563e-01,  3.9068e-01, -5.8133e-02,  6.4252e-02,  2.6019e-01,\n",
      "          -4.5091e-02, -1.0471e-01,  3.5805e-01, -2.1927e-01,  6.5842e-02,\n",
      "          -2.7985e-01, -3.7835e-02, -1.9726e-01,  1.3680e-01,  5.2531e-02,\n",
      "           9.0245e-02, -1.0415e-01, -3.2948e-02, -5.0311e-02, -1.4683e-01,\n",
      "           2.8565e-01, -3.4842e-03,  3.5730e-01, -7.1593e-02,  2.3815e-01,\n",
      "           1.5080e-01,  9.4708e-02,  1.1348e-02,  1.1794e-01, -8.1333e-02,\n",
      "          -7.8892e-02,  2.4066e-01,  1.2961e-01, -1.7714e-01, -8.5784e-02,\n",
      "          -2.7386e-01,  7.4883e-03,  1.4852e-01, -1.6682e-01, -3.5282e-02,\n",
      "           3.4502e-02, -9.1090e-02, -4.9025e-03, -2.2455e-01, -2.2315e-02,\n",
      "          -5.2262e-02,  3.6434e-02, -1.9881e-01,  3.7916e-02,  1.2213e-01,\n",
      "           1.2193e-02, -1.9170e-01, -2.8990e-02, -2.6957e-02, -9.1320e-02,\n",
      "          -4.5584e-02, -1.9790e-03,  8.9752e-02, -2.0404e-01, -1.3753e-01,\n",
      "           3.6129e-01, -1.9510e-01, -1.2117e-01,  7.5419e-02, -1.6029e-01,\n",
      "          -2.1938e-01,  1.8964e-01,  7.6606e-03, -2.2671e-01,  1.3106e-02,\n",
      "           1.2034e-01,  2.8033e-01, -1.5554e-01,  2.7185e-01, -8.3006e-02,\n",
      "          -9.7495e-03,  3.8492e-02,  2.6737e-01, -7.6989e-03, -3.5097e-03,\n",
      "          -1.4122e-01, -2.4050e-01,  1.9780e-02,  1.0553e-01,  1.2770e-02,\n",
      "           1.0892e-01, -1.1362e-01,  3.2840e-01,  1.2661e-01, -1.4544e-01,\n",
      "          -3.7646e-02,  1.2175e-01, -9.8994e-02,  1.3355e-01,  8.3353e-02,\n",
      "          -6.2549e-02,  6.3052e-02,  1.3714e-01,  9.5869e-02,  1.5183e-01,\n",
      "          -2.4239e-01,  1.9259e-01,  1.8755e-01,  2.6841e-02,  1.8873e-02,\n",
      "          -2.0870e-01, -8.8029e-02,  2.8966e-01,  3.7126e-01,  2.4854e-01,\n",
      "          -1.1389e-01, -2.6172e-01,  3.7718e-02,  1.2494e-01, -1.8916e-02,\n",
      "           7.8662e-03, -2.3956e-01, -1.4309e-01, -7.1859e-02,  2.9625e-03,\n",
      "          -2.7909e-02, -7.9919e-03, -1.4506e-01,  3.6882e-02, -1.0529e-01,\n",
      "          -1.4981e-01, -2.9089e-02, -1.5836e-01, -2.8230e-01,  1.6635e-01,\n",
      "          -4.2431e-02,  7.6535e-03,  8.9385e-02, -1.7344e-04,  2.2042e-02,\n",
      "          -3.2929e-02,  2.1864e-01, -1.8525e-01,  2.7149e-02, -3.3662e-02,\n",
      "           2.2384e-02,  2.6786e-01,  8.7032e-02,  1.1324e-01,  2.7071e-01,\n",
      "           5.6957e-02,  1.5663e-01,  3.1850e-01,  4.6755e-02,  1.1974e-01,\n",
      "           2.6164e-01, -1.4523e-01,  1.8534e-01,  6.8155e-02, -2.2767e-02,\n",
      "           6.1550e-02,  3.8386e-01, -1.7982e-01, -8.2321e-02,  1.6892e-01,\n",
      "          -1.7894e-01, -1.7381e-01,  1.3022e-01, -1.9176e-01, -6.3885e-03,\n",
      "          -3.0812e-02,  2.6691e-02,  2.1986e-01,  1.5951e-01,  1.1934e-01,\n",
      "          -1.8452e-02,  6.7310e-02, -3.0082e-01,  4.9166e-02, -8.7980e-02,\n",
      "          -8.2148e-02, -3.2188e-01, -1.5467e-02, -1.0555e-01,  1.4908e-01,\n",
      "           3.5359e-01,  7.7950e-02, -1.1161e-01, -2.3651e-01, -5.0931e-02,\n",
      "           1.2828e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3821, -2.3687,  0.8898, -0.3411, -0.2377,  0.1553,  0.2231,\n",
      "           0.0000, -0.5640,  0.0076, -0.1524,  0.4842,  0.5747,  0.0000,\n",
      "           0.6591, -1.0898,  1.5479,  0.4244,  0.0000, -0.8615, -0.9180,\n",
      "          -0.7336,  0.6915,  0.0542,  1.9397, -0.4962,  1.3571,  0.2571,\n",
      "          -0.6643,  1.1821,  1.5634, -0.1160,  1.1991,  0.7908,  1.2640,\n",
      "          -0.7181,  1.6183,  0.0000, -0.8955, -0.6313, -0.3871,  0.3799,\n",
      "          -0.9255, -0.2738, -2.8312, -1.3748, -1.0347,  1.5667,  0.7057,\n",
      "           2.1454,  1.2279,  1.1410,  0.0000,  1.3951,  0.5360,  0.0000,\n",
      "           0.4743,  0.3624, -1.0539,  0.8095, -0.0566, -0.0182, -0.5102,\n",
      "           0.6499, -0.5864,  2.7288,  0.1385,  0.4389,  0.7809,  0.4066,\n",
      "           0.0000, -0.7068, -0.3918,  1.8975,  0.9120, -0.1555,  1.2066,\n",
      "          -0.8949, -0.9744,  1.9159,  1.1798,  0.7020, -1.5659,  0.1282,\n",
      "          -1.7340,  0.6292,  0.6447, -2.1352, -3.1219, -0.2546, -0.6403,\n",
      "          -0.6188,  0.7280,  1.6611,  0.0000, -0.4778, -1.2503,  0.4428,\n",
      "           1.8213, -0.5192,  0.3223, -0.5026, -1.6206, -0.4704,  1.5762,\n",
      "           0.9259,  1.4048,  0.0000,  0.5582,  3.0796,  0.4361,  0.6956,\n",
      "          -0.4954,  1.2031,  0.1781,  1.5474,  0.5538,  2.3263,  2.3295,\n",
      "          -0.5100,  1.0922,  1.6520,  0.0599,  0.1070,  0.1788, -1.9168,\n",
      "          -1.4847, -0.3872,  1.1421,  1.7477, -0.7978, -0.1095,  0.0000,\n",
      "          -0.2511,  1.1459, -0.5997,  0.2935, -0.3311, -0.8202, -2.6199,\n",
      "          -0.2152,  0.0000, -1.9748,  0.0000, -0.1392, -2.0754,  1.6897,\n",
      "          -2.3398,  0.6174, -0.2536,  0.0000,  2.1954,  0.7731,  0.1747,\n",
      "           0.1449, -1.1432,  0.0596, -1.7116,  0.0851,  1.0294,  0.0000,\n",
      "          -1.9513, -0.1990, -0.0071,  0.2541,  0.0556, -1.7236,  0.3737,\n",
      "          -1.2311, -0.2630,  0.7950, -2.0435, -1.8580, -0.6444,  1.4846,\n",
      "           1.7649, -2.2904,  0.4697,  1.6067,  1.2011,  0.7582, -3.0787,\n",
      "           0.9246,  0.0000,  1.6426, -0.5184,  0.7514,  0.3794, -0.8066,\n",
      "          -0.7679, -1.6234, -1.1485, -2.3800, -1.3452,  1.7856,  0.3820,\n",
      "          -1.5499, -0.6036,  0.0000, -1.5550, -0.7668, -0.2415,  1.1231,\n",
      "           3.5412,  1.1131,  0.0000, -0.5076,  1.1540,  0.9084, -0.4868,\n",
      "           0.4661,  1.4977,  0.0000, -0.6289,  1.4627, -0.4449,  0.1048,\n",
      "          -0.1147,  0.0000, -1.4138,  1.5737,  2.0567, -1.3095, -0.5203,\n",
      "           0.3024,  0.0000,  0.9464,  0.0369,  0.0523,  0.6798,  0.1619,\n",
      "           0.1341, -1.9701, -0.4581,  1.2938, -0.3858, -0.1986,  1.4873,\n",
      "          -0.3215, -0.6614,  0.9252,  1.6483,  0.2110,  0.7042,  1.3673,\n",
      "          -0.1199, -0.3017,  0.9282,  0.0000,  0.0000,  0.9660,  0.0200,\n",
      "           0.9989, -0.4604, -0.9266, -0.7764]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1023, 0.0602, 0.1548, 0.1262, 0.0751, 0.0823, 0.0494, 0.0536, 0.1305,\n",
      "         0.1655]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 5.8001e-02, -2.7039e-02, -2.2013e-01,  1.8056e-02, -1.1147e-01,\n",
      "          -8.2260e-02, -1.7792e-01, -3.3335e-01, -1.0488e-02, -1.0586e-01,\n",
      "           3.0217e-01,  3.7088e-02, -2.8599e-01,  1.4482e-02,  1.7543e-01,\n",
      "           1.4965e-01,  5.7181e-02, -1.3296e-03, -1.4094e-01, -7.1058e-02,\n",
      "          -9.9279e-02, -1.3769e-01,  1.7371e-01,  3.5834e-02, -9.0003e-02,\n",
      "           2.1665e-01,  7.7164e-02, -7.8978e-02, -1.9970e-01, -5.8452e-02,\n",
      "          -9.4001e-02, -1.8983e-01, -1.0026e-01, -9.6824e-03,  7.2822e-02,\n",
      "          -1.2986e-01, -1.4633e-01, -9.9288e-02, -1.4090e-01,  8.5319e-02,\n",
      "           1.4485e-01, -1.2680e-01,  3.1963e-02, -1.1629e-01, -3.7673e-02,\n",
      "           1.6783e-01,  6.6466e-02, -1.1390e-01,  2.1561e-01,  8.0221e-02,\n",
      "          -1.1529e-01,  6.2478e-03, -6.7623e-02, -1.0972e-01, -1.9880e-01,\n",
      "           1.5708e-02, -1.3228e-01,  1.2125e-01, -3.7805e-02, -2.5537e-02,\n",
      "          -1.5798e-01, -1.9814e-01, -1.0995e-01,  5.3728e-02,  9.3869e-02,\n",
      "           2.1304e-01,  4.8781e-02, -5.7017e-02,  9.8033e-03,  1.9581e-01,\n",
      "           2.3873e-01,  3.8413e-01, -7.6539e-02,  1.3234e-01,  1.5978e-01,\n",
      "           2.0535e-02, -7.1717e-02,  3.6936e-01, -2.1485e-01,  9.3041e-02,\n",
      "          -3.1324e-01, -1.1024e-01, -2.8528e-01,  1.5115e-01,  8.8982e-02,\n",
      "           1.1039e-01, -9.1101e-02, -1.9889e-03, -2.3890e-02, -1.1491e-01,\n",
      "           3.1339e-01, -3.2522e-02,  2.9202e-01, -8.2063e-02,  2.2870e-01,\n",
      "           1.9333e-01,  9.3237e-02,  2.9405e-02,  1.1005e-01,  3.8886e-02,\n",
      "          -1.0497e-01,  2.2514e-01,  1.6649e-01, -1.2660e-01, -9.8213e-02,\n",
      "          -2.6581e-01,  5.7404e-02,  1.9689e-01, -1.8796e-01, -7.2871e-03,\n",
      "           3.5163e-02, -3.9350e-02,  4.0028e-04, -2.7618e-01, -1.0878e-01,\n",
      "          -4.8257e-02,  9.9496e-03, -1.7367e-01,  1.6330e-03,  8.2771e-02,\n",
      "           3.2610e-03, -1.8034e-01, -1.3754e-01,  4.1713e-02, -1.6489e-01,\n",
      "          -1.4598e-02, -4.8434e-03,  3.0902e-02, -6.1777e-02, -1.6595e-01,\n",
      "           3.6144e-01, -2.2547e-01, -1.0170e-01,  1.0231e-01, -1.5609e-01,\n",
      "          -2.0583e-01,  2.4231e-01,  3.9775e-02, -2.0379e-01,  1.8984e-02,\n",
      "           9.1514e-02,  3.5480e-01, -1.8331e-01,  2.9792e-01, -6.3705e-02,\n",
      "          -3.6247e-02,  5.6934e-02,  3.0883e-01,  1.8191e-02,  8.5354e-02,\n",
      "          -2.7239e-01, -1.2426e-01,  6.1656e-03,  1.6018e-01,  5.0231e-02,\n",
      "           1.5828e-01, -1.1806e-01,  3.6225e-01,  1.3594e-01, -1.4770e-01,\n",
      "          -4.2996e-02,  7.2079e-02, -1.8691e-01,  2.3501e-01,  2.9865e-02,\n",
      "          -4.4804e-02,  6.3062e-02,  5.6156e-02,  9.4251e-02,  1.7516e-01,\n",
      "          -2.3993e-01,  1.9127e-01,  2.1843e-01,  1.6632e-02, -5.7184e-02,\n",
      "          -2.6347e-01, -7.7858e-02,  3.1429e-01,  4.0749e-01,  1.8165e-01,\n",
      "          -1.6466e-01, -2.7108e-01, -5.1624e-02,  9.2735e-02,  2.3533e-02,\n",
      "           2.1878e-02, -2.8880e-01, -7.5375e-02, -2.6558e-02, -4.3791e-02,\n",
      "          -1.4533e-02,  4.7158e-02, -1.9938e-01,  1.7464e-02, -7.6056e-02,\n",
      "          -2.1312e-01,  1.1390e-02, -1.2365e-01, -2.7574e-01,  1.8554e-01,\n",
      "          -4.6361e-02,  4.7377e-02,  5.3371e-02,  3.8454e-02,  5.4026e-02,\n",
      "          -4.9948e-02,  1.9182e-01, -6.0799e-02, -8.3120e-03, -8.4357e-02,\n",
      "           5.4592e-03,  1.5601e-01,  1.1052e-01,  1.5235e-01,  2.1814e-01,\n",
      "           1.2547e-01,  8.7750e-02,  3.2742e-01, -2.4836e-02,  1.2690e-01,\n",
      "           2.9638e-01, -1.3394e-01,  2.0035e-01,  3.3929e-02,  2.1920e-02,\n",
      "           1.1854e-01,  3.9875e-01, -2.2905e-01, -1.7204e-01,  1.7091e-01,\n",
      "          -2.2271e-01, -1.9124e-01,  8.5188e-02, -2.5899e-01, -1.8783e-03,\n",
      "          -6.1803e-03, -1.1194e-02,  2.1727e-01,  2.0353e-01,  1.6408e-01,\n",
      "          -5.9697e-02,  2.9835e-02, -3.5327e-01,  3.1553e-02, -5.8518e-02,\n",
      "          -7.3840e-02, -3.3733e-01, -9.8839e-02, -4.4158e-02,  1.6413e-01,\n",
      "           3.8267e-01,  7.4376e-02, -1.3538e-01, -2.6469e-01, -2.8633e-02,\n",
      "           1.2337e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7277e-01, -4.3056e-01,  3.1488e-01, -1.0846e+00, -1.1724e+00,\n",
      "           7.4182e-01, -1.9142e+00,  1.3513e+00,  0.0000e+00,  0.0000e+00,\n",
      "           1.9028e+00,  6.0245e-01,  2.2862e-01, -9.1603e-01, -3.1819e+00,\n",
      "          -6.8468e-02,  0.0000e+00,  0.0000e+00,  1.3608e+00, -1.4348e+00,\n",
      "          -1.4068e-01, -5.2350e-01, -1.1194e+00, -2.5949e+00, -7.5653e-02,\n",
      "           1.3913e+00, -6.1936e-01,  1.9969e+00,  1.2764e-01,  5.5398e-01,\n",
      "           9.1487e-01, -3.5598e-03,  2.2292e-01,  2.0154e+00, -6.3764e-02,\n",
      "          -1.4084e+00, -1.1193e-01, -8.1774e-01,  3.1470e-01,  8.5396e-02,\n",
      "           0.0000e+00, -8.9975e-01,  1.0090e+00,  0.0000e+00,  1.9439e+00,\n",
      "           0.0000e+00,  7.0482e-01, -6.0137e-01, -1.0206e+00,  1.1163e+00,\n",
      "          -1.3222e+00,  2.6766e+00,  6.6664e-01, -8.4659e-01,  2.2748e-01,\n",
      "          -3.0898e-01,  0.0000e+00, -9.6676e-02,  1.2749e+00,  2.1808e+00,\n",
      "          -1.0062e+00,  3.6135e-02, -2.8013e-01,  2.6587e-01, -6.2791e-02,\n",
      "           3.9405e-01,  5.7804e-01,  1.1649e+00,  0.0000e+00, -1.4151e+00,\n",
      "           4.2759e-01,  0.0000e+00,  0.0000e+00, -7.9766e-01, -2.1445e-01,\n",
      "           1.3925e-01,  5.2564e-01,  1.3985e+00,  1.0269e+00, -7.9296e-01,\n",
      "           7.5762e-01, -1.0057e+00,  7.5725e-01,  1.0587e+00, -1.2144e+00,\n",
      "           0.0000e+00, -1.1074e+00,  0.0000e+00, -9.4471e-01,  0.0000e+00,\n",
      "           5.2903e-01,  9.8660e-01,  1.7014e+00,  9.4336e-01,  6.0809e-01,\n",
      "          -1.5949e-02,  0.0000e+00, -1.1755e+00,  1.3712e+00,  2.4478e+00,\n",
      "           2.4383e-01,  4.5643e-02, -4.6636e-01,  0.0000e+00,  1.6397e+00,\n",
      "          -1.0227e+00,  3.0285e+00,  6.1963e-01,  0.0000e+00, -1.2353e+00,\n",
      "           1.8985e-01, -5.0284e-01, -5.7023e-01,  7.1223e-01, -7.8036e-01,\n",
      "           6.3213e-01,  4.0408e-01,  2.2417e-01, -2.3271e+00,  2.9362e-02,\n",
      "          -8.1363e-01, -1.4106e+00,  0.0000e+00,  6.0330e-01, -9.5630e-01,\n",
      "          -2.0012e-01,  0.0000e+00,  2.1498e+00,  1.3961e+00, -2.0875e+00,\n",
      "           0.0000e+00,  4.4959e-01, -1.1672e+00,  4.2514e-01, -4.6886e-01,\n",
      "          -7.4459e-01, -1.0649e+00, -9.7469e-01, -1.9509e-02,  2.3976e+00,\n",
      "           6.9857e-01, -1.1217e+00,  1.6916e+00, -1.4019e-01, -6.6932e-01,\n",
      "           3.4110e-02,  7.5928e-01,  0.0000e+00, -1.0330e+00, -9.5660e-02,\n",
      "           0.0000e+00,  5.8694e-01, -3.3889e-01,  6.5761e-01,  1.8407e+00,\n",
      "          -2.5247e-01, -2.1736e-01,  0.0000e+00, -2.3622e+00,  1.0555e+00,\n",
      "           3.0244e-01, -7.7508e-02,  1.5431e-01, -1.2115e+00, -2.1877e-02,\n",
      "           1.6818e+00,  1.8516e+00,  2.7057e-01,  0.0000e+00, -7.1333e-01,\n",
      "          -1.2243e+00, -1.0939e+00, -2.5901e+00,  5.0554e-01, -3.0583e+00,\n",
      "          -2.8708e-01,  4.9829e-01,  8.2941e-01,  3.1707e-01, -7.9275e-01,\n",
      "           2.7120e-01,  0.0000e+00,  0.0000e+00,  8.3819e-01,  0.0000e+00,\n",
      "           7.2705e-01,  5.9910e-01,  3.5936e-01,  8.4221e-01, -1.8298e+00,\n",
      "           1.3634e+00,  0.0000e+00,  3.3683e-01,  0.0000e+00, -1.1714e+00,\n",
      "          -2.2149e+00,  1.6658e+00,  2.1524e+00,  3.6339e-01,  2.3835e+00,\n",
      "           3.2304e-02, -5.0150e-01, -1.2760e+00, -5.4240e-01, -4.0731e-01,\n",
      "          -1.4467e+00,  9.5376e-01, -8.5162e-01,  8.3066e-01, -1.5597e+00,\n",
      "           6.3618e-01,  6.7619e-01,  2.3971e+00,  5.4995e-02,  1.8939e+00,\n",
      "           1.3078e+00,  5.8082e-01, -2.3169e+00,  1.5503e+00, -2.2255e-01,\n",
      "          -2.2714e-01,  1.7331e+00,  0.0000e+00, -1.5519e+00,  9.2279e-01,\n",
      "          -1.2244e+00, -8.4800e-01, -1.8012e+00, -2.9704e-04,  3.7339e-01,\n",
      "           0.0000e+00, -1.2343e-01,  9.6622e-01, -1.7359e+00,  1.6939e+00,\n",
      "          -1.4404e+00,  6.3406e-01,  0.0000e+00,  9.8045e-01, -1.7153e+00,\n",
      "           1.5602e+00, -2.7190e-01, -2.5965e+00,  1.2383e+00, -1.2285e+00,\n",
      "           1.8840e+00, -5.0833e-01,  5.4284e-01, -2.6132e-01, -1.0216e+00,\n",
      "           1.3331e+00,  3.1028e-01, -5.1563e-02,  0.0000e+00,  0.0000e+00,\n",
      "           1.8061e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0524, 0.1104, 0.1758, 0.0762, 0.1134, 0.1152, 0.1243, 0.0641, 0.1046,\n",
      "         0.0635]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2585, -0.2558, -0.0117,  ..., -0.0472,  0.1660, -0.0418],\n",
      "        [ 0.1246, -0.0612, -0.1826,  ..., -0.3137, -0.0759,  0.1953],\n",
      "        [-0.3637, -0.0905,  0.0166,  ..., -0.3848, -0.1933,  0.4603],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0817,  0.1998,  ..., -0.3860, -0.0158, -0.2613],\n",
      "        [ 0.1906, -0.1397, -0.1389,  ..., -0.5774,  0.2970, -0.1838],\n",
      "        [ 0.4325,  0.3568, -0.6384,  ..., -0.3173,  0.0107, -0.0611]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0221, -0.0908, -0.1979,  0.0359, -0.0958, -0.0674, -0.1754,\n",
      "          -0.2518, -0.0320, -0.0698,  0.2609,  0.0937, -0.2720,  0.0564,\n",
      "           0.1746,  0.2544,  0.1231, -0.0489, -0.0806, -0.1277, -0.1281,\n",
      "          -0.0973,  0.1762,  0.0786, -0.0459,  0.2745,  0.1206, -0.0696,\n",
      "          -0.1895, -0.0805, -0.2323, -0.1285, -0.0875,  0.0656,  0.0915,\n",
      "          -0.1854, -0.1224, -0.0603, -0.1283,  0.0954,  0.1251, -0.1288,\n",
      "           0.0725, -0.1392, -0.0900,  0.1477,  0.0976, -0.0844,  0.1721,\n",
      "           0.0956, -0.1291,  0.0384,  0.0113, -0.0846, -0.1633,  0.0181,\n",
      "          -0.1728,  0.1026, -0.0588, -0.0775, -0.2018, -0.1879, -0.1033,\n",
      "          -0.0064,  0.1696,  0.1988,  0.0767, -0.1432,  0.0390,  0.1349,\n",
      "           0.2403,  0.3768, -0.0520,  0.1080,  0.2369, -0.0347, -0.1304,\n",
      "           0.3717, -0.2260,  0.0472, -0.2777, -0.0090, -0.2307,  0.1661,\n",
      "           0.1264,  0.0934, -0.1081,  0.0061, -0.0842, -0.0503,  0.3336,\n",
      "          -0.0601,  0.3136, -0.0906,  0.2628,  0.2428,  0.0060,  0.0048,\n",
      "           0.0929, -0.0415, -0.0009,  0.2688,  0.1457, -0.2110, -0.0728,\n",
      "          -0.2927, -0.0286,  0.1345, -0.1988, -0.1052,  0.0133,  0.0057,\n",
      "          -0.0758, -0.2157, -0.0821, -0.0636, -0.0040, -0.1941, -0.0382,\n",
      "           0.1571,  0.0202, -0.1657, -0.0728,  0.0410, -0.1380, -0.0161,\n",
      "          -0.0010,  0.1040, -0.0635, -0.1449,  0.3815, -0.1587, -0.1143,\n",
      "           0.0672, -0.1568, -0.2279,  0.1689, -0.0550, -0.1425,  0.0524,\n",
      "           0.0970,  0.3437, -0.1579,  0.2727, -0.1243, -0.0266,  0.0597,\n",
      "           0.3096,  0.0069,  0.0072, -0.1651, -0.2046, -0.0110,  0.1827,\n",
      "           0.0238,  0.1032, -0.1133,  0.3468,  0.1575, -0.0779, -0.0032,\n",
      "           0.1059, -0.1362,  0.1487, -0.0040, -0.1153,  0.0299,  0.0735,\n",
      "           0.0245,  0.1895, -0.1708,  0.2285,  0.1331, -0.0064, -0.0965,\n",
      "          -0.2378, -0.0808,  0.3166,  0.3619,  0.2066, -0.1083, -0.2590,\n",
      "           0.0205,  0.0813, -0.0522, -0.0088, -0.2201, -0.1161, -0.0469,\n",
      "          -0.0123,  0.0008,  0.0560, -0.0958, -0.0022, -0.0897, -0.2452,\n",
      "          -0.0014, -0.1489, -0.3138,  0.1677, -0.0837,  0.0278,  0.0758,\n",
      "          -0.0248,  0.0089,  0.0211,  0.1825, -0.1637, -0.0311, -0.0306,\n",
      "           0.0048,  0.1959,  0.0670,  0.2269,  0.2569,  0.0467,  0.1491,\n",
      "           0.2655,  0.0169,  0.1049,  0.2896, -0.1169,  0.1516,  0.0793,\n",
      "          -0.0190,  0.1037,  0.4088, -0.2029, -0.0786,  0.1250, -0.1533,\n",
      "          -0.2436,  0.1622, -0.1764, -0.0090, -0.0021,  0.0205,  0.2414,\n",
      "           0.1080,  0.1607, -0.0455,  0.1200, -0.3637,  0.0478, -0.1310,\n",
      "          -0.0891, -0.3524, -0.0183, -0.0909,  0.2179,  0.3841,  0.0795,\n",
      "          -0.0910, -0.2107, -0.0269,  0.1147]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00,  3.9984e-01, -9.6506e-01, -6.8095e-01,  3.7539e-01,\n",
      "          -2.0196e-01,  1.4647e+00, -8.3502e-02, -3.5833e+00,  9.0655e-01,\n",
      "           4.2800e-01, -6.2909e-01,  2.6024e+00, -6.3012e-01, -5.4133e-01,\n",
      "          -1.5800e-01,  8.5121e-01,  1.0942e+00,  4.5521e-01,  4.3619e-01,\n",
      "          -6.3331e-01, -3.8244e-01,  1.6400e+00,  1.5108e+00,  7.5327e-01,\n",
      "          -7.5839e-02, -1.8815e-01,  0.0000e+00,  1.6532e+00,  8.6137e-01,\n",
      "           1.2315e+00,  1.2191e+00, -1.0341e+00,  0.0000e+00, -1.5341e+00,\n",
      "           1.3954e+00,  2.8089e-01, -3.7439e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -4.5895e-01, -1.3979e+00, -2.6882e-01, -1.7146e+00, -1.5234e+00,\n",
      "           6.6770e-01,  5.4054e-01,  3.7111e-01, -1.3404e+00,  1.4450e-01,\n",
      "          -6.2941e-01,  0.0000e+00,  6.1012e-01,  0.0000e+00,  0.0000e+00,\n",
      "           2.0379e-01, -8.8130e-01, -1.2513e+00, -2.3724e-01, -4.2601e-01,\n",
      "           1.0993e+00,  1.4074e+00, -2.0255e-01,  0.0000e+00, -2.9625e+00,\n",
      "           5.5135e-01,  1.2782e+00, -1.2874e+00,  4.1033e-01,  5.2683e-01,\n",
      "          -1.2663e+00, -2.9742e-02,  7.0716e-01, -3.6398e+00,  3.2518e-01,\n",
      "          -7.0355e-04, -1.6002e-01,  1.0616e+00, -5.7352e-02, -1.1826e-01,\n",
      "          -1.3998e+00,  2.1299e+00, -9.2427e-01,  1.0059e+00, -2.0752e-01,\n",
      "           4.3592e-01,  1.6611e+00, -9.7393e-01, -1.0420e-01, -5.8102e-01,\n",
      "          -2.2725e+00,  1.0997e+00, -6.2244e-01,  0.0000e+00,  4.6712e-01,\n",
      "          -1.1700e+00,  3.3246e-02,  6.2890e-01,  1.7192e+00, -7.7877e-01,\n",
      "           2.6967e+00, -1.4616e+00,  1.0759e+00,  1.4529e+00, -6.6615e-01,\n",
      "          -7.6233e-01,  1.2111e+00,  0.0000e+00, -1.4729e+00, -1.3759e-02,\n",
      "          -2.4816e-01,  1.3405e-01,  0.0000e+00,  1.3099e+00, -1.6525e+00,\n",
      "          -2.9878e+00, -5.6932e-02, -4.9951e-01, -1.9336e-01,  4.4542e-01,\n",
      "          -1.4651e+00,  7.0210e-01, -1.4601e+00,  0.0000e+00, -9.5776e-01,\n",
      "          -1.3078e+00,  8.9585e-01,  0.0000e+00,  1.2846e+00, -7.5121e-01,\n",
      "          -8.2418e-01,  5.3071e-01, -1.5825e+00,  9.8386e-01,  2.7603e-01,\n",
      "          -5.8920e-01,  6.5856e-01,  5.7537e-01,  0.0000e+00, -1.0094e+00,\n",
      "          -3.8805e-01,  6.7777e-01, -7.8942e-01, -1.0069e-01, -1.6847e+00,\n",
      "          -1.0028e-01, -5.4296e-01, -8.4418e-01, -7.5511e-01,  1.7769e-01,\n",
      "           1.9978e+00, -1.9923e-01, -1.9294e+00, -4.0621e-01,  0.0000e+00,\n",
      "          -1.9435e-01, -6.4830e-02, -1.3037e-01,  3.9168e-02,  0.0000e+00,\n",
      "          -2.6652e-02,  2.2059e+00,  4.8101e-01, -5.5015e-01, -5.2595e-01,\n",
      "          -8.9144e-01,  2.8154e-01,  8.3034e-02, -3.5808e-01, -4.7790e-01,\n",
      "           7.3619e-01,  0.0000e+00,  2.0049e-02, -1.0025e+00,  0.0000e+00,\n",
      "          -1.0977e+00, -9.8592e-01,  0.0000e+00,  1.9683e+00,  8.6354e-02,\n",
      "          -3.0928e-02,  3.4984e-02,  6.7073e-01,  9.7973e-01, -7.4740e-01,\n",
      "          -3.4091e-01, -2.7817e+00,  0.0000e+00,  1.2089e+00,  1.0124e+00,\n",
      "           3.0724e+00,  4.9414e-01, -1.4437e-01, -5.9304e-01,  5.6004e-01,\n",
      "           0.0000e+00, -1.1874e+00,  5.3510e-01,  1.8108e+00, -9.4615e-01,\n",
      "          -1.6625e+00, -1.0152e+00,  1.2423e+00, -1.2207e-01,  2.3212e-01,\n",
      "          -5.7476e-01, -2.2919e+00,  6.8160e-01, -1.0733e+00, -4.7099e-01,\n",
      "           2.8671e+00, -5.7321e-01, -3.4114e-01,  7.9278e-01,  3.1284e-02,\n",
      "          -6.8339e-01, -1.0174e+00,  9.6669e-01, -2.4518e-01,  2.1687e+00,\n",
      "          -1.0826e+00, -4.2694e-01, -1.8432e+00, -5.0031e-01,  3.3900e-01,\n",
      "           7.0490e-01, -6.9648e-01, -6.2812e-01,  2.9220e-01, -1.5776e+00,\n",
      "          -1.1082e+00,  1.5812e+00, -6.1365e-01,  1.3100e+00, -2.9791e+00,\n",
      "           4.0336e+00,  5.8515e-01,  4.3065e-02, -1.5787e+00, -2.8617e-01,\n",
      "           7.4191e-01, -3.2468e+00, -3.0376e-01, -8.5169e-01,  1.1300e-02,\n",
      "           2.7558e-01,  2.7462e-01,  2.5219e-01,  2.6155e-01,  3.8654e-01,\n",
      "          -3.6567e-01, -1.5953e-01,  0.0000e+00, -5.2152e-02, -1.1462e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0389, 0.0466, 0.0830, 0.0675, 0.1248, 0.2890, 0.0695, 0.0895, 0.0625,\n",
      "         0.1287]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3548, -0.0233,  0.0816,  ..., -0.1195, -0.0301, -0.4732],\n",
      "        [ 0.1239,  0.1481,  0.2774,  ...,  0.1123,  0.0653,  0.0485],\n",
      "        [ 0.0526,  0.1065,  0.2625,  ...,  0.1219, -0.0483, -0.4450],\n",
      "        ...,\n",
      "        [ 0.2012,  0.1166, -0.4129,  ..., -0.6148,  0.2678, -0.1596],\n",
      "        [ 0.4493,  0.4131, -0.7137,  ..., -0.3597, -0.0150, -0.0618],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2712,  0.0244,  0.1405, -0.0709,  0.0314,  0.0156,  0.0069,\n",
      "          -0.2459, -0.1742, -0.0875,  0.0337,  0.1597,  0.0066,  0.1142,\n",
      "           0.1776,  0.2582,  0.0089, -0.0759, -0.2103, -0.1616,  0.2506,\n",
      "          -0.0135,  0.2128, -0.0871,  0.1155,  0.1057, -0.0263, -0.1332,\n",
      "          -0.1180,  0.1569, -0.0270,  0.0243, -0.2340,  0.0787,  0.0419,\n",
      "           0.1813, -0.0580, -0.0872,  0.0092,  0.3257,  0.0963,  0.1061,\n",
      "          -0.1370,  0.2033,  0.2779,  0.3447, -0.0449,  0.0621, -0.0406,\n",
      "          -0.1346, -0.0491,  0.0120,  0.0053, -0.0742,  0.0339,  0.0084,\n",
      "          -0.2837,  0.0592,  0.0618, -0.1362, -0.2318,  0.1356, -0.2046,\n",
      "           0.1203,  0.0603, -0.1214, -0.1136,  0.2047, -0.0544, -0.0252,\n",
      "           0.2234,  0.0892, -0.1891,  0.1641, -0.2689,  0.1714,  0.1821,\n",
      "           0.1520,  0.1139,  0.2091, -0.0615,  0.1634,  0.1075,  0.0806,\n",
      "           0.1875, -0.0260, -0.0021,  0.2041, -0.0239, -0.0241,  0.1211,\n",
      "          -0.0918, -0.2153,  0.0921,  0.1603,  0.2414,  0.2338,  0.2400,\n",
      "          -0.0233,  0.1912,  0.0568,  0.2724,  0.3027,  0.1436,  0.0341,\n",
      "          -0.1723,  0.2577,  0.0320, -0.4079, -0.0737, -0.1556,  0.0065,\n",
      "          -0.1846, -0.3315,  0.0188, -0.3817, -0.1673,  0.1064,  0.0815,\n",
      "           0.0525,  0.1982,  0.0034, -0.1589, -0.0224, -0.2637,  0.1139,\n",
      "           0.3762,  0.0126,  0.1736, -0.0688,  0.1586,  0.1115, -0.0074,\n",
      "          -0.0445,  0.2357, -0.0329,  0.1512,  0.0332,  0.1481, -0.1179,\n",
      "          -0.0131, -0.0302,  0.2537,  0.0722, -0.0829,  0.1348,  0.2683,\n",
      "           0.2209, -0.0415,  0.0821, -0.2601, -0.0560, -0.0198,  0.2707,\n",
      "          -0.1820,  0.1375, -0.1453,  0.2859,  0.0295,  0.0419, -0.0009,\n",
      "           0.1810,  0.0011,  0.0005, -0.1492, -0.0906, -0.2589,  0.0522,\n",
      "          -0.1382,  0.1118, -0.2238,  0.0412, -0.0811,  0.1389,  0.1531,\n",
      "          -0.1414,  0.2287, -0.1553,  0.0930, -0.0781,  0.0054,  0.1893,\n",
      "          -0.3808, -0.0665, -0.0942, -0.0205,  0.0836, -0.0457, -0.1169,\n",
      "          -0.2123,  0.0984, -0.0713,  0.1123, -0.3215, -0.1300, -0.3231,\n",
      "          -0.1432,  0.0448,  0.0144, -0.2327,  0.1749,  0.0502,  0.1957,\n",
      "          -0.1288, -0.2948,  0.1298, -0.0167, -0.2377,  0.1678, -0.2438,\n",
      "           0.0823, -0.3690,  0.0483,  0.1103, -0.1104, -0.0642,  0.0170,\n",
      "           0.0939, -0.2672, -0.1917, -0.0632,  0.2522,  0.2891, -0.0928,\n",
      "           0.1807,  0.1612, -0.0323,  0.1631, -0.1291,  0.0440, -0.1462,\n",
      "          -0.1711, -0.1919, -0.0983, -0.1988,  0.1573, -0.0438, -0.3368,\n",
      "          -0.0187,  0.1922,  0.0843, -0.0755, -0.2207,  0.2292,  0.0933,\n",
      "          -0.0640, -0.2856, -0.1193, -0.1501, -0.1161, -0.1789,  0.0372,\n",
      "          -0.1734, -0.2157,  0.1470, -0.1344]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4736,  0.0000, -1.2335, -0.1180,  0.4617,  0.0258,  0.6620,\n",
      "           0.5340,  0.6707,  0.9338,  1.7079, -1.0164,  0.9464, -0.2518,\n",
      "          -1.6338,  0.5125,  1.8775, -0.7566, -1.5631, -2.6434, -1.1336,\n",
      "           0.0000,  2.9297,  0.0000, -0.1169,  3.2093,  1.8370,  0.5189,\n",
      "           0.0000, -1.2857,  0.0294,  1.0135,  0.3248,  0.8598, -0.7986,\n",
      "          -1.4656,  0.6198, -0.7713,  1.9916,  0.1021,  0.4675, -2.2043,\n",
      "          -0.5664, -0.1151, -0.7130, -0.6893,  1.9277,  0.1099,  0.0000,\n",
      "          -1.8506,  1.4678,  0.4622,  0.0000, -0.2834,  0.5316,  0.2748,\n",
      "          -1.2423, -0.9512,  1.8140, -0.0118,  0.2049, -1.8183, -1.4015,\n",
      "           0.0000,  0.0000,  0.2652, -0.1669, -0.2553, -0.0045, -0.4609,\n",
      "          -0.3251, -0.3241,  0.1474, -0.1264,  0.6586, -0.8063,  2.0663,\n",
      "           1.6795,  0.0878, -0.5459,  0.0000,  0.0867,  0.3268, -1.8364,\n",
      "          -0.0715, -1.7323, -1.4585, -0.8909,  0.6231,  0.8108,  0.0000,\n",
      "          -1.1443,  1.9852, -0.3660, -0.7340,  0.1566,  2.1414, -0.4056,\n",
      "          -0.3042, -1.8394, -1.2904, -0.7214, -0.7663,  0.2373,  0.3819,\n",
      "           1.1138, -1.0701,  2.2523, -0.2628,  0.0000, -0.0532,  0.0000,\n",
      "          -0.2546, -0.2803, -1.9421,  0.0000,  1.0063, -2.4975, -0.5748,\n",
      "           0.0297, -1.6949, -0.4011, -0.3792, -0.0787, -0.5368,  0.0000,\n",
      "           1.3046,  0.1695,  0.3222,  1.3585,  2.0792, -2.6341,  0.3593,\n",
      "          -0.7230,  0.4292,  0.0000,  0.3268, -2.1020, -0.4969,  0.0000,\n",
      "          -0.6419,  0.2341, -1.1870, -1.2151, -0.6311, -0.0407,  0.4648,\n",
      "           1.7384,  1.5943,  0.0000,  0.0000, -0.5774, -0.4801, -0.0395,\n",
      "           0.3267, -0.1167,  1.3538, -0.0315, -1.9005, -1.8060, -1.4269,\n",
      "           0.0000, -0.7056, -0.3891, -0.9813, -0.1289,  0.4063,  0.9703,\n",
      "           0.5179, -0.1474,  1.5138, -0.3730, -0.3158, -2.0087,  0.1293,\n",
      "          -0.3524, -0.8304, -0.7691, -0.0402, -0.9376,  0.7277,  1.0420,\n",
      "           0.0468,  0.4632,  0.3163, -0.1181, -0.5416, -0.6642,  0.7548,\n",
      "          -1.0642, -0.5869, -1.7884,  1.2676, -0.9263, -1.6148, -0.3332,\n",
      "          -1.1570, -1.9606, -0.0720, -0.3754,  2.6977, -0.9216, -2.6316,\n",
      "          -0.5862, -0.7164, -1.3860, -1.2536,  0.1719,  0.2188, -1.1109,\n",
      "           0.9449, -0.6920, -1.5195,  0.3622,  0.2373, -1.4266, -2.3448,\n",
      "           0.0474, -1.4798,  0.4273,  0.0133, -0.9018,  0.3009,  0.0000,\n",
      "          -1.3014, -0.1876,  1.2723,  1.2666, -2.1880, -0.0564,  1.7374,\n",
      "          -1.1751,  0.9562,  0.0000,  0.5271,  0.7892, -0.6785,  0.1045,\n",
      "          -0.6804, -2.2622,  0.1674, -0.3138, -1.0432, -0.3819, -1.0801,\n",
      "           0.5579,  1.4997, -0.5647, -1.3772,  1.2434,  0.5826,  0.0000,\n",
      "           1.9514,  0.0000,  0.4873,  0.3902]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0204, 0.2831, 0.1040, 0.0493, 0.0953, 0.1161, 0.0372, 0.1391, 0.0906,\n",
      "         0.0649]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3548, -0.0233,  0.0816,  ..., -0.1195, -0.0301, -0.4732],\n",
      "        [ 0.1239,  0.1481,  0.2774,  ...,  0.1123,  0.0653,  0.0485],\n",
      "        [ 0.0526,  0.1065,  0.2625,  ...,  0.1219, -0.0483, -0.4450],\n",
      "        ...,\n",
      "        [ 0.2012,  0.1166, -0.4129,  ..., -0.6148,  0.2678, -0.1596],\n",
      "        [ 0.4493,  0.4131, -0.7137,  ..., -0.3597, -0.0150, -0.0618],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2125,  0.0900,  0.0727,  0.0500,  0.1370,  0.0905, -0.0891,\n",
      "          -0.1063, -0.0287, -0.0097,  0.0127,  0.1173,  0.0133,  0.1218,\n",
      "           0.1614,  0.2406,  0.1107, -0.0538, -0.3829, -0.1828,  0.0627,\n",
      "           0.0040,  0.0751, -0.1364, -0.0277, -0.0543,  0.0407, -0.1050,\n",
      "          -0.1039,  0.1033,  0.0019,  0.0720, -0.1285,  0.0888, -0.0234,\n",
      "           0.0970, -0.1931, -0.0599, -0.0853,  0.1579,  0.1090,  0.0806,\n",
      "          -0.0847,  0.1310,  0.2816,  0.2214,  0.0733,  0.1285,  0.0831,\n",
      "          -0.0962, -0.0618, -0.2383,  0.0686, -0.1252, -0.1135,  0.0337,\n",
      "          -0.1759,  0.1466,  0.0709,  0.0122, -0.1128,  0.0963, -0.1809,\n",
      "           0.1665, -0.0024, -0.0812, -0.0349,  0.1382, -0.1137, -0.0448,\n",
      "           0.2187,  0.1864, -0.2858,  0.1162, -0.3158,  0.1483,  0.2067,\n",
      "           0.0573,  0.1257,  0.0476, -0.1929,  0.0481,  0.0243,  0.1050,\n",
      "           0.1852,  0.0668,  0.0867,  0.1821, -0.0647,  0.0519, -0.0065,\n",
      "           0.0203, -0.1926,  0.0300,  0.1389,  0.2466,  0.2995,  0.2885,\n",
      "          -0.1056,  0.1476, -0.0773,  0.1681,  0.2762,  0.1391,  0.0386,\n",
      "          -0.0732,  0.2319, -0.0329, -0.3828,  0.0233, -0.1996,  0.0508,\n",
      "          -0.1685, -0.1699,  0.1456, -0.3010, -0.0587, -0.0174,  0.0595,\n",
      "          -0.1187,  0.1946, -0.1095, -0.1441, -0.0248, -0.3246,  0.0269,\n",
      "           0.3590,  0.0313,  0.3333,  0.0618,  0.0456, -0.0216,  0.1249,\n",
      "          -0.0436,  0.0767, -0.0967,  0.2623,  0.0645,  0.2417, -0.0841,\n",
      "           0.0617,  0.0712,  0.2216,  0.1841, -0.1553,  0.1250,  0.3193,\n",
      "           0.2139, -0.1227,  0.0994, -0.2862, -0.0902,  0.0793,  0.3209,\n",
      "          -0.1646,  0.2207, -0.0793,  0.2583,  0.0060,  0.0954, -0.0145,\n",
      "           0.1630, -0.0623,  0.1151, -0.1728, -0.1304, -0.1866, -0.0275,\n",
      "          -0.2324,  0.1703, -0.0669, -0.0375, -0.1127,  0.2650,  0.2361,\n",
      "          -0.1713,  0.1234, -0.1062,  0.1405, -0.1095, -0.0467,  0.2046,\n",
      "          -0.3861, -0.1103,  0.0207, -0.0108,  0.0883,  0.0300, -0.0273,\n",
      "          -0.2361,  0.1163, -0.1570,  0.0213, -0.2079, -0.1538, -0.1442,\n",
      "           0.0697,  0.0980, -0.0174, -0.1433,  0.0857,  0.0968,  0.1182,\n",
      "          -0.0582, -0.2298,  0.0599, -0.1025, -0.1107,  0.0982, -0.1503,\n",
      "           0.1050, -0.3022, -0.0317, -0.0411, -0.0974, -0.0820,  0.1155,\n",
      "           0.1854, -0.3800, -0.1687,  0.0297,  0.1550,  0.2821, -0.0984,\n",
      "           0.0596,  0.3189, -0.0049,  0.0081, -0.2852,  0.0671, -0.1430,\n",
      "          -0.2160, -0.1691, -0.1152, -0.1279,  0.0099, -0.1150, -0.2444,\n",
      "           0.0098,  0.1982,  0.1101, -0.0761, -0.2958,  0.1640,  0.2341,\n",
      "          -0.0199, -0.2675, -0.1628, -0.2028, -0.2041, -0.1195,  0.0659,\n",
      "          -0.1524, -0.1610,  0.1052, -0.1029]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9574e-02, -1.8078e+00,  1.3220e+00,  5.1608e-01,\n",
      "          -3.7601e-01,  1.2080e-03, -7.2296e-01,  2.1179e+00, -2.1365e-01,\n",
      "           2.8206e-01,  8.3061e-01, -1.1105e+00,  1.9973e-01,  3.1259e-01,\n",
      "           3.5184e-01, -6.8294e-01,  1.6918e-01,  8.7450e-01,  5.4563e-01,\n",
      "           1.8833e+00,  6.0187e-01, -3.6907e-02, -5.3535e-01, -1.0054e-01,\n",
      "           6.5107e-01, -1.6089e+00, -1.3622e+00, -2.1266e+00, -1.0345e+00,\n",
      "           3.8758e-02, -1.4546e+00, -2.0766e+00,  0.0000e+00, -2.8480e-01,\n",
      "          -2.0018e+00,  2.1883e-01,  9.9695e-01,  6.0135e-01,  9.5349e-01,\n",
      "          -2.2510e-01, -2.2112e+00, -7.0609e-01,  1.3959e+00,  0.0000e+00,\n",
      "          -1.1385e+00,  2.4257e-01,  7.4192e-01, -7.0975e-01, -1.3358e+00,\n",
      "           1.6085e+00, -1.3753e-01,  6.6256e-01,  1.1163e+00,  5.6734e-01,\n",
      "           3.3295e-01, -4.4961e-01, -8.8807e-01,  1.3373e-01,  6.2836e-01,\n",
      "          -7.0483e-01,  5.6372e-01, -6.9337e-01, -1.5473e+00,  0.0000e+00,\n",
      "           9.5603e-02, -1.7745e-01,  5.9487e-01, -2.1386e+00,  5.5962e-01,\n",
      "           1.8268e-01, -5.1242e-01,  0.0000e+00,  0.0000e+00, -6.4762e-01,\n",
      "           4.6107e-01, -1.0491e+00,  1.1893e-01,  5.1728e-01, -1.8640e-01,\n",
      "           0.0000e+00,  2.1581e+00,  7.7743e-01, -8.4539e-01,  0.0000e+00,\n",
      "           4.1929e-01,  0.0000e+00, -5.6409e-01, -1.4130e+00,  0.0000e+00,\n",
      "           4.0429e-01, -3.5153e-01,  4.9394e-01, -2.3210e+00,  1.2380e+00,\n",
      "           0.0000e+00,  1.3203e+00, -9.0734e-01,  2.3907e+00,  9.5519e-01,\n",
      "          -1.2008e+00,  5.9425e-01,  1.0664e+00, -1.7340e+00,  3.6527e-01,\n",
      "           4.0218e-01, -1.2705e+00,  4.5480e-01,  1.9688e+00,  1.4972e-01,\n",
      "          -8.3260e-01,  5.3398e-01,  8.0845e-01,  6.6411e-01, -1.0552e+00,\n",
      "           9.1775e-01, -7.0301e-01, -8.4516e-01,  2.5767e-01,  0.0000e+00,\n",
      "          -8.7704e-01,  0.0000e+00, -3.6480e-01,  0.0000e+00, -1.3006e+00,\n",
      "           1.0694e+00, -8.1159e-01,  6.4937e-01,  2.5571e-01, -1.4896e+00,\n",
      "           2.5021e+00,  3.7788e-01, -1.3455e+00,  7.2225e-01,  3.2012e+00,\n",
      "          -7.5283e-01, -3.8357e-01,  1.2823e+00,  2.2521e+00,  1.9417e-01,\n",
      "          -3.9193e-02,  3.0300e+00,  3.6289e-01, -1.8719e-01, -1.1121e+00,\n",
      "           0.0000e+00,  7.7540e-01, -7.7474e-01, -4.4802e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6507e-01, -2.8959e-01, -2.1305e+00, -5.8158e-01,\n",
      "           7.8592e-01, -1.8621e+00, -1.3048e+00,  1.9030e-01, -3.6288e+00,\n",
      "          -1.8688e+00,  1.1506e+00, -8.5981e-01,  9.5948e-01, -1.4613e+00,\n",
      "          -2.7180e-02,  1.9744e+00,  1.1269e+00, -4.8568e-01, -1.2416e+00,\n",
      "           0.0000e+00, -1.3226e+00, -1.6392e+00, -7.7175e-01,  6.8266e-01,\n",
      "          -1.3797e+00, -1.2606e-01,  6.0646e-01,  0.0000e+00,  2.5913e-01,\n",
      "           1.3326e+00, -2.5534e+00,  2.7773e-01, -5.8365e-01,  1.6234e+00,\n",
      "          -1.2403e+00, -1.7821e-03, -5.0170e-02,  9.0094e-01,  5.6556e-01,\n",
      "          -4.1987e-01,  3.8840e-01, -1.1578e-01,  8.0967e-01,  1.0503e+00,\n",
      "          -7.8917e-01, -1.4387e+00, -4.1549e-01, -7.5034e-01, -4.5396e-01,\n",
      "          -5.4747e-01,  7.2232e-01, -1.8533e+00,  1.3573e+00,  8.3761e-01,\n",
      "          -1.5239e+00, -3.5883e-01,  6.4769e-01,  2.0053e-01, -2.1782e+00,\n",
      "           8.3534e-01, -1.2911e+00, -1.2838e+00,  2.6098e-01,  0.0000e+00,\n",
      "           2.0758e+00,  1.3414e-01,  2.5770e+00, -3.0844e-02, -5.7958e-01,\n",
      "           0.0000e+00,  0.0000e+00, -3.8087e-01,  1.4696e+00,  8.0517e-01,\n",
      "           0.0000e+00,  6.6976e-01, -7.0034e-01,  8.9180e-02,  1.0256e+00,\n",
      "           9.7817e-01, -1.4083e+00,  6.5957e-01,  0.0000e+00, -1.6455e+00,\n",
      "          -6.0012e-01,  8.8813e-03, -7.1099e-01,  3.7046e-01, -2.2402e-01,\n",
      "          -7.5232e-01,  5.7211e-01,  0.0000e+00, -6.6373e-01,  1.5465e+00,\n",
      "           5.7829e-01,  1.8920e+00, -8.6400e-01,  4.9356e-01,  0.0000e+00,\n",
      "           5.0006e-01, -9.7496e-01,  1.7728e+00, -1.0636e+00, -8.0782e-01,\n",
      "          -6.2195e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0573, 0.1081, 0.1194, 0.1342, 0.0945, 0.1537, 0.0837, 0.0761, 0.0615,\n",
      "         0.1115]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3548, -0.0233,  0.0816,  ..., -0.1195, -0.0301, -0.4732],\n",
      "        [ 0.1239,  0.1481,  0.2774,  ...,  0.1123,  0.0653,  0.0485],\n",
      "        [ 0.0526,  0.1065,  0.2625,  ...,  0.1219, -0.0483, -0.4450],\n",
      "        ...,\n",
      "        [ 0.2012,  0.1166, -0.4129,  ..., -0.6148,  0.2678, -0.1596],\n",
      "        [ 0.4493,  0.4131, -0.7137,  ..., -0.3597, -0.0150, -0.0618],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9321e-01,  5.9513e-02,  8.4030e-02, -1.1246e-02,  1.1845e-01,\n",
      "           8.9771e-02, -5.3566e-02, -1.6082e-01, -9.5597e-02, -3.4785e-02,\n",
      "          -1.4650e-03,  1.7512e-01,  3.4681e-02,  1.1717e-01,  1.7414e-01,\n",
      "           2.4518e-01,  8.2981e-02, -8.3874e-02, -2.5698e-01, -1.9964e-01,\n",
      "           1.8358e-01, -6.8862e-03,  1.1720e-01, -1.0501e-01,  1.9541e-02,\n",
      "           3.1066e-02,  7.1401e-03, -1.3128e-01, -9.2149e-02,  1.5186e-01,\n",
      "           1.5101e-02,  6.4762e-02, -1.4014e-01,  1.2220e-01, -6.0837e-03,\n",
      "           1.1119e-01, -7.5816e-02, -3.4644e-02, -2.0670e-02,  2.1362e-01,\n",
      "           1.0741e-01,  7.7736e-02, -9.8121e-02,  1.2279e-01,  2.7482e-01,\n",
      "           2.7031e-01,  4.6807e-02,  8.2041e-02,  3.9900e-02, -8.4022e-02,\n",
      "          -4.8231e-02, -1.1324e-01,  4.8236e-02, -1.0317e-01, -6.2462e-03,\n",
      "           5.9317e-02, -2.5481e-01,  7.6658e-02,  6.6368e-02, -7.1529e-02,\n",
      "          -1.8560e-01,  1.4260e-01, -1.6810e-01,  1.5948e-01,  5.5713e-02,\n",
      "          -8.4581e-02, -9.6341e-02,  2.1457e-01, -3.8452e-02, -2.7805e-02,\n",
      "           1.9655e-01,  9.1473e-02, -2.0321e-01,  8.8478e-02, -2.7065e-01,\n",
      "           1.4654e-01,  2.2479e-01,  1.0871e-01,  1.1232e-01,  1.0815e-01,\n",
      "          -1.3897e-01,  1.2019e-01,  6.9471e-02,  8.8707e-02,  1.7646e-01,\n",
      "           4.1335e-02,  2.8837e-02,  1.8905e-01, -4.7427e-02, -1.0465e-02,\n",
      "           5.2507e-02, -2.9825e-03, -2.1318e-01,  8.7163e-02,  1.4090e-01,\n",
      "           2.1639e-01,  2.4714e-01,  2.3116e-01, -8.1198e-02,  1.3375e-01,\n",
      "           4.7418e-03,  1.6945e-01,  2.6234e-01,  1.4671e-01,  5.9571e-02,\n",
      "          -9.7058e-02,  1.6486e-01, -5.8153e-02, -4.2394e-01, -1.5561e-02,\n",
      "          -1.7843e-01,  7.8628e-02, -1.4339e-01, -2.4937e-01,  1.2760e-01,\n",
      "          -3.2557e-01, -1.0395e-01,  7.8812e-02,  8.2225e-02, -3.1896e-02,\n",
      "           1.9440e-01, -8.8397e-02, -1.6288e-01, -7.4575e-02, -2.7706e-01,\n",
      "           6.1010e-02,  3.4902e-01, -2.3351e-02,  2.7736e-01,  1.3188e-03,\n",
      "           7.4030e-02,  7.6056e-02,  2.9558e-02, -5.6205e-02,  1.4450e-01,\n",
      "          -3.5406e-02,  1.9413e-01,  4.4054e-02,  2.0480e-01, -1.0647e-01,\n",
      "           5.6984e-02,  5.5597e-03,  2.3617e-01,  1.6984e-01, -1.2185e-01,\n",
      "           1.3791e-01,  2.8650e-01,  2.0073e-01, -7.5501e-02,  1.1393e-01,\n",
      "          -2.1818e-01, -1.1261e-01,  1.5981e-02,  2.5884e-01, -1.6332e-01,\n",
      "           1.5384e-01, -1.3304e-01,  2.2989e-01, -1.7017e-02,  4.0739e-02,\n",
      "          -4.1822e-02,  1.7225e-01,  2.3871e-02,  6.8940e-02, -1.3387e-01,\n",
      "          -9.6482e-02, -1.7213e-01, -8.0504e-05, -1.9221e-01,  9.0853e-02,\n",
      "          -1.2148e-01,  2.1148e-02, -9.0557e-02,  1.9488e-01,  2.3172e-01,\n",
      "          -1.7037e-01,  1.8800e-01, -1.6483e-01,  1.0177e-01, -5.7358e-02,\n",
      "          -3.2776e-02,  1.9640e-01, -3.5532e-01, -1.1770e-01, -6.9125e-02,\n",
      "          -5.2610e-02,  9.3697e-02, -4.6137e-03, -1.0224e-01, -1.7064e-01,\n",
      "           1.1435e-01, -9.3449e-02,  1.2058e-01, -2.6422e-01, -1.3369e-01,\n",
      "          -2.1378e-01, -3.4608e-02,  8.0777e-02, -1.1645e-03, -1.8191e-01,\n",
      "           1.1002e-01,  1.0815e-01,  1.5522e-01, -9.1049e-02, -2.5636e-01,\n",
      "           9.4163e-02, -4.6658e-02, -2.0476e-01,  1.3990e-01, -1.5769e-01,\n",
      "           9.8231e-02, -3.1518e-01, -1.7431e-02,  2.9562e-02, -1.0358e-01,\n",
      "          -7.2284e-02,  1.7506e-02,  1.6178e-01, -3.1266e-01, -2.2348e-01,\n",
      "           2.1004e-02,  2.0042e-01,  2.9084e-01, -1.2251e-01,  1.1705e-01,\n",
      "           2.5815e-01, -5.4651e-02,  1.2417e-01, -1.6923e-01,  4.2337e-02,\n",
      "          -1.4413e-01, -2.0002e-01, -2.1886e-01, -7.2416e-02, -1.4151e-01,\n",
      "           9.4807e-02, -7.9901e-02, -2.8006e-01,  2.8191e-02,  2.0831e-01,\n",
      "           1.1078e-01, -8.8201e-02, -2.3669e-01,  1.9546e-01,  1.7525e-01,\n",
      "          -2.1307e-02, -2.3263e-01, -1.3982e-01, -1.9052e-01, -1.7035e-01,\n",
      "          -1.4393e-01,  3.0580e-02, -1.4313e-01, -1.8794e-01,  6.4717e-02,\n",
      "          -1.6429e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0626e+00, -6.9574e-02, -1.8078e+00,  1.3220e+00,  5.1608e-01,\n",
      "          -3.7601e-01,  1.2080e-03, -7.2296e-01,  2.1179e+00, -2.1365e-01,\n",
      "           0.0000e+00,  8.3061e-01, -1.1105e+00,  1.9973e-01,  3.1259e-01,\n",
      "           3.5184e-01, -6.8294e-01,  1.6918e-01,  8.7450e-01,  0.0000e+00,\n",
      "           1.8833e+00,  0.0000e+00,  0.0000e+00, -5.3535e-01, -1.0054e-01,\n",
      "           6.5107e-01, -1.6089e+00, -1.3622e+00, -2.1266e+00, -1.0345e+00,\n",
      "           3.8758e-02, -1.4546e+00, -2.0766e+00,  0.0000e+00, -2.8480e-01,\n",
      "          -2.0018e+00,  2.1883e-01,  9.9695e-01,  6.0135e-01,  9.5349e-01,\n",
      "          -2.2510e-01, -2.2112e+00, -7.0609e-01,  1.3959e+00,  8.9658e-02,\n",
      "          -1.1385e+00,  2.4257e-01,  7.4192e-01, -7.0975e-01, -1.3358e+00,\n",
      "           1.6085e+00, -1.3753e-01,  6.6256e-01,  1.1163e+00,  5.6734e-01,\n",
      "           3.3295e-01, -4.4961e-01, -8.8807e-01,  0.0000e+00,  6.2836e-01,\n",
      "          -7.0483e-01,  5.6372e-01, -6.9337e-01, -1.5473e+00,  2.8930e-01,\n",
      "           9.5603e-02, -1.7745e-01,  5.9487e-01, -2.1386e+00,  5.5962e-01,\n",
      "           1.8268e-01,  0.0000e+00, -3.4105e-01, -1.1320e+00, -6.4762e-01,\n",
      "           4.6107e-01, -1.0491e+00,  1.1893e-01,  5.1728e-01, -1.8640e-01,\n",
      "          -3.8497e-01,  2.1581e+00,  7.7743e-01, -8.4539e-01,  3.9787e-01,\n",
      "           4.1929e-01,  1.6046e+00,  0.0000e+00, -1.4130e+00, -1.4905e+00,\n",
      "           4.0429e-01, -3.5153e-01,  4.9394e-01, -2.3210e+00,  1.2380e+00,\n",
      "          -9.6299e-01,  1.3203e+00, -9.0734e-01,  2.3907e+00,  9.5519e-01,\n",
      "          -1.2008e+00,  5.9425e-01,  1.0664e+00, -1.7340e+00,  3.6527e-01,\n",
      "           4.0218e-01, -1.2705e+00,  4.5480e-01,  1.9688e+00,  1.4972e-01,\n",
      "          -8.3260e-01,  5.3398e-01,  8.0845e-01,  6.6411e-01,  0.0000e+00,\n",
      "           9.1775e-01, -7.0301e-01,  0.0000e+00,  2.5767e-01,  0.0000e+00,\n",
      "          -8.7704e-01, -1.3964e+00, -3.6480e-01, -1.8465e+00, -1.3006e+00,\n",
      "           1.0694e+00, -8.1159e-01,  6.4937e-01,  2.5571e-01, -1.4896e+00,\n",
      "           2.5021e+00,  3.7788e-01, -1.3455e+00,  0.0000e+00,  3.2012e+00,\n",
      "          -7.5283e-01, -3.8357e-01,  1.2823e+00,  2.2521e+00,  1.9417e-01,\n",
      "          -3.9193e-02,  3.0300e+00,  3.6289e-01, -1.8719e-01, -1.1121e+00,\n",
      "           0.0000e+00,  7.7540e-01, -7.7474e-01, -4.4802e-02, -1.3868e+00,\n",
      "           2.3360e+00,  7.6507e-01,  0.0000e+00, -2.1305e+00, -5.8158e-01,\n",
      "           7.8592e-01, -1.8621e+00,  0.0000e+00,  0.0000e+00, -3.6288e+00,\n",
      "          -1.8688e+00,  0.0000e+00, -8.5981e-01,  9.5948e-01, -1.4613e+00,\n",
      "          -2.7180e-02,  1.9744e+00,  1.1269e+00, -4.8568e-01, -1.2416e+00,\n",
      "          -2.1241e-01, -1.3226e+00, -1.6392e+00, -7.7175e-01,  6.8266e-01,\n",
      "          -1.3797e+00,  0.0000e+00,  6.0646e-01, -7.4897e-01,  0.0000e+00,\n",
      "           1.3326e+00, -2.5534e+00,  2.7773e-01, -5.8365e-01,  1.6234e+00,\n",
      "          -1.2403e+00, -1.7821e-03, -5.0170e-02,  9.0094e-01,  5.6556e-01,\n",
      "          -4.1987e-01,  3.8840e-01, -1.1578e-01,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.4387e+00, -4.1549e-01, -7.5034e-01, -4.5396e-01,\n",
      "          -5.4747e-01,  7.2232e-01, -1.8533e+00,  1.3573e+00,  8.3761e-01,\n",
      "          -1.5239e+00, -3.5883e-01,  6.4769e-01,  2.0053e-01, -2.1782e+00,\n",
      "           8.3534e-01, -1.2911e+00, -1.2838e+00,  2.6098e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.3414e-01,  2.5770e+00, -3.0844e-02, -5.7958e-01,\n",
      "          -1.4282e+00,  1.9012e+00, -3.8087e-01,  1.4696e+00,  8.0517e-01,\n",
      "           0.0000e+00,  6.6976e-01, -7.0034e-01,  8.9180e-02,  1.0256e+00,\n",
      "           9.7817e-01, -1.4083e+00,  6.5957e-01, -1.1449e+00, -1.6455e+00,\n",
      "          -6.0012e-01,  8.8813e-03, -7.1099e-01,  3.7046e-01, -2.2402e-01,\n",
      "          -7.5232e-01,  5.7211e-01,  5.3063e-01, -6.6373e-01,  1.5465e+00,\n",
      "           5.7829e-01,  1.8920e+00, -8.6400e-01,  0.0000e+00, -3.8716e-01,\n",
      "           5.0006e-01, -9.7496e-01,  1.7728e+00, -1.0636e+00,  0.0000e+00,\n",
      "          -6.2195e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0603, 0.1122, 0.1157, 0.1452, 0.0954, 0.1505, 0.0837, 0.0574, 0.0631,\n",
      "         0.1164]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3548, -0.0233,  0.0816,  ..., -0.1195, -0.0301, -0.4732],\n",
      "        [ 0.1239,  0.1481,  0.2774,  ...,  0.1123,  0.0653,  0.0485],\n",
      "        [ 0.0526,  0.1065,  0.2625,  ...,  0.1219, -0.0483, -0.4450],\n",
      "        ...,\n",
      "        [ 0.2012,  0.1166, -0.4129,  ..., -0.6148,  0.2678, -0.1596],\n",
      "        [ 0.4493,  0.4131, -0.7137,  ..., -0.3597, -0.0150, -0.0618],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.8881e-01,  5.7144e-02,  8.9312e-02, -1.1538e-02,  1.2993e-01,\n",
      "           9.6754e-02, -6.2783e-02, -1.5142e-01, -9.1619e-02, -2.5939e-02,\n",
      "          -1.0565e-02,  1.7829e-01,  4.4263e-02,  1.0978e-01,  1.7342e-01,\n",
      "           2.5073e-01,  8.7729e-02, -9.3548e-02, -2.5136e-01, -1.9863e-01,\n",
      "           1.8469e-01, -6.4288e-03,  1.0413e-01, -1.0511e-01,  2.0148e-02,\n",
      "           2.0586e-02, -3.1871e-03, -1.2878e-01, -8.6478e-02,  1.4856e-01,\n",
      "           1.3686e-02,  6.8024e-02, -1.3605e-01,  1.3618e-01, -9.6108e-03,\n",
      "           1.0703e-01, -7.0579e-02, -3.1597e-02, -1.9220e-02,  1.9684e-01,\n",
      "           1.0754e-01,  6.6490e-02, -9.6059e-02,  1.1049e-01,  2.8265e-01,\n",
      "           2.5891e-01,  5.5839e-02,  8.4730e-02,  4.1035e-02, -7.8238e-02,\n",
      "          -5.9425e-02, -1.1425e-01,  5.5477e-02, -1.0401e-01, -5.8786e-03,\n",
      "           5.9382e-02, -2.5586e-01,  7.4825e-02,  6.5072e-02, -6.2416e-02,\n",
      "          -1.8436e-01,  1.4779e-01, -1.6094e-01,  1.5839e-01,  6.3272e-02,\n",
      "          -8.6263e-02, -9.7555e-02,  2.1207e-01, -2.8319e-02, -3.0326e-02,\n",
      "           1.8957e-01,  8.8391e-02, -2.0340e-01,  7.9753e-02, -2.6823e-01,\n",
      "           1.3928e-01,  2.2163e-01,  1.0501e-01,  1.0524e-01,  1.0062e-01,\n",
      "          -1.4669e-01,  1.1233e-01,  6.7185e-02,  8.6637e-02,  1.7533e-01,\n",
      "           4.2420e-02,  2.5141e-02,  1.8079e-01, -5.2216e-02, -1.0153e-02,\n",
      "           4.9448e-02,  3.0413e-03, -2.0726e-01,  9.1112e-02,  1.4180e-01,\n",
      "           2.0634e-01,  2.4013e-01,  2.2835e-01, -9.0268e-02,  1.3244e-01,\n",
      "           6.9432e-03,  1.5539e-01,  2.5866e-01,  1.4441e-01,  5.0284e-02,\n",
      "          -9.4658e-02,  1.5157e-01, -7.9427e-02, -4.2194e-01, -1.5313e-02,\n",
      "          -1.7855e-01,  8.0236e-02, -1.3298e-01, -2.4215e-01,  1.3579e-01,\n",
      "          -3.2605e-01, -9.8453e-02,  8.1551e-02,  8.2053e-02, -3.3427e-02,\n",
      "           2.0550e-01, -9.4798e-02, -1.5865e-01, -7.8948e-02, -2.7587e-01,\n",
      "           6.3623e-02,  3.5162e-01, -2.2609e-02,  2.8799e-01,  5.0063e-03,\n",
      "           7.1285e-02,  7.5264e-02,  2.4983e-02, -6.4351e-02,  1.3674e-01,\n",
      "          -3.0010e-02,  1.9959e-01,  3.7122e-02,  2.0950e-01, -1.0538e-01,\n",
      "           7.0606e-02,  1.2351e-02,  2.4855e-01,  1.8277e-01, -1.2114e-01,\n",
      "           1.4099e-01,  2.8954e-01,  1.9543e-01, -8.0705e-02,  1.0907e-01,\n",
      "          -2.0964e-01, -1.2115e-01,  2.2058e-02,  2.5719e-01, -1.6464e-01,\n",
      "           1.4805e-01, -1.2993e-01,  2.2739e-01, -1.6007e-02,  4.3748e-02,\n",
      "          -3.9727e-02,  1.7484e-01,  3.4356e-02,  6.7708e-02, -1.2663e-01,\n",
      "          -9.6967e-02, -1.5860e-01, -2.6634e-04, -1.9248e-01,  9.0890e-02,\n",
      "          -1.1707e-01,  1.6998e-02, -8.8637e-02,  1.9076e-01,  2.3360e-01,\n",
      "          -1.6698e-01,  1.8849e-01, -1.6492e-01,  9.3080e-02, -4.4657e-02,\n",
      "          -2.6759e-02,  1.9699e-01, -3.4876e-01, -1.1745e-01, -8.1607e-02,\n",
      "          -5.5211e-02,  8.8484e-02, -1.4080e-02, -1.0109e-01, -1.6341e-01,\n",
      "           1.2100e-01, -8.7952e-02,  1.2468e-01, -2.6087e-01, -1.2949e-01,\n",
      "          -2.0439e-01, -4.3315e-02,  8.6889e-02, -1.2421e-04, -1.7652e-01,\n",
      "           1.0178e-01,  1.0560e-01,  1.6038e-01, -8.5932e-02, -2.4713e-01,\n",
      "           9.9954e-02, -4.1666e-02, -2.0540e-01,  1.3856e-01, -1.4305e-01,\n",
      "           1.0764e-01, -3.1526e-01, -2.3429e-02,  2.7259e-02, -9.5799e-02,\n",
      "          -7.6299e-02,  1.1208e-02,  1.6863e-01, -3.0976e-01, -2.2161e-01,\n",
      "           3.0316e-02,  1.9496e-01,  2.9715e-01, -1.2909e-01,  1.1375e-01,\n",
      "           2.6021e-01, -5.4688e-02,  1.3150e-01, -1.6553e-01,  4.2647e-02,\n",
      "          -1.5673e-01, -1.9970e-01, -2.1263e-01, -6.8515e-02, -1.4097e-01,\n",
      "           9.6352e-02, -8.0557e-02, -2.8384e-01,  2.7571e-02,  2.0474e-01,\n",
      "           1.1826e-01, -8.9038e-02, -2.4629e-01,  1.9244e-01,  1.7655e-01,\n",
      "          -1.6342e-02, -2.2422e-01, -1.4175e-01, -1.9378e-01, -1.6120e-01,\n",
      "          -1.4473e-01,  2.3024e-02, -1.3752e-01, -1.8015e-01,  5.6519e-02,\n",
      "          -1.6465e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7275e-01, -4.3058e-01,  3.1495e-01, -1.0846e+00, -1.1724e+00,\n",
      "           7.4176e-01, -1.9142e+00,  1.3513e+00,  1.9046e-01,  6.1736e-01,\n",
      "           1.9029e+00,  6.0244e-01,  2.2863e-01,  0.0000e+00, -3.1820e+00,\n",
      "          -6.8436e-02, -1.6330e+00, -9.4353e-01,  1.3607e+00, -1.4349e+00,\n",
      "          -1.4066e-01, -5.2358e-01, -1.1195e+00, -2.5950e+00, -7.5690e-02,\n",
      "           1.3913e+00, -6.1942e-01,  1.9970e+00,  1.2764e-01,  5.5404e-01,\n",
      "           9.1498e-01, -3.5821e-03,  2.2286e-01,  2.0155e+00, -6.3717e-02,\n",
      "          -1.4084e+00, -1.1191e-01, -8.1765e-01,  3.1474e-01,  8.5467e-02,\n",
      "           8.6215e-01, -8.9964e-01,  1.0090e+00, -1.5632e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00, -6.0147e-01, -1.0206e+00,  0.0000e+00,\n",
      "          -1.3223e+00,  2.6768e+00,  6.6669e-01, -8.4664e-01,  2.2755e-01,\n",
      "          -3.0908e-01, -1.4341e+00, -9.6603e-02,  1.2750e+00,  2.1809e+00,\n",
      "          -1.0063e+00,  3.6134e-02, -2.8013e-01,  2.6588e-01, -6.2805e-02,\n",
      "           3.9394e-01,  5.7804e-01,  1.1650e+00,  1.5806e+00,  0.0000e+00,\n",
      "           4.2757e-01,  2.9650e-01, -3.1341e-02, -7.9770e-01, -2.1443e-01,\n",
      "           1.3928e-01,  5.2566e-01,  1.3985e+00,  1.0270e+00, -7.9304e-01,\n",
      "           7.5769e-01, -1.0056e+00,  7.5736e-01,  1.0587e+00, -1.2145e+00,\n",
      "          -1.1304e-01, -1.1075e+00,  5.4876e-01, -9.4471e-01, -1.9014e+00,\n",
      "           5.2907e-01,  9.8668e-01,  0.0000e+00,  9.4345e-01,  6.0807e-01,\n",
      "          -1.5943e-02,  3.5316e-01, -1.1756e+00,  0.0000e+00,  2.4478e+00,\n",
      "           0.0000e+00,  4.5501e-02, -4.6638e-01, -9.8937e-01,  1.6399e+00,\n",
      "          -1.0229e+00,  3.0287e+00,  6.1971e-01, -1.0206e-01, -1.2353e+00,\n",
      "           1.8987e-01, -5.0287e-01, -5.7028e-01,  7.1226e-01, -7.8037e-01,\n",
      "           6.3221e-01,  4.0405e-01,  2.2412e-01, -2.3271e+00,  2.9347e-02,\n",
      "          -8.1372e-01, -1.4107e+00, -1.8371e+00,  6.0328e-01, -9.5640e-01,\n",
      "          -2.0021e-01,  3.9272e-02,  2.1499e+00,  1.3961e+00, -2.0875e+00,\n",
      "          -9.2642e-01,  4.4963e-01,  0.0000e+00,  4.2516e-01, -4.6880e-01,\n",
      "          -7.4474e-01, -1.0649e+00, -9.7474e-01, -1.9530e-02,  2.3976e+00,\n",
      "           6.9860e-01, -1.1217e+00,  1.6916e+00, -1.4022e-01, -6.6939e-01,\n",
      "           3.4035e-02,  7.5931e-01,  4.2304e-01, -1.0331e+00, -9.5643e-02,\n",
      "           1.5600e+00,  0.0000e+00, -3.3881e-01,  6.5764e-01,  1.8407e+00,\n",
      "           0.0000e+00, -2.1746e-01,  6.2341e-01, -2.3623e+00,  1.0555e+00,\n",
      "           3.0248e-01, -7.7483e-02,  1.5439e-01, -1.2116e+00, -2.1875e-02,\n",
      "           1.6819e+00,  1.8517e+00,  2.7066e-01, -1.2702e+00, -7.1328e-01,\n",
      "          -1.2244e+00,  0.0000e+00, -2.5902e+00,  0.0000e+00, -3.0585e+00,\n",
      "           0.0000e+00,  4.9824e-01,  8.2942e-01,  3.1708e-01, -7.9278e-01,\n",
      "           2.7130e-01,  2.3395e+00,  1.0572e+00,  8.3824e-01, -4.0309e-01,\n",
      "           7.2713e-01,  5.9908e-01,  3.5943e-01,  8.4233e-01, -1.8299e+00,\n",
      "           1.3634e+00,  2.1589e+00,  3.3673e-01, -1.0152e+00, -1.1716e+00,\n",
      "          -2.2149e+00,  1.6660e+00,  2.1525e+00,  3.6338e-01,  2.3835e+00,\n",
      "           3.2289e-02, -5.0154e-01, -1.2760e+00, -5.4244e-01, -4.0731e-01,\n",
      "          -1.4468e+00,  0.0000e+00, -8.5167e-01,  8.3056e-01, -1.5597e+00,\n",
      "           6.3624e-01,  6.7614e-01,  2.3973e+00,  5.5026e-02,  1.8939e+00,\n",
      "           1.3079e+00,  5.8076e-01, -2.3169e+00,  0.0000e+00, -2.2254e-01,\n",
      "          -2.2715e-01,  0.0000e+00,  2.7704e-01, -1.5519e+00,  9.2281e-01,\n",
      "           0.0000e+00, -8.4807e-01, -1.8014e+00, -3.3476e-04,  3.7336e-01,\n",
      "          -1.5733e+00, -1.2347e-01,  9.6623e-01, -1.7360e+00,  1.6940e+00,\n",
      "          -1.4404e+00,  6.3405e-01, -1.7218e+00,  9.8041e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.7197e-01, -2.5966e+00,  1.2384e+00, -1.2285e+00,\n",
      "           0.0000e+00, -5.0832e-01,  5.4282e-01, -2.6132e-01, -1.0217e+00,\n",
      "           1.3332e+00,  3.1037e-01, -5.1502e-02, -2.2884e-01, -1.6116e+00,\n",
      "           1.8061e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0467, 0.1192, 0.1538, 0.1111, 0.1330, 0.1009, 0.1097, 0.0747, 0.1008,\n",
      "         0.0501]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3548, -0.0233,  0.0816,  ..., -0.1195, -0.0301, -0.4732],\n",
      "        [ 0.1239,  0.1481,  0.2774,  ...,  0.1123,  0.0653,  0.0485],\n",
      "        [ 0.0526,  0.1065,  0.2625,  ...,  0.1219, -0.0483, -0.4450],\n",
      "        ...,\n",
      "        [ 0.2012,  0.1166, -0.4129,  ..., -0.6148,  0.2678, -0.1596],\n",
      "        [ 0.4493,  0.4131, -0.7137,  ..., -0.3597, -0.0150, -0.0618],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2012,  0.0991,  0.0466,  0.0249,  0.1141,  0.0764, -0.0494,\n",
      "          -0.1749, -0.0796, -0.0346,  0.0351,  0.1698,  0.0376,  0.1229,\n",
      "           0.1879,  0.2238,  0.1141, -0.0829, -0.3092, -0.2307,  0.1721,\n",
      "          -0.0025,  0.1388, -0.0957, -0.0199,  0.0242,  0.0150, -0.1411,\n",
      "          -0.1014,  0.1459,  0.0101,  0.0529, -0.1593,  0.1080,  0.0225,\n",
      "           0.1159, -0.0993, -0.0232, -0.0745,  0.2195,  0.0988,  0.0479,\n",
      "          -0.1097,  0.1390,  0.2877,  0.2996,  0.0445,  0.0813,  0.0783,\n",
      "          -0.0828, -0.0550, -0.1579,  0.0372, -0.1055, -0.0322,  0.0804,\n",
      "          -0.2725,  0.0923,  0.0711, -0.0672, -0.1791,  0.1563, -0.1959,\n",
      "           0.1651,  0.0291, -0.0844, -0.0971,  0.2463, -0.0435, -0.0398,\n",
      "           0.2087,  0.0986, -0.2137,  0.1051, -0.2898,  0.1435,  0.2474,\n",
      "           0.1160,  0.1256,  0.0822, -0.1602,  0.1013,  0.0585,  0.0744,\n",
      "           0.1800,  0.0667,  0.0468,  0.2060, -0.0574, -0.0278,  0.0449,\n",
      "           0.0063, -0.2077,  0.0797,  0.1336,  0.2303,  0.2738,  0.2862,\n",
      "          -0.0864,  0.1301, -0.0419,  0.1537,  0.2946,  0.1610,  0.0654,\n",
      "          -0.0878,  0.1858, -0.0501, -0.4404,  0.0079, -0.1589,  0.0997,\n",
      "          -0.1447, -0.2507,  0.1310, -0.3350, -0.0990,  0.0483,  0.0893,\n",
      "          -0.0678,  0.1895, -0.1416, -0.1696, -0.0873, -0.2864,  0.0394,\n",
      "           0.3525, -0.0300,  0.3195,  0.0095,  0.0376,  0.0378,  0.0681,\n",
      "          -0.0470,  0.1256, -0.0095,  0.2258,  0.0427,  0.1948, -0.1309,\n",
      "           0.0454, -0.0048,  0.2211,  0.1988, -0.1329,  0.1424,  0.2822,\n",
      "           0.2367, -0.0897,  0.1319, -0.2359, -0.1197,  0.0242,  0.2679,\n",
      "          -0.1774,  0.1698, -0.1409,  0.2269,  0.0029,  0.0242, -0.0661,\n",
      "           0.1612,  0.0180,  0.1121, -0.1271, -0.0984, -0.1997, -0.0361,\n",
      "          -0.1771,  0.0961, -0.1032,  0.0328, -0.1053,  0.2165,  0.2567,\n",
      "          -0.1850,  0.1610, -0.1710,  0.1706, -0.0781, -0.0611,  0.2009,\n",
      "          -0.3849, -0.1200, -0.0420, -0.0485,  0.0643,  0.0415, -0.0562,\n",
      "          -0.1982,  0.0912, -0.0970,  0.1210, -0.2576, -0.1361, -0.2228,\n",
      "           0.0055,  0.0698,  0.0022, -0.1494,  0.1090,  0.1336,  0.1427,\n",
      "          -0.0784, -0.2616,  0.0904, -0.0864, -0.1914,  0.1316, -0.1496,\n",
      "           0.1081, -0.3311, -0.0085,  0.0150, -0.1143, -0.0527, -0.0060,\n",
      "           0.1767, -0.3538, -0.2015,  0.0194,  0.1952,  0.2856, -0.1218,\n",
      "           0.1348,  0.2936, -0.0382,  0.1119, -0.1846,  0.0690, -0.1424,\n",
      "          -0.2033, -0.2441, -0.1126, -0.1460,  0.0830, -0.1018, -0.2751,\n",
      "           0.0305,  0.2239,  0.0960, -0.0907, -0.2455,  0.1657,  0.2098,\n",
      "          -0.0094, -0.2535, -0.1287, -0.1921, -0.2111, -0.1404,  0.0178,\n",
      "          -0.1721, -0.2028,  0.0529, -0.1618]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0867,  0.3998, -0.9651, -0.6810,  0.3754, -0.2019,  1.4646,\n",
      "          -0.0836, -3.5834,  0.9066,  0.4280, -0.6291,  2.6025, -0.6301,\n",
      "           0.0000, -0.1580,  0.8512,  1.0943,  0.4552,  0.4362, -0.6333,\n",
      "          -0.3825,  1.6400,  0.0000,  0.7533, -0.0758, -0.1881, -0.7597,\n",
      "           1.6532,  0.8614,  1.2315,  1.2190, -1.0341, -0.0831, -1.5341,\n",
      "           1.3954,  0.2809, -3.7439,  0.1977,  1.6003, -0.4590, -1.3978,\n",
      "          -0.2688, -1.7146, -1.5234,  0.6677,  0.5405,  0.3711, -1.3404,\n",
      "           0.1445, -0.6294,  2.7507,  0.6101, -1.0288, -0.0251,  0.2038,\n",
      "          -0.8814, -1.2514, -0.2372, -0.4260,  1.0993,  1.4073, -0.2026,\n",
      "          -0.5009, -2.9626,  0.5513,  0.0000, -1.2874,  0.4104,  0.5268,\n",
      "          -1.2664, -0.0297,  0.7072, -3.6399,  0.3252,  0.0000, -0.1600,\n",
      "           1.0616, -0.0575, -0.1183, -1.3998,  2.1300, -0.9243,  1.0058,\n",
      "          -0.2075,  0.0000,  1.6612, -0.9739, -0.1042, -0.5811, -2.2725,\n",
      "           0.0000, -0.6224, -1.1356,  0.0000, -1.1701,  0.0332,  0.6289,\n",
      "           1.7192,  0.0000,  2.6967, -1.4617,  1.0759,  0.0000, -0.6662,\n",
      "          -0.7623,  1.2112,  0.1272,  0.0000,  0.0000, -0.2482,  0.1341,\n",
      "          -1.0473,  1.3099, -1.6524, -2.9879, -0.0569, -0.4996, -0.1933,\n",
      "           0.4454, -1.4651,  0.7021,  0.0000, -0.7257, -0.9578, -1.3078,\n",
      "           0.8959,  0.1696,  1.2846, -0.7513, -0.8241,  0.5307, -1.5825,\n",
      "           0.9839,  0.2761, -0.5892,  0.6586,  0.0000, -1.1590, -1.0095,\n",
      "          -0.3881,  0.6778, -0.7894, -0.1007, -1.6847, -0.1003, -0.5430,\n",
      "          -0.8442,  0.0000,  0.1776,  1.9979, -0.1992,  0.0000, -0.4062,\n",
      "           0.4411, -0.1944, -0.0649, -0.1303,  0.0392,  0.0000, -0.0266,\n",
      "           0.0000,  0.4810, -0.5502, -0.5260, -0.8915,  0.2815,  0.0000,\n",
      "          -0.3581, -0.4779,  0.7363, -0.0309,  0.0200, -1.0024,  1.2776,\n",
      "          -1.0977, -0.9860, -2.0755,  1.9683,  0.0864, -0.0309,  0.0350,\n",
      "           0.6707,  0.9798, -0.7475, -0.3409, -2.7817, -0.7831,  1.2089,\n",
      "           1.0125,  3.0724,  0.4941, -0.1444, -0.5930,  0.5600,  2.1642,\n",
      "          -1.1874,  0.5350,  1.8108,  0.0000, -1.6625, -1.0153,  1.2422,\n",
      "          -0.1221,  0.0000, -0.5748, -2.2919,  0.6816, -1.0733, -0.4710,\n",
      "           2.8672, -0.5732, -0.3412,  0.7928,  0.0313, -0.6835, -1.0175,\n",
      "           0.9667, -0.2452,  0.0000, -1.0826, -0.4270,  0.0000, -0.5004,\n",
      "           0.3389,  0.7048, -0.6965, -0.6282,  0.0000, -1.5776, -1.1082,\n",
      "           1.5812,  0.0000,  1.3100, -2.9791,  4.0337,  0.5851,  0.0431,\n",
      "          -1.5788, -0.2862,  0.7419, -3.2468, -0.3037, -0.8518,  0.0113,\n",
      "           0.2756,  0.2746,  0.2522,  0.0000,  0.3866, -0.3657, -0.1595,\n",
      "           0.0000, -0.0521, -1.1463, -1.1313]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0423, 0.0654, 0.0772, 0.0739, 0.1399, 0.2736, 0.0798, 0.0735, 0.0591,\n",
      "         0.1153]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0050,  0.1501, -0.1418,  ...,  0.5532,  0.1694, -0.1555],\n",
      "        [ 0.0715,  0.0903, -0.2475,  ..., -0.0556, -0.0082,  0.2316],\n",
      "        [-0.0882, -0.0502,  0.3583,  ..., -0.2284, -0.1793,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.1467e-01, -8.8726e-02, -2.0167e-01, -1.1614e-01, -1.2212e-01,\n",
      "           1.1712e-01, -2.9313e-01, -2.0233e-01, -5.1114e-02, -1.7541e-01,\n",
      "           1.7272e-01, -5.6976e-02, -1.8452e-02, -1.2152e-01,  6.8586e-02,\n",
      "           1.9540e-04, -1.2346e-02,  9.6850e-02, -1.3327e-01, -6.7939e-02,\n",
      "          -1.6843e-01, -6.7639e-02,  1.3334e-02, -1.4084e-02, -2.7052e-03,\n",
      "           1.9453e-01,  5.8255e-02, -1.0970e-01, -1.4370e-01,  2.5139e-02,\n",
      "           8.7874e-02, -2.4170e-03,  2.0316e-01, -2.1649e-01,  7.7935e-02,\n",
      "          -2.1440e-01, -7.6035e-02, -1.4403e-01, -1.6750e-01, -3.7359e-02,\n",
      "           7.0985e-02,  8.1207e-02,  9.5880e-02, -2.6395e-01, -1.4441e-01,\n",
      "           1.4288e-01,  1.1029e-01, -1.9454e-01,  1.6120e-01, -8.7890e-02,\n",
      "          -1.2841e-01, -1.1713e-01, -2.0663e-01, -1.9528e-01, -3.5987e-01,\n",
      "          -3.3418e-02,  2.5020e-03,  1.9220e-02,  1.0405e-02,  1.9909e-01,\n",
      "          -3.4970e-02, -1.0124e-01, -2.8237e-02,  1.3428e-03,  5.9612e-02,\n",
      "           1.2856e-03, -9.1272e-02, -4.5600e-02,  2.9261e-02, -4.2089e-02,\n",
      "           2.9744e-01,  2.1901e-01,  1.7549e-02,  1.2702e-01, -2.5161e-02,\n",
      "           9.6238e-02,  2.9687e-01,  1.3550e-01,  6.0243e-02,  1.9640e-01,\n",
      "          -1.3983e-01,  4.4707e-02, -9.6864e-02,  8.8016e-02, -6.1928e-02,\n",
      "           1.0005e-01, -5.0529e-02,  1.9032e-01,  2.9219e-02, -2.8865e-02,\n",
      "           9.1608e-02, -1.0590e-01, -9.8660e-02,  2.4908e-02,  3.2620e-02,\n",
      "           2.5320e-01,  1.7101e-02,  1.0015e-01,  2.8917e-01,  9.3716e-02,\n",
      "          -2.3822e-02,  1.6457e-01,  2.4339e-01,  6.5719e-02,  2.0127e-01,\n",
      "          -3.5318e-01, -1.8288e-02,  1.7280e-01,  8.5994e-02,  8.5967e-03,\n",
      "          -2.7046e-02,  2.8425e-01, -1.1810e-02, -3.9055e-02,  1.2764e-01,\n",
      "           1.6640e-01, -1.4832e-01, -3.4759e-02, -8.1001e-02,  1.0518e-01,\n",
      "           9.1686e-02,  2.9189e-01, -8.9577e-02,  1.2593e-01, -1.2377e-01,\n",
      "          -9.2769e-02, -2.1805e-01, -9.4910e-02,  1.1237e-01,  1.9715e-02,\n",
      "          -1.5465e-01,  1.8703e-02,  9.1020e-02,  1.1945e-01, -3.0970e-01,\n",
      "          -1.1739e-01,  1.2920e-01,  1.7173e-01, -2.1801e-01, -1.2239e-01,\n",
      "          -3.4303e-01,  2.6227e-01, -2.9131e-01, -5.6526e-02,  7.3968e-04,\n",
      "           1.3300e-01, -3.7150e-02,  3.3930e-01, -3.9939e-02,  2.9745e-01,\n",
      "          -3.3516e-01,  6.5243e-02, -1.3257e-01,  2.4023e-01,  3.9830e-02,\n",
      "           1.1866e-01,  1.0946e-01,  1.7329e-01,  8.2550e-02,  1.1466e-01,\n",
      "          -1.7260e-01, -9.4416e-02, -2.8560e-01,  1.6036e-01, -2.2455e-01,\n",
      "          -9.0504e-03, -1.5582e-01,  5.7725e-02,  1.0736e-01,  1.6820e-02,\n",
      "          -1.2542e-01,  1.9319e-01,  1.3021e-01,  1.3880e-01, -4.0677e-02,\n",
      "           1.0330e-01,  8.6280e-02, -6.7917e-02,  1.0666e-01, -4.0304e-02,\n",
      "          -2.3930e-02, -1.3396e-01, -7.6220e-02, -6.0119e-02,  2.2729e-01,\n",
      "          -1.8180e-01, -1.1745e-01,  7.7650e-02,  1.0601e-04, -2.2696e-01,\n",
      "          -8.6355e-02,  4.9848e-02, -8.4847e-02, -1.8349e-01, -1.3614e-01,\n",
      "          -1.6249e-01,  9.6105e-02, -6.9487e-02, -1.5674e-01,  6.8764e-02,\n",
      "           7.7970e-02,  3.0589e-02,  5.5334e-02,  2.1448e-01, -1.9202e-01,\n",
      "           7.6969e-03,  3.3562e-02,  1.0971e-01, -2.4497e-01, -1.3615e-01,\n",
      "           1.1864e-01, -3.9232e-02, -3.6433e-02,  1.2837e-01,  6.7668e-02,\n",
      "          -1.1647e-01, -1.6086e-01,  2.2977e-01, -8.3043e-02,  5.6997e-02,\n",
      "           2.1926e-01, -1.5017e-01,  3.1807e-01, -1.0675e-01, -1.0223e-01,\n",
      "           1.3736e-01,  8.9685e-02, -7.1223e-02, -2.8370e-01, -1.9883e-02,\n",
      "          -2.7219e-01, -2.5810e-01, -3.0183e-03, -6.5891e-02, -1.4693e-01,\n",
      "          -2.1445e-01, -2.0168e-01,  2.6260e-01,  3.3959e-01,  1.3270e-01,\n",
      "          -1.7933e-01, -9.1637e-02,  1.1750e-01,  9.8410e-02, -1.3755e-01,\n",
      "          -2.0184e-01, -2.9075e-01, -1.0116e-01, -1.7251e-01, -1.3105e-01,\n",
      "           1.9236e-01,  1.1203e-01,  1.1629e-01, -1.9427e-01, -6.6539e-02,\n",
      "          -2.3333e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.5871, -1.5380, -0.7546,  1.1742, -0.8100, -0.6140,  0.0000,\n",
      "          -1.3126,  0.8379, -1.2589, -0.3344, -0.3279,  1.5496, -1.0905,\n",
      "          -1.3050, -1.7206, -0.1863, -2.1011, -1.3733, -0.3892, -1.3879,\n",
      "           1.1720,  0.5996,  1.4320,  1.9066, -1.1301, -0.2795, -0.5658,\n",
      "           1.8541,  0.5399, -0.2221,  0.1583,  0.8628,  1.5871,  0.1125,\n",
      "           0.4885,  0.0258, -0.8414, -1.0330, -1.7766, -0.9627, -0.3869,\n",
      "          -0.5588,  0.1231,  0.1159,  1.6972, -0.1828,  0.9721,  2.4062,\n",
      "           1.2868,  0.4630,  0.5023,  1.7768,  0.2836,  0.0000,  0.0000,\n",
      "           0.1345, -0.0550, -0.2590, -0.1065,  1.0237, -0.4097,  1.3337,\n",
      "          -0.6536,  0.2773, -0.3839,  0.9525, -1.6849, -1.1700, -0.7887,\n",
      "          -1.3197, -1.5125,  0.0232, -0.9737, -0.6341,  0.0000,  0.7243,\n",
      "           0.0000,  0.1146, -0.5423,  1.0743, -1.6211,  2.4653, -0.7318,\n",
      "          -0.5268,  0.3705,  0.4051,  0.1359, -0.3130, -0.2495,  1.2639,\n",
      "           1.4980,  0.8409,  1.5751,  0.9575,  0.3810,  1.4619, -1.0043,\n",
      "           0.3875,  2.5201, -0.4161, -0.4032,  1.5542, -1.8309, -0.1047,\n",
      "          -1.2293,  2.0140,  0.6361, -0.1233,  1.6547, -0.3787,  0.6146,\n",
      "          -1.2788,  2.0568, -1.7535,  0.7896,  0.2346,  0.5594, -0.0764,\n",
      "           0.9295,  0.8687,  2.4415, -0.6768,  1.7226,  0.5147, -0.1886,\n",
      "           0.6202, -1.1053,  1.2885,  0.4505,  0.7911,  0.6655,  1.3644,\n",
      "          -1.9301,  0.9718, -1.2126,  0.1494, -0.1500,  1.1243, -0.5445,\n",
      "           0.5540,  0.5128,  0.9022, -1.7464, -2.0189,  0.7695, -0.5768,\n",
      "           0.0000, -0.6989, -1.1146,  0.0000, -0.0555,  0.8168, -0.9828,\n",
      "          -2.2549, -0.6085,  0.1945,  1.3199,  1.4830, -1.1931,  1.6437,\n",
      "           1.4027, -0.1464, -0.0871, -0.4160,  1.8354, -0.8029,  0.9189,\n",
      "          -0.5721,  0.0329,  1.2194, -2.3008,  1.1170,  0.6357,  1.1491,\n",
      "          -0.3780, -1.5809,  0.1987,  0.7215,  1.4463,  0.0000,  0.0887,\n",
      "           0.0000, -1.1732,  0.5030,  1.3032, -0.2209, -0.2388,  0.1826,\n",
      "          -2.2103, -0.2569,  0.0000, -1.3158,  1.0577,  0.1565, -1.7942,\n",
      "          -1.4364, -0.8881,  0.5560,  0.3951,  0.1622,  0.0939,  0.6942,\n",
      "          -2.4305,  0.6163,  0.0000, -0.2191, -0.8151,  1.0583,  0.4205,\n",
      "          -0.2233, -1.4587,  0.0437, -0.1201,  0.7294,  1.5439,  1.4643,\n",
      "           0.3693, -0.9897,  0.0122,  0.0000,  0.7153, -0.6999, -0.4162,\n",
      "          -3.5973,  0.9404,  1.8602,  0.8237, -0.5736, -0.8764, -0.1284,\n",
      "           0.0671,  0.0377,  0.0000,  2.6763, -2.2634, -0.3978, -1.2050,\n",
      "          -0.4047, -1.1440,  1.1100, -0.0795,  0.4644,  0.0000,  1.4649,\n",
      "           1.4991,  1.5405, -1.9319, -0.9459, -0.9349, -0.3433,  0.8940,\n",
      "          -1.1450, -2.0696,  0.4555,  1.6398]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0598, 0.0701, 0.0933, 0.1579, 0.0773, 0.0630, 0.0959, 0.1165, 0.1315,\n",
      "         0.1346]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0050,  0.1501, -0.1418,  ...,  0.5532,  0.1694, -0.1555],\n",
      "        [ 0.0715,  0.0903, -0.2475,  ..., -0.0556, -0.0082,  0.2316],\n",
      "        [-0.0882, -0.0502,  0.3583,  ..., -0.2284, -0.1793,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0633, -0.0631, -0.1556, -0.0363, -0.0642,  0.1428, -0.1893,\n",
      "          -0.1554, -0.0230, -0.0744,  0.1341, -0.1066, -0.0528, -0.1719,\n",
      "           0.0436,  0.1122,  0.0205, -0.0042, -0.0395, -0.0662, -0.1561,\n",
      "          -0.0073, -0.0764,  0.0519,  0.0130,  0.1216, -0.0309, -0.0661,\n",
      "          -0.0860, -0.0495,  0.0226,  0.0627,  0.1622, -0.1159,  0.0811,\n",
      "          -0.1521, -0.0499, -0.0686, -0.1108, -0.1218,  0.0213,  0.0811,\n",
      "           0.0492, -0.2016, -0.0184,  0.0536,  0.1013, -0.1666,  0.0577,\n",
      "          -0.0120, -0.1952, -0.0798, -0.0972, -0.1516, -0.3173, -0.0339,\n",
      "          -0.0050, -0.0547,  0.0266,  0.2105, -0.1076, -0.0256, -0.0064,\n",
      "          -0.0597,  0.0842,  0.0243, -0.0289, -0.1163,  0.0916, -0.1010,\n",
      "           0.2265,  0.1656,  0.0547,  0.0265,  0.0248, -0.0223,  0.2392,\n",
      "           0.0802, -0.0045,  0.1463, -0.0959, -0.0149, -0.0779,  0.0609,\n",
      "          -0.0376,  0.0598, -0.0809,  0.1140,  0.0236, -0.0533,  0.1065,\n",
      "          -0.0747, -0.0706,  0.0191,  0.0484,  0.1432, -0.0020,  0.1246,\n",
      "           0.1278,  0.0432,  0.0450,  0.1080,  0.1981,  0.0501,  0.0645,\n",
      "          -0.2940, -0.0204,  0.0577,  0.0553, -0.0852,  0.0297,  0.1729,\n",
      "           0.0015, -0.0511,  0.0919,  0.1587, -0.1121, -0.0683, -0.1108,\n",
      "           0.0376,  0.0997,  0.2657, -0.0127,  0.0824, -0.0402, -0.1378,\n",
      "          -0.1730, -0.1174,  0.1628,  0.0386, -0.0930, -0.0348,  0.0505,\n",
      "           0.0907, -0.2758, -0.0197,  0.1402,  0.0301, -0.1998, -0.1105,\n",
      "          -0.1767,  0.2131, -0.1986,  0.0639,  0.0344,  0.0866, -0.0478,\n",
      "           0.2913, -0.0709,  0.1685, -0.2395, -0.0014, -0.0238,  0.1974,\n",
      "          -0.0278,  0.0178,  0.0969,  0.0692,  0.0937,  0.0326, -0.1773,\n",
      "          -0.0701, -0.1772,  0.0530, -0.0717, -0.0530, -0.0907,  0.0789,\n",
      "           0.1034,  0.0679, -0.0889,  0.1347,  0.1023,  0.0695,  0.0053,\n",
      "           0.1635,  0.0261, -0.0596,  0.1293, -0.0105,  0.0510, -0.0698,\n",
      "          -0.0042,  0.0148,  0.1058, -0.1125, -0.1049,  0.0474,  0.0764,\n",
      "          -0.1513, -0.1000, -0.0009, -0.0318, -0.1623, -0.0519, -0.1146,\n",
      "          -0.0262, -0.0651, -0.0812,  0.0631,  0.0211,  0.0369,  0.0719,\n",
      "           0.2611, -0.1309,  0.0791,  0.0042,  0.0570, -0.1336, -0.0583,\n",
      "           0.1665,  0.0279, -0.0480,  0.1148,  0.0487, -0.0868, -0.1359,\n",
      "           0.1284, -0.0653,  0.0764,  0.2312, -0.1194,  0.1944, -0.1355,\n",
      "          -0.0819,  0.0710,  0.0704, -0.0264, -0.1419, -0.0079, -0.2209,\n",
      "          -0.1544,  0.0676, -0.0804, -0.0660, -0.1826, -0.1667,  0.1898,\n",
      "           0.2635,  0.0771, -0.0762, -0.0953,  0.0369, -0.0117, -0.1041,\n",
      "          -0.1491, -0.2427, -0.0175, -0.0877,  0.0066,  0.1426,  0.0776,\n",
      "           0.0748, -0.0654, -0.0863, -0.1248]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0627e+00, -6.9610e-02, -1.8077e+00,  0.0000e+00,  5.1603e-01,\n",
      "           0.0000e+00,  1.1185e-03, -7.2298e-01,  2.1178e+00, -2.1369e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.1106e+00,  1.9978e-01,  3.1250e-01,\n",
      "           3.5174e-01, -6.8290e-01,  1.6915e-01,  0.0000e+00,  0.0000e+00,\n",
      "           1.8832e+00,  6.0190e-01, -3.6867e-02, -5.3526e-01, -1.0033e-01,\n",
      "           6.5096e-01, -1.6088e+00, -1.3623e+00, -2.1267e+00, -1.0344e+00,\n",
      "           3.8791e-02, -1.4546e+00, -2.0767e+00,  3.1558e-01, -2.8489e-01,\n",
      "          -2.0018e+00,  2.1891e-01,  9.9699e-01,  0.0000e+00,  9.5357e-01,\n",
      "          -2.2518e-01, -2.2113e+00, -7.0613e-01,  1.3960e+00,  0.0000e+00,\n",
      "          -1.1384e+00,  2.4249e-01,  7.4190e-01,  0.0000e+00, -1.3358e+00,\n",
      "           1.6085e+00, -1.3767e-01,  6.6263e-01,  1.1163e+00,  5.6727e-01,\n",
      "           0.0000e+00, -4.4969e-01, -8.8802e-01,  1.3382e-01,  6.2833e-01,\n",
      "          -7.0491e-01,  0.0000e+00, -6.9339e-01, -1.5473e+00,  2.8929e-01,\n",
      "           9.5764e-02,  0.0000e+00,  5.9489e-01, -2.1386e+00,  5.5969e-01,\n",
      "           1.8278e-01, -5.1245e-01, -3.4101e-01, -1.1319e+00, -6.4750e-01,\n",
      "           0.0000e+00, -1.0491e+00,  0.0000e+00,  5.1728e-01, -1.8654e-01,\n",
      "          -3.8501e-01,  0.0000e+00,  7.7731e-01, -8.4532e-01,  3.9783e-01,\n",
      "           4.1928e-01,  1.6046e+00, -5.6409e-01, -1.4131e+00, -1.4905e+00,\n",
      "           4.0428e-01, -3.5156e-01,  4.9394e-01, -2.3210e+00,  1.2380e+00,\n",
      "          -9.6294e-01,  0.0000e+00, -9.0741e-01,  2.3907e+00,  9.5519e-01,\n",
      "          -1.2006e+00,  5.9435e-01,  1.0665e+00, -1.7340e+00,  3.6511e-01,\n",
      "           4.0227e-01, -1.2705e+00,  4.5480e-01,  1.9688e+00,  1.4958e-01,\n",
      "          -8.3248e-01,  5.3398e-01,  0.0000e+00,  6.6420e-01, -1.0552e+00,\n",
      "           9.1771e-01, -7.0293e-01, -8.4510e-01,  2.5777e-01,  8.7975e-01,\n",
      "          -8.7691e-01, -1.3964e+00, -3.6483e-01, -1.8465e+00, -1.3005e+00,\n",
      "           1.0694e+00, -8.1157e-01,  6.4933e-01,  2.5571e-01, -1.4895e+00,\n",
      "           2.5021e+00,  3.7799e-01, -1.3455e+00,  7.2223e-01,  3.2011e+00,\n",
      "           0.0000e+00, -3.8358e-01,  1.2823e+00,  2.2520e+00,  1.9406e-01,\n",
      "          -3.9209e-02,  3.0300e+00,  3.6282e-01, -1.8712e-01, -1.1121e+00,\n",
      "           1.2470e+00,  7.7540e-01, -7.7475e-01, -4.4822e-02, -1.3870e+00,\n",
      "           0.0000e+00,  7.6499e-01, -2.8957e-01, -2.1305e+00, -5.8171e-01,\n",
      "           7.8584e-01, -1.8620e+00, -1.3048e+00,  1.9028e-01,  0.0000e+00,\n",
      "          -1.8689e+00,  1.1505e+00, -8.5975e-01,  9.5959e-01, -1.4613e+00,\n",
      "          -2.7199e-02,  1.9744e+00,  1.1269e+00, -4.8575e-01, -1.2416e+00,\n",
      "          -2.1237e-01, -1.3225e+00, -1.6392e+00, -7.7184e-01,  6.8267e-01,\n",
      "          -1.3796e+00, -1.2602e-01,  6.0651e-01, -7.4896e-01,  2.5912e-01,\n",
      "           0.0000e+00, -2.5534e+00,  2.7768e-01,  0.0000e+00,  1.6234e+00,\n",
      "           0.0000e+00, -1.8339e-03,  0.0000e+00,  9.0105e-01,  0.0000e+00,\n",
      "          -4.1998e-01,  3.8834e-01, -1.1584e-01,  8.0968e-01,  1.0503e+00,\n",
      "          -7.8913e-01,  0.0000e+00, -4.1552e-01, -7.5046e-01, -4.5404e-01,\n",
      "          -5.4752e-01,  7.2225e-01, -1.8532e+00,  1.3573e+00,  8.3757e-01,\n",
      "          -1.5238e+00, -3.5889e-01,  6.4780e-01,  2.0070e-01, -2.1782e+00,\n",
      "           8.3535e-01, -1.2911e+00, -1.2839e+00,  2.6105e-01,  0.0000e+00,\n",
      "           2.0758e+00,  1.3420e-01,  2.5770e+00, -3.0940e-02, -5.7963e-01,\n",
      "          -1.4282e+00,  1.9012e+00, -3.8072e-01,  1.4697e+00,  8.0515e-01,\n",
      "           3.6929e-01,  6.6972e-01, -7.0043e-01,  8.9296e-02,  1.0256e+00,\n",
      "           9.7814e-01, -1.4083e+00,  6.5962e-01, -1.1449e+00, -1.6455e+00,\n",
      "          -6.0009e-01,  8.9473e-03, -7.1105e-01,  3.7050e-01, -2.2397e-01,\n",
      "          -7.5234e-01,  5.7220e-01,  5.3066e-01, -6.6375e-01,  0.0000e+00,\n",
      "           5.7829e-01,  1.8920e+00, -8.6394e-01,  4.9359e-01, -3.8719e-01,\n",
      "           5.0010e-01, -9.7502e-01,  1.7728e+00, -1.0636e+00, -8.0782e-01,\n",
      "          -6.2198e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0761, 0.1071, 0.1612, 0.1415, 0.0799, 0.1494, 0.0780, 0.0513, 0.0539,\n",
      "         0.1015]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0050,  0.1501, -0.1418,  ...,  0.5532,  0.1694, -0.1555],\n",
      "        [ 0.0715,  0.0903, -0.2475,  ..., -0.0556, -0.0082,  0.2316],\n",
      "        [-0.0882, -0.0502,  0.3583,  ..., -0.2284, -0.1793,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0733, -0.0714, -0.1553, -0.0848, -0.0408,  0.2138, -0.2869,\n",
      "          -0.1863, -0.0505, -0.1049,  0.1700, -0.1111, -0.0813, -0.2052,\n",
      "           0.0698,  0.1375,  0.0039, -0.0137, -0.0748, -0.1221, -0.1847,\n",
      "          -0.0245, -0.0938,  0.0413,  0.0324,  0.1842, -0.0017, -0.0544,\n",
      "          -0.0989, -0.0500,  0.0326,  0.0935,  0.2289, -0.1654,  0.0680,\n",
      "          -0.1808, -0.0735, -0.1037, -0.1428, -0.1371,  0.0273,  0.1314,\n",
      "           0.0479, -0.2659, -0.0640,  0.0958,  0.1219, -0.2032,  0.0680,\n",
      "          -0.0021, -0.2061, -0.1211, -0.1061, -0.1860, -0.3925, -0.0610,\n",
      "           0.0012, -0.0734,  0.0624,  0.2425, -0.1212, -0.0277, -0.0127,\n",
      "          -0.0695,  0.0949,  0.0164, -0.0332, -0.1164,  0.0896, -0.0894,\n",
      "           0.3016,  0.2281,  0.0839,  0.0380,  0.0377,  0.0102,  0.2996,\n",
      "           0.0683,  0.0013,  0.2027, -0.0974,  0.0379, -0.1309,  0.1032,\n",
      "          -0.0572,  0.0741, -0.0748,  0.1816,  0.0276, -0.0288,  0.1231,\n",
      "          -0.1210, -0.1099,  0.0127,  0.0639,  0.1865,  0.0105,  0.1419,\n",
      "           0.1572,  0.0499,  0.0867,  0.1599,  0.2182,  0.0483,  0.1288,\n",
      "          -0.3707, -0.0246,  0.1039,  0.0690, -0.0928,  0.0266,  0.2380,\n",
      "          -0.0339, -0.0684,  0.1290,  0.2146, -0.1150, -0.0922, -0.1804,\n",
      "           0.0424,  0.0899,  0.3528, -0.0183,  0.1109, -0.0714, -0.1689,\n",
      "          -0.2083, -0.1179,  0.1796,  0.0584, -0.1370, -0.0093,  0.0331,\n",
      "           0.1237, -0.3465, -0.1073,  0.1482,  0.0591, -0.2478, -0.1426,\n",
      "          -0.2711,  0.2673, -0.2440,  0.0349,  0.0269,  0.1202, -0.0530,\n",
      "           0.3571, -0.0585,  0.2017, -0.3037, -0.0119, -0.0248,  0.2400,\n",
      "          -0.0341,  0.0078,  0.1074,  0.0814,  0.0749,  0.0523, -0.2129,\n",
      "          -0.0643, -0.2178,  0.1027, -0.1087, -0.0775, -0.1036,  0.1081,\n",
      "           0.1100,  0.0497, -0.1103,  0.1555,  0.1161,  0.1566,  0.0088,\n",
      "           0.1880,  0.0394, -0.0582,  0.1529, -0.0079,  0.0445, -0.1225,\n",
      "          -0.0016, -0.0170,  0.1383, -0.1312, -0.0881,  0.0425,  0.0691,\n",
      "          -0.1903, -0.0998,  0.0010, -0.0352, -0.1927, -0.1097, -0.1717,\n",
      "          -0.0301, -0.0673, -0.0979,  0.0678,  0.0188,  0.0732,  0.1025,\n",
      "           0.3102, -0.1920,  0.0929, -0.0109,  0.0443, -0.1651, -0.0920,\n",
      "           0.1564,  0.0425, -0.0693,  0.1339,  0.0717, -0.1102, -0.1431,\n",
      "           0.1564, -0.0961,  0.0900,  0.2814, -0.1189,  0.2429, -0.1746,\n",
      "          -0.1008,  0.0811,  0.0636, -0.0200, -0.1929, -0.0262, -0.2590,\n",
      "          -0.1897,  0.0588, -0.0892, -0.0923, -0.2264, -0.2435,  0.2509,\n",
      "           0.3426,  0.0952, -0.0955, -0.1451,  0.0744,  0.0246, -0.1555,\n",
      "          -0.2114, -0.3326, -0.0242, -0.1336, -0.0440,  0.1520,  0.1059,\n",
      "           0.1209, -0.1146, -0.0807, -0.1441]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5703,  0.0000,  0.2274, -0.0786,  0.3524,  0.5534, -0.2005,\n",
      "           2.0887,  1.3115, -1.0355,  0.6845,  2.1685,  1.1880, -0.8052,\n",
      "          -0.1087, -1.1277,  0.0000, -0.2911,  0.0083,  0.4265, -1.9756,\n",
      "          -1.8381, -1.2584,  0.1943, -0.1670,  1.3751, -0.2981,  0.0000,\n",
      "           1.8409,  0.7833,  0.3491,  0.3116,  0.0000,  0.9417,  0.6976,\n",
      "           0.0000, -2.8991,  0.0680,  0.0399,  1.2312, -0.7222, -1.0137,\n",
      "           0.2485,  1.0037,  0.0670,  0.3115, -1.0371, -1.1820, -0.4445,\n",
      "          -1.6405,  0.0000,  3.1694,  0.8633,  0.7639,  2.2062,  0.0000,\n",
      "           0.5927,  0.5677, -0.7551,  0.0000,  0.6264, -0.7198,  0.0000,\n",
      "           0.8945, -1.3379,  2.3299, -2.4165,  0.0922,  1.1603, -0.7180,\n",
      "           0.0000,  0.5510,  0.1900,  0.0234,  0.4083, -0.9004, -0.4859,\n",
      "           0.4328,  0.0000, -2.4957, -3.6231,  0.4018,  0.4971, -0.3813,\n",
      "          -2.3204, -1.0348, -0.6328,  0.0000, -1.9081, -0.6541, -0.4365,\n",
      "          -0.6695, -1.9173,  1.0180, -1.3663, -1.1211,  0.2168,  0.0181,\n",
      "           0.3039,  0.7635,  0.9417,  0.0000,  0.2242, -1.6317,  2.2437,\n",
      "          -0.1441,  0.1246, -1.0133, -1.2048, -1.4857, -1.5565, -1.3434,\n",
      "           0.1515, -1.7880,  0.0000, -1.0662, -1.7871, -0.1215, -1.8687,\n",
      "           0.0940,  0.6721,  0.5521,  1.5533,  0.4842,  0.1292,  0.5825,\n",
      "           0.7952,  0.0585,  0.3930, -0.0597, -0.0865, -0.5367,  0.7034,\n",
      "           1.1583,  0.3292, -0.2508,  0.1189, -1.3303, -0.3660,  0.0000,\n",
      "          -0.5971, -1.4722, -1.1960,  0.0295,  0.5016,  0.2593,  1.2102,\n",
      "           1.2552,  0.6334,  0.3161,  0.0788, -0.0554, -0.7096,  1.5831,\n",
      "           1.2669,  0.2798,  1.1350,  0.3053,  0.2608,  1.4424, -0.1750,\n",
      "           0.6840, -0.2123, -0.7213, -0.4679, -0.9413,  0.3296,  0.2564,\n",
      "           1.7294,  0.7026,  3.1422,  0.0000,  0.5633,  0.1030, -0.3934,\n",
      "          -0.9660, -0.4049,  1.1921, -0.2651, -1.5079, -0.1346, -0.0130,\n",
      "          -0.6023, -1.5680, -1.8518, -0.1686,  0.0070,  0.0000,  1.2949,\n",
      "           0.7388,  0.9677,  0.1602, -0.5359,  0.5354, -0.0471, -1.2977,\n",
      "          -1.5640,  3.1397, -1.0837, -0.0461,  0.8100, -2.1875, -2.6964,\n",
      "           0.0000, -0.9969,  0.9722, -1.6692, -0.6120, -0.9323, -1.1370,\n",
      "           0.8721,  0.0795, -1.3191, -0.7912,  1.3114, -0.2829,  1.3732,\n",
      "           0.2451, -2.3516,  1.9031,  1.0279,  0.0000,  1.7823,  1.0653,\n",
      "          -0.5726, -0.5735, -1.5895,  0.0000,  0.0000,  0.0000, -0.6434,\n",
      "           1.5656,  0.0933, -0.6272,  1.6772,  2.2888, -2.1840,  0.3258,\n",
      "           0.0000, -0.5350, -1.8332, -1.1664, -0.1110,  1.4426, -0.4778,\n",
      "           1.4837, -0.5851,  0.7759, -1.4378, -0.2593,  0.4355,  0.3198,\n",
      "          -0.3369,  1.6170,  0.2598, -0.0705]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0661, 0.1504, 0.0515, 0.0980, 0.1740, 0.0977, 0.1300, 0.0720, 0.0635,\n",
      "         0.0969]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0050,  0.1501, -0.1418,  ...,  0.5532,  0.1694, -0.1555],\n",
      "        [ 0.0715,  0.0903, -0.2475,  ..., -0.0556, -0.0082,  0.2316],\n",
      "        [-0.0882, -0.0502,  0.3583,  ..., -0.2284, -0.1793,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0543e-01, -6.3977e-02, -2.2313e-01, -7.4998e-02, -1.3555e-01,\n",
      "           1.6993e-01, -2.3293e-01, -1.8974e-01, -1.9394e-03, -6.6777e-02,\n",
      "           1.7304e-01, -9.4306e-02,  8.6510e-03, -1.7031e-01,  4.8887e-02,\n",
      "           4.5782e-02,  3.9442e-02,  3.6159e-02, -8.0361e-02, -7.4138e-02,\n",
      "          -1.7471e-01, -5.2217e-02, -5.8917e-02,  8.2884e-02,  9.9289e-03,\n",
      "           1.5005e-01,  6.6592e-03, -9.4142e-02, -1.2545e-01,  3.0360e-03,\n",
      "           2.7885e-02,  7.3474e-03,  2.0147e-01, -1.4690e-01,  1.2908e-01,\n",
      "          -1.8706e-01, -6.6327e-02, -1.1175e-01, -1.7223e-01, -1.0300e-01,\n",
      "           5.4144e-02,  5.2931e-02,  6.6026e-02, -2.3849e-01, -6.0702e-02,\n",
      "           1.0846e-01,  6.3014e-02, -2.2182e-01,  1.2012e-01, -1.4582e-02,\n",
      "          -1.6107e-01, -9.7629e-02, -1.4017e-01, -1.6162e-01, -3.7224e-01,\n",
      "          -2.9958e-02, -4.8831e-03,  3.3185e-02,  2.9118e-02,  2.0411e-01,\n",
      "          -1.0873e-01, -5.1054e-02, -3.8027e-03, -1.0231e-01,  1.2962e-01,\n",
      "           2.8441e-02, -3.6353e-02, -1.2627e-01,  1.1009e-01, -1.2488e-01,\n",
      "           2.7739e-01,  2.1549e-01,  5.6928e-02,  9.1734e-02, -1.4606e-02,\n",
      "          -5.1177e-03,  2.7920e-01,  1.1153e-01,  1.1249e-02,  1.8818e-01,\n",
      "          -1.0892e-01, -1.2384e-02, -9.5312e-02,  5.5366e-02, -7.5344e-02,\n",
      "           6.7012e-02, -1.1782e-01,  1.8387e-01, -2.5786e-02, -6.7617e-02,\n",
      "           1.2310e-01, -1.3617e-01, -9.6517e-02,  1.2700e-02,  7.4962e-02,\n",
      "           2.2302e-01, -7.7616e-03,  1.6227e-01,  2.1135e-01,  5.7420e-02,\n",
      "          -1.8466e-02,  1.5846e-01,  2.5746e-01,  7.4078e-02,  1.0842e-01,\n",
      "          -3.7934e-01, -3.7737e-02,  1.1519e-01,  7.3545e-02, -2.6228e-02,\n",
      "           7.2218e-03,  1.9799e-01, -1.8670e-02, -6.9482e-02,  8.1770e-02,\n",
      "           1.6546e-01, -1.1928e-01, -9.3364e-02, -1.0320e-01,  1.0666e-01,\n",
      "           1.0186e-01,  2.9740e-01, -4.0799e-02,  1.0195e-01, -5.4022e-02,\n",
      "          -1.2756e-01, -2.4043e-01, -4.8335e-02,  1.1944e-01,  5.8624e-02,\n",
      "          -1.2308e-01,  1.1027e-02,  7.2818e-02,  7.3579e-02, -3.5320e-01,\n",
      "          -6.4376e-02,  1.6729e-01,  8.3433e-02, -2.6054e-01, -1.7103e-01,\n",
      "          -2.9759e-01,  2.5718e-01, -2.6031e-01,  1.4994e-02,  2.2843e-02,\n",
      "           1.1435e-01, -3.2949e-02,  3.4083e-01, -6.5401e-02,  2.3061e-01,\n",
      "          -2.7549e-01,  1.9209e-05, -6.4883e-02,  2.0659e-01, -3.3544e-02,\n",
      "           2.3554e-02,  6.8648e-02,  1.3702e-01,  1.1613e-01,  7.8267e-02,\n",
      "          -2.0090e-01, -9.3878e-02, -1.8971e-01,  1.3243e-01, -1.3479e-01,\n",
      "          -1.5506e-02, -1.4384e-01,  7.9467e-02,  1.6811e-01,  1.0383e-01,\n",
      "          -1.1689e-01,  2.0278e-01,  1.3394e-01,  6.7980e-02, -7.1418e-02,\n",
      "           1.9231e-01,  6.6681e-02, -5.4726e-02,  8.3862e-02,  1.7364e-03,\n",
      "           2.4183e-02, -9.7511e-02, -3.7688e-02, -3.0132e-02,  1.2575e-01,\n",
      "          -1.5264e-01, -1.3457e-01,  6.0648e-02,  4.4370e-02, -2.1081e-01,\n",
      "          -1.1071e-01,  4.8492e-02, -6.6711e-02, -1.9007e-01, -7.4719e-02,\n",
      "          -1.5698e-01, -1.5816e-02, -1.3333e-01, -1.5869e-01,  1.3057e-01,\n",
      "           2.7937e-02,  5.3348e-02,  8.9169e-02,  2.6041e-01, -1.5778e-01,\n",
      "           8.6855e-02,  1.9526e-02,  6.8076e-02, -1.9631e-01, -5.8436e-02,\n",
      "           1.8784e-01, -1.0755e-02, -4.4031e-02,  1.5830e-01,  6.6544e-02,\n",
      "          -8.5798e-02, -1.4567e-01,  1.9782e-01, -4.1949e-02,  8.9584e-02,\n",
      "           2.3494e-01, -1.5103e-01,  2.8804e-01, -1.6496e-01, -8.3062e-02,\n",
      "           1.3098e-01,  1.3950e-01, -1.2812e-02, -2.3263e-01,  2.0906e-02,\n",
      "          -3.0949e-01, -2.3095e-01,  7.5341e-02, -9.9459e-02, -1.8112e-01,\n",
      "          -2.6388e-01, -2.1604e-01,  2.0613e-01,  3.0518e-01,  1.0717e-01,\n",
      "          -8.4340e-02, -7.2242e-02,  6.1436e-02,  3.8350e-02, -1.6974e-01,\n",
      "          -1.6855e-01, -2.9266e-01, -2.7669e-02, -1.1486e-01, -1.1864e-02,\n",
      "           1.8429e-01,  8.6391e-02,  8.2518e-02, -1.1110e-01, -1.0704e-01,\n",
      "          -1.7869e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.6791,  0.6008, -1.4888, -2.3994,  0.0000, -0.2820, -0.1544,\n",
      "          -0.0335,  2.1682, -1.4040,  0.7960,  0.5872,  0.7796, -0.0695,\n",
      "           0.0000,  0.1645, -2.0881,  1.2030,  0.6574,  0.3483, -1.4366,\n",
      "          -0.0429, -0.1850, -2.1976,  1.2029,  1.0365, -1.0878,  1.0171,\n",
      "          -0.8042,  0.1029, -2.7764,  0.0000, -0.4699,  1.6597, -1.2854,\n",
      "           0.9726, -0.1979, -1.1470,  0.1289,  0.5213,  0.9624, -1.0440,\n",
      "          -1.4330,  1.5452, -0.9132,  0.5576, -1.7532,  0.2054, -0.0636,\n",
      "          -1.7630,  0.0000,  0.0000, -0.4615,  0.8233, -0.3246, -0.3481,\n",
      "           0.5614, -0.8456, -0.3821,  0.9590,  0.0000,  1.1842,  1.9338,\n",
      "           0.7079, -1.0647, -0.2145, -0.5136, -0.4973,  0.6225, -0.9559,\n",
      "          -0.8591,  0.5740,  0.2696, -0.3650,  0.6739,  0.5656, -0.5898,\n",
      "          -0.7044, -0.9092,  0.1155, -1.2111, -1.4144, -0.0958,  1.1640,\n",
      "           3.1505,  0.9464,  0.1656, -1.1654, -1.0573,  2.6387, -0.4463,\n",
      "          -0.4291,  1.6804,  0.4025,  0.0000, -0.3961, -1.2698, -0.8583,\n",
      "          -0.5934,  0.1058, -0.2008,  0.0000,  2.1609, -0.7389, -0.7324,\n",
      "           0.8612,  0.4405,  0.1819,  0.0000,  0.0038, -0.3878, -1.5371,\n",
      "           0.9315,  1.3296, -0.7392, -0.4356,  0.5595, -0.9296,  0.3537,\n",
      "           0.6223,  0.0000,  0.7773, -0.5203,  1.7274, -1.0648,  0.0000,\n",
      "           0.4473,  1.3889,  0.2142, -1.5353, -0.1385, -0.5343, -0.2607,\n",
      "          -0.1621,  0.1429, -1.1179,  0.0000, -1.0188,  0.1985,  0.1809,\n",
      "          -0.4803, -0.8989,  0.6902, -0.3771,  0.9784,  0.8744,  0.0044,\n",
      "           0.1183, -0.6429, -0.7328,  1.2564,  0.0000, -0.7949, -0.7745,\n",
      "          -2.0748,  0.0651, -0.9203, -1.0096, -0.4234,  0.2670,  0.0000,\n",
      "           0.8459,  1.5853,  0.0000,  1.1611, -1.5134,  0.9553,  0.9856,\n",
      "           1.0503, -1.8313,  1.3393,  0.2784, -0.3207, -1.3026, -2.5122,\n",
      "          -1.0706, -0.9332,  0.5865, -1.5919,  0.7592,  0.5162,  0.9406,\n",
      "           0.7186, -0.2315, -2.2357, -0.8731, -0.4108,  0.0000,  0.1699,\n",
      "           1.4384, -1.0679, -1.1248, -1.5113, -0.6743, -1.7401, -1.5882,\n",
      "           0.1390,  0.9622,  1.9202,  1.2945,  1.5503,  0.3646, -0.2873,\n",
      "           0.0000, -0.6317,  0.5942, -0.1733,  1.3346,  0.7461, -0.5767,\n",
      "          -0.5881,  0.0000, -0.9805,  1.1632,  0.0000,  1.7962,  0.4091,\n",
      "          -1.0742, -0.7959,  0.0000, -0.3801,  0.0000, -1.9171, -0.4472,\n",
      "           0.5684,  1.0698,  1.7752,  0.2244,  0.4532, -0.0166, -1.8700,\n",
      "           0.0215, -0.4855, -1.3860, -1.2723, -0.5753,  0.0000, -0.0121,\n",
      "           0.3713, -0.9911,  0.2961,  0.0000,  0.0000,  1.0525, -2.4135,\n",
      "          -0.8852, -0.4682, -1.7345, -0.4616, -1.2174,  1.7262,  0.0000,\n",
      "           0.0000, -0.5532,  0.0000, -0.8538]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0362, 0.0409, 0.4219, 0.0676, 0.0772, 0.1007, 0.0874, 0.0372, 0.0836,\n",
      "         0.0473]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0050,  0.1501, -0.1418,  ...,  0.5532,  0.1694, -0.1555],\n",
      "        [ 0.0715,  0.0903, -0.2475,  ..., -0.0556, -0.0082,  0.2316],\n",
      "        [-0.0882, -0.0502,  0.3583,  ..., -0.2284, -0.1793,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0369, -0.0546, -0.0012, -0.0979,  0.1156,  0.2738, -0.3698,\n",
      "          -0.2080, -0.1437, -0.1366,  0.1919, -0.1114, -0.1075, -0.3137,\n",
      "           0.1089,  0.2470,  0.0142, -0.1552, -0.0278, -0.2309, -0.2193,\n",
      "           0.0138, -0.1830, -0.0247,  0.0256,  0.1706, -0.0968,  0.0666,\n",
      "          -0.1076, -0.1936, -0.0331,  0.1561,  0.2639, -0.1596, -0.0372,\n",
      "          -0.1482, -0.0757, -0.1604, -0.1495, -0.2060, -0.0284,  0.1555,\n",
      "          -0.0235, -0.2715, -0.0355,  0.0484,  0.1815, -0.1887,  0.0142,\n",
      "           0.0436, -0.2447, -0.2089, -0.0986, -0.1651, -0.4095, -0.1295,\n",
      "           0.0371, -0.1735,  0.1403,  0.3074, -0.1010,  0.0573, -0.0383,\n",
      "          -0.1060,  0.0465, -0.0515,  0.0225, -0.1074,  0.1014, -0.0432,\n",
      "           0.3162,  0.2124,  0.0732,  0.0452,  0.0791,  0.0426,  0.3394,\n",
      "           0.0450, -0.0025,  0.1737, -0.1340,  0.0462, -0.1733,  0.1395,\n",
      "          -0.0594,  0.1527, -0.0556,  0.2045,  0.0773,  0.0047,  0.0683,\n",
      "          -0.0871, -0.0536,  0.0889, -0.0271,  0.0943,  0.0759,  0.1333,\n",
      "          -0.0418,  0.0680,  0.2130,  0.0192,  0.1392,  0.0321,  0.1034,\n",
      "          -0.3372, -0.0258,  0.0284,  0.0978, -0.1830,  0.1031,  0.3000,\n",
      "          -0.0410, -0.0897,  0.2309,  0.2729, -0.1260, -0.0831, -0.3018,\n",
      "          -0.0571,  0.0686,  0.3833,  0.0764,  0.0735, -0.0753, -0.1977,\n",
      "          -0.1765, -0.1778,  0.2434,  0.0914, -0.1960, -0.0518,  0.0322,\n",
      "           0.1538, -0.3663, -0.1751,  0.1111,  0.0162, -0.2964, -0.1391,\n",
      "          -0.3145,  0.2339, -0.1425,  0.0486,  0.0278,  0.1931, -0.1282,\n",
      "           0.3529, -0.0884,  0.1426, -0.3069, -0.1205,  0.0503,  0.2958,\n",
      "          -0.0623, -0.0571,  0.1667,  0.0082,  0.0715,  0.0173, -0.2046,\n",
      "          -0.0113, -0.2767,  0.0476, -0.0255, -0.1329, -0.0091,  0.1329,\n",
      "           0.1539,  0.0530, -0.0433,  0.0503,  0.0777,  0.3215,  0.0710,\n",
      "           0.2209, -0.0150, -0.0293,  0.2399,  0.0579,  0.1379, -0.2865,\n",
      "           0.0697,  0.0200,  0.1690, -0.0736, -0.0853,  0.0756,  0.2023,\n",
      "          -0.1647, -0.0797, -0.0268, -0.0181, -0.2153, -0.1289, -0.2272,\n",
      "          -0.0807,  0.0355, -0.0082,  0.0043,  0.0315,  0.1570,  0.1730,\n",
      "           0.4036, -0.2195,  0.1277, -0.0873, -0.0172, -0.1757, -0.0907,\n",
      "           0.2357,  0.0588, -0.0715,  0.0537,  0.0934, -0.0847, -0.2699,\n",
      "           0.1072, -0.2053,  0.1728,  0.3508, -0.1047,  0.1960, -0.2173,\n",
      "          -0.0861, -0.0040, -0.0186,  0.0424, -0.1326, -0.1361, -0.2402,\n",
      "          -0.0787,  0.0746, -0.0962, -0.0428, -0.1235, -0.3188,  0.4075,\n",
      "           0.3505,  0.0164, -0.1506, -0.2681,  0.0701,  0.0137, -0.1722,\n",
      "          -0.2547, -0.4389, -0.0551, -0.1487, -0.0294,  0.0454,  0.1179,\n",
      "           0.1619, -0.1742, -0.1202, -0.0824]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7274e-01, -4.3062e-01,  3.1495e-01, -1.0846e+00, -1.1724e+00,\n",
      "           7.4174e-01,  0.0000e+00,  1.3513e+00,  1.9039e-01,  6.1734e-01,\n",
      "           1.9028e+00,  6.0245e-01,  2.2865e-01, -9.1607e-01, -3.1820e+00,\n",
      "          -6.8414e-02, -1.6331e+00, -9.4354e-01,  1.3607e+00, -1.4348e+00,\n",
      "          -1.4068e-01, -5.2358e-01, -1.1195e+00, -2.5949e+00, -7.5672e-02,\n",
      "           0.0000e+00, -6.1944e-01,  1.9970e+00,  1.2764e-01,  5.5405e-01,\n",
      "           9.1494e-01, -3.5952e-03,  2.2285e-01,  2.0155e+00, -6.3761e-02,\n",
      "          -1.4084e+00, -1.1188e-01, -8.1765e-01,  3.1469e-01,  8.5507e-02,\n",
      "           8.6218e-01, -8.9970e-01,  1.0090e+00, -1.5632e+00,  1.9440e+00,\n",
      "          -3.0007e-01,  0.0000e+00, -6.0149e-01, -1.0206e+00,  1.1164e+00,\n",
      "          -1.3223e+00,  2.6767e+00,  6.6668e-01, -8.4663e-01,  2.2755e-01,\n",
      "          -3.0912e-01, -1.4341e+00, -9.6640e-02,  1.2750e+00,  2.1809e+00,\n",
      "          -1.0063e+00,  3.6094e-02, -2.8013e-01,  2.6585e-01, -6.2833e-02,\n",
      "           3.9400e-01,  5.7803e-01,  0.0000e+00,  1.5806e+00, -1.4151e+00,\n",
      "           4.2753e-01,  2.9645e-01, -3.1296e-02, -7.9773e-01, -2.1443e-01,\n",
      "           1.3925e-01,  5.2566e-01,  1.3985e+00,  1.0270e+00, -7.9308e-01,\n",
      "           7.5765e-01, -1.0056e+00,  7.5733e-01,  1.0587e+00, -1.2144e+00,\n",
      "          -1.1306e-01, -1.1074e+00,  5.4875e-01,  0.0000e+00, -1.9014e+00,\n",
      "           5.2903e-01,  9.8671e-01,  0.0000e+00,  9.4346e-01,  6.0810e-01,\n",
      "          -1.5918e-02,  3.5315e-01, -1.1755e+00,  1.3713e+00,  0.0000e+00,\n",
      "           2.4377e-01,  4.5501e-02, -4.6639e-01, -9.8935e-01,  1.6398e+00,\n",
      "          -1.0229e+00,  3.0287e+00,  6.1975e-01, -1.0209e-01, -1.2353e+00,\n",
      "           1.8986e-01, -5.0290e-01, -5.7034e-01,  7.1228e-01, -7.8031e-01,\n",
      "           6.3215e-01,  4.0408e-01,  0.0000e+00, -2.3271e+00,  0.0000e+00,\n",
      "          -8.1369e-01, -1.4107e+00, -1.8372e+00,  6.0328e-01, -9.5637e-01,\n",
      "          -2.0021e-01,  3.9204e-02,  2.1498e+00,  1.3961e+00, -2.0875e+00,\n",
      "          -9.2638e-01,  4.4963e-01, -1.1673e+00,  4.2507e-01, -4.6882e-01,\n",
      "          -7.4480e-01,  0.0000e+00, -9.7470e-01, -1.9588e-02,  0.0000e+00,\n",
      "           6.9858e-01, -1.1216e+00,  1.6916e+00, -1.4018e-01, -6.6940e-01,\n",
      "           3.3951e-02,  7.5936e-01,  4.2307e-01, -1.0331e+00, -9.5664e-02,\n",
      "           1.5600e+00,  0.0000e+00, -3.3878e-01,  6.5764e-01,  1.8407e+00,\n",
      "          -2.5251e-01, -2.1748e-01,  6.2343e-01, -2.3622e+00,  1.0555e+00,\n",
      "           3.0243e-01, -7.7483e-02,  1.5443e-01, -1.2116e+00, -2.1910e-02,\n",
      "           1.6819e+00,  1.8517e+00,  2.7066e-01,  0.0000e+00, -7.1331e-01,\n",
      "          -1.2243e+00, -1.0939e+00, -2.5902e+00,  5.0560e-01, -3.0584e+00,\n",
      "          -2.8711e-01,  4.9824e-01,  8.2943e-01,  3.1699e-01, -7.9280e-01,\n",
      "           2.7134e-01,  2.3395e+00,  1.0572e+00,  8.3823e-01, -4.0307e-01,\n",
      "           7.2716e-01,  5.9911e-01,  3.5940e-01,  8.4235e-01, -1.8299e+00,\n",
      "           1.3634e+00,  2.1589e+00,  3.3678e-01, -1.0152e+00, -1.1716e+00,\n",
      "          -2.2149e+00,  1.6660e+00,  2.1524e+00,  3.6336e-01,  2.3835e+00,\n",
      "           3.2292e-02, -5.0153e-01, -1.2760e+00, -5.4239e-01, -4.0732e-01,\n",
      "          -1.4467e+00,  9.5372e-01, -8.5169e-01,  8.3062e-01, -1.5597e+00,\n",
      "           6.3623e-01,  6.7612e-01,  2.3973e+00,  5.5068e-02,  1.8938e+00,\n",
      "           1.3079e+00,  5.8080e-01, -2.3169e+00,  1.5502e+00,  0.0000e+00,\n",
      "          -2.2714e-01,  1.7331e+00,  2.7706e-01, -1.5519e+00,  9.2280e-01,\n",
      "          -1.2244e+00, -8.4808e-01,  0.0000e+00, -3.4225e-04,  3.7339e-01,\n",
      "          -1.5733e+00, -1.2349e-01,  9.6627e-01, -1.7360e+00,  1.6940e+00,\n",
      "          -1.4404e+00,  6.3407e-01, -1.7218e+00,  9.8037e-01, -1.7155e+00,\n",
      "           1.5603e+00, -2.7198e-01,  0.0000e+00,  1.2384e+00, -1.2285e+00,\n",
      "           1.8842e+00, -5.0835e-01,  5.4285e-01, -2.6132e-01,  0.0000e+00,\n",
      "           1.3332e+00,  3.1036e-01, -5.1470e-02, -2.2879e-01, -1.6116e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0536, 0.1208, 0.1658, 0.0881, 0.1500, 0.1169, 0.0969, 0.0484, 0.0864,\n",
      "         0.0732]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0050,  0.1501, -0.1418,  ...,  0.5532,  0.1694, -0.1555],\n",
      "        [ 0.0715,  0.0903, -0.2475,  ..., -0.0556, -0.0082,  0.2316],\n",
      "        [-0.0882, -0.0502,  0.3583,  ..., -0.2284, -0.1793,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0810, -0.0736, -0.1484, -0.0895, -0.0545,  0.2102, -0.2885,\n",
      "          -0.1923, -0.0518, -0.0926,  0.1754, -0.0902, -0.0223, -0.2123,\n",
      "           0.0628,  0.1096,  0.0268, -0.0177, -0.0614, -0.1265, -0.1894,\n",
      "          -0.0299, -0.0973,  0.0425,  0.0211,  0.1717, -0.0143, -0.0419,\n",
      "          -0.1212, -0.0521,  0.0102,  0.0599,  0.2307, -0.1537,  0.0771,\n",
      "          -0.1867, -0.0661, -0.1258, -0.1600, -0.1290,  0.0322,  0.0918,\n",
      "           0.0491, -0.2576, -0.0684,  0.0914,  0.1038, -0.2049,  0.0925,\n",
      "           0.0006, -0.1817, -0.1332, -0.1265, -0.1646, -0.3888, -0.0604,\n",
      "           0.0102, -0.0320,  0.0604,  0.2284, -0.1030, -0.0235, -0.0093,\n",
      "          -0.1040,  0.1036,  0.0022, -0.0199, -0.1257,  0.1088, -0.1041,\n",
      "           0.3012,  0.2149,  0.0641,  0.0760,  0.0229,  0.0165,  0.3014,\n",
      "           0.0905,  0.0125,  0.1835, -0.1138,  0.0249, -0.1119,  0.0867,\n",
      "          -0.0702,  0.0898, -0.0956,  0.1955,  0.0021, -0.0401,  0.1050,\n",
      "          -0.1236, -0.0864,  0.0330,  0.0462,  0.1908,  0.0123,  0.1447,\n",
      "           0.1506,  0.0527,  0.0606,  0.1241,  0.2205,  0.0558,  0.1244,\n",
      "          -0.3723, -0.0420,  0.0895,  0.0823, -0.0762,  0.0299,  0.2425,\n",
      "          -0.0308, -0.0650,  0.1361,  0.2050, -0.1224, -0.0874, -0.1632,\n",
      "           0.0659,  0.0892,  0.3369,  0.0006,  0.0950, -0.0614, -0.1511,\n",
      "          -0.2285, -0.0868,  0.1510,  0.0725, -0.1540,  0.0083,  0.0561,\n",
      "           0.0980, -0.3594, -0.1101,  0.1380,  0.0708, -0.2672, -0.1617,\n",
      "          -0.3125,  0.2488, -0.2325,  0.0132,  0.0173,  0.1449, -0.0620,\n",
      "           0.3470, -0.0721,  0.2040, -0.2850, -0.0335, -0.0352,  0.2329,\n",
      "          -0.0405, -0.0035,  0.1026,  0.1008,  0.0960,  0.0736, -0.2032,\n",
      "          -0.0635, -0.2169,  0.1013, -0.1142, -0.0537, -0.1098,  0.1023,\n",
      "           0.1544,  0.0731, -0.0948,  0.1602,  0.1119,  0.1573, -0.0256,\n",
      "           0.2054,  0.0463, -0.0534,  0.1221,  0.0193,  0.0617, -0.1575,\n",
      "          -0.0028, -0.0186,  0.1427, -0.1393, -0.1066,  0.0578,  0.0798,\n",
      "          -0.1981, -0.1005,  0.0242, -0.0420, -0.1980, -0.1041, -0.1768,\n",
      "          -0.0263, -0.0841, -0.1146,  0.0847,  0.0358,  0.0794,  0.1192,\n",
      "           0.2957, -0.1867,  0.0988, -0.0111,  0.0333, -0.1940, -0.0726,\n",
      "           0.1980,  0.0178, -0.0551,  0.1269,  0.0785, -0.1001, -0.1769,\n",
      "           0.1714, -0.0899,  0.1083,  0.2659, -0.1339,  0.2624, -0.1744,\n",
      "          -0.0942,  0.0896,  0.0852,  0.0075, -0.2052, -0.0369, -0.2827,\n",
      "          -0.1909,  0.0719, -0.0862, -0.1398, -0.2238, -0.2484,  0.2761,\n",
      "           0.3225,  0.0799, -0.1081, -0.1262,  0.0810,  0.0412, -0.1740,\n",
      "          -0.2032, -0.3404, -0.0345, -0.1444, -0.0336,  0.1423,  0.1009,\n",
      "           0.1195, -0.1365, -0.1099, -0.1552]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6547e-02,  3.9979e-01, -9.6515e-01, -6.8097e-01,  3.7552e-01,\n",
      "          -2.0196e-01,  1.4646e+00, -8.3567e-02, -3.5834e+00,  9.0661e-01,\n",
      "           4.2807e-01, -6.2911e-01,  2.6026e+00, -6.3003e-01, -5.4130e-01,\n",
      "          -1.5798e-01,  8.5120e-01,  1.0943e+00,  4.5522e-01,  4.3617e-01,\n",
      "          -6.3330e-01, -3.8251e-01,  1.6401e+00,  1.5109e+00,  7.5323e-01,\n",
      "           0.0000e+00, -1.8804e-01, -7.5966e-01,  1.6532e+00,  8.6135e-01,\n",
      "           1.2316e+00,  1.2190e+00, -1.0341e+00, -8.2959e-02, -1.5341e+00,\n",
      "           1.3954e+00,  2.8090e-01, -3.7439e+00,  1.9773e-01,  0.0000e+00,\n",
      "          -4.5895e-01, -1.3978e+00, -2.6877e-01, -1.7147e+00, -1.5234e+00,\n",
      "           6.6761e-01,  5.4056e-01,  3.7104e-01, -1.3404e+00,  1.4444e-01,\n",
      "           0.0000e+00,  2.7508e+00,  6.1015e-01, -1.0287e+00, -2.5085e-02,\n",
      "           2.0374e-01, -8.8133e-01, -1.2515e+00, -2.3714e-01, -4.2592e-01,\n",
      "           1.0993e+00,  1.4074e+00, -2.0261e-01, -5.0100e-01,  0.0000e+00,\n",
      "           5.5135e-01,  1.2782e+00, -1.2875e+00,  4.1040e-01,  5.2677e-01,\n",
      "          -1.2664e+00, -2.9811e-02,  7.0722e-01, -3.6399e+00,  3.2525e-01,\n",
      "          -7.4158e-04, -1.5999e-01,  1.0617e+00, -5.7500e-02, -1.1839e-01,\n",
      "          -1.3998e+00,  2.1302e+00, -9.2425e-01,  1.0058e+00, -2.0757e-01,\n",
      "           4.3585e-01,  1.6613e+00, -9.7399e-01,  0.0000e+00, -5.8114e-01,\n",
      "          -2.2725e+00,  1.0997e+00, -6.2240e-01, -1.1355e+00,  4.6718e-01,\n",
      "          -1.1701e+00,  3.3267e-02,  6.2887e-01,  1.7192e+00, -7.7884e-01,\n",
      "           2.6967e+00,  0.0000e+00,  1.0759e+00,  1.4530e+00, -6.6609e-01,\n",
      "          -7.6235e-01,  1.2112e+00,  1.2722e-01,  0.0000e+00, -1.3744e-02,\n",
      "           0.0000e+00,  1.3404e-01, -1.0474e+00,  1.3099e+00, -1.6525e+00,\n",
      "          -2.9880e+00, -5.6901e-02, -4.9967e-01, -1.9334e-01,  4.4538e-01,\n",
      "          -1.4651e+00,  0.0000e+00, -1.4601e+00, -7.2567e-01, -9.5784e-01,\n",
      "          -1.3080e+00,  8.9595e-01,  1.6967e-01,  0.0000e+00, -7.5130e-01,\n",
      "          -8.2403e-01,  5.3063e-01,  0.0000e+00,  9.8389e-01,  2.7607e-01,\n",
      "          -5.8923e-01,  6.5865e-01,  5.7533e-01, -1.1589e+00, -1.0095e+00,\n",
      "          -3.8813e-01,  6.7770e-01, -7.8946e-01,  0.0000e+00, -1.6847e+00,\n",
      "          -1.0037e-01, -5.4300e-01, -8.4423e-01, -7.5508e-01,  1.7763e-01,\n",
      "           1.9978e+00, -1.9929e-01, -1.9295e+00, -4.0624e-01,  4.4113e-01,\n",
      "          -1.9436e-01, -6.4790e-02, -1.3023e-01,  3.9166e-02,  5.3733e-01,\n",
      "          -2.6608e-02,  2.2060e+00,  4.8110e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -8.9151e-01,  2.8152e-01,  8.3015e-02, -3.5803e-01, -4.7787e-01,\n",
      "           7.3634e-01, -3.0950e-02,  2.0084e-02, -1.0024e+00,  1.2775e+00,\n",
      "          -1.0978e+00, -9.8605e-01, -2.0756e+00,  1.9683e+00,  8.6407e-02,\n",
      "          -3.0802e-02,  3.5001e-02,  6.7076e-01,  9.7976e-01, -7.4742e-01,\n",
      "          -3.4096e-01, -2.7818e+00, -7.8315e-01,  1.2089e+00,  1.0125e+00,\n",
      "           3.0726e+00,  4.9413e-01,  0.0000e+00, -5.9313e-01,  5.6006e-01,\n",
      "           2.1643e+00, -1.1874e+00,  5.3508e-01,  1.8108e+00, -9.4620e-01,\n",
      "           0.0000e+00,  0.0000e+00,  1.2422e+00, -1.2207e-01,  2.3209e-01,\n",
      "          -5.7481e-01, -2.2919e+00,  6.8162e-01, -1.0733e+00, -4.7097e-01,\n",
      "           0.0000e+00, -5.7321e-01, -3.4117e-01,  7.9287e-01,  3.1207e-02,\n",
      "          -6.8357e-01, -1.0176e+00,  9.6664e-01, -2.4519e-01,  2.1687e+00,\n",
      "          -1.0826e+00, -4.2702e-01, -1.8432e+00, -5.0037e-01,  0.0000e+00,\n",
      "           7.0485e-01, -6.9661e-01, -6.2815e-01,  2.9219e-01, -1.5776e+00,\n",
      "           0.0000e+00,  1.5812e+00, -6.1376e-01,  1.3100e+00, -2.9792e+00,\n",
      "           4.0338e+00,  5.8517e-01,  4.3079e-02, -1.5788e+00, -2.8630e-01,\n",
      "           7.4188e-01, -3.2470e+00, -3.0382e-01, -8.5175e-01,  1.1299e-02,\n",
      "           2.7560e-01,  2.7464e-01,  2.5219e-01,  2.6151e-01,  0.0000e+00,\n",
      "          -3.6569e-01, -1.5944e-01, -5.5358e-01, -5.2159e-02, -1.1463e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0540, 0.0535, 0.0726, 0.0818, 0.1329, 0.2778, 0.0552, 0.0836, 0.0657,\n",
      "         0.1230]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2562, -0.0007, -0.0879,  ...,  0.1557,  0.0295,  0.0472],\n",
      "        [ 0.2216, -0.1021, -0.5283,  ...,  0.0351, -0.0401,  0.1132],\n",
      "        [ 0.0051, -0.0993, -0.2119,  ...,  0.2441, -0.0357,  0.0256],\n",
      "        ...,\n",
      "        [ 0.4545,  0.4199, -0.6958,  ..., -0.2190,  0.0148, -0.0234],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.1128e-01,  7.1505e-02, -1.4921e-01, -3.6506e-02, -2.1307e-01,\n",
      "          -2.4573e-01,  4.1866e-03,  7.6518e-02, -1.7307e-01, -1.1799e-01,\n",
      "           1.9405e-01,  1.7787e-01, -2.0047e-01,  1.5682e-01,  1.5786e-01,\n",
      "           5.9518e-02,  1.2188e-01, -3.8702e-02,  2.1802e-02,  2.4937e-02,\n",
      "           4.0139e-02, -8.1880e-02,  2.0359e-01, -7.1369e-02,  5.2810e-02,\n",
      "           9.1347e-02,  8.9376e-02, -2.2145e-01, -7.8726e-02, -3.0678e-02,\n",
      "          -9.0903e-02, -1.1818e-01, -9.5792e-02, -1.5901e-01,  2.2800e-01,\n",
      "           7.4867e-02,  4.1720e-02, -1.1740e-01, -1.4089e-01,  2.1836e-01,\n",
      "           2.3116e-01, -9.0930e-02,  5.6681e-02,  6.0180e-02,  1.6044e-02,\n",
      "           1.1905e-01,  3.0782e-01, -2.5274e-01,  1.9545e-01, -8.4405e-02,\n",
      "           1.2322e-01,  1.8131e-01, -1.9795e-01, -1.4753e-01, -3.8881e-03,\n",
      "          -7.8939e-02,  3.9327e-02, -1.4314e-02,  1.0280e-01, -7.5654e-03,\n",
      "           2.8489e-02,  1.6392e-01,  1.2704e-01,  8.7972e-02, -2.0744e-01,\n",
      "           1.2157e-01, -1.4967e-01,  4.5552e-02,  3.5620e-02,  1.6509e-01,\n",
      "           5.6992e-03, -1.5381e-01, -2.5923e-01,  1.3514e-02, -5.5226e-03,\n",
      "           2.2131e-01,  2.2811e-02,  2.8278e-01, -3.7277e-02, -1.9344e-01,\n",
      "          -6.7769e-02, -8.4711e-02,  2.8002e-02, -1.1584e-01, -1.0409e-02,\n",
      "           1.4846e-01,  1.7818e-01, -1.5637e-02, -4.2030e-02, -9.3199e-02,\n",
      "           9.8589e-02, -2.1506e-01,  9.4931e-02,  7.9103e-02,  1.0183e-01,\n",
      "           1.3223e-01,  2.9460e-04, -6.7145e-02,  1.2664e-02,  2.3832e-01,\n",
      "          -1.5926e-01, -1.2622e-01,  2.0839e-01,  1.1935e-01, -2.3966e-02,\n",
      "          -1.3657e-01,  7.5524e-02, -4.0049e-02, -2.2118e-01,  4.4846e-02,\n",
      "          -5.7623e-02, -5.4329e-02, -1.6780e-01, -3.0637e-01,  1.5373e-01,\n",
      "          -8.4362e-03, -8.7154e-02, -9.2141e-02, -3.6085e-02, -1.1318e-01,\n",
      "           1.4429e-01,  1.4881e-01, -1.1312e-01,  1.3605e-01,  1.4841e-01,\n",
      "          -3.2039e-01, -5.9998e-02,  2.7735e-02,  4.5406e-02, -2.0188e-02,\n",
      "           1.1385e-01, -1.1209e-01, -4.3929e-02, -3.5564e-02,  4.3387e-02,\n",
      "          -1.5185e-01,  2.9669e-01,  7.4816e-02, -1.0443e-02,  2.2566e-01,\n",
      "           3.4941e-02,  3.1778e-01, -9.7774e-02,  1.9790e-01, -8.3571e-03,\n",
      "          -9.0583e-03,  1.7652e-01, -3.5528e-02,  1.8410e-01,  2.2605e-02,\n",
      "          -1.6584e-01,  1.3383e-01, -2.5786e-03, -4.3950e-02, -5.7662e-02,\n",
      "           1.1558e-01, -1.2222e-01,  2.7422e-01, -1.3066e-01, -5.7087e-02,\n",
      "          -2.4773e-02,  4.5227e-02, -2.8213e-01,  1.4033e-01, -1.2557e-01,\n",
      "           1.6147e-01, -2.2115e-01, -6.7073e-02,  3.1870e-02,  1.6995e-01,\n",
      "          -8.3296e-02,  6.6164e-02,  5.0735e-02,  9.1969e-02, -4.4186e-02,\n",
      "           1.0891e-01,  2.3927e-01,  2.9520e-01,  5.8404e-02, -1.1805e-01,\n",
      "          -4.0188e-02, -1.8457e-01, -2.9277e-01, -1.9923e-01,  1.9978e-01,\n",
      "           1.8517e-01,  1.9062e-04,  4.2688e-03,  1.5608e-01, -1.9028e-01,\n",
      "           2.2327e-02,  3.4849e-03, -9.2693e-02, -6.3630e-02, -1.9378e-01,\n",
      "          -1.2309e-01,  2.4970e-02, -3.0865e-02,  1.1514e-01, -6.6129e-02,\n",
      "          -1.8971e-01,  6.2010e-02, -9.0233e-02, -8.6922e-02, -3.0679e-02,\n",
      "           5.4449e-02,  3.8967e-02,  6.1101e-02,  2.1532e-01, -2.6101e-01,\n",
      "          -5.6889e-02, -1.5960e-01,  1.1019e-01,  9.2919e-02, -3.0093e-01,\n",
      "           1.6844e-01,  1.2294e-01,  1.4531e-01, -1.6975e-01,  3.2312e-02,\n",
      "           1.5730e-01,  4.2200e-02, -9.2243e-02, -3.3669e-02, -1.0710e-01,\n",
      "           2.7407e-02, -8.3860e-02,  3.3258e-02, -1.4522e-01,  9.2448e-02,\n",
      "          -2.0548e-01, -1.7080e-01, -1.2139e-01, -3.8837e-03, -1.2847e-02,\n",
      "           3.9421e-03,  6.5399e-03, -1.8796e-01,  4.0743e-01,  2.6952e-01,\n",
      "           1.2973e-01,  5.8063e-02, -5.3732e-02, -5.6047e-02,  1.8872e-02,\n",
      "           1.5471e-01, -1.1486e-01,  2.2360e-01,  1.6486e-01, -9.4726e-02,\n",
      "           1.6231e-01, -1.8084e-02, -1.8775e-01,  3.4910e-02, -3.0511e-02,\n",
      "           7.3110e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4737, -0.4589, -1.2334, -0.1180,  0.4617,  0.0258,  0.6621,\n",
      "           0.5340,  0.6707,  0.9338,  1.7079, -1.0163,  0.0000, -0.2517,\n",
      "          -1.6338,  0.5126,  0.0000, -0.7566,  0.0000, -2.6435, -1.1336,\n",
      "           0.1682,  2.9297,  0.5544,  0.0000,  3.2093,  1.8370,  0.5188,\n",
      "           0.0000, -1.2856,  0.0294,  1.0135,  0.3248,  0.8598, -0.7986,\n",
      "          -1.4656,  0.6198,  0.0000,  1.9915,  0.1021,  0.4674, -2.2043,\n",
      "          -0.5664, -0.1151, -0.7129, -0.6893,  1.9277,  0.1099, -0.2868,\n",
      "          -1.8506,  1.4679,  0.4623,  0.6675, -0.2833,  0.5316,  0.2749,\n",
      "          -1.2423, -0.9512,  1.8140, -0.0118,  0.2048, -1.8184, -1.4015,\n",
      "          -0.8064,  1.1798,  0.2653, -0.1669, -0.2553, -0.0044, -0.4609,\n",
      "          -0.3251, -0.3241,  0.1474, -0.1264,  0.6586, -0.8063,  0.0000,\n",
      "           1.6796,  0.0878, -0.5459,  1.2270,  0.0000,  0.3267, -1.8364,\n",
      "          -0.0715,  0.0000, -1.4585,  0.0000,  0.6231,  0.8108, -1.2238,\n",
      "          -1.1443,  1.9851, -0.3661, -0.7340,  0.1566,  2.1414, -0.4056,\n",
      "          -0.3043, -1.8394,  0.0000, -0.7215,  0.0000,  0.2374,  0.3819,\n",
      "           1.1139, -1.0701,  2.2523,  0.0000, -0.2883, -0.0532,  0.6107,\n",
      "          -0.2547, -0.2803, -1.9421,  1.1284,  1.0062, -2.4975, -0.5748,\n",
      "           0.0297, -1.6950, -0.4012, -0.3793,  0.0000, -0.5368, -1.1111,\n",
      "           1.3046,  0.1696,  0.3222,  1.3585,  2.0793, -2.6341,  0.3593,\n",
      "           0.0000,  0.0000,  0.0601,  0.3268, -2.1020, -0.4969, -1.6775,\n",
      "          -0.6419,  0.2342, -1.1870, -1.2151, -0.6311, -0.0407,  0.4647,\n",
      "           1.7384,  1.5943,  1.4317, -1.2628, -0.5774, -0.4801, -0.0395,\n",
      "           0.3267, -0.1166,  1.3538, -0.0314, -1.9006, -1.8061, -1.4268,\n",
      "          -0.9003, -0.7056, -0.3891, -0.9812, -0.1289,  0.4063,  0.9704,\n",
      "           0.5179, -0.1475,  1.5139, -0.3729,  0.0000, -2.0087,  0.1292,\n",
      "          -0.3524, -0.8305, -0.7691,  0.0000, -0.9376,  0.7277,  1.0420,\n",
      "           0.0468,  0.4632,  0.3163, -0.1181, -0.5416, -0.6643,  0.7549,\n",
      "          -1.0643, -0.5869, -1.7884,  1.2675, -0.9263, -1.6148,  0.0000,\n",
      "          -1.1570, -1.9607, -0.0720, -0.3754,  0.0000,  0.0000, -2.6317,\n",
      "          -0.5862, -0.7164, -1.3860, -1.2536,  0.1720,  0.2188, -1.1109,\n",
      "           0.9449, -0.6919, -1.5195,  0.3622,  0.2374, -1.4266, -2.3448,\n",
      "           0.0473, -1.4799,  0.4274,  0.0000,  0.0000,  0.0000, -1.1653,\n",
      "          -1.3014, -0.1876,  1.2723,  1.2665, -2.1881, -0.0563,  1.7373,\n",
      "          -1.1752,  0.9562,  0.0000,  0.5271,  0.7892, -0.6786,  0.1045,\n",
      "          -0.6804, -2.2622,  0.1674, -0.3138, -1.0432, -0.3820, -1.0801,\n",
      "           0.5580,  1.4997, -0.5646, -1.3772,  1.2434,  0.5826,  1.7529,\n",
      "           1.9514,  0.3626,  0.4873,  0.3903]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0242, 0.2394, 0.0847, 0.0564, 0.1083, 0.1282, 0.0310, 0.1884, 0.0791,\n",
      "         0.0603]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2562, -0.0007, -0.0879,  ...,  0.1557,  0.0295,  0.0472],\n",
      "        [ 0.2216, -0.1021, -0.5283,  ...,  0.0351, -0.0401,  0.1132],\n",
      "        [ 0.0051, -0.0993, -0.2119,  ...,  0.2441, -0.0357,  0.0256],\n",
      "        ...,\n",
      "        [ 0.4545,  0.4199, -0.6958,  ..., -0.2190,  0.0148, -0.0234],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0438,  0.0406, -0.2964, -0.0791, -0.1483, -0.1036, -0.0257,\n",
      "          -0.0813, -0.0842, -0.1937,  0.1630,  0.1507, -0.1606,  0.0724,\n",
      "           0.1745,  0.0589,  0.2084, -0.0197, -0.0461,  0.0840,  0.0212,\n",
      "          -0.0933,  0.2359, -0.0070,  0.0935, -0.0279,  0.0944, -0.1718,\n",
      "          -0.1094, -0.0363,  0.0262, -0.2085,  0.0232, -0.1576,  0.2719,\n",
      "           0.0424, -0.0502, -0.0433, -0.1999,  0.1379,  0.1756, -0.0642,\n",
      "           0.0364,  0.0537,  0.0105,  0.0941,  0.2356, -0.1998,  0.2380,\n",
      "          -0.0673,  0.0237,  0.1380, -0.2498, -0.1544, -0.0051,  0.0210,\n",
      "           0.0416,  0.0494,  0.1691,  0.0722, -0.0313,  0.1223, -0.0020,\n",
      "           0.0069, -0.1177,  0.1566, -0.1662,  0.0796,  0.0012,  0.1170,\n",
      "          -0.0327, -0.0354, -0.1941, -0.0481, -0.1604,  0.2985,  0.0661,\n",
      "           0.3109, -0.0483, -0.1168, -0.1641, -0.1429, -0.0759, -0.1101,\n",
      "          -0.0145,  0.1565,  0.0510, -0.0091, -0.0720, -0.1328,  0.0991,\n",
      "          -0.1309,  0.0813,  0.0445,  0.0475,  0.1426,  0.0069,  0.0214,\n",
      "           0.0192,  0.2514, -0.1651,  0.0057,  0.1590,  0.1153, -0.1893,\n",
      "          -0.1838,  0.0219,  0.0745, -0.2297,  0.0588,  0.0625,  0.0065,\n",
      "          -0.0979, -0.3582,  0.1519, -0.1220, -0.0204, -0.0586, -0.0791,\n",
      "          -0.0402,  0.1225,  0.1009, -0.1758,  0.1428,  0.0836, -0.2981,\n",
      "          -0.0157,  0.0121,  0.0199, -0.1258,  0.0086, -0.2297,  0.0458,\n",
      "           0.0031, -0.0974,  0.0173,  0.4328,  0.0392, -0.1628,  0.1363,\n",
      "           0.0643,  0.3078, -0.0803,  0.2384,  0.0497, -0.0431,  0.1187,\n",
      "          -0.0325,  0.1463, -0.0293, -0.1844,  0.1265, -0.0829, -0.0515,\n",
      "          -0.0148,  0.1219, -0.0172,  0.2804, -0.0747, -0.1153, -0.0618,\n",
      "          -0.0228, -0.2877,  0.2035, -0.1182,  0.0767, -0.1765, -0.0177,\n",
      "           0.0441,  0.2546, -0.1491,  0.0288,  0.0819,  0.1169, -0.1405,\n",
      "           0.0187,  0.2505,  0.2888,  0.2274, -0.1348, -0.0086, -0.2614,\n",
      "          -0.2233, -0.1734,  0.1484,  0.1078, -0.0291,  0.0326,  0.1633,\n",
      "          -0.2011, -0.0113,  0.1090, -0.1571, -0.0797, -0.1527, -0.0585,\n",
      "          -0.0693, -0.0161,  0.0333, -0.0028, -0.1704,  0.1601, -0.0837,\n",
      "           0.0548, -0.0519,  0.0272,  0.0748,  0.1717,  0.1337, -0.2686,\n",
      "          -0.0358, -0.2863,  0.0409,  0.1378, -0.2538,  0.1741,  0.0913,\n",
      "           0.2151, -0.1774,  0.0959,  0.2337, -0.0184,  0.0148, -0.0519,\n",
      "           0.0030,  0.0338,  0.0234, -0.0138, -0.1945,  0.1741, -0.3893,\n",
      "          -0.1688, -0.0645, -0.0097, -0.0246, -0.0032,  0.0432, -0.1527,\n",
      "           0.3362,  0.2675,  0.1651,  0.0101, -0.0166, -0.1079,  0.0290,\n",
      "           0.1644, -0.2227,  0.1397,  0.1917,  0.0300,  0.2490,  0.0026,\n",
      "          -0.1773,  0.0020, -0.0230,  0.0714]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0628e+00, -6.9651e-02,  0.0000e+00,  1.3220e+00,  5.1601e-01,\n",
      "          -3.7598e-01,  1.0701e-03, -7.2300e-01,  2.1178e+00, -2.1378e-01,\n",
      "           2.8199e-01,  8.3064e-01,  0.0000e+00,  1.9976e-01,  0.0000e+00,\n",
      "           3.5178e-01, -6.8294e-01,  0.0000e+00,  8.7460e-01,  5.4566e-01,\n",
      "           1.8833e+00,  6.0184e-01, -3.6808e-02, -5.3530e-01, -1.0024e-01,\n",
      "           6.5097e-01, -1.6087e+00, -1.3623e+00, -2.1267e+00, -1.0343e+00,\n",
      "           3.8871e-02, -1.4547e+00, -2.0766e+00,  3.1564e-01, -2.8489e-01,\n",
      "          -2.0018e+00,  2.1891e-01,  9.9705e-01,  6.0123e-01,  9.5365e-01,\n",
      "          -2.2524e-01, -2.2113e+00, -7.0616e-01,  1.3961e+00,  0.0000e+00,\n",
      "          -1.1386e+00,  2.4259e-01,  7.4185e-01, -7.0973e-01, -1.3358e+00,\n",
      "           1.6086e+00, -1.3748e-01,  6.6274e-01,  1.1163e+00,  5.6733e-01,\n",
      "           0.0000e+00, -4.4964e-01, -8.8808e-01,  1.3387e-01,  6.2842e-01,\n",
      "          -7.0497e-01,  5.6369e-01, -6.9338e-01, -1.5474e+00,  2.8930e-01,\n",
      "           9.5709e-02, -1.7743e-01,  0.0000e+00, -2.1385e+00,  5.5966e-01,\n",
      "           1.8279e-01, -5.1247e-01, -3.4104e-01, -1.1319e+00, -6.4747e-01,\n",
      "           4.6100e-01, -1.0491e+00,  0.0000e+00,  5.1726e-01, -1.8661e-01,\n",
      "          -3.8498e-01,  2.1580e+00,  7.7741e-01, -8.4541e-01,  3.9776e-01,\n",
      "           4.1924e-01,  1.6046e+00, -5.6414e-01, -1.4132e+00, -1.4905e+00,\n",
      "           4.0426e-01, -3.5151e-01,  0.0000e+00, -2.3209e+00,  1.2381e+00,\n",
      "          -9.6294e-01,  1.3201e+00, -9.0743e-01,  2.3908e+00,  9.5526e-01,\n",
      "          -1.2007e+00,  5.9431e-01,  0.0000e+00, -1.7340e+00,  3.6522e-01,\n",
      "           4.0227e-01, -1.2705e+00,  4.5490e-01,  0.0000e+00,  1.4956e-01,\n",
      "          -8.3237e-01,  5.3396e-01,  8.0831e-01,  6.6424e-01, -1.0551e+00,\n",
      "           9.1775e-01, -7.0289e-01,  0.0000e+00,  2.5776e-01,  0.0000e+00,\n",
      "          -8.7685e-01, -1.3965e+00, -3.6484e-01, -1.8465e+00, -1.3006e+00,\n",
      "           1.0693e+00,  0.0000e+00,  6.4943e-01,  2.5565e-01, -1.4895e+00,\n",
      "           2.5023e+00,  3.7792e-01, -1.3457e+00,  7.2231e-01,  3.2011e+00,\n",
      "          -7.5292e-01, -3.8354e-01,  0.0000e+00,  2.2521e+00,  1.9402e-01,\n",
      "          -3.9205e-02,  0.0000e+00,  3.6280e-01,  0.0000e+00, -1.1121e+00,\n",
      "           1.2470e+00,  7.7539e-01, -7.7469e-01, -4.4833e-02, -1.3870e+00,\n",
      "           2.3359e+00,  7.6496e-01, -2.8959e-01, -2.1306e+00, -5.8166e-01,\n",
      "           7.8585e-01, -1.8620e+00, -1.3047e+00,  1.9023e-01, -3.6288e+00,\n",
      "          -1.8688e+00,  1.1505e+00, -8.5968e-01,  9.5964e-01, -1.4614e+00,\n",
      "          -2.7227e-02,  1.9745e+00,  1.1270e+00, -4.8572e-01, -1.2416e+00,\n",
      "          -2.1227e-01, -1.3225e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.2609e-01,  6.0644e-01, -7.4889e-01,  2.5908e-01,\n",
      "           1.3326e+00,  0.0000e+00,  2.7772e-01, -5.8371e-01,  1.6235e+00,\n",
      "          -1.2403e+00, -1.8450e-03, -5.0200e-02,  0.0000e+00,  5.6556e-01,\n",
      "          -4.1998e-01,  3.8824e-01,  0.0000e+00,  8.0974e-01,  1.0503e+00,\n",
      "          -7.8912e-01, -1.4387e+00, -4.1566e-01, -7.5048e-01, -4.5402e-01,\n",
      "          -5.4750e-01,  7.2232e-01, -1.8533e+00,  1.3573e+00,  8.3750e-01,\n",
      "          -1.5239e+00, -3.5895e-01,  6.4781e-01,  2.0065e-01, -2.1782e+00,\n",
      "           8.3545e-01, -1.2911e+00,  0.0000e+00,  2.6112e-01, -1.5635e+00,\n",
      "           2.0758e+00,  1.3415e-01,  2.5770e+00,  0.0000e+00, -5.7963e-01,\n",
      "          -1.4282e+00,  1.9012e+00, -3.8075e-01,  1.4697e+00,  8.0505e-01,\n",
      "           3.6925e-01,  6.6975e-01, -7.0048e-01,  8.9254e-02,  1.0256e+00,\n",
      "           9.7807e-01,  0.0000e+00,  6.5968e-01,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00, -7.1106e-01,  3.7054e-01, -2.2406e-01,\n",
      "          -7.5233e-01,  5.7221e-01,  5.3064e-01, -6.6370e-01,  1.5465e+00,\n",
      "           5.7833e-01,  1.8922e+00, -8.6406e-01,  4.9359e-01, -3.8725e-01,\n",
      "           5.0013e-01, -9.7500e-01,  0.0000e+00, -1.0636e+00, -8.0792e-01,\n",
      "          -6.2195e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0546, 0.1277, 0.1020, 0.1037, 0.0911, 0.1896, 0.0830, 0.0580, 0.0585,\n",
      "         0.1319]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2562, -0.0007, -0.0879,  ...,  0.1557,  0.0295,  0.0472],\n",
      "        [ 0.2216, -0.1021, -0.5283,  ...,  0.0351, -0.0401,  0.1132],\n",
      "        [ 0.0051, -0.0993, -0.2119,  ...,  0.2441, -0.0357,  0.0256],\n",
      "        ...,\n",
      "        [ 0.4545,  0.4199, -0.6958,  ..., -0.2190,  0.0148, -0.0234],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0633,  0.0281, -0.1797, -0.0677, -0.1536, -0.1518, -0.0464,\n",
      "           0.0252, -0.1301, -0.1498,  0.1543,  0.2073, -0.1696,  0.1272,\n",
      "           0.1428,  0.0964,  0.1694, -0.0144, -0.0008,  0.0426,  0.0747,\n",
      "          -0.0627,  0.2316, -0.0626,  0.0900,  0.0899,  0.1310, -0.1695,\n",
      "          -0.0520, -0.0171, -0.0355, -0.1241,  0.0035, -0.1312,  0.2352,\n",
      "           0.0265, -0.0007, -0.0552, -0.1207,  0.1780,  0.1879, -0.0620,\n",
      "           0.0969,  0.0460, -0.0191,  0.1292,  0.2910, -0.1893,  0.2098,\n",
      "          -0.0920,  0.0973,  0.1558, -0.1981, -0.1427,  0.0155, -0.0373,\n",
      "           0.0536,  0.0116,  0.1279, -0.0227,  0.0020,  0.1230,  0.0638,\n",
      "           0.0329, -0.1512,  0.1376, -0.1486,  0.0248,  0.0231,  0.1248,\n",
      "           0.0237, -0.1064, -0.2028, -0.0267, -0.0534,  0.2804,  0.0306,\n",
      "           0.2616, -0.0523, -0.1298, -0.1119, -0.0630, -0.0184, -0.0937,\n",
      "           0.0295,  0.1097,  0.0956, -0.0068, -0.0590, -0.0944,  0.0924,\n",
      "          -0.1801,  0.1117,  0.0288,  0.0904,  0.1449, -0.0070, -0.0645,\n",
      "           0.0617,  0.2238, -0.1246, -0.0440,  0.1639,  0.0789, -0.0853,\n",
      "          -0.1654,  0.0301, -0.0025, -0.2328,  0.0217, -0.0114,  0.0093,\n",
      "          -0.1492, -0.3021,  0.1769, -0.0788, -0.0390, -0.0638, -0.0454,\n",
      "          -0.0576,  0.1030,  0.1541, -0.1127,  0.1342,  0.1312, -0.2954,\n",
      "          -0.0423,  0.0178,  0.0029, -0.0663,  0.0509, -0.1102, -0.0498,\n",
      "          -0.0184, -0.0193, -0.0929,  0.3167,  0.0702, -0.0614,  0.1585,\n",
      "           0.0562,  0.3030, -0.1000,  0.1906, -0.0066, -0.0055,  0.1327,\n",
      "          -0.0450,  0.1599, -0.0308, -0.1500,  0.1456, -0.0405, -0.0538,\n",
      "          -0.0275,  0.1026, -0.0640,  0.2703, -0.1270, -0.0533, -0.0379,\n",
      "           0.0351, -0.2686,  0.1448, -0.1228,  0.1181, -0.1917, -0.0066,\n",
      "          -0.0365,  0.1486, -0.1086,  0.0595,  0.0334,  0.1332, -0.0880,\n",
      "           0.0653,  0.2653,  0.2619,  0.0803, -0.1270, -0.0036, -0.2254,\n",
      "          -0.2453, -0.1943,  0.1510,  0.1243,  0.0518, -0.0296,  0.1257,\n",
      "          -0.1810,  0.0051,  0.0503, -0.0848, -0.0745, -0.2109, -0.0675,\n",
      "           0.0013, -0.0241,  0.0788, -0.0793, -0.1696,  0.0978, -0.0908,\n",
      "          -0.0466, -0.0424,  0.0173,  0.1057,  0.0949,  0.2020, -0.2827,\n",
      "          -0.0571, -0.1891,  0.0483,  0.1015, -0.2922,  0.1444,  0.1492,\n",
      "           0.1913, -0.1579,  0.0120,  0.1568,  0.0230, -0.0550, -0.0101,\n",
      "          -0.1064,  0.0420, -0.0579,  0.0178, -0.1295,  0.0984, -0.2610,\n",
      "          -0.1736, -0.1040,  0.0264, -0.0122,  0.0161,  0.0613, -0.1445,\n",
      "           0.3607,  0.2410,  0.1588,  0.0620, -0.0058, -0.0642,  0.0378,\n",
      "           0.1472, -0.1480,  0.1888,  0.1498, -0.0650,  0.2015,  0.0076,\n",
      "          -0.1585,  0.0265, -0.0150,  0.0811]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0628e+00, -6.9651e-02, -1.8077e+00,  1.3220e+00,  5.1601e-01,\n",
      "          -3.7598e-01,  1.0701e-03, -7.2300e-01,  2.1178e+00, -2.1378e-01,\n",
      "           2.8199e-01,  8.3064e-01, -1.1107e+00,  1.9976e-01,  3.1238e-01,\n",
      "           3.5178e-01, -6.8294e-01,  1.6909e-01,  8.7460e-01,  5.4566e-01,\n",
      "           1.8833e+00,  6.0184e-01, -3.6808e-02, -5.3530e-01, -1.0024e-01,\n",
      "           6.5097e-01, -1.6087e+00, -1.3623e+00, -2.1267e+00,  0.0000e+00,\n",
      "           3.8871e-02, -1.4547e+00, -2.0766e+00,  3.1564e-01, -2.8489e-01,\n",
      "           0.0000e+00,  2.1891e-01,  9.9705e-01,  6.0123e-01,  9.5365e-01,\n",
      "          -2.2524e-01, -2.2113e+00, -7.0616e-01,  1.3961e+00,  8.9618e-02,\n",
      "          -1.1386e+00,  2.4259e-01,  0.0000e+00,  0.0000e+00, -1.3358e+00,\n",
      "           1.6086e+00, -1.3748e-01,  6.6274e-01,  1.1163e+00,  5.6733e-01,\n",
      "           3.3306e-01, -4.4964e-01, -8.8808e-01,  1.3387e-01,  6.2842e-01,\n",
      "          -7.0497e-01,  0.0000e+00, -6.9338e-01, -1.5474e+00,  2.8930e-01,\n",
      "           9.5709e-02, -1.7743e-01,  5.9492e-01, -2.1385e+00,  5.5966e-01,\n",
      "           1.8279e-01, -5.1247e-01, -3.4104e-01, -1.1319e+00, -6.4747e-01,\n",
      "           0.0000e+00, -1.0491e+00,  1.1898e-01,  5.1726e-01, -1.8661e-01,\n",
      "          -3.8498e-01,  2.1580e+00,  0.0000e+00, -8.4541e-01,  0.0000e+00,\n",
      "           4.1924e-01,  1.6046e+00, -5.6414e-01,  0.0000e+00, -1.4905e+00,\n",
      "           4.0426e-01, -3.5151e-01,  4.9392e-01, -2.3209e+00,  1.2381e+00,\n",
      "          -9.6294e-01,  1.3201e+00, -9.0743e-01,  2.3908e+00,  9.5526e-01,\n",
      "          -1.2007e+00,  5.9431e-01,  1.0665e+00, -1.7340e+00,  3.6522e-01,\n",
      "           4.0227e-01, -1.2705e+00,  4.5490e-01,  1.9688e+00,  1.4956e-01,\n",
      "          -8.3237e-01,  5.3396e-01,  8.0831e-01,  6.6424e-01, -1.0551e+00,\n",
      "           9.1775e-01, -7.0289e-01, -8.4517e-01,  2.5776e-01,  8.7974e-01,\n",
      "          -8.7685e-01, -1.3965e+00, -3.6484e-01, -1.8465e+00, -1.3006e+00,\n",
      "           1.0693e+00, -8.1151e-01,  6.4943e-01,  2.5565e-01, -1.4895e+00,\n",
      "           2.5023e+00,  3.7792e-01, -1.3457e+00,  7.2231e-01,  3.2011e+00,\n",
      "          -7.5292e-01, -3.8354e-01,  1.2822e+00,  2.2521e+00,  1.9402e-01,\n",
      "          -3.9205e-02,  3.0300e+00,  3.6280e-01, -1.8706e-01, -1.1121e+00,\n",
      "           1.2470e+00,  7.7539e-01, -7.7469e-01, -4.4833e-02, -1.3870e+00,\n",
      "           0.0000e+00,  7.6496e-01, -2.8959e-01, -2.1306e+00, -5.8166e-01,\n",
      "           7.8585e-01, -1.8620e+00, -1.3047e+00,  1.9023e-01, -3.6288e+00,\n",
      "          -1.8688e+00,  1.1505e+00, -8.5968e-01,  9.5964e-01,  0.0000e+00,\n",
      "          -2.7227e-02,  1.9745e+00,  1.1270e+00, -4.8572e-01, -1.2416e+00,\n",
      "          -2.1227e-01, -1.3225e+00, -1.6392e+00, -7.7186e-01,  6.8267e-01,\n",
      "          -1.3796e+00, -1.2609e-01,  6.0644e-01, -7.4889e-01,  2.5908e-01,\n",
      "           1.3326e+00,  0.0000e+00,  2.7772e-01, -5.8371e-01,  1.6235e+00,\n",
      "          -1.2403e+00, -1.8450e-03,  0.0000e+00,  9.0113e-01,  5.6556e-01,\n",
      "          -4.1998e-01,  3.8824e-01, -1.1593e-01,  8.0974e-01,  1.0503e+00,\n",
      "          -7.8912e-01, -1.4387e+00, -4.1566e-01, -7.5048e-01, -4.5402e-01,\n",
      "          -5.4750e-01,  7.2232e-01, -1.8533e+00,  1.3573e+00,  8.3750e-01,\n",
      "          -1.5239e+00, -3.5895e-01,  6.4781e-01,  2.0065e-01, -2.1782e+00,\n",
      "           8.3545e-01, -1.2911e+00, -1.2839e+00,  2.6112e-01, -1.5635e+00,\n",
      "           2.0758e+00,  1.3415e-01,  2.5770e+00,  0.0000e+00, -5.7963e-01,\n",
      "          -1.4282e+00,  1.9012e+00, -3.8075e-01,  1.4697e+00,  8.0505e-01,\n",
      "           3.6925e-01,  0.0000e+00,  0.0000e+00,  8.9254e-02,  1.0256e+00,\n",
      "           9.7807e-01, -1.4083e+00,  6.5968e-01, -1.1449e+00, -1.6456e+00,\n",
      "          -6.0009e-01,  0.0000e+00,  0.0000e+00,  3.7054e-01, -2.2406e-01,\n",
      "           0.0000e+00,  5.7221e-01,  5.3064e-01, -6.6370e-01,  1.5465e+00,\n",
      "           0.0000e+00,  1.8922e+00,  0.0000e+00,  4.9359e-01, -3.8725e-01,\n",
      "           5.0013e-01, -9.7500e-01,  1.7728e+00, -1.0636e+00, -8.0792e-01,\n",
      "          -6.2195e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0671, 0.1109, 0.1380, 0.1313, 0.0998, 0.1367, 0.0592, 0.0525, 0.0673,\n",
      "         0.1371]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2562, -0.0007, -0.0879,  ...,  0.1557,  0.0295,  0.0472],\n",
      "        [ 0.2216, -0.1021, -0.5283,  ...,  0.0351, -0.0401,  0.1132],\n",
      "        [ 0.0051, -0.0993, -0.2119,  ...,  0.2441, -0.0357,  0.0256],\n",
      "        ...,\n",
      "        [ 0.4545,  0.4199, -0.6958,  ..., -0.2190,  0.0148, -0.0234],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-6.3132e-02, -1.1137e-02, -1.6164e-01, -5.7568e-02, -1.3912e-01,\n",
      "          -1.2628e-01, -7.2022e-02,  1.0368e-02, -1.0621e-01, -1.4266e-01,\n",
      "           1.4111e-01,  2.3079e-01, -1.4796e-01,  1.1395e-01,  1.2924e-01,\n",
      "           1.0985e-01,  1.9233e-01, -7.8823e-03,  9.2224e-03,  6.2790e-02,\n",
      "           1.1529e-01, -5.2958e-02,  2.3553e-01, -3.6955e-02,  1.0817e-01,\n",
      "           9.6618e-02,  1.3823e-01, -1.2018e-01, -2.7711e-02, -1.1999e-02,\n",
      "          -5.5304e-02, -1.3527e-01,  4.7677e-02, -1.0153e-01,  2.3346e-01,\n",
      "          -7.9569e-03, -5.4806e-03, -2.4073e-02, -7.9390e-02,  1.3370e-01,\n",
      "           1.6372e-01, -7.3682e-02,  1.2864e-01,  5.9977e-02, -7.3955e-03,\n",
      "           1.5413e-01,  2.9773e-01, -1.7533e-01,  2.0198e-01, -1.0761e-01,\n",
      "           7.0660e-02,  1.3831e-01, -1.8335e-01, -1.4427e-01,  4.4207e-02,\n",
      "          -5.5145e-02,  6.4476e-02,  2.9359e-02,  1.1971e-01, -2.6643e-02,\n",
      "          -2.2882e-02,  1.0498e-01,  3.2737e-02, -1.6947e-03, -1.2523e-01,\n",
      "           1.3201e-01, -1.4442e-01,  1.8582e-03,  2.4194e-02,  7.1373e-02,\n",
      "           5.4554e-02, -1.1471e-01, -1.6593e-01, -5.3526e-02, -6.3650e-02,\n",
      "           2.9184e-01,  4.5190e-02,  2.4391e-01, -6.5455e-02, -9.1122e-02,\n",
      "          -1.4457e-01, -9.9628e-02, -2.9246e-02, -8.4683e-02,  8.8263e-02,\n",
      "           9.6714e-02,  3.4177e-02,  1.2300e-02, -7.7200e-02, -1.0412e-01,\n",
      "           9.8496e-02, -1.8108e-01,  1.4484e-01,  1.6406e-02,  7.3323e-02,\n",
      "           1.6702e-01, -1.7125e-02, -8.5554e-02,  8.0121e-02,  2.2079e-01,\n",
      "          -1.0823e-01, -2.5034e-02,  1.5193e-01,  4.6657e-02, -1.0181e-01,\n",
      "          -1.6703e-01,  2.9335e-02, -1.0806e-03, -2.2657e-01,  1.1111e-02,\n",
      "           1.6744e-03,  4.1896e-02, -1.4399e-01, -2.8266e-01,  1.7486e-01,\n",
      "          -1.1703e-01, -1.5315e-02, -6.3886e-02, -2.0374e-02, -4.7856e-02,\n",
      "           7.1824e-02,  1.4878e-01, -1.0927e-01,  1.2346e-01,  1.2722e-01,\n",
      "          -2.7496e-01, -6.1120e-02, -1.0467e-02, -4.6853e-04, -8.9611e-02,\n",
      "           4.6323e-02, -8.7094e-02, -7.0364e-02, -3.1090e-02, -4.1732e-02,\n",
      "          -6.5591e-02,  3.2235e-01,  8.1123e-02, -7.5515e-02,  1.2719e-01,\n",
      "           8.8868e-02,  2.9618e-01, -1.1415e-01,  1.9447e-01, -5.7179e-03,\n",
      "          -2.9703e-03,  1.3155e-01, -5.2888e-02,  1.3060e-01, -3.6116e-02,\n",
      "          -1.2049e-01,  1.5153e-01, -4.8083e-02, -6.1792e-02, -2.2522e-02,\n",
      "           8.4399e-02, -4.8443e-02,  2.7224e-01, -1.1793e-01, -5.6375e-02,\n",
      "          -4.6748e-02,  3.4609e-02, -2.6147e-01,  1.1858e-01, -9.0847e-02,\n",
      "           1.2103e-01, -1.3505e-01,  2.6343e-02, -6.8982e-02,  1.4500e-01,\n",
      "          -1.0484e-01,  5.6066e-02,  3.6688e-02,  1.4359e-01, -1.0831e-01,\n",
      "           5.8833e-02,  2.6406e-01,  2.4048e-01,  4.2662e-02, -1.0318e-01,\n",
      "           2.9391e-02, -2.4554e-01, -2.3409e-01, -1.8906e-01,  1.2695e-01,\n",
      "           9.9002e-02,  5.8694e-02, -3.3888e-02,  1.4181e-01, -1.6519e-01,\n",
      "          -1.9411e-02,  5.3501e-02, -5.8822e-02, -8.2304e-02, -2.1351e-01,\n",
      "          -5.9163e-02, -1.5952e-03, -5.0308e-02,  5.8516e-02, -9.3320e-02,\n",
      "          -1.5742e-01,  1.0767e-01, -9.1420e-02, -5.1062e-02, -1.5690e-02,\n",
      "           7.5022e-03,  1.5038e-01,  9.4873e-02,  2.1642e-01, -2.9942e-01,\n",
      "          -2.0256e-02, -1.8263e-01,  2.7926e-02,  1.0769e-01, -2.9518e-01,\n",
      "           1.3805e-01,  1.6555e-01,  2.1296e-01, -1.4191e-01, -8.7852e-03,\n",
      "           1.4948e-01,  1.3750e-02, -5.3752e-02, -7.8668e-03, -1.2735e-01,\n",
      "           6.2306e-02, -4.7518e-02,  1.9461e-02, -7.6545e-02,  8.1436e-02,\n",
      "          -2.9296e-01, -1.6470e-01, -1.0601e-01,  4.5943e-02, -1.0324e-04,\n",
      "           1.9488e-02,  9.5011e-02, -1.2685e-01,  3.3178e-01,  2.1599e-01,\n",
      "           1.8624e-01,  6.9745e-02, -8.0621e-03, -8.5002e-02,  3.8341e-02,\n",
      "           1.6870e-01, -1.3119e-01,  1.8509e-01,  1.4880e-01, -4.1549e-02,\n",
      "           2.1459e-01,  2.0290e-02, -1.7564e-01,  3.9239e-02, -2.0652e-02,\n",
      "           9.6373e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7272e-01, -4.3063e-01,  3.1499e-01, -1.0846e+00, -1.1725e+00,\n",
      "           7.4169e-01, -1.9142e+00,  1.3513e+00,  1.9037e-01,  6.1733e-01,\n",
      "           1.9029e+00,  6.0243e-01,  2.2868e-01, -9.1610e-01, -3.1821e+00,\n",
      "          -6.8382e-02, -1.6331e+00, -9.4354e-01,  1.3607e+00, -1.4349e+00,\n",
      "          -1.4063e-01, -5.2367e-01, -1.1195e+00, -2.5951e+00, -7.5688e-02,\n",
      "           1.3913e+00, -6.1953e-01,  1.9971e+00,  1.2764e-01,  5.5414e-01,\n",
      "           9.1506e-01,  0.0000e+00,  2.2280e-01,  2.0156e+00,  0.0000e+00,\n",
      "          -1.4084e+00, -1.1185e-01, -8.1760e-01,  3.1474e-01,  8.5573e-02,\n",
      "           8.6229e-01, -8.9960e-01,  1.0090e+00, -1.5633e+00,  1.9441e+00,\n",
      "          -3.0010e-01,  7.0499e-01,  0.0000e+00, -1.0207e+00,  1.1165e+00,\n",
      "          -1.3223e+00,  0.0000e+00,  6.6672e-01, -8.4669e-01,  0.0000e+00,\n",
      "          -3.0924e-01, -1.4341e+00, -9.6589e-02,  1.2751e+00,  2.1810e+00,\n",
      "          -1.0063e+00,  0.0000e+00, -2.8012e-01,  2.6587e-01,  0.0000e+00,\n",
      "           3.9392e-01,  5.7802e-01,  1.1650e+00,  1.5806e+00, -1.4151e+00,\n",
      "           4.2753e-01,  0.0000e+00, -3.1297e-02, -7.9777e-01, -2.1441e-01,\n",
      "           0.0000e+00,  5.2571e-01,  1.3986e+00,  0.0000e+00, -7.9315e-01,\n",
      "           7.5775e-01, -1.0055e+00,  0.0000e+00,  1.0587e+00, -1.2146e+00,\n",
      "          -1.1307e-01, -1.1075e+00,  5.4876e-01, -9.4474e-01,  0.0000e+00,\n",
      "           5.2905e-01,  9.8678e-01,  1.7014e+00,  9.4355e-01,  6.0809e-01,\n",
      "          -1.5897e-02,  3.5328e-01, -1.1756e+00,  1.3714e+00,  0.0000e+00,\n",
      "           2.4371e-01,  4.5359e-02, -4.6642e-01, -9.8935e-01,  1.6400e+00,\n",
      "          -1.0230e+00,  3.0288e+00,  6.1983e-01, -1.0206e-01, -1.2353e+00,\n",
      "           1.8989e-01, -5.0293e-01, -5.7041e-01,  7.1231e-01, -7.8034e-01,\n",
      "           6.3222e-01,  4.0403e-01,  2.2408e-01, -2.3271e+00,  2.9362e-02,\n",
      "          -8.1380e-01, -1.4109e+00, -1.8373e+00,  6.0325e-01, -9.5646e-01,\n",
      "          -2.0031e-01,  3.9312e-02,  2.1499e+00,  0.0000e+00, -2.0876e+00,\n",
      "           0.0000e+00,  4.4967e-01, -1.1674e+00,  4.2512e-01, -4.6877e-01,\n",
      "          -7.4494e-01, -1.0649e+00, -9.7478e-01, -1.9585e-02,  2.3977e+00,\n",
      "           6.9859e-01, -1.1216e+00,  0.0000e+00, -1.4022e-01, -6.6948e-01,\n",
      "           3.3874e-02,  7.5938e-01,  4.2303e-01, -1.0332e+00, -9.5610e-02,\n",
      "           1.5600e+00,  5.8692e-01,  0.0000e+00,  0.0000e+00,  1.8408e+00,\n",
      "          -2.5253e-01, -2.1755e-01,  6.2349e-01, -2.3624e+00,  1.0555e+00,\n",
      "           3.0248e-01, -7.7466e-02,  1.5453e-01, -1.2116e+00, -2.1893e-02,\n",
      "           1.6820e+00,  0.0000e+00,  2.7074e-01, -1.2702e+00, -7.1324e-01,\n",
      "          -1.2243e+00, -1.0939e+00, -2.5903e+00,  5.0565e-01, -3.0586e+00,\n",
      "          -2.8715e-01,  4.9819e-01,  0.0000e+00,  3.1702e-01, -7.9282e-01,\n",
      "           2.7143e-01,  2.3395e+00,  1.0573e+00,  8.3828e-01, -4.0299e-01,\n",
      "           7.2727e-01,  5.9907e-01,  3.5945e-01,  8.4248e-01, -1.8300e+00,\n",
      "           1.3634e+00,  2.1590e+00,  0.0000e+00, -1.0153e+00, -1.1717e+00,\n",
      "          -2.2150e+00,  1.6662e+00,  2.1525e+00,  3.6337e-01,  2.3835e+00,\n",
      "           3.2305e-02, -5.0155e-01, -1.2761e+00, -5.4244e-01, -4.0733e-01,\n",
      "          -1.4468e+00,  9.5369e-01, -8.5173e-01,  0.0000e+00,  0.0000e+00,\n",
      "           6.3632e-01,  6.7606e-01,  2.3974e+00,  5.5112e-02,  1.8938e+00,\n",
      "           1.3080e+00,  5.8075e-01, -2.3170e+00,  1.5502e+00, -2.2253e-01,\n",
      "          -2.2714e-01,  1.7332e+00,  2.7700e-01, -1.5519e+00,  0.0000e+00,\n",
      "          -1.2244e+00, -8.4815e-01, -1.8013e+00, -3.8234e-04,  3.7338e-01,\n",
      "          -1.5734e+00, -1.2351e-01,  0.0000e+00, -1.7361e+00,  1.6941e+00,\n",
      "          -1.4405e+00,  6.3407e-01,  0.0000e+00,  9.8035e-01,  0.0000e+00,\n",
      "           1.5605e+00, -2.7204e-01, -2.5966e+00,  1.2384e+00, -1.2284e+00,\n",
      "           1.8845e+00, -5.0833e-01,  5.4284e-01, -2.6131e-01, -1.0218e+00,\n",
      "           1.3333e+00,  3.1045e-01, -5.1425e-02, -2.2878e-01, -1.6117e+00,\n",
      "           1.8061e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0663, 0.1124, 0.1500, 0.0879, 0.1405, 0.0992, 0.1127, 0.0852, 0.1006,\n",
      "         0.0452]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2562, -0.0007, -0.0879,  ...,  0.1557,  0.0295,  0.0472],\n",
      "        [ 0.2216, -0.1021, -0.5283,  ...,  0.0351, -0.0401,  0.1132],\n",
      "        [ 0.0051, -0.0993, -0.2119,  ...,  0.2441, -0.0357,  0.0256],\n",
      "        ...,\n",
      "        [ 0.4545,  0.4199, -0.6958,  ..., -0.2190,  0.0148, -0.0234],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.7522e-02, -3.0162e-02, -1.9788e-01, -7.1231e-02, -1.6414e-01,\n",
      "          -1.5415e-01, -7.3940e-02, -1.2453e-02, -1.0759e-01, -1.6203e-01,\n",
      "           1.4971e-01,  2.1418e-01, -1.7436e-01,  1.2263e-01,  1.5768e-01,\n",
      "           6.9242e-02,  1.6326e-01,  2.3339e-02, -1.6582e-02,  7.6000e-02,\n",
      "           9.5294e-02, -8.5245e-02,  2.4603e-01, -3.0107e-02,  1.0456e-01,\n",
      "           8.2552e-02,  1.5041e-01, -1.4347e-01, -6.0771e-02,  6.3207e-03,\n",
      "          -2.5909e-02, -1.7564e-01,  3.1741e-02, -1.5710e-01,  2.4339e-01,\n",
      "           4.2629e-03, -2.6761e-02, -3.6462e-02, -1.0282e-01,  1.4874e-01,\n",
      "           1.7604e-01, -4.9477e-02,  8.8662e-02,  7.2706e-02, -9.4931e-03,\n",
      "           1.7583e-01,  2.9618e-01, -2.1334e-01,  2.2500e-01, -1.1165e-01,\n",
      "           7.0300e-02,  1.2942e-01, -2.1501e-01, -1.7763e-01,  3.0906e-02,\n",
      "          -5.7223e-02,  5.5460e-02,  4.0373e-02,  1.3007e-01,  1.3963e-02,\n",
      "          -2.0308e-02,  1.0557e-01,  1.1641e-02,  3.3447e-02, -1.4083e-01,\n",
      "           1.3654e-01, -1.6788e-01,  6.1854e-02, -1.3280e-02,  9.9142e-02,\n",
      "           5.9599e-02, -8.5423e-02, -1.6586e-01, -7.1154e-02, -8.5816e-02,\n",
      "           3.0933e-01,  8.8975e-02,  2.6259e-01, -4.1546e-02, -7.9673e-02,\n",
      "          -1.3616e-01, -1.0521e-01, -4.1415e-02, -7.8703e-02,  6.7400e-02,\n",
      "           1.3290e-01,  6.9781e-02,  2.6507e-02, -6.1262e-02, -9.9181e-02,\n",
      "           1.1260e-01, -1.8920e-01,  1.1432e-01,  2.5298e-02,  5.6303e-02,\n",
      "           2.0445e-01, -1.3650e-03, -6.7611e-02,  8.7300e-02,  2.4403e-01,\n",
      "          -1.2846e-01,  1.3464e-03,  1.6476e-01,  6.7006e-02, -6.9025e-02,\n",
      "          -1.7417e-01,  6.0079e-02,  6.1630e-02, -2.3297e-01,  6.1260e-02,\n",
      "          -6.8725e-03,  5.2606e-02, -1.5645e-01, -3.0334e-01,  1.6093e-01,\n",
      "          -9.7897e-02, -1.9385e-02, -6.6834e-02, -3.9378e-02, -6.8460e-02,\n",
      "           6.9138e-02,  1.3773e-01, -1.5791e-01,  1.4996e-01,  7.7821e-02,\n",
      "          -2.9012e-01, -5.4444e-02, -2.3874e-02,  2.5144e-02, -1.1710e-01,\n",
      "           5.7433e-02, -1.3186e-01, -4.5235e-02, -2.7741e-04, -4.2538e-02,\n",
      "          -7.2592e-02,  3.6659e-01,  1.0433e-01, -8.2214e-02,  1.5600e-01,\n",
      "           6.3963e-02,  3.2418e-01, -1.3736e-01,  2.0719e-01,  2.4139e-02,\n",
      "          -2.3327e-02,  1.6715e-01, -3.5948e-02,  1.6339e-01, -1.6921e-03,\n",
      "          -1.5532e-01,  1.7399e-01, -7.0859e-02, -5.3422e-02, -9.7854e-03,\n",
      "           1.2705e-01, -4.3480e-02,  2.8965e-01, -1.5190e-01, -7.8948e-02,\n",
      "          -5.5259e-02,  2.9563e-02, -3.0466e-01,  1.5634e-01, -1.2159e-01,\n",
      "           1.1656e-01, -1.4723e-01, -1.2252e-03, -4.8457e-02,  1.7482e-01,\n",
      "          -1.2032e-01,  4.9387e-02,  6.5283e-02,  1.5524e-01, -9.8447e-02,\n",
      "           3.3085e-02,  2.5998e-01,  2.6080e-01,  7.7768e-02, -1.2792e-01,\n",
      "          -4.9270e-03, -2.5031e-01, -2.6284e-01, -2.0828e-01,  1.7503e-01,\n",
      "           1.0798e-01,  4.3966e-02, -9.2048e-04,  1.4468e-01, -1.9969e-01,\n",
      "          -1.3749e-02,  5.0069e-02, -8.8933e-02, -8.6764e-02, -2.2155e-01,\n",
      "          -9.8585e-02,  8.5911e-03, -5.3958e-02,  4.5414e-02, -9.1760e-02,\n",
      "          -1.4512e-01,  1.2691e-01, -1.1264e-01, -5.6725e-02, -3.7475e-02,\n",
      "          -2.7768e-03,  1.1908e-01,  1.1835e-01,  2.1842e-01, -3.4112e-01,\n",
      "          -4.2717e-02, -2.1435e-01,  3.5774e-02,  1.2215e-01, -3.0329e-01,\n",
      "           1.5793e-01,  1.8860e-01,  2.2320e-01, -1.6651e-01,  2.0599e-04,\n",
      "           1.8022e-01,  1.8657e-02, -4.3584e-02, -2.7456e-02, -9.8136e-02,\n",
      "           6.0110e-02, -5.8287e-02, -1.3963e-02, -1.2777e-01,  9.6270e-02,\n",
      "          -2.9542e-01, -1.7654e-01, -1.3573e-01,  3.9091e-02, -4.4102e-04,\n",
      "          -4.0650e-03,  5.2244e-02, -1.4033e-01,  3.6875e-01,  2.5201e-01,\n",
      "           1.8642e-01,  2.9714e-02, -1.1564e-02, -8.5919e-02,  3.1063e-02,\n",
      "           1.6822e-01, -1.5046e-01,  1.8304e-01,  1.6287e-01, -7.9721e-02,\n",
      "           2.2612e-01,  2.1683e-02, -2.0329e-01,  8.5791e-03,  9.5428e-03,\n",
      "           7.3257e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6464e-02,  3.9970e-01, -9.6525e-01, -6.8106e-01,  3.7556e-01,\n",
      "          -2.0200e-01,  1.4647e+00, -8.3500e-02, -3.5835e+00,  9.0649e-01,\n",
      "           4.2811e-01, -6.2908e-01,  2.6028e+00,  0.0000e+00, -5.4138e-01,\n",
      "          -1.5800e-01,  8.5118e-01,  1.0944e+00,  4.5523e-01,  4.3613e-01,\n",
      "          -6.3330e-01, -3.8254e-01,  1.6404e+00,  0.0000e+00,  7.5330e-01,\n",
      "          -7.5735e-02,  0.0000e+00, -7.5954e-01,  1.6533e+00,  8.6137e-01,\n",
      "           1.2316e+00,  1.2190e+00, -1.0341e+00, -8.2912e-02, -1.5342e+00,\n",
      "           1.3954e+00,  2.8095e-01, -3.7440e+00,  1.9774e-01,  1.6003e+00,\n",
      "          -4.5886e-01, -1.3979e+00, -2.6876e-01, -1.7149e+00, -1.5235e+00,\n",
      "           6.6762e-01,  5.4063e-01,  3.7105e-01, -1.3405e+00,  1.4442e-01,\n",
      "          -6.2931e-01,  2.7510e+00,  6.1022e-01, -1.0288e+00, -2.5094e-02,\n",
      "           2.0365e-01, -8.8143e-01, -1.2516e+00,  0.0000e+00,  0.0000e+00,\n",
      "           1.0995e+00,  1.4075e+00, -2.0264e-01, -5.0111e-01, -2.9627e+00,\n",
      "           5.5126e-01,  0.0000e+00, -1.2875e+00,  4.1058e-01,  5.2675e-01,\n",
      "          -1.2665e+00, -2.9892e-02,  0.0000e+00, -3.6401e+00,  3.2534e-01,\n",
      "          -8.8479e-04,  0.0000e+00,  1.0618e+00, -5.7541e-02, -1.1859e-01,\n",
      "           0.0000e+00,  2.1303e+00, -9.2431e-01,  1.0059e+00, -2.0760e-01,\n",
      "           4.3572e-01,  1.6613e+00, -9.7400e-01, -1.0414e-01, -5.8109e-01,\n",
      "           0.0000e+00,  1.0998e+00, -6.2240e-01, -1.1355e+00,  0.0000e+00,\n",
      "          -1.1702e+00,  3.3413e-02,  6.2890e-01,  1.7194e+00, -7.7900e-01,\n",
      "           2.6968e+00, -1.4617e+00,  1.0759e+00,  0.0000e+00, -6.6615e-01,\n",
      "          -7.6241e-01,  1.2113e+00,  1.2716e-01, -1.4729e+00, -1.3662e-02,\n",
      "          -2.4825e-01,  1.3411e-01, -1.0474e+00,  1.3099e+00, -1.6526e+00,\n",
      "          -2.9882e+00, -5.6835e-02, -4.9977e-01,  0.0000e+00,  4.4532e-01,\n",
      "          -1.4652e+00,  7.0207e-01, -1.4601e+00, -7.2572e-01,  0.0000e+00,\n",
      "          -1.3081e+00,  8.9608e-01,  1.6969e-01,  1.2846e+00, -7.5138e-01,\n",
      "          -8.2398e-01,  5.3055e-01, -1.5826e+00,  9.8396e-01,  2.7600e-01,\n",
      "           0.0000e+00,  6.5878e-01,  5.7519e-01, -1.1589e+00, -1.0096e+00,\n",
      "          -3.8817e-01,  6.7772e-01, -7.8954e-01, -1.0074e-01, -1.6848e+00,\n",
      "          -1.0046e-01, -5.4303e-01,  0.0000e+00, -7.5518e-01,  1.7765e-01,\n",
      "           1.9979e+00, -1.9935e-01, -1.9296e+00, -4.0618e-01,  4.4116e-01,\n",
      "          -1.9440e-01, -6.4690e-02, -1.3010e-01,  3.9205e-02,  5.3740e-01,\n",
      "           0.0000e+00,  2.2060e+00,  4.8110e-01, -5.5010e-01, -5.2609e-01,\n",
      "          -8.9160e-01,  2.8152e-01,  8.3123e-02, -3.5803e-01, -4.7790e-01,\n",
      "           7.3646e-01, -3.1093e-02,  2.0083e-02, -1.0024e+00,  0.0000e+00,\n",
      "           0.0000e+00, -9.8619e-01, -2.0757e+00,  1.9684e+00,  8.6474e-02,\n",
      "           0.0000e+00,  3.5043e-02,  0.0000e+00,  9.7974e-01, -7.4728e-01,\n",
      "          -3.4098e-01, -2.7820e+00, -7.8327e-01,  1.2090e+00,  1.0124e+00,\n",
      "           3.0728e+00,  4.9416e-01, -1.4432e-01, -5.9322e-01,  5.6016e-01,\n",
      "           2.1644e+00, -1.1875e+00,  5.3509e-01,  1.8109e+00, -9.4626e-01,\n",
      "          -1.6624e+00,  0.0000e+00,  1.2421e+00, -1.2205e-01,  2.3209e-01,\n",
      "           0.0000e+00, -2.2921e+00,  6.8154e-01, -1.0735e+00, -4.7098e-01,\n",
      "           2.8672e+00, -5.7327e-01, -3.4117e-01,  7.9287e-01,  3.1039e-02,\n",
      "          -6.8365e-01, -1.0178e+00,  9.6659e-01, -2.4527e-01,  2.1688e+00,\n",
      "          -1.0826e+00, -4.2701e-01, -1.8433e+00, -5.0044e-01,  3.3884e-01,\n",
      "           7.0490e-01, -6.9657e-01, -6.2813e-01,  2.9225e-01, -1.5779e+00,\n",
      "          -1.1082e+00,  1.5812e+00, -6.1370e-01,  0.0000e+00, -2.9792e+00,\n",
      "           4.0340e+00,  5.8521e-01,  4.3159e-02, -1.5789e+00, -2.8643e-01,\n",
      "           7.4188e-01,  0.0000e+00, -3.0389e-01, -8.5178e-01,  1.1322e-02,\n",
      "           2.7554e-01,  2.7463e-01,  2.5221e-01,  2.6149e-01,  3.8658e-01,\n",
      "          -3.6566e-01, -1.5942e-01, -5.5362e-01, -5.2235e-02, -1.1463e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0395, 0.0499, 0.1023, 0.0640, 0.1447, 0.2854, 0.0847, 0.0665, 0.0644,\n",
      "         0.0988]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5286e-01, -1.6643e-01, -9.5655e-02,  5.7997e-02, -1.8949e-01,\n",
      "           1.4099e-01, -2.4754e-01, -2.8571e-01, -5.1631e-02,  1.0089e-01,\n",
      "          -3.4799e-02, -1.4380e-01,  1.5621e-01, -3.0705e-02,  1.9916e-01,\n",
      "           2.9243e-01,  2.1547e-02, -3.6546e-02, -1.6328e-01,  1.3074e-02,\n",
      "          -2.7065e-01, -1.2573e-01,  3.5786e-02, -1.2712e-01, -1.4309e-02,\n",
      "           5.1326e-02,  8.3402e-02,  3.0288e-02, -2.0922e-01, -1.5752e-01,\n",
      "           8.3611e-02, -2.0620e-02,  1.8182e-02,  1.8327e-01,  7.0321e-02,\n",
      "          -1.3605e-01, -1.6463e-01,  1.6838e-01, -1.3026e-01, -1.5927e-01,\n",
      "           3.4140e-02,  1.3594e-01,  1.3409e-01, -1.4242e-01,  1.5068e-01,\n",
      "           1.4827e-02, -9.7668e-02, -1.6173e-01,  1.8537e-01, -1.0966e-01,\n",
      "          -2.7536e-01, -2.8664e-01,  3.1609e-02, -1.2007e-01, -2.7670e-01,\n",
      "          -1.2839e-01, -2.6464e-01,  2.2826e-01, -2.0470e-01,  2.2124e-02,\n",
      "           2.5275e-02,  6.9300e-02,  1.1566e-01,  5.0506e-02,  2.1587e-01,\n",
      "           5.4397e-02,  1.0027e-01, -2.1094e-01,  9.4915e-02, -2.7399e-01,\n",
      "           2.7055e-01,  2.1894e-01,  6.7226e-02, -2.6957e-02, -1.2828e-01,\n",
      "          -1.6283e-01,  3.0085e-01,  6.4970e-02,  5.0408e-02, -5.3953e-02,\n",
      "          -1.4887e-01,  8.5654e-02, -1.9866e-02,  1.9582e-02,  2.2151e-01,\n",
      "           1.3663e-01,  1.4674e-01,  1.4275e-01, -1.3521e-01, -1.4348e-02,\n",
      "           1.6854e-01,  1.1405e-01, -8.6557e-02, -2.4794e-01,  3.9150e-02,\n",
      "           2.5191e-01,  1.4877e-02,  9.9904e-02, -8.3655e-02,  1.2050e-01,\n",
      "           2.2238e-01, -2.1399e-01,  2.4767e-01,  1.9115e-01,  1.2149e-01,\n",
      "          -1.1784e-01, -6.9949e-02, -1.5354e-01, -6.9602e-04, -8.4299e-02,\n",
      "          -9.7754e-02,  4.0927e-02,  6.5094e-03,  7.2818e-02,  1.9672e-01,\n",
      "          -2.0426e-01, -1.5155e-01, -8.6696e-02,  1.8053e-01, -1.3023e-02,\n",
      "           2.7102e-01,  2.4272e-01, -2.6591e-01,  2.2417e-02, -7.1753e-02,\n",
      "          -1.6595e-01, -6.7694e-02, -3.4638e-02,  1.9608e-01,  1.5882e-01,\n",
      "           8.5476e-02, -5.2650e-03,  2.2659e-01, -7.2064e-02, -3.5027e-02,\n",
      "           2.1167e-01,  5.7228e-02, -2.8264e-02, -4.8782e-02,  1.5618e-02,\n",
      "           2.6836e-02,  1.3770e-01, -2.3038e-01,  1.9533e-01,  7.2208e-02,\n",
      "           1.5178e-01,  1.2108e-01,  3.0444e-01, -2.5678e-01,  2.6262e-01,\n",
      "          -2.2853e-01, -1.0412e-01, -8.6868e-02,  2.2483e-01, -2.7277e-03,\n",
      "           3.1120e-01,  1.2969e-01,  1.8316e-01, -2.0937e-04,  1.4464e-01,\n",
      "          -1.9822e-01, -1.7629e-01,  1.6620e-02,  1.4089e-01, -2.1031e-01,\n",
      "          -1.0462e-02, -1.5174e-01,  1.0055e-01, -2.0141e-03,  2.4568e-01,\n",
      "           3.7192e-02,  1.5227e-01,  8.1961e-02, -9.8092e-02,  2.7616e-02,\n",
      "           9.4156e-02,  3.1624e-01, -1.1487e-01,  1.3857e-01,  1.7973e-01,\n",
      "           2.6825e-02,  2.0064e-02, -2.2977e-01,  4.4567e-02,  1.5401e-01,\n",
      "          -1.5439e-01, -2.0623e-01, -6.0672e-02,  1.9136e-01, -2.4885e-01,\n",
      "          -1.0867e-01, -6.2636e-02,  1.6525e-01, -2.1079e-01,  1.0267e-01,\n",
      "           5.0976e-03,  6.9065e-02,  1.2286e-03, -2.1069e-01,  1.0135e-01,\n",
      "           7.6900e-02, -2.1474e-01,  7.2924e-02,  1.4253e-01, -1.2217e-02,\n",
      "          -9.1742e-02, -4.4438e-02,  2.3316e-02, -1.9007e-01,  1.4375e-01,\n",
      "           1.6746e-01,  1.9701e-02,  1.2964e-01,  1.6452e-01, -4.1147e-02,\n",
      "          -1.9301e-01,  1.2570e-01,  8.9991e-02, -2.2122e-01, -7.2965e-02,\n",
      "           1.2825e-01, -2.1410e-01,  3.2051e-01, -2.3969e-02, -7.5231e-02,\n",
      "           1.1772e-01,  1.3462e-01, -1.0290e-01, -4.0529e-01,  1.2172e-01,\n",
      "          -1.3386e-01, -3.8190e-01, -8.8318e-02, -1.3138e-01, -6.6417e-02,\n",
      "          -1.7915e-01, -3.0340e-01,  2.1827e-02,  1.5852e-01,  2.4897e-01,\n",
      "           1.1365e-01,  8.3251e-02, -1.0576e-01, -5.2840e-02,  7.1561e-02,\n",
      "          -2.1251e-01, -8.8301e-02, -3.2264e-02, -2.4107e-01, -1.5604e-01,\n",
      "           7.7812e-02, -8.2510e-02,  1.8434e-02, -2.7287e-02, -2.1213e-02,\n",
      "          -6.0580e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1546, -1.4809,  1.6542, -1.0093, -1.1129,  0.4009,  0.6459,\n",
      "           0.0000, -0.9020,  0.0943, -0.2105,  0.3158,  0.1259, -0.9576,\n",
      "          -0.3084,  0.3243, -1.8654, -2.1361,  0.6076, -0.5290,  0.7697,\n",
      "           0.2831, -1.2572, -0.9726,  0.0000,  1.4258, -1.6558,  1.0545,\n",
      "           0.9843, -1.2889,  0.3065, -0.9454, -0.7688, -1.5227, -0.3681,\n",
      "           0.4837, -0.9886,  0.0000,  0.3281,  0.6278,  0.6074, -1.1763,\n",
      "           0.3724,  1.2540, -1.7947,  1.9481, -1.4985, -0.4424, -0.2787,\n",
      "           1.1461,  0.8644,  0.0354,  0.0000, -1.0043, -0.2964,  0.0000,\n",
      "          -1.8690,  0.5102,  1.5725,  2.0570, -0.8823, -0.7339,  1.9472,\n",
      "          -0.9057, -0.8592,  0.1079,  0.6386, -0.6167,  0.0201,  0.4298,\n",
      "          -1.5889, -0.0277, -0.6440,  1.4263,  0.0000,  0.5574, -3.6193,\n",
      "          -0.6178, -1.4061, -0.3102,  0.0000,  1.3116,  0.8809, -0.9602,\n",
      "           0.6946,  0.6943,  0.0461, -2.9891,  0.8146, -0.0184, -1.4902,\n",
      "           0.3245, -1.2888,  2.3923,  1.8839,  0.2150, -1.1106,  1.0774,\n",
      "           1.5503, -2.1244,  0.0142, -0.6630,  0.0000, -1.8831,  0.4069,\n",
      "           1.4168, -1.9889, -0.9156,  0.4130,  1.8161, -1.4320,  0.1788,\n",
      "          -0.4970,  1.2997, -0.1464, -0.1102,  0.3375,  0.0000,  0.8514,\n",
      "          -1.2943,  0.0000, -0.0992,  0.0000,  0.5349,  0.2248,  0.0000,\n",
      "          -0.2034, -1.0702,  0.0000, -0.4276, -1.2483,  2.3284,  0.0000,\n",
      "           0.3275, -0.0094, -0.6382, -0.0640, -0.5992, -0.4515,  0.0000,\n",
      "           0.5454, -1.1797, -2.2946, -0.8852,  0.2167, -0.1875,  0.9173,\n",
      "          -0.0829,  1.5434, -0.7187,  0.3219, -1.3512,  0.0000, -1.9307,\n",
      "           0.5127, -0.3339, -0.2291, -0.7580,  0.9342, -0.0182,  0.2297,\n",
      "           0.0000,  2.2614, -1.7643, -0.3897, -0.6916,  0.5296,  2.1351,\n",
      "          -1.6401,  0.0000,  1.2532, -2.0849, -0.0058, -1.1597,  0.0000,\n",
      "          -0.7981, -0.3057, -0.4302,  0.1176,  0.0000,  0.1503,  0.0000,\n",
      "           0.1989,  0.9699,  0.4837, -0.0759, -1.5015,  0.0000,  0.4031,\n",
      "          -1.4620,  1.0707,  0.6060,  0.5036, -0.5077,  0.7244, -0.0432,\n",
      "           1.8719,  0.0433, -0.8384, -0.2755,  0.1187, -0.2976,  0.2834,\n",
      "           0.3539, -0.0090, -0.7144,  0.6960,  2.0160, -0.7490,  0.0000,\n",
      "           2.7888,  0.0000,  1.5050,  0.1008, -0.5908,  0.0000, -0.1422,\n",
      "           0.0000,  0.0000,  0.6369, -0.6888,  1.8591,  0.6068,  0.4732,\n",
      "           0.0296,  1.5296, -0.3648, -0.2609,  0.8421, -0.2541,  0.7770,\n",
      "          -0.5509,  1.2381,  0.0929,  2.0768,  0.5536, -1.7043,  2.7776,\n",
      "          -1.4946,  1.8031, -0.8491,  0.2572, -1.0494, -0.8529,  0.1357,\n",
      "          -1.7790,  0.3811,  1.9829,  0.5693,  0.5471, -1.7501,  0.3681,\n",
      "           0.1557,  1.5689, -2.7253,  0.4069]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0389, 0.1305, 0.1482, 0.0558, 0.1409, 0.1747, 0.0638, 0.0565, 0.1050,\n",
      "         0.0856]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1702, -0.0968, -0.1470,  0.0536, -0.1228,  0.1791, -0.2391,\n",
      "          -0.2711,  0.0102,  0.1193,  0.0240, -0.1697,  0.0828, -0.0825,\n",
      "           0.1643,  0.3170,  0.0732, -0.0343, -0.1987, -0.0518, -0.2677,\n",
      "          -0.1016, -0.0064, -0.0671, -0.0317,  0.0130,  0.0541,  0.0039,\n",
      "          -0.1789, -0.1164,  0.0264, -0.0047,  0.0287,  0.1200,  0.0425,\n",
      "          -0.1030, -0.1662,  0.1189, -0.1432, -0.1340,  0.0571,  0.1421,\n",
      "           0.0570, -0.1440,  0.1534,  0.0391, -0.0987, -0.1291,  0.2018,\n",
      "          -0.0273, -0.2427, -0.3146,  0.0604, -0.0692, -0.2996, -0.0794,\n",
      "          -0.2013,  0.2831, -0.0690,  0.0350,  0.0006,  0.0125,  0.0215,\n",
      "           0.0491,  0.2316,  0.0372,  0.0841, -0.1786,  0.0463, -0.2388,\n",
      "           0.2507,  0.2707,  0.0352, -0.0547, -0.1382, -0.0853,  0.2779,\n",
      "           0.0628,  0.0067, -0.0236, -0.2121,  0.0609, -0.0877,  0.0482,\n",
      "           0.1592,  0.1183,  0.1049,  0.1711, -0.1472, -0.0121,  0.1468,\n",
      "           0.1387, -0.0630, -0.2300,  0.0744,  0.2636,  0.0724,  0.2179,\n",
      "          -0.0811,  0.1208,  0.1533, -0.1001,  0.2101,  0.1735,  0.0659,\n",
      "          -0.1744, -0.0588, -0.1032, -0.0574, -0.0405, -0.0492,  0.0429,\n",
      "           0.0041,  0.0304,  0.1710, -0.1612, -0.0613, -0.1081,  0.0870,\n",
      "          -0.0615,  0.2808,  0.1193, -0.2065,  0.0296, -0.0995, -0.1749,\n",
      "          -0.0261,  0.0046,  0.2682,  0.1396,  0.0540, -0.0082,  0.2146,\n",
      "          -0.0600, -0.1162,  0.1325,  0.1425, -0.0104, -0.0258, -0.0151,\n",
      "          -0.0019,  0.1845, -0.1871,  0.2124,  0.0533,  0.1041,  0.1890,\n",
      "           0.3528, -0.2197,  0.1865, -0.3008, -0.1359, -0.0452,  0.2465,\n",
      "          -0.0261,  0.2530,  0.0718,  0.2158, -0.0102,  0.1593, -0.1900,\n",
      "          -0.1000, -0.0605,  0.2112, -0.2204, -0.0290, -0.1187,  0.0887,\n",
      "           0.0338,  0.2894,  0.0014,  0.1561,  0.0701, -0.0126,  0.0427,\n",
      "           0.0958,  0.2659, -0.0410,  0.1737,  0.1509,  0.0084,  0.0310,\n",
      "          -0.2277,  0.0121,  0.1418, -0.1009, -0.1793, -0.0455,  0.1444,\n",
      "          -0.2266, -0.0853, -0.0159,  0.0791, -0.1573,  0.0774, -0.0421,\n",
      "          -0.0019, -0.0432, -0.2456,  0.1218,  0.0239, -0.1198,  0.0900,\n",
      "           0.1875, -0.0289, -0.0420, -0.0901, -0.0095, -0.1871,  0.1084,\n",
      "           0.1727, -0.0129,  0.0750,  0.1863, -0.0073, -0.1574,  0.1393,\n",
      "           0.1319, -0.2929, -0.0365,  0.1487, -0.2047,  0.3543, -0.1144,\n",
      "          -0.0331,  0.1793,  0.1758, -0.0565, -0.4501,  0.1318, -0.1819,\n",
      "          -0.3659, -0.0362, -0.1273, -0.1378, -0.2389, -0.3310,  0.0213,\n",
      "           0.1829,  0.2087,  0.1381, -0.0116, -0.1534, -0.0080,  0.0681,\n",
      "          -0.1963, -0.1818, -0.0395, -0.2545, -0.1049,  0.0804, -0.0518,\n",
      "           0.0094, -0.0764, -0.0227, -0.0019]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7783, -1.6518,  0.0000, -0.7321,  2.5182, -1.9079,\n",
      "          -0.0322,  0.9501,  1.1946,  1.4102, -0.7570, -0.0650,  0.0643,\n",
      "           1.0464,  1.8848,  0.8699, -0.7846, -0.6402, -1.4033, -0.4984,\n",
      "          -0.3792,  1.1427,  0.2330,  0.1891, -0.6129,  1.4039, -0.1509,\n",
      "          -1.0407,  0.4962, -0.5713,  0.6010, -1.6986,  0.2317, -0.0795,\n",
      "           0.1484,  0.6450,  0.0000,  1.0517,  0.1023, -0.6919, -0.4360,\n",
      "          -1.0640,  0.8179, -0.6326, -0.6561,  1.3725,  0.9364,  1.6034,\n",
      "           0.0000, -1.0082,  0.0000, -1.1125,  1.2530, -1.9745,  1.7089,\n",
      "           0.5930, -1.8923,  0.3414, -0.2939, -0.7703,  1.8691,  0.0000,\n",
      "           0.0000, -0.8353,  1.2344, -0.3573,  0.2900, -0.7529, -1.1645,\n",
      "           0.0000,  0.7806,  0.2706,  1.2050, -0.3984,  0.3549,  0.0000,\n",
      "          -0.1575, -0.9149,  0.2960, -0.1448,  1.2864,  0.4653,  1.2970,\n",
      "           0.7706,  0.6607,  1.0454,  0.0000, -1.2411, -1.4363,  1.3105,\n",
      "          -1.5854, -0.1111,  0.0000,  0.3468,  1.0034, -0.8684,  0.7313,\n",
      "          -1.6815, -0.9244,  0.0000,  0.0287, -0.5966,  1.0584,  0.0000,\n",
      "           0.7758, -0.9058, -0.3679,  0.0000, -0.5476, -0.1380, -3.2785,\n",
      "          -0.1009, -1.8785,  0.0000,  1.6882,  2.0294, -1.6459, -0.8964,\n",
      "           2.5842, -1.3262,  1.4237, -0.6274,  0.4670,  1.3157, -0.9868,\n",
      "           0.0736, -0.9854, -0.6748,  0.2474, -1.2009,  1.1298,  1.1406,\n",
      "           1.4884,  0.3787,  0.6466, -0.8380,  0.2416,  0.3445, -1.2616,\n",
      "           0.0306,  0.8638,  0.5016,  0.9069, -1.2681, -0.6408, -0.4416,\n",
      "           0.8728,  0.0000,  0.0426, -0.0565,  0.6208,  0.1452, -0.1962,\n",
      "           0.1078, -1.6722, -0.4025,  0.2513, -2.0697,  0.4120,  1.1555,\n",
      "           0.1994,  0.9130,  0.8434,  0.4177,  1.6039,  0.1772, -1.1143,\n",
      "          -0.3224,  0.2511,  0.4444, -0.4550,  0.4446, -1.3452,  1.7354,\n",
      "           0.5173,  1.1775,  0.2898, -1.8322, -1.8661,  0.2594,  0.0000,\n",
      "           0.0000,  0.3290, -0.7441,  0.5921, -1.2414, -1.5174, -2.3036,\n",
      "           0.1466, -1.6242, -1.3208, -0.0497,  1.2995,  0.9801, -1.4146,\n",
      "           0.0000,  3.0139, -0.2259,  1.0331,  0.0290,  0.1194, -1.3192,\n",
      "          -1.0708,  0.0000,  1.7330,  0.5271,  1.9821, -0.9787, -1.3423,\n",
      "           1.5992, -0.4015,  2.4607, -0.5199,  0.7545,  0.2065, -0.8208,\n",
      "           0.9060, -3.5298,  0.1758, -0.7814, -0.6932, -1.4188,  0.2511,\n",
      "          -0.0645, -1.4654,  0.4266, -0.5196,  0.0465, -0.6251, -0.0712,\n",
      "           0.7484, -2.0270, -1.0490, -0.4312,  0.0000,  0.5161, -2.7968,\n",
      "          -1.4577, -0.6645,  1.0260,  0.1329,  2.7508,  1.0027,  0.5472,\n",
      "          -0.1735, -1.5056,  2.2320,  1.1873, -0.0479,  0.7226,  0.1089,\n",
      "          -2.8553, -0.0138, -0.8380, -0.5807]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0514, 0.1655, 0.1003, 0.1173, 0.0888, 0.0941, 0.0944, 0.0843, 0.1082,\n",
      "         0.0959]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9075e-01, -6.7412e-02, -1.9664e-01,  3.8915e-02, -1.1653e-01,\n",
      "           2.0603e-01, -1.9393e-01, -2.8755e-01,  1.2614e-02,  8.7039e-02,\n",
      "           9.7199e-02, -1.4918e-01,  7.4754e-02, -8.6661e-02,  1.9378e-01,\n",
      "           2.8916e-01,  1.0482e-01, -6.0949e-02, -2.0511e-01, -8.1961e-02,\n",
      "          -2.2741e-01, -1.0582e-01,  2.6819e-03, -7.0308e-02, -3.1536e-02,\n",
      "           3.6509e-02,  5.3392e-02,  2.4743e-04, -1.3945e-01, -7.5631e-02,\n",
      "           2.1981e-02, -1.4430e-02,  5.0170e-03,  8.0774e-02,  5.4057e-03,\n",
      "          -9.9403e-02, -1.3707e-01,  1.0079e-01, -1.4150e-01, -9.7486e-02,\n",
      "           3.9687e-02,  1.1015e-01, -7.0080e-03, -1.4382e-01,  1.2309e-01,\n",
      "           9.1632e-02, -1.0965e-01, -1.2712e-01,  2.1457e-01, -1.9666e-02,\n",
      "          -1.7078e-01, -3.1693e-01,  6.3892e-02, -3.7702e-02, -2.5595e-01,\n",
      "          -9.0699e-02, -1.6632e-01,  2.8323e-01, -3.1578e-03,  2.5806e-03,\n",
      "           2.9336e-02,  1.0781e-02, -4.0213e-02,  4.3616e-02,  2.4599e-01,\n",
      "           1.7065e-02,  8.6974e-02, -8.6006e-02, -8.2951e-03, -1.6192e-01,\n",
      "           1.9497e-01,  2.6219e-01,  7.7135e-02, -5.9233e-02, -1.5018e-01,\n",
      "          -1.0176e-02,  2.4377e-01,  8.4541e-02, -1.7315e-02,  2.7317e-02,\n",
      "          -2.0950e-01,  8.2216e-02, -1.2842e-01,  7.2579e-02,  1.2707e-01,\n",
      "           1.3121e-01,  1.0398e-01,  2.0266e-01, -1.5316e-01,  1.4205e-02,\n",
      "           1.2288e-01,  1.3754e-01, -3.2458e-02, -2.0632e-01,  6.4769e-02,\n",
      "           2.4868e-01,  7.7297e-02,  2.3622e-01, -7.3379e-02,  1.3463e-01,\n",
      "           1.4970e-01, -8.3704e-02,  1.4166e-01,  1.9800e-01,  8.6383e-02,\n",
      "          -1.9251e-01, -4.2007e-02, -4.7265e-02, -5.6342e-02, -1.6192e-02,\n",
      "          -2.4804e-02,  4.4150e-02,  4.9780e-03, -2.1012e-02,  1.5264e-01,\n",
      "          -1.4676e-01, -4.2414e-02, -9.6427e-02,  3.0474e-02, -7.7266e-02,\n",
      "           2.5696e-01,  2.7001e-02, -1.8931e-01,  1.7236e-02, -1.1568e-01,\n",
      "          -1.5387e-01,  8.0638e-03,  3.6481e-02,  2.2812e-01,  1.2657e-01,\n",
      "           6.1157e-02,  1.5022e-02,  1.8790e-01, -4.6259e-02, -9.2879e-02,\n",
      "           9.7092e-02,  1.3654e-01, -1.3491e-02, -3.3609e-02, -4.7432e-02,\n",
      "          -5.7172e-02,  2.0572e-01, -1.7073e-01,  1.7065e-01,  5.1487e-02,\n",
      "           9.1702e-02,  1.9199e-01,  3.5856e-01, -1.7324e-01,  1.8236e-01,\n",
      "          -3.0121e-01, -1.3937e-01, -5.6386e-02,  2.1504e-01, -2.8059e-02,\n",
      "           2.3873e-01,  1.3762e-02,  1.9027e-01, -4.9324e-02,  1.3501e-01,\n",
      "          -1.6046e-01, -6.9915e-02, -1.0765e-01,  2.7292e-01, -2.6535e-01,\n",
      "          -4.4448e-03, -8.3483e-02,  8.1635e-02,  4.1792e-02,  2.5581e-01,\n",
      "          -1.5109e-02,  1.4554e-01,  5.0916e-02,  2.7995e-02,  1.8210e-02,\n",
      "           2.8381e-02,  2.7290e-01,  1.4075e-02,  1.6636e-01,  1.4692e-01,\n",
      "          -2.3264e-03,  6.1267e-03, -2.1294e-01, -9.0659e-03,  1.1976e-01,\n",
      "          -7.2917e-02, -1.8110e-01, -4.0593e-02,  1.1684e-01, -1.9988e-01,\n",
      "          -5.8108e-02,  4.2697e-02,  4.1008e-02, -1.2466e-01,  8.0187e-02,\n",
      "          -9.5503e-02, -3.7196e-02, -4.9229e-02, -2.3687e-01,  1.2216e-01,\n",
      "           4.5586e-03, -5.3493e-02,  8.2287e-02,  2.0926e-01, -3.9477e-02,\n",
      "          -5.1980e-02, -1.3862e-01, -2.2233e-02, -1.9983e-01,  1.0100e-01,\n",
      "           1.4478e-01, -2.9582e-02,  7.2182e-02,  2.1329e-01, -3.4432e-04,\n",
      "          -1.4459e-01,  1.4089e-01,  1.3856e-01, -3.1804e-01, -4.7581e-02,\n",
      "           1.3839e-01, -1.9207e-01,  3.5193e-01, -1.6602e-01,  1.6649e-02,\n",
      "           1.7997e-01,  1.6132e-01, -2.9933e-02, -4.6228e-01,  1.2626e-01,\n",
      "          -1.7330e-01, -3.5495e-01, -5.2380e-02, -9.4761e-02, -1.8002e-01,\n",
      "          -2.2399e-01, -3.5659e-01,  3.5433e-02,  2.0761e-01,  1.7312e-01,\n",
      "           1.3815e-01, -1.0883e-01, -1.8064e-01,  4.1652e-02,  5.4814e-02,\n",
      "          -1.9609e-01, -2.0376e-01, -5.0340e-02, -2.4509e-01, -1.2110e-01,\n",
      "           5.4258e-02, -4.7554e-02, -1.0575e-02, -1.1458e-01, -4.7256e-03,\n",
      "           4.3861e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2023,  0.0000, -0.3715,  0.7879,  0.4715,  1.8660, -1.0208,\n",
      "          -0.8476,  0.3689,  0.5325, -0.9851,  1.2016, -0.3075,  0.0000,\n",
      "          -0.1010, -0.7596,  2.1565,  1.2313, -1.5359,  0.0609, -0.2341,\n",
      "           0.0000,  0.4175, -0.1859,  0.0000,  0.0000,  0.4487,  3.6947,\n",
      "           1.0316,  0.0000, -0.2251,  0.0987,  2.3923, -1.5308, -0.5280,\n",
      "           1.7472, -1.5024, -0.3227, -0.6053,  0.4449,  0.1858, -2.4734,\n",
      "          -0.1901,  1.5004, -0.4748,  1.5317, -0.1796, -0.9619,  0.1169,\n",
      "           1.0846, -1.8565, -0.4871, -1.9576, -1.2830, -0.9112,  0.0000,\n",
      "           0.2746,  1.2873, -1.6721, -0.6662, -0.4063,  1.1925, -3.1656,\n",
      "           0.3014,  0.4123, -0.4140,  0.3684, -1.3518,  0.0568,  0.8701,\n",
      "           0.0000, -0.1818,  0.2848,  0.0000,  0.5149,  0.0420,  2.4232,\n",
      "          -0.3317, -0.1011,  0.0000,  0.2869,  0.5110,  1.6037,  0.0000,\n",
      "           0.2532,  0.0158,  1.0137,  0.0000,  0.0000,  0.8415,  0.0000,\n",
      "           0.0000,  0.8190,  1.1406,  0.6380,  0.0789, -0.5907,  0.6997,\n",
      "          -0.0169, -0.0324,  0.0000, -1.9018, -0.8351, -0.6408,  0.4033,\n",
      "           1.0646, -1.9098,  0.7466,  0.8569,  0.0000, -0.2275,  0.4934,\n",
      "          -0.3824, -0.5130, -0.6341,  0.1632, -1.3454, -1.2769,  0.7330,\n",
      "          -1.8665, -1.7915,  1.2258, -2.5863, -0.2438, -0.9742,  0.0000,\n",
      "          -0.8379,  1.7398, -0.1670,  0.9374, -0.3571, -0.2684, -0.0378,\n",
      "           0.9894,  0.9909,  1.1838, -0.5810,  0.5580, -1.1121,  0.7497,\n",
      "           1.5485,  0.2589,  0.3462, -1.3684,  1.0405,  0.0000, -0.0916,\n",
      "          -0.4321, -1.1963, -1.6152, -1.2281,  0.5721,  0.3945, -0.5528,\n",
      "           0.8256,  0.7814, -1.4050, -0.9897, -0.2250,  0.2145,  0.3581,\n",
      "           0.0000, -0.4257, -0.1589, -0.9458,  0.4526, -0.1307,  0.2063,\n",
      "           0.5829,  0.9521,  1.8289,  0.0484,  0.0000,  0.5464,  0.7459,\n",
      "           0.9946,  0.0000, -0.4217, -1.0165,  0.0000,  0.5154, -1.5042,\n",
      "           0.0000, -1.8609,  0.3887, -1.5736,  0.9383, -0.1945, -0.2921,\n",
      "           0.9381, -1.5762,  0.2170,  1.1652, -1.6067, -0.1274,  0.8218,\n",
      "           0.4373,  0.0000, -0.3231, -0.4805, -0.8490,  0.0000, -0.4822,\n",
      "           1.9338,  0.0844,  0.2245,  0.0000,  0.8010, -0.7417, -1.0578,\n",
      "          -0.3480,  0.9096,  0.2632,  1.6315, -0.1271,  0.8623,  2.5083,\n",
      "          -1.8207, -0.1638,  0.6022, -0.4553, -0.3133,  1.6688,  0.6964,\n",
      "           0.0000, -0.9866, -1.9780,  0.0000, -0.1344, -0.2431,  1.5160,\n",
      "          -0.4308, -1.9444,  1.1555,  0.0000, -0.4438,  0.0000,  1.0507,\n",
      "           1.0977,  0.7435, -0.2205, -0.6855,  0.0152,  0.0000, -1.5405,\n",
      "          -2.9631, -0.4755, -0.9126, -0.4029, -0.0572,  0.4254,  1.5986,\n",
      "          -0.1676,  0.2199,  2.0293, -1.2109]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0598, 0.0990, 0.0955, 0.0763, 0.0628, 0.1419, 0.1003, 0.1043, 0.1231,\n",
      "         0.1370]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2050, -0.0568, -0.1758,  0.0433, -0.1399,  0.1517, -0.1716,\n",
      "          -0.2712, -0.0286,  0.0683,  0.0597, -0.1560,  0.0898, -0.0350,\n",
      "           0.2171,  0.2199,  0.0773, -0.0538, -0.2126, -0.0365, -0.2232,\n",
      "          -0.1160,  0.0364, -0.0760, -0.0353,  0.0442,  0.0739, -0.0183,\n",
      "          -0.1375, -0.1033,  0.0749, -0.0334, -0.0069,  0.0822,  0.0051,\n",
      "          -0.0805, -0.1228,  0.0737, -0.1389, -0.1092,  0.0171,  0.1032,\n",
      "           0.0112, -0.1364,  0.1370,  0.0992, -0.0960, -0.1582,  0.1877,\n",
      "          -0.0820, -0.1952, -0.2775,  0.0119, -0.0519, -0.2127, -0.1058,\n",
      "          -0.2001,  0.2315, -0.0750,  0.0285,  0.0304,  0.0535, -0.0155,\n",
      "           0.0705,  0.1856,  0.0265,  0.0529, -0.0667, -0.0175, -0.1328,\n",
      "           0.1808,  0.2555,  0.0820, -0.0095, -0.1590, -0.0371,  0.2534,\n",
      "           0.0919, -0.0183,  0.0410, -0.1752,  0.0601, -0.1228,  0.0789,\n",
      "           0.1323,  0.1459,  0.1154,  0.1822, -0.0995, -0.0058,  0.1429,\n",
      "           0.1352, -0.0626, -0.2098,  0.0247,  0.2142,  0.0603,  0.1522,\n",
      "          -0.0686,  0.1697,  0.1506, -0.1267,  0.1746,  0.2101,  0.0931,\n",
      "          -0.1456, -0.0164, -0.0524, -0.0183, -0.0199, -0.0173,  0.0497,\n",
      "           0.0285, -0.0200,  0.1258, -0.1615, -0.0782, -0.0647,  0.0440,\n",
      "          -0.0689,  0.2161,  0.0647, -0.2366,  0.0262, -0.1238, -0.1420,\n",
      "          -0.0034,  0.0181,  0.1825,  0.1267,  0.1023, -0.0173,  0.1842,\n",
      "          -0.0218, -0.0268,  0.1216,  0.1486, -0.0141, -0.0551, -0.0169,\n",
      "          -0.0286,  0.1988, -0.1929,  0.1874,  0.0473,  0.1133,  0.1526,\n",
      "           0.3228, -0.1598,  0.2563, -0.2901, -0.1248, -0.0995,  0.2239,\n",
      "          -0.0021,  0.2831,  0.0200,  0.1560, -0.0540,  0.0833, -0.1385,\n",
      "          -0.1326, -0.0787,  0.2399, -0.2250, -0.0110, -0.1154,  0.0683,\n",
      "           0.0412,  0.2235, -0.0210,  0.1105,  0.0790, -0.0137, -0.0007,\n",
      "          -0.0380,  0.2706,  0.0009,  0.1809,  0.1330, -0.0360, -0.0249,\n",
      "          -0.2293, -0.0224,  0.1244, -0.0831, -0.2001, -0.0416,  0.1200,\n",
      "          -0.2023, -0.0577,  0.0039,  0.0202, -0.1450,  0.0597, -0.0663,\n",
      "           0.0172, -0.0161, -0.2076,  0.1077,  0.0257, -0.0892,  0.0672,\n",
      "           0.1889, -0.0231, -0.0829, -0.1164,  0.0412, -0.1913,  0.0936,\n",
      "           0.0974, -0.0496,  0.0888,  0.1675, -0.0264, -0.1308,  0.0919,\n",
      "           0.0900, -0.2897, -0.0846,  0.1405, -0.1894,  0.3194, -0.1278,\n",
      "           0.0185,  0.1502,  0.1125, -0.0621, -0.4332,  0.1378, -0.1448,\n",
      "          -0.3460, -0.0953, -0.1103, -0.1208, -0.1808, -0.3320,  0.0223,\n",
      "           0.1855,  0.1694,  0.1164, -0.1149, -0.1662,  0.0155,  0.0645,\n",
      "          -0.1829, -0.1817, -0.0588, -0.1871, -0.1323,  0.0518, -0.0785,\n",
      "          -0.0268, -0.1071,  0.0151, -0.0023]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5703e+00, -1.4751e+00,  2.2745e-01, -7.8661e-02,  3.5238e-01,\n",
      "           5.5339e-01, -2.0057e-01,  2.0888e+00,  1.3115e+00,  0.0000e+00,\n",
      "           6.8458e-01,  2.1685e+00,  1.1879e+00, -8.0524e-01,  0.0000e+00,\n",
      "          -1.1277e+00,  1.9604e+00, -2.9119e-01,  8.2720e-03,  4.2644e-01,\n",
      "          -1.9755e+00, -1.8382e+00, -1.2584e+00,  1.9422e-01, -1.6712e-01,\n",
      "           1.3751e+00, -2.9798e-01, -9.7432e-01,  1.8410e+00,  7.8338e-01,\n",
      "           3.4917e-01,  3.1160e-01,  0.0000e+00,  9.4182e-01,  6.9771e-01,\n",
      "           4.5400e-01, -2.8991e+00,  6.8059e-02,  3.9824e-02,  0.0000e+00,\n",
      "          -7.2212e-01, -1.0137e+00,  2.4845e-01,  1.0036e+00,  6.6984e-02,\n",
      "           3.1140e-01, -1.0371e+00, -1.1820e+00, -4.4467e-01, -1.6405e+00,\n",
      "          -1.5658e+00,  3.1695e+00,  0.0000e+00,  7.6397e-01,  2.2063e+00,\n",
      "           5.5903e-01,  5.9273e-01,  5.6768e-01, -7.5497e-01,  4.1296e-01,\n",
      "           6.2635e-01, -7.1982e-01, -3.6499e-01,  8.9445e-01, -1.3380e+00,\n",
      "           2.3298e+00, -2.4166e+00,  9.2195e-02,  1.1603e+00, -7.1807e-01,\n",
      "           7.5202e-02,  5.5108e-01,  1.9009e-01,  0.0000e+00,  4.0837e-01,\n",
      "          -9.0035e-01, -4.8585e-01,  4.3276e-01,  0.0000e+00, -2.4957e+00,\n",
      "          -3.6230e+00,  4.0194e-01,  4.9731e-01, -3.8140e-01, -2.3205e+00,\n",
      "          -1.0348e+00, -6.3280e-01,  1.8182e+00, -1.9082e+00, -6.5412e-01,\n",
      "           0.0000e+00, -6.6939e-01, -1.9173e+00,  1.0181e+00, -1.3664e+00,\n",
      "          -1.1212e+00,  2.1693e-01,  0.0000e+00,  3.0395e-01,  7.6351e-01,\n",
      "           9.4168e-01,  9.3364e-01,  2.2417e-01,  0.0000e+00,  2.2438e+00,\n",
      "          -1.4415e-01,  1.2450e-01, -1.0132e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -1.5565e+00, -1.3434e+00,  1.5153e-01,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.7871e+00, -1.2154e-01, -1.8688e+00,  9.3966e-02,\n",
      "           6.7214e-01,  5.5195e-01,  1.5533e+00,  4.8422e-01,  1.2911e-01,\n",
      "           5.8249e-01,  0.0000e+00,  5.8465e-02,  3.9308e-01, -5.9777e-02,\n",
      "           0.0000e+00, -5.3673e-01,  7.0346e-01,  1.1584e+00,  3.2931e-01,\n",
      "          -2.5081e-01,  1.1895e-01, -1.3305e+00, -3.6606e-01, -7.7324e-01,\n",
      "          -5.9707e-01,  0.0000e+00,  0.0000e+00,  2.9508e-02,  5.0155e-01,\n",
      "           2.5936e-01,  1.2102e+00,  1.2552e+00,  0.0000e+00,  3.1603e-01,\n",
      "           7.8741e-02, -5.5373e-02, -7.0960e-01,  1.5831e+00,  1.2670e+00,\n",
      "           2.7976e-01,  1.1350e+00,  3.0538e-01,  2.6076e-01,  1.4424e+00,\n",
      "          -1.7490e-01,  6.8405e-01, -2.1221e-01, -7.2126e-01,  0.0000e+00,\n",
      "          -9.4138e-01,  3.2961e-01,  2.5654e-01,  1.7294e+00,  7.0260e-01,\n",
      "           3.1422e+00,  2.0557e+00,  5.6336e-01,  1.0298e-01, -3.9346e-01,\n",
      "          -9.6617e-01, -4.0504e-01,  1.1920e+00,  0.0000e+00, -1.5080e+00,\n",
      "          -1.3460e-01, -1.2934e-02, -6.0225e-01, -1.5680e+00, -1.8517e+00,\n",
      "           0.0000e+00,  6.9061e-03,  1.3398e+00,  1.2951e+00,  7.3882e-01,\n",
      "           9.6780e-01,  1.6020e-01, -5.3596e-01,  5.3552e-01, -4.7150e-02,\n",
      "          -1.2978e+00, -1.5639e+00,  3.1396e+00, -1.0838e+00, -4.6120e-02,\n",
      "           8.1000e-01, -2.1875e+00, -2.6965e+00,  1.4469e+00, -9.9694e-01,\n",
      "           9.7218e-01, -1.6693e+00, -6.1200e-01, -9.3246e-01, -1.1369e+00,\n",
      "           8.7218e-01,  7.9548e-02, -1.3190e+00, -7.9120e-01,  1.3114e+00,\n",
      "          -2.8295e-01,  1.3732e+00,  2.4502e-01, -2.3517e+00,  1.9031e+00,\n",
      "           1.0279e+00, -1.4199e+00,  1.7823e+00,  1.0654e+00, -5.7268e-01,\n",
      "          -5.7351e-01, -1.5896e+00,  1.5833e-03, -3.3770e-01, -2.9544e+00,\n",
      "          -6.4345e-01,  1.5655e+00,  9.3177e-02, -6.2735e-01,  1.6772e+00,\n",
      "           0.0000e+00, -2.1840e+00,  3.2571e-01,  1.5120e+00, -5.3505e-01,\n",
      "          -1.8332e+00, -1.1665e+00, -1.1106e-01,  1.4426e+00, -4.7775e-01,\n",
      "           1.4837e+00,  0.0000e+00,  7.7591e-01,  0.0000e+00, -2.5935e-01,\n",
      "           4.3559e-01,  3.1982e-01, -3.3691e-01,  1.6171e+00,  2.5967e-01,\n",
      "          -7.0434e-02]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0734, 0.1842, 0.0438, 0.1068, 0.1680, 0.0858, 0.0885, 0.0905, 0.0733,\n",
      "         0.0857]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.7899e-01, -1.2795e-01, -2.2370e-01,  3.1857e-02, -1.5484e-01,\n",
      "           2.1407e-01, -2.1962e-01, -3.1089e-01,  1.5859e-02,  6.4144e-02,\n",
      "           1.1151e-01, -1.4416e-01,  8.3164e-02, -9.3686e-02,  1.7442e-01,\n",
      "           3.1860e-01,  9.0744e-02, -2.0182e-02, -1.4912e-01, -5.7556e-02,\n",
      "          -2.2145e-01, -1.0221e-01, -2.4895e-03, -6.2756e-02, -2.6386e-02,\n",
      "           8.7991e-02,  4.9541e-02, -6.7887e-03, -1.4435e-01, -5.6146e-02,\n",
      "           3.4491e-02, -6.6691e-03,  2.2658e-02,  7.6498e-02,  2.6673e-02,\n",
      "          -1.5780e-01, -1.0711e-01,  1.5192e-01, -9.5063e-02, -8.5575e-02,\n",
      "           6.0036e-02,  1.1585e-01,  1.7239e-02, -1.7010e-01,  1.0088e-01,\n",
      "           7.5281e-02, -9.3304e-02, -1.2197e-01,  2.3111e-01, -3.3636e-02,\n",
      "          -1.7319e-01, -2.9915e-01,  5.1237e-02, -7.5770e-02, -2.9229e-01,\n",
      "          -8.4030e-02, -1.6894e-01,  2.7802e-01, -2.0839e-02, -1.2298e-02,\n",
      "           3.1050e-02, -3.5621e-02, -3.6350e-02,  4.8955e-02,  2.8275e-01,\n",
      "           4.2027e-02,  8.6127e-02, -1.0605e-01,  7.2030e-03, -1.9289e-01,\n",
      "           1.9776e-01,  2.5210e-01,  1.1506e-01, -1.1632e-01, -1.2380e-01,\n",
      "          -3.1672e-03,  2.4510e-01,  1.0188e-01, -8.6002e-03,  3.0653e-02,\n",
      "          -2.0029e-01,  1.1443e-01, -8.9918e-02,  5.6226e-02,  1.4343e-01,\n",
      "           1.2186e-01,  8.9773e-02,  1.8502e-01, -1.5762e-01,  4.4844e-04,\n",
      "           1.3382e-01,  1.4684e-01, -2.7537e-02, -2.0576e-01,  7.5960e-02,\n",
      "           2.6998e-01,  5.4704e-02,  2.3969e-01, -8.7194e-03,  1.0383e-01,\n",
      "           1.9002e-01, -6.4862e-02,  1.4414e-01,  2.0108e-01,  1.1915e-01,\n",
      "          -2.0824e-01, -7.6568e-02, -4.5490e-02, -6.6297e-02, -2.5460e-02,\n",
      "          -3.9649e-02,  5.3850e-02, -5.5301e-03, -1.6937e-02,  1.6400e-01,\n",
      "          -1.3480e-01, -6.5154e-02, -8.6596e-02,  4.3783e-02, -4.3190e-02,\n",
      "           2.7817e-01,  6.2699e-02, -1.7918e-01,  1.9984e-02, -9.9590e-02,\n",
      "          -1.4854e-01, -4.3389e-02, -1.4962e-02,  2.4583e-01,  1.0907e-01,\n",
      "           5.2499e-02,  3.8070e-02,  1.8721e-01, -3.7864e-02, -7.7128e-02,\n",
      "           1.4174e-01,  9.9679e-02, -2.9600e-03, -2.5066e-02, -6.2159e-02,\n",
      "          -5.7567e-02,  2.0898e-01, -2.3696e-01,  1.4948e-01,  6.2825e-02,\n",
      "           8.1412e-02,  1.8706e-01,  3.8455e-01, -1.8960e-01,  1.7948e-01,\n",
      "          -2.9556e-01, -1.0020e-01, -7.4127e-02,  1.9175e-01, -2.3406e-02,\n",
      "           2.4115e-01,  4.4674e-02,  2.0669e-01, -3.2612e-02,  1.5409e-01,\n",
      "          -2.0087e-01, -7.1872e-02, -1.2573e-01,  2.4025e-01, -3.1010e-01,\n",
      "           1.3486e-02, -8.8864e-02,  1.0585e-01,  1.5139e-02,  2.2246e-01,\n",
      "          -2.0032e-02,  2.0619e-01,  5.9360e-02,  9.2680e-04,  3.4465e-02,\n",
      "           6.9453e-02,  3.0955e-01, -2.8244e-02,  1.5808e-01,  1.5689e-01,\n",
      "           2.9661e-02,  3.9419e-02, -1.9559e-01,  2.7597e-02,  1.3733e-01,\n",
      "          -1.1795e-01, -1.9119e-01, -5.1978e-02,  1.0122e-01, -1.9093e-01,\n",
      "          -8.1628e-02,  5.8058e-02,  8.0826e-02, -1.3720e-01,  9.3953e-02,\n",
      "          -8.8062e-02, -5.1350e-02, -6.5049e-02, -2.4257e-01,  1.1120e-01,\n",
      "           2.8996e-02, -8.5523e-02,  8.6126e-02,  2.2109e-01, -7.2754e-02,\n",
      "          -5.5641e-02, -1.2290e-01, -3.4606e-02, -2.0012e-01,  1.1122e-01,\n",
      "           1.5734e-01,  8.7680e-03,  6.9823e-02,  2.5449e-01,  1.3643e-03,\n",
      "          -1.8666e-01,  1.6114e-01,  1.6852e-01, -2.8110e-01, -5.9659e-02,\n",
      "           1.5321e-01, -2.0132e-01,  3.6861e-01, -1.6201e-01, -1.9269e-02,\n",
      "           1.6400e-01,  1.7221e-01, -3.7556e-02, -4.5825e-01,  1.1021e-01,\n",
      "          -1.4844e-01, -3.7298e-01, -4.4088e-02, -5.6894e-02, -1.5708e-01,\n",
      "          -2.3754e-01, -3.5144e-01,  6.0646e-02,  2.3496e-01,  2.0151e-01,\n",
      "           1.3096e-01, -8.0840e-02, -1.3298e-01,  4.9536e-02,  5.0361e-02,\n",
      "          -1.9598e-01, -1.3815e-01, -5.4473e-02, -2.5847e-01, -1.2716e-01,\n",
      "           9.5182e-02, -3.4272e-02,  4.3837e-03, -1.0628e-01, -2.0017e-02,\n",
      "          -5.7716e-03]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.8080e+00, -5.2281e-01,  9.9696e-01, -9.1122e-02,  8.0508e-01,\n",
      "           9.7891e-01, -1.8015e+00,  0.0000e+00, -3.9305e-01, -6.3923e-01,\n",
      "          -4.3642e-01,  1.2693e+00,  0.0000e+00, -9.8424e-02,  1.2610e+00,\n",
      "           1.0131e+00,  2.4621e-01, -1.8152e+00,  9.5385e-01,  0.0000e+00,\n",
      "          -6.0530e-01,  0.0000e+00,  1.0611e+00, -8.1204e-02,  0.0000e+00,\n",
      "           1.2687e-01,  0.0000e+00, -8.7134e-04, -1.8634e-01,  2.0639e+00,\n",
      "          -9.4409e-01, -6.2335e-01, -8.0592e-01,  0.0000e+00,  9.7462e-01,\n",
      "           9.6675e-01, -1.0188e+00, -9.4793e-01,  2.4936e+00,  3.4790e-01,\n",
      "           1.5005e+00, -1.2680e+00, -6.4432e-01,  3.7341e-02, -3.0869e-01,\n",
      "           5.5965e-01,  2.0699e-01,  7.8602e-02,  4.3868e-01,  5.7516e-01,\n",
      "          -3.5416e-01,  1.2920e+00,  4.4509e-01,  1.0790e+00,  1.0529e+00,\n",
      "          -6.1718e-01, -7.4754e-01,  4.2727e-01, -1.6077e+00,  1.3506e+00,\n",
      "          -2.1785e+00, -1.7042e+00, -2.6779e-01,  9.8559e-01, -3.0092e+00,\n",
      "          -1.4842e+00,  2.8691e-03,  8.8062e-01, -8.3523e-01, -1.3171e-01,\n",
      "          -5.8812e-02,  4.7847e-01,  3.5232e-02, -4.3716e-01, -3.4775e-01,\n",
      "          -1.3496e+00,  0.0000e+00,  9.0009e-01,  0.0000e+00, -1.8684e-01,\n",
      "          -1.6289e+00,  0.0000e+00,  0.0000e+00,  4.4894e-01, -1.0581e+00,\n",
      "          -1.1322e+00,  3.3123e-02, -7.8620e-01,  4.1295e-01, -2.8992e-01,\n",
      "          -2.4774e+00,  4.2403e-01,  1.8360e+00, -2.4845e-01, -2.7647e-01,\n",
      "          -4.0601e-03, -1.9462e+00,  4.8253e-01,  7.6952e-02,  9.3621e-01,\n",
      "          -6.7947e-01, -8.0972e-01,  8.7173e-01, -1.3502e+00,  1.0824e+00,\n",
      "          -1.9756e-01,  9.6817e-01, -7.8588e-01, -5.1862e-01, -6.3555e-01,\n",
      "           1.0919e+00,  1.5895e+00,  4.6934e-01, -6.9186e-01,  0.0000e+00,\n",
      "          -1.1070e+00, -6.0287e-01,  7.8980e-01,  8.4113e-01, -1.4464e+00,\n",
      "           9.5589e-01,  5.1186e-01, -1.9084e+00, -3.9047e-01, -7.3633e-02,\n",
      "           0.0000e+00,  0.0000e+00,  1.1843e+00,  2.1908e-01,  1.0290e+00,\n",
      "          -7.8483e-01,  8.3284e-01,  6.4880e-01, -3.8306e-01,  2.1417e+00,\n",
      "          -2.8613e-01,  2.5862e+00, -7.8494e-01,  8.6293e-01,  2.8389e-01,\n",
      "           0.0000e+00, -6.1699e-01,  6.7484e-01, -7.0905e-01, -1.1251e+00,\n",
      "          -1.2016e+00,  0.0000e+00, -2.1383e-03,  8.7740e-01,  8.0912e-01,\n",
      "           1.7922e+00,  9.5743e-01,  9.9557e-01, -5.2808e-01,  0.0000e+00,\n",
      "          -6.7343e-01, -1.2646e+00,  3.9118e-01,  7.2309e-01, -2.0582e+00,\n",
      "          -8.9045e-01,  1.2306e+00, -1.0853e+00, -8.6229e-02,  2.8449e-01,\n",
      "           0.0000e+00, -3.6225e-01,  5.8404e-01,  4.7796e-01,  2.9890e-01,\n",
      "          -1.9847e+00,  3.5883e-01,  1.1839e+00, -1.8167e+00, -1.6615e+00,\n",
      "           8.2713e-01, -2.0324e+00, -1.1484e+00, -1.6294e-01, -1.0228e+00,\n",
      "           7.7903e-01, -2.1569e-01, -3.0908e-01,  1.8127e-01,  7.4815e-01,\n",
      "           7.4795e-01, -2.5948e-01,  1.7883e-01, -1.4154e+00,  2.7857e-01,\n",
      "           1.5771e+00,  5.6060e-01, -2.1478e+00, -1.2114e+00,  2.9404e+00,\n",
      "           1.4773e-01, -2.0066e-01, -3.1040e-01, -9.2190e-02, -8.3721e-01,\n",
      "          -1.6186e+00,  9.1453e-01,  1.0162e+00,  1.6940e+00,  5.4440e-02,\n",
      "           9.5869e-01,  6.6771e-01,  5.4355e-01, -9.3189e-01, -1.5256e+00,\n",
      "           1.0123e+00,  6.7120e-01,  4.6847e-01, -1.0841e+00, -4.1507e-01,\n",
      "          -6.6289e-01,  0.0000e+00,  5.9290e-01,  1.3801e+00, -1.1348e+00,\n",
      "           0.0000e+00, -1.0757e+00, -1.3857e+00,  1.3255e-01, -1.1518e+00,\n",
      "          -1.5345e+00, -6.3676e-01,  1.4867e-01,  0.0000e+00, -7.7456e-01,\n",
      "           1.2033e+00,  0.0000e+00,  0.0000e+00,  4.7065e-01,  0.0000e+00,\n",
      "           2.8271e+00, -1.6093e-01, -8.6638e-01,  0.0000e+00,  1.1099e+00,\n",
      "          -4.6952e-01, -8.9650e-01, -1.1482e-01,  6.5620e-01,  1.0481e+00,\n",
      "           2.3664e-01,  0.0000e+00, -1.2619e-01,  3.2215e-02,  8.5205e-02,\n",
      "          -3.7621e-01, -4.6662e-01,  6.5850e-01,  2.4090e+00,  2.4293e+00,\n",
      "          -4.8684e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0534, 0.0730, 0.0643, 0.1293, 0.1388, 0.1528, 0.0494, 0.1492, 0.0873,\n",
      "         0.1024]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1642, -0.1449, -0.1960,  0.0248, -0.1858,  0.1499, -0.2100,\n",
      "          -0.3144,  0.0005,  0.0155,  0.0779, -0.1223,  0.0830, -0.0386,\n",
      "           0.2024,  0.2700,  0.0576, -0.0186, -0.2064, -0.0151, -0.2287,\n",
      "          -0.1389,  0.0590, -0.1309, -0.0212,  0.0581,  0.0750, -0.0050,\n",
      "          -0.1670, -0.0767,  0.0850, -0.0263,  0.0021,  0.0860,  0.0388,\n",
      "          -0.1473, -0.1835,  0.1360, -0.1559, -0.0890,  0.0473,  0.1121,\n",
      "           0.0502, -0.1412,  0.0974,  0.0929, -0.0973, -0.1565,  0.2224,\n",
      "          -0.0958, -0.2035, -0.3006,  0.0219, -0.1149, -0.2641, -0.1155,\n",
      "          -0.1872,  0.2423, -0.0831,  0.0271,  0.0569,  0.0040,  0.0109,\n",
      "           0.0815,  0.2201,  0.0372,  0.0923, -0.0842,  0.0211, -0.1585,\n",
      "           0.2246,  0.2243,  0.0832, -0.0363, -0.1536, -0.0371,  0.2604,\n",
      "           0.1183,  0.0368,  0.0145, -0.1734,  0.0850, -0.0900,  0.0429,\n",
      "           0.1825,  0.1586,  0.1496,  0.1694, -0.1109,  0.0376,  0.1401,\n",
      "           0.0950, -0.0410, -0.2059,  0.0445,  0.2730,  0.0501,  0.1760,\n",
      "          -0.0343,  0.1540,  0.1581, -0.1145,  0.1922,  0.2000,  0.1434,\n",
      "          -0.1769, -0.0241, -0.0266, -0.0269, -0.0313, -0.0712,  0.0675,\n",
      "           0.0178, -0.0144,  0.1637, -0.1671, -0.1360, -0.0911,  0.1026,\n",
      "          -0.0543,  0.2641,  0.1293, -0.2558,  0.0320, -0.1241, -0.1476,\n",
      "          -0.0295, -0.0484,  0.2123,  0.1034,  0.0763, -0.0154,  0.2135,\n",
      "          -0.0211, -0.0477,  0.1504,  0.0765, -0.0093, -0.0499, -0.0135,\n",
      "          -0.0478,  0.2000, -0.2225,  0.1622,  0.0896,  0.0893,  0.1577,\n",
      "           0.3376, -0.1856,  0.2463, -0.2980, -0.0561, -0.0967,  0.2202,\n",
      "           0.0088,  0.3080,  0.0747,  0.1935, -0.0234,  0.1366, -0.1791,\n",
      "          -0.1343, -0.1174,  0.2483, -0.2909,  0.0114, -0.0994,  0.0436,\n",
      "          -0.0134,  0.2206, -0.0126,  0.1497,  0.0679, -0.0149,  0.0100,\n",
      "           0.0265,  0.3022, -0.0511,  0.1507,  0.1278, -0.0041,  0.0303,\n",
      "          -0.2234,  0.0235,  0.1636, -0.1041, -0.2113, -0.0282,  0.1614,\n",
      "          -0.2538, -0.0703,  0.0314,  0.0850, -0.1692,  0.1149, -0.0878,\n",
      "           0.0311, -0.0027, -0.2102,  0.0932,  0.0490, -0.1182,  0.0262,\n",
      "           0.1801, -0.0214, -0.1126, -0.0936,  0.0388, -0.2022,  0.0803,\n",
      "           0.1421, -0.0151,  0.1115,  0.2197, -0.0316, -0.1733,  0.1574,\n",
      "           0.1524, -0.2674, -0.0556,  0.1439, -0.2132,  0.3477, -0.0925,\n",
      "          -0.0144,  0.1627,  0.1464, -0.1163, -0.4509,  0.1228, -0.1511,\n",
      "          -0.3822, -0.0959, -0.1272, -0.1248, -0.1862, -0.3242,  0.0386,\n",
      "           0.2312,  0.2466,  0.0920, -0.0216, -0.1600,  0.0140,  0.0973,\n",
      "          -0.2216, -0.1163, -0.0828, -0.2404, -0.1777,  0.0938, -0.0404,\n",
      "          -0.0140, -0.0890,  0.0135, -0.0118]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.5256, -2.0607, -1.2199, -0.0505,  0.1061,  0.5891,  0.2238,\n",
      "           0.4854, -0.8762, -0.3505, -0.4517, -0.3706,  0.2670,  0.2643,\n",
      "           1.1536, -0.9325,  0.2347,  0.6379,  0.3195,  0.1214, -0.9001,\n",
      "          -1.5587,  0.0000,  1.9364,  1.1132,  0.8858,  0.0000,  1.1807,\n",
      "           0.3943,  3.8465, -2.4708,  0.0000, -0.8854,  1.3479, -0.3061,\n",
      "          -0.4142,  0.2816, -0.7962,  0.6691, -2.2861,  1.5056, -0.6473,\n",
      "           0.0000, -1.5493,  0.5092,  0.0000,  0.1321,  0.2878,  0.5549,\n",
      "          -1.1211,  0.5370, -0.3246, -0.4431,  2.8998, -0.0915,  1.2615,\n",
      "          -1.8157, -0.6670, -0.1905,  0.9219,  3.3492,  0.0000,  1.3118,\n",
      "          -0.4432,  0.2157, -0.3718, -1.7705, -1.8204, -0.0644, -1.4523,\n",
      "          -0.9729,  0.0000,  0.0000,  0.2727,  0.0000, -0.1053,  1.2333,\n",
      "          -0.1782,  1.1886, -0.3455,  0.2540, -0.0157,  0.0482,  1.3485,\n",
      "          -0.0919,  0.0000, -0.0378, -1.2290, -0.7182, -0.5515,  0.3123,\n",
      "           0.2910,  0.0000, -1.9777, -0.3220, -0.0572,  0.0000, -0.8920,\n",
      "           0.0000,  1.0998,  1.3075,  0.4732,  4.1068,  0.7968,  0.9062,\n",
      "           0.1797,  0.0000, -0.4613, -0.7488, -1.3485,  1.7867,  0.6538,\n",
      "           0.0000, -1.3974,  0.0231,  1.2552,  1.0173,  0.0000,  2.6897,\n",
      "          -2.3133,  1.4689, -0.7871,  1.1695,  0.5497, -0.7035, -0.8365,\n",
      "          -0.0437,  2.7590, -0.3720, -1.4577, -0.5376,  0.0000,  0.3861,\n",
      "           2.2464,  0.0531,  0.2223,  1.6544, -0.7722,  0.0000, -0.2761,\n",
      "          -1.0227,  0.2490,  1.7291, -2.0651,  0.6233, -0.5220,  1.5557,\n",
      "           1.1534, -0.4160, -0.1229, -0.9402, -0.9883, -0.6044, -0.0816,\n",
      "           0.6719,  0.0000, -1.0146, -0.3231,  0.1042,  0.9383,  0.6930,\n",
      "          -0.4695, -0.2876,  0.5987, -1.5337,  0.9151,  0.7505,  1.6087,\n",
      "          -1.2059, -2.6986,  0.1455, -0.4822,  1.0243, -1.0262, -0.6829,\n",
      "           2.7124, -0.3884, -0.2028, -1.1382, -0.4367,  0.0000,  1.2941,\n",
      "           0.7404,  0.6457, -2.3418,  0.3245,  1.6566, -1.8793,  0.6852,\n",
      "           1.0696, -0.1883,  0.3234, -1.5545,  0.5398, -1.1002, -0.3413,\n",
      "          -0.3604,  0.3461,  0.0917,  0.0000,  1.4372,  0.2411, -1.1510,\n",
      "           0.6123,  0.9138,  0.7949,  0.1033, -0.2968,  0.0000,  0.1514,\n",
      "           0.8093,  0.0000,  0.0000,  0.3044,  1.5482,  0.5874, -2.7274,\n",
      "          -0.9208, -1.2349,  0.3479,  1.0471, -0.7772,  1.1999,  0.7222,\n",
      "          -0.0621, -0.4361,  1.3137,  0.0000,  0.5704, -0.8642,  1.9288,\n",
      "          -1.1688,  0.2351, -1.3321, -0.7689, -0.5350, -1.2934, -1.1777,\n",
      "          -0.0879, -0.9945, -1.2108,  1.2546, -1.1848,  0.0723,  0.6952,\n",
      "          -2.5281, -0.0098,  1.8063,  0.4248,  0.0323, -1.5317,  0.0000,\n",
      "           0.5965, -1.5532, -1.4292,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0621, 0.0829, 0.0813, 0.1327, 0.0989, 0.1441, 0.1653, 0.1277, 0.0694,\n",
      "         0.0356]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0401e-01, -1.1976e-01, -2.0167e-01,  6.7524e-02, -1.8099e-01,\n",
      "           2.0755e-01, -1.7738e-01, -3.1020e-01, -2.9367e-02,  6.1746e-02,\n",
      "           8.4175e-02, -1.1639e-01,  1.4525e-01, -2.8794e-02,  2.3752e-01,\n",
      "           2.6384e-01,  9.0785e-02, -7.7014e-02, -1.9417e-01, -2.1531e-02,\n",
      "          -2.3888e-01, -1.1645e-01,  5.0259e-02, -1.4590e-01, -7.8197e-03,\n",
      "           8.9610e-02,  1.0560e-01, -8.3718e-04, -1.5010e-01, -1.0053e-01,\n",
      "           8.9123e-02, -9.6928e-03, -1.2348e-02,  1.4312e-01,  1.9077e-02,\n",
      "          -1.5406e-01, -1.1709e-01,  1.4202e-01, -1.4804e-01, -1.1245e-01,\n",
      "           4.4070e-03,  1.0503e-01,  5.4871e-02, -1.5728e-01,  1.1689e-01,\n",
      "           1.0826e-01, -1.0059e-01, -1.5489e-01,  2.3022e-01, -1.2107e-01,\n",
      "          -2.0788e-01, -2.9875e-01,  3.3099e-02, -7.3858e-02, -2.3315e-01,\n",
      "          -1.3978e-01, -2.1220e-01,  2.3243e-01, -1.1049e-01, -5.0331e-03,\n",
      "           6.4483e-02,  6.7345e-02,  2.7323e-02,  5.4988e-02,  2.4115e-01,\n",
      "           3.1190e-02,  1.0212e-01, -9.1089e-02,  7.1084e-03, -1.8419e-01,\n",
      "           2.0308e-01,  2.3154e-01,  1.1612e-01, -2.6891e-02, -1.5423e-01,\n",
      "          -6.0546e-02,  2.8677e-01,  1.1844e-01,  1.3308e-02,  3.0448e-02,\n",
      "          -1.8054e-01,  1.1680e-01, -8.0027e-02,  7.7304e-02,  1.7251e-01,\n",
      "           1.6568e-01,  1.4064e-01,  2.0176e-01, -1.4730e-01,  3.3356e-02,\n",
      "           1.4330e-01,  1.2842e-01, -3.6148e-02, -2.2827e-01,  3.8643e-02,\n",
      "           2.5867e-01,  1.5666e-02,  1.3327e-01, -4.8916e-02,  1.6388e-01,\n",
      "           2.0363e-01, -1.8388e-01,  1.8627e-01,  2.2874e-01,  1.5388e-01,\n",
      "          -1.7728e-01, -2.9509e-02, -9.5702e-02, -2.8156e-03, -6.2690e-02,\n",
      "          -5.4589e-02,  5.6689e-02,  3.8049e-02,  1.1217e-02,  1.9007e-01,\n",
      "          -2.0719e-01, -1.3563e-01, -6.7347e-02,  1.0219e-01, -4.1956e-02,\n",
      "           2.6037e-01,  1.1498e-01, -2.3633e-01,  1.1997e-02, -1.1217e-01,\n",
      "          -1.6315e-01, -5.4601e-03,  1.6342e-02,  1.5456e-01,  1.5645e-01,\n",
      "           1.1080e-01,  3.4850e-02,  1.9754e-01, -5.6996e-02, -9.6575e-03,\n",
      "           1.6562e-01,  9.3781e-02, -4.3273e-02, -4.9817e-02, -3.4970e-02,\n",
      "          -1.8526e-02,  2.0907e-01, -2.1775e-01,  1.8359e-01,  6.5231e-02,\n",
      "           1.4904e-01,  1.6190e-01,  3.5658e-01, -2.1170e-01,  2.9153e-01,\n",
      "          -2.7053e-01, -1.1853e-01, -1.2351e-01,  2.3210e-01, -9.4567e-03,\n",
      "           3.2435e-01,  3.4644e-02,  1.4908e-01, -6.9880e-02,  1.3828e-01,\n",
      "          -1.4802e-01, -1.5152e-01, -6.9175e-02,  2.3054e-01, -3.1451e-01,\n",
      "          -6.6576e-03, -1.3719e-01,  8.7020e-02, -8.7306e-05,  1.9350e-01,\n",
      "           1.9903e-03,  1.2487e-01,  4.7833e-02, -3.7897e-02, -4.5387e-03,\n",
      "          -3.9200e-02,  3.4035e-01, -3.0056e-02,  1.3260e-01,  1.4817e-01,\n",
      "           4.8654e-03, -8.9920e-03, -2.3550e-01, -6.5228e-03,  1.2482e-01,\n",
      "          -1.3511e-01, -2.2296e-01, -6.0360e-02,  1.5309e-01, -2.3483e-01,\n",
      "          -6.5611e-02,  1.5716e-02,  1.0631e-01, -1.6518e-01,  9.6812e-02,\n",
      "          -5.6692e-02,  4.1710e-02, -1.8207e-02, -2.2003e-01,  8.9187e-02,\n",
      "           4.3239e-02, -1.3235e-01,  6.1020e-02,  2.0829e-01, -2.2630e-02,\n",
      "          -1.0499e-01, -1.2422e-01,  1.7970e-02, -2.1636e-01,  1.1294e-01,\n",
      "           1.2386e-01, -1.5939e-02,  1.1251e-01,  2.0175e-01, -3.8290e-02,\n",
      "          -2.1424e-01,  1.5870e-01,  1.0596e-01, -2.9284e-01, -1.2520e-01,\n",
      "           1.2795e-01, -2.1906e-01,  3.3966e-01, -1.1125e-01, -4.2790e-03,\n",
      "           1.5411e-01,  1.1600e-01, -6.5180e-02, -4.6596e-01,  1.3458e-01,\n",
      "          -1.4457e-01, -4.1429e-01, -1.1219e-01, -8.4567e-02, -1.2477e-01,\n",
      "          -1.8088e-01, -3.6214e-01,  4.0137e-02,  2.1288e-01,  1.9681e-01,\n",
      "           1.2916e-01, -8.2756e-02, -1.7731e-01,  1.4869e-02,  9.8076e-02,\n",
      "          -2.3018e-01, -1.5753e-01, -5.6873e-02, -2.6101e-01, -2.0224e-01,\n",
      "           4.1672e-02, -8.0715e-02, -1.6934e-02, -9.1275e-02,  1.8431e-02,\n",
      "           8.1327e-03]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7269e-01, -4.3061e-01,  3.1495e-01, -1.0846e+00, -1.1725e+00,\n",
      "           7.4168e-01, -1.9142e+00,  0.0000e+00,  1.9038e-01,  6.1732e-01,\n",
      "           1.9029e+00,  6.0243e-01,  2.2868e-01, -9.1615e-01, -3.1821e+00,\n",
      "          -6.8371e-02, -1.6331e+00, -9.4357e-01,  1.3607e+00, -1.4349e+00,\n",
      "          -1.4065e-01, -5.2368e-01, -1.1196e+00, -2.5951e+00, -7.5735e-02,\n",
      "           1.3913e+00, -6.1944e-01,  1.9971e+00,  1.2762e-01,  5.5415e-01,\n",
      "           9.1506e-01, -3.6210e-03,  2.2275e-01,  2.0157e+00, -6.3732e-02,\n",
      "           0.0000e+00, -1.1184e-01, -8.1759e-01,  3.1474e-01,  8.5573e-02,\n",
      "           8.6233e-01, -8.9957e-01,  1.0090e+00, -1.5633e+00,  1.9441e+00,\n",
      "          -3.0013e-01,  7.0495e-01, -6.0160e-01, -1.0207e+00,  1.1164e+00,\n",
      "          -1.3223e+00,  0.0000e+00,  6.6672e-01, -8.4667e-01,  2.2759e-01,\n",
      "          -3.0930e-01,  0.0000e+00, -9.6590e-02,  1.2751e+00,  2.1810e+00,\n",
      "           0.0000e+00,  3.6085e-02, -2.8012e-01,  2.6588e-01, -6.2861e-02,\n",
      "           3.9397e-01,  5.7804e-01,  1.1649e+00,  1.5806e+00, -1.4151e+00,\n",
      "           4.2754e-01,  2.9644e-01, -3.1263e-02, -7.9773e-01, -2.1442e-01,\n",
      "           1.3927e-01,  5.2570e-01,  1.3986e+00,  1.0270e+00, -7.9317e-01,\n",
      "           7.5770e-01, -1.0055e+00,  7.5744e-01,  1.0587e+00, -1.2146e+00,\n",
      "          -1.1306e-01, -1.1075e+00,  0.0000e+00,  0.0000e+00, -1.9014e+00,\n",
      "           5.2904e-01,  9.8676e-01,  1.7015e+00,  9.4350e-01,  6.0811e-01,\n",
      "          -1.5909e-02,  3.5328e-01, -1.1756e+00,  1.3714e+00,  2.4478e+00,\n",
      "           0.0000e+00,  4.5361e-02, -4.6644e-01, -9.8939e-01,  1.6400e+00,\n",
      "          -1.0231e+00,  3.0288e+00,  6.1982e-01,  0.0000e+00,  0.0000e+00,\n",
      "           1.8992e-01, -5.0289e-01, -5.7041e-01,  7.1232e-01,  0.0000e+00,\n",
      "           6.3230e-01,  4.0401e-01,  2.2406e-01, -2.3270e+00,  2.9363e-02,\n",
      "          -8.1374e-01, -1.4109e+00, -1.8373e+00,  6.0328e-01, -9.5644e-01,\n",
      "          -2.0033e-01,  3.9334e-02,  2.1499e+00,  1.3961e+00, -2.0876e+00,\n",
      "          -9.2637e-01,  4.4964e-01, -1.1674e+00,  4.2516e-01, -4.6876e-01,\n",
      "          -7.4498e-01, -1.0649e+00, -9.7476e-01, -1.9528e-02,  0.0000e+00,\n",
      "           6.9854e-01, -1.1217e+00,  1.6916e+00, -1.4020e-01, -6.6953e-01,\n",
      "           3.3845e-02,  7.5933e-01,  4.2307e-01, -1.0332e+00, -9.5609e-02,\n",
      "           1.5600e+00,  0.0000e+00, -3.3873e-01,  6.5765e-01,  1.8408e+00,\n",
      "          -2.5248e-01,  0.0000e+00,  6.2347e-01, -2.3624e+00,  1.0556e+00,\n",
      "           3.0245e-01, -7.7467e-02,  1.5453e-01, -1.2116e+00, -2.1940e-02,\n",
      "           0.0000e+00,  1.8518e+00,  2.7071e-01, -1.2702e+00, -7.1328e-01,\n",
      "           0.0000e+00, -1.0939e+00, -2.5902e+00,  0.0000e+00, -3.0586e+00,\n",
      "           0.0000e+00,  4.9814e-01,  8.2947e-01,  3.1698e-01, -7.9285e-01,\n",
      "           2.7141e-01,  2.3396e+00,  0.0000e+00,  8.3831e-01, -4.0297e-01,\n",
      "           7.2726e-01,  5.9905e-01,  3.5948e-01,  0.0000e+00, -1.8300e+00,\n",
      "           1.3634e+00,  2.1589e+00,  3.3666e-01, -1.0153e+00, -1.1718e+00,\n",
      "          -2.2150e+00,  1.6662e+00,  2.1525e+00,  3.6341e-01,  2.3836e+00,\n",
      "           3.2320e-02, -5.0150e-01, -1.2762e+00, -5.4241e-01, -4.0737e-01,\n",
      "          -1.4468e+00,  9.5369e-01, -8.5177e-01,  8.3051e-01, -1.5598e+00,\n",
      "           6.3633e-01,  6.7606e-01,  2.3974e+00,  5.5103e-02,  1.8938e+00,\n",
      "           1.3080e+00,  5.8074e-01, -2.3170e+00,  1.5502e+00, -2.2259e-01,\n",
      "          -2.2715e-01,  1.7332e+00,  2.7700e-01, -1.5519e+00,  9.2281e-01,\n",
      "          -1.2244e+00, -8.4820e-01, -1.8013e+00, -4.4885e-04,  3.7340e-01,\n",
      "           0.0000e+00, -1.2352e-01,  9.6626e-01, -1.7361e+00,  1.6940e+00,\n",
      "          -1.4405e+00,  6.3409e-01, -1.7219e+00,  9.8034e-01, -1.7156e+00,\n",
      "           1.5604e+00, -2.7207e-01, -2.5967e+00,  1.2385e+00, -1.2284e+00,\n",
      "           1.8845e+00, -5.0832e-01,  5.4283e-01, -2.6132e-01, -1.0218e+00,\n",
      "           1.3333e+00,  3.1045e-01, -5.1414e-02, -2.2880e-01, -1.6118e+00,\n",
      "           1.8061e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0507, 0.1298, 0.1641, 0.0776, 0.1194, 0.1112, 0.1225, 0.0658, 0.0859,\n",
      "         0.0728]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3539, -0.0254,  0.0806,  ..., -0.1192, -0.0264, -0.4741],\n",
      "        [ 0.2407,  0.0422, -0.1433,  ..., -0.3221, -0.1260,  0.1325],\n",
      "        [ 0.0564,  0.1661,  0.1753,  ..., -0.0213,  0.0336,  0.3670],\n",
      "        ...,\n",
      "        [ 0.3458, -0.1068, -0.4902,  ..., -0.4259,  0.3989, -0.0977],\n",
      "        [ 0.5256,  0.3554, -0.7343,  ..., -0.3406,  0.0410,  0.0184],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.8457e-01, -7.4164e-02, -1.7076e-01,  7.5362e-02, -9.9991e-02,\n",
      "           2.2435e-01, -2.0265e-01, -2.5482e-01,  2.1559e-02,  1.2418e-01,\n",
      "           6.0407e-02, -1.4364e-01,  9.3264e-02, -7.9380e-02,  1.6890e-01,\n",
      "           3.0903e-01,  1.0991e-01, -6.4092e-02, -2.0107e-01, -6.6658e-02,\n",
      "          -2.5539e-01, -7.8334e-02, -1.5023e-02, -8.6598e-02, -2.1955e-02,\n",
      "           2.3590e-02,  7.0492e-02, -8.8597e-04, -1.4881e-01, -9.7246e-02,\n",
      "           1.9837e-02,  1.6935e-02,  1.8577e-02,  1.3068e-01,  1.9246e-02,\n",
      "          -1.1810e-01, -1.3039e-01,  1.1162e-01, -1.4378e-01, -1.2290e-01,\n",
      "           3.8308e-02,  1.2830e-01,  3.9312e-02, -1.4766e-01,  1.4300e-01,\n",
      "           6.3388e-02, -8.8155e-02, -1.0306e-01,  2.1586e-01, -3.2368e-02,\n",
      "          -2.1686e-01, -3.1529e-01,  7.5937e-02, -4.0684e-02, -2.7699e-01,\n",
      "          -8.2716e-02, -1.7348e-01,  2.7550e-01, -3.5516e-02,  1.8434e-02,\n",
      "           1.6343e-02,  2.4119e-02,  1.7537e-03,  3.8415e-02,  2.4028e-01,\n",
      "           2.5464e-02,  9.3281e-02, -1.5150e-01,  1.6791e-02, -2.2242e-01,\n",
      "           2.1856e-01,  2.6636e-01,  4.1498e-02, -5.5469e-02, -1.3922e-01,\n",
      "          -5.7583e-02,  2.7149e-01,  7.2024e-02, -4.8611e-03, -3.2019e-03,\n",
      "          -2.2777e-01,  7.9609e-02, -9.1263e-02,  7.5612e-02,  1.3764e-01,\n",
      "           1.2226e-01,  9.5981e-02,  1.9220e-01, -1.6552e-01,  1.5511e-02,\n",
      "           1.2441e-01,  1.4824e-01, -3.7770e-02, -2.1627e-01,  8.0461e-02,\n",
      "           2.6034e-01,  6.2198e-02,  2.1826e-01, -7.2685e-02,  1.2398e-01,\n",
      "           1.4649e-01, -9.9964e-02,  1.8201e-01,  1.7766e-01,  7.3940e-02,\n",
      "          -1.9151e-01, -4.5369e-02, -1.1347e-01, -5.7477e-02, -4.5479e-02,\n",
      "          -3.9097e-02,  4.2817e-02,  1.7781e-02,  2.9622e-02,  1.8533e-01,\n",
      "          -1.7131e-01, -4.8792e-02, -9.7792e-02,  6.5430e-02, -6.8617e-02,\n",
      "           2.7711e-01,  7.0977e-02, -1.6749e-01,  1.9668e-02, -1.0512e-01,\n",
      "          -1.7717e-01,  9.5148e-03,  4.4200e-02,  2.3977e-01,  1.5585e-01,\n",
      "           6.0954e-02,  2.5526e-02,  1.9472e-01, -7.3774e-02, -1.0508e-01,\n",
      "           1.0894e-01,  1.5488e-01, -2.6452e-02, -6.9610e-03, -3.9351e-02,\n",
      "           3.1746e-03,  2.0560e-01, -1.5889e-01,  2.1318e-01,  3.6849e-02,\n",
      "           1.1785e-01,  2.1048e-01,  3.6322e-01, -2.1702e-01,  1.8913e-01,\n",
      "          -2.9400e-01, -1.5632e-01, -4.9213e-02,  2.4979e-01, -4.0975e-02,\n",
      "           2.4738e-01,  3.1274e-02,  1.8945e-01, -4.4206e-02,  1.7399e-01,\n",
      "          -1.5566e-01, -8.1047e-02, -7.2179e-02,  2.1976e-01, -2.6182e-01,\n",
      "          -4.2782e-02, -1.2132e-01,  9.2154e-02,  2.2625e-02,  2.5514e-01,\n",
      "           1.6189e-03,  1.2885e-01,  3.7898e-02,  1.2717e-02,  3.7546e-02,\n",
      "           4.0105e-02,  2.6997e-01, -9.4993e-03,  1.4684e-01,  1.3397e-01,\n",
      "           1.4717e-02,  2.4017e-02, -2.2404e-01, -1.5282e-02,  1.1440e-01,\n",
      "          -1.0271e-01, -1.6960e-01, -5.5466e-02,  1.2653e-01, -2.1315e-01,\n",
      "          -6.0872e-02,  1.7997e-04,  7.1399e-02, -1.3124e-01,  6.5832e-02,\n",
      "          -4.0913e-02, -3.9524e-03, -5.2893e-02, -2.4277e-01,  1.0573e-01,\n",
      "           5.7887e-03, -9.3500e-02,  9.1868e-02,  2.0843e-01, -3.2575e-02,\n",
      "          -3.5843e-02, -1.2161e-01, -2.7574e-02, -1.8851e-01,  1.0121e-01,\n",
      "           1.5696e-01, -2.0176e-02,  5.8033e-02,  1.7861e-01, -5.0844e-03,\n",
      "          -1.8340e-01,  1.6494e-01,  1.2856e-01, -3.1852e-01, -7.3725e-02,\n",
      "           1.3571e-01, -1.9965e-01,  3.4679e-01, -1.4184e-01, -1.7204e-02,\n",
      "           1.9464e-01,  1.6018e-01, -2.6281e-02, -4.6065e-01,  1.3232e-01,\n",
      "          -1.8352e-01, -3.7714e-01, -3.7069e-02, -9.0632e-02, -1.5436e-01,\n",
      "          -2.3640e-01, -3.4607e-01,  2.5094e-02,  1.8378e-01,  1.7006e-01,\n",
      "           1.5560e-01, -6.9725e-02, -1.8698e-01,  1.4697e-02,  8.8198e-02,\n",
      "          -1.9902e-01, -2.1276e-01, -4.0782e-02, -2.7632e-01, -1.2826e-01,\n",
      "           4.6650e-02, -5.1442e-02,  2.0774e-03, -8.8099e-02, -7.8743e-03,\n",
      "           3.2670e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6484e-02,  3.9965e-01, -9.6535e-01, -6.8108e-01,  3.7563e-01,\n",
      "          -2.0197e-01,  0.0000e+00,  0.0000e+00, -3.5836e+00,  9.0654e-01,\n",
      "           4.2817e-01, -6.2905e-01,  2.6029e+00, -6.2996e-01, -5.4133e-01,\n",
      "          -1.5800e-01,  8.5117e-01,  1.0945e+00,  4.5520e-01,  4.3612e-01,\n",
      "          -6.3332e-01, -3.8263e-01,  1.6404e+00,  1.5108e+00,  7.5328e-01,\n",
      "          -7.5728e-02, -1.8807e-01, -7.5953e-01,  1.6533e+00,  8.6137e-01,\n",
      "           1.2316e+00,  1.2190e+00, -1.0341e+00, -8.2903e-02, -1.5342e+00,\n",
      "           1.3954e+00,  2.8087e-01, -3.7441e+00,  1.9776e-01,  1.6004e+00,\n",
      "          -4.5895e-01,  0.0000e+00, -2.6871e-01, -1.7149e+00, -1.5236e+00,\n",
      "           6.6756e-01,  5.4063e-01,  3.7097e-01, -1.3404e+00,  1.4440e-01,\n",
      "          -6.2928e-01,  2.7511e+00,  6.1019e-01, -1.0288e+00, -2.5147e-02,\n",
      "           2.0366e-01, -8.8148e-01,  0.0000e+00, -2.3707e-01, -4.2583e-01,\n",
      "           1.0996e+00,  1.4075e+00, -2.0270e-01, -5.0107e-01, -2.9628e+00,\n",
      "           5.5120e-01,  1.2783e+00, -1.2875e+00,  4.1062e-01,  5.2670e-01,\n",
      "          -1.2666e+00, -2.9928e-02,  7.0727e-01, -3.6402e+00,  3.2536e-01,\n",
      "          -9.6190e-04, -1.6004e-01,  1.0619e+00, -5.7649e-02, -1.1863e-01,\n",
      "          -1.3999e+00,  2.1304e+00, -9.2434e-01,  1.0059e+00, -2.0759e-01,\n",
      "           4.3564e-01,  1.6614e+00,  0.0000e+00, -1.0408e-01, -5.8117e-01,\n",
      "          -2.2726e+00,  1.0999e+00, -6.2236e-01, -1.1355e+00,  4.6722e-01,\n",
      "          -1.1703e+00,  0.0000e+00,  6.2891e-01,  1.7194e+00, -7.7909e-01,\n",
      "           2.6968e+00, -1.4618e+00,  1.0759e+00,  0.0000e+00, -6.6620e-01,\n",
      "          -7.6241e-01,  1.2113e+00,  1.2718e-01, -1.4728e+00, -1.3637e-02,\n",
      "          -2.4830e-01,  1.3413e-01,  0.0000e+00,  1.3099e+00, -1.6526e+00,\n",
      "          -2.9883e+00, -5.6750e-02, -4.9987e-01, -1.9335e-01,  4.4531e-01,\n",
      "          -1.4654e+00,  7.0207e-01,  0.0000e+00, -7.2572e-01, -9.5797e-01,\n",
      "          -1.3082e+00,  8.9615e-01,  1.6968e-01,  1.2847e+00, -7.5148e-01,\n",
      "          -8.2392e-01,  5.3050e-01, -1.5826e+00,  9.8395e-01,  2.7602e-01,\n",
      "          -5.8925e-01,  6.5887e-01,  5.7512e-01, -1.1588e+00,  0.0000e+00,\n",
      "          -3.8822e-01,  6.7775e-01, -7.8956e-01, -1.0079e-01, -1.6848e+00,\n",
      "          -1.0052e-01, -5.4305e-01, -8.4424e-01, -7.5518e-01,  1.7760e-01,\n",
      "           1.9980e+00, -1.9936e-01, -1.9296e+00, -4.0615e-01,  4.4121e-01,\n",
      "          -1.9442e-01, -6.4706e-02, -1.3002e-01,  3.9173e-02,  5.3741e-01,\n",
      "          -2.6595e-02,  2.2061e+00,  4.8109e-01, -5.5013e-01, -5.2617e-01,\n",
      "          -8.9172e-01,  2.8152e-01,  8.3154e-02, -3.5803e-01, -4.7787e-01,\n",
      "           7.3653e-01,  0.0000e+00,  2.0074e-02, -1.0022e+00,  1.2776e+00,\n",
      "          -1.0979e+00, -9.8625e-01, -2.0758e+00,  1.9685e+00,  8.6500e-02,\n",
      "          -3.0740e-02,  3.5007e-02,  6.7087e-01,  0.0000e+00, -7.4730e-01,\n",
      "          -3.4097e-01, -2.7820e+00, -7.8331e-01,  1.2090e+00,  1.0124e+00,\n",
      "           3.0729e+00,  4.9412e-01, -1.4434e-01, -5.9328e-01,  5.6020e-01,\n",
      "           2.1644e+00, -1.1875e+00,  5.3509e-01,  1.8110e+00, -9.4632e-01,\n",
      "          -1.6624e+00,  0.0000e+00,  1.2421e+00, -1.2208e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.2921e+00,  6.8161e-01,  0.0000e+00, -4.7098e-01,\n",
      "           2.8673e+00, -5.7324e-01, -3.4116e-01,  7.9287e-01,  3.1007e-02,\n",
      "          -6.8373e-01, -1.0179e+00,  9.6652e-01, -2.4528e-01,  2.1688e+00,\n",
      "          -1.0827e+00, -4.2703e-01, -1.8434e+00, -5.0053e-01,  3.3878e-01,\n",
      "           0.0000e+00, -6.9657e-01, -6.2813e-01,  2.9226e-01, -1.5779e+00,\n",
      "          -1.1083e+00,  1.5812e+00, -6.1384e-01,  1.3100e+00, -2.9793e+00,\n",
      "           4.0341e+00,  5.8519e-01,  4.3152e-02, -1.5790e+00,  0.0000e+00,\n",
      "           7.4185e-01, -3.2473e+00, -3.0389e-01,  0.0000e+00,  1.1320e-02,\n",
      "           0.0000e+00,  2.7464e-01,  2.5223e-01,  2.6143e-01,  3.8662e-01,\n",
      "          -3.6566e-01, -1.5936e-01, -5.5366e-01, -5.2250e-02, -1.1464e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0494, 0.0515, 0.0763, 0.0787, 0.1110, 0.2622, 0.0876, 0.0811, 0.0727,\n",
      "         0.1295]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3544, -0.0258,  0.0803,  ..., -0.1193, -0.0266, -0.4760],\n",
      "        [ 0.2448,  0.0404, -0.1500,  ..., -0.3241, -0.1259,  0.1285],\n",
      "        [ 0.0596,  0.1640,  0.1700,  ..., -0.0256,  0.0348,  0.3625],\n",
      "        ...,\n",
      "        [ 0.1137, -0.2778,  0.2607,  ...,  0.6766,  0.4033,  0.0790],\n",
      "        [ 0.2240, -0.1304, -0.0609,  ...,  0.0556,  0.5531,  0.0153],\n",
      "        [ 0.4827,  0.3742, -0.5911,  ...,  0.0166,  0.1714,  0.1230]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1125, -0.1167, -0.0525,  0.1901, -0.0791,  0.0481, -0.3404,\n",
      "          -0.1972,  0.0155,  0.1463,  0.1231, -0.1225, -0.0320, -0.0398,\n",
      "           0.0769,  0.1597,  0.0952,  0.0785, -0.1327, -0.0653, -0.3743,\n",
      "          -0.0216, -0.0237,  0.2883,  0.1207, -0.0704,  0.0802, -0.0975,\n",
      "          -0.2953, -0.0483, -0.0449, -0.1808,  0.1939,  0.0611, -0.1464,\n",
      "          -0.1313, -0.0797, -0.0728, -0.0519, -0.2384, -0.0184,  0.0523,\n",
      "          -0.0242,  0.0032,  0.0295,  0.0674,  0.0318, -0.0561,  0.0682,\n",
      "           0.0112, -0.3585,  0.0164, -0.0823, -0.2198, -0.3320,  0.0472,\n",
      "          -0.0801,  0.1811, -0.0378,  0.0934, -0.1144,  0.0347, -0.0707,\n",
      "           0.0725,  0.3180, -0.0098, -0.1341, -0.0127, -0.2394, -0.1471,\n",
      "           0.0931,  0.3956, -0.0528, -0.1827, -0.1934, -0.1123,  0.4341,\n",
      "           0.0894,  0.0718,  0.2095, -0.2436, -0.1947, -0.4089,  0.2351,\n",
      "           0.1138,  0.0695,  0.1912,  0.0714, -0.2594,  0.3025,  0.1056,\n",
      "           0.1678, -0.0351, -0.1836,  0.1075,  0.4574,  0.0915,  0.1976,\n",
      "           0.1851, -0.0958,  0.0559,  0.0849,  0.2161,  0.0163, -0.0833,\n",
      "          -0.1300, -0.1332,  0.2209, -0.0902,  0.0006, -0.1713,  0.1000,\n",
      "          -0.1863,  0.0219, -0.0239,  0.0725, -0.0944, -0.2789,  0.0305,\n",
      "          -0.1484,  0.1548, -0.0214, -0.2224,  0.1082, -0.1072, -0.2254,\n",
      "          -0.0927, -0.1092,  0.3163,  0.1866,  0.3449, -0.1048,  0.0865,\n",
      "           0.1085, -0.2404, -0.1138,  0.4560, -0.1839, -0.0912,  0.0626,\n",
      "           0.0629,  0.2666, -0.3015,  0.1895,  0.2216,  0.1573,  0.2699,\n",
      "           0.2848, -0.1302,  0.1798, -0.4108, -0.0079,  0.1103,  0.1012,\n",
      "           0.0027,  0.2646,  0.0633,  0.3313, -0.0597,  0.0227, -0.2891,\n",
      "           0.0568, -0.2383, -0.0384, -0.2928, -0.1161, -0.2403,  0.0796,\n",
      "          -0.0849,  0.4264,  0.0665, -0.0730, -0.0227,  0.0743,  0.1401,\n",
      "          -0.0716,  0.1073, -0.0775,  0.2851, -0.0278,  0.0634, -0.0032,\n",
      "          -0.1280, -0.1722,  0.2388, -0.0558, -0.2368,  0.1498,  0.2038,\n",
      "          -0.2122,  0.0917, -0.1648, -0.1892,  0.0660, -0.1857,  0.0344,\n",
      "           0.1579, -0.1276, -0.3087,  0.1104, -0.0223,  0.0497, -0.1496,\n",
      "           0.1895, -0.3758, -0.2349, -0.0469,  0.1416, -0.2649, -0.1405,\n",
      "           0.0885,  0.0915, -0.1387,  0.1136,  0.0961, -0.0584,  0.1322,\n",
      "           0.2823, -0.0284, -0.2515, -0.0866, -0.0905,  0.1161,  0.0804,\n",
      "           0.0042,  0.0766,  0.1718, -0.2611, -0.2614,  0.1296, -0.1478,\n",
      "          -0.3980,  0.0909,  0.1281,  0.1368, -0.1782,  0.0589, -0.0958,\n",
      "           0.0352,  0.1745,  0.0906,  0.1234, -0.4001,  0.0421, -0.0536,\n",
      "          -0.0413, -0.0329,  0.1048, -0.1155,  0.0337,  0.1840,  0.1565,\n",
      "          -0.1231,  0.0794,  0.1265, -0.0351]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4738, -0.4590, -1.2335, -0.1179,  0.4618,  0.0257,  0.6620,\n",
      "           0.5340,  0.6706,  0.9338,  1.7080, -1.0164,  0.9465,  0.0000,\n",
      "          -1.6339,  0.5126,  1.8775, -0.7566, -1.5631, -2.6436, -1.1337,\n",
      "           0.1682,  2.9299,  0.5543,  0.0000,  3.2095,  1.8370,  0.0000,\n",
      "          -2.2263, -1.2857,  0.0295,  1.0135,  0.3247,  0.8600, -0.7986,\n",
      "          -1.4656,  0.0000, -0.7712,  1.9916,  0.1022,  0.4675, -2.2043,\n",
      "          -0.5664, -0.1152, -0.7129, -0.6893,  0.0000,  0.1099, -0.2867,\n",
      "          -1.8506,  1.4680,  0.4624,  0.6675, -0.2835,  0.5317,  0.2749,\n",
      "          -1.2423,  0.0000,  0.0000, -0.0117,  0.2048, -1.8183, -1.4015,\n",
      "          -0.8064,  1.1797,  0.2653, -0.1668, -0.2554, -0.0044, -0.4609,\n",
      "           0.0000, -0.3242,  0.0000, -0.1266,  0.6587, -0.8064,  2.0662,\n",
      "           1.6797,  0.0878, -0.5461,  1.2270,  0.0867,  0.3269, -1.8364,\n",
      "          -0.0716, -1.7323, -1.4585, -0.8910,  0.0000,  0.8108, -1.2237,\n",
      "          -1.1443,  1.9852, -0.3660, -0.7340,  0.0000,  2.1416, -0.4056,\n",
      "          -0.3043, -1.8395, -1.2904, -0.7216, -0.7664,  0.2375,  0.0000,\n",
      "           1.1139, -1.0700,  2.2524, -0.2628, -0.2883, -0.0532,  0.0000,\n",
      "          -0.2548, -0.2802,  0.0000,  1.1283,  1.0062, -2.4977, -0.5748,\n",
      "           0.0297,  0.0000, -0.4011, -0.3794, -0.0787, -0.5369, -1.1112,\n",
      "           1.3048,  0.1697,  0.0000,  1.3585,  2.0794, -2.6342,  0.3592,\n",
      "          -0.7230,  0.4292,  0.0600,  0.3269, -2.1021, -0.4969, -1.6776,\n",
      "          -0.6420,  0.2341, -1.1871, -1.2152,  0.0000, -0.0407,  0.4648,\n",
      "           1.7384,  1.5941,  0.0000, -1.2628,  0.0000, -0.4801, -0.0394,\n",
      "           0.3267, -0.1166,  1.3538, -0.0313, -1.9006, -1.8060, -1.4269,\n",
      "          -0.9004, -0.7055, -0.3891, -0.9814,  0.0000,  0.4063,  0.9705,\n",
      "           0.5179, -0.1474,  1.5141, -0.3730, -0.3159, -2.0087,  0.1292,\n",
      "          -0.3524, -0.8306, -0.7692, -0.0401, -0.9376,  0.7278,  1.0421,\n",
      "           0.0469,  0.4633,  0.3165, -0.1181, -0.5418, -0.6643,  0.7549,\n",
      "          -1.0643, -0.5868, -1.7885,  1.2675, -0.9264, -1.6148, -0.3332,\n",
      "          -1.1570,  0.0000, -0.0720, -0.3756,  2.6977, -0.9216, -2.6318,\n",
      "          -0.5862, -0.7165, -1.3860, -1.2537,  0.1719,  0.2187, -1.1109,\n",
      "           0.9450, -0.6919, -1.5195,  0.3623,  0.2372, -1.4267, -2.3449,\n",
      "           0.0472, -1.4799,  0.0000,  0.0133, -0.9018,  0.3009, -1.1653,\n",
      "          -1.3016, -0.1876,  1.2723,  1.2666, -2.1881, -0.0564,  1.7373,\n",
      "           0.0000,  0.9563,  1.9991,  0.5270,  0.7894, -0.6786,  0.1046,\n",
      "          -0.6805, -2.2623,  0.0000, -0.3140,  0.0000, -0.3820, -1.0801,\n",
      "           0.5580,  1.4998, -0.5647, -1.3773,  1.2434,  0.5826,  1.7530,\n",
      "           1.9514,  0.3625,  0.4872,  0.3903]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0279, 0.2611, 0.0869, 0.0487, 0.1034, 0.1324, 0.0266, 0.1708, 0.0794,\n",
      "         0.0628]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3544, -0.0258,  0.0803,  ..., -0.1193, -0.0266, -0.4760],\n",
      "        [ 0.2448,  0.0404, -0.1500,  ..., -0.3241, -0.1259,  0.1285],\n",
      "        [ 0.0596,  0.1640,  0.1700,  ..., -0.0256,  0.0348,  0.3625],\n",
      "        ...,\n",
      "        [ 0.1137, -0.2778,  0.2607,  ...,  0.6766,  0.4033,  0.0790],\n",
      "        [ 0.2240, -0.1304, -0.0609,  ...,  0.0556,  0.5531,  0.0153],\n",
      "        [ 0.4827,  0.3742, -0.5911,  ...,  0.0166,  0.1714,  0.1230]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4884e-01, -8.6220e-02, -5.4938e-02,  1.2104e-01, -1.3799e-02,\n",
      "           2.0061e-01, -3.9150e-01, -1.9686e-01, -3.6368e-04,  1.9313e-01,\n",
      "           1.0672e-01, -1.5082e-01, -9.6479e-02, -6.8381e-02,  5.1570e-02,\n",
      "           2.7068e-01,  6.1010e-02,  4.5347e-02, -1.4739e-01, -2.0459e-01,\n",
      "          -3.5965e-01, -3.4192e-03, -6.7614e-02,  2.9007e-01,  1.1679e-01,\n",
      "          -6.0532e-03,  8.7574e-02, -1.5210e-02, -2.1334e-01, -8.5292e-02,\n",
      "          -1.0155e-01, -8.9795e-02,  2.1275e-01, -4.4480e-03, -1.5334e-01,\n",
      "          -1.2595e-02, -1.2912e-01, -3.4916e-02,  1.2383e-02, -1.9517e-01,\n",
      "           3.7710e-02,  1.7917e-01, -4.2207e-02, -7.5465e-02,  1.9635e-02,\n",
      "           7.8964e-02, -3.3230e-02, -3.8192e-02,  9.6635e-02,  1.1871e-01,\n",
      "          -3.0044e-01, -7.0743e-02,  4.4268e-03, -1.2593e-01, -3.1815e-01,\n",
      "           1.2914e-02, -1.2709e-01,  2.5724e-01,  6.0713e-02,  5.6210e-03,\n",
      "          -9.9233e-02, -3.6785e-02, -1.6357e-01,  4.6798e-02,  3.8800e-01,\n",
      "          -7.0539e-02, -9.8317e-02, -5.6562e-02, -2.0549e-01, -1.2009e-01,\n",
      "           1.9271e-01,  4.5298e-01,  1.3465e-02, -2.3978e-01, -1.0496e-01,\n",
      "          -4.9996e-02,  3.8153e-01,  3.6832e-02,  2.7003e-02,  2.1704e-01,\n",
      "          -1.8855e-01, -8.1800e-03, -3.6821e-01,  2.3986e-01,  1.4376e-01,\n",
      "           6.8978e-02,  1.4916e-01,  1.4999e-01, -2.9528e-01,  2.3576e-01,\n",
      "           8.3914e-02,  2.2118e-01, -7.0629e-03, -2.2366e-01,  1.3359e-01,\n",
      "           3.8660e-01,  1.1267e-01,  2.6805e-01,  1.5882e-01, -1.3633e-01,\n",
      "           1.5524e-01,  1.7180e-01,  1.3137e-01,  3.5882e-02, -7.2678e-02,\n",
      "          -2.4939e-01, -1.3572e-01,  1.4526e-01, -1.7941e-01, -1.7068e-02,\n",
      "          -7.8786e-02,  7.7896e-02, -1.9727e-01,  4.5927e-02,  2.1092e-02,\n",
      "           5.1730e-02,  5.3466e-02, -2.4473e-01, -8.9477e-02, -1.5143e-01,\n",
      "           1.2414e-01, -3.9765e-03, -9.6552e-02,  5.1453e-02, -7.5351e-02,\n",
      "          -2.4136e-01, -1.1026e-01, -4.9550e-02,  3.4833e-01,  1.4289e-01,\n",
      "           2.6013e-01, -3.0078e-03, -1.0124e-02,  9.5689e-02, -2.9146e-01,\n",
      "          -1.6239e-01,  3.9188e-01, -1.0656e-01, -5.8626e-02,  2.4088e-02,\n",
      "          -3.0984e-02,  2.6969e-01, -2.8755e-01,  1.6393e-01,  1.3368e-01,\n",
      "           1.4723e-01,  2.9498e-01,  3.6378e-01, -1.0607e-01,  2.5698e-02,\n",
      "          -3.3360e-01, -9.3105e-02,  1.4448e-01,  1.0517e-01, -5.7683e-02,\n",
      "           1.3497e-01,  6.4480e-02,  3.2359e-01, -1.2940e-01,  8.6146e-02,\n",
      "          -2.9967e-01,  1.7408e-01, -1.5992e-01,  6.6971e-02, -2.7617e-01,\n",
      "          -1.4954e-01, -1.2343e-01,  1.7780e-01, -4.6506e-02,  2.8260e-01,\n",
      "           4.3655e-02,  6.5922e-02, -1.1709e-02,  2.0417e-01,  1.5164e-01,\n",
      "          -1.6240e-02,  9.7665e-02, -2.8855e-02,  2.3876e-01,  9.6136e-02,\n",
      "           2.4707e-02,  1.0044e-02, -1.2126e-01, -1.5712e-01,  1.5635e-01,\n",
      "          -1.2105e-01, -1.0891e-01,  2.3982e-02,  6.0583e-02, -9.9366e-02,\n",
      "           2.7997e-02, -9.7682e-02, -1.3985e-01,  4.5333e-02, -2.3423e-01,\n",
      "          -2.6096e-03, -4.4385e-03, -1.4842e-01, -2.9863e-01,  9.8492e-02,\n",
      "          -5.5474e-02,  1.2637e-01,  4.9415e-02,  1.7565e-01, -3.7033e-01,\n",
      "          -1.3606e-01, -9.4097e-02,  1.0484e-02, -2.6174e-01, -1.0631e-01,\n",
      "           8.4210e-02,  1.4148e-01, -1.4025e-01,  1.7269e-01,  1.1572e-01,\n",
      "          -1.3803e-01,  1.9750e-01,  2.3508e-01, -1.0723e-01, -2.0790e-01,\n",
      "           1.2898e-02, -6.2933e-02,  1.3725e-01, -1.2828e-02, -1.0595e-02,\n",
      "           7.2117e-02,  1.3311e-01, -1.3733e-01, -2.8029e-01,  7.0240e-02,\n",
      "          -5.6139e-02, -3.5013e-01,  1.2326e-01,  1.4138e-01, -1.1916e-02,\n",
      "          -2.3613e-01, -7.4241e-02, -5.0837e-02,  6.8172e-02,  1.1997e-01,\n",
      "           1.2472e-01, -2.2953e-02, -2.8862e-01,  9.1106e-02, -1.5351e-01,\n",
      "          -8.0672e-02, -1.6415e-01,  1.6795e-01, -2.2064e-01,  3.9295e-02,\n",
      "           1.4952e-01,  1.0892e-01, -7.2743e-02,  3.9862e-02,  1.0427e-01,\n",
      "           3.3424e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0628e+00, -6.9694e-02, -1.8078e+00,  1.3220e+00,  0.0000e+00,\n",
      "          -3.7615e-01,  1.0706e-03, -7.2302e-01,  2.1179e+00, -2.1387e-01,\n",
      "           2.8215e-01,  8.3071e-01, -1.1107e+00,  1.9985e-01,  3.1234e-01,\n",
      "           3.5181e-01, -6.8283e-01,  1.6906e-01,  8.7450e-01,  5.4566e-01,\n",
      "           1.8833e+00,  6.0194e-01, -3.6772e-02, -5.3539e-01, -1.0015e-01,\n",
      "           6.5096e-01, -1.6088e+00,  0.0000e+00, -2.1267e+00, -1.0344e+00,\n",
      "           3.8890e-02, -1.4547e+00, -2.0767e+00,  0.0000e+00, -2.8495e-01,\n",
      "          -2.0018e+00,  2.1901e-01,  9.9703e-01,  6.0115e-01,  9.5358e-01,\n",
      "          -2.2518e-01, -2.2112e+00, -7.0621e-01,  1.3960e+00,  8.9642e-02,\n",
      "          -1.1386e+00,  2.4253e-01,  7.4188e-01, -7.0969e-01, -1.3360e+00,\n",
      "           1.6086e+00, -1.3738e-01,  6.6270e-01,  1.1164e+00,  5.6726e-01,\n",
      "           3.3306e-01, -4.4965e-01, -8.8805e-01,  1.3371e-01,  6.2848e-01,\n",
      "          -7.0479e-01,  5.6367e-01, -6.9330e-01, -1.5473e+00,  2.8929e-01,\n",
      "           9.5769e-02, -1.7745e-01,  5.9493e-01, -2.1384e+00,  5.5976e-01,\n",
      "           1.8279e-01, -5.1244e-01, -3.4112e-01, -1.1319e+00, -6.4739e-01,\n",
      "           4.6096e-01, -1.0492e+00,  1.1900e-01,  0.0000e+00, -1.8665e-01,\n",
      "          -3.8498e-01,  2.1580e+00,  7.7746e-01,  0.0000e+00,  3.9774e-01,\n",
      "           4.1922e-01,  0.0000e+00, -5.6416e-01, -1.4132e+00, -1.4906e+00,\n",
      "           4.0431e-01,  0.0000e+00,  4.9387e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -9.6298e-01,  0.0000e+00, -9.0762e-01,  2.3908e+00,  9.5525e-01,\n",
      "          -1.2008e+00,  5.9437e-01,  1.0665e+00, -1.7339e+00,  3.6530e-01,\n",
      "           4.0225e-01,  0.0000e+00,  4.5495e-01,  1.9688e+00,  1.4950e-01,\n",
      "          -8.3242e-01,  5.3398e-01,  8.0825e-01,  6.6426e-01, -1.0551e+00,\n",
      "           9.1767e-01, -7.0291e-01, -8.4517e-01,  2.5770e-01,  8.7979e-01,\n",
      "          -8.7685e-01, -1.3966e+00, -3.6486e-01, -1.8465e+00, -1.3006e+00,\n",
      "           1.0693e+00, -8.1154e-01,  6.4939e-01,  2.5567e-01, -1.4895e+00,\n",
      "           2.5024e+00,  3.7789e-01, -1.3457e+00,  0.0000e+00,  3.2011e+00,\n",
      "           0.0000e+00, -3.8361e-01,  1.2823e+00,  2.2522e+00,  1.9398e-01,\n",
      "          -3.9221e-02,  3.0300e+00,  3.6269e-01, -1.8704e-01, -1.1121e+00,\n",
      "           1.2470e+00,  7.7539e-01, -7.7457e-01, -4.4906e-02,  0.0000e+00,\n",
      "           2.3359e+00,  7.6497e-01, -2.8960e-01, -2.1306e+00, -5.8171e-01,\n",
      "           7.8587e-01,  0.0000e+00, -1.3046e+00,  1.9021e-01, -3.6290e+00,\n",
      "          -1.8688e+00,  1.1505e+00, -8.5959e-01,  9.5964e-01, -1.4614e+00,\n",
      "          -2.7191e-02,  1.9745e+00,  1.1270e+00, -4.8580e-01, -1.2415e+00,\n",
      "          -2.1228e-01, -1.3225e+00, -1.6392e+00, -7.7176e-01,  6.8262e-01,\n",
      "          -1.3796e+00, -1.2607e-01,  6.0653e-01, -7.4891e-01,  2.5913e-01,\n",
      "           1.3325e+00, -2.5534e+00,  2.7782e-01, -5.8366e-01,  1.6234e+00,\n",
      "          -1.2403e+00, -1.8841e-03, -5.0250e-02,  9.0120e-01,  5.6545e-01,\n",
      "          -4.2001e-01,  3.8814e-01, -1.1593e-01,  8.0981e-01,  0.0000e+00,\n",
      "          -7.8913e-01, -1.4387e+00, -4.1571e-01, -7.5040e-01, -4.5413e-01,\n",
      "          -5.4747e-01,  7.2225e-01, -1.8533e+00,  1.3574e+00,  0.0000e+00,\n",
      "          -1.5239e+00, -3.5894e-01,  6.4780e-01,  2.0055e-01, -2.1782e+00,\n",
      "           8.3545e-01, -1.2912e+00, -1.2839e+00,  2.6116e-01, -1.5635e+00,\n",
      "           2.0757e+00,  1.3420e-01,  2.5769e+00, -3.1079e-02, -5.7966e-01,\n",
      "          -1.4282e+00,  1.9012e+00, -3.8077e-01,  1.4696e+00,  8.0506e-01,\n",
      "           3.6918e-01,  6.6982e-01,  0.0000e+00,  8.9158e-02,  1.0255e+00,\n",
      "           9.7811e-01,  0.0000e+00,  6.5964e-01, -1.1450e+00, -1.6456e+00,\n",
      "          -6.0007e-01,  8.9749e-03, -7.1100e-01,  0.0000e+00, -2.2412e-01,\n",
      "          -7.5235e-01,  5.7220e-01,  5.3058e-01, -6.6360e-01,  1.5466e+00,\n",
      "           5.7833e-01,  1.8920e+00, -8.6406e-01,  4.9357e-01, -3.8727e-01,\n",
      "           5.0008e-01,  0.0000e+00,  1.7728e+00,  0.0000e+00, -8.0797e-01,\n",
      "          -6.2185e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0491, 0.1051, 0.1203, 0.1305, 0.1280, 0.1811, 0.0675, 0.0583, 0.0535,\n",
      "         0.1066]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3544, -0.0258,  0.0803,  ..., -0.1193, -0.0266, -0.4760],\n",
      "        [ 0.2448,  0.0404, -0.1500,  ..., -0.3241, -0.1259,  0.1285],\n",
      "        [ 0.0596,  0.1640,  0.1700,  ..., -0.0256,  0.0348,  0.3625],\n",
      "        ...,\n",
      "        [ 0.1137, -0.2778,  0.2607,  ...,  0.6766,  0.4033,  0.0790],\n",
      "        [ 0.2240, -0.1304, -0.0609,  ...,  0.0556,  0.5531,  0.0153],\n",
      "        [ 0.4827,  0.3742, -0.5911,  ...,  0.0166,  0.1714,  0.1230]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2147e-01, -9.8845e-02, -1.1049e-01,  1.6602e-01, -2.8663e-02,\n",
      "           1.0104e-01, -3.2768e-01, -1.6442e-01,  3.8830e-02,  1.9629e-01,\n",
      "           7.7142e-02, -1.3449e-01, -4.6435e-02, -6.1597e-02,  5.0648e-02,\n",
      "           2.6064e-01,  1.0947e-01,  6.1493e-02, -1.6371e-01, -9.3239e-02,\n",
      "          -3.7805e-01,  1.2603e-03, -6.3107e-02,  2.4908e-01,  7.0786e-02,\n",
      "          -5.9165e-02,  8.9159e-02, -1.0384e-01, -2.4969e-01, -5.9797e-02,\n",
      "          -7.3917e-02, -9.9220e-02,  1.7900e-01,  7.5304e-02, -8.8147e-02,\n",
      "          -1.4360e-01, -1.0910e-01, -3.6226e-02, -5.8527e-02, -2.0884e-01,\n",
      "           2.2581e-02,  1.0626e-01,  6.0382e-03, -5.4023e-02,  7.5326e-02,\n",
      "           2.8214e-02,  5.1293e-02, -1.3797e-02,  1.0362e-01,  5.7048e-02,\n",
      "          -3.4940e-01, -5.4894e-02, -3.1232e-02, -1.8840e-01, -3.6945e-01,\n",
      "           6.0038e-02, -8.1401e-02,  2.1882e-01,  5.2323e-03,  8.4722e-02,\n",
      "          -1.3338e-01, -1.5896e-02, -8.2109e-02,  7.0366e-02,  3.1971e-01,\n",
      "           9.1257e-03, -8.6468e-02, -1.0457e-01, -1.9598e-01, -2.2114e-01,\n",
      "           1.6348e-01,  4.0031e-01, -8.1502e-02, -1.8038e-01, -1.5946e-01,\n",
      "          -8.8179e-02,  4.0281e-01,  6.9316e-02,  3.8031e-02,  1.2390e-01,\n",
      "          -2.9634e-01, -1.3103e-01, -3.2877e-01,  2.1006e-01,  9.7716e-02,\n",
      "           4.1978e-02,  1.4042e-01,  9.8204e-02, -2.3768e-01,  2.3045e-01,\n",
      "           1.2112e-01,  1.8688e-01, -6.0705e-02, -1.9757e-01,  1.5667e-01,\n",
      "           4.5076e-01,  1.0776e-01,  2.6006e-01,  1.4489e-01, -8.6217e-02,\n",
      "           4.9340e-02,  1.4251e-01,  2.1988e-01,  2.0104e-02, -8.1900e-02,\n",
      "          -1.7100e-01, -1.3477e-01,  1.2627e-01, -1.4538e-01, -1.6435e-02,\n",
      "          -1.4176e-01,  9.5452e-02, -1.5274e-01,  4.7792e-02,  2.5336e-02,\n",
      "           4.8280e-02, -1.2720e-02, -2.5607e-01,  3.5918e-03, -1.1715e-01,\n",
      "           2.0656e-01,  4.2707e-03, -1.5517e-01,  1.1972e-01, -1.0726e-01,\n",
      "          -2.3559e-01, -7.2073e-02, -9.0421e-02,  3.8100e-01,  1.7443e-01,\n",
      "           2.5313e-01, -6.5107e-02,  9.8537e-02,  6.8480e-02, -2.8876e-01,\n",
      "          -8.2615e-02,  4.3639e-01, -1.4088e-01, -2.3990e-02,  4.0162e-02,\n",
      "           7.8253e-02,  2.7059e-01, -2.7917e-01,  2.2371e-01,  1.4756e-01,\n",
      "           1.2244e-01,  3.1612e-01,  3.4289e-01, -1.6468e-01,  1.2620e-01,\n",
      "          -4.0653e-01, -7.5530e-02,  1.1631e-01,  1.6400e-01, -2.6243e-02,\n",
      "           2.2704e-01,  7.0374e-02,  3.4427e-01, -3.9333e-02,  1.0193e-01,\n",
      "          -2.7217e-01,  7.0693e-02, -2.2293e-01, -1.0078e-02, -2.8044e-01,\n",
      "          -1.4214e-01, -2.2301e-01,  8.8299e-02, -5.9736e-02,  4.2525e-01,\n",
      "           4.9258e-02,  6.8295e-03, -2.6319e-02,  8.5700e-02,  1.5868e-01,\n",
      "           2.5504e-03,  9.0239e-02, -6.2780e-02,  2.7777e-01, -3.8300e-03,\n",
      "           5.5239e-02,  3.3307e-02, -1.4180e-01, -1.3797e-01,  1.8708e-01,\n",
      "          -6.5721e-02, -1.8063e-01,  8.6012e-02,  1.5572e-01, -1.9491e-01,\n",
      "           6.7034e-02, -1.2265e-01, -1.4029e-01,  2.8477e-02, -1.6139e-01,\n",
      "           4.5942e-02,  1.0830e-01, -1.4862e-01, -3.1606e-01,  1.0960e-01,\n",
      "          -4.0463e-02,  2.3850e-02, -7.1718e-02,  1.8487e-01, -3.2065e-01,\n",
      "          -1.2557e-01, -5.3263e-02,  5.7447e-02, -2.3911e-01, -1.1012e-01,\n",
      "           1.3487e-01,  6.6966e-02, -1.3087e-01,  1.4273e-01,  1.0567e-01,\n",
      "          -9.7109e-02,  1.6867e-01,  2.7775e-01, -1.3358e-01, -2.0673e-01,\n",
      "          -3.6258e-04, -1.1566e-01,  1.7652e-01,  6.3636e-03, -1.9768e-02,\n",
      "           1.3461e-01,  2.0498e-01, -1.9415e-01, -3.0581e-01,  1.1593e-01,\n",
      "          -1.7209e-01, -3.9818e-01,  1.1978e-01,  8.5732e-02,  5.0989e-02,\n",
      "          -2.2929e-01, -9.4179e-03, -5.6341e-02,  6.6920e-02,  1.6392e-01,\n",
      "           1.2860e-01,  9.7924e-02, -3.5082e-01,  3.5291e-02,  6.2770e-03,\n",
      "          -7.7468e-02, -1.3723e-01,  8.3623e-02, -1.9267e-01,  6.5251e-02,\n",
      "           1.8574e-01,  1.2846e-01, -6.2994e-02,  3.0983e-02,  8.5062e-02,\n",
      "          -2.2363e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0628e+00, -6.9694e-02, -1.8078e+00,  1.3220e+00,  5.1608e-01,\n",
      "          -3.7615e-01,  1.0706e-03, -7.2302e-01,  2.1179e+00, -2.1387e-01,\n",
      "           2.8215e-01,  8.3071e-01, -1.1107e+00,  1.9985e-01,  3.1234e-01,\n",
      "           3.5181e-01,  0.0000e+00,  1.6906e-01,  8.7450e-01,  5.4566e-01,\n",
      "           1.8833e+00,  6.0194e-01, -3.6772e-02, -5.3539e-01, -1.0015e-01,\n",
      "           0.0000e+00, -1.6088e+00, -1.3623e+00, -2.1267e+00, -1.0344e+00,\n",
      "           3.8890e-02, -1.4547e+00, -2.0767e+00,  3.1568e-01, -2.8495e-01,\n",
      "          -2.0018e+00,  2.1901e-01,  9.9703e-01,  6.0115e-01,  9.5358e-01,\n",
      "          -2.2518e-01, -2.2112e+00, -7.0621e-01,  1.3960e+00,  8.9642e-02,\n",
      "          -1.1386e+00,  2.4253e-01,  7.4188e-01, -7.0969e-01, -1.3360e+00,\n",
      "           0.0000e+00,  0.0000e+00,  6.6270e-01,  1.1164e+00,  5.6726e-01,\n",
      "           3.3306e-01, -4.4965e-01, -8.8805e-01,  1.3371e-01,  6.2848e-01,\n",
      "          -7.0479e-01,  5.6367e-01, -6.9330e-01, -1.5473e+00,  2.8929e-01,\n",
      "           9.5769e-02, -1.7745e-01,  5.9493e-01, -2.1384e+00,  5.5976e-01,\n",
      "           1.8279e-01, -5.1244e-01, -3.4112e-01, -1.1319e+00, -6.4739e-01,\n",
      "           4.6096e-01, -1.0492e+00,  1.1900e-01,  5.1720e-01, -1.8665e-01,\n",
      "          -3.8498e-01,  2.1580e+00,  7.7746e-01, -8.4543e-01,  3.9774e-01,\n",
      "           4.1922e-01,  1.6046e+00, -5.6416e-01, -1.4132e+00, -1.4906e+00,\n",
      "           0.0000e+00, -3.5155e-01,  4.9387e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6298e-01,  1.3202e+00, -9.0762e-01,  2.3908e+00,  9.5525e-01,\n",
      "          -1.2008e+00,  5.9437e-01,  1.0665e+00, -1.7339e+00,  3.6530e-01,\n",
      "           4.0225e-01, -1.2704e+00,  4.5495e-01,  1.9688e+00,  1.4950e-01,\n",
      "          -8.3242e-01,  5.3398e-01,  8.0825e-01,  6.6426e-01,  0.0000e+00,\n",
      "           9.1767e-01, -7.0291e-01, -8.4517e-01,  2.5770e-01,  8.7979e-01,\n",
      "           0.0000e+00, -1.3966e+00, -3.6486e-01, -1.8465e+00, -1.3006e+00,\n",
      "           1.0693e+00, -8.1154e-01,  6.4939e-01,  2.5567e-01, -1.4895e+00,\n",
      "           2.5024e+00,  0.0000e+00, -1.3457e+00,  7.2242e-01,  3.2011e+00,\n",
      "          -7.5281e-01, -3.8361e-01,  1.2823e+00,  0.0000e+00,  1.9398e-01,\n",
      "          -3.9221e-02,  3.0300e+00,  3.6269e-01, -1.8704e-01, -1.1121e+00,\n",
      "           1.2470e+00,  7.7539e-01, -7.7457e-01, -4.4906e-02, -1.3871e+00,\n",
      "           2.3359e+00,  0.0000e+00,  0.0000e+00, -2.1306e+00,  0.0000e+00,\n",
      "           7.8587e-01, -1.8620e+00, -1.3046e+00,  1.9021e-01, -3.6290e+00,\n",
      "          -1.8688e+00,  1.1505e+00, -8.5959e-01,  9.5964e-01,  0.0000e+00,\n",
      "          -2.7191e-02,  1.9745e+00,  1.1270e+00, -4.8580e-01, -1.2415e+00,\n",
      "          -2.1228e-01, -1.3225e+00, -1.6392e+00, -7.7176e-01,  6.8262e-01,\n",
      "          -1.3796e+00, -1.2607e-01,  6.0653e-01, -7.4891e-01,  2.5913e-01,\n",
      "           1.3325e+00, -2.5534e+00,  0.0000e+00, -5.8366e-01,  1.6234e+00,\n",
      "          -1.2403e+00, -1.8841e-03, -5.0250e-02,  9.0120e-01,  5.6545e-01,\n",
      "          -4.2001e-01,  0.0000e+00, -1.1593e-01,  8.0981e-01,  1.0502e+00,\n",
      "          -7.8913e-01, -1.4387e+00, -4.1571e-01, -7.5040e-01, -4.5413e-01,\n",
      "           0.0000e+00,  7.2225e-01, -1.8533e+00,  1.3574e+00,  8.3760e-01,\n",
      "           0.0000e+00, -3.5894e-01,  0.0000e+00,  2.0055e-01, -2.1782e+00,\n",
      "           8.3545e-01, -1.2912e+00, -1.2839e+00,  2.6116e-01, -1.5635e+00,\n",
      "           2.0757e+00,  1.3420e-01,  2.5769e+00, -3.1079e-02, -5.7966e-01,\n",
      "          -1.4282e+00,  1.9012e+00, -3.8077e-01,  1.4696e+00,  8.0506e-01,\n",
      "           0.0000e+00,  6.6982e-01,  0.0000e+00,  8.9158e-02,  0.0000e+00,\n",
      "           0.0000e+00, -1.4083e+00,  6.5964e-01, -1.1450e+00, -1.6456e+00,\n",
      "           0.0000e+00,  8.9749e-03, -7.1100e-01,  3.7049e-01, -2.2412e-01,\n",
      "           0.0000e+00,  5.7220e-01,  5.3058e-01, -6.6360e-01,  1.5466e+00,\n",
      "           5.7833e-01,  1.8920e+00,  0.0000e+00,  4.9357e-01, -3.8727e-01,\n",
      "           0.0000e+00, -9.7501e-01,  1.7728e+00, -1.0635e+00,  0.0000e+00,\n",
      "          -6.2185e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0609, 0.1216, 0.1427, 0.1613, 0.1002, 0.1157, 0.0699, 0.0527, 0.0548,\n",
      "         0.1201]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3544, -0.0258,  0.0803,  ..., -0.1193, -0.0266, -0.4760],\n",
      "        [ 0.2448,  0.0404, -0.1500,  ..., -0.3241, -0.1259,  0.1285],\n",
      "        [ 0.0596,  0.1640,  0.1700,  ..., -0.0256,  0.0348,  0.3625],\n",
      "        ...,\n",
      "        [ 0.1137, -0.2778,  0.2607,  ...,  0.6766,  0.4033,  0.0790],\n",
      "        [ 0.2240, -0.1304, -0.0609,  ...,  0.0556,  0.5531,  0.0153],\n",
      "        [ 0.4827,  0.3742, -0.5911,  ...,  0.0166,  0.1714,  0.1230]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1392, -0.0800, -0.1390,  0.1449, -0.0217,  0.1296, -0.3173,\n",
      "          -0.1623,  0.0482,  0.1896,  0.0574, -0.1585, -0.0867, -0.0822,\n",
      "           0.0334,  0.2886,  0.1072,  0.0531, -0.2008, -0.1045, -0.3795,\n",
      "          -0.0007, -0.0697,  0.2078,  0.0511, -0.0692,  0.0708, -0.1042,\n",
      "          -0.2273, -0.0680, -0.0594, -0.0694,  0.1605,  0.0469, -0.0796,\n",
      "          -0.1065, -0.1342, -0.0253, -0.0660, -0.1975,  0.0603,  0.1324,\n",
      "          -0.0016, -0.0723,  0.1043,  0.0297,  0.0388, -0.0228,  0.1295,\n",
      "           0.0683, -0.3391, -0.1085, -0.0195, -0.1758, -0.3849,  0.0504,\n",
      "          -0.0797,  0.2424,  0.0493,  0.1041, -0.1329, -0.0497, -0.1101,\n",
      "           0.0742,  0.2978,  0.0048, -0.0741, -0.1329, -0.1717, -0.2075,\n",
      "           0.2051,  0.4116, -0.0897, -0.1739, -0.1535, -0.0662,  0.3827,\n",
      "           0.0631,  0.0313,  0.1086, -0.2971, -0.1018, -0.2929,  0.1968,\n",
      "           0.1123,  0.0504,  0.1239,  0.1091, -0.2131,  0.1914,  0.1160,\n",
      "           0.1966, -0.0552, -0.1875,  0.1482,  0.4194,  0.1317,  0.3023,\n",
      "           0.1203, -0.0492,  0.0361,  0.1597,  0.2175,  0.0648, -0.0790,\n",
      "          -0.2048, -0.1098,  0.0922, -0.1821, -0.0045, -0.1116,  0.0923,\n",
      "          -0.1219,  0.0540,  0.0568,  0.0222,  0.0120, -0.2383, -0.0211,\n",
      "          -0.1342,  0.2276,  0.0014, -0.1311,  0.0967, -0.1077, -0.2328,\n",
      "          -0.0590, -0.0920,  0.4124,  0.1648,  0.2110, -0.0644,  0.1192,\n",
      "           0.0647, -0.2895, -0.0690,  0.4376, -0.1096, -0.0006,  0.0221,\n",
      "           0.0675,  0.2661, -0.2644,  0.2525,  0.1195,  0.0994,  0.3305,\n",
      "           0.3678, -0.1661,  0.1023, -0.4178, -0.0918,  0.1318,  0.2020,\n",
      "          -0.0528,  0.2199,  0.0802,  0.3417, -0.0308,  0.1213, -0.2585,\n",
      "           0.0674, -0.2279,  0.0405, -0.2658, -0.1502, -0.1946,  0.0858,\n",
      "          -0.0322,  0.3994,  0.0272,  0.0464,  0.0019,  0.1112,  0.1661,\n",
      "           0.0169,  0.0835, -0.0494,  0.2794,  0.0072,  0.0185,  0.0631,\n",
      "          -0.1564, -0.1226,  0.1801, -0.0674, -0.1646,  0.0612,  0.1135,\n",
      "          -0.1879,  0.0422, -0.1094, -0.1431,  0.0081, -0.1415,  0.0364,\n",
      "           0.0672, -0.1339, -0.2964,  0.1116, -0.0460,  0.0446, -0.0175,\n",
      "           0.2116, -0.2807, -0.0984, -0.0644,  0.0425, -0.2249, -0.1057,\n",
      "           0.1573,  0.0506, -0.1210,  0.1351,  0.0946, -0.1178,  0.1705,\n",
      "           0.2825, -0.1855, -0.1658,  0.0636, -0.1208,  0.2051, -0.0353,\n",
      "          -0.0354,  0.1756,  0.1932, -0.1724, -0.3460,  0.1160, -0.1741,\n",
      "          -0.3895,  0.1069,  0.0365, -0.0080, -0.2615, -0.0668, -0.0396,\n",
      "           0.0937,  0.1611,  0.1387,  0.0459, -0.3233,  0.0335,  0.0284,\n",
      "          -0.0852, -0.1869,  0.0680, -0.2247,  0.0559,  0.1817,  0.1249,\n",
      "          -0.0668,  0.0214,  0.0819, -0.0152]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6500e-02,  3.9959e-01, -9.6545e-01, -6.8113e-01,  3.7569e-01,\n",
      "          -2.0195e-01,  1.4647e+00, -8.3485e-02, -3.5837e+00,  9.0657e-01,\n",
      "           0.0000e+00, -6.2907e-01,  2.6031e+00, -6.2991e-01, -5.4130e-01,\n",
      "          -1.5795e-01,  8.5120e-01,  1.0946e+00,  4.5518e-01,  0.0000e+00,\n",
      "          -6.3332e-01, -3.8273e-01,  1.6404e+00,  1.5109e+00,  7.5330e-01,\n",
      "          -7.5726e-02, -1.8798e-01, -7.5951e-01,  1.6534e+00,  8.6141e-01,\n",
      "           1.2316e+00,  1.2190e+00, -1.0342e+00, -8.2910e-02, -1.5343e+00,\n",
      "           0.0000e+00,  2.8083e-01, -3.7441e+00,  1.9778e-01,  1.6004e+00,\n",
      "          -4.5898e-01, -1.3979e+00, -2.6863e-01, -1.7150e+00, -1.5237e+00,\n",
      "           6.6748e-01,  5.4065e-01,  3.7088e-01, -1.3404e+00,  1.4435e-01,\n",
      "           0.0000e+00,  2.7512e+00,  6.1019e-01, -1.0289e+00, -2.5189e-02,\n",
      "           2.0364e-01, -8.8152e-01, -1.2517e+00, -2.3705e-01, -4.2576e-01,\n",
      "           1.0997e+00,  1.4076e+00, -2.0276e-01, -5.0108e-01, -2.9630e+00,\n",
      "           5.5112e-01,  1.2783e+00, -1.2876e+00,  4.1069e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.9944e-02,  7.0731e-01, -3.6404e+00,  3.2540e-01,\n",
      "          -1.0777e-03, -1.5999e-01,  1.0619e+00, -5.7817e-02, -1.1873e-01,\n",
      "          -1.4000e+00,  2.1305e+00, -9.2437e-01,  1.0058e+00, -2.0757e-01,\n",
      "           4.3557e-01,  1.6614e+00, -9.7396e-01, -1.0400e-01, -5.8124e-01,\n",
      "          -2.2726e+00,  1.0999e+00, -6.2235e-01, -1.1356e+00,  0.0000e+00,\n",
      "          -1.1703e+00,  3.3464e-02,  6.2895e-01,  1.7194e+00, -7.7922e-01,\n",
      "           2.6969e+00, -1.4619e+00,  1.0759e+00,  1.4531e+00, -6.6623e-01,\n",
      "          -7.6239e-01,  1.2114e+00,  0.0000e+00, -1.4728e+00, -1.3574e-02,\n",
      "          -2.4833e-01,  1.3417e-01, -1.0475e+00,  1.3099e+00, -1.6526e+00,\n",
      "          -2.9884e+00, -5.6706e-02, -4.9995e-01, -1.9337e-01,  4.4531e-01,\n",
      "          -1.4655e+00,  0.0000e+00, -1.4602e+00, -7.2573e-01, -9.5803e-01,\n",
      "          -1.3083e+00,  8.9622e-01,  1.6971e-01,  1.2847e+00, -7.5154e-01,\n",
      "          -8.2382e-01,  5.3043e-01, -1.5827e+00,  9.8394e-01,  0.0000e+00,\n",
      "          -5.8930e-01,  6.5893e-01,  0.0000e+00, -1.1588e+00, -1.0096e+00,\n",
      "          -3.8827e-01,  0.0000e+00, -7.8961e-01, -1.0090e-01, -1.6849e+00,\n",
      "          -1.0059e-01,  0.0000e+00, -8.4427e-01, -7.5521e-01,  1.7753e-01,\n",
      "           0.0000e+00, -1.9936e-01, -1.9298e+00, -4.0611e-01,  4.4127e-01,\n",
      "          -1.9443e-01, -6.4721e-02, -1.2993e-01,  3.9158e-02,  5.3744e-01,\n",
      "          -2.6515e-02,  0.0000e+00,  0.0000e+00, -5.5014e-01, -5.2628e-01,\n",
      "          -8.9182e-01,  2.8150e-01,  8.3208e-02, -3.5803e-01, -4.7784e-01,\n",
      "           7.3662e-01, -3.1194e-02,  2.0065e-02, -1.0022e+00,  1.2776e+00,\n",
      "           0.0000e+00, -9.8638e-01, -2.0759e+00,  0.0000e+00,  8.6527e-02,\n",
      "           0.0000e+00,  3.5006e-02,  0.0000e+00,  9.7977e-01, -7.4733e-01,\n",
      "          -3.4097e-01,  0.0000e+00, -7.8339e-01,  1.2091e+00,  1.0125e+00,\n",
      "           3.0730e+00,  4.9407e-01, -1.4432e-01, -5.9336e-01,  5.6024e-01,\n",
      "           2.1645e+00, -1.1876e+00,  5.3500e-01,  1.8111e+00, -9.4641e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  1.2421e+00, -1.2211e-01,  2.3203e-01,\n",
      "          -5.7486e-01, -2.2921e+00,  6.8166e-01, -1.0736e+00, -4.7097e-01,\n",
      "           2.8674e+00, -5.7325e-01, -3.4116e-01,  7.9290e-01,  3.0946e-02,\n",
      "          -6.8382e-01, -1.0181e+00,  0.0000e+00, -2.4530e-01,  0.0000e+00,\n",
      "          -1.0827e+00, -4.2707e-01,  0.0000e+00, -5.0062e-01,  3.3867e-01,\n",
      "           7.0488e-01, -6.9657e-01, -6.2813e-01,  2.9225e-01, -1.5779e+00,\n",
      "          -1.1083e+00,  1.5812e+00, -6.1395e-01,  1.3100e+00, -2.9793e+00,\n",
      "           0.0000e+00,  5.8518e-01,  4.3141e-02, -1.5792e+00, -2.8648e-01,\n",
      "           7.4186e-01, -3.2474e+00, -3.0392e-01, -8.5184e-01,  1.1343e-02,\n",
      "           2.7554e-01,  2.7465e-01,  2.5226e-01,  2.6136e-01,  3.8660e-01,\n",
      "          -3.6567e-01, -1.5927e-01, -5.5371e-01, -5.2290e-02, -1.1465e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0354, 0.0723, 0.0916, 0.0802, 0.1192, 0.2673, 0.0723, 0.0954, 0.0640,\n",
      "         0.1023]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1191, -0.0327, -0.2306, -0.0340, -0.0744, -0.1113, -0.2017,\n",
      "          -0.2130,  0.0895,  0.1060,  0.1554, -0.2404, -0.0333, -0.2484,\n",
      "           0.0273,  0.0149,  0.2709,  0.3273, -0.0011,  0.1549, -0.0778,\n",
      "          -0.2032,  0.0623,  0.1337, -0.0747,  0.1773, -0.0774, -0.1648,\n",
      "          -0.1404, -0.0904, -0.0367,  0.0878,  0.2431,  0.1235,  0.0413,\n",
      "          -0.0899, -0.0915, -0.0603,  0.0988, -0.0909,  0.0454, -0.0135,\n",
      "          -0.0861, -0.1852, -0.0449,  0.0462, -0.1450, -0.2345,  0.1470,\n",
      "           0.0470, -0.1766, -0.1416, -0.0770, -0.0037, -0.3606, -0.1216,\n",
      "          -0.0869,  0.1594,  0.1243,  0.1288, -0.1108, -0.0432, -0.0396,\n",
      "           0.0659,  0.4528,  0.0043, -0.1651, -0.0913,  0.1870, -0.0265,\n",
      "           0.0971,  0.0670,  0.2608, -0.0968, -0.0397,  0.1864,  0.1276,\n",
      "           0.0105, -0.0712,  0.2687, -0.0317, -0.0754, -0.1235,  0.1107,\n",
      "          -0.0696, -0.0941, -0.1465,  0.0412, -0.1082, -0.0366,  0.1027,\n",
      "           0.1554,  0.1543, -0.1669,  0.1136,  0.2837, -0.0337,  0.3671,\n",
      "           0.2968, -0.0606, -0.1089, -0.1287,  0.1729,  0.0166, -0.0882,\n",
      "          -0.0645, -0.0336,  0.0331, -0.2139,  0.0898,  0.1179,  0.2214,\n",
      "           0.0970, -0.1544, -0.0195, -0.0025,  0.2416, -0.0266, -0.0647,\n",
      "          -0.1617,  0.2569,  0.0257, -0.0825,  0.1147,  0.0038, -0.2565,\n",
      "          -0.1094, -0.2023,  0.4061, -0.1093,  0.2075, -0.1164,  0.1413,\n",
      "           0.1841, -0.1128,  0.2504,  0.3287,  0.0358,  0.0569, -0.2406,\n",
      "          -0.0871,  0.0538, -0.3515,  0.2302, -0.1150,  0.3342,  0.0237,\n",
      "           0.3307,  0.0279,  0.1866,  0.0311,  0.0379,  0.1399,  0.0805,\n",
      "           0.1863,  0.2179, -0.0054,  0.0598,  0.0750, -0.0936, -0.1820,\n",
      "          -0.3090, -0.3107,  0.3392, -0.1333, -0.1180, -0.1479,  0.1758,\n",
      "           0.1621, -0.0326, -0.0796,  0.0938,  0.3547, -0.0234,  0.0703,\n",
      "          -0.1582,  0.0492, -0.1079,  0.0738, -0.0991, -0.0394,  0.1722,\n",
      "           0.0672, -0.2251,  0.0192, -0.2479, -0.2099, -0.1607, -0.0226,\n",
      "          -0.0792, -0.3198, -0.1221, -0.0227,  0.0309, -0.1717, -0.0938,\n",
      "          -0.1078, -0.2608, -0.2269,  0.2188, -0.0418,  0.0055, -0.1489,\n",
      "           0.1233,  0.0454, -0.3317, -0.1660,  0.0240,  0.0420, -0.2306,\n",
      "          -0.0044, -0.0602,  0.0066,  0.3015, -0.2281, -0.0411, -0.2831,\n",
      "           0.0943, -0.1326, -0.0688, -0.0363, -0.2017,  0.0214,  0.1170,\n",
      "          -0.0873,  0.0672,  0.1474, -0.0633, -0.2222,  0.1272, -0.0047,\n",
      "          -0.1697, -0.0908, -0.0359, -0.0889, -0.2671,  0.0427,  0.0742,\n",
      "           0.3292,  0.1782,  0.1603,  0.1139, -0.0575,  0.0535, -0.1549,\n",
      "          -0.0889, -0.0962,  0.0817, -0.1297,  0.0104,  0.3902,  0.0983,\n",
      "          -0.0862, -0.1209, -0.0806, -0.2092]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1546, -1.4810,  1.6542, -1.0092, -1.1129,  0.0000,  0.6459,\n",
      "          -1.2221, -0.9020,  0.0943, -0.2104,  0.3158,  0.1260, -0.9576,\n",
      "          -0.3084,  0.3244, -1.8655, -2.1361,  0.6077, -0.5291,  0.7697,\n",
      "           0.2831, -1.2573, -0.9726,  1.1923,  0.0000, -1.6558,  1.0545,\n",
      "           0.9843, -1.2888,  0.3065, -0.9454, -0.7688,  0.0000, -0.3682,\n",
      "           0.4837, -0.9886,  0.0000,  0.3282,  0.6278,  0.6074, -1.1763,\n",
      "           0.3725,  1.2540, -1.7949,  1.9480, -1.4984, -0.4424, -0.2787,\n",
      "           1.1461,  0.0000,  0.0000, -0.0721, -1.0043, -0.2963, -0.8048,\n",
      "           0.0000,  0.5101,  1.5725,  2.0571, -0.8822, -0.7339,  1.9471,\n",
      "          -0.9057, -0.8591,  0.0000,  0.6386, -0.6167,  0.0203,  0.4298,\n",
      "          -1.5890, -0.0278, -0.6441,  1.4262, -0.4465,  0.5575,  0.0000,\n",
      "          -0.6178, -1.4061, -0.3103,  0.8707,  1.3117,  0.8809, -0.9602,\n",
      "           0.6945,  0.6941,  0.0461, -2.9892,  0.8146, -0.0184, -1.4903,\n",
      "           0.3245, -1.2887,  2.3923,  1.8839,  0.2151, -1.1105,  1.0774,\n",
      "           1.5503, -2.1244,  0.0000, -0.6631, -1.1344, -1.8830,  0.4069,\n",
      "           1.4168, -1.9890, -0.9156,  0.4130,  1.8162, -1.4321,  0.1789,\n",
      "          -0.4970,  1.2997, -0.1464, -0.1101,  0.0000, -1.6420,  0.8514,\n",
      "          -1.2943, -1.3453, -0.0993,  0.8787,  0.5349,  0.2249,  0.8197,\n",
      "          -0.2033, -1.0701,  0.1243,  0.0000, -1.2482,  2.3284,  0.0000,\n",
      "           0.3275, -0.0094, -0.6382, -0.0640, -0.5992, -0.4515,  1.0986,\n",
      "           0.5454, -1.1798, -2.2946, -0.8852,  0.2166, -0.1876,  0.9173,\n",
      "          -0.0830,  1.5433, -0.7186,  0.3219, -1.3512,  1.8157, -1.9307,\n",
      "           0.5127, -0.3340, -0.2290, -0.7580,  0.9342, -0.0182,  0.2297,\n",
      "          -1.1459,  0.0000, -1.7643, -0.3898, -0.6917,  0.5296,  2.1350,\n",
      "          -1.6401, -2.7421,  1.2533, -2.0849, -0.0059, -1.1597, -0.9214,\n",
      "          -0.7981, -0.3058, -0.4303,  0.1177, -1.5137,  0.1503, -0.4530,\n",
      "           0.1990,  0.0000,  0.4838, -0.0759, -1.5016,  0.0000,  0.0000,\n",
      "          -1.4621,  1.0707,  0.6060,  0.0000, -0.5077,  0.7245, -0.0432,\n",
      "           1.8719,  0.0432, -0.8384, -0.2755,  0.1188, -0.2977,  0.2833,\n",
      "           0.3539, -0.0090, -0.7144,  0.6960,  2.0160, -0.7491,  1.8921,\n",
      "           0.0000,  0.1561,  1.5050,  0.1009, -0.5908, -0.0219, -0.1422,\n",
      "          -1.3817,  0.4087,  0.6369, -0.6888,  1.8591,  0.6068,  0.4731,\n",
      "           0.0296,  1.5297, -0.3648,  0.0000,  0.8420, -0.2541,  0.7769,\n",
      "          -0.5510,  0.0000,  0.0929,  2.0767,  0.5536, -1.7044,  2.7777,\n",
      "          -1.4947,  1.8030, -0.8491,  0.2572, -1.0494, -0.8530,  0.1357,\n",
      "          -1.7790,  0.3811,  1.9828,  0.0000,  0.5471, -1.7500,  0.3682,\n",
      "           0.1557,  1.5689, -2.7255,  0.4070]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0532, 0.1418, 0.1235, 0.0663, 0.1187, 0.2066, 0.0464, 0.0566, 0.1129,\n",
      "         0.0740]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1602,  0.0247, -0.2491, -0.0271, -0.0494, -0.0464, -0.2269,\n",
      "          -0.2568,  0.0831,  0.1130,  0.1493, -0.2740, -0.0476, -0.2642,\n",
      "           0.0498,  0.0697,  0.2500,  0.2805, -0.0153,  0.1115, -0.1353,\n",
      "          -0.2006,  0.0221,  0.1601, -0.0939,  0.1385, -0.0634, -0.1449,\n",
      "          -0.1389, -0.1057, -0.0553,  0.0408,  0.2174,  0.0909, -0.0013,\n",
      "          -0.0439, -0.0984, -0.0748,  0.0618, -0.1084,  0.0273,  0.0086,\n",
      "          -0.1381, -0.2023,  0.0270,  0.0377, -0.1668, -0.2024,  0.1564,\n",
      "           0.0969, -0.1479, -0.1898, -0.0679, -0.0161, -0.3796, -0.0703,\n",
      "          -0.1000,  0.1973,  0.1618,  0.1040, -0.1291, -0.0545, -0.0930,\n",
      "           0.0604,  0.4453,  0.0107, -0.1095, -0.0752,  0.1181, -0.0159,\n",
      "           0.1026,  0.1226,  0.2440, -0.1008, -0.0540,  0.1783,  0.1687,\n",
      "          -0.0070, -0.1109,  0.2594, -0.0711, -0.0723, -0.1559,  0.1286,\n",
      "          -0.0302, -0.0688, -0.1166,  0.0618, -0.1206, -0.0796,  0.1287,\n",
      "           0.2016,  0.1008, -0.1868,  0.1042,  0.2437,  0.0323,  0.4148,\n",
      "           0.2238, -0.0052, -0.0844, -0.0966,  0.1625,  0.0488, -0.0793,\n",
      "          -0.0770, -0.0336,  0.0518, -0.2079,  0.0887,  0.1357,  0.1744,\n",
      "           0.0561, -0.1829, -0.0220,  0.0062,  0.2467, -0.0464, -0.1062,\n",
      "          -0.1597,  0.2522, -0.0141, -0.1005,  0.1151, -0.0248, -0.2257,\n",
      "          -0.0757, -0.1771,  0.4307, -0.0783,  0.1819, -0.1098,  0.1453,\n",
      "           0.1797, -0.1383,  0.1963,  0.3297,  0.0495,  0.0250, -0.2133,\n",
      "          -0.0956,  0.1053, -0.3585,  0.2235, -0.1010,  0.2784,  0.0635,\n",
      "           0.3854,  0.0151,  0.1832, -0.0390, -0.0256,  0.1201,  0.0953,\n",
      "           0.1392,  0.1848, -0.0338,  0.1001,  0.0353, -0.0967, -0.2227,\n",
      "          -0.2562, -0.3146,  0.3669, -0.1352, -0.0995, -0.1048,  0.1822,\n",
      "           0.1811,  0.0923, -0.0904,  0.1335,  0.3349, -0.0168,  0.0371,\n",
      "          -0.1164,  0.0813, -0.0742,  0.1502, -0.0214, -0.0810,  0.1285,\n",
      "           0.0194, -0.1621,  0.0288, -0.2022, -0.2310, -0.1358, -0.0406,\n",
      "          -0.0517, -0.2923, -0.0911, -0.0863,  0.0121, -0.1411, -0.1057,\n",
      "          -0.1407, -0.2624, -0.2535,  0.2327, -0.0722,  0.0396, -0.0909,\n",
      "           0.1701,  0.0151, -0.2713, -0.2030,  0.0077,  0.0044, -0.1608,\n",
      "           0.0085, -0.0631, -0.0142,  0.2856, -0.1664, -0.0152, -0.2693,\n",
      "           0.0950, -0.1929, -0.0479,  0.0241, -0.1971,  0.0858,  0.0108,\n",
      "          -0.0626,  0.0853,  0.1599, -0.0403, -0.2852,  0.1428, -0.0616,\n",
      "          -0.1735, -0.0513, -0.0383, -0.1234, -0.2818, -0.0484,  0.0869,\n",
      "           0.3305,  0.1655,  0.1440,  0.0444, -0.0438,  0.0629, -0.1407,\n",
      "          -0.1060, -0.1522,  0.0758, -0.1180,  0.0358,  0.3694,  0.0865,\n",
      "          -0.0750, -0.1384, -0.0814, -0.1705]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.0000, -1.6519, -0.1831,  0.0000,  2.5182, -1.9079,\n",
      "          -0.0322,  0.9501,  1.1946,  1.4102, -0.7570, -0.0650,  0.0644,\n",
      "           1.0464,  1.8849,  0.8699, -0.7846, -0.6402, -1.4034, -0.4984,\n",
      "          -0.3792,  0.0000,  0.2330,  0.1891, -0.6129,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.5712,  0.6009, -1.6986,  0.2318, -0.0795,\n",
      "           0.1484,  0.6450, -2.2130,  1.0517,  0.1023, -0.6919, -0.4361,\n",
      "          -1.0640,  0.8178, -0.6326, -0.6561,  1.3725,  0.9364,  1.6035,\n",
      "           0.3693, -1.0082, -1.1724, -1.1125,  1.2530, -1.9746,  1.7088,\n",
      "           0.0000, -1.8923,  0.3414, -0.2939, -0.7703,  1.8691, -0.5938,\n",
      "          -1.6814, -0.8353,  0.0000, -0.3574,  0.2900, -0.7529, -1.1645,\n",
      "           2.2476,  0.0000,  0.0000,  1.2050, -0.3984,  0.3548,  0.2297,\n",
      "          -0.1575, -0.9149,  0.2960, -0.1449,  1.2864,  0.4653,  1.2970,\n",
      "           0.7705,  0.6606,  1.0454, -0.3682, -1.2411, -1.4363,  1.3105,\n",
      "          -1.5854, -0.1110,  3.2387,  0.3468,  1.0035, -0.8684,  0.7313,\n",
      "          -1.6815, -0.9243,  0.1908,  0.0286, -0.5966,  1.0585, -0.2310,\n",
      "           0.7758, -0.9058, -0.3679, -0.2784,  0.0000,  0.0000, -3.2784,\n",
      "          -0.1010,  0.0000,  1.6976,  0.0000,  2.0295, -1.6459, -0.8963,\n",
      "           2.5842, -1.3262,  1.4237, -0.6274,  0.0000,  1.3157, -0.9868,\n",
      "           0.0000, -0.9854, -0.6748,  0.2474, -1.2009,  1.1298,  1.1406,\n",
      "           1.4884,  0.3786,  0.6466, -0.8379,  0.2416,  0.3445, -1.2616,\n",
      "           0.0305,  0.8638,  0.5016,  0.0000, -1.2681, -0.6408,  0.0000,\n",
      "           0.8728, -0.0675,  0.0000, -0.0565,  0.6208,  0.0000, -0.1962,\n",
      "           0.1077, -1.6722, -0.4025,  0.2513, -2.0697,  0.4120,  1.1555,\n",
      "           0.1995,  0.9130,  0.8435,  0.4176,  1.6039,  0.1772, -1.1144,\n",
      "          -0.3224,  0.2510,  0.4445, -0.4551,  0.4446, -1.3451,  1.7355,\n",
      "           0.5173,  1.1775,  0.2897, -1.8322, -1.8661,  0.0000, -0.6474,\n",
      "          -1.1657,  0.0000, -0.7441,  0.5921, -1.2414,  0.0000, -2.3036,\n",
      "           0.1466, -1.6242, -1.3208,  0.0000,  1.2995,  0.9802,  0.0000,\n",
      "          -1.1401,  3.0139, -0.2259,  1.0331,  0.0290,  0.1193, -1.3193,\n",
      "          -1.0708,  0.0567,  1.7329,  0.5271,  1.9821, -0.9787, -1.3423,\n",
      "           1.5992, -0.4015,  2.4607, -0.5199,  0.0000,  0.2066, -0.8208,\n",
      "           0.9059, -3.5299,  0.1757, -0.7814,  0.0000,  0.0000,  0.2511,\n",
      "          -0.0646, -1.4654,  0.4266, -0.5196,  0.0000, -0.6250,  0.0000,\n",
      "           0.7485, -2.0270, -1.0490, -0.4313, -0.1124,  0.5161, -2.7968,\n",
      "          -1.4577, -0.6646,  0.0000,  0.1329,  2.7508,  0.0000,  0.5472,\n",
      "          -0.1735, -1.5055,  2.2320,  1.1874, -0.0479,  0.7226,  0.1089,\n",
      "          -2.8554, -0.0138, -0.8380, -0.5807]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0344, 0.1503, 0.1170, 0.1096, 0.0836, 0.1143, 0.0891, 0.0961, 0.1063,\n",
      "         0.0993]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.7101e-01,  5.6005e-02, -1.6878e-01, -1.7741e-02, -2.5771e-02,\n",
      "          -1.4149e-02, -2.7220e-01, -2.4222e-01,  5.4691e-02,  9.0770e-02,\n",
      "           1.3012e-01, -2.5642e-01, -5.3845e-02, -2.5684e-01,  6.5246e-02,\n",
      "           6.8845e-02,  2.1466e-01,  2.5208e-01, -1.3384e-02,  8.4268e-02,\n",
      "          -1.1104e-01, -2.2266e-01, -9.0558e-04,  1.0826e-01, -7.7424e-02,\n",
      "           1.2836e-01, -2.8604e-02, -1.0387e-01, -1.4092e-01, -9.5295e-02,\n",
      "          -6.4836e-02,  2.3840e-02,  2.1517e-01,  6.0691e-02, -8.4329e-02,\n",
      "          -1.7366e-03, -7.6128e-02, -1.1713e-01,  1.0071e-01, -8.0531e-02,\n",
      "           3.7254e-02,  3.1455e-02, -1.8598e-01, -1.9522e-01,  1.9967e-02,\n",
      "           3.6889e-02, -1.7654e-01, -1.8768e-01,  1.0264e-01,  1.4969e-01,\n",
      "          -8.9131e-02, -2.0102e-01, -6.1440e-02, -8.4630e-03, -3.4971e-01,\n",
      "          -4.8568e-02, -1.0602e-01,  2.1024e-01,  1.6752e-01,  6.8822e-02,\n",
      "          -1.0010e-01, -8.3607e-02, -1.3640e-01,  5.5498e-02,  4.2139e-01,\n",
      "           1.5956e-02, -7.0354e-02, -3.7844e-02,  9.4747e-02,  3.1877e-02,\n",
      "           1.2972e-01,  1.2505e-01,  2.5685e-01, -8.9326e-02, -4.4970e-02,\n",
      "           2.0528e-01,  2.0292e-01,  4.6755e-03, -1.3749e-01,  2.5033e-01,\n",
      "          -3.0496e-02, -2.5501e-02, -1.8644e-01,  1.3843e-01, -6.4147e-03,\n",
      "          -8.7051e-02, -8.7663e-02,  7.0793e-02, -9.1762e-02, -5.9313e-02,\n",
      "           6.8857e-02,  1.7942e-01,  9.3342e-02, -1.5053e-01,  9.9601e-02,\n",
      "           2.2242e-01,  6.3056e-02,  4.0686e-01,  1.9650e-01,  4.3011e-03,\n",
      "          -7.9699e-02, -5.1704e-02,  1.2577e-01,  9.0968e-02, -6.9998e-02,\n",
      "          -3.4488e-02, -3.7698e-02,  1.0280e-01, -2.1245e-01,  9.4108e-02,\n",
      "           1.2243e-01,  1.6537e-01,  2.0869e-02, -1.7711e-01, -6.2933e-03,\n",
      "           4.9109e-02,  2.4649e-01, -3.0541e-02, -1.3054e-01, -1.6903e-01,\n",
      "           1.9358e-01, -3.8965e-02, -8.2062e-02,  1.2161e-01, -6.8094e-02,\n",
      "          -2.1444e-01, -6.4083e-02, -1.7437e-01,  3.7254e-01, -8.3334e-02,\n",
      "           1.3367e-01, -8.1527e-02,  1.1560e-01,  1.8883e-01, -1.5947e-01,\n",
      "           1.4846e-01,  2.9621e-01,  6.8852e-02,  5.4894e-03, -1.8221e-01,\n",
      "          -1.2757e-01,  1.0006e-01, -3.2832e-01,  2.0240e-01, -8.9909e-02,\n",
      "           2.5020e-01,  6.5192e-02,  3.7227e-01,  4.2061e-02,  1.6311e-01,\n",
      "          -4.5133e-02,  9.0651e-03,  1.1823e-01,  1.0078e-01,  1.5807e-01,\n",
      "           1.8514e-01, -3.4951e-02,  5.9641e-02, -1.1918e-02, -1.1717e-01,\n",
      "          -1.9785e-01, -2.4646e-01, -2.7470e-01,  3.8782e-01, -1.3691e-01,\n",
      "          -6.7223e-02, -5.0188e-02,  1.4300e-01,  1.7123e-01,  6.5713e-02,\n",
      "          -1.0553e-01,  1.0905e-01,  2.8564e-01,  2.8399e-02,  2.7700e-02,\n",
      "          -1.2503e-01,  8.3523e-02, -1.4340e-02,  1.5611e-01,  5.7798e-03,\n",
      "          -1.0647e-01,  6.9500e-02,  2.2876e-02, -1.7541e-01,  5.2633e-02,\n",
      "          -1.6811e-01, -2.0715e-01, -1.2393e-01, -9.8184e-02, -5.9764e-02,\n",
      "          -2.3451e-01, -8.5784e-02, -1.1227e-01,  2.1440e-02, -1.5242e-01,\n",
      "          -9.9705e-02, -1.4823e-01, -2.4016e-01, -2.0941e-01,  2.4390e-01,\n",
      "          -5.6579e-02,  7.3166e-02, -1.0580e-01,  1.5871e-01, -2.4954e-03,\n",
      "          -2.9114e-01, -2.0973e-01,  5.4974e-03, -3.9449e-02, -1.3412e-01,\n",
      "          -2.8827e-02, -5.3539e-02, -1.9367e-02,  2.6739e-01, -1.6542e-01,\n",
      "           1.8688e-02, -2.3515e-01,  9.3774e-02, -2.0961e-01, -2.6516e-02,\n",
      "           7.3818e-03, -1.5477e-01,  1.0160e-01,  6.3786e-04,  8.6049e-03,\n",
      "           8.6952e-02,  1.2862e-01, -6.8696e-02, -2.9457e-01,  1.4545e-01,\n",
      "          -6.7067e-02, -1.3687e-01, -5.8952e-02, -4.8453e-02, -1.1274e-01,\n",
      "          -2.6046e-01, -2.2769e-04,  8.1389e-02,  3.2758e-01,  1.5362e-01,\n",
      "           1.5418e-01, -5.2192e-03, -2.5818e-02,  9.4160e-02, -1.1970e-01,\n",
      "          -1.5358e-01, -1.4921e-01,  8.1969e-02, -9.9692e-02,  3.5264e-03,\n",
      "           3.5988e-01,  4.5706e-02, -7.3463e-02, -1.3967e-01, -5.2154e-02,\n",
      "          -1.2761e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5703e+00, -1.4751e+00,  2.2746e-01, -7.8630e-02,  3.5245e-01,\n",
      "           5.5343e-01, -2.0048e-01,  2.0887e+00,  1.3115e+00, -1.0356e+00,\n",
      "           6.8464e-01,  0.0000e+00,  1.1879e+00, -8.0520e-01, -1.0880e-01,\n",
      "          -1.1277e+00,  1.9604e+00, -2.9134e-01,  8.3349e-03,  4.2648e-01,\n",
      "          -1.9755e+00,  0.0000e+00, -1.2584e+00,  1.9426e-01, -1.6712e-01,\n",
      "           1.3753e+00, -2.9792e-01, -9.7434e-01,  1.8410e+00,  7.8347e-01,\n",
      "           3.4922e-01,  0.0000e+00,  5.3679e-01,  9.4183e-01,  6.9771e-01,\n",
      "           0.0000e+00, -2.8991e+00,  6.8020e-02,  3.9947e-02,  1.2314e+00,\n",
      "          -7.2213e-01, -1.0137e+00,  2.4837e-01,  1.0036e+00,  6.7011e-02,\n",
      "           3.1137e-01, -1.0372e+00,  0.0000e+00, -4.4470e-01, -1.6405e+00,\n",
      "          -1.5657e+00,  3.1697e+00,  8.6339e-01,  7.6395e-01,  2.2064e+00,\n",
      "           0.0000e+00,  5.9270e-01,  5.6767e-01, -7.5495e-01,  4.1308e-01,\n",
      "           0.0000e+00, -7.1972e-01, -3.6500e-01,  0.0000e+00, -1.3380e+00,\n",
      "           2.3298e+00,  0.0000e+00,  9.2163e-02,  1.1604e+00, -7.1804e-01,\n",
      "           7.5235e-02,  5.5115e-01,  1.9004e-01,  2.3361e-02,  4.0842e-01,\n",
      "          -9.0038e-01, -4.8583e-01,  0.0000e+00, -1.3789e+00, -2.4957e+00,\n",
      "           0.0000e+00,  4.0200e-01,  0.0000e+00, -3.8142e-01, -2.3205e+00,\n",
      "          -1.0348e+00, -6.3269e-01,  1.8182e+00, -1.9083e+00, -6.5423e-01,\n",
      "          -4.3652e-01, -6.6937e-01, -1.9174e+00,  0.0000e+00, -1.3665e+00,\n",
      "          -1.1212e+00,  2.1701e-01,  1.8024e-02,  3.0399e-01,  7.6352e-01,\n",
      "           9.4165e-01,  9.3357e-01,  2.2423e-01, -1.6317e+00,  2.2438e+00,\n",
      "          -1.4416e-01,  1.2455e-01, -1.0131e+00, -1.2048e+00, -1.4857e+00,\n",
      "          -1.5566e+00, -1.3435e+00,  1.5154e-01, -1.7879e+00, -1.1431e+00,\n",
      "          -1.0661e+00, -1.7873e+00,  0.0000e+00, -1.8688e+00,  9.3905e-02,\n",
      "           6.7217e-01,  5.5185e-01,  1.5533e+00,  4.8423e-01,  1.2912e-01,\n",
      "           5.8245e-01,  7.9526e-01,  5.8553e-02,  3.9308e-01, -5.9725e-02,\n",
      "          -8.6366e-02, -5.3679e-01,  7.0348e-01,  1.1585e+00,  3.2931e-01,\n",
      "          -2.5084e-01,  1.1900e-01, -1.3305e+00, -3.6597e-01,  0.0000e+00,\n",
      "          -5.9706e-01, -1.4722e+00,  0.0000e+00,  2.9589e-02,  5.0143e-01,\n",
      "           2.5939e-01,  1.2102e+00,  1.2553e+00,  0.0000e+00,  3.1598e-01,\n",
      "           7.8681e-02, -5.5413e-02, -7.0965e-01,  1.5831e+00,  1.2670e+00,\n",
      "           2.7981e-01,  1.1350e+00,  3.0530e-01,  2.6073e-01,  1.4423e+00,\n",
      "          -1.7485e-01,  6.8408e-01, -2.1208e-01, -7.2115e-01, -4.6793e-01,\n",
      "          -9.4142e-01,  3.2959e-01,  2.5656e-01,  1.7295e+00,  7.0258e-01,\n",
      "           3.1423e+00,  2.0557e+00,  5.6333e-01,  1.0299e-01, -3.9346e-01,\n",
      "          -9.6627e-01, -4.0507e-01,  1.1920e+00, -2.6507e-01, -1.5079e+00,\n",
      "          -1.3464e-01, -1.2926e-02, -6.0225e-01, -1.5680e+00, -1.8516e+00,\n",
      "          -1.6867e-01,  6.9087e-03,  1.3398e+00,  1.2951e+00,  7.3883e-01,\n",
      "           9.6785e-01,  1.6021e-01, -5.3599e-01,  5.3557e-01, -4.7228e-02,\n",
      "          -1.2979e+00, -1.5638e+00,  3.1396e+00, -1.0837e+00,  0.0000e+00,\n",
      "           8.1007e-01, -2.1875e+00, -2.6966e+00,  1.4469e+00, -9.9697e-01,\n",
      "           9.7215e-01, -1.6693e+00, -6.1198e-01, -9.3249e-01, -1.1370e+00,\n",
      "           8.7221e-01,  7.9599e-02, -1.3190e+00, -7.9117e-01,  1.3114e+00,\n",
      "          -2.8292e-01,  1.3732e+00,  0.0000e+00, -2.3518e+00,  1.9031e+00,\n",
      "           1.0278e+00,  0.0000e+00,  1.7823e+00,  1.0654e+00, -5.7279e-01,\n",
      "          -5.7350e-01, -1.5897e+00,  1.5605e-03, -3.3769e-01, -2.9544e+00,\n",
      "          -6.4345e-01,  1.5655e+00,  0.0000e+00, -6.2731e-01,  1.6771e+00,\n",
      "           2.2889e+00, -2.1839e+00,  3.2568e-01,  1.5120e+00, -5.3511e-01,\n",
      "          -1.8332e+00, -1.1666e+00, -1.1115e-01,  1.4427e+00, -4.7768e-01,\n",
      "           1.4839e+00,  0.0000e+00,  7.7596e-01, -1.4378e+00, -2.5937e-01,\n",
      "           4.3560e-01,  3.1988e-01, -3.3689e-01,  0.0000e+00,  2.5959e-01,\n",
      "          -7.0406e-02]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0757, 0.1794, 0.0632, 0.1011, 0.1646, 0.0680, 0.1320, 0.0701, 0.0519,\n",
      "         0.0939]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1569,  0.0031, -0.1270,  0.0042, -0.0184,  0.0529, -0.3096,\n",
      "          -0.1979,  0.0446,  0.1257,  0.0933, -0.2387, -0.0131, -0.2778,\n",
      "           0.0410,  0.1538,  0.2006,  0.2606,  0.0239,  0.0745, -0.1033,\n",
      "          -0.1801, -0.0745,  0.1049, -0.0621,  0.1555, -0.0437, -0.0790,\n",
      "          -0.1496, -0.0818, -0.0758,  0.0698,  0.2249,  0.0704, -0.0842,\n",
      "          -0.0820,  0.0026, -0.0753,  0.2054, -0.0874,  0.1021,  0.0522,\n",
      "          -0.1261, -0.2280,  0.0257, -0.0263, -0.1126, -0.1640,  0.0770,\n",
      "           0.1436, -0.1070, -0.2242, -0.0344, -0.0284, -0.3804, -0.0587,\n",
      "          -0.1379,  0.2263,  0.1156,  0.0356, -0.0735, -0.1310, -0.1355,\n",
      "           0.0433,  0.4302,  0.0328, -0.0716, -0.1063,  0.1292, -0.0400,\n",
      "           0.1330,  0.1380,  0.2726, -0.1553, -0.0131,  0.1852,  0.2038,\n",
      "           0.0322, -0.1528,  0.1975, -0.0196,  0.0209, -0.1229,  0.1277,\n",
      "           0.0193, -0.1234, -0.1075,  0.0677, -0.0950, -0.0805,  0.0401,\n",
      "           0.1978,  0.0860, -0.1302,  0.1474,  0.2380,  0.0372,  0.3837,\n",
      "           0.2048, -0.0598, -0.0006,  0.0059,  0.1079,  0.1196, -0.0683,\n",
      "          -0.0148, -0.1153,  0.0801, -0.2111,  0.0686,  0.0908,  0.1485,\n",
      "          -0.0081, -0.1267,  0.0414,  0.0704,  0.2561, -0.0032, -0.1170,\n",
      "          -0.1263,  0.2051, -0.0210, -0.0311,  0.1139, -0.0551, -0.2187,\n",
      "          -0.1294, -0.1848,  0.3663, -0.0638,  0.0833, -0.0058,  0.1123,\n",
      "           0.1446, -0.1595,  0.1830,  0.2629,  0.0678,  0.0358, -0.1954,\n",
      "          -0.0955,  0.0818, -0.3247,  0.1984, -0.0903,  0.2423,  0.0893,\n",
      "           0.3683,  0.0195,  0.1000, -0.0373,  0.0517,  0.1070,  0.0812,\n",
      "           0.1399,  0.1649,  0.0088,  0.0590, -0.0007, -0.0719, -0.2270,\n",
      "          -0.2062, -0.2293,  0.3042, -0.1416, -0.0629, -0.0537,  0.1787,\n",
      "           0.1310,  0.0158, -0.0970,  0.1625,  0.2273,  0.0407,  0.0891,\n",
      "          -0.0500,  0.1211, -0.0289,  0.1288,  0.0339, -0.0562,  0.1072,\n",
      "           0.0254, -0.1439,  0.0508, -0.2067, -0.1736, -0.1596, -0.1483,\n",
      "          -0.0463, -0.2226, -0.0635, -0.0559,  0.0099, -0.1715, -0.0225,\n",
      "          -0.1703, -0.2257, -0.2057,  0.2228, -0.0033,  0.0297, -0.0390,\n",
      "           0.1666, -0.0508, -0.2618, -0.1808, -0.0169, -0.0647, -0.0572,\n",
      "           0.0224, -0.0133, -0.0331,  0.2499, -0.1548, -0.0628, -0.1941,\n",
      "           0.1093, -0.1916, -0.0644,  0.0021, -0.1458,  0.1355, -0.0174,\n",
      "          -0.0140,  0.0736,  0.1011, -0.0596, -0.2971,  0.1200, -0.0592,\n",
      "          -0.1365, -0.0252, -0.0092, -0.0847, -0.2808,  0.0100,  0.0866,\n",
      "           0.2966,  0.1530,  0.2197, -0.0054, -0.0079,  0.1067, -0.1262,\n",
      "          -0.1425, -0.0924,  0.1074, -0.1365,  0.0076,  0.3399,  0.0304,\n",
      "          -0.0446, -0.1133, -0.0859, -0.1385]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2374,  1.5464, -1.4574, -2.1743,  0.4578,  0.6051, -1.2220,\n",
      "          -2.4152,  0.7392,  0.6027,  1.1430,  1.8317, -0.6932, -1.0176,\n",
      "           1.1932,  0.0000, -0.1018,  0.0593,  0.3566,  2.5194,  0.1245,\n",
      "           0.1779,  0.7003,  0.0232, -0.3435,  0.1994, -0.0881,  0.0000,\n",
      "          -0.4196,  0.1259, -2.8633,  1.5789,  0.0283,  0.8738,  0.2505,\n",
      "          -0.1789,  0.9108,  0.2324, -0.3417,  1.0623,  0.0000, -3.5220,\n",
      "           0.1043, -0.4621,  0.8527, -0.6388, -0.2945, -0.6661, -1.4549,\n",
      "          -0.5310,  0.4026, -0.4636,  0.2277,  0.3494, -1.3048, -2.4934,\n",
      "          -1.9620,  1.1336, -1.5310, -2.2034,  0.4966, -0.5711,  0.4712,\n",
      "           0.4294,  0.0000,  0.2742, -0.2059, -3.5248, -0.7421,  1.1779,\n",
      "           0.5176, -0.5179,  0.3122,  1.3258,  0.1444, -1.4119, -0.8996,\n",
      "           0.0000,  1.2058,  0.0000,  0.0000, -0.0664,  0.0000, -1.1751,\n",
      "          -1.4207,  0.7919,  0.6449, -1.6482, -1.0191, -0.4070, -1.4374,\n",
      "           0.0000,  0.7203, -0.4046,  1.3763,  0.0689,  0.8792, -0.3768,\n",
      "          -0.9557, -0.2155, -0.3142,  0.0000,  0.0000, -1.3891,  0.4908,\n",
      "          -0.0706,  0.8455, -1.0996, -2.5653,  1.9620,  0.5291,  2.3762,\n",
      "          -0.8094,  0.2370, -0.4525, -1.1392,  0.9391,  0.2810,  1.4185,\n",
      "           0.0000, -0.8042,  0.0427,  0.0000,  0.1262,  0.8746,  0.2340,\n",
      "           0.2854,  1.6737,  1.6592, -1.4765,  1.5543,  0.0858,  0.0403,\n",
      "           0.0651,  0.6417, -0.7448,  1.1552, -1.0884,  0.6815,  0.1434,\n",
      "          -2.9085,  2.4223,  0.6841,  0.2254, -1.7731, -1.8019,  2.3112,\n",
      "           0.2799,  0.0000,  1.3773, -1.0619, -0.6280,  0.0000,  0.6378,\n",
      "          -0.7031, -0.0087,  0.7190, -0.6867,  0.0000,  0.3946, -0.0955,\n",
      "           0.0000, -1.6188,  0.4803, -0.7267, -3.0465,  1.5364,  2.3947,\n",
      "          -0.6769, -1.1615,  1.4077,  0.0000, -0.8787,  0.6904,  0.0000,\n",
      "          -1.2019,  0.0000,  0.8803, -1.3812, -1.4021,  0.9720, -0.7426,\n",
      "           0.0000,  0.3040, -0.4567,  1.8101, -0.2224, -1.1367,  2.0591,\n",
      "           0.3037,  0.0000,  0.0506, -0.4834, -2.7770,  2.0675,  0.1339,\n",
      "          -1.3624,  0.3048,  1.3172, -1.1013,  0.4698,  1.2463,  0.0000,\n",
      "           0.5061,  1.1494, -0.5191,  0.1318,  1.4371, -0.5169, -0.2770,\n",
      "           0.9153, -0.7465,  0.1000,  0.0000, -0.1689,  1.7607,  1.9114,\n",
      "           0.6387,  0.0000,  1.3993, -1.2296, -0.6516, -0.1257, -0.5849,\n",
      "           0.0000, -0.9303,  0.0593, -1.2436,  1.1056,  1.2229,  0.9316,\n",
      "          -0.3077,  0.0382, -1.8254,  0.0000,  1.4334,  0.0000,  0.8726,\n",
      "          -2.0895,  0.9484,  1.9402, -0.6005, -1.3173, -0.9557, -1.3038,\n",
      "           1.2989, -0.5040,  0.0000,  0.0231,  1.0724,  0.7546,  0.0000,\n",
      "          -0.0592, -0.3211,  1.0476, -0.2030]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0530, 0.0770, 0.1478, 0.0771, 0.0781, 0.1680, 0.0957, 0.1108, 0.1149,\n",
      "         0.0776]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1644,  0.0336, -0.1891, -0.0198, -0.0651, -0.0800, -0.2385,\n",
      "          -0.2353,  0.0691,  0.0677,  0.1447, -0.2738, -0.0526, -0.2394,\n",
      "           0.0691,  0.0091,  0.2405,  0.2710, -0.0067,  0.1252, -0.1023,\n",
      "          -0.2333,  0.0484,  0.1011, -0.1001,  0.1311, -0.0285, -0.1361,\n",
      "          -0.1390, -0.0960, -0.0473,  0.0131,  0.2239,  0.0883, -0.0620,\n",
      "          -0.0127, -0.1041, -0.1263,  0.0708, -0.0859,  0.0215,  0.0094,\n",
      "          -0.1886, -0.1928,  0.0104,  0.0516, -0.1696, -0.1884,  0.1191,\n",
      "           0.0939, -0.1068, -0.1672, -0.0858, -0.0177, -0.3404, -0.0722,\n",
      "          -0.0876,  0.1832,  0.1530,  0.1184, -0.1120, -0.0546, -0.1118,\n",
      "           0.0765,  0.4306,  0.0214, -0.1186, -0.0340,  0.1079,  0.0442,\n",
      "           0.1092,  0.1103,  0.2602, -0.0795, -0.0541,  0.2191,  0.1690,\n",
      "          -0.0079, -0.1082,  0.2798, -0.0306, -0.0550, -0.1877,  0.1363,\n",
      "          -0.0325, -0.0734, -0.0965,  0.0367, -0.0898, -0.0385,  0.0747,\n",
      "           0.1949,  0.1208, -0.1400,  0.0550,  0.2220,  0.0530,  0.4025,\n",
      "           0.2488,  0.0012, -0.1251, -0.1031,  0.1426,  0.0758, -0.0619,\n",
      "          -0.0237, -0.0052,  0.0747, -0.2270,  0.1052,  0.1146,  0.2042,\n",
      "           0.0598, -0.1745, -0.0252,  0.0354,  0.2302, -0.0294, -0.1072,\n",
      "          -0.1998,  0.2175, -0.0222, -0.0948,  0.1349, -0.0672, -0.2186,\n",
      "          -0.0556, -0.2017,  0.3935, -0.0977,  0.1874, -0.1426,  0.1273,\n",
      "           0.2228, -0.1173,  0.1847,  0.3230,  0.0688,  0.0438, -0.2118,\n",
      "          -0.1219,  0.1115, -0.3331,  0.2168, -0.1166,  0.2853,  0.0386,\n",
      "           0.3578,  0.0253,  0.2203, -0.0107,  0.0033,  0.1288,  0.1065,\n",
      "           0.1835,  0.2317, -0.0217,  0.0552,  0.0063, -0.1379, -0.1655,\n",
      "          -0.2830, -0.2984,  0.3907, -0.1566, -0.0840, -0.0795,  0.1364,\n",
      "           0.1598,  0.0441, -0.1027,  0.0681,  0.3471,  0.0087,  0.0401,\n",
      "          -0.1850,  0.0618, -0.0419,  0.1370, -0.0345, -0.0870,  0.1014,\n",
      "           0.0418, -0.2061,  0.0523, -0.1831, -0.2217, -0.1188, -0.0547,\n",
      "          -0.0777, -0.2560, -0.1413, -0.1258,  0.0157, -0.1522, -0.1054,\n",
      "          -0.1062, -0.2552, -0.1748,  0.2419, -0.0620,  0.0654, -0.1637,\n",
      "           0.1340,  0.0086, -0.3373, -0.2087,  0.0265, -0.0135, -0.1990,\n",
      "          -0.0368, -0.0675, -0.0104,  0.2880, -0.1977,  0.0226, -0.2712,\n",
      "           0.1005, -0.1844, -0.0339,  0.0032, -0.1684,  0.0681,  0.0551,\n",
      "          -0.0384,  0.0936,  0.1435, -0.0913, -0.2585,  0.1458, -0.0361,\n",
      "          -0.1634, -0.1010, -0.0420, -0.0891, -0.2540,  0.0176,  0.0791,\n",
      "           0.3457,  0.1733,  0.1231,  0.0283, -0.0652,  0.0865, -0.1015,\n",
      "          -0.1347, -0.1161,  0.0525, -0.0748, -0.0033,  0.3947,  0.0637,\n",
      "          -0.0956, -0.1425, -0.0415, -0.1894]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4739, -0.4590, -1.2335, -0.1179,  0.0000,  0.0000,  0.6621,\n",
      "           0.5339,  0.6706,  0.9338,  1.7081, -1.0164,  0.9466,  0.0000,\n",
      "          -1.6339,  0.5127,  1.8775, -0.7565, -1.5630, -2.6437, -1.1337,\n",
      "           0.1681,  2.9299,  0.5543, -0.1169,  3.2096,  1.8370,  0.5189,\n",
      "          -2.2263, -1.2855,  0.0295,  1.0135,  0.3247,  0.8601, -0.7986,\n",
      "          -1.4656,  0.6198, -0.7713,  1.9916,  0.1023,  0.4675, -2.2043,\n",
      "          -0.5663, -0.1152, -0.7129, -0.6894,  1.9278,  0.1098, -0.2867,\n",
      "          -1.8507,  1.4680,  0.4625,  0.6676, -0.2835,  0.5317,  0.2748,\n",
      "          -1.2423, -0.9513,  1.8141, -0.0118,  0.2048, -1.8184, -1.4016,\n",
      "           0.0000,  1.1797,  0.2653, -0.1668, -0.2555, -0.0043,  0.0000,\n",
      "          -0.3252, -0.3242,  0.0000, -0.1266,  0.6587,  0.0000,  2.0661,\n",
      "           1.6797,  0.0877, -0.5462,  1.2270,  0.0869,  0.0000, -1.8365,\n",
      "          -0.0717, -1.7324, -1.4586, -0.8910,  0.6231,  0.8108,  0.0000,\n",
      "          -1.1443,  1.9852,  0.0000, -0.7340,  0.1566,  0.0000, -0.4056,\n",
      "          -0.3043, -1.8394, -1.2905,  0.0000, -0.7664,  0.2376,  0.3819,\n",
      "           1.1138, -1.0699,  2.2524,  0.0000, -0.2883, -0.0532,  0.6107,\n",
      "          -0.2549,  0.0000, -1.9422,  1.1283,  1.0062, -2.4977, -0.5748,\n",
      "           0.0297, -1.6952, -0.4012, -0.3795, -0.0787, -0.5370, -1.1113,\n",
      "           1.3049,  0.1698,  0.3223,  1.3585,  0.0000,  0.0000,  0.3591,\n",
      "          -0.7229,  0.4293,  0.0599,  0.3269, -2.1022, -0.4969, -1.6776,\n",
      "          -0.6420,  0.2342, -1.1870, -1.2153, -0.6312, -0.0408,  0.4648,\n",
      "           1.7384,  1.5941,  0.0000, -1.2628,  0.0000, -0.4801, -0.0394,\n",
      "           0.3268, -0.1166,  1.3539,  0.0000,  0.0000, -1.8060,  0.0000,\n",
      "          -0.9003, -0.7055, -0.3892, -0.9815, -0.1289,  0.4064,  0.9705,\n",
      "           0.5178, -0.1474,  0.0000, -0.3731, -0.3159,  0.0000,  0.1291,\n",
      "          -0.3525, -0.8307, -0.7692, -0.0400, -0.9376,  0.7278,  1.0421,\n",
      "           0.0000,  0.4633,  0.3165, -0.1181, -0.5419, -0.6644,  0.7550,\n",
      "          -1.0643, -0.5867, -1.7885,  1.2675, -0.9264,  0.0000, -0.3332,\n",
      "           0.0000, -1.9608, -0.0720, -0.3756,  2.6978, -0.9215, -2.6319,\n",
      "          -0.5862, -0.7166, -1.3860, -1.2537,  0.1720,  0.2185, -1.1110,\n",
      "           0.9451, -0.6920, -1.5196,  0.3624,  0.2373, -1.4268, -2.3450,\n",
      "           0.0471, -1.4800,  0.4274,  0.0133, -0.9018,  0.0000, -1.1654,\n",
      "          -1.3017, -0.1876,  1.2724,  1.2665,  0.0000, -0.0564,  1.7373,\n",
      "          -1.1752,  0.9562,  0.0000,  0.5270,  0.7895, -0.6786,  0.1046,\n",
      "          -0.6805, -2.2624,  0.1675, -0.3140, -1.0433, -0.3820,  0.0000,\n",
      "           0.5580,  1.4999, -0.5647, -1.3773,  1.2434,  0.5826,  1.7530,\n",
      "           1.9513,  0.3625,  0.0000,  0.3903]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0284, 0.2230, 0.1536, 0.0467, 0.1435, 0.1051, 0.0301, 0.1338, 0.0773,\n",
      "         0.0586]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.7758e-01,  3.8736e-02, -2.1226e-01, -3.8037e-02, -1.5384e-02,\n",
      "           3.7708e-02, -3.1409e-01, -2.8383e-01,  5.2575e-02,  9.3727e-02,\n",
      "           1.1770e-01, -2.7602e-01, -7.7619e-02, -2.5175e-01,  4.6427e-02,\n",
      "           1.3547e-01,  1.7671e-01,  2.5173e-01, -1.9413e-02,  5.5569e-02,\n",
      "          -1.6770e-01, -1.9913e-01, -4.3988e-05,  1.3062e-01, -7.6157e-02,\n",
      "           1.7322e-01,  1.8446e-02, -1.2652e-01, -1.3262e-01, -8.3198e-02,\n",
      "          -6.1726e-02,  2.8652e-02,  2.2975e-01,  3.5260e-02, -7.3421e-02,\n",
      "          -9.4536e-03, -1.0160e-01, -9.1526e-02,  7.1445e-02, -7.9894e-02,\n",
      "           1.9980e-02,  1.0056e-01, -1.7924e-01, -2.4613e-01,  2.3642e-02,\n",
      "           4.2612e-02, -1.8215e-01, -1.4786e-01,  1.5007e-01,  1.5097e-01,\n",
      "          -9.1576e-02, -2.2163e-01, -4.7071e-02, -3.3819e-02, -3.9835e-01,\n",
      "           3.8518e-03, -1.1193e-01,  2.1899e-01,  1.7939e-01,  4.1742e-02,\n",
      "          -1.3596e-01, -1.1497e-01, -1.4020e-01,  6.7948e-02,  4.3582e-01,\n",
      "           2.7645e-02, -5.7140e-02, -5.8091e-02,  4.4408e-02,  5.4880e-03,\n",
      "           1.7386e-01,  1.8168e-01,  2.6311e-01, -1.2473e-01, -1.7338e-02,\n",
      "           1.9162e-01,  2.4069e-01, -1.3529e-02, -1.3651e-01,  2.5372e-01,\n",
      "          -5.6895e-02,  4.1651e-02, -1.8552e-01,  1.7594e-01,  1.6247e-02,\n",
      "          -9.3786e-02, -5.8308e-02,  9.2435e-02, -1.2330e-01, -8.3888e-02,\n",
      "           1.4274e-01,  2.2203e-01,  4.5865e-02, -2.3048e-01,  1.1906e-01,\n",
      "           2.4424e-01,  7.9454e-02,  4.2176e-01,  2.3399e-01,  1.9095e-02,\n",
      "          -2.5541e-02,  6.7851e-03,  1.4107e-01,  6.7493e-02,  1.9356e-04,\n",
      "          -1.0349e-01, -4.7024e-02,  1.0346e-01, -2.1774e-01,  7.5895e-02,\n",
      "           1.2803e-01,  1.7427e-01,  5.7111e-03, -1.5433e-01, -1.2740e-03,\n",
      "           5.9496e-02,  2.4007e-01, -4.5066e-02, -1.4747e-01, -1.3773e-01,\n",
      "           2.1118e-01, -9.5597e-03, -9.8303e-02,  1.4245e-01, -8.3402e-02,\n",
      "          -2.1584e-01, -5.1746e-02, -1.7194e-01,  4.1295e-01, -6.3199e-02,\n",
      "           1.2347e-01, -4.6707e-02,  1.0054e-01,  1.9898e-01, -1.8502e-01,\n",
      "           1.0582e-01,  2.9532e-01,  9.1659e-02,  2.5311e-02, -1.5014e-01,\n",
      "          -1.3040e-01,  1.5610e-01, -3.8198e-01,  1.9512e-01, -9.8626e-02,\n",
      "           2.1009e-01,  1.0897e-01,  4.4854e-01,  3.1049e-02,  1.6123e-01,\n",
      "          -1.1485e-01, -3.2608e-02,  6.8387e-02,  1.2535e-01,  1.2086e-01,\n",
      "           1.5911e-01, -4.5563e-02,  1.2258e-01, -6.4263e-02, -6.9470e-02,\n",
      "          -2.5600e-01, -1.9321e-01, -2.9352e-01,  3.8480e-01, -1.8351e-01,\n",
      "          -9.4907e-02, -7.3798e-02,  1.8416e-01,  1.3855e-01,  1.1304e-01,\n",
      "          -1.3010e-01,  1.7630e-01,  2.9316e-01,  2.8057e-02,  2.5505e-02,\n",
      "          -7.6677e-02,  1.2566e-01, -3.1908e-02,  2.1030e-01,  3.5305e-02,\n",
      "          -1.4419e-01,  7.9875e-02, -8.9408e-03, -1.1758e-01,  5.9961e-02,\n",
      "          -1.7358e-01, -1.8207e-01, -1.4159e-01, -1.3416e-01, -3.9653e-02,\n",
      "          -2.4628e-01, -8.8297e-02, -1.1556e-01,  7.6422e-03, -1.5605e-01,\n",
      "          -1.0544e-01, -1.2894e-01, -2.7272e-01, -2.5720e-01,  2.0996e-01,\n",
      "          -6.9350e-02,  6.1409e-02, -5.2721e-02,  1.7704e-01, -3.9087e-02,\n",
      "          -2.3897e-01, -2.1708e-01, -2.6297e-02, -4.4716e-02, -1.3644e-01,\n",
      "          -3.4884e-02, -2.6196e-02, -4.0163e-02,  2.9331e-01, -1.2550e-01,\n",
      "          -2.9888e-02, -1.8292e-01,  9.2721e-02, -2.4091e-01, -5.5211e-02,\n",
      "           5.8589e-02, -1.5908e-01,  1.4376e-01, -4.3432e-02, -3.8563e-02,\n",
      "           1.0215e-01,  1.3067e-01, -3.8161e-02, -3.4994e-01,  1.2922e-01,\n",
      "          -6.2241e-02, -1.9167e-01, -3.8101e-02, -2.0169e-02, -1.3191e-01,\n",
      "          -3.0797e-01, -1.0590e-01,  1.0608e-01,  3.6974e-01,  1.7044e-01,\n",
      "           1.3395e-01, -1.3423e-02,  1.2453e-02,  1.0792e-01, -1.0688e-01,\n",
      "          -1.8423e-01, -2.0296e-01,  1.0072e-01, -1.4861e-01, -2.0873e-02,\n",
      "           3.6702e-01,  6.2914e-02, -2.6301e-02, -1.6792e-01, -4.0101e-02,\n",
      "          -1.3087e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-9.9195e-01, -1.1823e+00,  4.6340e-01,  9.8992e-02, -2.2153e-01,\n",
      "           1.2257e+00,  2.6397e-01, -1.1817e+00,  0.0000e+00, -4.6295e-02,\n",
      "          -1.6640e-01,  1.5216e+00, -6.3650e-01, -8.0142e-01, -1.9952e-01,\n",
      "          -4.1388e-01,  4.1346e-01, -3.7479e-01,  5.7207e-01,  1.8718e+00,\n",
      "          -1.2081e-01, -3.1100e-01,  2.1271e-01,  2.4674e+00,  1.0309e+00,\n",
      "           9.9347e-01,  1.8117e-01,  3.2751e-01,  7.9994e-02, -9.3161e-01,\n",
      "          -1.2572e+00,  0.0000e+00,  1.3861e+00,  1.0389e+00,  2.8656e-01,\n",
      "           2.8099e-01,  8.4558e-01, -7.2984e-01,  4.0060e-01,  4.5649e-01,\n",
      "           2.1244e-01,  0.0000e+00,  0.0000e+00,  5.3537e-01,  8.1670e-01,\n",
      "          -1.7466e+00,  3.9128e-01,  4.8975e-01,  8.8362e-01, -7.7730e-01,\n",
      "           4.8449e-01, -3.1679e-01, -2.3704e-01,  9.1345e-01,  1.0606e+00,\n",
      "           1.0280e+00,  1.5453e+00, -1.1803e+00, -1.0914e+00,  0.0000e+00,\n",
      "           2.0156e+00,  8.6693e-01,  4.4448e-01, -2.9874e+00,  8.1727e-01,\n",
      "           6.4662e-01,  2.3232e+00,  9.3933e-01, -2.2228e+00,  9.0558e-01,\n",
      "          -8.2939e-01,  8.9167e-01,  1.0736e+00, -6.1760e-01, -9.7639e-03,\n",
      "          -1.7999e+00,  2.0936e+00,  2.7707e+00,  2.2190e+00,  0.0000e+00,\n",
      "          -9.3161e-01,  5.4121e-01, -7.5772e-01, -1.1755e+00, -3.0813e-01,\n",
      "           0.0000e+00,  0.0000e+00,  1.0733e+00, -4.5746e-01,  1.4986e+00,\n",
      "           4.6887e-01,  1.6142e-01, -4.3430e-01,  0.0000e+00,  1.6241e-01,\n",
      "           5.7635e-02, -6.1306e-01,  0.0000e+00, -9.3953e-01,  8.6698e-01,\n",
      "          -3.9240e-01,  2.0786e+00,  2.7298e-01, -2.0206e+00,  1.2453e+00,\n",
      "           1.1644e+00, -8.4993e-01,  1.7570e-02, -6.8775e-01,  1.4343e+00,\n",
      "           2.0225e-01, -5.0311e-01,  1.5884e+00,  4.8058e-02, -1.6781e+00,\n",
      "           4.8736e-01, -1.5663e+00, -2.1155e+00,  7.7731e-01,  1.2661e+00,\n",
      "           6.2639e-01, -7.3474e-01, -6.3108e-01,  1.8075e+00,  0.0000e+00,\n",
      "          -2.6100e-01, -5.8748e-01, -1.4301e+00,  0.0000e+00,  0.0000e+00,\n",
      "           1.3021e+00,  0.0000e+00, -1.9039e+00, -1.7386e+00,  3.5263e-01,\n",
      "           5.4473e-01,  2.8682e-03,  4.4778e-01,  0.0000e+00, -2.1373e-01,\n",
      "          -6.1439e-01, -9.8210e-02, -6.4718e-01, -5.8078e-01,  1.6427e-01,\n",
      "           3.2013e-01, -1.2088e-01, -9.5273e-01, -4.1984e-03,  1.1193e-01,\n",
      "           1.3591e+00, -2.0065e-01,  4.5925e-02,  2.0592e+00, -4.1249e-01,\n",
      "           2.9746e-01,  1.6473e-01,  1.9154e+00, -3.5384e-01,  0.0000e+00,\n",
      "          -3.2506e-01,  3.5265e-01, -6.2094e-01,  1.2952e-01, -1.7456e+00,\n",
      "          -2.1006e-01, -4.7041e-01,  7.3581e-01,  1.9973e+00, -2.5588e-01,\n",
      "          -4.7084e-01,  1.0271e+00, -1.1933e-02,  1.8365e+00, -2.0402e+00,\n",
      "          -5.4806e-01,  3.1035e-01,  1.4374e+00, -5.4878e-01,  1.3190e-01,\n",
      "           2.2870e+00, -1.9356e+00,  1.7895e+00, -1.9694e+00,  8.1484e-01,\n",
      "           1.2093e+00, -7.2809e-01,  4.3789e-01,  3.5960e-01, -7.3458e-01,\n",
      "          -3.8566e-01,  9.4392e-01, -1.4782e+00, -6.9157e-04,  9.4897e-01,\n",
      "          -1.9036e+00,  1.6073e-01, -1.9473e+00, -3.5735e-01,  8.0575e-02,\n",
      "           4.4238e-02, -5.2624e-02, -1.0128e-01, -1.3480e+00, -9.0917e-01,\n",
      "          -4.5435e-01,  1.8000e+00,  4.7148e-01,  5.6220e-01, -1.6284e+00,\n",
      "           0.0000e+00, -1.7265e+00, -4.2305e-01, -4.1286e-01, -6.9409e-01,\n",
      "          -3.6759e-01,  1.0080e+00,  5.1056e-01, -9.5897e-01,  6.8319e-02,\n",
      "           2.6271e+00, -1.3243e-01,  6.5786e-01,  0.0000e+00,  2.1613e+00,\n",
      "           1.5851e-01, -8.8020e-01,  1.0486e+00,  0.0000e+00, -5.3469e-01,\n",
      "          -9.9958e-01, -1.0587e+00, -2.3347e-01,  6.6792e-01, -3.8130e-01,\n",
      "          -3.1513e-01, -4.2653e-01,  1.3374e+00,  5.9345e-01,  7.3772e-01,\n",
      "          -1.1930e+00,  8.5430e-01,  2.0388e-01,  1.4684e+00,  1.4919e+00,\n",
      "           0.0000e+00, -8.0063e-01, -1.6123e+00,  2.5679e-01,  1.1274e+00,\n",
      "          -3.7384e-02, -8.3744e-01, -2.1780e-01,  1.0117e+00, -1.3791e-01,\n",
      "           1.6397e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0433, 0.0935, 0.0724, 0.1076, 0.1524, 0.1876, 0.0697, 0.1005, 0.1011,\n",
      "         0.0720]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5270e-01,  5.3770e-03, -2.2821e-01, -1.4904e-02, -6.8709e-02,\n",
      "          -7.3410e-02, -2.3867e-01, -2.4113e-01,  8.4048e-02,  9.2613e-02,\n",
      "           1.4820e-01, -2.3748e-01, -4.9929e-02, -2.5802e-01,  3.9605e-02,\n",
      "           5.0069e-02,  2.4698e-01,  3.2977e-01, -2.2788e-02,  1.4902e-01,\n",
      "          -9.8301e-02, -2.1484e-01,  2.6716e-02,  1.2898e-01, -7.6180e-02,\n",
      "           1.5004e-01, -7.7066e-02, -1.5962e-01, -1.5827e-01, -9.6361e-02,\n",
      "          -2.5570e-02,  6.5224e-02,  2.2691e-01,  7.2858e-02, -5.4235e-03,\n",
      "          -8.2911e-02, -7.8876e-02, -8.6482e-02,  1.1970e-01, -9.1100e-02,\n",
      "           5.7690e-02,  3.0856e-03, -1.1135e-01, -1.9518e-01, -1.1586e-02,\n",
      "           3.3817e-02, -1.4583e-01, -2.5275e-01,  1.3032e-01,  8.0251e-02,\n",
      "          -1.7183e-01, -1.7952e-01, -9.7994e-02, -3.1700e-02, -3.8260e-01,\n",
      "          -8.8078e-02, -1.1552e-01,  1.8283e-01,  1.2964e-01,  1.2352e-01,\n",
      "          -9.9629e-02, -9.1253e-02, -9.9424e-02,  7.0514e-02,  4.3848e-01,\n",
      "           1.2858e-02, -1.2021e-01, -6.6028e-02,  1.5220e-01, -7.0214e-03,\n",
      "           1.1746e-01,  9.3723e-02,  2.5968e-01, -8.7799e-02, -5.2453e-02,\n",
      "           1.7880e-01,  1.9296e-01,  5.0984e-02, -1.0702e-01,  2.5915e-01,\n",
      "          -3.0671e-02, -8.4590e-02, -1.3950e-01,  1.1646e-01, -2.1915e-02,\n",
      "          -9.2719e-02, -1.2516e-01,  5.3036e-02, -7.1940e-02, -6.1727e-02,\n",
      "           9.5595e-02,  1.5480e-01,  1.3155e-01, -1.4952e-01,  1.4096e-01,\n",
      "           2.8294e-01, -2.5238e-04,  3.8684e-01,  2.6080e-01, -1.8968e-02,\n",
      "          -1.0511e-01, -7.1478e-02,  1.8554e-01,  6.5443e-02, -9.5418e-02,\n",
      "          -5.6974e-02, -3.2844e-02,  9.5713e-02, -2.1245e-01,  9.1898e-02,\n",
      "           1.2213e-01,  1.9261e-01,  7.7980e-02, -1.8285e-01, -1.3336e-02,\n",
      "           1.5190e-02,  2.3373e-01, -1.7244e-02, -8.8169e-02, -1.5252e-01,\n",
      "           2.3578e-01,  7.7357e-03, -9.8872e-02,  1.2607e-01, -3.9825e-02,\n",
      "          -2.5237e-01, -1.1374e-01, -2.3044e-01,  4.0947e-01, -1.1555e-01,\n",
      "           1.6753e-01, -1.0249e-01,  1.5222e-01,  1.8937e-01, -1.4939e-01,\n",
      "           2.4388e-01,  3.3095e-01,  4.5726e-02,  6.3930e-03, -1.9032e-01,\n",
      "          -9.2354e-02,  7.9913e-02, -3.6549e-01,  2.4572e-01, -7.5750e-02,\n",
      "           2.9177e-01,  4.7438e-02,  3.6726e-01,  4.5948e-02,  1.7859e-01,\n",
      "          -3.2204e-02,  8.4874e-02,  1.2301e-01,  1.0224e-01,  1.8293e-01,\n",
      "           2.2463e-01, -1.0394e-02,  5.7614e-02,  6.6423e-02, -1.0667e-01,\n",
      "          -2.1933e-01, -3.1128e-01, -3.2741e-01,  3.6069e-01, -1.1952e-01,\n",
      "          -9.1679e-02, -1.1638e-01,  1.4796e-01,  1.7578e-01,  4.4668e-03,\n",
      "          -1.0669e-01,  1.2677e-01,  3.2293e-01, -1.9074e-02,  5.8845e-02,\n",
      "          -1.3766e-01,  6.7514e-02, -6.8925e-02,  1.3179e-01, -7.4614e-02,\n",
      "          -8.9377e-02,  1.3414e-01,  3.3228e-02, -1.8437e-01,  4.8800e-02,\n",
      "          -2.2974e-01, -2.4327e-01, -1.4247e-01, -6.2327e-02, -8.4610e-02,\n",
      "          -2.9245e-01, -7.3824e-02, -6.1587e-02,  1.5125e-02, -1.6355e-01,\n",
      "          -8.0750e-02, -1.3164e-01, -2.3577e-01, -2.4439e-01,  2.2659e-01,\n",
      "          -2.6882e-02,  2.0668e-02, -1.2241e-01,  1.7545e-01,  3.8329e-02,\n",
      "          -3.3214e-01, -1.7077e-01,  6.4248e-02, -1.6859e-03, -1.8024e-01,\n",
      "           6.2723e-03, -7.0413e-02, -4.1124e-03,  2.8295e-01, -2.1858e-01,\n",
      "          -2.9712e-02, -2.8003e-01,  1.1218e-01, -1.6931e-01, -5.0581e-02,\n",
      "          -9.1625e-04, -2.0120e-01,  7.4960e-02,  6.7718e-02, -2.7200e-02,\n",
      "           7.6198e-02,  1.3422e-01, -1.0126e-01, -2.9092e-01,  1.4972e-01,\n",
      "          -6.3135e-02, -1.5242e-01, -6.3263e-02, -7.5442e-02, -9.0835e-02,\n",
      "          -2.6966e-01,  4.0972e-02,  7.7632e-02,  3.3775e-01,  1.8537e-01,\n",
      "           1.7712e-01,  6.2944e-02, -4.7067e-02,  5.1866e-02, -1.3421e-01,\n",
      "          -1.1701e-01, -1.1118e-01,  8.1670e-02, -1.1979e-01,  1.3839e-02,\n",
      "           3.9747e-01,  7.4426e-02, -9.4843e-02, -1.2092e-01, -7.7011e-02,\n",
      "          -1.7474e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00, -6.2703e-01, -1.9931e+00,  0.0000e+00, -5.6030e-01,\n",
      "          -6.6829e-01,  1.5898e+00, -6.3831e-01,  8.6485e-01,  4.1269e-01,\n",
      "           1.8119e-01, -8.6669e-01, -8.9200e-01, -7.1010e-02, -1.0395e+00,\n",
      "           9.4921e-01, -5.1920e-01,  1.0432e+00,  1.3127e+00,  1.6585e+00,\n",
      "          -1.8813e-02, -1.0046e-01,  1.9418e+00, -1.3199e-01, -1.1594e+00,\n",
      "          -1.3476e+00,  1.9174e+00,  6.6861e-01,  0.0000e+00, -2.2963e-01,\n",
      "          -2.4707e-01, -9.9362e-01, -3.8933e-02,  1.7526e-01,  1.0695e+00,\n",
      "           5.1127e-01,  0.0000e+00,  1.5375e+00,  7.9021e-01,  7.4163e-01,\n",
      "           8.8743e-01,  6.7609e-03, -6.5346e-01,  0.0000e+00, -9.8353e-02,\n",
      "           1.2099e+00,  5.4498e-01,  1.1248e+00,  7.8069e-01,  1.5559e-01,\n",
      "          -5.9753e-02,  1.0431e+00, -5.2499e-01, -2.4128e-01, -1.6114e+00,\n",
      "           6.3959e-01,  8.1413e-01,  1.8315e-01, -9.0799e-01,  2.7930e+00,\n",
      "          -1.9487e+00,  2.1899e-03, -1.5636e-01, -7.2891e-01, -2.2460e+00,\n",
      "          -4.1171e-01,  1.7959e+00, -6.3008e-01,  2.8045e-01, -2.9553e+00,\n",
      "          -5.5716e-01, -8.3070e-01, -1.0719e+00, -1.7175e+00,  1.2348e-01,\n",
      "           0.0000e+00, -6.4587e-01, -8.3157e-01, -1.7544e+00,  3.3113e-01,\n",
      "          -6.5031e-01, -1.4658e+00, -7.9031e-01, -5.2981e-01, -3.0899e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.2066e+00, -2.1260e+00,  2.9623e-01,\n",
      "           9.1103e-01,  3.0026e-01,  7.1523e-01,  0.0000e+00, -1.5195e+00,\n",
      "          -6.1561e-01,  0.0000e+00,  6.9071e-01,  2.5518e+00,  7.3674e-01,\n",
      "           1.2797e+00,  6.8480e-01, -1.2852e+00,  1.0636e+00,  1.6358e+00,\n",
      "          -5.0344e-01, -1.1970e+00,  1.2104e+00, -1.4139e-01, -7.2112e-01,\n",
      "           0.0000e+00,  1.8900e-01, -7.4885e-01, -1.4628e+00, -4.8128e-01,\n",
      "           3.7765e-01,  6.5465e-01,  9.3977e-01,  8.8759e-01,  1.3579e+00,\n",
      "          -4.3925e-01,  1.5753e+00, -4.8789e-01,  1.2918e+00,  1.1609e-01,\n",
      "           2.4235e-01, -1.9179e-01, -9.4155e-01, -5.1634e-01,  0.0000e+00,\n",
      "           7.5235e-01,  1.5527e+00,  0.0000e+00,  9.4762e-01,  2.0790e+00,\n",
      "           0.0000e+00, -1.1997e+00, -7.0450e-01, -7.0262e-01, -1.8086e+00,\n",
      "          -8.4889e-01,  2.4263e+00,  6.6024e-01, -8.1476e-01, -6.5729e-01,\n",
      "           1.1374e+00,  1.5699e+00, -1.3599e-01,  0.0000e+00,  5.3447e-01,\n",
      "          -9.7984e-01, -1.7392e+00, -1.1497e+00,  5.9334e-01, -1.4760e+00,\n",
      "          -6.5469e-02,  3.9882e-01,  0.0000e+00,  5.5922e-01, -1.3275e+00,\n",
      "           6.0618e-01,  5.5972e-01, -4.3863e-01, -4.4022e-01,  1.3079e-01,\n",
      "          -1.2714e+00,  4.4653e-02,  3.9525e-01,  1.9436e+00, -1.3887e+00,\n",
      "           0.0000e+00,  1.3688e+00,  0.0000e+00,  6.4270e-01,  1.0393e+00,\n",
      "          -9.5459e-01,  7.1863e-01, -2.1170e+00,  0.0000e+00,  4.7554e-01,\n",
      "          -1.5664e+00,  2.9518e-01, -4.5200e-01,  0.0000e+00,  6.2255e-01,\n",
      "          -4.4141e-01,  3.9530e-01, -6.7424e-01,  1.9095e-01,  0.0000e+00,\n",
      "          -1.2462e+00, -1.9493e-01,  3.3409e-01, -4.3186e-01, -1.1827e+00,\n",
      "           0.0000e+00, -7.5187e-01, -1.7419e+00, -1.0864e+00, -3.7154e-01,\n",
      "           8.4517e-01,  0.0000e+00, -4.6360e-01, -7.3718e-01,  0.0000e+00,\n",
      "           7.2380e-01, -7.1760e-01,  1.7111e+00, -1.6035e+00,  1.5847e-01,\n",
      "          -1.8099e+00,  0.0000e+00,  0.0000e+00, -8.2440e-02, -5.3261e-01,\n",
      "          -1.2294e-01, -5.0726e-01,  1.0380e+00,  1.6360e+00,  1.0307e+00,\n",
      "           1.4116e-01,  1.1926e+00, -1.5237e+00, -1.5553e+00, -2.2379e-01,\n",
      "           7.2721e-01,  2.0852e+00, -6.8429e-01,  1.0972e+00, -3.0595e-01,\n",
      "           3.9624e-02,  1.1043e-01, -1.6870e-01, -7.4997e-01,  2.0193e+00,\n",
      "           3.9890e-01, -1.7779e+00, -5.7385e-01,  0.0000e+00,  1.2551e+00,\n",
      "          -1.9587e+00, -1.2022e+00, -1.6221e+00,  2.4950e-01,  1.3037e+00,\n",
      "          -5.9868e-01,  0.0000e+00, -4.2779e-01,  3.2048e+00,  1.5360e+00,\n",
      "          -4.7202e-01,  0.0000e+00, -1.2220e+00, -1.4657e+00,  4.3567e-01,\n",
      "          -1.4236e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0909, 0.1315, 0.2468, 0.1212, 0.0914, 0.0618, 0.0326, 0.0601, 0.0708,\n",
      "         0.0930]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1830,  0.1346, -0.1475,  0.0085,  0.0885,  0.0761, -0.3417,\n",
      "          -0.2576,  0.0467,  0.0807,  0.0894, -0.2514, -0.0444, -0.2707,\n",
      "           0.0490,  0.1299,  0.1956,  0.2314,  0.0312,  0.1280, -0.2024,\n",
      "          -0.2195, -0.0514,  0.0870, -0.0721,  0.1136,  0.0322, -0.0498,\n",
      "          -0.1240, -0.1467, -0.0812,  0.0153,  0.2309,  0.1186, -0.1480,\n",
      "           0.0295, -0.0857, -0.1483,  0.0879, -0.1385, -0.0359,  0.0266,\n",
      "          -0.2150, -0.2533,  0.1008, -0.0099, -0.1878, -0.0605,  0.1194,\n",
      "           0.1954, -0.0171, -0.2715, -0.0495, -0.0974, -0.4023,  0.0197,\n",
      "          -0.0985,  0.1788,  0.2138,  0.0117, -0.1153, -0.0436, -0.1290,\n",
      "           0.0569,  0.4207,  0.0309,  0.0763, -0.0363,  0.0178,  0.0913,\n",
      "           0.0979,  0.0897,  0.2356, -0.0685, -0.0107,  0.1912,  0.2656,\n",
      "          -0.0684, -0.1723,  0.2420, -0.0330, -0.0025, -0.1412,  0.2087,\n",
      "           0.1191, -0.0599, -0.0264,  0.0419, -0.1240, -0.0893,  0.1190,\n",
      "           0.2402,  0.0169, -0.2023,  0.0851,  0.1264,  0.1247,  0.4409,\n",
      "           0.1308,  0.0671, -0.0723, -0.0987,  0.1252,  0.0660, -0.0027,\n",
      "           0.0114, -0.0177,  0.0924, -0.1671,  0.0364,  0.1222,  0.1059,\n",
      "          -0.0662, -0.2222,  0.0273,  0.0404,  0.2444, -0.0527, -0.1605,\n",
      "          -0.1491,  0.1736, -0.0119, -0.0945,  0.1260, -0.0579, -0.1458,\n",
      "           0.0027, -0.1794,  0.3977, -0.0189,  0.1198, -0.0575,  0.0958,\n",
      "           0.1773, -0.1301,  0.0326,  0.2294,  0.0701,  0.0192, -0.1760,\n",
      "          -0.0506,  0.1421, -0.3927,  0.1674, -0.1230,  0.2378,  0.1099,\n",
      "           0.4307,  0.0103,  0.2047,  0.0027, -0.0789,  0.0854,  0.0797,\n",
      "           0.0848,  0.1172, -0.0674,  0.0820, -0.1135, -0.1201, -0.2784,\n",
      "          -0.2116, -0.2861,  0.3744, -0.1569, -0.1030,  0.0228,  0.1829,\n",
      "           0.1161,  0.1755, -0.0724,  0.1141,  0.2361,  0.0247, -0.0737,\n",
      "          -0.1283,  0.1646, -0.0849,  0.1714,  0.1165, -0.1781,  0.0645,\n",
      "           0.0057, -0.0728,  0.0083, -0.1716, -0.2128, -0.1326, -0.1496,\n",
      "           0.0265, -0.2243, -0.1168, -0.1709,  0.0206, -0.1377, -0.0557,\n",
      "          -0.1197, -0.2304, -0.2181,  0.2141, -0.1311,  0.0846, -0.1007,\n",
      "           0.1673, -0.0093, -0.2507, -0.2993, -0.0428, -0.0195, -0.0568,\n",
      "          -0.0804, -0.0187, -0.0626,  0.1505, -0.0940,  0.0127, -0.2325,\n",
      "           0.0210, -0.2504, -0.0611,  0.0345, -0.1379,  0.0808, -0.0958,\n",
      "          -0.0408,  0.0728,  0.0679, -0.0460, -0.2991,  0.1469, -0.0902,\n",
      "          -0.1109, -0.0016,  0.0197, -0.1049, -0.2276, -0.0673,  0.1316,\n",
      "           0.3241,  0.1298,  0.0943,  0.0223,  0.0549,  0.0951, -0.0623,\n",
      "          -0.1835, -0.1735,  0.1002, -0.1003, -0.0149,  0.3435,  0.0918,\n",
      "          -0.0235, -0.1165, -0.0446, -0.1146]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7268e-01, -4.3062e-01,  3.1500e-01, -1.0846e+00, -1.1725e+00,\n",
      "           7.4165e-01, -1.9143e+00,  0.0000e+00,  1.9037e-01,  6.1730e-01,\n",
      "           1.9031e+00,  6.0244e-01,  2.2872e-01, -9.1620e-01, -3.1823e+00,\n",
      "          -6.8365e-02, -1.6332e+00, -9.4355e-01,  1.3606e+00, -1.4350e+00,\n",
      "          -1.4062e-01, -5.2378e-01,  0.0000e+00,  0.0000e+00, -7.5751e-02,\n",
      "           1.3913e+00, -6.1952e-01,  1.9973e+00,  1.2762e-01,  5.5424e-01,\n",
      "           9.1519e-01, -3.6359e-03,  2.2268e-01,  2.0158e+00, -6.3715e-02,\n",
      "          -1.4085e+00,  0.0000e+00, -8.1755e-01,  3.1481e-01,  8.5649e-02,\n",
      "           8.6245e-01, -8.9949e-01,  1.0090e+00,  0.0000e+00,  1.9442e+00,\n",
      "           0.0000e+00,  7.0511e-01, -6.0170e-01,  0.0000e+00,  1.1165e+00,\n",
      "          -1.3224e+00,  2.6769e+00,  6.6678e-01, -8.4672e-01,  2.2763e-01,\n",
      "          -3.0942e-01, -1.4340e+00,  0.0000e+00,  1.2753e+00,  2.1811e+00,\n",
      "          -1.0063e+00,  3.6064e-02,  0.0000e+00,  2.6588e-01, -6.2891e-02,\n",
      "           3.9390e-01,  5.7802e-01,  1.1650e+00,  1.5807e+00, -1.4151e+00,\n",
      "           4.2753e-01,  2.9642e-01, -3.1227e-02, -7.9779e-01, -2.1439e-01,\n",
      "           1.3928e-01,  5.2575e-01,  1.3986e+00,  1.0270e+00, -7.9327e-01,\n",
      "           7.5780e-01, -1.0054e+00,  7.5756e-01,  1.0587e+00, -1.2147e+00,\n",
      "           0.0000e+00, -1.1076e+00,  5.4877e-01, -9.4475e-01, -1.9013e+00,\n",
      "           5.2906e-01,  9.8685e-01,  1.7016e+00,  9.4359e-01,  6.0809e-01,\n",
      "          -1.5904e-02,  3.5343e-01, -1.1756e+00,  1.3715e+00,  2.4479e+00,\n",
      "           2.4366e-01,  4.5203e-02, -4.6647e-01, -9.8940e-01,  0.0000e+00,\n",
      "          -1.0232e+00,  3.0290e+00,  6.1991e-01,  0.0000e+00, -1.2354e+00,\n",
      "           1.8992e-01, -5.0293e-01, -5.7048e-01,  7.1234e-01, -7.8031e-01,\n",
      "           6.3236e-01,  4.0396e-01,  2.2401e-01,  0.0000e+00,  2.9358e-02,\n",
      "          -8.1384e-01,  0.0000e+00, -1.8374e+00,  6.0327e-01,  0.0000e+00,\n",
      "          -2.0043e-01,  3.9450e-02,  2.1500e+00,  1.3962e+00, -2.0877e+00,\n",
      "          -9.2636e-01,  4.4967e-01,  0.0000e+00,  4.2519e-01, -4.6871e-01,\n",
      "          -7.4513e-01, -1.0649e+00, -9.7485e-01, -1.9509e-02,  2.3977e+00,\n",
      "           6.9856e-01, -1.1217e+00,  1.6916e+00, -1.4024e-01, -6.6959e-01,\n",
      "           0.0000e+00,  7.5938e-01,  4.2303e-01, -1.0333e+00, -9.5567e-02,\n",
      "           1.5600e+00,  5.8693e-01, -3.3867e-01,  6.5766e-01,  1.8409e+00,\n",
      "          -2.5253e-01, -2.1754e-01,  6.2353e-01, -2.3625e+00,  1.0557e+00,\n",
      "           3.0249e-01, -7.7416e-02,  1.5461e-01, -1.2117e+00, -2.1934e-02,\n",
      "           1.6820e+00,  1.8519e+00,  2.7082e-01,  0.0000e+00, -7.1323e-01,\n",
      "          -1.2244e+00, -1.0940e+00, -2.5903e+00,  5.0562e-01, -3.0589e+00,\n",
      "          -2.8717e-01,  4.9807e-01,  8.2952e-01,  3.1700e-01, -7.9286e-01,\n",
      "           2.7153e-01,  2.3396e+00,  1.0573e+00,  8.3836e-01, -4.0290e-01,\n",
      "           7.2735e-01,  5.9900e-01,  3.5951e-01,  8.4255e-01, -1.8302e+00,\n",
      "           1.3634e+00,  2.1590e+00,  3.3655e-01, -1.0153e+00, -1.1719e+00,\n",
      "          -2.2151e+00,  1.6664e+00,  2.1526e+00,  3.6342e-01,  2.3836e+00,\n",
      "           3.2352e-02, -5.0151e-01, -1.2763e+00,  0.0000e+00, -4.0740e-01,\n",
      "          -1.4469e+00,  9.5363e-01, -8.5182e-01,  8.3041e-01, -1.5599e+00,\n",
      "           6.3641e-01,  6.7601e-01,  2.3975e+00,  5.5137e-02,  1.8938e+00,\n",
      "           1.3081e+00,  5.8068e-01, -2.3171e+00,  1.5502e+00, -2.2259e-01,\n",
      "          -2.2715e-01,  1.7333e+00,  0.0000e+00, -1.5519e+00,  9.2283e-01,\n",
      "          -1.2244e+00, -8.4827e-01, -1.8015e+00, -4.8077e-04,  3.7337e-01,\n",
      "           0.0000e+00, -1.2357e-01,  9.6628e-01, -1.7362e+00,  0.0000e+00,\n",
      "          -1.4405e+00,  6.3409e-01, -1.7221e+00,  9.8033e-01, -1.7158e+00,\n",
      "           1.5606e+00, -2.7213e-01,  0.0000e+00,  1.2385e+00, -1.2284e+00,\n",
      "           1.8847e+00, -5.0832e-01,  5.4282e-01, -2.6133e-01, -1.0219e+00,\n",
      "           1.3334e+00,  3.1056e-01,  0.0000e+00, -2.2879e-01, -1.6120e+00,\n",
      "           1.8063e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0457, 0.1106, 0.1730, 0.0690, 0.1168, 0.1088, 0.1561, 0.0650, 0.0852,\n",
      "         0.0697]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3543, -0.0266,  0.0800,  ..., -0.1184, -0.0233, -0.4768],\n",
      "        [ 0.2498,  0.0387, -0.1544,  ..., -0.3242, -0.1221,  0.1312],\n",
      "        [ 0.1607,  0.4020, -0.1086,  ..., -0.1162,  0.0496, -0.1411],\n",
      "        ...,\n",
      "        [ 0.2461, -0.1410, -0.0446,  ..., -0.3825,  0.3740, -0.3064],\n",
      "        [ 0.4918,  0.3632, -0.6191,  ..., -0.2846,  0.0346, -0.0749],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1526,  0.0312, -0.1426,  0.0120, -0.0440, -0.0196, -0.2767,\n",
      "          -0.2177,  0.0674,  0.0904,  0.1129, -0.2914, -0.0258, -0.2831,\n",
      "           0.0414,  0.0677,  0.2320,  0.2482,  0.0621,  0.1236, -0.1260,\n",
      "          -0.2184, -0.0027,  0.1007, -0.0840,  0.1402, -0.0141, -0.0977,\n",
      "          -0.1458, -0.1099, -0.0998,  0.0341,  0.2425,  0.1318, -0.0907,\n",
      "          -0.0131, -0.0661, -0.1205,  0.1112, -0.1021,  0.0361,  0.0306,\n",
      "          -0.1865, -0.2251,  0.0369,  0.0019, -0.1661, -0.1400,  0.0880,\n",
      "           0.1401, -0.0917, -0.1820, -0.0558, -0.0279, -0.3612, -0.0569,\n",
      "          -0.0987,  0.1952,  0.1393,  0.0763, -0.1186, -0.0638, -0.1011,\n",
      "           0.0467,  0.4605,  0.0381, -0.0828, -0.0909,  0.1430,  0.0063,\n",
      "           0.1272,  0.0995,  0.2843, -0.1069, -0.0097,  0.1989,  0.1888,\n",
      "          -0.0165, -0.1399,  0.2506, -0.0175, -0.0161, -0.1599,  0.1428,\n",
      "          -0.0034, -0.1075, -0.1059,  0.0176, -0.1209, -0.0654,  0.0558,\n",
      "           0.2227,  0.1209, -0.1442,  0.0632,  0.1962,  0.0534,  0.4179,\n",
      "           0.2405, -0.0258, -0.0931, -0.0868,  0.1318,  0.0825, -0.0596,\n",
      "           0.0005, -0.0522,  0.0429, -0.2190,  0.0636,  0.1148,  0.1884,\n",
      "           0.0327, -0.1432,  0.0092,  0.0661,  0.2394, -0.0236, -0.1031,\n",
      "          -0.1802,  0.2227, -0.0024, -0.0435,  0.1324, -0.0491, -0.2212,\n",
      "          -0.0714, -0.2045,  0.3816, -0.0732,  0.1533, -0.0933,  0.1130,\n",
      "           0.1986, -0.1466,  0.1776,  0.2899,  0.0619,  0.0491, -0.2462,\n",
      "          -0.0924,  0.1060, -0.3347,  0.2137, -0.1266,  0.2830,  0.0551,\n",
      "           0.3782, -0.0012,  0.1892,  0.0259, -0.0153,  0.1176,  0.1064,\n",
      "           0.1700,  0.1989, -0.0077,  0.0412, -0.0248, -0.1274, -0.1806,\n",
      "          -0.2582, -0.2438,  0.3467, -0.1621, -0.0887, -0.0498,  0.1634,\n",
      "           0.1548,  0.0640, -0.1003,  0.0787,  0.3060,  0.0087,  0.0375,\n",
      "          -0.1354,  0.0920, -0.0477,  0.1172,  0.0234, -0.0708,  0.1043,\n",
      "           0.0560, -0.1777,  0.0284, -0.1940, -0.2103, -0.1295, -0.0909,\n",
      "          -0.0582, -0.2554, -0.1524, -0.1097,  0.0116, -0.1479, -0.0586,\n",
      "          -0.1192, -0.2844, -0.1600,  0.2488, -0.0596,  0.0573, -0.1408,\n",
      "           0.1359, -0.0111, -0.3111, -0.2185, -0.0223, -0.0409, -0.1498,\n",
      "          -0.0161, -0.0261, -0.0267,  0.2766, -0.1761, -0.0066, -0.2538,\n",
      "           0.0769, -0.1810, -0.0361, -0.0143, -0.1603,  0.0739,  0.0264,\n",
      "          -0.0449,  0.0876,  0.1291, -0.0633, -0.2330,  0.1385, -0.0511,\n",
      "          -0.1574, -0.0652, -0.0102, -0.0761, -0.2637,  0.0264,  0.0919,\n",
      "           0.3410,  0.1615,  0.1401,  0.0423, -0.0302,  0.0935, -0.0859,\n",
      "          -0.1635, -0.1025,  0.1007, -0.0932,  0.0103,  0.3935,  0.0483,\n",
      "          -0.0702, -0.1237, -0.0659, -0.1755]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6461e-02,  3.9950e-01, -9.6562e-01,  0.0000e+00,  3.7579e-01,\n",
      "          -2.0192e-01,  1.4647e+00, -8.3465e-02, -3.5839e+00,  9.0661e-01,\n",
      "           0.0000e+00, -6.2909e-01,  2.6033e+00, -6.2981e-01, -5.4130e-01,\n",
      "          -1.5790e-01,  8.5123e-01,  1.0947e+00,  0.0000e+00,  4.3611e-01,\n",
      "          -6.3331e-01, -3.8284e-01,  1.6405e+00,  1.5108e+00,  7.5334e-01,\n",
      "           0.0000e+00, -1.8787e-01, -7.5946e-01,  1.6534e+00,  8.6144e-01,\n",
      "           1.2316e+00,  1.2190e+00, -1.0342e+00, -8.2908e-02, -1.5343e+00,\n",
      "           1.3954e+00,  2.8082e-01, -3.7442e+00,  1.9777e-01,  1.6004e+00,\n",
      "          -4.5903e-01,  0.0000e+00, -2.6858e-01, -1.7152e+00, -1.5238e+00,\n",
      "           6.6742e-01,  5.4070e-01,  3.7080e-01, -1.3404e+00,  1.4428e-01,\n",
      "          -6.2924e-01,  2.7515e+00,  6.1019e-01, -1.0289e+00, -2.5243e-02,\n",
      "           2.0358e-01, -8.8162e-01, -1.2519e+00, -2.3705e-01, -4.2565e-01,\n",
      "           1.0999e+00,  1.4076e+00, -2.0283e-01, -5.0117e-01, -2.9631e+00,\n",
      "           5.5103e-01,  1.2784e+00, -1.2876e+00,  0.0000e+00,  5.2664e-01,\n",
      "          -1.2667e+00, -3.0009e-02,  7.0735e-01, -3.6406e+00,  3.2553e-01,\n",
      "          -1.2171e-03, -1.5996e-01,  1.0620e+00, -5.7974e-02, -1.1888e-01,\n",
      "          -1.4000e+00,  2.1307e+00, -9.2447e-01,  1.0058e+00, -2.0758e-01,\n",
      "           4.3544e-01,  1.6615e+00, -9.7399e-01, -1.0396e-01, -5.8132e-01,\n",
      "          -2.2727e+00,  1.1000e+00, -6.2232e-01, -1.1356e+00,  4.6728e-01,\n",
      "          -1.1704e+00,  3.3550e-02,  6.2900e-01,  1.7195e+00, -7.7939e-01,\n",
      "           2.6970e+00, -1.4620e+00,  1.0759e+00,  1.4532e+00, -6.6624e-01,\n",
      "          -7.6237e-01,  1.2115e+00,  1.2721e-01, -1.4728e+00,  0.0000e+00,\n",
      "          -2.4839e-01,  1.3420e-01, -1.0475e+00,  1.3099e+00, -1.6527e+00,\n",
      "          -2.9886e+00, -5.6664e-02, -5.0008e-01,  0.0000e+00,  4.4527e-01,\n",
      "           0.0000e+00,  7.0208e-01, -1.4603e+00, -7.2573e-01, -9.5813e-01,\n",
      "           0.0000e+00,  8.9639e-01,  1.6976e-01,  1.2847e+00, -7.5164e-01,\n",
      "          -8.2371e-01,  5.3032e-01, -1.5828e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -5.8935e-01,  6.5906e-01,  5.7501e-01, -1.1588e+00,  0.0000e+00,\n",
      "          -3.8836e-01,  6.7776e-01, -7.8969e-01, -1.0101e-01, -1.6851e+00,\n",
      "          -1.0072e-01, -5.4313e-01, -8.4429e-01, -7.5520e-01,  0.0000e+00,\n",
      "           1.9981e+00, -1.9935e-01, -1.9299e+00, -4.0610e-01,  4.4138e-01,\n",
      "          -1.9441e-01, -6.4664e-02, -1.2982e-01,  3.9154e-02,  5.3749e-01,\n",
      "          -2.6482e-02,  2.2062e+00,  4.8109e-01, -5.5013e-01, -5.2642e-01,\n",
      "          -8.9194e-01,  2.8153e-01,  8.3299e-02, -3.5801e-01, -4.7786e-01,\n",
      "           7.3674e-01,  0.0000e+00,  2.0073e-02, -1.0021e+00,  1.2775e+00,\n",
      "          -1.0980e+00, -9.8651e-01, -2.0761e+00,  1.9686e+00,  8.6582e-02,\n",
      "          -3.0675e-02,  3.5035e-02,  6.7093e-01,  9.7982e-01, -7.4729e-01,\n",
      "          -3.4094e-01, -2.7821e+00, -7.8352e-01,  1.2092e+00,  1.0124e+00,\n",
      "           3.0732e+00,  4.9406e-01, -1.4433e-01, -5.9350e-01,  5.6034e-01,\n",
      "           2.1646e+00, -1.1876e+00,  5.3497e-01,  1.8112e+00, -9.4649e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  1.2420e+00, -1.2210e-01,  2.3199e-01,\n",
      "          -5.7490e-01, -2.2923e+00,  0.0000e+00, -1.0737e+00, -4.7099e-01,\n",
      "           2.8675e+00,  0.0000e+00, -3.4112e-01,  7.9301e-01,  3.0802e-02,\n",
      "          -6.8397e-01,  0.0000e+00,  0.0000e+00, -2.4537e-01,  0.0000e+00,\n",
      "          -1.0827e+00, -4.2712e-01, -1.8435e+00,  0.0000e+00,  3.3847e-01,\n",
      "           0.0000e+00, -6.9656e-01, -6.2815e-01,  2.9224e-01, -1.5780e+00,\n",
      "          -1.1083e+00,  1.5813e+00,  0.0000e+00,  1.3100e+00, -2.9794e+00,\n",
      "           4.0343e+00,  5.8519e-01,  4.3200e-02,  0.0000e+00,  0.0000e+00,\n",
      "           7.4186e-01,  0.0000e+00, -3.0396e-01, -8.5197e-01,  1.1348e-02,\n",
      "           2.7549e-01,  2.7470e-01,  2.5228e-01,  0.0000e+00,  3.8662e-01,\n",
      "          -3.6567e-01,  0.0000e+00, -5.5376e-01, -5.2338e-02, -1.1466e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0607, 0.0567, 0.0892, 0.0740, 0.1089, 0.2629, 0.0992, 0.0831, 0.0604,\n",
      "         0.1047]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2545, -0.0010, -0.0875,  ...,  0.1592,  0.0317,  0.0431],\n",
      "        [ 0.2202, -0.1033, -0.5299,  ...,  0.0377, -0.0375,  0.1093],\n",
      "        [ 0.1181, -0.0401, -0.6793,  ..., -0.3293, -0.2103,  0.3149],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2014,  0.0777, -0.3919, -0.0914, -0.0180, -0.0756, -0.0040,\n",
      "          -0.2219,  0.0087, -0.0433,  0.1560, -0.0473, -0.1424,  0.0478,\n",
      "           0.2683,  0.1443,  0.2211,  0.0857, -0.2206,  0.0383, -0.1393,\n",
      "          -0.0119,  0.1634, -0.0545, -0.1777, -0.2696,  0.0199, -0.1655,\n",
      "          -0.0767, -0.0505,  0.1452, -0.2219, -0.0590, -0.1482,  0.2551,\n",
      "          -0.0151, -0.0755,  0.0417, -0.2721,  0.1121, -0.0862, -0.0893,\n",
      "          -0.1656,  0.0423, -0.0575,  0.1792, -0.0221, -0.0460,  0.2010,\n",
      "           0.0293, -0.1743,  0.0217, -0.1783, -0.1091, -0.0108,  0.0096,\n",
      "           0.0740,  0.1968,  0.1554,  0.0467,  0.0432, -0.0317, -0.1251,\n",
      "           0.0203, -0.0744,  0.1156, -0.2030,  0.2609, -0.1259,  0.1492,\n",
      "           0.0376,  0.1609, -0.0941,  0.0053, -0.2863,  0.2061,  0.1178,\n",
      "           0.2091,  0.0122,  0.1542, -0.1975, -0.1525, -0.2966, -0.0884,\n",
      "          -0.1045,  0.0438, -0.0418, -0.0679,  0.0699, -0.0337,  0.0140,\n",
      "          -0.0506,  0.0453,  0.0815, -0.0005, -0.0370, -0.0120,  0.1591,\n",
      "           0.0163,  0.1914, -0.2049,  0.1494, -0.0378,  0.2277, -0.1769,\n",
      "          -0.1331,  0.0408,  0.1539, -0.1036,  0.2323,  0.3295,  0.1268,\n",
      "           0.0772, -0.3072, -0.0854, -0.0490, -0.0793, -0.0054, -0.1771,\n",
      "          -0.0403,  0.0177, -0.0339, -0.3718,  0.0083, -0.1219,  0.0127,\n",
      "           0.1080, -0.1136,  0.1399,  0.0074,  0.0095, -0.2185,  0.1481,\n",
      "           0.1700, -0.1368,  0.1084,  0.3592, -0.0522, -0.3022,  0.0611,\n",
      "          -0.0282,  0.2935, -0.0626,  0.2259,  0.1095, -0.1116, -0.0187,\n",
      "           0.0700,  0.1501, -0.0450, -0.3295,  0.1209, -0.1577,  0.1066,\n",
      "           0.1336,  0.2630,  0.0178,  0.1851,  0.0870, -0.1539, -0.0779,\n",
      "          -0.1946, -0.2558,  0.2307, -0.1191,  0.0586, -0.0942, -0.1889,\n",
      "           0.0973,  0.2763, -0.2145,  0.0372,  0.0478,  0.0494, -0.1415,\n",
      "          -0.0165,  0.0788,  0.2321,  0.3157, -0.0721, -0.0148, -0.1388,\n",
      "          -0.1451,  0.0236,  0.1574,  0.0468, -0.1153,  0.0678,  0.2142,\n",
      "          -0.2304, -0.0259,  0.0507, -0.3226, -0.0636, -0.1095,  0.0178,\n",
      "          -0.0364,  0.0339, -0.1071,  0.0691, -0.0752,  0.2581, -0.0719,\n",
      "           0.2214,  0.0503, -0.0137, -0.1063,  0.3184,  0.0042, -0.1516,\n",
      "           0.0628, -0.2143, -0.0311,  0.0704, -0.0743,  0.2017,  0.0209,\n",
      "           0.1652, -0.2523,  0.1398,  0.2392, -0.1177,  0.0858, -0.0819,\n",
      "           0.1101,  0.1017,  0.0276, -0.0999, -0.2989,  0.2208, -0.3601,\n",
      "          -0.0033, -0.0176, -0.2198,  0.0651, -0.0374, -0.1621, -0.0195,\n",
      "           0.1334,  0.0330, -0.0335, -0.1031, -0.0236, -0.1285,  0.1608,\n",
      "          -0.0533, -0.2907, -0.1283,  0.0964,  0.0543,  0.1866,  0.0608,\n",
      "          -0.1254, -0.2793, -0.0228,  0.0906]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4740, -0.4590, -1.2336, -0.1179,  0.4617,  0.0256,  0.6622,\n",
      "           0.0000,  0.0000,  0.9337,  1.7082, -1.0164,  0.0000,  0.0000,\n",
      "          -1.6340,  0.5127,  1.8776, -0.7565, -1.5630, -2.6437, -1.1337,\n",
      "           0.1680,  2.9300,  0.5543, -0.1169,  3.2096,  1.8370,  0.5189,\n",
      "          -2.2263, -1.2855,  0.0295,  1.0135,  0.3246,  0.8601, -0.7986,\n",
      "          -1.4656,  0.6198, -0.7713,  1.9917,  0.1024,  0.4675, -2.2043,\n",
      "          -0.5664, -0.1152, -0.7131, -0.6894,  1.9279,  0.1098, -0.2868,\n",
      "          -1.8507,  1.4681,  0.4627,  0.6676, -0.2835,  0.5317,  0.2748,\n",
      "          -1.2422, -0.9513,  1.8142,  0.0000,  0.2048, -1.8183, -1.4016,\n",
      "          -0.8064,  1.1798,  0.2652, -0.1668, -0.2556, -0.0042, -0.4610,\n",
      "          -0.3252, -0.3242,  0.1474, -0.1267,  0.0000, -0.8064,  2.0662,\n",
      "           1.6798,  0.0877, -0.5462,  1.2270,  0.0870,  0.3269,  0.0000,\n",
      "          -0.0717, -1.7325,  0.0000, -0.8910,  0.6231,  0.8107,  0.0000,\n",
      "          -1.1444,  1.9853, -0.3660, -0.7340,  0.1565,  2.1418, -0.4055,\n",
      "          -0.3042, -1.8395, -1.2905, -0.7217, -0.7664,  0.2376,  0.3820,\n",
      "           1.1138,  0.0000,  2.2525, -0.2628, -0.2881, -0.0533,  0.6108,\n",
      "          -0.2549, -0.2803, -1.9422,  0.0000,  1.0061, -2.4979, -0.5747,\n",
      "           0.0297, -1.6952, -0.4013, -0.3796, -0.0787, -0.5370, -1.1114,\n",
      "           1.3050,  0.1699,  0.3223,  1.3585,  2.0796, -2.6343,  0.3591,\n",
      "          -0.7229,  0.4293,  0.0598,  0.3269, -2.1024, -0.4968, -1.6776,\n",
      "          -0.6420,  0.2341, -1.1870, -1.2153, -0.6313, -0.0409,  0.4648,\n",
      "           1.7384,  1.5941,  0.0000, -1.2628, -0.5773, -0.4802,  0.0000,\n",
      "           0.3268, -0.1165,  1.3540, -0.0312,  0.0000, -1.8060, -1.4269,\n",
      "          -0.9003, -0.7054, -0.3891, -0.9816, -0.1289,  0.4064,  0.9706,\n",
      "           0.5179, -0.1474,  1.5143, -0.3731,  0.0000, -2.0087,  0.1291,\n",
      "          -0.3525, -0.8307, -0.7692, -0.0399, -0.9376,  0.7279,  0.0000,\n",
      "           0.0469,  0.4633,  0.3166, -0.1181, -0.5420, -0.6644,  0.7551,\n",
      "          -1.0643, -0.5866, -1.7884,  1.2674, -0.9265, -1.6148, -0.3332,\n",
      "           0.0000, -1.9607, -0.0719, -0.3756,  2.6979, -0.9214, -2.6320,\n",
      "          -0.5862, -0.7166, -1.3860, -1.2537,  0.1720,  0.2185, -1.1110,\n",
      "           0.9452, -0.6920, -1.5196,  0.3624,  0.2372, -1.4269, -2.3450,\n",
      "           0.0472,  0.0000,  0.4274,  0.0133, -0.9018,  0.3009, -1.1654,\n",
      "          -1.3018, -0.1876,  1.2724,  1.2666, -2.1881, -0.0564,  1.7373,\n",
      "          -1.1751,  0.9562,  1.9991,  0.5269,  0.7896, -0.6786,  0.1046,\n",
      "          -0.6805, -2.2623,  0.1675, -0.3142, -1.0434, -0.3821, -1.0800,\n",
      "           0.5580,  1.4999, -0.5647, -1.3773,  1.2434,  0.5826,  1.7530,\n",
      "           1.9514,  0.3624,  0.4871,  0.3903]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0198, 0.2455, 0.1044, 0.0464, 0.1140, 0.1465, 0.0333, 0.1673, 0.0680,\n",
      "         0.0548]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2545, -0.0010, -0.0875,  ...,  0.1592,  0.0317,  0.0431],\n",
      "        [ 0.2202, -0.1033, -0.5299,  ...,  0.0377, -0.0375,  0.1093],\n",
      "        [ 0.1181, -0.0401, -0.6793,  ..., -0.3293, -0.2103,  0.3149],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1747,  0.0117, -0.3994, -0.1470,  0.0586,  0.0633, -0.0473,\n",
      "          -0.2097, -0.0074, -0.1308,  0.1113,  0.0597, -0.0928,  0.0340,\n",
      "           0.2250,  0.1785,  0.2654,  0.0646, -0.1498,  0.0633, -0.0906,\n",
      "           0.0133,  0.1847, -0.0843, -0.0395, -0.2317,  0.1081, -0.1034,\n",
      "          -0.0750, -0.0389,  0.1718, -0.1870,  0.0743, -0.1071,  0.2834,\n",
      "          -0.0544, -0.0704,  0.1079, -0.2417,  0.1199, -0.0285, -0.0487,\n",
      "          -0.0583,  0.0234, -0.1291,  0.0789,  0.0373,  0.0442,  0.2129,\n",
      "           0.0295, -0.1409,  0.0733, -0.1694, -0.1174,  0.0052,  0.0683,\n",
      "           0.0865,  0.1415,  0.1805, -0.0014,  0.0363, -0.0059, -0.0866,\n",
      "          -0.0552, -0.0561,  0.1513, -0.2028,  0.1973, -0.0721,  0.0995,\n",
      "          -0.0158,  0.1445, -0.0863, -0.0897, -0.2839,  0.3054,  0.0754,\n",
      "           0.2292,  0.0229,  0.0570, -0.2015, -0.0399, -0.2237, -0.0808,\n",
      "          -0.0826,  0.0266, -0.0693, -0.0643, -0.0477, -0.0461, -0.0179,\n",
      "          -0.0159,  0.0314,  0.0306, -0.0018, -0.0150, -0.0573,  0.0842,\n",
      "           0.0429,  0.1275, -0.1261,  0.2018, -0.0884,  0.1779, -0.2287,\n",
      "          -0.1739, -0.0768,  0.1551, -0.1378,  0.1646,  0.3108,  0.1390,\n",
      "           0.0328, -0.3021,  0.0390, -0.1023, -0.0408,  0.0163, -0.1810,\n",
      "           0.0679,  0.0265,  0.0459, -0.2961,  0.0331, -0.0590, -0.0683,\n",
      "           0.1080, -0.0594,  0.0284, -0.0304, -0.1054, -0.1924,  0.1115,\n",
      "           0.1118, -0.1967,  0.1661,  0.3684, -0.0586, -0.2928,  0.0217,\n",
      "           0.0170,  0.2416, -0.0193,  0.1942,  0.0715, -0.0954, -0.0556,\n",
      "          -0.0226,  0.1099, -0.1663, -0.2277,  0.1172, -0.2054,  0.0015,\n",
      "           0.0965,  0.1734,  0.0925,  0.1869,  0.0443, -0.1209, -0.0891,\n",
      "          -0.1318, -0.1993,  0.1717, -0.1903, -0.0410, -0.1078, -0.0710,\n",
      "          -0.0085,  0.2203, -0.2167,  0.0165,  0.0057,  0.1209, -0.1821,\n",
      "          -0.0223,  0.1574,  0.2077,  0.3345, -0.0940,  0.0473, -0.1824,\n",
      "          -0.0826, -0.0101,  0.0905, -0.0165,  0.0217, -0.0111,  0.1394,\n",
      "          -0.1911, -0.0254,  0.1014, -0.2440, -0.0347, -0.1568,  0.1283,\n",
      "          -0.0558,  0.0550, -0.0491,  0.0499, -0.0997,  0.2569, -0.0263,\n",
      "           0.2096, -0.0436,  0.0127, -0.0473,  0.2643,  0.0065, -0.1501,\n",
      "           0.0039, -0.2508, -0.0673,  0.0837, -0.0833,  0.1179,  0.0962,\n",
      "           0.1801, -0.1953,  0.1129,  0.2272, -0.0813,  0.0839, -0.0174,\n",
      "           0.1040,  0.0436,  0.0181, -0.0396, -0.2499,  0.2120, -0.3992,\n",
      "          -0.0554,  0.0303, -0.0881,  0.0758, -0.0045, -0.0454, -0.0370,\n",
      "           0.1060,  0.0761,  0.0388, -0.0311,  0.0984, -0.1228,  0.1314,\n",
      "          -0.0156, -0.3261, -0.0701,  0.0551,  0.0541,  0.2219,  0.0673,\n",
      "          -0.0427, -0.2134, -0.0225,  0.0930]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00, -6.9724e-02, -1.8078e+00,  1.3220e+00,  0.0000e+00,\n",
      "          -3.7626e-01,  0.0000e+00,  0.0000e+00,  2.1179e+00, -2.1399e-01,\n",
      "           2.8225e-01,  8.3076e-01, -1.1107e+00,  1.9979e-01,  3.1228e-01,\n",
      "           3.5191e-01, -6.8286e-01,  1.6901e-01,  8.7447e-01,  5.4551e-01,\n",
      "           1.8833e+00,  6.0187e-01, -3.6682e-02, -5.3542e-01, -1.0006e-01,\n",
      "           6.5097e-01,  0.0000e+00, -1.3623e+00, -2.1267e+00, -1.0343e+00,\n",
      "           3.8855e-02, -1.4547e+00, -2.0767e+00,  0.0000e+00, -2.8490e-01,\n",
      "          -2.0018e+00,  2.1898e-01,  9.9702e-01,  6.0118e-01,  9.5365e-01,\n",
      "          -2.2527e-01, -2.2112e+00, -7.0625e-01,  1.3961e+00,  8.9584e-02,\n",
      "          -1.1387e+00,  2.4268e-01,  0.0000e+00, -7.0977e-01, -1.3360e+00,\n",
      "           1.6088e+00, -1.3731e-01,  6.6279e-01,  1.1164e+00,  5.6728e-01,\n",
      "           3.3308e-01, -4.4963e-01, -8.8819e-01,  1.3380e-01,  6.2852e-01,\n",
      "          -7.0488e-01,  5.6371e-01, -6.9334e-01, -1.5473e+00,  2.8938e-01,\n",
      "           9.5678e-02, -1.7748e-01,  5.9484e-01,  0.0000e+00,  5.5973e-01,\n",
      "           1.8293e-01, -5.1240e-01, -3.4109e-01,  0.0000e+00, -6.4738e-01,\n",
      "           4.6090e-01, -1.0492e+00,  1.1892e-01,  5.1718e-01, -1.8669e-01,\n",
      "          -3.8496e-01,  2.1581e+00,  0.0000e+00, -8.4545e-01,  3.9774e-01,\n",
      "           0.0000e+00,  1.6045e+00, -5.6415e-01, -1.4132e+00, -1.4905e+00,\n",
      "           4.0433e-01,  0.0000e+00,  4.9396e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6290e-01,  1.3203e+00, -9.0767e-01,  2.3908e+00,  9.5536e-01,\n",
      "          -1.2009e+00,  5.9434e-01,  1.0665e+00, -1.7339e+00,  3.6540e-01,\n",
      "           4.0229e-01, -1.2704e+00,  4.5509e-01,  1.9688e+00,  1.4954e-01,\n",
      "          -8.3238e-01,  5.3397e-01,  8.0823e-01,  6.6424e-01, -1.0551e+00,\n",
      "           9.1764e-01,  0.0000e+00, -8.4526e-01,  2.5773e-01,  8.7985e-01,\n",
      "          -8.7680e-01, -1.3967e+00, -3.6490e-01,  0.0000e+00, -1.3007e+00,\n",
      "           1.0693e+00, -8.1149e-01,  6.4945e-01,  2.5564e-01, -1.4895e+00,\n",
      "           2.5025e+00,  0.0000e+00, -1.3458e+00,  7.2244e-01,  3.2012e+00,\n",
      "           0.0000e+00, -3.8358e-01,  1.2822e+00,  0.0000e+00,  1.9402e-01,\n",
      "          -3.9230e-02,  3.0300e+00,  3.6273e-01, -1.8701e-01, -1.1120e+00,\n",
      "           1.2471e+00,  7.7537e-01, -7.7455e-01, -4.4896e-02,  0.0000e+00,\n",
      "           2.3359e+00,  7.6495e-01, -2.8964e-01, -2.1307e+00, -5.8165e-01,\n",
      "           7.8577e-01, -1.8621e+00, -1.3046e+00,  1.9011e-01, -3.6289e+00,\n",
      "          -1.8688e+00,  1.1506e+00, -8.5952e-01,  0.0000e+00, -1.4615e+00,\n",
      "          -2.7145e-02,  1.9745e+00,  1.1269e+00, -4.8585e-01, -1.2415e+00,\n",
      "          -2.1220e-01, -1.3225e+00, -1.6392e+00, -7.7178e-01,  6.8267e-01,\n",
      "          -1.3796e+00, -1.2615e-01,  6.0649e-01, -7.4877e-01,  2.5917e-01,\n",
      "           0.0000e+00, -2.5534e+00,  2.7786e-01, -5.8374e-01,  1.6236e+00,\n",
      "          -1.2403e+00, -1.8665e-03,  0.0000e+00,  9.0124e-01,  5.6542e-01,\n",
      "          -4.2001e-01,  0.0000e+00,  0.0000e+00,  8.0981e-01,  1.0502e+00,\n",
      "          -7.8912e-01, -1.4387e+00,  0.0000e+00, -7.5038e-01, -4.5418e-01,\n",
      "          -5.4748e-01,  7.2230e-01,  0.0000e+00,  1.3574e+00,  8.3764e-01,\n",
      "          -1.5239e+00, -3.5895e-01,  6.4780e-01,  2.0060e-01, -2.1784e+00,\n",
      "           8.3549e-01,  0.0000e+00, -1.2838e+00,  0.0000e+00, -1.5634e+00,\n",
      "           0.0000e+00,  0.0000e+00,  2.5768e+00, -3.1146e-02, -5.7954e-01,\n",
      "          -1.4282e+00,  1.9012e+00, -3.8077e-01,  1.4695e+00,  8.0502e-01,\n",
      "           3.6918e-01,  6.6990e-01, -7.0054e-01,  8.9119e-02,  1.0255e+00,\n",
      "           9.7809e-01, -1.4084e+00,  6.5971e-01, -1.1450e+00, -1.6456e+00,\n",
      "          -6.0013e-01,  8.9321e-03, -7.1095e-01,  3.7048e-01,  0.0000e+00,\n",
      "          -7.5240e-01,  5.7227e-01,  5.3059e-01, -6.6353e-01,  1.5465e+00,\n",
      "           5.7837e-01,  1.8921e+00, -8.6415e-01,  0.0000e+00, -3.8726e-01,\n",
      "           0.0000e+00, -9.7502e-01,  1.7727e+00, -1.0634e+00, -8.0802e-01,\n",
      "          -6.2185e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0539, 0.1250, 0.1539, 0.1474, 0.0984, 0.1452, 0.0700, 0.0543, 0.0579,\n",
      "         0.0939]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2545, -0.0010, -0.0875,  ...,  0.1592,  0.0317,  0.0431],\n",
      "        [ 0.2202, -0.1033, -0.5299,  ...,  0.0377, -0.0375,  0.1093],\n",
      "        [ 0.1181, -0.0401, -0.6793,  ..., -0.3293, -0.2103,  0.3149],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1681,  0.0287, -0.4111, -0.1325,  0.0541,  0.0345, -0.0381,\n",
      "          -0.1894, -0.0017, -0.0520,  0.1522,  0.0693, -0.1119,  0.0489,\n",
      "           0.2785,  0.2285,  0.3024,  0.0655, -0.1464,  0.0592, -0.1155,\n",
      "           0.0821,  0.1531, -0.1282, -0.1309, -0.2970,  0.0757, -0.1028,\n",
      "          -0.0472, -0.0510,  0.1309, -0.1700,  0.0110, -0.1042,  0.3200,\n",
      "          -0.0620, -0.0175,  0.1177, -0.2523,  0.1492, -0.0680, -0.1138,\n",
      "          -0.0908,  0.0482, -0.1512,  0.1168,  0.0416,  0.0727,  0.2117,\n",
      "           0.0453, -0.1856,  0.1058, -0.1350, -0.1239,  0.0304, -0.0052,\n",
      "           0.1400,  0.1955,  0.1649, -0.0494,  0.0867,  0.0120, -0.0606,\n",
      "          -0.0551, -0.0727,  0.1585, -0.2343,  0.2416, -0.0705,  0.1126,\n",
      "           0.0085,  0.1255, -0.1208, -0.0916, -0.2813,  0.2818,  0.0555,\n",
      "           0.2222,  0.0549,  0.0875, -0.1960, -0.0582, -0.2529, -0.1114,\n",
      "          -0.0978,  0.0068, -0.0724, -0.1097, -0.0496, -0.0281, -0.0508,\n",
      "          -0.0383,  0.0526,  0.0698, -0.0020, -0.0843, -0.1073,  0.0657,\n",
      "           0.0357,  0.1033, -0.1507,  0.1919, -0.1334,  0.2322, -0.2063,\n",
      "          -0.1653, -0.0625,  0.1045, -0.1038,  0.2320,  0.3672,  0.1572,\n",
      "           0.0381, -0.3049,  0.0011, -0.0549, -0.0992,  0.0212, -0.1951,\n",
      "           0.0379,  0.0132,  0.0489, -0.3604, -0.0187, -0.0589,  0.0091,\n",
      "           0.1416, -0.0835,  0.0663,  0.0558, -0.0575, -0.1522,  0.0985,\n",
      "           0.1163, -0.1676,  0.1439,  0.3466, -0.0865, -0.3227,  0.0037,\n",
      "           0.0085,  0.2782, -0.0010,  0.2110,  0.0690, -0.1141, -0.0565,\n",
      "          -0.0581,  0.1261, -0.1927, -0.2433,  0.1372, -0.1996,  0.0205,\n",
      "           0.1194,  0.2141,  0.0856,  0.1836,  0.0673, -0.1368, -0.0740,\n",
      "          -0.1521, -0.1895,  0.1198, -0.1977, -0.0244, -0.0788, -0.1569,\n",
      "           0.0037,  0.2493, -0.2073,  0.0336, -0.0330,  0.0894, -0.1710,\n",
      "           0.0391,  0.1310,  0.2303,  0.2978, -0.0443,  0.1013, -0.1451,\n",
      "          -0.0902,  0.0198,  0.1193, -0.0134,  0.0178, -0.0087,  0.2321,\n",
      "          -0.2283, -0.0354,  0.0291, -0.2770, -0.0212, -0.1808,  0.1590,\n",
      "          -0.0181,  0.0428, -0.0299,  0.0488, -0.0938,  0.2775, -0.0095,\n",
      "           0.2001, -0.0018,  0.0355, -0.1047,  0.2815,  0.0368, -0.1398,\n",
      "           0.0575, -0.1956, -0.0521,  0.0403, -0.0693,  0.1479,  0.1244,\n",
      "           0.1694, -0.2341,  0.1058,  0.2213, -0.0930,  0.0536, -0.0252,\n",
      "           0.0893,  0.0572, -0.0367, -0.0120, -0.2327,  0.2052, -0.3990,\n",
      "          -0.0091,  0.0173, -0.1438,  0.1109, -0.0111, -0.1092, -0.0372,\n",
      "           0.0755,  0.0098,  0.0018, -0.0170,  0.0904, -0.1590,  0.1729,\n",
      "          -0.0488, -0.3266, -0.0803,  0.0309,  0.0360,  0.1990,  0.0656,\n",
      "          -0.0578, -0.2968, -0.0607,  0.1112]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00, -6.9724e-02, -1.8078e+00,  0.0000e+00,  5.1608e-01,\n",
      "          -3.7626e-01,  1.0244e-03, -7.2301e-01,  2.1179e+00, -2.1399e-01,\n",
      "           2.8225e-01,  8.3076e-01, -1.1107e+00,  1.9979e-01,  3.1228e-01,\n",
      "           0.0000e+00, -6.8286e-01,  1.6901e-01,  8.7447e-01,  0.0000e+00,\n",
      "           1.8833e+00,  6.0187e-01, -3.6682e-02, -5.3542e-01, -1.0006e-01,\n",
      "           6.5097e-01, -1.6088e+00, -1.3623e+00, -2.1267e+00, -1.0343e+00,\n",
      "           3.8855e-02, -1.4547e+00, -2.0767e+00,  3.1568e-01, -2.8490e-01,\n",
      "          -2.0018e+00,  2.1898e-01,  9.9702e-01,  6.0118e-01,  9.5365e-01,\n",
      "           0.0000e+00, -2.2112e+00, -7.0625e-01,  1.3961e+00,  8.9584e-02,\n",
      "           0.0000e+00,  2.4268e-01,  7.4188e-01, -7.0977e-01, -1.3360e+00,\n",
      "           1.6088e+00, -1.3731e-01,  6.6279e-01,  0.0000e+00,  5.6728e-01,\n",
      "           3.3308e-01, -4.4963e-01, -8.8819e-01,  1.3380e-01,  6.2852e-01,\n",
      "          -7.0488e-01,  5.6371e-01, -6.9334e-01, -1.5473e+00,  0.0000e+00,\n",
      "           9.5678e-02, -1.7748e-01,  5.9484e-01, -2.1383e+00,  5.5973e-01,\n",
      "           1.8293e-01, -5.1240e-01, -3.4109e-01, -1.1320e+00, -6.4738e-01,\n",
      "           4.6090e-01, -1.0492e+00,  0.0000e+00,  5.1718e-01, -1.8669e-01,\n",
      "          -3.8496e-01,  2.1581e+00,  0.0000e+00, -8.4545e-01,  3.9774e-01,\n",
      "           0.0000e+00,  1.6045e+00, -5.6415e-01, -1.4132e+00, -1.4905e+00,\n",
      "           4.0433e-01, -3.5157e-01,  4.9396e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6290e-01,  1.3203e+00, -9.0767e-01,  2.3908e+00,  9.5536e-01,\n",
      "          -1.2009e+00,  5.9434e-01,  1.0665e+00, -1.7339e+00,  3.6540e-01,\n",
      "           4.0229e-01, -1.2704e+00,  4.5509e-01,  1.9688e+00,  1.4954e-01,\n",
      "          -8.3238e-01,  5.3397e-01,  0.0000e+00,  6.6424e-01, -1.0551e+00,\n",
      "           0.0000e+00, -7.0282e-01, -8.4526e-01,  2.5773e-01,  8.7985e-01,\n",
      "          -8.7680e-01, -1.3967e+00, -3.6490e-01, -1.8464e+00, -1.3007e+00,\n",
      "           1.0693e+00, -8.1149e-01,  6.4945e-01,  2.5564e-01, -1.4895e+00,\n",
      "           2.5025e+00,  3.7789e-01, -1.3458e+00,  7.2244e-01,  3.2012e+00,\n",
      "          -7.5281e-01, -3.8358e-01,  1.2822e+00,  2.2522e+00,  1.9402e-01,\n",
      "           0.0000e+00,  3.0300e+00,  0.0000e+00, -1.8701e-01, -1.1120e+00,\n",
      "           1.2471e+00,  7.7537e-01, -7.7455e-01, -4.4896e-02, -1.3871e+00,\n",
      "           2.3359e+00,  7.6495e-01, -2.8964e-01, -2.1307e+00, -5.8165e-01,\n",
      "           7.8577e-01, -1.8621e+00, -1.3046e+00,  1.9011e-01, -3.6289e+00,\n",
      "          -1.8688e+00,  0.0000e+00, -8.5952e-01,  9.5966e-01, -1.4615e+00,\n",
      "          -2.7145e-02,  1.9745e+00,  1.1269e+00, -4.8585e-01, -1.2415e+00,\n",
      "          -2.1220e-01, -1.3225e+00, -1.6392e+00, -7.7178e-01,  6.8267e-01,\n",
      "          -1.3796e+00,  0.0000e+00,  6.0649e-01, -7.4877e-01,  2.5917e-01,\n",
      "           1.3326e+00, -2.5534e+00,  2.7786e-01, -5.8374e-01,  1.6236e+00,\n",
      "          -1.2403e+00, -1.8665e-03, -5.0210e-02,  9.0124e-01,  5.6542e-01,\n",
      "          -4.2001e-01,  3.8815e-01, -1.1598e-01,  8.0981e-01,  1.0502e+00,\n",
      "          -7.8912e-01, -1.4387e+00, -4.1586e-01, -7.5038e-01, -4.5418e-01,\n",
      "          -5.4748e-01,  0.0000e+00, -1.8534e+00,  1.3574e+00,  8.3764e-01,\n",
      "          -1.5239e+00, -3.5895e-01,  6.4780e-01,  2.0060e-01,  0.0000e+00,\n",
      "           8.3549e-01, -1.2912e+00,  0.0000e+00,  2.6121e-01, -1.5634e+00,\n",
      "           2.0758e+00,  1.3426e-01,  2.5768e+00, -3.1146e-02, -5.7954e-01,\n",
      "          -1.4282e+00,  1.9012e+00,  0.0000e+00,  1.4695e+00,  0.0000e+00,\n",
      "           3.6918e-01,  6.6990e-01, -7.0054e-01,  8.9119e-02,  1.0255e+00,\n",
      "           9.7809e-01, -1.4084e+00,  6.5971e-01, -1.1450e+00, -1.6456e+00,\n",
      "          -6.0013e-01,  8.9321e-03, -7.1095e-01,  3.7048e-01, -2.2417e-01,\n",
      "          -7.5240e-01,  5.7227e-01,  5.3059e-01, -6.6353e-01,  1.5465e+00,\n",
      "           5.7837e-01,  1.8921e+00, -8.6415e-01,  4.9347e-01, -3.8726e-01,\n",
      "           5.0010e-01, -9.7502e-01,  1.7727e+00, -1.0634e+00, -8.0802e-01,\n",
      "          -6.2185e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0654, 0.0972, 0.1492, 0.1643, 0.0925, 0.1476, 0.0718, 0.0526, 0.0656,\n",
      "         0.0937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2545, -0.0010, -0.0875,  ...,  0.1592,  0.0317,  0.0431],\n",
      "        [ 0.2202, -0.1033, -0.5299,  ...,  0.0377, -0.0375,  0.1093],\n",
      "        [ 0.1181, -0.0401, -0.6793,  ..., -0.3293, -0.2103,  0.3149],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.6586e-01,  3.4302e-02, -4.0086e-01, -1.2195e-01,  5.0436e-02,\n",
      "           2.3397e-02, -3.5240e-02, -1.8039e-01,  2.2717e-04, -2.8919e-02,\n",
      "           1.5301e-01,  6.6165e-02, -1.1128e-01,  5.0136e-02,  2.8077e-01,\n",
      "           2.2958e-01,  2.9748e-01,  6.5085e-02, -1.4631e-01,  5.7966e-02,\n",
      "          -1.2009e-01,  9.0957e-02,  1.4353e-01, -1.2888e-01, -1.4738e-01,\n",
      "          -3.0064e-01,  6.1908e-02, -1.0498e-01, -4.1867e-02, -4.9790e-02,\n",
      "           1.2466e-01, -1.6484e-01, -7.1363e-03, -1.0159e-01,  3.1601e-01,\n",
      "          -6.3992e-02, -5.7068e-03,  1.1265e-01, -2.4798e-01,  1.4741e-01,\n",
      "          -7.7690e-02, -1.2186e-01, -9.8006e-02,  4.8572e-02, -1.4732e-01,\n",
      "           1.2595e-01,  3.8556e-02,  7.2818e-02,  2.0698e-01,  4.8099e-02,\n",
      "          -1.8836e-01,  1.0679e-01, -1.2733e-01, -1.2223e-01,  3.2917e-02,\n",
      "          -1.3756e-02,  1.4595e-01,  2.0529e-01,  1.5508e-01, -5.1757e-02,\n",
      "           9.0181e-02,  1.1768e-02, -5.6163e-02, -5.1641e-02, -7.2265e-02,\n",
      "           1.5647e-01, -2.3396e-01,  2.4391e-01, -7.3881e-02,  1.1422e-01,\n",
      "           1.4030e-02,  1.1808e-01, -1.2256e-01, -8.6337e-02, -2.7394e-01,\n",
      "           2.6400e-01,  5.4537e-02,  2.1339e-01,  5.6225e-02,  9.7512e-02,\n",
      "          -1.9041e-01, -6.5466e-02, -2.5434e-01, -1.1408e-01, -1.0266e-01,\n",
      "           5.7939e-03, -7.2570e-02, -1.1323e-01, -4.0006e-02, -2.2982e-02,\n",
      "          -5.0826e-02, -4.4348e-02,  5.7323e-02,  8.0883e-02,  2.8917e-04,\n",
      "          -9.2805e-02, -1.1276e-01,  7.1321e-02,  3.5360e-02,  9.9512e-02,\n",
      "          -1.5875e-01,  1.8325e-01, -1.3410e-01,  2.3416e-01, -2.0026e-01,\n",
      "          -1.5561e-01, -5.2860e-02,  9.2289e-02, -9.6403e-02,  2.3581e-01,\n",
      "           3.6956e-01,  1.5424e-01,  4.3586e-02, -2.9687e-01, -7.8381e-03,\n",
      "          -4.8254e-02, -1.0229e-01,  2.3585e-02, -1.9116e-01,  2.7884e-02,\n",
      "           8.0990e-03,  4.2849e-02, -3.6276e-01, -2.7608e-02, -5.6764e-02,\n",
      "           2.5696e-02,  1.4223e-01, -8.7177e-02,  7.1261e-02,  6.6799e-02,\n",
      "          -4.2223e-02, -1.4549e-01,  9.4985e-02,  1.1829e-01, -1.5316e-01,\n",
      "           1.3005e-01,  3.3725e-01, -8.9373e-02, -3.1949e-01,  3.0711e-03,\n",
      "           7.7001e-03,  2.7898e-01, -2.0835e-03,  2.1161e-01,  7.1017e-02,\n",
      "          -1.1290e-01, -5.2895e-02, -6.0834e-02,  1.3115e-01, -1.8584e-01,\n",
      "          -2.4317e-01,  1.3660e-01, -1.8826e-01,  2.8166e-02,  1.2204e-01,\n",
      "           2.1855e-01,  7.9028e-02,  1.7899e-01,  6.9457e-02, -1.3652e-01,\n",
      "          -6.8172e-02, -1.5896e-01, -1.8502e-01,  1.1262e-01, -1.8628e-01,\n",
      "          -1.4333e-02, -7.5167e-02, -1.6955e-01,  8.9437e-03,  2.5130e-01,\n",
      "          -2.0120e-01,  3.6156e-02, -3.8160e-02,  7.9617e-02, -1.6168e-01,\n",
      "           4.8749e-02,  1.2502e-01,  2.2875e-01,  2.8216e-01, -3.8916e-02,\n",
      "           1.0890e-01, -1.3578e-01, -8.8629e-02,  2.1179e-02,  1.2072e-01,\n",
      "          -5.6669e-03,  1.1275e-02, -4.1605e-03,  2.4338e-01, -2.3152e-01,\n",
      "          -3.3649e-02,  1.3485e-02, -2.8029e-01, -1.9061e-02, -1.7685e-01,\n",
      "           1.5454e-01, -1.3565e-02,  3.5934e-02, -3.3077e-02,  4.3771e-02,\n",
      "          -9.0386e-02,  2.7365e-01, -1.4102e-02,  1.9302e-01,  1.0504e-02,\n",
      "           3.6186e-02, -1.0891e-01,  2.8202e-01,  4.4682e-02, -1.3726e-01,\n",
      "           6.6220e-02, -1.7996e-01, -4.8427e-02,  3.2244e-02, -6.3733e-02,\n",
      "           1.5258e-01,  1.2251e-01,  1.6546e-01, -2.4003e-01,  1.0339e-01,\n",
      "           2.1630e-01, -9.5138e-02,  4.7466e-02, -3.1302e-02,  8.2375e-02,\n",
      "           6.1312e-02, -4.0760e-02, -1.3663e-02, -2.2975e-01,  2.0172e-01,\n",
      "          -3.8714e-01,  4.8524e-03,  1.2685e-02, -1.5095e-01,  1.1522e-01,\n",
      "          -1.1098e-02, -1.2216e-01, -3.4020e-02,  7.3622e-02, -3.2879e-03,\n",
      "          -1.3345e-03, -1.6730e-02,  8.2538e-02, -1.6222e-01,  1.7713e-01,\n",
      "          -5.3248e-02, -3.1875e-01, -8.0975e-02,  3.1909e-02,  3.3182e-02,\n",
      "           1.8899e-01,  6.2457e-02, -6.3673e-02, -3.0444e-01, -6.4677e-02,\n",
      "           1.0980e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00,  3.9945e-01, -9.6573e-01, -6.8118e-01,  3.7584e-01,\n",
      "          -2.0194e-01,  1.4647e+00, -8.3417e-02, -3.5841e+00,  9.0663e-01,\n",
      "           0.0000e+00, -6.2909e-01,  2.6036e+00, -6.2980e-01, -5.4135e-01,\n",
      "          -1.5790e-01,  0.0000e+00,  1.0947e+00,  4.5513e-01,  0.0000e+00,\n",
      "          -6.3335e-01, -3.8288e-01,  1.6408e+00,  1.5108e+00,  7.5340e-01,\n",
      "          -7.5704e-02, -1.8789e-01, -7.5932e-01,  1.6535e+00,  8.6146e-01,\n",
      "           1.2317e+00,  1.2190e+00, -1.0342e+00, -8.2825e-02,  0.0000e+00,\n",
      "           1.3954e+00,  2.8091e-01, -3.7444e+00,  1.9783e-01,  1.6006e+00,\n",
      "          -4.5894e-01, -1.3979e+00, -2.6855e-01, -1.7153e+00, -1.5239e+00,\n",
      "           6.6744e-01,  5.4079e-01,  3.7080e-01, -1.3405e+00,  0.0000e+00,\n",
      "          -6.2927e-01,  2.7517e+00,  0.0000e+00, -1.0290e+00, -2.5315e-02,\n",
      "           2.0350e-01, -8.8171e-01, -1.2520e+00, -2.3703e-01, -4.2558e-01,\n",
      "           1.1000e+00,  1.4078e+00, -2.0284e-01, -5.0128e-01, -2.9633e+00,\n",
      "           5.5100e-01,  1.2785e+00,  0.0000e+00,  4.1081e-01,  0.0000e+00,\n",
      "          -1.2668e+00,  0.0000e+00,  7.0735e-01,  0.0000e+00,  3.2565e-01,\n",
      "          -1.3451e-03, -1.6000e-01,  1.0622e+00, -5.7989e-02, -1.1906e-01,\n",
      "          -1.4001e+00,  2.1308e+00, -9.2449e-01,  1.0059e+00, -2.0766e-01,\n",
      "           0.0000e+00,  1.6615e+00, -9.7403e-01, -1.0390e-01, -5.8134e-01,\n",
      "          -2.2729e+00,  1.1001e+00, -6.2236e-01, -1.1356e+00,  0.0000e+00,\n",
      "          -1.1705e+00,  3.3723e-02,  6.2901e-01,  1.7197e+00,  0.0000e+00,\n",
      "           2.6971e+00,  0.0000e+00,  1.0760e+00,  1.4534e+00, -6.6625e-01,\n",
      "          -7.6242e-01,  1.2117e+00,  0.0000e+00, -1.4729e+00, -1.3518e-02,\n",
      "          -2.4845e-01,  1.3423e-01, -1.0477e+00,  1.3099e+00, -1.6529e+00,\n",
      "          -2.9888e+00, -5.6598e-02, -5.0021e-01, -1.9335e-01,  4.4523e-01,\n",
      "          -1.4656e+00,  0.0000e+00, -1.4603e+00, -7.2579e-01, -9.5825e-01,\n",
      "          -1.3084e+00,  8.9656e-01,  0.0000e+00,  1.2849e+00, -7.5175e-01,\n",
      "           0.0000e+00,  5.3022e-01, -1.5829e+00,  9.8397e-01,  2.7605e-01,\n",
      "          -5.8938e-01,  6.5916e-01,  5.7484e-01, -1.1587e+00, -1.0097e+00,\n",
      "          -3.8845e-01,  6.7781e-01,  0.0000e+00, -1.0106e-01, -1.6852e+00,\n",
      "           0.0000e+00, -5.4312e-01, -8.4432e-01, -7.5530e-01,  1.7750e-01,\n",
      "           1.9983e+00, -1.9943e-01, -1.9300e+00,  0.0000e+00,  4.4144e-01,\n",
      "          -1.9444e-01, -6.4568e-02, -1.2970e-01,  3.9215e-02,  5.3754e-01,\n",
      "          -2.6470e-02,  2.2062e+00,  4.8110e-01, -5.5008e-01, -5.2656e-01,\n",
      "           0.0000e+00,  2.8154e-01,  8.3468e-02, -3.5802e-01, -4.7792e-01,\n",
      "           7.3693e-01, -3.1338e-02,  2.0083e-02, -1.0021e+00,  1.2776e+00,\n",
      "          -1.0982e+00, -9.8664e-01, -2.0763e+00,  1.9687e+00,  8.6563e-02,\n",
      "          -3.0591e-02,  3.5055e-02,  6.7102e-01,  9.7984e-01, -7.4717e-01,\n",
      "          -3.4092e-01, -2.7824e+00, -7.8366e-01,  1.2093e+00,  1.0124e+00,\n",
      "           3.0734e+00,  4.9415e-01, -1.4436e-01, -5.9365e-01,  5.6046e-01,\n",
      "           2.1647e+00, -1.1877e+00,  5.3500e-01,  1.8112e+00, -9.4657e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  1.2420e+00, -1.2214e-01,  2.3199e-01,\n",
      "          -5.7492e-01, -2.2924e+00,  6.8170e-01, -1.0739e+00, -4.7103e-01,\n",
      "           2.8676e+00, -5.7326e-01, -3.4107e-01,  7.9300e-01,  3.0620e-02,\n",
      "           0.0000e+00, -1.0183e+00,  9.6647e-01, -2.4544e-01,  2.1689e+00,\n",
      "          -1.0827e+00, -4.2711e-01,  0.0000e+00,  0.0000e+00,  3.3832e-01,\n",
      "           7.0485e-01, -6.9656e-01, -6.2818e-01,  2.9228e-01, -1.5782e+00,\n",
      "          -1.1084e+00,  0.0000e+00, -6.1403e-01,  1.3099e+00, -2.9795e+00,\n",
      "           4.0345e+00,  5.8521e-01,  4.3297e-02, -1.5794e+00, -2.8661e-01,\n",
      "           7.4183e-01, -3.2477e+00, -3.0407e-01, -8.5202e-01,  1.1373e-02,\n",
      "           0.0000e+00,  2.7470e-01,  2.5235e-01,  2.6127e-01,  3.8655e-01,\n",
      "          -3.6565e-01, -1.5916e-01, -5.5379e-01, -5.2448e-02, -1.1466e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0410, 0.0481, 0.0738, 0.0653, 0.1518, 0.3153, 0.0590, 0.0801, 0.0610,\n",
      "         0.1046]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0185,  0.4012, -0.0083,  ...,  0.1341,  0.0970, -0.2319],\n",
      "        [ 0.2256,  0.2776, -0.3079,  ..., -0.1557,  0.2025, -0.2737],\n",
      "        [ 0.0505,  0.3596, -0.4216,  ..., -0.0572, -0.0573, -0.5396],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2877,  0.1531, -0.2953, -0.0329, -0.0265, -0.1095,  0.0251,\n",
      "          -0.2557,  0.1268, -0.1896,  0.0877, -0.0511, -0.2074,  0.0221,\n",
      "           0.0421, -0.0290,  0.0036,  0.2150, -0.2136,  0.1048, -0.1621,\n",
      "          -0.1665,  0.2091,  0.0339, -0.2304, -0.2840,  0.0761, -0.2343,\n",
      "          -0.0663, -0.0113,  0.1644, -0.2328, -0.2018, -0.2840,  0.0354,\n",
      "          -0.0307, -0.2055, -0.0481, -0.3787, -0.0057, -0.1911, -0.0408,\n",
      "          -0.2568, -0.0750,  0.1841,  0.0485, -0.1194, -0.2097,  0.2369,\n",
      "          -0.0429, -0.1460,  0.0522, -0.2376, -0.0791, -0.0692,  0.0367,\n",
      "          -0.1017,  0.0105,  0.2671,  0.1708, -0.1191, -0.1233, -0.2267,\n",
      "           0.0623, -0.1332, -0.0344, -0.0651,  0.1235, -0.1575,  0.1305,\n",
      "          -0.0568,  0.1163,  0.0526,  0.2089, -0.2209,  0.0839,  0.1440,\n",
      "           0.1293, -0.0102,  0.0846, -0.1084, -0.2069, -0.2943, -0.0240,\n",
      "          -0.1074,  0.1002,  0.0580, -0.0999,  0.1074, -0.1275,  0.1228,\n",
      "           0.1041, -0.0148, -0.1241, -0.0241,  0.0532,  0.2021,  0.1260,\n",
      "          -0.0086,  0.3502, -0.2574,  0.0332,  0.2516,  0.3072, -0.1323,\n",
      "          -0.0391,  0.2774,  0.2867,  0.0620,  0.0887,  0.1114,  0.1647,\n",
      "          -0.0989, -0.2426, -0.1979,  0.0932, -0.0286, -0.0464, -0.2315,\n",
      "          -0.0714, -0.0694, -0.1898, -0.2341,  0.1253, -0.2945, -0.0593,\n",
      "           0.0088, -0.0613,  0.1378, -0.1945,  0.0067, -0.1946,  0.0543,\n",
      "           0.1087, -0.1747,  0.0814,  0.2069,  0.1424, -0.1754,  0.1346,\n",
      "          -0.3210,  0.3306, -0.1583,  0.1128,  0.1267, -0.1766,  0.0763,\n",
      "           0.3514,  0.0614,  0.2980, -0.3787,  0.0283, -0.0139,  0.0929,\n",
      "           0.0064,  0.3773,  0.0162,  0.1345, -0.0547, -0.2102,  0.0040,\n",
      "          -0.2778, -0.2764,  0.2429, -0.0174, -0.0236, -0.1151, -0.2467,\n",
      "           0.3034,  0.2400, -0.2545,  0.0191,  0.3018, -0.0523, -0.0744,\n",
      "          -0.2882, -0.1244,  0.2074,  0.3022, -0.1977, -0.1971, -0.1532,\n",
      "          -0.1231,  0.0958,  0.2499,  0.1008, -0.1793,  0.0372,  0.0208,\n",
      "          -0.2386,  0.0629,  0.0247, -0.3675, -0.1153,  0.0116, -0.2526,\n",
      "          -0.0540,  0.0442, -0.0959, -0.0049, -0.0889,  0.0925, -0.0693,\n",
      "           0.0755,  0.0300,  0.0080, -0.1987,  0.2801,  0.1943, -0.2497,\n",
      "          -0.0112, -0.1972, -0.0460,  0.1175, -0.1949,  0.1569, -0.1091,\n",
      "           0.0195, -0.1364,  0.1095,  0.2454, -0.1003,  0.1549, -0.0170,\n",
      "           0.0021,  0.1133,  0.0532, -0.1578, -0.3899,  0.1226, -0.2298,\n",
      "          -0.0986, -0.0290, -0.1666, -0.0171,  0.0237, -0.2082, -0.0295,\n",
      "           0.3205,  0.1284, -0.1334, -0.1470, -0.1264, -0.0574,  0.0546,\n",
      "          -0.2634, -0.2168, -0.1745,  0.2056,  0.0188,  0.1906, -0.0216,\n",
      "          -0.2089, -0.1970, -0.0030, -0.1649]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4742, -0.4591, -1.2336, -0.1178,  0.0000,  0.0256,  0.6622,\n",
      "           0.0000,  0.6706,  0.9337,  1.7083, -1.0165,  0.9467, -0.2517,\n",
      "          -1.6341,  0.5128,  1.8776, -0.7565, -1.5630, -2.6438, -1.1337,\n",
      "           0.0000,  2.9302,  0.5543, -0.1168,  3.2097,  1.8371,  0.5190,\n",
      "          -2.2263, -1.2855,  0.0296,  1.0135,  0.3246,  0.8602, -0.7987,\n",
      "          -1.4656,  0.6199, -0.7713,  1.9917,  0.1024,  0.4676, -2.2044,\n",
      "          -0.5664, -0.1153, -0.7131, -0.6895,  1.9280,  0.1098,  0.0000,\n",
      "          -1.8508,  1.4682,  0.4628,  0.6676, -0.2836,  0.5317,  0.2747,\n",
      "          -1.2422, -0.9514,  1.8143,  0.0000,  0.2048, -1.8182, -1.4017,\n",
      "          -0.8065,  0.0000,  0.0000, -0.1667, -0.2557, -0.0041, -0.4610,\n",
      "           0.0000, -0.3243,  0.1475, -0.1268,  0.0000, -0.8065,  2.0662,\n",
      "           1.6799,  0.0877, -0.5464,  1.2270,  0.0871,  0.3269,  0.0000,\n",
      "          -0.0718, -1.7326, -1.4586, -0.8910,  0.6231,  0.8107, -1.2237,\n",
      "          -1.1444,  1.9853, -0.3659,  0.0000,  0.1565,  2.1420, -0.4055,\n",
      "          -0.3042, -1.8396, -1.2905, -0.7218,  0.0000,  0.2377,  0.3821,\n",
      "           1.1139, -1.0699,  2.2526, -0.2628, -0.2881,  0.0000,  0.6108,\n",
      "          -0.2550,  0.0000, -1.9424,  1.1283,  1.0061, -2.4980, -0.5747,\n",
      "           0.0297, -1.6954, -0.4013, -0.3797, -0.0788, -0.5371, -1.1115,\n",
      "           1.3052,  0.1700,  0.0000,  0.0000,  2.0798, -2.6343,  0.3590,\n",
      "          -0.7229,  0.4294,  0.0597,  0.3270, -2.1026, -0.4968, -1.6778,\n",
      "          -0.6421,  0.2341, -1.1871, -1.2154, -0.6313, -0.0410,  0.4649,\n",
      "           1.7384,  1.5940,  1.4317, -1.2628, -0.5774, -0.4802, -0.0395,\n",
      "           0.3268, -0.1165,  1.3540, -0.0312,  0.0000, -1.8060, -1.4270,\n",
      "          -0.9004, -0.7054, -0.3891, -0.9818, -0.1290,  0.4064,  0.0000,\n",
      "           0.5179, -0.1473,  1.5146, -0.3732, -0.3159, -2.0088,  0.1290,\n",
      "          -0.3525, -0.8309, -0.7694, -0.0399, -0.9376,  0.7279,  1.0421,\n",
      "           0.0470,  0.0000,  0.3168, -0.1181, -0.5422, -0.6644,  0.7551,\n",
      "          -1.0644, -0.5865, -1.7884,  1.2674, -0.9266, -1.6148,  0.0000,\n",
      "          -1.1570,  0.0000, -0.0720, -0.3758,  2.6981, -0.9215, -2.6321,\n",
      "          -0.5862,  0.0000, -1.3861, -1.2538,  0.1720,  0.2184, -1.1111,\n",
      "           0.9453, -0.6920, -1.5197,  0.3625,  0.2371, -1.4270, -2.3451,\n",
      "           0.0471, -1.4800,  0.4276,  0.0000, -0.9018,  0.0000, -1.1655,\n",
      "          -1.3019, -0.1876,  1.2724,  1.2667, -2.1881, -0.0565,  1.7373,\n",
      "          -1.1751,  0.9563,  1.9991,  0.5269,  0.7899, -0.6785,  0.1047,\n",
      "          -0.6806, -2.2624,  0.1676, -0.3143, -1.0434, -0.3820, -1.0800,\n",
      "           0.5580,  1.5001, -0.5647, -1.3774,  0.0000,  0.5826,  1.7532,\n",
      "           1.9513,  0.3623,  0.4871,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0199, 0.2501, 0.0833, 0.0566, 0.1036, 0.1323, 0.0314, 0.1762, 0.0887,\n",
      "         0.0580]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0185,  0.4012, -0.0083,  ...,  0.1341,  0.0970, -0.2319],\n",
      "        [ 0.2256,  0.2776, -0.3079,  ..., -0.1557,  0.2025, -0.2737],\n",
      "        [ 0.0505,  0.3596, -0.4216,  ..., -0.0572, -0.0573, -0.5396],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9921e-01,  1.3867e-01, -2.2606e-01,  5.6242e-02,  1.7645e-02,\n",
      "          -7.4895e-02, -5.1746e-02, -1.5317e-01,  1.4643e-01, -5.1158e-02,\n",
      "          -2.5117e-02,  5.4546e-02, -1.7832e-01, -1.0943e-03, -4.7305e-02,\n",
      "          -3.7235e-02,  7.5505e-02,  1.7918e-01, -2.3439e-02,  1.1030e-01,\n",
      "          -1.3598e-01, -1.3867e-01,  1.2778e-01, -4.2238e-02, -2.1883e-01,\n",
      "          -1.2858e-01,  1.7429e-01, -1.6429e-01, -1.3269e-02, -1.7512e-04,\n",
      "           1.5115e-01, -2.5909e-01, -1.1453e-01, -2.0377e-01,  7.3206e-02,\n",
      "          -3.7557e-03, -1.7017e-01, -9.0125e-02, -2.7675e-01, -4.4314e-02,\n",
      "          -2.2667e-01,  4.4186e-02, -1.2071e-01, -1.2516e-02,  1.6018e-01,\n",
      "          -8.0587e-02, -2.7362e-02, -1.0948e-01,  1.8186e-01,  6.9846e-02,\n",
      "          -5.9771e-02,  1.0339e-01, -2.2914e-01, -1.1557e-01, -8.5605e-02,\n",
      "           6.8153e-02, -7.2094e-02, -1.3183e-01,  1.5023e-01,  1.6908e-02,\n",
      "          -1.8071e-01, -9.3879e-02, -1.1401e-01, -3.8848e-02, -1.0176e-01,\n",
      "          -7.8334e-02,  5.3033e-02,  9.7099e-02, -1.3938e-01,  8.8964e-02,\n",
      "          -6.4881e-02,  1.4993e-04,  6.4912e-02,  2.7520e-01, -7.5904e-02,\n",
      "          -3.9566e-02,  1.2871e-01, -1.0220e-02,  2.9554e-02,  6.9875e-02,\n",
      "          -6.8050e-02, -7.6018e-02, -1.9704e-01,  5.7005e-02, -9.3013e-02,\n",
      "          -1.9903e-02,  3.1901e-02, -1.1924e-01,  1.0731e-02, -4.9508e-02,\n",
      "          -2.5392e-03,  1.3263e-01, -6.8996e-02, -1.8670e-01,  1.0807e-02,\n",
      "           1.9303e-02,  7.4303e-02,  5.9287e-02,  7.6387e-02,  2.7874e-01,\n",
      "          -2.2872e-01, -1.0865e-01,  1.2962e-01,  2.4647e-01, -1.3536e-02,\n",
      "           2.7715e-02,  2.5088e-01,  1.7374e-01,  6.0228e-02,  4.0196e-02,\n",
      "           9.5879e-02,  1.4076e-01, -1.0376e-01, -1.0530e-01, -8.0917e-02,\n",
      "           9.5876e-02, -2.6116e-02,  1.0048e-02, -2.4065e-01,  7.6638e-03,\n",
      "          -3.4828e-02, -2.4922e-02, -8.3424e-02,  4.3807e-02, -2.1047e-01,\n",
      "           2.5088e-02,  6.2718e-02, -8.2928e-03,  7.5678e-02, -7.5410e-03,\n",
      "          -3.9762e-02,  4.3120e-02, -1.1067e-01, -2.6808e-02, -9.8519e-02,\n",
      "           4.7127e-02,  1.1930e-01,  7.5705e-02, -1.3327e-02, -1.5893e-02,\n",
      "          -2.0211e-01,  2.2417e-01, -1.8603e-01,  7.2560e-02,  5.4968e-02,\n",
      "          -9.9434e-02,  2.9896e-02,  2.8508e-01,  2.4820e-02,  2.1722e-01,\n",
      "          -2.1246e-01, -3.7021e-02, -5.6996e-02,  8.8737e-02, -6.0674e-02,\n",
      "           2.7395e-01, -2.2246e-02,  1.6147e-01, -1.4895e-01, -1.4972e-01,\n",
      "           2.8747e-02, -2.3797e-01, -1.5096e-01,  8.3950e-02, -8.5388e-02,\n",
      "          -5.9375e-02, -1.5280e-01, -2.4809e-01,  2.6654e-01,  9.2663e-02,\n",
      "          -2.0166e-01,  4.0435e-02,  2.3790e-01, -1.1212e-01, -4.4802e-02,\n",
      "          -2.6451e-01, -2.0190e-02,  1.3285e-01,  2.3876e-01, -6.4911e-02,\n",
      "          -1.5071e-01, -8.2375e-02, -1.7525e-02,  9.4732e-02,  1.4852e-01,\n",
      "          -1.9401e-02, -9.2483e-02, -4.2166e-02, -1.3398e-01, -2.1071e-01,\n",
      "           1.4391e-01, -1.2049e-02, -1.7625e-01, -6.2904e-02,  4.8086e-02,\n",
      "          -2.4028e-01, -5.5251e-03, -2.2846e-02,  3.8083e-02, -9.9087e-02,\n",
      "          -1.6331e-01,  5.5877e-02, -9.2353e-02,  9.3859e-03, -8.1603e-02,\n",
      "           1.2397e-01, -2.4276e-01,  2.2753e-01,  2.4940e-01, -1.4114e-01,\n",
      "          -1.2281e-01, -1.0741e-01,  8.9764e-03, -3.6121e-02, -2.6366e-01,\n",
      "           1.0885e-01, -3.7628e-02, -4.8109e-02, -6.0151e-03,  7.1495e-02,\n",
      "           1.2639e-01,  2.7829e-02,  7.2414e-02, -2.6413e-04, -7.1217e-02,\n",
      "           2.5747e-02,  1.0331e-02, -3.6744e-02, -3.2424e-01,  9.4677e-03,\n",
      "          -3.5748e-02, -9.9568e-02,  2.5946e-02, -6.6851e-02,  1.2435e-02,\n",
      "           3.9104e-02, -2.1994e-01,  2.5437e-02,  3.1652e-01,  5.6049e-02,\n",
      "          -8.5817e-02, -4.2287e-02,  8.9184e-03, -2.0460e-02,  1.5448e-01,\n",
      "          -2.5635e-01, -1.7903e-01, -1.5111e-01,  8.3613e-02, -1.0090e-01,\n",
      "           1.8582e-01, -6.5311e-02, -1.6054e-01, -1.4652e-01,  4.5141e-02,\n",
      "          -1.8741e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00,  0.0000e+00, -1.8077e+00,  0.0000e+00,  5.1605e-01,\n",
      "          -3.7631e-01,  0.0000e+00, -7.2303e-01,  2.1178e+00, -2.1394e-01,\n",
      "           2.8226e-01,  8.3078e-01, -1.1107e+00,  1.9985e-01,  0.0000e+00,\n",
      "           3.5194e-01, -6.8292e-01,  1.6894e-01,  8.7459e-01,  5.4549e-01,\n",
      "           0.0000e+00,  6.0181e-01, -3.6709e-02, -5.3540e-01, -1.0007e-01,\n",
      "           6.5083e-01, -1.6088e+00, -1.3623e+00, -2.1268e+00, -1.0343e+00,\n",
      "           3.8894e-02,  0.0000e+00, -2.0766e+00,  3.1566e-01, -2.8485e-01,\n",
      "          -2.0019e+00,  2.1898e-01,  9.9695e-01,  6.0114e-01,  0.0000e+00,\n",
      "          -2.2535e-01, -2.2111e+00, -7.0635e-01,  1.3961e+00,  8.9565e-02,\n",
      "          -1.1387e+00,  2.4261e-01,  7.4190e-01, -7.0973e-01,  0.0000e+00,\n",
      "           1.6088e+00, -1.3721e-01,  6.6282e-01,  1.1164e+00,  5.6738e-01,\n",
      "           3.3312e-01, -4.4972e-01, -8.8830e-01,  1.3374e-01,  6.2855e-01,\n",
      "          -7.0495e-01,  0.0000e+00,  0.0000e+00, -1.5473e+00,  2.8938e-01,\n",
      "           9.5662e-02, -1.7752e-01,  5.9486e-01,  0.0000e+00,  5.5975e-01,\n",
      "           1.8287e-01, -5.1241e-01, -3.4107e-01, -1.1319e+00, -6.4732e-01,\n",
      "           4.6095e-01, -1.0493e+00,  1.1883e-01,  5.1710e-01, -1.8666e-01,\n",
      "          -3.8506e-01,  2.1581e+00,  7.7755e-01, -8.4552e-01,  3.9775e-01,\n",
      "           4.1929e-01,  1.6044e+00, -5.6420e-01, -1.4133e+00, -1.4906e+00,\n",
      "           4.0434e-01, -3.5154e-01,  4.9384e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6293e-01,  1.3204e+00, -9.0766e-01,  0.0000e+00,  9.5530e-01,\n",
      "          -1.2009e+00,  5.9426e-01,  1.0665e+00, -1.7337e+00,  3.6545e-01,\n",
      "           4.0223e-01, -1.2704e+00,  4.5514e-01,  1.9688e+00,  1.4952e-01,\n",
      "          -8.3225e-01,  5.3386e-01,  8.0828e-01,  6.6419e-01, -1.0549e+00,\n",
      "           9.1770e-01, -7.0279e-01, -8.4523e-01,  2.5771e-01,  8.7985e-01,\n",
      "          -8.7681e-01, -1.3967e+00, -3.6501e-01, -1.8464e+00, -1.3008e+00,\n",
      "           1.0692e+00, -8.1150e-01,  6.4941e-01,  2.5559e-01, -1.4894e+00,\n",
      "           2.5025e+00,  0.0000e+00, -1.3458e+00,  7.2248e-01,  3.2012e+00,\n",
      "          -7.5281e-01, -3.8358e-01,  1.2822e+00,  2.2522e+00,  1.9404e-01,\n",
      "          -3.9249e-02,  3.0301e+00,  3.6274e-01, -1.8695e-01, -1.1119e+00,\n",
      "           1.2471e+00,  7.7539e-01, -7.7456e-01, -4.4907e-02,  0.0000e+00,\n",
      "           2.3359e+00,  7.6490e-01, -2.8963e-01, -2.1307e+00, -5.8159e-01,\n",
      "           7.8589e-01, -1.8621e+00, -1.3047e+00,  1.9012e-01, -3.6290e+00,\n",
      "          -1.8687e+00,  1.1506e+00, -8.5962e-01,  9.5967e-01,  0.0000e+00,\n",
      "          -2.7185e-02,  0.0000e+00,  1.1270e+00, -4.8598e-01, -1.2414e+00,\n",
      "          -2.1209e-01, -1.3225e+00, -1.6391e+00, -7.7182e-01,  6.8264e-01,\n",
      "          -1.3797e+00, -1.2617e-01,  6.0664e-01, -7.4873e-01,  2.5933e-01,\n",
      "           1.3325e+00, -2.5534e+00,  2.7782e-01, -5.8379e-01,  1.6236e+00,\n",
      "          -1.2403e+00, -1.8600e-03, -5.0211e-02,  9.0118e-01,  5.6549e-01,\n",
      "          -4.1998e-01,  3.8816e-01, -1.1597e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -7.8919e-01, -1.4388e+00, -4.1594e-01, -7.5036e-01, -4.5416e-01,\n",
      "          -5.4740e-01,  7.2227e-01, -1.8535e+00,  1.3574e+00,  0.0000e+00,\n",
      "          -1.5240e+00, -3.5889e-01,  6.4766e-01,  0.0000e+00, -2.1784e+00,\n",
      "           8.3544e-01, -1.2912e+00, -1.2838e+00,  2.6126e-01,  0.0000e+00,\n",
      "           2.0757e+00,  1.3423e-01,  2.5768e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -1.4283e+00,  1.9011e+00, -3.8080e-01,  1.4694e+00,  8.0507e-01,\n",
      "           0.0000e+00,  6.6980e-01, -7.0059e-01,  8.9144e-02,  1.0256e+00,\n",
      "           9.7815e-01, -1.4084e+00,  6.5967e-01,  0.0000e+00, -1.6456e+00,\n",
      "          -6.0010e-01,  8.8578e-03, -7.1095e-01,  3.7047e-01, -2.2415e-01,\n",
      "           0.0000e+00,  0.0000e+00,  5.3058e-01, -6.6345e-01,  1.5465e+00,\n",
      "           5.7833e-01,  1.8921e+00, -8.6417e-01,  4.9344e-01, -3.8740e-01,\n",
      "           5.0018e-01, -9.7517e-01,  1.7727e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -6.2188e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0733, 0.0952, 0.1212, 0.1293, 0.0985, 0.1720, 0.0698, 0.0611, 0.0639,\n",
      "         0.1157]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0185,  0.4012, -0.0083,  ...,  0.1341,  0.0970, -0.2319],\n",
      "        [ 0.2256,  0.2776, -0.3079,  ..., -0.1557,  0.2025, -0.2737],\n",
      "        [ 0.0505,  0.3596, -0.4216,  ..., -0.0572, -0.0573, -0.5396],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0522e-01,  1.3553e-01, -2.2084e-01,  2.1998e-02,  3.5682e-02,\n",
      "          -3.8976e-02, -9.4551e-03, -1.7744e-01,  1.5914e-01, -1.1704e-01,\n",
      "           2.0852e-02,  5.7482e-02, -1.5151e-01,  2.9035e-05, -3.0628e-02,\n",
      "          -1.8177e-02,  4.2994e-02,  1.8913e-01, -5.3476e-02,  1.3267e-01,\n",
      "          -1.4963e-01, -1.0767e-01,  1.5794e-01, -9.4059e-03, -2.1036e-01,\n",
      "          -2.4598e-01,  1.4052e-01, -1.7526e-01, -1.8589e-02, -4.5894e-03,\n",
      "           1.1390e-01, -1.7510e-01, -1.3959e-01, -1.9763e-01,  4.3012e-02,\n",
      "          -5.8142e-02, -1.6563e-01, -6.4146e-02, -3.1405e-01, -5.1255e-02,\n",
      "          -2.4083e-01, -4.3725e-02, -1.8741e-01, -6.7698e-02,  1.9241e-01,\n",
      "          -5.8743e-02, -6.9841e-02, -9.4601e-02,  2.1700e-01,  1.5867e-02,\n",
      "          -7.2336e-02,  1.2853e-01, -2.0147e-01, -7.8188e-02, -5.1093e-02,\n",
      "           3.5559e-02, -8.6336e-02, -8.5757e-02,  2.1551e-01,  5.5605e-02,\n",
      "          -1.5412e-01, -6.3550e-02, -1.2462e-01, -2.1879e-02, -1.2489e-01,\n",
      "          -3.8404e-02,  4.0137e-02,  5.5100e-02, -1.0832e-01,  7.1168e-02,\n",
      "          -1.0027e-01,  1.1040e-02,  5.6613e-02,  2.2322e-01, -1.2263e-01,\n",
      "           1.1047e-02,  1.0063e-01,  4.4622e-02,  1.5015e-02,  2.0129e-02,\n",
      "          -6.7250e-02, -1.2764e-01, -1.9733e-01, -1.5041e-02, -8.3741e-02,\n",
      "           4.3090e-02,  4.3155e-02, -1.5721e-01,  2.3300e-03, -8.4740e-02,\n",
      "           5.3078e-02,  1.4034e-01, -3.4324e-02, -1.6629e-01, -8.7807e-03,\n",
      "           8.6534e-03,  1.3611e-01,  4.3057e-02,  4.6615e-03,  2.6917e-01,\n",
      "          -2.2049e-01, -4.8865e-02,  2.1675e-01,  2.6235e-01, -9.6704e-02,\n",
      "           2.2484e-03,  2.4677e-01,  2.0427e-01,  7.9547e-02,  1.0259e-02,\n",
      "           8.5775e-02,  1.5547e-01, -1.3447e-01, -1.5846e-01, -1.1725e-01,\n",
      "           1.1984e-01, -2.1830e-02, -3.1407e-02, -2.3265e-01, -1.5113e-02,\n",
      "          -8.3698e-02, -1.0244e-01, -1.0206e-01,  8.3275e-02, -2.2426e-01,\n",
      "          -1.9924e-02,  4.9694e-02, -1.6371e-02,  5.6122e-02, -8.1731e-02,\n",
      "          -3.0845e-02, -5.1547e-02, -7.1636e-02,  5.3638e-03, -1.2799e-01,\n",
      "           5.1532e-02,  9.9721e-02,  1.1276e-01, -8.9267e-02,  3.5236e-02,\n",
      "          -2.5951e-01,  2.9010e-01, -1.5625e-01,  8.7242e-02,  8.1918e-02,\n",
      "          -1.2700e-01,  4.9506e-02,  3.1754e-01, -2.5509e-03,  2.4729e-01,\n",
      "          -2.1998e-01, -1.2165e-02, -3.5984e-02,  2.2395e-02, -8.0615e-02,\n",
      "           3.0595e-01,  1.8428e-02,  1.1975e-01, -1.4162e-01, -1.5339e-01,\n",
      "           4.8352e-02, -2.5667e-01, -1.7374e-01,  7.5588e-02, -4.2470e-02,\n",
      "          -7.9871e-02, -1.3772e-01, -2.4504e-01,  2.7785e-01,  1.6453e-01,\n",
      "          -2.0047e-01,  7.1488e-03,  2.5202e-01, -8.3410e-02, -5.6831e-02,\n",
      "          -2.7466e-01, -9.6917e-02,  1.5299e-01,  1.8791e-01, -1.2969e-01,\n",
      "          -1.4219e-01, -1.0274e-01, -2.6917e-02,  1.1937e-01,  1.8094e-01,\n",
      "           4.6284e-02, -7.4640e-02, -2.2681e-02, -6.0340e-02, -1.9407e-01,\n",
      "           8.2843e-02, -3.1450e-02, -2.7281e-01, -8.1176e-02,  9.3105e-04,\n",
      "          -2.0374e-01, -1.9061e-02, -5.2651e-03, -1.2808e-02, -8.4190e-02,\n",
      "          -1.4232e-01,  4.4670e-02, -5.2392e-02, -3.6106e-02, -2.0490e-02,\n",
      "           8.5848e-02, -2.4174e-01,  1.6286e-01,  2.5984e-01, -2.0213e-01,\n",
      "          -5.4498e-02, -1.2854e-01, -3.7045e-02,  2.9173e-02, -2.3480e-01,\n",
      "           9.3810e-02, -5.1143e-02, -4.5874e-02, -5.5722e-02,  7.2343e-02,\n",
      "           1.3448e-01, -5.4127e-02,  6.1413e-02,  2.0578e-02, -7.9883e-02,\n",
      "           5.0205e-02, -1.5224e-02, -8.1140e-02, -2.8813e-01,  5.9067e-02,\n",
      "          -1.2575e-01, -7.0183e-02,  2.4237e-02, -4.0543e-02,  1.5558e-02,\n",
      "           6.4457e-02, -1.7803e-01, -8.9992e-03,  3.0143e-01,  7.9359e-02,\n",
      "          -1.1826e-01, -4.5107e-02, -3.3385e-02, -5.6373e-02,  9.0304e-02,\n",
      "          -2.8644e-01, -1.7270e-01, -1.1189e-01,  1.3752e-01, -2.0097e-02,\n",
      "           1.8546e-01, -3.7956e-02, -1.4433e-01, -1.4190e-01,  4.6371e-04,\n",
      "          -2.1095e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00, -6.9770e-02, -1.8077e+00,  1.3220e+00,  5.1605e-01,\n",
      "          -3.7631e-01,  1.0883e-03,  0.0000e+00,  2.1178e+00,  0.0000e+00,\n",
      "           2.8226e-01,  8.3078e-01, -1.1107e+00,  1.9985e-01,  3.1218e-01,\n",
      "           3.5194e-01, -6.8292e-01,  1.6894e-01,  8.7459e-01,  5.4549e-01,\n",
      "           1.8834e+00,  6.0181e-01, -3.6709e-02, -5.3540e-01, -1.0007e-01,\n",
      "           6.5083e-01, -1.6088e+00, -1.3623e+00, -2.1268e+00, -1.0343e+00,\n",
      "           3.8894e-02, -1.4548e+00, -2.0766e+00,  3.1566e-01, -2.8485e-01,\n",
      "          -2.0019e+00,  2.1898e-01,  9.9695e-01,  6.0114e-01,  9.5362e-01,\n",
      "          -2.2535e-01, -2.2111e+00, -7.0635e-01,  0.0000e+00,  8.9565e-02,\n",
      "          -1.1387e+00,  2.4261e-01,  7.4190e-01,  0.0000e+00, -1.3360e+00,\n",
      "           0.0000e+00, -1.3721e-01,  6.6282e-01,  1.1164e+00,  5.6738e-01,\n",
      "           3.3312e-01,  0.0000e+00, -8.8830e-01,  1.3374e-01,  6.2855e-01,\n",
      "          -7.0495e-01,  5.6382e-01, -6.9327e-01, -1.5473e+00,  2.8938e-01,\n",
      "           9.5662e-02, -1.7752e-01,  5.9486e-01, -2.1383e+00,  5.5975e-01,\n",
      "           1.8287e-01,  0.0000e+00, -3.4107e-01, -1.1319e+00, -6.4732e-01,\n",
      "           4.6095e-01, -1.0493e+00,  1.1883e-01,  5.1710e-01, -1.8666e-01,\n",
      "          -3.8506e-01,  2.1581e+00,  7.7755e-01, -8.4552e-01,  3.9775e-01,\n",
      "           4.1929e-01,  1.6044e+00,  0.0000e+00, -1.4133e+00, -1.4906e+00,\n",
      "           4.0434e-01, -3.5154e-01,  4.9384e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6293e-01,  1.3204e+00, -9.0766e-01,  2.3908e+00,  9.5530e-01,\n",
      "          -1.2009e+00,  5.9426e-01,  1.0665e+00, -1.7337e+00,  3.6545e-01,\n",
      "           4.0223e-01, -1.2704e+00,  4.5514e-01,  1.9688e+00,  1.4952e-01,\n",
      "          -8.3225e-01,  5.3386e-01,  8.0828e-01,  6.6419e-01, -1.0549e+00,\n",
      "           9.1770e-01, -7.0279e-01, -8.4523e-01,  2.5771e-01,  8.7985e-01,\n",
      "          -8.7681e-01, -1.3967e+00, -3.6501e-01, -1.8464e+00,  0.0000e+00,\n",
      "           1.0692e+00, -8.1150e-01,  6.4941e-01,  2.5559e-01, -1.4894e+00,\n",
      "           2.5025e+00,  3.7787e-01, -1.3458e+00,  7.2248e-01,  3.2012e+00,\n",
      "          -7.5281e-01, -3.8358e-01,  1.2822e+00,  2.2522e+00,  1.9404e-01,\n",
      "          -3.9249e-02,  0.0000e+00,  3.6274e-01, -1.8695e-01,  0.0000e+00,\n",
      "           1.2471e+00,  7.7539e-01, -7.7456e-01, -4.4907e-02, -1.3871e+00,\n",
      "           2.3359e+00,  7.6490e-01, -2.8963e-01, -2.1307e+00, -5.8159e-01,\n",
      "           7.8589e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.6290e+00,\n",
      "          -1.8687e+00,  0.0000e+00, -8.5962e-01,  9.5967e-01,  0.0000e+00,\n",
      "          -2.7185e-02,  1.9744e+00,  1.1270e+00, -4.8598e-01, -1.2414e+00,\n",
      "          -2.1209e-01, -1.3225e+00, -1.6391e+00,  0.0000e+00,  6.8264e-01,\n",
      "          -1.3797e+00, -1.2617e-01,  6.0664e-01, -7.4873e-01,  2.5933e-01,\n",
      "           1.3325e+00, -2.5534e+00,  2.7782e-01, -5.8379e-01,  1.6236e+00,\n",
      "          -1.2403e+00, -1.8600e-03, -5.0211e-02,  9.0118e-01,  5.6549e-01,\n",
      "          -4.1998e-01,  3.8816e-01, -1.1597e-01,  8.0967e-01,  1.0502e+00,\n",
      "          -7.8919e-01, -1.4388e+00,  0.0000e+00, -7.5036e-01, -4.5416e-01,\n",
      "          -5.4740e-01,  7.2227e-01, -1.8535e+00,  1.3574e+00,  8.3772e-01,\n",
      "          -1.5240e+00, -3.5889e-01,  6.4766e-01,  2.0065e-01, -2.1784e+00,\n",
      "           8.3544e-01, -1.2912e+00, -1.2838e+00,  2.6126e-01, -1.5633e+00,\n",
      "           2.0757e+00,  0.0000e+00,  2.5768e+00, -3.1130e-02,  0.0000e+00,\n",
      "          -1.4283e+00,  1.9011e+00, -3.8080e-01,  1.4694e+00,  8.0507e-01,\n",
      "           3.6908e-01,  0.0000e+00,  0.0000e+00,  8.9144e-02,  1.0256e+00,\n",
      "           0.0000e+00, -1.4084e+00,  6.5967e-01, -1.1449e+00, -1.6456e+00,\n",
      "          -6.0010e-01,  8.8578e-03, -7.1095e-01,  3.7047e-01, -2.2415e-01,\n",
      "          -7.5233e-01,  5.7232e-01,  0.0000e+00, -6.6345e-01,  1.5465e+00,\n",
      "           5.7833e-01,  1.8921e+00, -8.6417e-01,  4.9344e-01, -3.8740e-01,\n",
      "           5.0018e-01, -9.7517e-01,  1.7727e+00, -1.0635e+00, -8.0792e-01,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0479, 0.1267, 0.1185, 0.1529, 0.1117, 0.1397, 0.0640, 0.0490, 0.0726,\n",
      "         0.1169]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0185,  0.4012, -0.0083,  ...,  0.1341,  0.0970, -0.2319],\n",
      "        [ 0.2256,  0.2776, -0.3079,  ..., -0.1557,  0.2025, -0.2737],\n",
      "        [ 0.0505,  0.3596, -0.4216,  ..., -0.0572, -0.0573, -0.5396],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0427e-01,  1.1511e-01, -2.1052e-01,  2.1502e-02,  5.7353e-02,\n",
      "          -2.4968e-02, -2.0604e-02, -1.6174e-01,  1.6319e-01, -1.0662e-01,\n",
      "           3.5662e-03,  9.9256e-02, -1.4927e-01,  6.2719e-03, -4.9677e-02,\n",
      "          -5.3868e-03,  3.4404e-02,  1.9517e-01, -4.1926e-02,  1.2997e-01,\n",
      "          -1.3719e-01, -9.4047e-02,  1.5325e-01, -3.1546e-02, -2.1342e-01,\n",
      "          -2.3683e-01,  1.6871e-01, -1.6803e-01, -6.4266e-03,  1.5263e-02,\n",
      "           1.2948e-01, -1.6934e-01, -1.4152e-01, -2.1219e-01,  5.8331e-02,\n",
      "          -7.7748e-02, -1.5105e-01, -5.2864e-02, -3.1276e-01, -4.3732e-02,\n",
      "          -2.4827e-01, -3.8519e-02, -1.6624e-01, -7.4035e-02,  1.8455e-01,\n",
      "          -8.0600e-02, -5.0925e-02, -8.9514e-02,  2.2111e-01,  1.7511e-02,\n",
      "          -7.2758e-02,  1.4614e-01, -1.9891e-01, -8.1265e-02, -4.9352e-02,\n",
      "           3.0500e-02, -8.7936e-02, -1.0597e-01,  2.0979e-01,  3.5595e-02,\n",
      "          -1.5994e-01, -7.8826e-02, -1.1568e-01, -3.1533e-02, -1.3815e-01,\n",
      "          -5.0854e-02,  4.0204e-02,  4.4964e-02, -1.0894e-01,  5.4442e-02,\n",
      "          -1.0670e-01, -1.2069e-03,  7.4725e-02,  2.1978e-01, -1.0922e-01,\n",
      "           4.1552e-03,  8.7937e-02,  3.7308e-02,  2.5674e-02, -1.2361e-03,\n",
      "          -6.0205e-02, -9.6856e-02, -1.8977e-01, -1.3587e-02, -9.5334e-02,\n",
      "           2.0921e-02,  4.0677e-02, -1.6599e-01, -8.2730e-03, -7.7168e-02,\n",
      "           3.6073e-02,  1.4291e-01, -3.9376e-02, -1.7822e-01,  7.1383e-03,\n",
      "           1.2788e-02,  1.1456e-01,  1.3789e-02,  1.8597e-02,  2.5631e-01,\n",
      "          -2.1066e-01, -4.7139e-02,  2.0614e-01,  2.8164e-01, -8.6683e-02,\n",
      "          -3.1382e-03,  2.4392e-01,  2.0134e-01,  8.3169e-02,  1.2430e-02,\n",
      "           7.7363e-02,  1.7034e-01, -1.5224e-01, -1.3133e-01, -1.0432e-01,\n",
      "           1.3607e-01, -1.5871e-02, -2.1796e-02, -2.4658e-01,  6.1404e-03,\n",
      "          -9.2203e-02, -9.5584e-02, -7.6368e-02,  7.5506e-02, -2.3341e-01,\n",
      "          -1.2291e-02,  4.0861e-02, -1.6854e-04,  4.1434e-02, -7.2906e-02,\n",
      "          -5.6587e-02, -7.9288e-03, -1.0541e-01, -2.1558e-02, -1.2560e-01,\n",
      "           5.0544e-02,  8.1374e-02,  1.1636e-01, -6.2928e-02,  2.4722e-02,\n",
      "          -2.7826e-01,  2.8307e-01, -1.5270e-01,  7.3169e-02,  7.8847e-02,\n",
      "          -1.3732e-01,  5.6124e-02,  3.1913e-01, -2.0365e-03,  2.2815e-01,\n",
      "          -2.1499e-01, -7.0825e-03, -3.4327e-02,  8.8243e-03, -9.7521e-02,\n",
      "           3.0874e-01,  3.0074e-02,  1.2639e-01, -1.6018e-01, -1.4893e-01,\n",
      "           6.6325e-02, -2.5478e-01, -1.5356e-01,  4.2658e-02, -5.1168e-02,\n",
      "          -9.3248e-02, -1.5961e-01, -2.5388e-01,  2.7457e-01,  1.2861e-01,\n",
      "          -2.0810e-01,  2.4299e-02,  2.4436e-01, -8.3562e-02, -3.1714e-02,\n",
      "          -2.7425e-01, -9.6359e-02,  1.6008e-01,  1.7873e-01, -1.3489e-01,\n",
      "          -1.2660e-01, -9.5311e-02, -6.3519e-03,  1.1977e-01,  1.8681e-01,\n",
      "           2.8067e-02, -3.8824e-02, -4.7682e-02, -9.3405e-02, -2.0221e-01,\n",
      "           1.1014e-01, -3.4902e-02, -2.4225e-01, -7.1863e-02, -1.0173e-02,\n",
      "          -2.0811e-01, -1.6059e-02, -3.8405e-03,  5.8791e-03, -1.1395e-01,\n",
      "          -1.4416e-01,  3.3840e-02, -3.4311e-02, -5.7074e-02, -4.6893e-02,\n",
      "           1.1821e-01, -2.4272e-01,  1.6253e-01,  2.9158e-01, -2.0351e-01,\n",
      "          -6.8863e-02, -1.1896e-01, -3.0059e-02,  1.3167e-02, -2.5375e-01,\n",
      "           7.1310e-02, -2.1700e-02, -5.4026e-02, -3.3808e-02,  5.4203e-02,\n",
      "           1.1733e-01, -2.7072e-02,  6.0307e-02,  3.5942e-02, -9.8292e-02,\n",
      "           3.5386e-02, -2.6121e-02, -6.1675e-02, -2.9784e-01,  2.8950e-02,\n",
      "          -1.0055e-01, -7.9100e-02,  2.7766e-02, -1.7672e-02,  1.9070e-02,\n",
      "           6.7862e-02, -1.8255e-01, -1.0055e-02,  3.0599e-01,  7.1191e-02,\n",
      "          -1.0294e-01, -3.8022e-02, -9.1297e-03, -4.3858e-02,  8.8246e-02,\n",
      "          -3.0227e-01, -1.6672e-01, -1.1877e-01,  1.3066e-01, -4.1707e-02,\n",
      "           1.7431e-01, -5.3327e-02, -1.3417e-01, -1.5069e-01,  6.1663e-03,\n",
      "          -2.2489e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6335e-02,  0.0000e+00, -9.6587e-01, -6.8128e-01,  3.7588e-01,\n",
      "          -2.0195e-01,  1.4648e+00, -8.3386e-02, -3.5842e+00,  9.0660e-01,\n",
      "           4.2824e-01, -6.2908e-01,  2.6038e+00,  0.0000e+00, -5.4142e-01,\n",
      "          -1.5796e-01,  0.0000e+00,  1.0948e+00,  4.5516e-01,  4.3610e-01,\n",
      "          -6.3339e-01, -3.8293e-01,  1.6410e+00,  1.5109e+00,  7.5348e-01,\n",
      "          -7.5691e-02, -1.8791e-01, -7.5920e-01,  1.6536e+00,  8.6151e-01,\n",
      "           1.2317e+00,  1.2190e+00, -1.0342e+00, -8.2757e-02, -1.5344e+00,\n",
      "           1.3953e+00,  2.8095e-01, -3.7446e+00,  1.9789e-01,  1.6007e+00,\n",
      "          -4.5882e-01, -1.3981e+00, -2.6854e-01, -1.7154e+00, -1.5240e+00,\n",
      "           6.6746e-01,  5.4087e-01,  3.7079e-01, -1.3406e+00,  1.4423e-01,\n",
      "          -6.2929e-01,  2.7519e+00,  6.1028e-01,  0.0000e+00, -2.5384e-02,\n",
      "           2.0342e-01, -8.8180e-01, -1.2521e+00, -2.3697e-01, -4.2553e-01,\n",
      "           1.1002e+00,  0.0000e+00, -2.0289e-01, -5.0138e-01, -2.9635e+00,\n",
      "           5.5095e-01,  1.2786e+00, -1.2877e+00,  4.1096e-01,  5.2658e-01,\n",
      "          -1.2668e+00, -3.0070e-02,  7.0737e-01, -3.6408e+00,  3.2575e-01,\n",
      "          -1.4637e-03, -1.6001e-01,  1.0623e+00, -5.7994e-02, -1.1923e-01,\n",
      "          -1.4002e+00,  0.0000e+00, -9.2454e-01,  1.0059e+00, -2.0771e-01,\n",
      "           4.3531e-01,  1.6616e+00, -9.7409e-01, -1.0384e-01, -5.8134e-01,\n",
      "          -2.2731e+00,  1.1002e+00, -6.2237e-01, -1.1355e+00,  4.6728e-01,\n",
      "          -1.1705e+00,  3.3857e-02,  0.0000e+00,  0.0000e+00, -7.7955e-01,\n",
      "           2.6971e+00, -1.4621e+00,  1.0760e+00,  1.4535e+00, -6.6629e-01,\n",
      "          -7.6246e-01,  1.2119e+00,  1.2717e-01, -1.4730e+00, -1.3468e-02,\n",
      "          -2.4852e-01,  1.3427e-01, -1.0478e+00,  1.3100e+00, -1.6530e+00,\n",
      "          -2.9890e+00, -5.6521e-02, -5.0037e-01, -1.9334e-01,  4.4515e-01,\n",
      "          -1.4658e+00,  7.0217e-01, -1.4604e+00,  0.0000e+00, -9.5837e-01,\n",
      "          -1.3086e+00,  8.9671e-01,  1.6987e-01,  1.2850e+00, -7.5184e-01,\n",
      "          -8.2367e-01,  5.3016e-01, -1.5830e+00,  9.8400e-01,  2.7602e-01,\n",
      "          -5.8944e-01,  6.5924e-01,  5.7466e-01, -1.1587e+00, -1.0098e+00,\n",
      "          -3.8853e-01,  6.7782e-01, -7.8982e-01, -1.0115e-01, -1.6854e+00,\n",
      "          -1.0081e-01, -5.4313e-01, -8.4435e-01,  0.0000e+00,  1.7753e-01,\n",
      "           1.9984e+00, -1.9951e-01,  0.0000e+00, -4.0610e-01,  4.4147e-01,\n",
      "          -1.9447e-01, -6.4483e-02, -1.2957e-01,  0.0000e+00,  5.3757e-01,\n",
      "          -2.6475e-02,  2.2063e+00,  0.0000e+00, -5.5000e-01,  0.0000e+00,\n",
      "          -8.9203e-01,  2.8156e-01,  8.3642e-02,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -3.1460e-02,  2.0073e-02, -1.0020e+00,  1.2777e+00,\n",
      "          -1.0983e+00, -9.8678e-01, -2.0765e+00,  1.9688e+00,  8.6539e-02,\n",
      "          -3.0489e-02,  3.5086e-02,  6.7111e-01,  9.7986e-01, -7.4708e-01,\n",
      "          -3.4090e-01, -2.7826e+00,  0.0000e+00,  1.2094e+00,  1.0124e+00,\n",
      "           3.0737e+00,  4.9425e-01, -1.4436e-01, -5.9381e-01,  0.0000e+00,\n",
      "           2.1648e+00, -1.1877e+00,  5.3502e-01,  1.8113e+00, -9.4667e-01,\n",
      "          -1.6624e+00,  0.0000e+00,  1.2419e+00, -1.2217e-01,  2.3201e-01,\n",
      "          -5.7497e-01, -2.2925e+00,  6.8167e-01, -1.0740e+00, -4.7109e-01,\n",
      "           2.8678e+00, -5.7334e-01, -3.4109e-01,  7.9304e-01,  3.0476e-02,\n",
      "          -6.8403e-01, -1.0185e+00,  9.6642e-01, -2.4550e-01,  2.1690e+00,\n",
      "          -1.0827e+00, -4.2712e-01, -1.8436e+00, -5.0072e-01,  3.3815e-01,\n",
      "           7.0489e-01, -6.9655e-01, -6.2819e-01,  2.9229e-01,  0.0000e+00,\n",
      "          -1.1085e+00,  1.5813e+00, -6.1398e-01,  1.3098e+00, -2.9796e+00,\n",
      "           4.0348e+00,  5.8523e-01,  4.3365e-02, -1.5795e+00, -2.8672e-01,\n",
      "           7.4183e-01, -3.2480e+00, -3.0418e-01, -8.5210e-01,  0.0000e+00,\n",
      "           2.7545e-01,  2.7471e-01,  2.5242e-01,  2.6125e-01,  3.8653e-01,\n",
      "          -3.6564e-01, -1.5908e-01, -5.5382e-01, -5.2547e-02, -1.1466e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0481, 0.0564, 0.0978, 0.0708, 0.1514, 0.2694, 0.0562, 0.0922, 0.0641,\n",
      "         0.0937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-7.0781e-02, -7.1968e-02,  6.3391e-02,  2.3192e-01, -2.3066e-01,\n",
      "          -9.4955e-02,  4.7236e-02,  6.9076e-02, -4.4107e-02, -1.6257e-01,\n",
      "           1.7755e-01, -4.8839e-02, -1.0053e-01,  4.3105e-02,  1.1766e-01,\n",
      "          -1.6074e-01, -1.5326e-01,  1.4745e-01, -2.6624e-01,  1.1416e-01,\n",
      "          -2.5336e-01, -1.4356e-01, -8.3167e-03,  1.2413e-01, -7.4844e-02,\n",
      "           1.4606e-01, -1.0950e-01,  8.1846e-02, -2.7051e-02, -8.1673e-02,\n",
      "           3.6733e-02, -1.7509e-01,  4.4830e-02, -2.5726e-01, -9.2872e-02,\n",
      "          -7.7345e-02,  1.7017e-02, -1.3307e-01,  3.4729e-02, -1.3161e-01,\n",
      "           2.0984e-01,  3.8910e-03, -3.9432e-02, -1.7888e-02,  5.1152e-02,\n",
      "           1.2802e-01, -2.0724e-02, -2.6926e-01,  1.1168e-01,  1.1797e-01,\n",
      "          -2.1444e-01, -2.8792e-01, -3.2147e-01, -1.6734e-02, -1.4584e-01,\n",
      "          -2.8173e-01, -1.4128e-01, -6.3746e-02,  2.6341e-02, -8.6733e-02,\n",
      "           5.9792e-02, -6.6091e-02, -2.5898e-01,  1.5995e-01,  4.6368e-02,\n",
      "           1.9257e-02,  2.2726e-02,  3.9336e-01, -4.1575e-02,  2.2581e-01,\n",
      "           3.9817e-01,  9.2349e-02, -1.3366e-01, -1.1323e-01, -1.2729e-01,\n",
      "          -4.5002e-02,  2.7123e-01,  1.7085e-01, -1.3401e-01,  1.3436e-01,\n",
      "          -5.8723e-02, -1.2604e-01, -1.1380e-02,  9.7917e-03, -8.4497e-03,\n",
      "          -3.2483e-02,  1.6351e-01,  2.9042e-01,  2.0217e-02, -1.7252e-01,\n",
      "          -8.9786e-02,  9.9733e-02,  1.4868e-02, -1.0488e-01, -2.9585e-01,\n",
      "           2.6688e-01,  6.0069e-02,  4.4598e-02,  2.8183e-01,  2.7361e-02,\n",
      "          -1.3484e-01, -6.8179e-02,  1.8744e-01,  9.4834e-03,  9.4851e-04,\n",
      "          -3.2680e-02,  1.4182e-01,  1.8344e-01,  6.0380e-02,  2.5275e-01,\n",
      "           8.1188e-02,  1.2686e-02,  5.3102e-02,  5.6370e-02,  4.0844e-02,\n",
      "          -1.2663e-01, -2.3274e-01, -5.2076e-02, -2.8550e-01, -3.4749e-01,\n",
      "           2.8906e-03, -1.3431e-02, -1.4524e-01, -4.4694e-02, -2.3488e-01,\n",
      "          -9.1207e-02, -4.3025e-02, -1.9169e-01,  1.1116e-02, -1.6706e-01,\n",
      "           8.8030e-02, -2.4505e-02, -1.1834e-01, -8.8380e-03, -3.0432e-01,\n",
      "           1.1162e-01,  8.6940e-02, -2.6547e-02, -1.2302e-01,  1.4759e-01,\n",
      "          -1.1723e-01,  2.6979e-01, -1.2824e-01,  2.0042e-01,  8.4949e-02,\n",
      "           1.8413e-01,  5.3435e-03, -3.4398e-02,  9.8709e-02,  1.8652e-01,\n",
      "           1.6331e-01,  1.2858e-01, -1.4707e-02,  4.8124e-02, -2.0978e-01,\n",
      "           5.0536e-02, -1.8049e-01,  1.5722e-01, -2.6155e-01,  1.1291e-01,\n",
      "          -1.9881e-01,  1.6866e-01,  2.8145e-02,  1.5172e-01,  7.7453e-02,\n",
      "           7.5536e-02,  1.0661e-01, -3.5299e-01,  2.1133e-01,  4.0056e-02,\n",
      "          -1.2236e-01,  6.6277e-03, -8.8823e-02, -1.1698e-01,  1.9908e-01,\n",
      "           2.4418e-02,  4.0884e-02,  1.0080e-01, -9.6137e-02,  1.0632e-01,\n",
      "          -2.0408e-01, -8.3411e-02,  3.6020e-02, -1.5490e-01,  2.6716e-01,\n",
      "           7.2726e-02, -1.6968e-01,  1.8317e-01,  7.3209e-02, -3.0034e-02,\n",
      "          -1.9541e-01,  7.3266e-02,  2.2367e-02, -2.1932e-01,  1.0744e-02,\n",
      "          -3.4525e-01,  1.5310e-01, -6.6975e-02, -1.0587e-01, -5.3817e-02,\n",
      "          -5.3275e-02,  1.2885e-01, -7.3368e-02, -1.4531e-01,  5.7669e-02,\n",
      "           9.4304e-03,  1.9051e-01,  1.0416e-01, -2.7407e-02, -1.6182e-01,\n",
      "          -1.3667e-01, -9.6285e-03, -4.1471e-02,  8.5470e-02, -1.3663e-01,\n",
      "           2.2169e-01, -1.9779e-01,  3.8706e-01,  1.2276e-02,  1.5127e-01,\n",
      "          -1.0524e-01, -9.5431e-02,  1.5152e-01,  1.7087e-04, -7.8955e-02,\n",
      "          -8.0439e-02, -1.3918e-01, -1.4756e-01, -1.0015e-02, -5.3764e-02,\n",
      "          -4.4756e-02, -1.3510e-01, -2.7335e-01, -1.9920e-01, -3.0479e-01,\n",
      "           4.0549e-02, -1.7755e-01,  9.4005e-02,  3.4240e-01,  1.4976e-01,\n",
      "          -9.8718e-02, -3.3921e-01, -1.8543e-01, -6.5026e-02, -1.0022e-01,\n",
      "          -1.0568e-01, -1.0181e-01, -1.2589e-01, -8.5442e-02,  2.9477e-02,\n",
      "           5.8156e-02, -1.1097e-01, -1.5114e-02,  3.2724e-01,  8.0263e-02,\n",
      "           1.8281e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0448,  1.2545, -0.4664,  1.7171,  2.1264, -0.2519, -0.9079,\n",
      "          -0.0988,  1.1704, -2.1523,  0.0000, -1.1158, -2.9079,  0.3782,\n",
      "           2.3037,  0.7979, -0.4095, -0.6149, -0.2805,  0.1081,  0.1244,\n",
      "           0.2528, -0.6048,  0.6489,  0.8123, -0.0134, -0.9921, -1.4426,\n",
      "           0.7556,  1.0295,  2.7912,  0.1369, -1.2161, -1.0195,  0.0882,\n",
      "          -0.0185,  0.0000,  0.2673,  0.6425,  0.0000, -0.2679, -0.9844,\n",
      "           0.1589, -0.2240,  1.0191, -0.3816, -0.5498, -2.1849, -2.1085,\n",
      "           0.4286,  2.3789, -1.0152,  0.4625,  0.4323, -2.0464,  0.6875,\n",
      "          -0.5578, -0.1242,  0.0000,  1.5115,  0.3692, -0.7990, -0.3514,\n",
      "          -0.4275,  0.1153, -1.0634,  1.2921, -1.1347, -1.4301,  0.7686,\n",
      "           0.7184, -0.2438, -0.7987, -0.4705, -1.2764,  0.6311,  0.2606,\n",
      "           0.1704, -1.4212, -2.2302,  1.6304,  0.1554,  1.0573, -0.0068,\n",
      "           1.0074,  1.7522, -0.5065,  0.2261,  0.0000,  0.0145,  0.8279,\n",
      "           0.6210, -0.3062, -2.0888, -0.1636,  0.7981,  0.9418,  0.3354,\n",
      "          -1.9783,  0.6224,  1.2574,  1.1965, -0.5282, -0.4683,  0.5846,\n",
      "           0.0000,  2.2056, -0.4719, -1.7298, -0.1462, -1.2139, -1.7617,\n",
      "           0.1692, -0.7762,  0.0000,  0.5293, -0.6108, -0.9200, -1.9304,\n",
      "           0.5734,  0.6994, -1.1987,  0.0000, -0.2661,  0.8870, -0.7541,\n",
      "           1.0484,  2.0804, -1.2003, -2.0670, -1.1239, -0.2626,  1.2994,\n",
      "          -0.7233, -1.7858, -2.8104,  0.0000,  0.0000, -0.7178,  0.1088,\n",
      "           1.0378, -1.4279, -1.6466,  1.4238,  2.6917,  0.7387,  1.2630,\n",
      "           3.2325,  0.0000,  1.2100, -0.6048, -1.7824, -0.0645,  0.0000,\n",
      "          -0.1897, -0.7710,  0.3756,  0.6387,  1.3777,  0.2800, -0.1719,\n",
      "          -1.0612, -1.4685,  0.4448,  0.4867, -0.2785,  0.0333, -1.9414,\n",
      "          -0.2388, -1.4670,  0.5140,  1.3974,  0.5181, -0.8871,  1.1624,\n",
      "           1.5167, -0.3158, -0.0257,  0.4780, -0.3760,  0.4144, -0.3533,\n",
      "           0.9599,  0.3760,  1.9494, -1.7204, -1.0730, -0.1613,  0.7116,\n",
      "           0.0965, -0.7705, -1.2738,  0.7383,  0.0000,  0.3841, -1.2636,\n",
      "           2.8157, -0.4362,  0.6855,  0.0000,  0.0000, -1.0701,  0.9878,\n",
      "          -0.5556, -0.1357, -2.0008,  0.2932,  0.0000,  1.2635,  2.1705,\n",
      "           0.3261,  0.6177, -0.7075, -0.5392,  0.5764,  0.0000, -2.6898,\n",
      "          -0.0533, -1.5536, -1.1537,  1.3688,  0.0946, -0.7013,  2.1901,\n",
      "           0.0000, -0.6011,  0.6134, -0.2504,  1.7970,  1.2116,  0.4037,\n",
      "           0.0848, -0.0391,  0.5898,  0.9646, -1.0874,  1.6294, -1.3610,\n",
      "          -0.0792, -0.5930,  2.6465, -1.0669, -0.0633,  1.1017,  1.1765,\n",
      "           0.1781, -0.0546, -0.2370,  0.0000,  1.2425, -1.8118, -0.0663,\n",
      "          -1.0721, -1.6390,  0.0000, -0.5374]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0383, 0.1798, 0.0760, 0.0909, 0.0828, 0.0617, 0.2055, 0.0873, 0.1293,\n",
      "         0.0484]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 4.3947e-02, -2.7008e-02, -2.6635e-02,  8.0259e-02, -2.6272e-01,\n",
      "          -1.4523e-01,  4.4200e-03, -1.5073e-02, -5.5078e-02, -2.0181e-01,\n",
      "           1.2910e-01, -4.9728e-02, -1.7621e-01,  5.2479e-02,  1.3761e-01,\n",
      "          -1.4540e-01, -1.7193e-01,  1.1925e-01, -2.2101e-01,  6.6116e-03,\n",
      "          -2.0982e-01, -1.0767e-01,  4.1278e-02,  1.4000e-01, -9.6456e-02,\n",
      "           1.6499e-01, -6.0712e-03,  1.8324e-02, -4.1396e-03, -9.0982e-02,\n",
      "           1.1959e-01, -8.3165e-02,  4.9033e-02, -2.5746e-01, -2.1395e-01,\n",
      "          -2.5750e-02, -9.0205e-02, -7.2012e-02, -2.4650e-02, -5.3240e-02,\n",
      "           1.3266e-01,  2.3963e-02, -1.1483e-01, -9.6649e-02, -5.7249e-02,\n",
      "           1.4663e-01, -7.9281e-03, -2.3438e-01,  6.0161e-02,  7.1544e-02,\n",
      "          -1.7593e-01, -1.7033e-01, -2.4501e-01, -4.8990e-02, -1.0531e-01,\n",
      "          -2.1041e-01, -9.9808e-02, -9.0081e-03,  6.8335e-02, -5.7714e-02,\n",
      "           9.3103e-03, -1.3083e-01, -2.1642e-01,  1.9812e-01, -7.0422e-02,\n",
      "          -2.9819e-02,  1.4091e-02,  4.1094e-01, -1.2779e-01,  2.5961e-01,\n",
      "           3.7478e-01,  1.9107e-01, -5.9145e-02, -1.1884e-01, -7.0402e-02,\n",
      "           8.5223e-02,  3.1618e-01,  1.0684e-01, -7.9926e-02,  1.5244e-01,\n",
      "           3.3944e-02, -5.3979e-02, -1.2968e-01,  6.6192e-02,  6.1561e-02,\n",
      "          -6.6391e-02,  2.1567e-01,  2.7976e-01,  7.4149e-02, -1.3270e-01,\n",
      "          -3.9523e-02, -8.8937e-03, -1.2457e-02, -1.5478e-01, -2.7823e-01,\n",
      "           2.9348e-01,  7.4154e-02,  7.0140e-02,  2.3160e-01,  1.5681e-01,\n",
      "          -4.8457e-02,  2.2309e-02,  1.2223e-01, -4.3020e-02,  6.3944e-02,\n",
      "          -2.2211e-02,  1.2737e-01,  2.3339e-01,  7.2203e-02,  1.9657e-01,\n",
      "           7.9976e-02,  1.0596e-01,  1.3280e-04, -2.6211e-02,  4.3567e-02,\n",
      "          -1.5570e-03, -1.4952e-01, -5.4835e-02, -2.8512e-01, -2.4245e-01,\n",
      "           2.9002e-02,  1.0433e-02, -3.0041e-01, -1.3041e-02, -2.9698e-01,\n",
      "          -4.0276e-02, -5.4539e-02, -2.3266e-01,  8.7015e-02, -1.6788e-01,\n",
      "           1.1761e-01, -6.2375e-03, -1.0261e-01,  2.8917e-02, -1.7072e-01,\n",
      "           4.1049e-02,  7.5835e-03,  5.5452e-03, -6.6183e-02,  1.7666e-01,\n",
      "          -1.9889e-01,  1.8213e-01, -1.6556e-01,  1.6358e-01,  4.0427e-02,\n",
      "           1.0089e-01,  9.6561e-02,  1.0097e-01,  1.5250e-01,  1.8994e-01,\n",
      "          -3.7390e-02,  1.3981e-01, -9.1931e-02,  7.2498e-02, -8.1398e-02,\n",
      "           1.5042e-01, -9.5050e-02,  1.5345e-01, -2.0578e-01,  9.1858e-02,\n",
      "          -9.7116e-02,  7.6630e-02, -1.9650e-01,  1.7940e-01, -3.4119e-02,\n",
      "          -1.3125e-02,  8.4989e-02, -2.7221e-01,  1.8896e-01, -1.8850e-02,\n",
      "          -1.5145e-01,  2.2360e-03, -8.1814e-02, -7.5753e-02,  9.5585e-02,\n",
      "           6.1382e-02,  4.5303e-02,  8.4854e-02,  2.3786e-02,  6.5444e-02,\n",
      "          -2.6231e-01, -9.7930e-02, -5.8100e-02, -4.6690e-02,  2.8209e-01,\n",
      "           1.0966e-01, -1.5363e-01,  1.1935e-01,  2.4470e-02, -7.9960e-02,\n",
      "          -7.7553e-02,  1.1520e-01, -9.4230e-02, -1.8760e-01,  4.8109e-03,\n",
      "          -3.5263e-01,  1.9700e-01,  3.6616e-03, -1.4714e-01,  1.5741e-02,\n",
      "          -1.9314e-02,  9.8753e-02, -6.8505e-02, -1.3509e-01,  2.3270e-02,\n",
      "           3.9987e-03,  5.4997e-02,  2.6459e-01, -6.8431e-02, -2.0697e-01,\n",
      "          -1.4676e-01, -4.5860e-02,  6.0746e-03,  1.1546e-01, -4.8852e-02,\n",
      "           2.0621e-01, -8.5469e-02,  3.1808e-01, -8.9466e-02,  1.2035e-01,\n",
      "           9.3749e-02, -3.1257e-02,  1.0455e-01,  2.6840e-03, -2.8987e-02,\n",
      "          -3.6837e-02, -1.6352e-01, -1.4824e-01, -1.1974e-01, -1.1226e-01,\n",
      "          -4.7770e-02, -1.0285e-01, -1.7657e-01, -1.6992e-01, -2.9393e-01,\n",
      "          -2.4971e-02, -2.3982e-01,  6.2774e-02,  2.9351e-01,  9.5495e-02,\n",
      "          -9.1068e-02, -2.7136e-01, -1.6581e-01,  3.0049e-02, -3.7466e-02,\n",
      "          -1.4004e-01, -1.2118e-01, -1.6164e-01, -1.9195e-02, -9.7167e-02,\n",
      "           9.6878e-02, -9.3050e-02, -5.5441e-02,  2.0601e-01,  1.9609e-01,\n",
      "           1.6711e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.0941e+00, -1.6148e-01,  3.7312e-01, -9.3212e-02,  7.0852e-01,\n",
      "           9.5505e-01,  6.0218e-01, -3.0259e-01,  0.0000e+00,  3.9726e-01,\n",
      "           1.0981e+00,  6.6504e-02, -6.7433e-01,  0.0000e+00, -6.1262e-01,\n",
      "           1.0059e+00, -3.3610e-01,  5.9728e-01,  3.3618e-01, -1.3971e+00,\n",
      "           0.0000e+00,  1.1742e-01,  3.5575e-01,  0.0000e+00, -9.2417e-01,\n",
      "          -9.8039e-01,  3.3723e-01,  5.0702e-01, -1.9476e-01,  8.5844e-01,\n",
      "          -6.9879e-01,  1.0668e-01, -6.2908e-01, -2.1699e-01,  2.1033e-01,\n",
      "          -9.2812e-03, -4.4823e-01, -1.3333e+00,  1.4292e+00,  1.1821e+00,\n",
      "          -3.2114e+00,  3.1793e-01,  3.1247e-01, -1.1646e-01, -1.7016e+00,\n",
      "          -7.1016e-01,  3.8430e-01, -1.1723e+00,  2.0965e+00,  5.1757e-01,\n",
      "           1.8875e+00, -1.1039e+00,  1.1981e-02,  1.0407e-01,  7.3069e-01,\n",
      "           0.0000e+00, -1.3007e-01, -1.7411e-01,  0.0000e+00,  1.5828e+00,\n",
      "           2.8703e-01,  0.0000e+00, -5.3504e-01, -1.4271e+00, -1.7302e+00,\n",
      "          -1.0931e+00, -1.0572e+00,  1.5331e+00, -9.7603e-01, -2.8618e+00,\n",
      "          -8.7952e-01,  6.2378e-01,  6.3045e-01,  6.8975e-01,  8.2704e-01,\n",
      "           7.2561e-01,  0.0000e+00, -6.8600e-01,  9.9717e-01, -1.0547e+00,\n",
      "          -2.5653e+00,  1.7533e+00, -2.4382e-01,  0.0000e+00,  1.3148e-02,\n",
      "           7.6380e-01, -2.0535e+00,  4.7649e-01, -1.5655e+00,  0.0000e+00,\n",
      "           3.8671e-01,  2.2182e+00,  1.1675e+00,  3.6207e-01, -7.8862e-01,\n",
      "          -8.6318e-01,  1.1111e+00, -1.5580e+00, -4.7133e-01,  0.0000e+00,\n",
      "           2.5617e+00, -3.8748e-02,  0.0000e+00,  1.0134e+00, -1.6310e+00,\n",
      "          -2.8220e-01, -9.8942e-02, -7.3137e-02, -1.7932e+00, -1.2238e-01,\n",
      "          -2.1292e+00, -3.0129e-01,  8.0620e-01, -1.5057e+00,  1.7414e+00,\n",
      "           1.1383e+00, -5.6719e-01, -1.1109e-01,  1.7225e+00,  3.9725e-01,\n",
      "           0.0000e+00,  9.2988e-01,  1.3159e-01, -1.5971e-02, -9.5267e-01,\n",
      "           0.0000e+00,  1.3251e+00, -2.0541e+00, -6.3950e-01,  1.5838e+00,\n",
      "           2.5818e-02, -3.2781e-01,  1.8962e+00, -1.4202e-01,  0.0000e+00,\n",
      "          -1.5778e+00,  9.2483e-01,  0.0000e+00,  5.8590e-02, -6.0086e-01,\n",
      "          -1.3204e+00, -1.6197e+00, -2.6011e+00, -4.6931e-01,  1.1786e+00,\n",
      "           1.6322e+00,  2.6976e+00,  2.6488e-01,  2.3254e+00,  2.2877e-01,\n",
      "          -7.2623e-01, -3.7262e-01,  2.9953e-01,  4.8221e-01, -3.8973e-01,\n",
      "           6.4539e-01,  7.7853e-01, -2.0627e+00, -7.0192e-01,  0.0000e+00,\n",
      "          -1.0566e-01, -2.0278e-01,  5.9189e-01,  1.0008e+00,  4.4587e-01,\n",
      "          -6.3045e-03,  1.4759e-01,  4.8641e-01,  1.4363e+00,  0.0000e+00,\n",
      "          -1.0582e+00,  7.6201e-01,  8.7997e-01,  3.1007e-01,  4.7285e-01,\n",
      "          -4.0976e-01,  1.2830e-01, -5.8214e-01, -8.4127e-01,  6.7618e-01,\n",
      "          -5.4288e-01, -4.5110e-01, -1.5850e+00,  0.0000e+00, -2.6267e+00,\n",
      "          -1.4816e+00, -3.0928e+00,  1.2700e+00,  1.4648e-01,  2.0817e-01,\n",
      "          -2.2931e+00, -4.4145e-01,  2.2692e-01,  2.3420e-01, -5.8261e-01,\n",
      "           2.4112e-01, -1.6561e-01,  3.7293e-01, -6.3799e-01, -3.9394e-01,\n",
      "          -7.1965e-01,  1.0417e+00,  1.1622e+00, -1.1103e-01, -4.1134e-02,\n",
      "          -1.6270e+00,  1.7329e+00, -2.3601e-01, -5.5294e-01,  1.0347e+00,\n",
      "           6.0886e-01, -5.1561e-01,  5.3288e-02,  1.3250e+00, -1.3381e+00,\n",
      "           1.2872e-01, -1.7173e+00, -9.3611e-01,  4.2329e-02,  1.1060e+00,\n",
      "           2.0961e-01,  0.0000e+00,  0.0000e+00,  1.1007e+00,  0.0000e+00,\n",
      "           1.0811e+00, -2.3692e+00,  3.7845e-01, -3.6039e-01, -2.0453e-03,\n",
      "           1.9905e+00, -4.4548e-01, -1.7798e+00,  0.0000e+00, -1.8060e+00,\n",
      "          -1.9361e+00,  6.7363e-01, -1.1325e-01, -6.5185e-01,  8.8693e-01,\n",
      "           6.4459e-01,  2.6348e-01,  0.0000e+00,  2.4037e-01,  1.2993e+00,\n",
      "           7.2259e-01, -5.9338e-01,  1.7862e-01, -8.1850e-02, -2.4697e-02,\n",
      "          -1.5750e-01,  0.0000e+00, -9.0928e-01, -1.3063e+00,  8.9164e-01,\n",
      "          -6.9691e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0560, 0.1164, 0.0928, 0.0842, 0.1764, 0.1764, 0.0609, 0.0696, 0.1017,\n",
      "         0.0654]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0654, -0.0730,  0.0638,  0.1797, -0.2640, -0.0986,  0.0159,\n",
      "           0.0482, -0.0440, -0.1593,  0.1535, -0.0323, -0.1109,  0.0204,\n",
      "           0.1026, -0.1536, -0.1663,  0.1073, -0.2016,  0.0593, -0.2314,\n",
      "          -0.1046, -0.0340,  0.1297, -0.0799,  0.1789, -0.0994,  0.0692,\n",
      "          -0.0206, -0.1340,  0.0458, -0.1105,  0.0543, -0.2142, -0.1507,\n",
      "          -0.0412, -0.0195, -0.0802,  0.0639, -0.1348,  0.1999, -0.0029,\n",
      "          -0.0576, -0.0609,  0.0255,  0.1168,  0.0229, -0.2304,  0.0573,\n",
      "           0.0938, -0.1972, -0.2373, -0.2642, -0.0262, -0.1018, -0.2717,\n",
      "          -0.1434, -0.0303,  0.0447, -0.0830,  0.0492, -0.0838, -0.2099,\n",
      "           0.1592,  0.0208,  0.0079,  0.0560,  0.3825, -0.0615,  0.2183,\n",
      "           0.3905,  0.0866, -0.1237, -0.1555, -0.0425, -0.0047,  0.2766,\n",
      "           0.1249, -0.0990,  0.1194,  0.0241, -0.0975, -0.0295,  0.0133,\n",
      "           0.0379, -0.0658,  0.1917,  0.2770,  0.0031, -0.1750, -0.0877,\n",
      "           0.0268,  0.0429, -0.1446, -0.2815,  0.2674,  0.0519,  0.0372,\n",
      "           0.2459,  0.0525, -0.0865, -0.0826,  0.1687, -0.0348,  0.0341,\n",
      "           0.0023,  0.0811,  0.1566,  0.1149,  0.1882,  0.0987,  0.0261,\n",
      "           0.0150,  0.0653,  0.0754, -0.0911, -0.1920, -0.0545, -0.2557,\n",
      "          -0.2754,  0.0324,  0.0054, -0.1823, -0.0702, -0.2294, -0.0744,\n",
      "          -0.0498, -0.1962,  0.0230, -0.1425,  0.0999,  0.0464, -0.1330,\n",
      "          -0.0291, -0.2430,  0.0689, -0.0049, -0.0445, -0.1037,  0.1311,\n",
      "          -0.1318,  0.2021, -0.1132,  0.1887,  0.0480,  0.1626,  0.0650,\n",
      "           0.0024,  0.0965,  0.1664,  0.1605,  0.0913, -0.0536,  0.0099,\n",
      "          -0.1809,  0.0533, -0.1239,  0.1419, -0.2425,  0.1162, -0.1466,\n",
      "           0.1523, -0.0417,  0.1186,  0.0557,  0.0537,  0.1432, -0.3045,\n",
      "           0.1797,  0.0151, -0.1058,  0.0103, -0.1294, -0.1306,  0.1777,\n",
      "           0.0836,  0.0479,  0.0887, -0.1107,  0.1359, -0.2206, -0.0798,\n",
      "           0.0005, -0.1061,  0.2479,  0.1056, -0.1342,  0.1292,  0.0717,\n",
      "          -0.0370, -0.1460,  0.1028,  0.0134, -0.2160,  0.0017, -0.3390,\n",
      "           0.2019, -0.0522, -0.1003, -0.0166, -0.0337,  0.1081, -0.0645,\n",
      "          -0.1806,  0.0829,  0.0225,  0.1334,  0.1508, -0.0337, -0.1646,\n",
      "          -0.1250, -0.0030, -0.0237,  0.0704, -0.1048,  0.2026, -0.1341,\n",
      "           0.3406, -0.0182,  0.1331, -0.0458, -0.0723,  0.0992,  0.0187,\n",
      "          -0.0831, -0.0929, -0.1832, -0.1011,  0.0008, -0.0924, -0.0500,\n",
      "          -0.0904, -0.2106, -0.1555, -0.3346,  0.0169, -0.1757,  0.0648,\n",
      "           0.2995,  0.0991, -0.1059, -0.2870, -0.1789, -0.0295, -0.0908,\n",
      "          -0.1111, -0.0720, -0.1424, -0.0266, -0.0192,  0.0623, -0.0856,\n",
      "          -0.0239,  0.3153,  0.1200,  0.1874]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.7315,  0.8591, -1.2737,  0.0000,  0.0000,  0.0000, -1.8860,\n",
      "          -1.1839,  0.5316, -0.3752,  0.3807,  0.4263, -1.4058,  0.1973,\n",
      "          -0.5079, -1.1076, -0.9175,  1.0990, -0.3008, -1.4498, -1.4388,\n",
      "           2.5023,  0.1689,  0.0221,  0.0000,  1.8608, -1.1410, -0.8951,\n",
      "           0.2903, -0.2780, -1.7991, -2.0109,  0.8091,  0.0000,  0.5702,\n",
      "          -0.8483,  0.5375, -1.9855,  1.0501,  0.7903,  0.4772, -1.2014,\n",
      "          -0.0244,  1.5335,  0.1367,  0.7733,  0.1675,  0.0000, -0.3034,\n",
      "           0.0000, -1.8757, -1.1886, -0.5017,  0.0000,  0.1203,  1.3955,\n",
      "          -0.9595,  0.0000,  1.7547,  0.0620,  0.2481, -0.1466,  0.0039,\n",
      "           0.0000,  0.4816,  0.3277,  0.7942, -0.4779,  0.0000, -0.9591,\n",
      "          -0.2922,  0.6091, -1.2976, -0.2897,  0.7924,  2.8415, -0.2556,\n",
      "          -0.3241,  0.5026,  0.8645, -1.0859,  0.0087,  0.1980,  0.2852,\n",
      "          -0.1342, -1.0848,  0.7429,  2.0083, -1.3032,  0.7864,  1.4279,\n",
      "           0.5902, -2.3325,  2.2005, -2.1353, -0.5408,  2.4308,  2.0342,\n",
      "           0.0000, -0.0199, -0.4548,  0.0000,  0.0000, -0.3369,  1.3427,\n",
      "           0.0276, -0.5961, -0.5311,  1.1933, -0.6048,  2.5355,  1.0109,\n",
      "           0.4604, -0.4224,  0.4384,  0.0000, -0.1147,  1.5981,  1.3911,\n",
      "          -0.5749,  0.8981,  0.7941,  1.5577,  0.7732, -0.9116, -0.1628,\n",
      "          -1.2574, -0.1381, -1.7151, -1.0619,  0.1848, -0.3668,  0.5866,\n",
      "          -0.4033, -2.1022,  0.2152,  0.0000, -1.5809, -1.8716, -0.6525,\n",
      "           0.0000,  0.0494, -1.5815, -0.2034,  1.0809, -0.2738, -0.9171,\n",
      "          -1.1321, -0.8197,  0.0000, -2.2552,  0.0000, -0.7642,  0.2076,\n",
      "           0.1228, -1.2039, -0.7379,  1.0693,  1.4065, -0.4237, -0.5212,\n",
      "          -0.6938, -1.3419, -0.0150, -1.5043,  0.6024,  0.9552, -0.3439,\n",
      "          -0.8953, -1.3750, -1.6809,  1.1510,  0.8769, -1.3913, -0.1136,\n",
      "           0.2668,  0.6518,  0.6702,  0.4416, -0.0699, -0.9450, -2.4648,\n",
      "           0.4151, -0.7623,  0.0000,  0.6063,  0.2457, -1.1533, -0.1242,\n",
      "           1.3496, -0.4984,  1.5484,  0.6113, -1.3684,  0.5221,  0.0000,\n",
      "           1.7645, -1.2045,  0.9878,  0.0000, -1.8759,  0.2171,  0.0000,\n",
      "          -0.3905, -0.4577, -1.2371, -0.0436,  0.9469, -0.5009,  0.1602,\n",
      "          -0.4577,  0.4758,  0.0000, -0.6525, -0.4570,  0.1797,  0.4974,\n",
      "           1.2329,  0.9487,  1.1346, -1.4537,  0.9314,  0.0000,  0.7155,\n",
      "          -1.0203,  1.6915, -2.3353, -0.0890,  0.8177,  0.0000,  0.4547,\n",
      "           1.4997,  0.0000,  0.8754,  0.4395,  3.1256,  0.1522,  2.0241,\n",
      "           0.0160, -0.5074,  0.9338, -1.8914,  0.1119, -1.0173, -1.2372,\n",
      "          -0.3379,  0.2116,  0.5994, -0.7856,  1.2067, -2.1742,  0.0314,\n",
      "          -0.5497,  0.0000, -0.0074, -1.6806]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0509, 0.0715, 0.2062, 0.1623, 0.0717, 0.0963, 0.0809, 0.0997, 0.0929,\n",
      "         0.0677]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0325, -0.0645,  0.0086,  0.1025, -0.3660, -0.1252,  0.0511,\n",
      "          -0.0063, -0.0283, -0.1902,  0.1361,  0.0485, -0.1201,  0.0110,\n",
      "           0.1494, -0.0801, -0.1315,  0.0292, -0.1220,  0.0135, -0.1995,\n",
      "          -0.1038, -0.0300,  0.1159, -0.0957,  0.2128, -0.0617,  0.1143,\n",
      "           0.0122, -0.0919,  0.0343, -0.0831,  0.0050, -0.1825, -0.2648,\n",
      "          -0.0312, -0.0215, -0.0888,  0.0528, -0.0772,  0.1623,  0.0258,\n",
      "          -0.1132, -0.0686, -0.0304,  0.1566,  0.0401, -0.2266,  0.0193,\n",
      "           0.0478, -0.1540, -0.1745, -0.1753, -0.0126, -0.0387, -0.2888,\n",
      "          -0.0812,  0.0238,  0.1525, -0.0103,  0.0495, -0.0857, -0.2224,\n",
      "           0.1672, -0.0467, -0.0266,  0.1098,  0.3976, -0.0873,  0.2284,\n",
      "           0.3937,  0.1933, -0.1466, -0.1544, -0.0016,  0.0282,  0.3013,\n",
      "           0.0874, -0.1340,  0.1290,  0.0461, -0.1723, -0.1363,  0.0377,\n",
      "           0.0960, -0.0565,  0.2024,  0.2750, -0.0038, -0.1944, -0.0252,\n",
      "           0.0107,  0.0112, -0.1681, -0.2450,  0.1740,  0.1248,  0.0831,\n",
      "           0.2037,  0.1314, -0.0700, -0.1095,  0.1263, -0.0603,  0.0187,\n",
      "          -0.0846,  0.1018,  0.1556,  0.1332,  0.1368,  0.0857,  0.0187,\n",
      "          -0.0253, -0.0169,  0.0799, -0.0341, -0.1731, -0.0462, -0.2040,\n",
      "          -0.2517,  0.1127, -0.0023, -0.2861, -0.0954, -0.2228, -0.0901,\n",
      "          -0.0683, -0.2390,  0.0287, -0.1873,  0.1186,  0.0910, -0.1483,\n",
      "          -0.0194, -0.2380,  0.0598, -0.0231, -0.0341, -0.1335,  0.1777,\n",
      "          -0.1845,  0.1925, -0.1297,  0.2580,  0.1471,  0.1372,  0.1070,\n",
      "           0.0629,  0.0745,  0.1696,  0.1257,  0.1581, -0.1326,  0.0412,\n",
      "          -0.1403,  0.0646, -0.1543,  0.1535, -0.1601,  0.1122, -0.0826,\n",
      "           0.1024, -0.1735,  0.1519,  0.1314,  0.0725,  0.1159, -0.2786,\n",
      "           0.1656,  0.0107, -0.1504, -0.0043, -0.1704, -0.1571,  0.0456,\n",
      "           0.1650,  0.0458,  0.0818, -0.1637,  0.1686, -0.2231, -0.2151,\n",
      "          -0.0671, -0.0631,  0.2588,  0.1371, -0.1995,  0.1149,  0.1262,\n",
      "          -0.0552, -0.1388,  0.1407, -0.0126, -0.1949,  0.0157, -0.3571,\n",
      "           0.1379, -0.0569, -0.1385,  0.0173, -0.0524,  0.0608, -0.0043,\n",
      "          -0.2287,  0.0814, -0.0102,  0.1501,  0.2167, -0.1043, -0.1637,\n",
      "          -0.1070,  0.0164,  0.0097,  0.0709, -0.0414,  0.0782, -0.0578,\n",
      "           0.3041, -0.1071,  0.0982,  0.0233, -0.0790,  0.1107, -0.0193,\n",
      "          -0.0728, -0.0503, -0.1980, -0.1731, -0.0333, -0.1682, -0.0824,\n",
      "          -0.0867, -0.2187, -0.1536, -0.3654, -0.0384, -0.2236,  0.0715,\n",
      "           0.3204, -0.0071, -0.1481, -0.2883, -0.1864,  0.0111,  0.0061,\n",
      "          -0.1040, -0.0500, -0.1609,  0.0523, -0.0033,  0.0563, -0.0068,\n",
      "          -0.1050,  0.2741,  0.1341,  0.2342]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0894, -0.4686,  0.0000, -0.9866,  0.0000,  1.2545, -1.2219,\n",
      "          -1.2619, -0.2124, -0.1739,  0.2412, -0.0862,  0.3217, -0.5951,\n",
      "          -0.5344, -1.0308,  0.8779,  2.1059, -3.1555,  0.0000,  1.0514,\n",
      "          -0.5662,  0.0840,  1.1032,  1.1321,  3.2021,  0.0000, -1.6348,\n",
      "           1.4029, -0.0366, -1.2997,  0.3688, -0.5141,  0.6222,  0.1127,\n",
      "          -1.0811, -0.5986, -1.9710, -1.6372, -0.8935,  0.4659,  0.5986,\n",
      "          -0.5677,  1.3730,  1.9337,  0.5705,  0.3884,  0.0000,  0.4735,\n",
      "           1.1799, -0.0509,  0.0000,  0.0000,  1.3422, -2.1598, -0.4959,\n",
      "           0.6033,  0.5633,  1.4366,  0.8019,  0.0000,  0.9264,  0.7506,\n",
      "          -0.1943, -1.2749, -0.0447,  0.4540, -0.7029, -1.1017,  0.8467,\n",
      "          -1.3463,  0.0000, -0.6281,  0.5921,  2.6140, -1.3754,  1.6930,\n",
      "           0.0000, -0.0676, -1.9558,  0.0000,  0.7247, -0.5709, -3.1908,\n",
      "           0.0000, -0.5181, -0.6333, -0.9799,  2.1781, -1.6938, -1.9562,\n",
      "          -0.6157, -1.2295,  1.6288,  0.6311, -2.7656, -0.6583,  0.8446,\n",
      "          -1.2684,  1.0483,  0.2904,  0.0000,  0.1085,  0.2258, -0.3360,\n",
      "           0.2775,  2.0212,  1.8671,  2.8215,  1.3601,  1.0725, -0.9123,\n",
      "           1.3122,  0.0557,  1.5245, -0.0093, -1.1333, -1.0903, -0.6004,\n",
      "          -0.9735, -1.0996, -0.7957, -1.4731, -0.9213,  0.8290, -0.0836,\n",
      "          -0.4223,  1.2237, -0.9091,  0.0233,  0.0000,  1.9912, -0.0297,\n",
      "           0.0000,  1.1650, -0.8708, -0.1173,  0.2373,  0.0000,  1.1920,\n",
      "          -1.5716, -2.6021,  0.1999,  0.4137, -0.6270,  1.7639,  1.0187,\n",
      "          -1.5179,  0.0000,  0.0000,  0.0000, -0.1323,  0.7099,  0.3022,\n",
      "          -0.5761, -0.0075,  1.1777, -3.6604, -0.0868, -1.6989, -0.8024,\n",
      "           0.0000, -0.2766,  0.0000, -0.0570, -0.2255, -2.0499,  0.2403,\n",
      "           0.4871,  1.2145,  1.0554,  0.0000,  1.0669,  0.8288,  0.0000,\n",
      "           1.3625, -0.0118, -1.1765,  1.9734,  0.0763,  0.4524,  2.3034,\n",
      "           0.5123, -2.3879,  0.5364,  0.0000,  1.1868,  2.1815,  0.5530,\n",
      "           0.0000,  0.0503, -2.0792, -1.4371,  0.0000,  0.2080,  0.8559,\n",
      "           1.3000, -2.7085,  0.0000, -0.8149,  2.1276, -1.8554,  0.5217,\n",
      "           0.0000, -0.3413, -0.7646, -1.5147,  0.4147, -0.4520, -0.0275,\n",
      "          -0.2642, -0.9976,  1.5164,  0.4733,  0.6498,  1.2727,  0.7757,\n",
      "           0.0908, -1.3158,  0.0000,  1.3428,  0.8303, -1.0299,  0.9621,\n",
      "          -0.0434, -1.6067, -1.0800, -1.4137, -0.4735, -1.0308, -0.7740,\n",
      "          -0.3890,  0.2980, -0.2057, -1.2262,  0.6066, -0.2141, -0.2157,\n",
      "           0.0000, -1.1318,  0.0000, -2.1221,  0.8798,  1.2665, -0.5883,\n",
      "           0.0000,  0.0000,  0.4871, -0.7152, -0.8524, -0.0687,  0.5127,\n",
      "           0.7213,  0.8487, -0.9927,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0713, 0.0810, 0.1519, 0.0923, 0.1438, 0.1366, 0.0391, 0.1132, 0.0588,\n",
      "         0.1121]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-4.6907e-02, -6.3481e-02,  2.8827e-02,  1.5481e-01, -3.1188e-01,\n",
      "          -1.1332e-01,  4.6339e-02,  1.5099e-02, -3.8627e-02, -1.6560e-01,\n",
      "           1.5410e-01, -1.3494e-02, -1.0770e-01,  1.0274e-02,  1.2492e-01,\n",
      "          -1.2117e-01, -1.3634e-01,  6.5315e-02, -1.7638e-01,  4.2112e-02,\n",
      "          -2.3937e-01, -1.1826e-01, -3.5322e-02,  1.2663e-01, -9.1074e-02,\n",
      "           1.6585e-01, -1.1258e-01,  6.2851e-02, -2.6166e-02, -1.3188e-01,\n",
      "           4.0801e-02, -1.0272e-01,  1.9142e-02, -1.9215e-01, -1.8304e-01,\n",
      "          -2.1412e-02, -1.9716e-02, -9.0510e-02,  4.1645e-02, -1.1201e-01,\n",
      "           1.7762e-01, -4.3633e-03, -9.8856e-02, -6.4922e-02,  2.3272e-02,\n",
      "           1.3442e-01,  1.8583e-02, -2.2932e-01,  3.9650e-02,  8.2665e-02,\n",
      "          -1.9494e-01, -2.1187e-01, -2.3381e-01, -1.4565e-02, -7.8970e-02,\n",
      "          -2.6009e-01, -1.1828e-01, -1.4992e-03,  9.8224e-02, -3.3764e-02,\n",
      "           4.7020e-02, -7.9575e-02, -2.1353e-01,  1.5370e-01, -4.6638e-03,\n",
      "          -3.4215e-03,  7.9037e-02,  3.9087e-01, -6.9177e-02,  2.1898e-01,\n",
      "           3.7566e-01,  1.3242e-01, -1.4813e-01, -1.3645e-01, -3.3974e-02,\n",
      "          -5.3374e-03,  2.7281e-01,  1.1408e-01, -1.0569e-01,  1.1377e-01,\n",
      "           2.8337e-02, -1.4936e-01, -8.3387e-02,  2.5397e-02,  5.3776e-02,\n",
      "          -4.6642e-02,  1.9153e-01,  2.6405e-01, -5.4004e-03, -1.8905e-01,\n",
      "          -6.2858e-02,  1.3782e-02,  3.4230e-02, -1.3680e-01, -2.5881e-01,\n",
      "           2.1126e-01,  8.8153e-02,  7.9266e-02,  1.9912e-01,  9.6341e-02,\n",
      "          -1.0502e-01, -1.0588e-01,  1.5840e-01, -3.4375e-02,  2.9046e-03,\n",
      "          -3.2120e-02,  7.5414e-02,  1.4685e-01,  1.2110e-01,  1.7062e-01,\n",
      "           1.0666e-01,  7.8489e-03,  1.6121e-02,  2.2732e-02,  5.9210e-02,\n",
      "          -7.6194e-02, -1.8270e-01, -4.8891e-02, -2.2821e-01, -2.6371e-01,\n",
      "           7.6889e-02, -2.2825e-02, -2.2039e-01, -7.8338e-02, -2.2596e-01,\n",
      "          -7.6928e-02, -5.9088e-02, -2.0570e-01,  2.7157e-02, -1.5327e-01,\n",
      "           1.1302e-01,  5.4900e-02, -1.1579e-01, -2.6836e-02, -2.4822e-01,\n",
      "           6.7690e-02,  2.7394e-03, -5.3830e-02, -1.3714e-01,  1.3860e-01,\n",
      "          -1.4510e-01,  1.9356e-01, -1.0254e-01,  2.2079e-01,  1.0259e-01,\n",
      "           1.4088e-01,  7.2322e-02,  3.2466e-02,  8.4084e-02,  1.6585e-01,\n",
      "           1.3717e-01,  1.1046e-01, -8.0217e-02,  2.7639e-02, -1.6056e-01,\n",
      "           5.6826e-02, -1.3676e-01,  1.3697e-01, -1.7383e-01,  1.0709e-01,\n",
      "          -1.1672e-01,  1.0643e-01, -9.6173e-02,  1.4152e-01,  1.0672e-01,\n",
      "           7.0194e-02,  1.3784e-01, -2.9018e-01,  1.8521e-01,  4.4217e-02,\n",
      "          -1.2662e-01,  1.1292e-02, -1.2769e-01, -1.5750e-01,  1.0591e-01,\n",
      "           1.1133e-01,  4.0619e-02,  9.9556e-02, -1.1639e-01,  1.5085e-01,\n",
      "          -2.2217e-01, -1.3760e-01, -2.9344e-02, -8.1534e-02,  2.3969e-01,\n",
      "           1.3492e-01, -1.8089e-01,  1.2995e-01,  1.1176e-01, -4.8850e-02,\n",
      "          -1.4469e-01,  1.2534e-01, -1.7788e-02, -2.0421e-01,  2.4521e-02,\n",
      "          -3.4279e-01,  1.6049e-01, -5.7662e-02, -1.2123e-01,  1.8930e-02,\n",
      "          -4.9454e-02,  9.3316e-02, -4.3849e-02, -1.6916e-01,  9.9371e-02,\n",
      "           6.6704e-03,  1.3469e-01,  1.9159e-01, -7.1797e-02, -1.4803e-01,\n",
      "          -1.0276e-01, -4.0215e-03, -3.1373e-04,  7.9410e-02, -7.6452e-02,\n",
      "           1.5195e-01, -1.3049e-01,  3.1735e-01, -5.4843e-02,  1.3880e-01,\n",
      "          -8.2604e-04, -8.6836e-02,  1.1260e-01, -8.7966e-03, -5.3082e-02,\n",
      "          -6.7734e-02, -1.6950e-01, -1.2677e-01, -3.2259e-02, -9.0748e-02,\n",
      "          -8.7127e-02, -7.5416e-02, -2.0037e-01, -1.6148e-01, -3.4688e-01,\n",
      "          -2.7457e-03, -1.8913e-01,  6.1181e-02,  2.9579e-01,  5.1019e-02,\n",
      "          -1.3855e-01, -2.7968e-01, -1.9105e-01, -1.8193e-02, -5.4233e-02,\n",
      "          -1.0150e-01, -7.1796e-02, -1.6154e-01,  3.1007e-02,  1.5262e-02,\n",
      "           5.8011e-02, -5.2129e-02, -7.0332e-02,  2.8602e-01,  1.1009e-01,\n",
      "           2.1003e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0506,  1.6141, -1.2213,  0.1080, -0.8037, -0.0744,  0.1357,\n",
      "          -1.0207, -0.3500,  0.6069,  0.5419,  1.4546,  0.1338, -1.7006,\n",
      "           0.0000, -2.3566, -0.7013,  0.0000, -1.8744,  1.1428,  0.7346,\n",
      "          -1.9030,  0.4698,  0.7691, -0.3140, -0.4288, -0.3102, -0.2257,\n",
      "           0.0000,  0.0963,  1.4812, -2.2024,  0.0000,  0.0000,  0.0000,\n",
      "           2.4261,  1.0767,  0.0000, -0.3677,  0.0000,  0.3716, -0.4464,\n",
      "           2.2500, -1.2587,  1.5157, -0.3133,  0.0000, -1.1211, -0.3444,\n",
      "           0.1404, -0.7956,  0.0000,  0.0000, -0.4866, -0.4768,  1.2274,\n",
      "           0.4435,  1.6409, -0.8595,  0.1732, -1.4061,  0.0000, -2.4134,\n",
      "           1.9314, -0.5695, -0.6560, -0.2815,  0.0357, -1.5837,  1.6462,\n",
      "          -1.4249,  0.9807, -0.0848,  1.7226, -1.0820,  1.2172,  0.0089,\n",
      "           1.5481,  1.3214,  0.2864,  1.0363, -0.5740, -0.5292,  1.2607,\n",
      "          -1.1709,  2.7706,  0.0368, -0.3125, -0.3951,  0.0000, -0.6997,\n",
      "          -1.2072, -0.1374, -1.2539, -0.3586,  1.9074,  0.6109,  0.4666,\n",
      "           1.2742,  0.9408,  0.0986, -1.6311,  1.1924, -0.7315,  1.1343,\n",
      "          -2.1753,  0.5374,  0.0000,  0.5053,  1.8176,  1.3764, -0.3852,\n",
      "           0.0000,  0.5283,  0.0388,  0.0000,  0.7163,  0.0829, -0.4988,\n",
      "           0.6507, -1.9371, -0.1452,  0.3462,  0.9735,  0.3104, -0.0720,\n",
      "          -0.3569, -1.1981,  0.9570,  0.7303, -1.1507,  0.6041,  0.0000,\n",
      "           0.0000,  0.5432, -1.1582, -1.1250, -0.1606,  0.0000,  0.0000,\n",
      "           1.1297,  0.3956,  1.8452, -0.8987,  1.9361,  0.7250,  0.0000,\n",
      "           0.2226,  0.0000,  0.5006, -0.6787,  0.0383,  0.4276,  0.0568,\n",
      "           1.2492,  0.8824, -1.2593, -1.2798,  0.4686, -0.6548, -0.0674,\n",
      "          -1.6399, -1.0454, -0.2557, -0.3492, -0.3369,  0.0187, -1.9616,\n",
      "           0.5776, -0.4899,  0.0000,  1.3032,  3.1645,  0.9587,  1.0213,\n",
      "           0.0000,  0.7562, -0.1308,  0.4547, -0.8265,  0.9847, -1.4253,\n",
      "          -0.0714, -0.0151, -2.3934,  0.5258, -1.3846, -0.3716, -1.3875,\n",
      "           2.4804,  0.7480,  0.7422,  1.9217, -0.0912, -0.1426,  0.6047,\n",
      "          -0.1706, -1.1476,  1.9326,  1.4632, -0.1506, -0.2662,  0.7296,\n",
      "          -1.5531,  0.0000,  0.6864,  0.9932,  0.4499, -0.9492,  2.2195,\n",
      "          -0.8902,  0.8169,  0.1870,  0.4399,  1.7619,  0.3605, -0.9267,\n",
      "           1.2921, -0.4946, -0.2085,  0.2803, -1.9130,  0.6170, -0.6299,\n",
      "           0.0495, -0.5804,  0.0662, -0.5980, -0.4547, -0.3996,  0.0000,\n",
      "          -1.5173, -2.0323, -0.5674, -1.1071,  1.9825,  1.8104, -0.1326,\n",
      "           1.7838, -0.1124, -0.4886,  0.0000, -0.7951,  0.7568,  1.6990,\n",
      "           0.0000, -0.2755, -0.4579, -0.5620,  0.6714,  0.0000, -0.2975,\n",
      "           0.0000,  0.6649, -2.0468, -0.1356]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0506, 0.0583, 0.1014, 0.0818, 0.0953, 0.2286, 0.1157, 0.1407, 0.0935,\n",
      "         0.0340]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0075, -0.0414,  0.0016,  0.1973, -0.2489, -0.1357,  0.0592,\n",
      "           0.0295, -0.0409, -0.1911,  0.1811, -0.0643, -0.1386,  0.0600,\n",
      "           0.1545, -0.1576, -0.1423,  0.1637, -0.3021,  0.1025, -0.2577,\n",
      "          -0.1699,  0.0419,  0.1388, -0.0936,  0.1202, -0.0819,  0.0505,\n",
      "          -0.0302, -0.0546,  0.0697, -0.1881,  0.0231, -0.2978, -0.1150,\n",
      "          -0.0712, -0.0209, -0.1570, -0.0304, -0.0948,  0.1746,  0.0136,\n",
      "          -0.0782, -0.0217,  0.0311,  0.1644, -0.0519, -0.2960,  0.1321,\n",
      "           0.1097, -0.2213, -0.2737, -0.3386, -0.0265, -0.1582, -0.2551,\n",
      "          -0.1135, -0.0498,  0.0566, -0.0527,  0.0376, -0.0845, -0.2908,\n",
      "           0.1817,  0.0020,  0.0033, -0.0069,  0.4262, -0.0748,  0.2548,\n",
      "           0.3978,  0.1619, -0.1184, -0.0762, -0.1721, -0.0114,  0.2976,\n",
      "           0.1754, -0.1401,  0.1607, -0.0843, -0.1465, -0.0794,  0.0339,\n",
      "          -0.0007, -0.0105,  0.1724,  0.2940,  0.0663, -0.1637, -0.0538,\n",
      "           0.0931, -0.0159, -0.0967, -0.3021,  0.2760,  0.0962,  0.0857,\n",
      "           0.2724,  0.0980, -0.1510, -0.0220,  0.1813,  0.0224, -0.0101,\n",
      "          -0.0665,  0.1882,  0.2335,  0.0237,  0.2859,  0.0753,  0.0441,\n",
      "           0.0637, -0.0118,  0.0066, -0.0961, -0.2250, -0.0527, -0.3095,\n",
      "          -0.3656,  0.0071, -0.0334, -0.2093, -0.0091, -0.2793, -0.0848,\n",
      "          -0.0469, -0.2183,  0.0474, -0.1976,  0.1052, -0.0786, -0.0890,\n",
      "           0.0307, -0.2998,  0.1172,  0.1363,  0.0012, -0.1359,  0.1820,\n",
      "          -0.1523,  0.2899, -0.1587,  0.2094,  0.1178,  0.1541,  0.0067,\n",
      "           0.0227,  0.1300,  0.2141,  0.0514,  0.1700, -0.0275,  0.0983,\n",
      "          -0.1664,  0.1115, -0.1934,  0.1752, -0.2283,  0.0936, -0.1896,\n",
      "           0.1169, -0.0574,  0.2130,  0.0637,  0.0644,  0.0665, -0.3575,\n",
      "           0.2421,  0.0572, -0.1600,  0.0072, -0.0428, -0.0993,  0.1465,\n",
      "           0.0017,  0.0340,  0.1149, -0.0177,  0.0670, -0.2327, -0.1173,\n",
      "           0.0006, -0.1412,  0.2966,  0.0832, -0.2163,  0.2070,  0.0747,\n",
      "          -0.0638, -0.1853,  0.0810, -0.0497, -0.2188,  0.0233, -0.3716,\n",
      "           0.1255, -0.0519, -0.1461, -0.0335, -0.0589,  0.1376, -0.0827,\n",
      "          -0.1005,  0.0315, -0.0194,  0.1742,  0.1739, -0.0505, -0.1903,\n",
      "          -0.1430, -0.0427, -0.0256,  0.1209, -0.1237,  0.2345, -0.2001,\n",
      "           0.4001, -0.0281,  0.1604, -0.0352, -0.0939,  0.1789, -0.0266,\n",
      "          -0.0359, -0.0348, -0.1110, -0.1978, -0.0919, -0.0427, -0.0703,\n",
      "          -0.1534, -0.2806, -0.2337, -0.2914,  0.0188, -0.2166,  0.0997,\n",
      "           0.3625,  0.1537, -0.1037, -0.3563, -0.2002, -0.0494, -0.0684,\n",
      "          -0.1136, -0.1387, -0.1431, -0.0688,  0.0182,  0.0791, -0.1160,\n",
      "          -0.0551,  0.2726,  0.1027,  0.1818]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.3038e-01, -1.9568e-01, -4.4299e-01, -4.9257e-02,  2.9877e-01,\n",
      "           4.8902e-01,  1.3842e+00, -9.6906e-01,  3.3058e-01,  1.4739e+00,\n",
      "           1.9654e+00,  7.3887e-01,  2.3643e-01,  4.1500e-01,  2.4579e+00,\n",
      "           1.0298e+00, -1.0174e+00, -9.7822e-01,  1.4137e+00,  4.9406e-01,\n",
      "           1.4840e+00, -2.6411e-01,  1.8119e+00, -7.3187e-01, -9.2624e-01,\n",
      "           1.1251e+00,  8.4694e-02,  1.5015e+00,  6.1297e-01, -1.8742e+00,\n",
      "          -3.0852e-01, -6.7954e-01, -4.0551e-01, -4.0372e-01,  2.5187e+00,\n",
      "           0.0000e+00,  1.5088e+00,  1.8642e+00,  1.0161e+00,  0.0000e+00,\n",
      "           6.3119e-01,  9.6640e-01,  1.9190e+00, -4.6539e-01,  4.2080e-01,\n",
      "          -2.0575e+00, -9.2583e-01,  0.0000e+00,  4.8077e-01,  1.8818e+00,\n",
      "           1.9455e+00,  3.1270e-01,  0.0000e+00,  9.9307e-01, -7.8628e-01,\n",
      "           1.0052e+00, -2.5794e-01,  1.1769e+00,  5.0723e-01,  5.6610e-01,\n",
      "          -3.2230e-01, -6.1616e-01,  1.4821e+00, -1.0298e+00, -6.9757e-02,\n",
      "           1.4354e+00,  2.5919e-01, -1.9973e+00,  3.3172e-01,  0.0000e+00,\n",
      "          -2.1864e-01,  6.7440e-01, -2.7493e-01, -3.8207e-01,  1.7429e+00,\n",
      "           1.6606e+00,  3.8752e-01,  8.5355e-01, -3.9509e-01, -1.4611e-01,\n",
      "           0.0000e+00, -5.5095e-01,  0.0000e+00,  3.1749e-01, -5.4440e-01,\n",
      "          -1.0705e+00,  4.0236e-01, -5.6699e-02, -1.4579e+00,  0.0000e+00,\n",
      "          -1.2847e+00,  1.1716e+00, -3.4400e-01, -7.2826e-01, -6.9154e-01,\n",
      "           1.2026e+00, -1.6865e+00,  1.2234e+00,  0.0000e+00, -1.0687e+00,\n",
      "           1.2711e+00, -9.5546e-01,  7.3581e-01,  1.2484e+00, -7.2601e-02,\n",
      "           3.6216e-01, -3.2138e-01, -1.8900e-01, -2.1957e-01,  1.8864e-01,\n",
      "           2.4086e+00,  5.1736e-02,  4.9281e-01, -5.8649e-01,  0.0000e+00,\n",
      "           1.8552e+00,  1.1738e+00,  7.0746e-02,  1.1688e-01, -1.2911e-01,\n",
      "          -2.3109e+00, -1.1846e+00,  1.0782e+00, -1.6537e+00,  6.6407e-01,\n",
      "           1.3978e-02, -1.6225e-01,  2.0459e-02, -1.2872e+00, -1.2228e+00,\n",
      "          -6.9446e-01, -1.8015e+00, -6.0662e-01,  2.2184e-01,  1.5429e+00,\n",
      "           1.6562e-01,  2.2794e+00,  3.1880e-02,  1.9961e-01,  0.0000e+00,\n",
      "          -2.3175e+00,  0.0000e+00, -1.0987e+00,  1.1814e+00,  3.4674e-02,\n",
      "          -7.8482e-01,  0.0000e+00, -2.7623e+00,  5.9984e-01,  1.0951e+00,\n",
      "           0.0000e+00,  9.7980e-02, -3.6900e-01, -2.8348e+00,  0.0000e+00,\n",
      "           1.2890e+00,  1.0364e+00,  7.7376e-01, -6.4348e-01,  1.3059e+00,\n",
      "          -3.2894e-01,  1.2572e+00, -1.8881e-01, -1.2923e+00,  1.2906e+00,\n",
      "          -7.2086e-01,  2.7898e-01, -4.1109e-01, -7.4268e-01,  1.1199e+00,\n",
      "           0.0000e+00, -1.9550e+00, -2.7494e-01, -1.1304e-01,  3.2725e-01,\n",
      "           0.0000e+00, -3.5238e-01, -1.7778e+00, -1.7855e-01, -3.9270e-01,\n",
      "           1.6166e+00,  2.0050e+00, -3.0173e-01,  3.4567e-02,  8.4897e-01,\n",
      "           0.0000e+00, -9.5674e-01, -1.4843e-01,  2.5381e+00, -1.1400e+00,\n",
      "           1.1809e+00, -1.7565e-03,  1.6605e+00, -9.1385e-01, -1.9320e+00,\n",
      "           0.0000e+00, -8.4286e-01, -3.5428e-01,  5.0163e-02, -1.0097e+00,\n",
      "           1.1018e+00, -5.9641e-01,  7.1450e-01,  0.0000e+00,  0.0000e+00,\n",
      "           2.9518e-01, -4.0197e-01, -1.7448e-01,  0.0000e+00, -4.4167e-01,\n",
      "          -2.1388e-01, -2.7731e-02, -7.1859e-01,  0.0000e+00,  5.1582e-01,\n",
      "          -2.6719e-01, -9.0442e-02,  2.2127e+00, -1.2812e-01,  5.1880e-01,\n",
      "          -8.6566e-01, -6.3014e-01,  1.0214e+00,  0.0000e+00, -6.4753e-01,\n",
      "          -2.8678e-01,  1.7522e+00,  2.9495e-01,  0.0000e+00, -8.7781e-02,\n",
      "           6.0824e-01, -1.9344e+00,  2.0342e+00, -1.6238e+00,  5.1803e-01,\n",
      "          -2.0426e-01,  8.4342e-01,  0.0000e+00,  9.5371e-01,  5.2941e-01,\n",
      "           3.1033e-01, -1.6677e-01, -1.2343e+00, -4.2165e-01,  0.0000e+00,\n",
      "           1.0882e+00,  4.2663e-01,  1.1963e+00, -6.6066e-01,  8.0808e-01,\n",
      "          -6.0553e-01,  9.6298e-01,  7.6491e-01,  5.4389e-01, -1.1215e+00,\n",
      "           8.7226e-02]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0690, 0.2243, 0.0879, 0.0513, 0.1215, 0.1140, 0.0643, 0.1027, 0.1262,\n",
      "         0.0388]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0057, -0.0438,  0.0071,  0.1503, -0.2946, -0.1263,  0.0371,\n",
      "           0.0090, -0.0704, -0.1623,  0.1377, -0.1030, -0.1303,  0.0111,\n",
      "           0.1106, -0.1430, -0.1550,  0.0635, -0.1694, -0.0024, -0.2604,\n",
      "          -0.0747, -0.0290,  0.1860, -0.1029,  0.1371, -0.0908,  0.0353,\n",
      "          -0.0280, -0.1726,  0.0911, -0.0545,  0.0678, -0.1945, -0.2242,\n",
      "           0.0074, -0.0636, -0.0340, -0.0078, -0.1020,  0.1637, -0.0428,\n",
      "          -0.1401, -0.1271, -0.0218,  0.0839,  0.0061, -0.2131,  0.0098,\n",
      "           0.1266, -0.2135, -0.1530, -0.2329, -0.0302, -0.1019, -0.2265,\n",
      "          -0.1230, -0.0152,  0.0443, -0.0739,  0.0081, -0.1107, -0.1537,\n",
      "           0.1526, -0.0480, -0.0311,  0.0791,  0.4021, -0.0658,  0.2153,\n",
      "           0.3517,  0.1409, -0.0793, -0.1393, -0.0269,  0.0320,  0.2871,\n",
      "           0.0969, -0.0661,  0.1050,  0.0789, -0.0805, -0.0577,  0.0443,\n",
      "           0.0594, -0.0928,  0.1904,  0.2679,  0.0252, -0.1656, -0.0956,\n",
      "          -0.0154,  0.0317, -0.1228, -0.3046,  0.2675,  0.0112,  0.0843,\n",
      "           0.1643,  0.1289, -0.0496, -0.0438,  0.1200, -0.0538,  0.0122,\n",
      "           0.0542,  0.0580,  0.1625,  0.1176,  0.1469,  0.1184,  0.0708,\n",
      "           0.0082,  0.0198,  0.0698, -0.0191, -0.1445, -0.0608, -0.2690,\n",
      "          -0.2054,  0.0634,  0.0011, -0.2612, -0.0550, -0.2576, -0.0094,\n",
      "          -0.0523, -0.2184,  0.0843, -0.1182,  0.1274,  0.0343, -0.0952,\n",
      "          -0.0557, -0.1514,  0.0568, -0.0562, -0.0701, -0.0589,  0.1205,\n",
      "          -0.1611,  0.1055, -0.1077,  0.1629,  0.0109,  0.1091,  0.0992,\n",
      "           0.0435,  0.1192,  0.1449,  0.0737,  0.0665, -0.0811,  0.0527,\n",
      "          -0.1282,  0.0999, -0.0741,  0.1114, -0.1652,  0.1069, -0.0718,\n",
      "           0.0537, -0.1348,  0.1052, -0.0031, -0.0248,  0.1481, -0.2536,\n",
      "           0.2339,  0.0202, -0.1119, -0.0052, -0.1197, -0.1361,  0.1258,\n",
      "           0.1332,  0.0425,  0.0856, -0.0261,  0.1222, -0.2408, -0.0551,\n",
      "          -0.0209, -0.0179,  0.2347,  0.1364, -0.1771,  0.0967,  0.0565,\n",
      "          -0.0470, -0.0638,  0.1364, -0.0729, -0.1951,  0.0539, -0.3286,\n",
      "           0.2021,  0.0043, -0.1264,  0.0712, -0.0166,  0.0819, -0.0566,\n",
      "          -0.1356,  0.0664,  0.0752,  0.0140,  0.2465, -0.0954, -0.1483,\n",
      "          -0.0995, -0.0255,  0.0271,  0.1030, -0.0163,  0.2038, -0.1409,\n",
      "           0.2842, -0.0615,  0.1638,  0.0871, -0.0277,  0.0583,  0.0083,\n",
      "          -0.0139, -0.0858, -0.1662, -0.0749, -0.0551, -0.1103, -0.0852,\n",
      "          -0.0433, -0.0954, -0.1384, -0.3200, -0.0105, -0.2195,  0.0437,\n",
      "           0.2189,  0.0689, -0.0923, -0.2294, -0.1835, -0.0010, -0.0783,\n",
      "          -0.1234, -0.1062, -0.1634,  0.0201, -0.0122,  0.0692, -0.1011,\n",
      "          -0.0539,  0.2678,  0.1592,  0.1920]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7266e-01, -4.3065e-01,  3.1506e-01, -1.0847e+00, -1.1725e+00,\n",
      "           7.4163e-01, -1.9143e+00,  1.3514e+00,  1.9035e-01,  6.1726e-01,\n",
      "           1.9032e+00,  6.0242e-01,  2.2878e-01, -9.1627e-01, -3.1825e+00,\n",
      "          -6.8355e-02,  0.0000e+00, -9.4354e-01,  1.3606e+00, -1.4351e+00,\n",
      "          -1.4059e-01, -5.2392e-01, -1.1196e+00, -2.5952e+00, -7.5774e-02,\n",
      "           1.3914e+00,  0.0000e+00,  1.9975e+00,  1.2764e-01,  5.5436e-01,\n",
      "           9.1532e-01,  0.0000e+00,  2.2261e-01,  2.0160e+00, -6.3694e-02,\n",
      "          -1.4085e+00, -1.1182e-01, -8.1753e-01,  3.1489e-01,  8.5728e-02,\n",
      "           8.6258e-01, -8.9943e-01,  1.0089e+00, -1.5634e+00,  1.9443e+00,\n",
      "          -3.0017e-01,  7.0529e-01, -6.0179e-01, -1.0207e+00,  1.1166e+00,\n",
      "          -1.3225e+00,  2.6771e+00,  0.0000e+00, -8.4676e-01,  2.2769e-01,\n",
      "          -3.0955e-01, -1.4340e+00, -9.6542e-02,  1.2754e+00,  2.1813e+00,\n",
      "          -1.0063e+00,  3.6060e-02,  0.0000e+00,  0.0000e+00, -6.2925e-02,\n",
      "           3.9384e-01,  5.7800e-01,  1.1651e+00,  1.5808e+00, -1.4152e+00,\n",
      "           4.2752e-01,  2.9641e-01,  0.0000e+00, -7.9785e-01, -2.1438e-01,\n",
      "           1.3932e-01,  0.0000e+00,  1.3987e+00,  1.0271e+00, -7.9338e-01,\n",
      "           7.5790e-01, -1.0053e+00,  0.0000e+00,  1.0587e+00,  0.0000e+00,\n",
      "          -1.1307e-01, -1.1077e+00,  5.4877e-01, -9.4476e-01, -1.9013e+00,\n",
      "           5.2909e-01,  9.8697e-01,  1.7017e+00,  9.4370e-01,  6.0806e-01,\n",
      "          -1.5884e-02,  3.5359e-01, -1.1757e+00,  1.3717e+00,  2.4480e+00,\n",
      "           2.4362e-01,  4.5045e-02, -4.6650e-01, -9.8940e-01,  1.6401e+00,\n",
      "          -1.0233e+00,  3.0292e+00,  6.2003e-01, -1.0201e-01, -1.2354e+00,\n",
      "           1.8993e-01, -5.0299e-01, -5.7056e-01,  7.1235e-01, -7.8038e-01,\n",
      "           6.3242e-01,  4.0391e-01,  2.2393e-01, -2.3271e+00,  0.0000e+00,\n",
      "          -8.1395e-01,  0.0000e+00, -1.8376e+00,  6.0326e-01, -9.5656e-01,\n",
      "           0.0000e+00,  3.9602e-02,  2.1502e+00,  1.3962e+00, -2.0877e+00,\n",
      "           0.0000e+00,  4.4968e-01, -1.1676e+00,  4.2523e-01, -4.6863e-01,\n",
      "          -7.4529e-01,  0.0000e+00, -9.7496e-01, -1.9473e-02,  2.3977e+00,\n",
      "           6.9858e-01, -1.1217e+00,  1.6917e+00, -1.4028e-01, -6.6966e-01,\n",
      "           3.3746e-02,  7.5943e-01,  4.2300e-01, -1.0334e+00, -9.5534e-02,\n",
      "           1.5600e+00,  5.8692e-01, -3.3862e-01,  6.5768e-01,  1.8409e+00,\n",
      "          -2.5258e-01, -2.1761e-01,  6.2359e-01, -2.3627e+00,  1.0557e+00,\n",
      "           3.0254e-01, -7.7379e-02,  1.5472e-01, -1.2118e+00, -2.1934e-02,\n",
      "           1.6821e+00,  1.8520e+00,  2.7095e-01, -1.2702e+00, -7.1320e-01,\n",
      "          -1.2243e+00, -1.0940e+00, -2.5904e+00,  5.0566e-01, -3.0591e+00,\n",
      "           0.0000e+00,  4.9799e-01,  8.2957e-01,  0.0000e+00, -7.9289e-01,\n",
      "           2.7166e-01,  2.3396e+00,  1.0574e+00,  8.3842e-01, -4.0283e-01,\n",
      "           7.2745e-01,  5.9895e-01,  3.5956e-01,  8.4270e-01, -1.8303e+00,\n",
      "           1.3635e+00,  2.1591e+00,  3.3642e-01, -1.0154e+00, -1.1721e+00,\n",
      "          -2.2153e+00,  1.6666e+00,  2.1526e+00,  3.6342e-01,  2.3836e+00,\n",
      "           3.2397e-02, -5.0152e-01, -1.2764e+00, -5.4249e-01, -4.0745e-01,\n",
      "          -1.4470e+00,  9.5359e-01, -8.5187e-01,  8.3029e-01, -1.5600e+00,\n",
      "           6.3651e-01,  6.7596e-01,  2.3976e+00,  5.5179e-02,  1.8937e+00,\n",
      "           1.3082e+00,  5.8060e-01, -2.3172e+00,  1.5502e+00, -2.2259e-01,\n",
      "          -2.2717e-01,  1.7334e+00,  2.7692e-01,  0.0000e+00,  9.2283e-01,\n",
      "          -1.2244e+00, -8.4835e-01, -1.8017e+00, -5.1666e-04,  3.7332e-01,\n",
      "          -1.5734e+00,  0.0000e+00,  0.0000e+00, -1.7364e+00,  1.6941e+00,\n",
      "          -1.4405e+00,  6.3406e-01, -1.7222e+00,  9.8034e-01, -1.7159e+00,\n",
      "           1.5607e+00, -2.7222e-01, -2.5967e+00,  1.2386e+00, -1.2284e+00,\n",
      "           1.8850e+00, -5.0833e-01,  5.4282e-01,  0.0000e+00, -1.0219e+00,\n",
      "           1.3335e+00,  3.1067e-01, -5.1375e-02, -2.2880e-01,  0.0000e+00,\n",
      "           1.8064e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0466, 0.1296, 0.1520, 0.0828, 0.1481, 0.0927, 0.1198, 0.0594, 0.1038,\n",
      "         0.0652]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2882, -0.5108,  0.3513,  ...,  0.0041, -0.0211,  0.1256],\n",
      "        [ 0.0825,  0.0023, -0.0421,  ...,  0.3779,  0.4224,  0.2671],\n",
      "        [-0.1549, -0.2128,  0.0218,  ...,  0.3909,  0.2178,  0.5771],\n",
      "        ...,\n",
      "        [ 0.5686,  0.4636, -0.6646,  ..., -0.0726,  0.0455,  0.1617],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-3.4317e-02, -6.9499e-02,  3.2757e-02,  1.1158e-01, -2.9532e-01,\n",
      "          -1.0162e-01,  1.9435e-02,  1.1283e-02, -6.0778e-02, -1.8534e-01,\n",
      "           1.3795e-01,  5.0250e-03, -1.2517e-01,  2.7309e-02,  1.1616e-01,\n",
      "          -1.2778e-01, -1.7505e-01,  6.4639e-02, -1.6923e-01,  1.8419e-02,\n",
      "          -2.2918e-01, -1.0241e-01, -3.1109e-02,  1.0590e-01, -8.0579e-02,\n",
      "           2.1057e-01, -5.7185e-02,  6.0982e-02, -3.8208e-03, -1.2173e-01,\n",
      "           7.2631e-02, -7.3532e-02,  4.4100e-02, -1.9832e-01, -2.1705e-01,\n",
      "          -2.5910e-02, -2.5017e-02, -6.2395e-02,  5.5431e-02, -8.2550e-02,\n",
      "           1.7679e-01,  2.3461e-02, -9.9419e-02, -9.1894e-02, -3.2847e-02,\n",
      "           1.2761e-01,  3.0500e-02, -2.1484e-01,  2.4513e-02,  7.3607e-02,\n",
      "          -1.7222e-01, -1.9343e-01, -2.0968e-01, -2.1637e-02, -7.3204e-02,\n",
      "          -2.5744e-01, -1.2850e-01, -3.8633e-03,  8.4340e-02, -6.2135e-02,\n",
      "           5.2808e-02, -1.0669e-01, -2.0331e-01,  1.8097e-01, -2.6644e-02,\n",
      "          -1.4688e-02,  7.8081e-02,  4.0359e-01, -1.0149e-01,  2.4442e-01,\n",
      "           3.9611e-01,  1.4930e-01, -1.2114e-01, -1.6062e-01, -7.7243e-03,\n",
      "           3.4024e-02,  2.9566e-01,  1.0855e-01, -8.9025e-02,  1.2189e-01,\n",
      "           6.8105e-02, -7.8211e-02, -9.8373e-02,  5.0792e-02,  5.9293e-02,\n",
      "          -7.7888e-02,  2.2166e-01,  2.8826e-01, -4.6346e-03, -1.6964e-01,\n",
      "          -7.0770e-02,  4.6007e-04,  1.6388e-02, -1.7522e-01, -2.5771e-01,\n",
      "           2.3802e-01,  7.2325e-02,  5.1357e-02,  2.3185e-01,  9.5210e-02,\n",
      "          -5.4035e-02, -7.1259e-02,  1.3487e-01, -5.9393e-02,  5.8859e-02,\n",
      "          -2.6146e-02,  6.5812e-02,  1.7157e-01,  1.3740e-01,  1.5252e-01,\n",
      "           1.0037e-01,  3.8696e-02, -1.0945e-02,  3.4999e-02,  7.5031e-02,\n",
      "          -4.1087e-02, -1.7473e-01, -4.9869e-02, -2.4184e-01, -2.3262e-01,\n",
      "           6.6453e-02,  1.0271e-02, -2.6125e-01, -7.6239e-02, -2.4979e-01,\n",
      "          -6.6952e-02, -6.4067e-02, -2.1641e-01,  3.0627e-02, -1.5207e-01,\n",
      "           1.0784e-01,  8.2974e-02, -1.4051e-01, -1.4587e-02, -2.1563e-01,\n",
      "           3.3153e-02, -4.5328e-02, -3.9220e-02, -9.4429e-02,  1.5111e-01,\n",
      "          -1.7516e-01,  1.7831e-01, -1.2477e-01,  2.0224e-01,  5.9187e-02,\n",
      "           1.3941e-01,  9.9915e-02,  4.8840e-02,  1.0135e-01,  1.6982e-01,\n",
      "           1.0922e-01,  1.2077e-01, -1.0544e-01,  1.7971e-02, -1.3544e-01,\n",
      "           6.3817e-02, -1.0551e-01,  1.3641e-01, -2.1101e-01,  1.2012e-01,\n",
      "          -9.9731e-02,  1.3017e-01, -1.2281e-01,  1.3395e-01,  4.4198e-02,\n",
      "           2.9879e-02,  1.4349e-01, -2.8433e-01,  1.4768e-01, -2.2341e-02,\n",
      "          -1.3526e-01,  4.0190e-03, -1.5623e-01, -1.3422e-01,  1.0726e-01,\n",
      "           1.1213e-01,  5.2202e-02,  8.3250e-02, -1.0738e-01,  1.4460e-01,\n",
      "          -2.3786e-01, -1.2186e-01, -3.6388e-02, -5.4913e-02,  2.5562e-01,\n",
      "           1.2709e-01, -1.3809e-01,  9.9521e-02,  6.3659e-02, -4.4376e-02,\n",
      "          -1.0998e-01,  1.3216e-01, -1.3912e-02, -1.8467e-01,  2.6970e-03,\n",
      "          -3.4514e-01,  2.0847e-01, -3.0210e-02, -1.1668e-01,  7.3308e-03,\n",
      "          -3.4680e-02,  8.0761e-02, -3.5865e-02, -2.0694e-01,  8.4300e-02,\n",
      "           2.4049e-02,  1.0686e-01,  2.0838e-01, -7.4035e-02, -1.5927e-01,\n",
      "          -1.3390e-01,  2.7005e-03, -1.0172e-04,  7.9000e-02, -5.1256e-02,\n",
      "           1.4169e-01, -8.8558e-02,  3.0618e-01, -6.9006e-02,  1.1901e-01,\n",
      "           2.4184e-02, -6.0524e-02,  1.0292e-01,  1.4629e-02, -7.4647e-02,\n",
      "          -8.2878e-02, -2.0384e-01, -1.2228e-01, -4.1351e-02, -1.2862e-01,\n",
      "          -3.8721e-02, -7.8338e-02, -1.9153e-01, -1.4387e-01, -3.4969e-01,\n",
      "          -7.5684e-03, -2.1169e-01,  6.1697e-02,  3.0102e-01,  5.4104e-02,\n",
      "          -1.3270e-01, -2.7207e-01, -1.6268e-01,  2.2476e-02, -4.8811e-02,\n",
      "          -1.3214e-01, -7.6064e-02, -1.6954e-01, -5.9438e-04, -5.3367e-02,\n",
      "           6.7762e-02, -5.4868e-02, -3.8004e-02,  2.7457e-01,  1.6399e-01,\n",
      "           2.0584e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6221e-02,  3.9940e-01, -9.6591e-01, -6.8129e-01,  3.7591e-01,\n",
      "          -2.0197e-01,  0.0000e+00, -8.3385e-02, -3.5842e+00,  9.0659e-01,\n",
      "           4.2825e-01, -6.2912e-01,  2.6039e+00, -6.2979e-01, -5.4143e-01,\n",
      "           0.0000e+00,  8.5125e-01,  1.0948e+00,  4.5515e-01,  4.3610e-01,\n",
      "           0.0000e+00, -3.8295e-01,  1.6411e+00,  1.5109e+00,  7.5353e-01,\n",
      "          -7.5602e-02, -1.8794e-01,  0.0000e+00,  1.6536e+00,  8.6160e-01,\n",
      "           1.2318e+00,  1.2190e+00, -1.0342e+00, -8.2756e-02, -1.5344e+00,\n",
      "           1.3954e+00,  2.8091e-01, -3.7446e+00,  1.9785e-01,  1.6007e+00,\n",
      "          -4.5885e-01, -1.3982e+00, -2.6852e-01, -1.7155e+00, -1.5240e+00,\n",
      "           6.6745e-01,  5.4087e-01,  3.7073e-01, -1.3406e+00,  1.4420e-01,\n",
      "          -6.2926e-01,  2.7520e+00,  6.1026e-01, -1.0291e+00, -2.5411e-02,\n",
      "           2.0342e-01, -8.8181e-01, -1.2522e+00, -2.3694e-01, -4.2553e-01,\n",
      "           1.1002e+00,  1.4079e+00, -2.0293e-01, -5.0140e-01, -2.9635e+00,\n",
      "           5.5087e-01,  1.2786e+00, -1.2877e+00,  4.1102e-01,  5.2663e-01,\n",
      "          -1.2668e+00, -3.0046e-02,  7.0735e-01,  0.0000e+00,  3.2575e-01,\n",
      "          -1.4901e-03, -1.5997e-01,  0.0000e+00, -5.8053e-02, -1.1925e-01,\n",
      "          -1.4002e+00,  2.1309e+00, -9.2455e-01,  1.0058e+00, -2.0770e-01,\n",
      "           4.3525e-01,  1.6616e+00, -9.7415e-01, -1.0379e-01, -5.8133e-01,\n",
      "          -2.2732e+00,  1.1002e+00,  0.0000e+00, -1.1355e+00,  4.6724e-01,\n",
      "          -1.1706e+00,  3.3889e-02,  0.0000e+00,  1.7198e+00, -7.7960e-01,\n",
      "           2.6971e+00, -1.4622e+00,  1.0760e+00,  1.4536e+00, -6.6630e-01,\n",
      "          -7.6253e-01,  1.2120e+00,  1.2718e-01,  0.0000e+00, -1.3424e-02,\n",
      "          -2.4852e-01,  1.3422e-01, -1.0479e+00,  1.3100e+00, -1.6531e+00,\n",
      "          -2.9891e+00, -5.6545e-02, -5.0042e-01, -1.9335e-01,  4.4514e-01,\n",
      "          -1.4659e+00,  7.0215e-01, -1.4604e+00, -7.2591e-01,  0.0000e+00,\n",
      "          -1.3086e+00,  8.9677e-01,  1.6991e-01,  1.2851e+00, -7.5193e-01,\n",
      "          -8.2370e-01,  5.3013e-01, -1.5830e+00,  9.8401e-01,  0.0000e+00,\n",
      "          -5.8951e-01,  6.5925e-01,  5.7463e-01, -1.1587e+00, -1.0098e+00,\n",
      "           0.0000e+00,  6.7777e-01, -7.8982e-01, -1.0122e-01, -1.6854e+00,\n",
      "          -1.0080e-01, -5.4318e-01,  0.0000e+00,  0.0000e+00,  1.7756e-01,\n",
      "           1.9984e+00, -1.9957e-01, -1.9301e+00, -4.0613e-01,  4.4137e-01,\n",
      "           0.0000e+00, -6.4494e-02, -1.2951e-01,  3.9280e-02,  5.3757e-01,\n",
      "          -2.6512e-02,  0.0000e+00,  4.8113e-01, -5.4996e-01,  0.0000e+00,\n",
      "          -8.9208e-01,  2.8161e-01,  8.3740e-02, -3.5802e-01, -4.7797e-01,\n",
      "           7.3716e-01, -3.1482e-02,  2.0063e-02,  0.0000e+00,  0.0000e+00,\n",
      "          -1.0983e+00, -9.8682e-01, -2.0766e+00,  1.9689e+00,  8.6542e-02,\n",
      "          -3.0426e-02,  3.5053e-02,  0.0000e+00,  9.7980e-01, -7.4703e-01,\n",
      "          -3.4086e-01, -2.7827e+00, -7.8381e-01,  1.2094e+00,  1.0124e+00,\n",
      "           3.0738e+00,  4.9428e-01, -1.4433e-01, -5.9388e-01,  0.0000e+00,\n",
      "           2.1649e+00, -1.1878e+00,  0.0000e+00,  1.8113e+00, -9.4675e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  1.2420e+00, -1.2213e-01,  0.0000e+00,\n",
      "          -5.7509e-01, -2.2925e+00,  6.8174e-01, -1.0740e+00, -4.7107e-01,\n",
      "           0.0000e+00, -5.7332e-01, -3.4111e-01,  7.9303e-01,  3.0445e-02,\n",
      "          -6.8409e-01, -1.0186e+00,  9.6641e-01, -2.4552e-01,  2.1691e+00,\n",
      "          -1.0827e+00, -4.2721e-01, -1.8436e+00, -5.0076e-01,  3.3807e-01,\n",
      "           7.0492e-01, -6.9649e-01, -6.2820e-01,  2.9230e-01,  0.0000e+00,\n",
      "          -1.1085e+00,  1.5814e+00, -6.1405e-01,  0.0000e+00, -2.9797e+00,\n",
      "           4.0349e+00,  5.8522e-01,  4.3333e-02, -1.5796e+00, -2.8683e-01,\n",
      "           7.4175e-01,  0.0000e+00, -3.0421e-01, -8.5216e-01,  1.1360e-02,\n",
      "           2.7541e-01,  2.7470e-01,  2.5237e-01,  2.6122e-01,  0.0000e+00,\n",
      "          -3.6564e-01, -1.5903e-01, -5.5382e-01, -5.2531e-02, -1.1467e+00,\n",
      "          -1.1313e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0380, 0.0306, 0.1030, 0.0558, 0.1531, 0.3163, 0.0692, 0.0718, 0.0629,\n",
      "         0.0992]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0183,  0.4030, -0.0100,  ...,  0.1343,  0.0970, -0.2327],\n",
      "        [ 0.2252,  0.2810, -0.3118,  ..., -0.1554,  0.2041, -0.2770],\n",
      "        [ 0.0501,  0.3627, -0.4266,  ..., -0.0533, -0.0559, -0.5428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2567,  0.1543, -0.3090,  0.0163, -0.0748, -0.1318, -0.0082,\n",
      "          -0.2526, -0.0035, -0.1605,  0.0313, -0.0873, -0.2893,  0.0013,\n",
      "           0.1797,  0.0081,  0.2066,  0.1385, -0.2740,  0.0807, -0.1518,\n",
      "          -0.2251,  0.1705,  0.1560, -0.3171, -0.2166,  0.0536, -0.2244,\n",
      "          -0.1003,  0.0193,  0.0730, -0.2726, -0.2103, -0.2455, -0.1108,\n",
      "          -0.0204, -0.2174, -0.1387, -0.2010, -0.0643, -0.1790,  0.0624,\n",
      "          -0.1932,  0.0532,  0.2379,  0.0779, -0.0309, -0.1618,  0.1607,\n",
      "          -0.0992, -0.0183, -0.0542, -0.3780, -0.1668, -0.0694,  0.0332,\n",
      "          -0.0649, -0.0055,  0.1834,  0.1612, -0.0113,  0.0406, -0.3505,\n",
      "           0.0008, -0.1893, -0.0294,  0.0060,  0.2066, -0.2234,  0.1375,\n",
      "          -0.0223,  0.1594, -0.0939,  0.2857, -0.0726,  0.0511,  0.1709,\n",
      "           0.1742,  0.0534,  0.2260, -0.1623, -0.2543, -0.2836,  0.0253,\n",
      "          -0.1661,  0.1732,  0.0594,  0.0011,  0.1411, -0.1319,  0.1382,\n",
      "          -0.0068, -0.0043, -0.0713, -0.0995,  0.1654,  0.1609,  0.2765,\n",
      "           0.0080,  0.3437, -0.1985, -0.0100,  0.2426,  0.2108, -0.0672,\n",
      "          -0.0546,  0.2177,  0.2979, -0.0087, -0.0087,  0.1720,  0.1356,\n",
      "          -0.0756, -0.3278, -0.1674,  0.0647, -0.1150, -0.0850, -0.2468,\n",
      "          -0.1835, -0.0138, -0.1604, -0.3239,  0.0500, -0.2564, -0.0796,\n",
      "           0.0987, -0.0618,  0.0867,  0.0494,  0.1767, -0.1806,  0.1298,\n",
      "           0.1473, -0.0267, -0.0559,  0.2140,  0.1940, -0.1894,  0.1685,\n",
      "          -0.1754,  0.3673, -0.3291,  0.1097,  0.1766, -0.1357,  0.1236,\n",
      "           0.3063,  0.0722,  0.2810, -0.4243,  0.0687, -0.2066,  0.1292,\n",
      "           0.0545,  0.3956, -0.1372,  0.1810,  0.0298, -0.1350, -0.0074,\n",
      "          -0.2160, -0.2749,  0.2990, -0.0756,  0.0567, -0.1338, -0.3042,\n",
      "           0.3070,  0.2725, -0.2308,  0.0264,  0.4150, -0.0553, -0.1551,\n",
      "          -0.3163,  0.0148,  0.1055,  0.3385, -0.0825, -0.3083, -0.1464,\n",
      "          -0.1198,  0.0838,  0.2629,  0.1398, -0.1746,  0.2321,  0.0952,\n",
      "          -0.1549,  0.0645,  0.0148, -0.3444, -0.1162,  0.1167, -0.2741,\n",
      "           0.0112, -0.0818, -0.1687,  0.1485, -0.1543,  0.1818, -0.0794,\n",
      "           0.0956, -0.0502, -0.1071, -0.0778,  0.2291, -0.0299, -0.1335,\n",
      "           0.0194, -0.1122, -0.0469,  0.1506, -0.1852,  0.2826, -0.1021,\n",
      "           0.0811, -0.1870,  0.2139,  0.1961, -0.1619,  0.2771, -0.1486,\n",
      "           0.0647,  0.2314, -0.0356, -0.2082, -0.3269,  0.2627, -0.1473,\n",
      "          -0.1837, -0.0765, -0.1520, -0.1090, -0.0602, -0.2564,  0.0494,\n",
      "           0.2724,  0.1169, -0.2847, -0.2494, -0.1695, -0.1268,  0.0403,\n",
      "          -0.1740, -0.2861, -0.2280,  0.1207,  0.0066,  0.1573,  0.0251,\n",
      "          -0.1663, -0.1894,  0.1074, -0.1461]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4744, -0.4592,  0.0000, -0.1177,  0.4618,  0.0255,  0.0000,\n",
      "           0.5340,  0.6705,  0.9336,  1.7084, -1.0165,  0.9469, -0.2517,\n",
      "          -1.6342,  0.5129,  1.8777, -0.7565, -1.5629, -2.6440, -1.1338,\n",
      "           0.0000,  0.0000,  0.5543, -0.1167,  3.2098,  1.8371,  0.5191,\n",
      "          -2.2263, -1.2855,  0.0000,  1.0135,  0.0000,  0.8604, -0.7988,\n",
      "          -1.4656,  0.6200, -0.7713,  0.0000,  0.1026,  0.0000, -2.2044,\n",
      "          -0.5665, -0.1153, -0.7131, -0.6896,  1.9281,  0.1099, -0.2868,\n",
      "          -1.8508,  1.4682,  0.4630,  0.6677, -0.2837,  0.5317,  0.2747,\n",
      "          -1.2422, -0.9515,  1.8144, -0.0117,  0.2047, -1.8181, -1.4018,\n",
      "          -0.8065,  1.1797,  0.2652, -0.1667, -0.2559, -0.0041, -0.4611,\n",
      "          -0.3252, -0.3243,  0.1475, -0.1270,  0.6587, -0.8065,  2.0662,\n",
      "           1.6801,  0.0877, -0.5465,  1.2271,  0.0873,  0.3270, -1.8366,\n",
      "          -0.0719, -1.7328, -1.4585, -0.8910,  0.6232,  0.8107, -1.2237,\n",
      "          -1.1444,  1.9854, -0.3658, -0.7340,  0.1564,  2.1421, -0.4055,\n",
      "          -0.3042, -1.8397, -1.2905, -0.7219, -0.7664,  0.2378,  0.3821,\n",
      "           1.1139, -1.0698,  2.2527, -0.2629, -0.2880, -0.0533,  0.6109,\n",
      "          -0.2552, -0.2803, -1.9425,  1.1283,  1.0061, -2.4982, -0.5746,\n",
      "           0.0298, -1.6955, -0.4012, -0.3798, -0.0789,  0.0000, -1.1117,\n",
      "           1.3054,  0.1701,  0.3224,  1.3585,  2.0800,  0.0000,  0.3588,\n",
      "          -0.7229,  0.4295,  0.0597,  0.3271, -2.1029, -0.4968, -1.6779,\n",
      "          -0.6422,  0.0000, -1.1872, -1.2156, -0.6314, -0.0410,  0.4650,\n",
      "           1.7385,  1.5939,  0.0000, -1.2628, -0.5774,  0.0000, -0.0395,\n",
      "           0.3269, -0.1165,  1.3541, -0.0311, -1.9007, -1.8060, -1.4271,\n",
      "          -0.9004, -0.7053, -0.3891, -0.9820, -0.1290,  0.4064,  0.9707,\n",
      "           0.5180, -0.1473,  1.5148,  0.0000, -0.3159, -2.0088,  0.1290,\n",
      "           0.0000, -0.8310, -0.7695, -0.0398, -0.9377,  0.7280,  1.0421,\n",
      "           0.0470,  0.4633,  0.3169, -0.1180, -0.5424, -0.6644,  0.7553,\n",
      "          -1.0645, -0.5864, -1.7885,  1.2674, -0.9267, -1.6149,  0.0000,\n",
      "          -1.1571, -1.9608, -0.0720,  0.0000,  2.6982, -0.9215, -2.6322,\n",
      "          -0.5862, -0.7168, -1.3862, -1.2539,  0.1720,  0.2184, -1.1113,\n",
      "           0.9454, -0.6920, -1.5198,  0.3625,  0.2370, -1.4271,  0.0000,\n",
      "           0.0471, -1.4801,  0.4277,  0.0133, -0.9019,  0.3008, -1.1656,\n",
      "          -1.3021, -0.1875,  1.2725,  1.2667,  0.0000, -0.0566,  1.7373,\n",
      "          -1.1752,  0.9564,  1.9991,  0.5268,  0.7901, -0.6785,  0.1047,\n",
      "          -0.6807, -2.2625,  0.0000, -0.3145, -1.0435, -0.3820, -1.0801,\n",
      "           0.5581,  1.5003,  0.0000, -1.3775,  1.2435,  0.5825,  1.7533,\n",
      "           1.9513,  0.3623,  0.4871,  0.3903]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0207, 0.2403, 0.1191, 0.0638, 0.1144, 0.1148, 0.0378, 0.1419, 0.0780,\n",
      "         0.0693]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0183,  0.4030, -0.0100,  ...,  0.1343,  0.0970, -0.2327],\n",
      "        [ 0.2252,  0.2810, -0.3118,  ..., -0.1554,  0.2041, -0.2770],\n",
      "        [ 0.0501,  0.3627, -0.4266,  ..., -0.0533, -0.0559, -0.5428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1709,  0.1365, -0.2364,  0.0893, -0.0014, -0.0674, -0.0781,\n",
      "          -0.1452,  0.0616, -0.0343, -0.0663,  0.0440, -0.2443, -0.0095,\n",
      "           0.0266, -0.0065,  0.2101,  0.1424, -0.0532,  0.0980, -0.1278,\n",
      "          -0.1717,  0.1048,  0.0368, -0.2849, -0.0766,  0.1722, -0.1629,\n",
      "          -0.0232,  0.0258,  0.0851, -0.2913, -0.1241, -0.1785, -0.0203,\n",
      "          -0.0148, -0.1771, -0.1441, -0.1520, -0.0905, -0.2322,  0.1193,\n",
      "          -0.0782,  0.0708,  0.1999, -0.0776,  0.0361, -0.0622,  0.1360,\n",
      "           0.0387,  0.0388,  0.0492, -0.3256, -0.1769, -0.0812,  0.0642,\n",
      "          -0.0532, -0.1666,  0.1087, -0.0094, -0.1133,  0.0090, -0.1956,\n",
      "          -0.0935, -0.1301, -0.0749,  0.1152,  0.1404, -0.1819,  0.0956,\n",
      "          -0.0558,  0.0228, -0.0319,  0.3301,  0.0260, -0.0638,  0.1435,\n",
      "           0.0097,  0.0767,  0.1598, -0.1008, -0.0986, -0.1793,  0.0899,\n",
      "          -0.1428,  0.0262,  0.0393, -0.0579,  0.0277, -0.0483, -0.0015,\n",
      "           0.0660, -0.0630, -0.1624, -0.0367,  0.0917,  0.0483,  0.1533,\n",
      "           0.1051,  0.2721, -0.1859, -0.1444,  0.1304,  0.1927,  0.0367,\n",
      "           0.0184,  0.2178,  0.1839,  0.0224, -0.0371,  0.1368,  0.1350,\n",
      "          -0.1084, -0.1578, -0.0516,  0.0788, -0.0928, -0.0109, -0.2598,\n",
      "          -0.0601, -0.0120,  0.0005, -0.1420, -0.0042, -0.1874,  0.0043,\n",
      "           0.1241, -0.0055,  0.0233,  0.1596,  0.0611,  0.0754, -0.0838,\n",
      "          -0.0164, -0.0007, -0.0520,  0.1114,  0.1180, -0.0078,  0.0118,\n",
      "          -0.1189,  0.2610, -0.3045,  0.0683,  0.0863, -0.0776,  0.0582,\n",
      "           0.2517,  0.0269,  0.2098, -0.2459, -0.0225, -0.1821,  0.1031,\n",
      "          -0.0407,  0.2934, -0.1288,  0.1892, -0.1086, -0.0836,  0.0329,\n",
      "          -0.1950, -0.1436,  0.1102, -0.1443, -0.0249, -0.1701, -0.2927,\n",
      "           0.2671,  0.1053, -0.1864,  0.0351,  0.3189, -0.1108, -0.0974,\n",
      "          -0.2967,  0.0701,  0.0696,  0.2591,  0.0063, -0.2319, -0.0888,\n",
      "          -0.0024,  0.0908,  0.1634, -0.0026, -0.0652,  0.0764, -0.0963,\n",
      "          -0.1568,  0.1555, -0.0282, -0.1597, -0.0603,  0.1133, -0.2577,\n",
      "           0.0497, -0.1033,  0.0017, -0.0073, -0.2161,  0.1129, -0.0874,\n",
      "          -0.0027, -0.1465,  0.0629, -0.1774,  0.1755,  0.1185, -0.0719,\n",
      "          -0.1127, -0.0426, -0.0054, -0.0215, -0.2695,  0.1867, -0.0142,\n",
      "          -0.0132, -0.0343,  0.1400,  0.0951, -0.0127,  0.1448, -0.0745,\n",
      "          -0.0628,  0.1013, -0.0751, -0.0671, -0.2730,  0.1029,  0.0396,\n",
      "          -0.1513, -0.0010, -0.0353, -0.0402, -0.0059, -0.2626,  0.0798,\n",
      "           0.2868,  0.0504, -0.1866, -0.1022, -0.0111, -0.0764,  0.1441,\n",
      "          -0.2239, -0.2281, -0.1763,  0.0129, -0.1290,  0.1722, -0.0272,\n",
      "          -0.1259, -0.1477,  0.1100, -0.1898]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00, -6.9769e-02, -1.8077e+00,  1.3219e+00,  5.1597e-01,\n",
      "          -3.7631e-01,  1.1641e-03, -7.2311e-01,  2.1179e+00, -2.1398e-01,\n",
      "           2.8234e-01,  8.3074e-01,  0.0000e+00,  1.9995e-01,  3.1212e-01,\n",
      "           3.5185e-01, -6.8298e-01,  1.6894e-01,  8.7463e-01,  5.4558e-01,\n",
      "           1.8835e+00,  6.0178e-01, -3.6585e-02, -5.3536e-01, -1.0001e-01,\n",
      "           6.5093e-01, -1.6088e+00, -1.3623e+00, -2.1268e+00, -1.0343e+00,\n",
      "           3.8979e-02, -1.4547e+00, -2.0765e+00,  3.1563e-01, -2.8498e-01,\n",
      "          -2.0018e+00,  2.1900e-01,  9.9703e-01,  6.0104e-01,  9.5368e-01,\n",
      "          -2.2533e-01, -2.2112e+00, -7.0632e-01,  1.3962e+00,  8.9525e-02,\n",
      "          -1.1388e+00,  2.4258e-01,  7.4197e-01, -7.0974e-01, -1.3360e+00,\n",
      "           1.6088e+00, -1.3722e-01,  6.6291e-01,  0.0000e+00,  0.0000e+00,\n",
      "           3.3327e-01, -4.4972e-01, -8.8822e-01,  1.3380e-01,  6.2856e-01,\n",
      "          -7.0515e-01,  5.6382e-01, -6.9321e-01, -1.5473e+00,  2.8953e-01,\n",
      "           9.5650e-02, -1.7758e-01,  5.9477e-01, -2.1384e+00,  5.5976e-01,\n",
      "           1.8298e-01, -5.1241e-01, -3.4120e-01, -1.1319e+00, -6.4733e-01,\n",
      "           0.0000e+00, -1.0494e+00,  1.1894e-01,  5.1718e-01, -1.8669e-01,\n",
      "          -3.8493e-01,  2.1582e+00,  0.0000e+00, -8.4550e-01,  3.9777e-01,\n",
      "           4.1922e-01,  1.6044e+00, -5.6417e-01,  0.0000e+00, -1.4906e+00,\n",
      "           4.0426e-01, -3.5163e-01,  4.9395e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6292e-01,  1.3204e+00, -9.0761e-01,  2.3907e+00,  9.5528e-01,\n",
      "          -1.2010e+00,  5.9435e-01,  1.0665e+00, -1.7337e+00,  3.6542e-01,\n",
      "           4.0226e-01,  0.0000e+00,  4.5507e-01,  1.9688e+00,  0.0000e+00,\n",
      "          -8.3220e-01,  5.3378e-01,  8.0824e-01,  0.0000e+00, -1.0548e+00,\n",
      "           9.1761e-01, -7.0276e-01, -8.4514e-01,  2.5769e-01,  8.7989e-01,\n",
      "          -8.7678e-01, -1.3968e+00, -3.6504e-01, -1.8464e+00, -1.3008e+00,\n",
      "           1.0693e+00, -8.1157e-01,  6.4928e-01,  2.5564e-01, -1.4893e+00,\n",
      "           2.5025e+00,  3.7793e-01,  0.0000e+00,  7.2247e-01,  3.2012e+00,\n",
      "          -7.5272e-01, -3.8355e-01,  1.2822e+00,  2.2524e+00,  1.9400e-01,\n",
      "          -3.9287e-02,  3.0302e+00,  3.6270e-01, -1.8690e-01, -1.1119e+00,\n",
      "           1.2472e+00,  7.7551e-01, -7.7458e-01, -4.4904e-02, -1.3871e+00,\n",
      "           2.3359e+00,  7.6476e-01,  0.0000e+00, -2.1307e+00, -5.8166e-01,\n",
      "           7.8583e-01, -1.8620e+00, -1.3047e+00,  1.9014e-01,  0.0000e+00,\n",
      "          -1.8686e+00,  1.1506e+00, -8.5953e-01,  9.5971e-01, -1.4614e+00,\n",
      "          -2.7020e-02,  1.9744e+00,  1.1271e+00, -4.8595e-01, -1.2414e+00,\n",
      "          -2.1200e-01, -1.3225e+00, -1.6392e+00, -7.7184e-01,  6.8262e-01,\n",
      "          -1.3796e+00, -1.2611e-01,  6.0671e-01, -7.4873e-01,  2.5931e-01,\n",
      "           1.3325e+00, -2.5535e+00,  0.0000e+00, -5.8377e-01,  1.6236e+00,\n",
      "          -1.2403e+00, -1.7411e-03, -5.0266e-02,  9.0130e-01,  5.6544e-01,\n",
      "          -4.1999e-01,  3.8807e-01, -1.1597e-01,  8.0970e-01,  1.0503e+00,\n",
      "          -7.8913e-01, -1.4389e+00, -4.1599e-01, -7.5044e-01, -4.5422e-01,\n",
      "          -5.4743e-01,  7.2230e-01, -1.8535e+00,  1.3574e+00,  8.3772e-01,\n",
      "          -1.5239e+00, -3.5885e-01,  6.4781e-01,  2.0070e-01,  0.0000e+00,\n",
      "           8.3545e-01, -1.2913e+00, -1.2839e+00,  2.6129e-01, -1.5633e+00,\n",
      "           2.0757e+00,  1.3425e-01,  0.0000e+00, -3.1168e-02, -5.7938e-01,\n",
      "           0.0000e+00,  1.9011e+00,  0.0000e+00,  1.4694e+00,  8.0502e-01,\n",
      "           3.6903e-01,  6.6984e-01, -7.0062e-01,  8.9210e-02,  1.0256e+00,\n",
      "           9.7814e-01, -1.4085e+00,  6.5975e-01, -1.1449e+00, -1.6456e+00,\n",
      "          -6.0017e-01,  8.8659e-03, -7.1098e-01,  3.7059e-01, -2.2413e-01,\n",
      "          -7.5231e-01,  0.0000e+00,  5.3066e-01, -6.6347e-01,  1.5465e+00,\n",
      "           5.7833e-01,  1.8920e+00, -8.6422e-01,  4.9342e-01, -3.8731e-01,\n",
      "           5.0012e-01, -9.7523e-01,  1.7728e+00,  0.0000e+00, -8.0788e-01,\n",
      "          -6.2185e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0682, 0.1474, 0.1278, 0.1212, 0.0833, 0.1733, 0.0719, 0.0619, 0.0588,\n",
      "         0.0863]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0183,  0.4030, -0.0100,  ...,  0.1343,  0.0970, -0.2327],\n",
      "        [ 0.2252,  0.2810, -0.3118,  ..., -0.1554,  0.2041, -0.2770],\n",
      "        [ 0.0501,  0.3627, -0.4266,  ..., -0.0533, -0.0559, -0.5428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.7449e-01,  1.5099e-01, -2.4749e-01,  8.4375e-02, -1.2289e-02,\n",
      "          -5.9542e-02, -4.9470e-02, -1.7135e-01,  3.5724e-02, -7.4863e-02,\n",
      "          -3.6944e-02,  7.1133e-03, -2.5925e-01, -1.8400e-02,  6.3239e-02,\n",
      "           8.9175e-03,  2.3808e-01,  1.2901e-01, -8.8170e-02,  1.1606e-01,\n",
      "          -1.4665e-01, -1.8039e-01,  1.1372e-01,  9.1887e-02, -3.0431e-01,\n",
      "          -1.4884e-01,  1.2344e-01, -1.7528e-01, -4.0896e-02,  1.0226e-02,\n",
      "           3.2515e-02, -2.7846e-01, -1.4948e-01, -1.5712e-01, -6.6227e-02,\n",
      "          -2.9746e-02, -1.8144e-01, -1.4950e-01, -1.5481e-01, -1.2398e-01,\n",
      "          -2.4272e-01,  7.8026e-02, -1.2289e-01,  5.5706e-02,  2.4732e-01,\n",
      "          -6.3738e-02,  1.5224e-02, -5.5346e-02,  1.3435e-01, -9.7050e-04,\n",
      "           4.3023e-02,  3.1482e-02, -3.4736e-01, -1.8753e-01, -7.7411e-02,\n",
      "           3.7955e-02, -5.2834e-02, -1.4087e-01,  1.4205e-01,  3.6019e-02,\n",
      "          -7.7869e-02,  6.5120e-02, -2.3565e-01, -9.5904e-02, -1.3201e-01,\n",
      "          -4.8328e-02,  1.3174e-01,  1.3292e-01, -1.8345e-01,  9.0667e-02,\n",
      "          -8.1924e-02,  3.9357e-02, -6.4087e-02,  3.1566e-01,  1.4401e-02,\n",
      "          -5.3889e-02,  1.3631e-01,  4.8470e-02,  6.9953e-02,  1.7574e-01,\n",
      "          -1.2272e-01, -1.7127e-01, -1.8132e-01,  6.4219e-02, -1.5359e-01,\n",
      "           8.7123e-02,  4.1939e-02, -6.2947e-02,  3.4383e-02, -9.3207e-02,\n",
      "           4.6914e-02,  4.9167e-02, -2.1961e-02, -1.2605e-01, -7.5971e-02,\n",
      "           9.4873e-02,  9.0030e-02,  2.0597e-01,  6.2484e-02,  2.8694e-01,\n",
      "          -1.9130e-01, -1.3921e-01,  1.9391e-01,  1.9160e-01, -8.1850e-03,\n",
      "           5.4027e-03,  2.1440e-01,  1.9472e-01,  2.1186e-02, -8.2186e-02,\n",
      "           1.5393e-01,  1.3654e-01, -1.1644e-01, -2.2252e-01, -7.6657e-02,\n",
      "           6.9197e-02, -1.2431e-01, -4.2822e-02, -2.4890e-01, -1.1076e-01,\n",
      "          -2.1430e-02, -4.9216e-02, -1.9533e-01,  3.6391e-03, -1.8849e-01,\n",
      "          -3.6614e-02,  1.3780e-01, -2.2433e-02,  2.0284e-02,  1.5140e-01,\n",
      "           1.1087e-01, -1.2847e-02, -2.0848e-02,  2.0499e-02,  5.2243e-03,\n",
      "          -6.5081e-02,  1.2538e-01,  1.3906e-01, -6.4407e-02,  5.7253e-02,\n",
      "          -1.1665e-01,  3.1526e-01, -3.2835e-01,  8.6617e-02,  1.1023e-01,\n",
      "          -8.8490e-02,  8.3173e-02,  2.5364e-01,  8.4695e-03,  2.4305e-01,\n",
      "          -2.6643e-01, -2.5954e-02, -1.9516e-01,  8.3286e-02, -3.5806e-02,\n",
      "           3.2129e-01, -1.5020e-01,  1.7385e-01, -6.5241e-02, -9.5571e-02,\n",
      "           3.9830e-02, -2.0940e-01, -1.6931e-01,  1.4646e-01, -1.1582e-01,\n",
      "          -2.2329e-02, -1.4812e-01, -3.0167e-01,  2.9259e-01,  1.8856e-01,\n",
      "          -1.8025e-01,  4.1149e-03,  3.6402e-01, -1.0937e-01, -1.4002e-01,\n",
      "          -3.1559e-01,  5.7317e-02,  6.2903e-02,  2.6027e-01, -4.1217e-03,\n",
      "          -2.5932e-01, -1.2155e-01, -8.2127e-03,  1.0674e-01,  1.7841e-01,\n",
      "           5.2204e-02, -9.3294e-02,  1.3413e-01, -7.0184e-03, -1.2595e-01,\n",
      "           1.1025e-01, -4.8744e-02, -2.3122e-01, -7.5407e-02,  1.2999e-01,\n",
      "          -2.4023e-01,  5.2851e-02, -1.2514e-01, -4.7272e-02,  5.7518e-02,\n",
      "          -2.3028e-01,  1.3425e-01, -7.9579e-02, -3.3300e-04, -1.1022e-01,\n",
      "           6.8688e-03, -1.5417e-01,  1.3833e-01,  7.4051e-02, -8.3319e-02,\n",
      "          -5.3671e-02, -4.7206e-02, -3.6763e-02,  2.4413e-02, -2.4156e-01,\n",
      "           2.2157e-01, -5.5322e-02, -3.5664e-03, -7.7663e-02,  1.7411e-01,\n",
      "           1.1476e-01, -8.2664e-02,  1.6536e-01, -9.7594e-02, -6.0778e-02,\n",
      "           1.4767e-01, -8.7681e-02, -1.0852e-01, -2.3780e-01,  1.7447e-01,\n",
      "          -2.6878e-02, -1.5446e-01, -1.3276e-02, -3.6999e-02, -6.0726e-02,\n",
      "          -1.2706e-02, -2.5068e-01,  7.6557e-02,  2.5445e-01,  6.0993e-02,\n",
      "          -2.4146e-01, -1.2638e-01, -5.7650e-02, -1.3762e-01,  1.0452e-01,\n",
      "          -2.1603e-01, -2.3908e-01, -1.6375e-01,  4.8475e-02, -6.1057e-02,\n",
      "           1.7424e-01,  2.7533e-03, -1.2640e-01, -1.4292e-01,  9.2040e-02,\n",
      "          -1.8885e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1419, -1.3596, -0.6633,  1.6815,  2.4830,  0.0000,  1.3995,\n",
      "          -0.9368, -0.7142, -0.2962, -0.5820, -0.2200,  2.5559, -1.0551,\n",
      "           0.0000,  0.2161,  0.3039,  0.0000,  0.9577,  0.2220, -1.5414,\n",
      "          -1.1544,  0.0000, -1.8147, -0.3955,  1.5210,  1.7255,  0.0000,\n",
      "          -0.2971,  0.0000, -1.4559,  0.0000, -0.6737,  0.0000,  0.0000,\n",
      "           0.6830, -1.4604,  2.1383,  0.1804,  0.0000,  0.3991, -0.1961,\n",
      "           1.3082,  0.8320,  1.4219,  0.3938,  0.3494,  0.1076, -1.1250,\n",
      "          -0.8446,  0.6895,  0.9794, -2.5885,  1.2124,  1.6781,  0.2128,\n",
      "           0.0178,  1.0910,  1.0114,  1.4963, -0.8581, -1.2765, -2.4445,\n",
      "           0.0000, -0.8670, -0.1022,  0.3198, -1.1791,  1.1061, -0.3298,\n",
      "          -0.4427,  0.4201,  0.0000, -1.3155,  1.7190,  1.4826, -0.6504,\n",
      "           2.5033, -0.3946, -0.8124,  0.8008,  0.3516, -0.0583, -1.1617,\n",
      "          -0.6169, -2.7815,  0.0000, -0.0543, -1.7540,  0.2434, -0.1546,\n",
      "          -0.5269, -1.8710,  1.9172,  1.0335, -0.8282,  0.0978, -0.2966,\n",
      "          -0.1612, -1.0472, -1.1854,  0.0130, -0.0581, -0.2458,  0.1053,\n",
      "           0.0000,  0.0000,  2.2528,  0.4401,  0.1307,  0.2423,  0.5217,\n",
      "          -0.3204,  0.2415, -0.0770,  0.0000,  1.5987, -0.2630, -0.7201,\n",
      "          -0.2745, -0.2474,  1.7815,  0.6797, -0.6455,  0.0191,  0.6758,\n",
      "          -1.3010, -0.1075,  0.0000, -0.9822,  1.2400, -1.1601,  0.0000,\n",
      "           0.0000, -2.3546,  0.0000, -3.4683, -0.9829,  1.4212, -1.0900,\n",
      "           0.5350,  0.0000,  0.4640,  0.0000,  1.3428, -0.8939,  2.4420,\n",
      "          -0.3704, -1.5685, -0.7333, -0.8485, -0.5474, -2.5834,  0.9101,\n",
      "          -0.3374, -0.7973,  0.0000,  0.9333, -0.4491, -1.7377,  0.6847,\n",
      "           0.0000,  0.9739,  0.2742,  0.4457, -2.8163,  0.1089,  0.0000,\n",
      "          -0.1290,  0.5758, -0.1558, -1.2321, -0.6540, -0.1765, -0.1687,\n",
      "          -0.5095, -0.7967, -0.1947,  0.9824,  0.1116,  1.1967, -0.1845,\n",
      "          -0.7671,  0.3473, -2.4944,  0.0000,  0.9574, -0.9258, -0.1133,\n",
      "           0.5711,  0.1741,  2.1622, -0.6163,  1.3764, -0.0819, -0.5877,\n",
      "           1.7684,  0.3901, -0.1345,  0.0000, -0.4709, -1.1040, -1.6427,\n",
      "           1.4439,  0.0000,  0.1423,  0.0917, -0.6064, -1.1034, -1.2551,\n",
      "          -0.6821, -1.8652,  2.1895, -1.7824,  0.7082, -0.9349, -1.7239,\n",
      "          -1.9957, -1.1668, -0.4402,  0.0801, -0.7354, -1.3406, -0.3617,\n",
      "           0.0958,  0.3168, -1.1970, -1.2607, -1.4066,  0.3964, -0.3269,\n",
      "          -1.5161,  1.1266,  0.0000, -0.0694,  0.0000,  0.0000, -0.6049,\n",
      "          -0.6455,  0.5978,  0.0848,  0.8710,  0.0000, -1.8476,  0.0607,\n",
      "           0.5828,  0.6049,  1.2978, -0.4212, -1.1536, -1.6780, -1.5688,\n",
      "          -1.2525, -0.0130,  0.3591, -0.4896]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0764, 0.1663, 0.1484, 0.0459, 0.1108, 0.1788, 0.0704, 0.0815, 0.0867,\n",
      "         0.0348]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0183,  0.4030, -0.0100,  ...,  0.1343,  0.0970, -0.2327],\n",
      "        [ 0.2252,  0.2810, -0.3118,  ..., -0.1554,  0.2041, -0.2770],\n",
      "        [ 0.0501,  0.3627, -0.4266,  ..., -0.0533, -0.0559, -0.5428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9126e-01,  1.7777e-01, -2.6728e-01,  8.4949e-02, -2.4638e-02,\n",
      "          -8.9160e-02, -5.7629e-02, -1.8856e-01,  7.1364e-02, -7.1304e-02,\n",
      "          -3.4743e-02, -7.3271e-03, -2.5099e-01, -1.8770e-02,  6.2934e-02,\n",
      "          -2.4886e-02,  2.2356e-01,  1.4987e-01, -8.1825e-02,  1.1834e-01,\n",
      "          -1.6311e-01, -1.9371e-01,  1.3228e-01,  7.2913e-02, -2.9400e-01,\n",
      "          -1.3843e-01,  1.4278e-01, -1.8918e-01, -4.6287e-02, -2.4670e-04,\n",
      "           6.5583e-02, -2.8882e-01, -1.3411e-01, -1.7393e-01, -5.2826e-02,\n",
      "          -2.8851e-03, -2.1505e-01, -1.6560e-01, -1.8877e-01, -1.0262e-01,\n",
      "          -2.4322e-01,  9.4116e-02, -1.3645e-01,  6.4878e-02,  2.3321e-01,\n",
      "          -3.9060e-02, -4.1193e-03, -7.3145e-02,  1.5769e-01,  2.2851e-02,\n",
      "           3.2100e-02,  3.7821e-02, -3.4160e-01, -1.6704e-01, -7.7236e-02,\n",
      "           7.2661e-02, -5.9622e-02, -1.2944e-01,  1.4214e-01,  3.0289e-02,\n",
      "          -1.0960e-01,  3.9943e-02, -2.2130e-01, -7.3721e-02, -1.4002e-01,\n",
      "          -5.1114e-02,  1.1522e-01,  1.5761e-01, -1.8543e-01,  1.2311e-01,\n",
      "          -5.6640e-02,  4.4686e-02, -6.0419e-02,  3.4833e-01, -8.2476e-03,\n",
      "          -3.7874e-02,  1.6808e-01,  3.8750e-02,  6.3535e-02,  1.8335e-01,\n",
      "          -1.1385e-01, -1.5663e-01, -2.1031e-01,  7.1298e-02, -1.2639e-01,\n",
      "           7.6269e-02,  5.0141e-02, -6.5199e-02,  4.1524e-02, -7.0683e-02,\n",
      "           4.0228e-02,  7.3449e-02, -5.9255e-02, -1.5999e-01, -6.6067e-02,\n",
      "           9.1928e-02,  1.0215e-01,  1.9025e-01,  6.4344e-02,  3.0878e-01,\n",
      "          -2.1455e-01, -1.3227e-01,  1.8027e-01,  1.8246e-01, -1.1684e-03,\n",
      "           2.0042e-02,  2.3984e-01,  2.1752e-01,  2.4600e-02, -4.5455e-02,\n",
      "           1.5152e-01,  1.2689e-01, -9.7815e-02, -2.2265e-01, -8.9043e-02,\n",
      "           7.7255e-02, -9.8356e-02, -3.9677e-02, -2.6287e-01, -9.8016e-02,\n",
      "          -1.5354e-02, -3.2534e-02, -1.8878e-01,  2.1262e-02, -1.9594e-01,\n",
      "          -1.3981e-02,  1.4334e-01, -3.0977e-02,  4.3218e-02,  1.3316e-01,\n",
      "           1.0226e-01, -9.6596e-03, -3.6243e-02,  3.4142e-02, -1.6815e-02,\n",
      "          -4.8775e-02,  1.3712e-01,  1.3479e-01, -7.3180e-02,  3.8262e-02,\n",
      "          -1.1959e-01,  3.1001e-01, -3.2108e-01,  9.9370e-02,  1.0566e-01,\n",
      "          -7.4395e-02,  5.7579e-02,  2.9027e-01,  2.1617e-02,  2.6334e-01,\n",
      "          -2.7103e-01, -1.3872e-02, -1.9694e-01,  1.1065e-01, -2.5390e-02,\n",
      "           3.2205e-01, -1.3353e-01,  1.8439e-01, -9.7226e-02, -1.0099e-01,\n",
      "           1.1400e-02, -2.2382e-01, -1.9434e-01,  1.5817e-01, -1.2561e-01,\n",
      "          -9.4358e-03, -1.5205e-01, -3.0233e-01,  2.9734e-01,  1.8248e-01,\n",
      "          -1.9410e-01,  9.1340e-03,  3.5411e-01, -1.0987e-01, -1.4229e-01,\n",
      "          -3.2221e-01,  4.8596e-02,  7.0837e-02,  2.7264e-01, -8.5643e-03,\n",
      "          -2.6426e-01, -1.0327e-01, -4.1976e-02,  1.0429e-01,  1.7854e-01,\n",
      "           4.6987e-02, -1.1449e-01,  1.1638e-01, -4.5658e-02, -1.5898e-01,\n",
      "           1.0686e-01, -2.8413e-02, -2.4902e-01, -8.5520e-02,  1.1491e-01,\n",
      "          -2.6198e-01,  3.9996e-02, -1.0784e-01, -4.1409e-02,  2.7589e-02,\n",
      "          -2.1845e-01,  1.2804e-01, -1.1207e-01,  1.1533e-02, -9.9122e-02,\n",
      "           9.6348e-03, -1.9399e-01,  1.7473e-01,  9.5764e-02, -9.7828e-02,\n",
      "          -8.6076e-02, -7.2762e-02, -2.2898e-02,  2.0720e-02, -2.5827e-01,\n",
      "           2.2239e-01, -6.0355e-02, -1.9005e-03, -8.3648e-02,  1.6905e-01,\n",
      "           1.2586e-01, -7.3727e-02,  1.5071e-01, -9.2894e-02, -3.3429e-02,\n",
      "           1.3492e-01, -6.6643e-02, -1.1423e-01, -2.7832e-01,  1.6112e-01,\n",
      "          -2.5865e-02, -1.3953e-01, -7.3544e-03, -6.4464e-02, -4.4884e-02,\n",
      "          -3.6103e-04, -2.6068e-01,  7.6418e-02,  3.0965e-01,  7.5277e-02,\n",
      "          -2.3155e-01, -1.1898e-01, -5.6360e-02, -9.8345e-02,  1.4639e-01,\n",
      "          -2.2834e-01, -2.5349e-01, -1.7108e-01,  4.4150e-02, -8.4252e-02,\n",
      "           2.0371e-01, -5.1469e-03, -1.4660e-01, -1.4329e-01,  1.0274e-01,\n",
      "          -1.9588e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.9107e-01, -4.6642e-01,  9.6357e-01, -8.3927e-01,  8.7068e-01,\n",
      "           9.1402e-01,  8.7576e-02, -2.8570e+00, -5.9767e-01,  1.3244e+00,\n",
      "          -9.0206e-01, -4.6378e-01,  6.6379e-01, -1.1136e+00,  0.0000e+00,\n",
      "          -1.2793e+00,  4.4054e-01, -3.5115e-01,  1.3372e+00,  1.1846e+00,\n",
      "           1.6804e+00,  7.1466e-01, -8.5848e-02,  9.2043e-02,  0.0000e+00,\n",
      "          -4.3797e-01,  3.0013e-01,  4.3951e-02,  1.3875e-01,  1.1357e+00,\n",
      "           5.7037e-01, -6.3348e-01, -1.6761e-03,  3.8928e-02,  0.0000e+00,\n",
      "           4.5385e-01, -1.4476e+00, -5.2348e-02,  1.7894e-01,  4.2610e-01,\n",
      "           5.9428e-01, -8.9285e-01,  1.4110e-01,  6.7766e-01,  2.3106e+00,\n",
      "          -7.6496e-01, -2.0306e-01,  2.5938e-01,  0.0000e+00,  4.7922e-01,\n",
      "          -1.4574e+00, -7.9550e-01,  2.8155e-01, -3.7546e-01,  1.5074e-01,\n",
      "           7.2012e-01,  0.0000e+00,  0.0000e+00,  7.0544e-02, -1.0432e+00,\n",
      "          -9.6305e-01, -8.8839e-01, -4.7364e-01, -1.3386e+00, -1.2853e-01,\n",
      "           1.3107e+00,  2.3109e+00, -5.9727e-01, -2.2196e+00,  1.4457e+00,\n",
      "          -1.7459e-01,  6.1635e-01, -3.6940e-01, -3.9079e-01,  6.6080e-02,\n",
      "           1.0389e+00,  4.6325e-01,  1.2015e+00,  2.2851e-02, -9.4583e-01,\n",
      "           0.0000e+00,  5.5800e-01, -1.7168e-01, -3.9620e-01, -2.3514e-01,\n",
      "           8.9840e-01, -1.2061e+00, -1.7387e+00,  7.4844e-01, -2.1868e+00,\n",
      "          -6.4594e-02, -1.2183e+00,  2.9853e-01,  2.1012e+00, -3.1158e-01,\n",
      "          -3.9358e+00, -2.9650e-03, -1.1896e+00, -8.9175e-01,  4.7092e-01,\n",
      "           0.0000e+00, -4.3819e-01, -2.1662e+00, -2.7372e-01,  5.8276e-01,\n",
      "           0.0000e+00,  2.1234e-01,  1.9601e-01,  3.2239e+00,  1.2392e+00,\n",
      "           7.9626e-01,  1.6931e+00, -1.2098e+00, -2.6895e-02,  3.1566e+00,\n",
      "          -2.4003e+00,  0.0000e+00,  1.3293e+00, -4.0906e-01, -2.6590e-03,\n",
      "          -3.6326e-01,  4.3994e-01, -1.2566e+00,  1.3665e-01,  4.6730e-01,\n",
      "          -9.2945e-01,  2.3132e-01,  3.5407e-02, -3.7469e-01, -1.1572e+00,\n",
      "           1.9792e+00,  7.9193e-01, -1.9984e+00,  1.1088e+00,  1.0319e+00,\n",
      "          -6.3548e-01,  9.5865e-01, -1.5515e+00,  1.1256e+00, -4.1253e-01,\n",
      "           4.8499e-01, -1.2540e+00, -1.3177e+00, -9.7012e-02,  6.2859e-01,\n",
      "          -5.5024e-01, -3.7474e-01, -8.3355e-01,  1.3559e+00,  0.0000e+00,\n",
      "          -2.6338e+00,  2.1763e-02, -1.3801e+00,  7.2985e-01,  1.0415e+00,\n",
      "          -7.1813e-01, -1.2860e+00,  3.6273e-02, -7.7351e-01,  0.0000e+00,\n",
      "           9.4244e-01,  0.0000e+00,  8.8261e-01,  2.2506e+00,  0.0000e+00,\n",
      "          -1.1997e+00, -1.1303e-01,  1.4086e-01,  0.0000e+00,  1.7551e+00,\n",
      "           3.9297e-01,  1.5914e+00,  6.7798e-01, -3.0351e-01,  2.3714e+00,\n",
      "          -1.0865e+00,  1.4916e+00,  5.5409e-01, -2.3599e-01,  2.5831e+00,\n",
      "           2.4167e-01,  4.0050e-01,  1.4425e-01,  0.0000e+00,  9.1355e-01,\n",
      "          -1.9180e+00, -5.5538e-01, -1.0586e-01,  0.0000e+00, -1.3054e+00,\n",
      "           6.0950e-01,  9.9263e-01,  1.4223e+00, -3.9611e-01, -2.2334e+00,\n",
      "          -1.3968e+00,  1.2419e-01, -1.4215e-01,  3.5556e-01,  6.3984e-01,\n",
      "          -2.1815e+00,  0.0000e+00,  0.0000e+00,  2.4670e+00, -5.0968e-01,\n",
      "          -1.4190e+00, -1.7025e+00,  1.7270e-01, -1.3231e+00,  8.7941e-01,\n",
      "          -4.9054e-01, -5.2343e-01, -9.4550e-01,  4.5732e-02,  4.7162e-01,\n",
      "          -4.0514e-01,  1.4855e+00, -6.0866e-01, -1.8687e+00, -3.2970e-01,\n",
      "          -2.9145e+00,  1.5513e+00, -2.8592e-01, -5.6139e-01,  8.4455e-01,\n",
      "           1.2985e+00, -8.0506e-01,  2.1939e+00,  9.0460e-01, -7.0831e-01,\n",
      "           1.1775e+00,  3.6984e+00,  0.0000e+00,  0.0000e+00, -4.8888e-01,\n",
      "          -4.7915e-01,  1.3951e+00, -6.8076e-01,  0.0000e+00, -2.3967e-01,\n",
      "           1.4011e+00, -1.9629e+00,  9.6964e-01,  0.0000e+00,  8.5012e-01,\n",
      "          -7.1845e-01,  1.9289e-01, -7.8286e-01,  3.8198e-02, -1.3474e+00,\n",
      "           3.3599e-01, -1.5546e+00,  1.2522e+00,  1.9230e+00,  3.9609e-01,\n",
      "           2.3642e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0564, 0.1231, 0.1301, 0.0850, 0.0967, 0.1012, 0.0766, 0.0808, 0.1206,\n",
      "         0.1296]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0183,  0.4030, -0.0100,  ...,  0.1343,  0.0970, -0.2327],\n",
      "        [ 0.2252,  0.2810, -0.3118,  ..., -0.1554,  0.2041, -0.2770],\n",
      "        [ 0.0501,  0.3627, -0.4266,  ..., -0.0533, -0.0559, -0.5428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1304,  0.1156, -0.1929,  0.0695,  0.0091, -0.0299, -0.0534,\n",
      "          -0.1280,  0.0353, -0.0574, -0.0420,  0.0314, -0.2086, -0.0068,\n",
      "           0.0388,  0.0059,  0.1899,  0.1172, -0.0542,  0.0938, -0.1131,\n",
      "          -0.1361,  0.0933,  0.0603, -0.2438, -0.1020,  0.1301, -0.1416,\n",
      "          -0.0183,  0.0211,  0.0295, -0.2143, -0.1106, -0.1277, -0.0524,\n",
      "          -0.0387, -0.1486, -0.1203, -0.1136, -0.0958, -0.2053,  0.0808,\n",
      "          -0.0904,  0.0474,  0.1902, -0.0577,  0.0220, -0.0230,  0.1168,\n",
      "           0.0076,  0.0584,  0.0443, -0.2774, -0.1465, -0.0556,  0.0375,\n",
      "          -0.0460, -0.1357,  0.1138, -0.0047, -0.0687,  0.0488, -0.1765,\n",
      "          -0.0841, -0.1136, -0.0395,  0.1152,  0.1048, -0.1461,  0.0801,\n",
      "          -0.0651,  0.0236, -0.0536,  0.2648,  0.0255, -0.0390,  0.1125,\n",
      "           0.0270,  0.0665,  0.1352, -0.0863, -0.1039, -0.1365,  0.0547,\n",
      "          -0.1208,  0.0598,  0.0434, -0.0545,  0.0192, -0.0536,  0.0223,\n",
      "           0.0491, -0.0374, -0.1248, -0.0520,  0.0811,  0.0673,  0.1405,\n",
      "           0.0673,  0.2199, -0.1426, -0.1095,  0.1495,  0.1490,  0.0120,\n",
      "           0.0097,  0.1753,  0.1652,  0.0228, -0.0725,  0.1137,  0.1185,\n",
      "          -0.1101, -0.1652, -0.0487,  0.0658, -0.0956, -0.0287, -0.2147,\n",
      "          -0.0759, -0.0317, -0.0229, -0.1419,  0.0059, -0.1513, -0.0247,\n",
      "           0.1172, -0.0106, -0.0056,  0.1380,  0.0751,  0.0294, -0.0545,\n",
      "           0.0039,  0.0095, -0.0670,  0.0751,  0.1209, -0.0332,  0.0396,\n",
      "          -0.1000,  0.2580, -0.2680,  0.0620,  0.0843, -0.0665,  0.0581,\n",
      "           0.2099,  0.0050,  0.1937, -0.2067, -0.0148, -0.1701,  0.0585,\n",
      "          -0.0386,  0.2575, -0.1183,  0.1395, -0.0864, -0.0516,  0.0368,\n",
      "          -0.1614, -0.1280,  0.0936, -0.1207, -0.0314, -0.1307, -0.2470,\n",
      "           0.2227,  0.1236, -0.1443,  0.0022,  0.2875, -0.0788, -0.1044,\n",
      "          -0.2638,  0.0489,  0.0475,  0.1928, -0.0052, -0.2114, -0.0904,\n",
      "           0.0007,  0.0857,  0.1472,  0.0302, -0.0361,  0.0909, -0.0427,\n",
      "          -0.1061,  0.1004, -0.0442, -0.1773, -0.0562,  0.0860, -0.1967,\n",
      "           0.0561, -0.0965, -0.0240,  0.0186, -0.1871,  0.0993, -0.0577,\n",
      "          -0.0358, -0.1067,  0.0191, -0.1419,  0.0920,  0.0819, -0.0737,\n",
      "          -0.0693, -0.0278, -0.0337,  0.0089, -0.2121,  0.1623, -0.0114,\n",
      "          -0.0085, -0.0549,  0.1279,  0.0777, -0.0572,  0.1179, -0.0636,\n",
      "          -0.0686,  0.1101, -0.1006, -0.0842, -0.1865,  0.1289,  0.0142,\n",
      "          -0.1180, -0.0078, -0.0021, -0.0372,  0.0027, -0.2075,  0.0671,\n",
      "           0.2223,  0.0531, -0.1940, -0.0906, -0.0268, -0.0987,  0.0951,\n",
      "          -0.1998, -0.1944, -0.1230,  0.0135, -0.0840,  0.1493,  0.0045,\n",
      "          -0.0872, -0.1174,  0.0813, -0.1714]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7263e-01, -4.3069e-01,  3.1509e-01, -1.0847e+00, -1.1726e+00,\n",
      "           7.4160e-01, -1.9144e+00,  0.0000e+00,  1.9033e-01,  6.1725e-01,\n",
      "           1.9034e+00,  6.0244e-01,  2.2885e-01, -9.1633e-01, -3.1827e+00,\n",
      "           0.0000e+00, -1.6333e+00, -9.4353e-01,  1.3605e+00, -1.4352e+00,\n",
      "          -1.4057e-01, -5.2405e-01, -1.1197e+00, -2.5953e+00, -7.5797e-02,\n",
      "           1.3914e+00, -6.1962e-01,  1.9977e+00,  1.2765e-01,  5.5449e-01,\n",
      "           9.1547e-01, -3.6558e-03,  2.2255e-01,  2.0162e+00, -6.3681e-02,\n",
      "          -1.4085e+00, -1.1181e-01, -8.1752e-01,  3.1497e-01,  8.5835e-02,\n",
      "           8.6273e-01, -8.9938e-01,  0.0000e+00, -1.5635e+00,  1.9444e+00,\n",
      "          -3.0021e-01,  7.0548e-01, -6.0189e-01, -1.0208e+00,  1.1167e+00,\n",
      "          -1.3226e+00,  0.0000e+00,  6.6684e-01, -8.4681e-01,  2.2775e-01,\n",
      "          -3.0967e-01, -1.4340e+00, -9.6491e-02,  1.2755e+00,  2.1814e+00,\n",
      "          -1.0064e+00,  3.6038e-02, -2.8014e-01,  2.6590e-01, -6.2963e-02,\n",
      "           3.9379e-01,  5.7799e-01,  1.1651e+00,  1.5809e+00, -1.4152e+00,\n",
      "           4.2751e-01,  2.9640e-01, -3.1206e-02, -7.9795e-01, -2.1436e-01,\n",
      "           1.3934e-01,  5.2580e-01,  1.3987e+00,  1.0272e+00, -7.9351e-01,\n",
      "           7.5799e-01, -1.0053e+00,  7.5770e-01,  1.0587e+00, -1.2149e+00,\n",
      "          -1.1309e-01, -1.1078e+00,  0.0000e+00, -9.4478e-01,  0.0000e+00,\n",
      "           5.2910e-01,  0.0000e+00,  1.7018e+00,  0.0000e+00,  6.0803e-01,\n",
      "          -1.5883e-02,  3.5376e-01, -1.1758e+00,  1.3719e+00,  0.0000e+00,\n",
      "           2.4356e-01,  4.4894e-02, -4.6652e-01, -9.8943e-01,  1.6403e+00,\n",
      "          -1.0234e+00,  0.0000e+00,  6.2014e-01, -1.0202e-01, -1.2354e+00,\n",
      "           1.8994e-01, -5.0304e-01, -5.7065e-01,  7.1238e-01, -7.8047e-01,\n",
      "           6.3247e-01,  4.0388e-01,  0.0000e+00, -2.3271e+00,  2.9335e-02,\n",
      "          -8.1409e-01, -1.4111e+00, -1.8377e+00,  6.0325e-01, -9.5668e-01,\n",
      "          -2.0058e-01,  3.9731e-02,  2.1503e+00,  1.3962e+00, -2.0879e+00,\n",
      "           0.0000e+00,  4.4972e-01, -1.1677e+00,  4.2527e-01, -4.6857e-01,\n",
      "          -7.4545e-01, -1.0649e+00, -9.7508e-01, -1.9456e-02,  2.3977e+00,\n",
      "           6.9859e-01, -1.1217e+00,  1.6917e+00,  0.0000e+00, -6.6974e-01,\n",
      "           3.3656e-02,  7.5949e-01,  4.2298e-01, -1.0335e+00, -9.5492e-02,\n",
      "           1.5600e+00,  5.8689e-01, -3.3857e-01,  6.5769e-01,  1.8410e+00,\n",
      "          -2.5263e-01, -2.1767e-01,  6.2368e-01, -2.3628e+00,  1.0558e+00,\n",
      "           3.0261e-01, -7.7329e-02,  1.5482e-01, -1.2119e+00, -2.1957e-02,\n",
      "           1.6822e+00,  1.8521e+00,  2.7109e-01, -1.2703e+00, -7.1318e-01,\n",
      "          -1.2243e+00, -1.0941e+00, -2.5905e+00,  5.0572e-01, -3.0594e+00,\n",
      "          -2.8722e-01,  0.0000e+00,  8.2960e-01,  3.1701e-01, -7.9293e-01,\n",
      "           2.7180e-01,  2.3397e+00,  1.0575e+00,  8.3850e-01, -4.0278e-01,\n",
      "           7.2756e-01,  5.9890e-01,  3.5958e-01,  8.4288e-01, -1.8305e+00,\n",
      "           1.3635e+00,  2.1593e+00,  0.0000e+00, -1.0155e+00, -1.1722e+00,\n",
      "          -2.2154e+00,  1.6668e+00,  2.1527e+00,  0.0000e+00,  0.0000e+00,\n",
      "           3.2421e-02, -5.0156e-01, -1.2765e+00, -5.4258e-01, -4.0746e-01,\n",
      "           0.0000e+00,  9.5354e-01,  0.0000e+00,  8.3017e-01, -1.5601e+00,\n",
      "           6.3664e-01,  6.7590e-01,  2.3978e+00,  0.0000e+00,  1.8937e+00,\n",
      "           1.3084e+00,  5.8052e-01, -2.3173e+00,  1.5502e+00, -2.2257e-01,\n",
      "          -2.2718e-01,  1.7335e+00,  0.0000e+00, -1.5520e+00,  9.2284e-01,\n",
      "           0.0000e+00, -8.4843e-01, -1.8019e+00, -5.4910e-04,  3.7328e-01,\n",
      "          -1.5735e+00, -1.2363e-01,  9.6631e-01, -1.7366e+00,  1.6942e+00,\n",
      "          -1.4405e+00,  6.3404e-01, -1.7224e+00,  9.8032e-01, -1.7161e+00,\n",
      "           1.5608e+00, -2.7233e-01, -2.5968e+00,  1.2387e+00, -1.2283e+00,\n",
      "           1.8852e+00, -5.0835e-01,  5.4283e-01, -2.6132e-01, -1.0220e+00,\n",
      "           1.3336e+00,  3.1079e-01, -5.1323e-02, -2.2880e-01, -1.6121e+00,\n",
      "           1.8065e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0595, 0.1475, 0.1375, 0.0955, 0.1037, 0.1025, 0.1342, 0.0793, 0.0848,\n",
      "         0.0554]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0183,  0.4030, -0.0100,  ...,  0.1343,  0.0970, -0.2327],\n",
      "        [ 0.2252,  0.2810, -0.3118,  ..., -0.1554,  0.2041, -0.2770],\n",
      "        [ 0.0501,  0.3627, -0.4266,  ..., -0.0533, -0.0559, -0.5428],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1397,  0.1241, -0.2071,  0.0783,  0.0134, -0.0309, -0.0624,\n",
      "          -0.1349,  0.0395, -0.0572, -0.0507,  0.0395, -0.2270, -0.0077,\n",
      "           0.0356,  0.0071,  0.2074,  0.1275, -0.0510,  0.1028, -0.1219,\n",
      "          -0.1479,  0.0987,  0.0598, -0.2655, -0.1033,  0.1472, -0.1514,\n",
      "          -0.0170,  0.0234,  0.0341, -0.2370, -0.1176, -0.1371, -0.0530,\n",
      "          -0.0405, -0.1596, -0.1313, -0.1216, -0.1055, -0.2259,  0.0912,\n",
      "          -0.0925,  0.0515,  0.2054, -0.0703,  0.0277, -0.0218,  0.1252,\n",
      "           0.0136,  0.0653,  0.0504, -0.3017, -0.1642, -0.0636,  0.0417,\n",
      "          -0.0488, -0.1556,  0.1199, -0.0102, -0.0790,  0.0510, -0.1875,\n",
      "          -0.0952, -0.1205, -0.0465,  0.1295,  0.1121, -0.1595,  0.0853,\n",
      "          -0.0717,  0.0200, -0.0536,  0.2899,  0.0332, -0.0484,  0.1214,\n",
      "           0.0222,  0.0737,  0.1463, -0.0923, -0.1070, -0.1453,  0.0651,\n",
      "          -0.1320,  0.0578,  0.0462, -0.0610,  0.0167, -0.0562,  0.0191,\n",
      "           0.0550, -0.0411, -0.1388, -0.0542,  0.0853,  0.0672,  0.1503,\n",
      "           0.0799,  0.2385, -0.1554, -0.1266,  0.1577,  0.1633,  0.0196,\n",
      "           0.0131,  0.1913,  0.1739,  0.0252, -0.0793,  0.1237,  0.1305,\n",
      "          -0.1215, -0.1725, -0.0479,  0.0720, -0.1044, -0.0276, -0.2341,\n",
      "          -0.0780, -0.0330, -0.0177, -0.1483,  0.0032, -0.1635, -0.0230,\n",
      "           0.1282, -0.0096, -0.0067,  0.1552,  0.0775,  0.0427, -0.0669,\n",
      "          -0.0023,  0.0125, -0.0734,  0.0794,  0.1282, -0.0266,  0.0365,\n",
      "          -0.1066,  0.2758, -0.2930,  0.0646,  0.0872, -0.0711,  0.0626,\n",
      "           0.2259,  0.0050,  0.2079, -0.2187, -0.0208, -0.1837,  0.0642,\n",
      "          -0.0449,  0.2773, -0.1296,  0.1542, -0.0985, -0.0570,  0.0418,\n",
      "          -0.1755, -0.1337,  0.0961, -0.1345, -0.0377, -0.1442, -0.2691,\n",
      "           0.2406,  0.1269, -0.1563,  0.0039,  0.3106, -0.0891, -0.1115,\n",
      "          -0.2872,  0.0577,  0.0500,  0.2097, -0.0010, -0.2280, -0.0964,\n",
      "           0.0074,  0.0934,  0.1561,  0.0251, -0.0363,  0.0928, -0.0540,\n",
      "          -0.1152,  0.1151, -0.0513, -0.1833, -0.0581,  0.0956, -0.2144,\n",
      "           0.0639, -0.1073, -0.0184,  0.0149, -0.2079,  0.1065, -0.0641,\n",
      "          -0.0399, -0.1215,  0.0279, -0.1569,  0.1016,  0.0947, -0.0771,\n",
      "          -0.0816, -0.0263, -0.0341,  0.0012, -0.2345,  0.1740, -0.0097,\n",
      "          -0.0137, -0.0522,  0.1361,  0.0815, -0.0538,  0.1251, -0.0671,\n",
      "          -0.0804,  0.1147, -0.1099, -0.0849, -0.2033,  0.1326,  0.0237,\n",
      "          -0.1302, -0.0066,  0.0013, -0.0386,  0.0029, -0.2273,  0.0749,\n",
      "           0.2424,  0.0541, -0.2073, -0.0932, -0.0215, -0.1058,  0.1076,\n",
      "          -0.2189, -0.2095, -0.1343,  0.0113, -0.0983,  0.1621,  0.0018,\n",
      "          -0.0938, -0.1276,  0.0900, -0.1876]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6047e-02,  3.9930e-01, -9.6611e-01, -6.8140e-01,  3.7594e-01,\n",
      "          -2.0195e-01,  1.4648e+00, -8.3360e-02,  0.0000e+00,  9.0660e-01,\n",
      "           4.2838e-01, -6.2911e-01,  2.6043e+00, -6.2976e-01, -5.4149e-01,\n",
      "          -1.5803e-01,  8.5131e-01,  1.0948e+00,  4.5518e-01,  4.3605e-01,\n",
      "          -6.3343e-01, -3.8302e-01,  1.6414e+00,  1.5109e+00,  7.5357e-01,\n",
      "          -7.5596e-02, -1.8794e-01, -7.5924e-01,  0.0000e+00,  8.6166e-01,\n",
      "           1.2319e+00,  0.0000e+00, -1.0342e+00,  0.0000e+00,  0.0000e+00,\n",
      "           1.3953e+00,  2.8097e-01, -3.7448e+00,  1.9795e-01,  1.6009e+00,\n",
      "          -4.5871e-01, -1.3983e+00, -2.6851e-01, -1.7157e+00, -1.5242e+00,\n",
      "           6.6746e-01,  0.0000e+00,  3.7072e-01, -1.3408e+00,  1.4414e-01,\n",
      "          -6.2930e-01,  2.7522e+00,  6.1035e-01, -1.0292e+00, -2.5519e-02,\n",
      "           2.0332e-01, -8.8193e-01, -1.2524e+00, -2.3687e-01, -4.2546e-01,\n",
      "           1.1004e+00,  1.4081e+00, -2.0303e-01, -5.0155e-01, -2.9638e+00,\n",
      "           5.5079e-01,  1.2788e+00, -1.2878e+00,  4.1120e-01,  5.2657e-01,\n",
      "           0.0000e+00, -3.0115e-02,  7.0734e-01, -3.6410e+00,  3.2590e-01,\n",
      "          -1.6507e-03, -1.5997e-01,  1.0624e+00,  0.0000e+00, -1.1947e-01,\n",
      "           0.0000e+00,  2.1311e+00, -9.2457e-01,  1.0059e+00,  0.0000e+00,\n",
      "           4.3507e-01,  0.0000e+00, -9.7426e-01, -1.0373e-01, -5.8134e-01,\n",
      "          -2.2734e+00,  1.1003e+00, -6.2238e-01, -1.1355e+00,  4.6723e-01,\n",
      "          -1.1706e+00,  3.4049e-02,  6.2904e-01,  0.0000e+00, -7.7979e-01,\n",
      "           2.6972e+00, -1.4623e+00,  1.0761e+00,  1.4537e+00, -6.6633e-01,\n",
      "          -7.6260e-01,  1.2122e+00,  1.2717e-01, -1.4730e+00, -1.3338e-02,\n",
      "          -2.4859e-01,  1.3430e-01, -1.0481e+00,  0.0000e+00, -1.6534e+00,\n",
      "          -2.9894e+00, -5.6473e-02, -5.0059e-01, -1.9330e-01,  0.0000e+00,\n",
      "          -1.4662e+00,  7.0223e-01,  0.0000e+00, -7.2602e-01, -9.5834e-01,\n",
      "          -1.3089e+00,  8.9696e-01,  1.7002e-01,  1.2853e+00, -7.5206e-01,\n",
      "          -8.2363e-01,  5.3007e-01, -1.5831e+00,  9.8407e-01,  2.7603e-01,\n",
      "          -5.8960e-01,  6.5938e-01,  5.7438e-01, -1.1587e+00, -1.0100e+00,\n",
      "          -3.8856e-01,  6.7778e-01, -7.8992e-01, -1.0133e-01, -1.6856e+00,\n",
      "           0.0000e+00, -5.4320e-01, -8.4439e-01, -7.5539e-01,  1.7760e-01,\n",
      "           0.0000e+00, -1.9965e-01, -1.9303e+00,  0.0000e+00,  4.4146e-01,\n",
      "          -1.9443e-01, -6.4389e-02,  0.0000e+00,  3.9339e-02,  5.3764e-01,\n",
      "          -2.6514e-02,  2.2063e+00,  4.8116e-01, -5.4990e-01,  0.0000e+00,\n",
      "          -8.9222e-01,  2.8163e-01,  8.3926e-02, -3.5803e-01, -4.7804e-01,\n",
      "           7.3739e-01, -3.1622e-02,  2.0039e-02, -1.0020e+00,  0.0000e+00,\n",
      "          -1.0985e+00, -9.8702e-01, -2.0768e+00,  1.9690e+00,  8.6501e-02,\n",
      "          -3.0323e-02,  3.5084e-02,  6.7115e-01,  9.7983e-01, -7.4692e-01,\n",
      "          -3.4084e-01, -2.7830e+00, -7.8399e-01,  1.2096e+00,  1.0124e+00,\n",
      "           3.0741e+00,  4.9438e-01, -1.4437e-01, -5.9406e-01,  5.6057e-01,\n",
      "           2.1650e+00, -1.1879e+00,  5.3505e-01,  1.8114e+00, -9.4685e-01,\n",
      "          -1.6623e+00, -1.0152e+00,  1.2419e+00, -1.2219e-01,  2.3202e-01,\n",
      "          -5.7515e-01, -2.2927e+00,  6.8171e-01, -1.0742e+00, -4.7117e-01,\n",
      "           2.8678e+00, -5.7342e-01, -3.4114e-01,  7.9308e-01,  3.0287e-02,\n",
      "          -6.8419e-01,  0.0000e+00,  9.6639e-01, -2.4563e-01,  2.1693e+00,\n",
      "          -1.0827e+00, -4.2726e-01,  0.0000e+00, -5.0086e-01,  0.0000e+00,\n",
      "           7.0499e-01, -6.9649e-01, -6.2820e-01,  2.9232e-01, -1.5784e+00,\n",
      "          -1.1086e+00,  1.5814e+00, -6.1403e-01,  0.0000e+00,  0.0000e+00,\n",
      "           4.0353e+00,  5.8524e-01,  4.3357e-02,  0.0000e+00, -2.8699e-01,\n",
      "           7.4176e-01, -3.2481e+00, -3.0437e-01,  0.0000e+00,  1.1342e-02,\n",
      "           2.7539e-01,  2.7472e-01,  2.5246e-01,  2.6120e-01,  3.8653e-01,\n",
      "          -3.6561e-01, -1.5892e-01, -5.5386e-01, -5.2636e-02, -1.1467e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0563, 0.0675, 0.0955, 0.1113, 0.1252, 0.2211, 0.0674, 0.0763, 0.0716,\n",
      "         0.1078]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1154,  0.0578, -0.1188,  ..., -0.4748,  0.2046, -0.2509],\n",
      "        [ 0.2999,  0.1215,  0.1223,  ...,  0.1456,  0.3344, -0.1450],\n",
      "        [-0.0329, -0.0491, -0.1405,  ..., -0.3148, -0.3281,  0.4688],\n",
      "        ...,\n",
      "        [ 0.0887, -0.5148, -0.0341,  ..., -0.5032, -0.3098, -0.1818],\n",
      "        [ 0.2574, -0.3781, -0.2902,  ..., -0.6294,  0.2557, -0.2161],\n",
      "        [ 0.5635,  0.2864, -0.7020,  ..., -0.3966, -0.0236, -0.0109]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.7253e-01, -1.1467e-01, -1.7534e-01, -1.4536e-01, -1.5252e-01,\n",
      "          -2.2568e-01, -5.3895e-02,  4.6604e-02, -2.6084e-02, -1.6250e-01,\n",
      "           1.1971e-01, -1.8875e-02,  2.8674e-01,  1.8482e-01,  1.2419e-01,\n",
      "          -8.7538e-02, -4.4559e-02, -9.8105e-02, -2.2404e-01, -1.3639e-01,\n",
      "          -9.5052e-02,  4.3247e-02,  1.0148e-01,  1.1190e-01,  3.3371e-02,\n",
      "           7.5999e-02,  1.2006e-01,  1.3988e-01, -2.1865e-01, -7.4222e-02,\n",
      "          -2.1090e-01, -2.3275e-01, -1.1840e-01,  5.0756e-02,  9.4575e-02,\n",
      "          -1.8072e-01, -9.9497e-02, -4.7392e-02, -2.1719e-01,  6.6252e-02,\n",
      "          -4.6806e-02, -1.5750e-01, -5.4548e-02,  9.3318e-02,  1.0143e-01,\n",
      "           1.9381e-01,  6.0815e-02, -3.0858e-01,  1.2006e-01,  4.0434e-02,\n",
      "          -4.2032e-02,  2.1180e-01, -1.7475e-01,  2.5194e-01, -3.8052e-02,\n",
      "          -1.3073e-01, -8.5407e-02,  3.9291e-02,  4.0145e-02, -2.0198e-02,\n",
      "          -1.6920e-01,  1.4257e-02, -9.8289e-02,  3.8365e-02, -1.2344e-01,\n",
      "          -1.5328e-01,  2.0025e-02, -1.0721e-01, -1.3652e-02,  3.2338e-02,\n",
      "           2.3145e-01,  1.3130e-01,  5.4259e-02, -7.7899e-03,  1.7928e-02,\n",
      "           1.5573e-01, -7.5150e-02,  1.6726e-01, -3.3575e-02, -9.9084e-03,\n",
      "          -1.1463e-02, -5.1493e-02, -1.6226e-01, -1.1433e-03,  1.2011e-01,\n",
      "           2.4038e-01,  1.2442e-01,  2.9566e-02, -1.2321e-02, -1.2216e-01,\n",
      "          -5.1321e-02,  1.3775e-01,  1.1087e-01, -7.3774e-02,  2.2242e-01,\n",
      "           1.5336e-01, -2.2049e-01, -1.6851e-02,  7.9433e-02, -7.0185e-02,\n",
      "          -1.2799e-02, -2.2381e-01,  1.5154e-01,  2.8613e-03, -1.5092e-02,\n",
      "           4.6535e-02, -8.2939e-02,  1.2109e-01, -6.2138e-02,  2.3871e-01,\n",
      "          -6.0199e-02,  3.1341e-02, -1.3358e-01, -1.1829e-01, -2.6508e-02,\n",
      "          -3.3337e-02, -9.2296e-02,  1.6103e-01,  5.1306e-03,  1.3433e-01,\n",
      "           6.2569e-02,  1.9545e-02, -1.9633e-01, -1.2779e-02, -2.7517e-01,\n",
      "          -1.9916e-02, -2.8713e-01, -9.4235e-02,  1.0397e-01,  4.3290e-03,\n",
      "           3.8629e-02,  2.7798e-02,  2.7744e-01,  1.0468e-01,  4.4208e-02,\n",
      "          -7.8618e-02, -1.6921e-01, -1.9420e-04, -1.1595e-01,  7.2748e-02,\n",
      "          -6.3590e-02,  2.1945e-01, -3.3639e-01,  1.5662e-01,  6.6484e-03,\n",
      "           1.0040e-01,  7.7405e-03, -5.6562e-02,  2.4096e-01,  1.4601e-01,\n",
      "          -3.1369e-01,  2.7378e-01,  5.9307e-03,  7.2633e-02,  9.4915e-03,\n",
      "           1.4044e-01, -1.0867e-01,  1.1566e-01, -1.4866e-01,  3.2276e-02,\n",
      "           1.4351e-01, -2.4628e-01, -1.7889e-02, -5.3164e-02, -3.1325e-02,\n",
      "           1.2068e-01, -1.8317e-01, -2.6201e-01,  4.4286e-02, -1.7032e-01,\n",
      "           7.9531e-02,  1.7453e-01,  1.6263e-01,  2.0501e-01, -2.0522e-01,\n",
      "          -1.7368e-02, -1.8218e-01, -2.1971e-02,  2.6964e-01, -1.7359e-02,\n",
      "          -9.3398e-02,  1.2335e-02, -8.8083e-02, -4.0826e-02, -3.4527e-01,\n",
      "           1.6579e-01, -6.2799e-02, -2.0246e-01, -5.6028e-02, -2.0298e-01,\n",
      "          -6.6910e-02,  2.7826e-01, -2.9560e-02, -1.1263e-02, -1.2511e-01,\n",
      "          -1.3970e-01, -1.8906e-01,  8.1902e-02,  1.7045e-01,  7.7135e-02,\n",
      "          -2.2355e-01,  4.7984e-02,  2.2820e-02,  7.8302e-02,  1.0531e-01,\n",
      "           1.4881e-01,  5.9784e-02,  3.5246e-02, -3.2221e-02,  1.9346e-02,\n",
      "           4.1856e-02, -1.4259e-01, -8.1234e-02,  2.4608e-01, -7.4321e-02,\n",
      "           2.0717e-02,  2.4860e-01,  6.2595e-03, -2.3407e-01,  1.3972e-01,\n",
      "           2.2282e-01, -1.3323e-01,  8.7571e-02, -1.8642e-01,  8.7504e-02,\n",
      "          -1.8044e-02, -2.7889e-02,  7.4078e-02,  2.9040e-02,  7.2190e-02,\n",
      "           7.0687e-02, -8.9148e-02, -3.6941e-01,  7.6448e-02,  3.9171e-02,\n",
      "           2.9900e-02, -9.4503e-03,  1.4723e-01, -1.1100e-02,  1.3577e-01,\n",
      "          -2.9391e-02, -7.3287e-02, -2.0407e-01,  2.0378e-01,  6.4107e-02,\n",
      "           1.6820e-01, -7.3931e-02, -1.2153e-01,  5.5568e-02, -1.3809e-01,\n",
      "          -6.3706e-02,  7.2397e-02, -2.9235e-02, -2.2985e-01, -2.5276e-01,\n",
      "           8.2082e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4746, -0.4593, -1.2337, -0.1176,  0.0000,  0.0000,  0.6621,\n",
      "           0.5340,  0.6705,  0.9336,  1.7086, -1.0166,  0.9472, -0.2517,\n",
      "          -1.6343,  0.5130,  1.8778, -0.7565, -1.5629,  0.0000, -1.1339,\n",
      "           0.1679,  2.9304,  0.5543, -0.1166,  0.0000,  1.8372,  0.5193,\n",
      "          -2.2262, -1.2855,  0.0297,  1.0135,  0.3246,  0.8605,  0.0000,\n",
      "          -1.4656,  0.0000, -0.7714,  1.9919,  0.1027,  0.4677, -2.2045,\n",
      "          -0.5665, -0.1154, -0.7132, -0.6897,  1.9283,  0.1100, -0.2868,\n",
      "          -1.8509,  1.4683,  0.4632,  0.6679, -0.2838,  0.0000,  0.0000,\n",
      "          -1.2422, -0.9516,  1.8146, -0.0116,  0.2047, -1.8180, -1.4019,\n",
      "          -0.8066,  1.1796,  0.2653, -0.1666, -0.2561, -0.0041,  0.0000,\n",
      "          -0.3253, -0.3244,  0.1475,  0.0000,  0.6588, -0.8067,  2.0663,\n",
      "           1.6804,  0.0877, -0.5467,  1.2272,  0.0876,  0.3271, -1.8366,\n",
      "          -0.0721,  0.0000, -1.4585, -0.8909,  0.6232,  0.8107, -1.2238,\n",
      "          -1.1445,  0.0000, -0.3657, -0.7340,  0.1564,  2.1423, -0.4055,\n",
      "          -0.3042, -1.8398, -1.2905,  0.0000, -0.7664,  0.2379,  0.3821,\n",
      "           1.1139, -1.0696,  2.2529, -0.2629, -0.2880, -0.0532,  0.6109,\n",
      "          -0.2554, -0.2803,  0.0000,  1.1282,  1.0061, -2.4985, -0.5745,\n",
      "           0.0298, -1.6957, -0.4013, -0.3800,  0.0000, -0.5373, -1.1119,\n",
      "           1.3056,  0.1702,  0.3224,  1.3586,  2.0802, -2.6344,  0.0000,\n",
      "          -0.7229,  0.4296,  0.0596,  0.0000, -2.1033, -0.4968,  0.0000,\n",
      "          -0.6424,  0.0000, -1.1873, -1.2157, -0.6315, -0.0411,  0.4651,\n",
      "           1.7386,  1.5937,  1.4316, -1.2629, -0.5775, -0.4803, -0.0395,\n",
      "           0.3269, -0.1164,  1.3541, -0.0309, -1.9008, -1.8060, -1.4272,\n",
      "          -0.9005,  0.0000,  0.0000, -0.9822, -0.1290,  0.4063,  0.9709,\n",
      "           0.5180, -0.1472,  1.5151, -0.3733, -0.3159, -2.0089,  0.1289,\n",
      "          -0.3525, -0.8312, -0.7698, -0.0397,  0.0000,  0.7281,  1.0422,\n",
      "           0.0471,  0.4634,  0.3170, -0.1179, -0.5427, -0.6645,  0.7555,\n",
      "          -1.0645, -0.5862, -1.7886,  1.2674, -0.9268, -1.6149, -0.3331,\n",
      "          -1.1571, -1.9609, -0.0720, -0.3760,  2.6984, -0.9216, -2.6325,\n",
      "          -0.5863, -0.7170,  0.0000, -1.2540,  0.1720,  0.2183, -1.1114,\n",
      "           0.9455, -0.6920, -1.5199,  0.3626,  0.2368, -1.4273, -2.3453,\n",
      "           0.0471, -1.4803,  0.0000,  0.0133, -0.9020,  0.3008, -1.1657,\n",
      "          -1.3024, -0.1875,  1.2726,  1.2667, -2.1881, -0.0567,  1.7372,\n",
      "          -1.1752,  0.9564,  1.9991,  0.5267,  0.7904, -0.6785,  0.1046,\n",
      "           0.0000, -2.2627,  0.1677, -0.3148, -1.0436, -0.3820, -1.0801,\n",
      "           0.5583,  1.5005, -0.5647, -1.3777,  1.2435,  0.0000,  1.7535,\n",
      "           1.9512,  0.3622,  0.0000,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0253, 0.2208, 0.0725, 0.0550, 0.1094, 0.1574, 0.0400, 0.1638, 0.0891,\n",
      "         0.0669]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1154,  0.0578, -0.1188,  ..., -0.4748,  0.2046, -0.2509],\n",
      "        [ 0.2999,  0.1215,  0.1223,  ...,  0.1456,  0.3344, -0.1450],\n",
      "        [-0.0329, -0.0491, -0.1405,  ..., -0.3148, -0.3281,  0.4688],\n",
      "        ...,\n",
      "        [ 0.0887, -0.5148, -0.0341,  ..., -0.5032, -0.3098, -0.1818],\n",
      "        [ 0.2574, -0.3781, -0.2902,  ..., -0.6294,  0.2557, -0.2161],\n",
      "        [ 0.5635,  0.2864, -0.7020,  ..., -0.3966, -0.0236, -0.0109]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1775, -0.1338, -0.1014, -0.1520, -0.1656, -0.1818, -0.0541,\n",
      "           0.0618, -0.0364, -0.1335,  0.0869,  0.0082,  0.3402,  0.0865,\n",
      "           0.0867, -0.1111, -0.0763, -0.0452, -0.2151, -0.0720,  0.0068,\n",
      "          -0.0854,  0.0630,  0.0174,  0.0406,  0.0919,  0.1741,  0.1985,\n",
      "          -0.2379, -0.0243, -0.1416, -0.2259, -0.0558, -0.0109,  0.0316,\n",
      "          -0.2690, -0.1246, -0.0656, -0.1114,  0.1418, -0.0291, -0.1817,\n",
      "           0.0216,  0.0719,  0.0671,  0.2351,  0.1073, -0.2334,  0.0868,\n",
      "           0.0452, -0.0074,  0.1235, -0.0752,  0.2016, -0.0571, -0.1926,\n",
      "          -0.1024,  0.0217, -0.0082, -0.0369, -0.1363,  0.0367, -0.0642,\n",
      "           0.0901, -0.1410, -0.0894,  0.0435, -0.1059, -0.0166,  0.0241,\n",
      "           0.1976,  0.1079,  0.0429, -0.0607,  0.0483,  0.1566, -0.0937,\n",
      "           0.0746, -0.0301,  0.0651,  0.0350, -0.0364, -0.0466,  0.0709,\n",
      "           0.1296,  0.2297,  0.1305,  0.0948, -0.0597, -0.1159, -0.0070,\n",
      "           0.1348,  0.0375, -0.0962,  0.2462,  0.1814, -0.1815,  0.0010,\n",
      "           0.0522, -0.0715,  0.0435, -0.2493,  0.1668, -0.0143,  0.0462,\n",
      "           0.0933, -0.1020,  0.0466,  0.0255,  0.2406, -0.0413,  0.0606,\n",
      "          -0.1667, -0.0698, -0.0668, -0.0529, -0.0613,  0.1761, -0.0225,\n",
      "           0.1345,  0.1118,  0.0778, -0.1750,  0.0334, -0.2140,  0.0211,\n",
      "          -0.3049, -0.0408,  0.0906,  0.0068,  0.0664,  0.0549,  0.2372,\n",
      "           0.1249,  0.0352, -0.1492, -0.2347, -0.0104, -0.0869,  0.0237,\n",
      "          -0.0895,  0.2423, -0.4367,  0.1464, -0.0497,  0.0826,  0.0178,\n",
      "          -0.1057,  0.3049,  0.1621, -0.2753,  0.2070,  0.0459,  0.0500,\n",
      "          -0.0993,  0.1228, -0.1049,  0.1295, -0.1506,  0.0601,  0.1201,\n",
      "          -0.2376,  0.0350, -0.0925, -0.0447,  0.1224, -0.1125, -0.2048,\n",
      "           0.0057, -0.1445,  0.0438,  0.1200,  0.0962,  0.2330, -0.2619,\n",
      "          -0.0104, -0.1762, -0.0207,  0.1889, -0.1059, -0.1040,  0.0482,\n",
      "          -0.0844, -0.0419, -0.3295,  0.1440, -0.0660, -0.2533, -0.0271,\n",
      "          -0.1676, -0.0457,  0.2596, -0.0619,  0.0431, -0.0572, -0.0803,\n",
      "          -0.2047,  0.1408,  0.1517,  0.0583, -0.2447,  0.0963, -0.0082,\n",
      "           0.0158,  0.1200,  0.0835,  0.0832,  0.0246, -0.0866,  0.0154,\n",
      "           0.0029, -0.1085, -0.1529,  0.2128, -0.0435, -0.0080,  0.2843,\n",
      "           0.0498, -0.1546,  0.1359,  0.2384, -0.0476,  0.0426, -0.1977,\n",
      "           0.0088, -0.0695, -0.0185, -0.0157,  0.0871,  0.0603,  0.1412,\n",
      "          -0.0944, -0.3889,  0.0592, -0.0118, -0.0008, -0.0444,  0.1657,\n",
      "          -0.0259,  0.1816, -0.0798, -0.0654, -0.1798,  0.2180,  0.0454,\n",
      "           0.1223, -0.0378, -0.0787,  0.0452, -0.1451, -0.0911,  0.0479,\n",
      "           0.0037, -0.1971, -0.1522,  0.0176]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00, -6.9751e-02, -1.8077e+00,  1.3220e+00,  0.0000e+00,\n",
      "          -3.7632e-01,  1.1915e-03, -7.2324e-01,  2.1180e+00, -2.1400e-01,\n",
      "           2.8248e-01,  8.3079e-01,  0.0000e+00,  1.9995e-01,  3.1200e-01,\n",
      "           3.5186e-01, -6.8300e-01,  1.6896e-01,  8.7472e-01,  0.0000e+00,\n",
      "           1.8834e+00,  6.0179e-01, -3.6562e-02, -5.3536e-01, -9.9900e-02,\n",
      "           6.5092e-01, -1.6087e+00, -1.3624e+00, -2.1269e+00, -1.0343e+00,\n",
      "           3.8996e-02, -1.4548e+00, -2.0765e+00,  3.1565e-01, -2.8499e-01,\n",
      "          -2.0019e+00,  2.1901e-01,  9.9702e-01,  6.0111e-01,  9.5378e-01,\n",
      "          -2.2539e-01, -2.2112e+00, -7.0637e-01,  1.3962e+00,  8.9500e-02,\n",
      "          -1.1388e+00,  2.4255e-01,  7.4198e-01, -7.0982e-01, -1.3358e+00,\n",
      "           1.6089e+00, -1.3707e-01,  6.6298e-01,  1.1163e+00,  5.6739e-01,\n",
      "           3.3333e-01, -4.4979e-01,  0.0000e+00,  1.3385e-01,  6.2865e-01,\n",
      "          -7.0523e-01,  5.6383e-01, -6.9322e-01, -1.5474e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.7761e-01,  5.9470e-01, -2.1383e+00,  5.5970e-01,\n",
      "           1.8298e-01, -5.1247e-01, -3.4121e-01, -1.1320e+00, -6.4724e-01,\n",
      "           4.6096e-01,  0.0000e+00,  1.1902e-01,  5.1728e-01, -1.8685e-01,\n",
      "          -3.8489e-01,  2.1583e+00,  7.7759e-01, -8.4557e-01,  3.9774e-01,\n",
      "           4.1919e-01,  1.6044e+00, -5.6423e-01, -1.4133e+00, -1.4906e+00,\n",
      "           4.0420e-01, -3.5169e-01,  4.9400e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6286e-01,  1.3204e+00,  0.0000e+00,  2.3908e+00,  0.0000e+00,\n",
      "           0.0000e+00,  5.9434e-01,  1.0665e+00, -1.7336e+00,  3.6546e-01,\n",
      "           4.0221e-01, -1.2704e+00,  0.0000e+00,  1.9688e+00,  1.4947e-01,\n",
      "          -8.3211e-01,  5.3384e-01,  8.0826e-01,  6.6417e-01, -1.0548e+00,\n",
      "           9.1755e-01, -7.0275e-01,  0.0000e+00,  2.5774e-01,  8.7990e-01,\n",
      "          -8.7679e-01, -1.3969e+00, -3.6512e-01, -1.8465e+00, -1.3009e+00,\n",
      "           1.0692e+00, -8.1155e-01,  6.4927e-01,  2.5571e-01, -1.4893e+00,\n",
      "           2.5026e+00,  3.7796e-01, -1.3458e+00,  7.2252e-01,  3.2014e+00,\n",
      "          -7.5277e-01, -3.8347e-01,  1.2822e+00,  2.2524e+00,  1.9393e-01,\n",
      "          -3.9437e-02,  3.0302e+00,  0.0000e+00, -1.8689e-01, -1.1119e+00,\n",
      "           1.2471e+00,  7.7554e-01, -7.7460e-01, -4.4955e-02, -1.3872e+00,\n",
      "           2.3359e+00,  7.6466e-01, -2.8968e-01, -2.1308e+00, -5.8158e-01,\n",
      "           7.8582e-01, -1.8621e+00,  0.0000e+00,  1.9013e-01, -3.6290e+00,\n",
      "          -1.8686e+00,  1.1507e+00,  0.0000e+00,  9.5974e-01, -1.4615e+00,\n",
      "          -2.7010e-02,  1.9744e+00,  1.1272e+00, -4.8601e-01, -1.2414e+00,\n",
      "           0.0000e+00, -1.3226e+00, -1.6393e+00, -7.7184e-01,  6.8255e-01,\n",
      "          -1.3797e+00, -1.2618e-01,  6.0664e-01, -7.4867e-01,  2.5927e-01,\n",
      "           1.3326e+00, -2.5536e+00,  2.7774e-01, -5.8389e-01,  1.6236e+00,\n",
      "          -1.2402e+00, -1.7602e-03, -5.0342e-02,  9.0144e-01,  5.6545e-01,\n",
      "          -4.1998e-01,  3.8801e-01, -1.1612e-01,  8.0970e-01,  1.0503e+00,\n",
      "          -7.8907e-01, -1.4388e+00, -4.1612e-01,  0.0000e+00, -4.5426e-01,\n",
      "          -5.4743e-01,  7.2226e-01, -1.8537e+00,  1.3574e+00,  8.3770e-01,\n",
      "          -1.5240e+00, -3.5889e-01,  6.4794e-01,  2.0067e-01,  0.0000e+00,\n",
      "           8.3560e-01, -1.2913e+00, -1.2839e+00,  2.6131e-01, -1.5633e+00,\n",
      "           2.0758e+00,  1.3421e-01,  2.5768e+00, -3.1171e-02, -5.7938e-01,\n",
      "          -1.4283e+00,  1.9011e+00, -3.8080e-01,  1.4694e+00,  8.0495e-01,\n",
      "           3.6904e-01,  6.6982e-01, -7.0070e-01,  0.0000e+00,  1.0256e+00,\n",
      "           9.7812e-01, -1.4086e+00,  6.5975e-01, -1.1450e+00,  0.0000e+00,\n",
      "          -6.0015e-01,  8.8912e-03, -7.1104e-01,  3.7054e-01, -2.2426e-01,\n",
      "          -7.5230e-01,  5.7233e-01,  5.3064e-01, -6.6350e-01,  1.5466e+00,\n",
      "           5.7844e-01,  1.8921e+00,  0.0000e+00,  4.9340e-01, -3.8729e-01,\n",
      "           5.0014e-01, -9.7528e-01,  1.7728e+00, -1.0635e+00, -8.0794e-01,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0627, 0.1088, 0.1409, 0.1250, 0.1121, 0.1779, 0.0670, 0.0518, 0.0659,\n",
      "         0.0879]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1154,  0.0578, -0.1188,  ..., -0.4748,  0.2046, -0.2509],\n",
      "        [ 0.2999,  0.1215,  0.1223,  ...,  0.1456,  0.3344, -0.1450],\n",
      "        [-0.0329, -0.0491, -0.1405,  ..., -0.3148, -0.3281,  0.4688],\n",
      "        ...,\n",
      "        [ 0.0887, -0.5148, -0.0341,  ..., -0.5032, -0.3098, -0.1818],\n",
      "        [ 0.2574, -0.3781, -0.2902,  ..., -0.6294,  0.2557, -0.2161],\n",
      "        [ 0.5635,  0.2864, -0.7020,  ..., -0.3966, -0.0236, -0.0109]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1608, -0.1027, -0.1626, -0.1489, -0.1570, -0.2342, -0.0079,\n",
      "           0.0726, -0.0247, -0.1556,  0.1349, -0.0368,  0.2921,  0.1417,\n",
      "           0.1338, -0.1021, -0.0226, -0.1090, -0.1896, -0.1025, -0.1016,\n",
      "           0.0175,  0.0302,  0.0855,  0.0019,  0.0838,  0.1206,  0.1621,\n",
      "          -0.1717, -0.0469, -0.1681, -0.2076, -0.0705,  0.0907,  0.0663,\n",
      "          -0.1742, -0.1482, -0.0583, -0.1717,  0.0321, -0.0373, -0.1430,\n",
      "          -0.0042,  0.0597,  0.1570,  0.1867,  0.0942, -0.2873,  0.1214,\n",
      "           0.0496, -0.0707,  0.2257, -0.1674,  0.2544, -0.0143, -0.1384,\n",
      "          -0.0600,  0.0235,  0.0393, -0.0320, -0.1115, -0.0178, -0.0587,\n",
      "           0.0645, -0.1262, -0.1849,  0.0349, -0.1309, -0.0154,  0.0655,\n",
      "           0.1941,  0.0998,  0.0839, -0.0488,  0.0222,  0.1547, -0.1119,\n",
      "           0.1304, -0.0302, -0.0405,  0.0299, -0.0346, -0.0913,  0.0095,\n",
      "           0.1066,  0.2604,  0.1378,  0.0240, -0.0370, -0.0998, -0.0650,\n",
      "           0.1442,  0.1201, -0.1052,  0.1950,  0.1366, -0.2219, -0.0147,\n",
      "           0.0422, -0.0788,  0.0223, -0.2607,  0.1656,  0.0042, -0.0023,\n",
      "           0.0423, -0.1398,  0.0652,  0.0271,  0.2469, -0.0113,  0.0480,\n",
      "          -0.1112, -0.0937, -0.0033, -0.0208, -0.0726,  0.1695, -0.0698,\n",
      "           0.1371,  0.0429,  0.0269, -0.1961, -0.0181, -0.2414, -0.0285,\n",
      "          -0.3111, -0.0738,  0.1033,  0.0063,  0.0330,  0.0118,  0.2490,\n",
      "           0.0814,  0.0502, -0.0432, -0.1631, -0.0269, -0.1114,  0.0428,\n",
      "          -0.0615,  0.2659, -0.3276,  0.1969, -0.0235,  0.0670,  0.0048,\n",
      "          -0.0655,  0.2345,  0.1596, -0.3108,  0.2095,  0.0142,  0.0577,\n",
      "          -0.0100,  0.1240, -0.1007,  0.1078, -0.1856,  0.0748,  0.1646,\n",
      "          -0.2632, -0.0592, -0.0509, -0.0652,  0.1051, -0.1273, -0.2054,\n",
      "           0.0758, -0.1695,  0.0779,  0.1466,  0.1043,  0.2196, -0.2144,\n",
      "          -0.0214, -0.1825,  0.0029,  0.2701, -0.0086, -0.1060, -0.0211,\n",
      "          -0.0578, -0.0160, -0.3356,  0.1681, -0.0890, -0.2178, -0.0597,\n",
      "          -0.1609, -0.0312,  0.2771, -0.0386,  0.0179, -0.0779, -0.1302,\n",
      "          -0.1566,  0.1233,  0.1919,  0.0745, -0.2408,  0.0659,  0.0125,\n",
      "           0.0645,  0.0879,  0.1325,  0.0166,  0.0668, -0.0867,  0.0322,\n",
      "           0.0193, -0.1343, -0.0963,  0.1955, -0.0834,  0.0530,  0.2094,\n",
      "           0.0601, -0.1964,  0.1445,  0.1980, -0.1321,  0.0979, -0.1925,\n",
      "           0.0857, -0.0695, -0.0458,  0.0706,  0.0480,  0.0576,  0.0671,\n",
      "          -0.0492, -0.3480,  0.0672,  0.0418,  0.0192, -0.0297,  0.1689,\n",
      "          -0.0118,  0.1441, -0.0425, -0.1218, -0.2138,  0.1884,  0.0794,\n",
      "           0.1042, -0.0518, -0.1291,  0.0398, -0.1459, -0.0213,  0.0584,\n",
      "           0.0271, -0.2195, -0.2197,  0.0880]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00, -6.9751e-02, -1.8077e+00,  1.3220e+00,  5.1600e-01,\n",
      "          -3.7632e-01,  1.1915e-03, -7.2324e-01,  2.1180e+00, -2.1400e-01,\n",
      "           2.8248e-01,  0.0000e+00, -1.1107e+00,  0.0000e+00,  3.1200e-01,\n",
      "           3.5186e-01, -6.8300e-01,  1.6896e-01,  8.7472e-01,  5.4557e-01,\n",
      "           1.8834e+00,  6.0179e-01,  0.0000e+00, -5.3536e-01, -9.9900e-02,\n",
      "           6.5092e-01, -1.6087e+00, -1.3624e+00,  0.0000e+00, -1.0343e+00,\n",
      "           3.8996e-02, -1.4548e+00, -2.0765e+00,  3.1565e-01,  0.0000e+00,\n",
      "          -2.0019e+00,  2.1901e-01,  9.9702e-01,  6.0111e-01,  9.5378e-01,\n",
      "          -2.2539e-01, -2.2112e+00, -7.0637e-01,  1.3962e+00,  8.9500e-02,\n",
      "          -1.1388e+00,  2.4255e-01,  7.4198e-01, -7.0982e-01, -1.3358e+00,\n",
      "           0.0000e+00, -1.3707e-01,  6.6298e-01,  1.1163e+00,  5.6739e-01,\n",
      "           3.3333e-01, -4.4979e-01, -8.8826e-01,  1.3385e-01,  6.2865e-01,\n",
      "          -7.0523e-01,  5.6383e-01, -6.9322e-01,  0.0000e+00,  2.8949e-01,\n",
      "           9.5648e-02, -1.7761e-01,  0.0000e+00, -2.1383e+00,  5.5970e-01,\n",
      "           1.8298e-01, -5.1247e-01, -3.4121e-01, -1.1320e+00, -6.4724e-01,\n",
      "           0.0000e+00, -1.0494e+00,  1.1902e-01,  5.1728e-01, -1.8685e-01,\n",
      "          -3.8489e-01,  2.1583e+00,  7.7759e-01, -8.4557e-01,  3.9774e-01,\n",
      "           4.1919e-01,  1.6044e+00, -5.6423e-01, -1.4133e+00, -1.4906e+00,\n",
      "           4.0420e-01, -3.5169e-01,  4.9400e-01, -2.3209e+00,  1.2380e+00,\n",
      "          -9.6286e-01,  1.3204e+00, -9.0763e-01,  2.3908e+00,  9.5534e-01,\n",
      "          -1.2010e+00,  0.0000e+00,  1.0665e+00, -1.7336e+00,  3.6546e-01,\n",
      "           4.0221e-01, -1.2704e+00,  4.5517e-01,  1.9688e+00,  1.4947e-01,\n",
      "          -8.3211e-01,  5.3384e-01,  8.0826e-01,  6.6417e-01, -1.0548e+00,\n",
      "           9.1755e-01, -7.0275e-01, -8.4517e-01,  2.5774e-01,  8.7990e-01,\n",
      "          -8.7679e-01, -1.3969e+00, -3.6512e-01, -1.8465e+00, -1.3009e+00,\n",
      "           1.0692e+00, -8.1155e-01,  0.0000e+00,  2.5571e-01, -1.4893e+00,\n",
      "           2.5026e+00,  3.7796e-01, -1.3458e+00,  7.2252e-01,  0.0000e+00,\n",
      "           0.0000e+00, -3.8347e-01,  0.0000e+00,  2.2524e+00,  1.9393e-01,\n",
      "           0.0000e+00,  3.0302e+00,  3.6270e-01, -1.8689e-01, -1.1119e+00,\n",
      "           1.2471e+00,  7.7554e-01, -7.7460e-01, -4.4955e-02, -1.3872e+00,\n",
      "           2.3359e+00,  7.6466e-01, -2.8968e-01, -2.1308e+00, -5.8158e-01,\n",
      "           7.8582e-01, -1.8621e+00, -1.3047e+00,  1.9013e-01, -3.6290e+00,\n",
      "          -1.8686e+00,  1.1507e+00, -8.5956e-01,  9.5974e-01, -1.4615e+00,\n",
      "          -2.7010e-02,  1.9744e+00,  0.0000e+00, -4.8601e-01, -1.2414e+00,\n",
      "          -2.1189e-01, -1.3226e+00, -1.6393e+00, -7.7184e-01,  0.0000e+00,\n",
      "          -1.3797e+00, -1.2618e-01,  6.0664e-01, -7.4867e-01,  2.5927e-01,\n",
      "           1.3326e+00, -2.5536e+00,  2.7774e-01, -5.8389e-01,  1.6236e+00,\n",
      "          -1.2402e+00, -1.7602e-03, -5.0342e-02,  9.0144e-01,  5.6545e-01,\n",
      "          -4.1998e-01,  3.8801e-01,  0.0000e+00,  8.0970e-01,  1.0503e+00,\n",
      "          -7.8907e-01, -1.4388e+00, -4.1612e-01, -7.5043e-01, -4.5426e-01,\n",
      "          -5.4743e-01,  7.2226e-01, -1.8537e+00,  1.3574e+00,  8.3770e-01,\n",
      "          -1.5240e+00, -3.5889e-01,  0.0000e+00,  2.0067e-01,  0.0000e+00,\n",
      "           8.3560e-01, -1.2913e+00, -1.2839e+00,  0.0000e+00, -1.5633e+00,\n",
      "           2.0758e+00,  1.3421e-01,  2.5768e+00, -3.1171e-02, -5.7938e-01,\n",
      "          -1.4283e+00,  1.9011e+00, -3.8080e-01,  1.4694e+00,  8.0495e-01,\n",
      "           3.6904e-01,  6.6982e-01, -7.0070e-01,  8.9177e-02,  1.0256e+00,\n",
      "           9.7812e-01, -1.4086e+00,  6.5975e-01, -1.1450e+00, -1.6456e+00,\n",
      "          -6.0015e-01,  8.8912e-03, -7.1104e-01,  3.7054e-01, -2.2426e-01,\n",
      "          -7.5230e-01,  5.7233e-01,  5.3064e-01,  0.0000e+00,  1.5466e+00,\n",
      "           5.7844e-01,  1.8921e+00, -8.6431e-01,  4.9340e-01, -3.8729e-01,\n",
      "           5.0014e-01, -9.7528e-01,  1.7728e+00, -1.0635e+00, -8.0794e-01,\n",
      "          -6.2176e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0539, 0.1287, 0.1453, 0.1529, 0.0953, 0.1401, 0.0835, 0.0484, 0.0694,\n",
      "         0.0825]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1154,  0.0578, -0.1188,  ..., -0.4748,  0.2046, -0.2509],\n",
      "        [ 0.2999,  0.1215,  0.1223,  ...,  0.1456,  0.3344, -0.1450],\n",
      "        [-0.0329, -0.0491, -0.1405,  ..., -0.3148, -0.3281,  0.4688],\n",
      "        ...,\n",
      "        [ 0.0887, -0.5148, -0.0341,  ..., -0.5032, -0.3098, -0.1818],\n",
      "        [ 0.2574, -0.3781, -0.2902,  ..., -0.6294,  0.2557, -0.2161],\n",
      "        [ 0.5635,  0.2864, -0.7020,  ..., -0.3966, -0.0236, -0.0109]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1629, -0.1098, -0.1648, -0.1356, -0.1591, -0.2255, -0.0046,\n",
      "           0.0725, -0.0111, -0.1454,  0.1334, -0.0458,  0.2922,  0.1097,\n",
      "           0.1163, -0.1083, -0.0202, -0.0904, -0.1932, -0.0666, -0.0949,\n",
      "          -0.0007,  0.0119,  0.0599, -0.0155,  0.0855,  0.1263,  0.1733,\n",
      "          -0.1497, -0.0383, -0.1511, -0.1988, -0.0459,  0.1058,  0.0533,\n",
      "          -0.1793, -0.1797, -0.0461, -0.1526,  0.0166, -0.0315, -0.1331,\n",
      "           0.0203,  0.0407,  0.1745,  0.1938,  0.1153, -0.2889,  0.1286,\n",
      "           0.0383, -0.0839,  0.2201, -0.1530,  0.2592, -0.0045, -0.1468,\n",
      "          -0.0586,  0.0257,  0.0282, -0.0277, -0.1067, -0.0249, -0.0634,\n",
      "           0.0833, -0.1188, -0.1798,  0.0388, -0.1334, -0.0151,  0.0630,\n",
      "           0.1762,  0.0775,  0.1072, -0.0652,  0.0229,  0.1588, -0.1127,\n",
      "           0.1022, -0.0360, -0.0360,  0.0330, -0.0338, -0.0684,  0.0204,\n",
      "           0.1061,  0.2644,  0.1436,  0.0280, -0.0402, -0.0863, -0.0551,\n",
      "           0.1500,  0.1229, -0.1286,  0.1750,  0.1429, -0.2126, -0.0130,\n",
      "           0.0370, -0.0731,  0.0251, -0.2650,  0.1815,  0.0017,  0.0092,\n",
      "           0.0410, -0.1571,  0.0507,  0.0667,  0.2647,  0.0043,  0.0613,\n",
      "          -0.1032, -0.0866,  0.0031, -0.0159, -0.0556,  0.1670, -0.1048,\n",
      "           0.1385,  0.0286,  0.0339, -0.2008, -0.0242, -0.2257, -0.0437,\n",
      "          -0.3216, -0.0635,  0.1037, -0.0034,  0.0146,  0.0111,  0.2384,\n",
      "           0.0812,  0.0555, -0.0266, -0.1444, -0.0351, -0.1113,  0.0377,\n",
      "          -0.0696,  0.2706, -0.3366,  0.2178, -0.0308,  0.0346,  0.0018,\n",
      "          -0.0680,  0.2367,  0.1692, -0.3122,  0.1918,  0.0282,  0.0649,\n",
      "          -0.0132,  0.1198, -0.0971,  0.0943, -0.1957,  0.0815,  0.1662,\n",
      "          -0.2642, -0.0685, -0.0534, -0.0744,  0.0987, -0.1011, -0.1722,\n",
      "           0.0702, -0.1820,  0.0556,  0.1291,  0.0793,  0.2272, -0.2503,\n",
      "          -0.0318, -0.1820,  0.0204,  0.2817, -0.0201, -0.1244, -0.0366,\n",
      "          -0.0526, -0.0235, -0.3234,  0.1651, -0.0875, -0.2053, -0.0688,\n",
      "          -0.1392, -0.0233,  0.2590, -0.0349,  0.0251, -0.0430, -0.1206,\n",
      "          -0.1402,  0.1451,  0.1950,  0.0713, -0.2457,  0.0842, -0.0036,\n",
      "           0.0682,  0.0856,  0.1207, -0.0025,  0.0774, -0.1118,  0.0173,\n",
      "          -0.0145, -0.1380, -0.1132,  0.1799, -0.0848,  0.0648,  0.1953,\n",
      "           0.0748, -0.1807,  0.1494,  0.1869, -0.1291,  0.0882, -0.1884,\n",
      "           0.0826, -0.0705, -0.0432,  0.0400,  0.0480,  0.0626,  0.0724,\n",
      "          -0.0496, -0.3419,  0.0664,  0.0491,  0.0105, -0.0303,  0.1746,\n",
      "           0.0032,  0.1523, -0.0517, -0.1430, -0.2121,  0.1791,  0.0944,\n",
      "           0.0765, -0.0436, -0.1383,  0.0336, -0.1365,  0.0015,  0.0475,\n",
      "           0.0438, -0.2254, -0.1979,  0.0726]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00,  3.9923e-01, -9.6623e-01, -6.8144e-01,  3.7599e-01,\n",
      "          -2.0191e-01,  1.4648e+00, -8.3370e-02, -3.5844e+00,  9.0663e-01,\n",
      "           4.2843e-01,  0.0000e+00,  2.6044e+00,  0.0000e+00, -5.4148e-01,\n",
      "          -1.5797e-01,  8.5136e-01,  0.0000e+00,  4.5515e-01,  4.3607e-01,\n",
      "          -6.3347e-01, -3.8311e-01,  1.6414e+00,  1.5110e+00,  0.0000e+00,\n",
      "          -7.5601e-02, -1.8787e-01, -7.5924e-01,  1.6537e+00,  8.6164e-01,\n",
      "           1.2319e+00,  0.0000e+00,  0.0000e+00, -8.2657e-02, -1.5345e+00,\n",
      "           0.0000e+00,  2.8094e-01, -3.7449e+00,  1.9798e-01,  1.6010e+00,\n",
      "          -4.5874e-01, -1.3984e+00, -2.6850e-01, -1.7158e+00, -1.5243e+00,\n",
      "           6.6742e-01,  5.4099e-01,  3.7066e-01, -1.3408e+00,  1.4412e-01,\n",
      "           0.0000e+00,  0.0000e+00,  6.1032e-01,  0.0000e+00,  0.0000e+00,\n",
      "           2.0331e-01, -8.8204e-01, -1.2524e+00, -2.3683e-01, -4.2544e-01,\n",
      "           1.1005e+00,  1.4082e+00, -2.0313e-01, -5.0156e-01, -2.9640e+00,\n",
      "           5.5071e-01,  1.2788e+00, -1.2879e+00,  4.1128e-01,  5.2654e-01,\n",
      "          -1.2670e+00, -3.0112e-02,  0.0000e+00, -3.6411e+00,  3.2595e-01,\n",
      "          -1.7302e-03, -1.5994e-01,  1.0625e+00, -5.8093e-02, -1.1955e-01,\n",
      "          -1.4003e+00,  2.1312e+00, -9.2467e-01,  1.0059e+00, -2.0778e-01,\n",
      "           0.0000e+00,  1.6616e+00, -9.7430e-01, -1.0366e-01, -5.8138e-01,\n",
      "          -2.2735e+00,  1.1003e+00,  0.0000e+00, -1.1355e+00,  4.6730e-01,\n",
      "          -1.1707e+00,  3.4058e-02,  0.0000e+00,  1.7200e+00, -7.7989e-01,\n",
      "           2.6973e+00, -1.4624e+00,  1.0761e+00,  1.4538e+00, -6.6638e-01,\n",
      "           0.0000e+00,  1.2122e+00,  1.2717e-01, -1.4730e+00, -1.3309e-02,\n",
      "          -2.4863e-01,  1.3437e-01, -1.0481e+00,  1.3101e+00, -1.6534e+00,\n",
      "          -2.9895e+00, -5.6437e-02, -5.0068e-01, -1.9328e-01,  4.4507e-01,\n",
      "          -1.4663e+00,  7.0227e-01, -1.4605e+00, -7.2605e-01, -9.5838e-01,\n",
      "           0.0000e+00,  8.9705e-01,  1.7003e-01,  1.2853e+00, -7.5215e-01,\n",
      "          -8.2358e-01,  5.3004e-01, -1.5831e+00,  9.8408e-01,  2.7608e-01,\n",
      "          -5.8958e-01,  6.5950e-01,  5.7428e-01, -1.1587e+00, -1.0100e+00,\n",
      "          -3.8861e-01,  6.7781e-01, -7.8994e-01, -1.0141e-01, -1.6857e+00,\n",
      "          -1.0095e-01, -5.4324e-01, -8.4443e-01, -7.5540e-01,  1.7759e-01,\n",
      "           1.9986e+00, -1.9964e-01, -1.9304e+00, -4.0612e-01,  0.0000e+00,\n",
      "          -1.9444e-01, -6.4378e-02, -1.2934e-01,  3.9326e-02,  5.3764e-01,\n",
      "          -2.6460e-02,  2.2064e+00,  4.8112e-01, -5.4992e-01, -5.2672e-01,\n",
      "          -8.9233e-01,  2.8162e-01,  8.3996e-02, -3.5804e-01, -4.7801e-01,\n",
      "           7.3744e-01, -3.1719e-02,  2.0033e-02, -1.0020e+00,  1.2778e+00,\n",
      "          -1.0985e+00, -9.8711e-01, -2.0769e+00,  1.9691e+00,  0.0000e+00,\n",
      "           0.0000e+00,  3.5052e-02,  6.7124e-01,  9.7987e-01, -7.4696e-01,\n",
      "           0.0000e+00, -2.7831e+00, -7.8408e-01,  1.2097e+00,  1.0124e+00,\n",
      "           3.0742e+00,  4.9439e-01, -1.4434e-01, -5.9413e-01,  5.6061e-01,\n",
      "           2.1651e+00, -1.1879e+00,  5.3503e-01,  1.8116e+00, -9.4693e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  0.0000e+00,  0.0000e+00,  2.3199e-01,\n",
      "          -5.7515e-01, -2.2928e+00,  6.8178e-01, -1.0743e+00, -4.7120e-01,\n",
      "           2.8679e+00, -5.7341e-01,  0.0000e+00,  7.9310e-01,  3.0234e-02,\n",
      "          -6.8431e-01, -1.0189e+00,  9.6636e-01, -2.4565e-01,  2.1694e+00,\n",
      "          -1.0828e+00, -4.2727e-01, -1.8438e+00, -5.0093e-01,  3.3787e-01,\n",
      "           7.0496e-01, -6.9647e-01, -6.2819e-01,  2.9227e-01, -1.5785e+00,\n",
      "          -1.1086e+00,  1.5814e+00, -6.1413e-01,  1.3099e+00, -2.9798e+00,\n",
      "           4.0354e+00,  5.8525e-01,  4.3350e-02, -1.5797e+00, -2.8706e-01,\n",
      "           7.4178e-01,  0.0000e+00, -3.0439e-01,  0.0000e+00,  1.1333e-02,\n",
      "           2.7539e-01,  2.7474e-01,  2.5250e-01,  0.0000e+00,  3.8657e-01,\n",
      "          -3.6559e-01, -1.5885e-01,  0.0000e+00, -5.2629e-02, -1.1468e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0458, 0.0464, 0.0778, 0.0632, 0.1352, 0.3410, 0.0633, 0.0680, 0.0606,\n",
      "         0.0987]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.8259e-01,  2.2744e-01, -2.7770e-01, -1.1618e-01, -3.0818e-01,\n",
      "          -2.0976e-01, -5.5847e-02, -2.4865e-01,  1.9467e-04,  4.0401e-02,\n",
      "           2.4898e-01, -1.1113e-01, -1.5879e-01,  3.5852e-03,  2.8036e-01,\n",
      "          -1.0198e-01,  3.5579e-02,  1.6604e-01, -2.8402e-01, -3.2563e-02,\n",
      "          -1.8019e-01, -1.4761e-01,  3.6893e-02,  3.8066e-02, -2.5648e-01,\n",
      "          -8.1239e-02, -5.7301e-02, -2.6617e-01, -3.5116e-02, -1.5422e-01,\n",
      "           2.1673e-01, -1.8055e-01, -1.8566e-01, -4.1964e-01, -3.6344e-02,\n",
      "           1.5177e-01, -6.2625e-02, -1.1755e-01, -2.5238e-01,  1.7587e-03,\n",
      "          -5.6181e-02,  1.7093e-01, -2.1524e-01,  4.3567e-02,  2.0092e-01,\n",
      "           1.8229e-01,  1.3011e-01, -4.1423e-01,  1.0175e-01, -7.4856e-02,\n",
      "          -8.9359e-02, -1.2265e-01, -2.4334e-01, -1.8289e-02, -1.6317e-01,\n",
      "           4.2858e-03, -6.2037e-02,  1.6264e-01,  9.2697e-02,  3.4394e-01,\n",
      "           3.1498e-04, -1.2460e-01, -2.6217e-01,  2.0379e-01, -1.7835e-01,\n",
      "          -8.0812e-02, -2.8026e-02,  1.4866e-01, -2.1179e-01,  1.4812e-01,\n",
      "           5.1320e-02,  2.4534e-01,  3.0403e-02,  2.3613e-01, -2.0565e-01,\n",
      "           1.6839e-01,  3.5762e-01,  1.8612e-01,  3.1347e-02,  1.9560e-01,\n",
      "          -5.8003e-02, -2.3019e-01, -2.4684e-01, -3.4711e-03, -1.1379e-02,\n",
      "           2.0736e-01,  5.3261e-02,  1.0645e-02,  1.5750e-01, -2.1577e-01,\n",
      "           1.5109e-01,  8.8823e-02,  7.9566e-02, -9.7463e-02, -1.3177e-01,\n",
      "           1.7387e-01,  9.6957e-02,  2.4825e-01,  3.0375e-03,  1.5953e-01,\n",
      "          -2.2816e-01,  4.2093e-02,  1.2369e-01,  7.7431e-02, -7.8825e-02,\n",
      "          -1.4847e-01,  1.0618e-01,  3.6147e-01, -1.0611e-01,  3.1805e-01,\n",
      "           2.0579e-01,  6.0767e-02,  1.3480e-01, -2.9667e-01, -1.0599e-01,\n",
      "           6.6044e-02,  1.2093e-01, -9.4649e-02, -6.0330e-02, -1.2593e-01,\n",
      "           5.8176e-02, -2.2351e-01, -2.4650e-01,  1.1343e-01, -2.6851e-01,\n",
      "          -2.1644e-01,  1.0631e-01, -3.0170e-02,  2.7190e-01, -2.8622e-01,\n",
      "          -8.6941e-02, -1.7237e-01,  1.3771e-01,  3.6651e-01,  3.7413e-02,\n",
      "           2.3874e-02,  1.5844e-01,  1.3172e-01, -6.2817e-02,  1.1149e-01,\n",
      "          -7.9327e-02,  2.3710e-01, -9.3411e-02,  1.4920e-01, -1.2108e-02,\n",
      "          -2.0193e-02, -6.1441e-02,  2.2540e-01,  3.9612e-02,  2.0117e-01,\n",
      "          -3.1928e-01,  8.1900e-02, -1.2157e-01,  1.3212e-01,  1.8757e-01,\n",
      "           2.0236e-01, -1.1336e-01,  3.4515e-01, -2.7573e-03, -8.0820e-02,\n",
      "          -1.1723e-01,  1.6883e-02, -1.7094e-01,  3.0477e-01,  4.0339e-03,\n",
      "           1.0079e-01, -5.1437e-02, -7.0552e-02,  2.7314e-01,  2.6200e-01,\n",
      "          -2.2573e-01,  1.8184e-01,  2.8257e-01, -2.2844e-02, -6.4639e-02,\n",
      "          -2.1942e-01, -2.1585e-02,  5.5175e-02,  2.9982e-01, -1.0116e-02,\n",
      "          -9.5632e-02, -1.1924e-01, -1.9900e-01, -1.0706e-01,  9.1175e-02,\n",
      "           7.3562e-02, -2.9374e-01,  6.6526e-02,  8.3775e-02,  3.2941e-02,\n",
      "          -4.2950e-02,  1.4406e-01, -3.3983e-01, -1.8339e-01, -5.2713e-03,\n",
      "          -1.3859e-01, -8.9219e-02, -3.7190e-02, -1.9781e-01,  1.5287e-01,\n",
      "           5.9904e-02,  1.3451e-01, -9.1141e-02,  2.2627e-01, -1.0763e-01,\n",
      "          -4.4091e-02, -6.5381e-02,  2.1496e-01, -1.7469e-01, -8.6286e-02,\n",
      "           1.0557e-01, -1.1679e-01, -2.1041e-01,  2.7818e-01,  8.1747e-02,\n",
      "           1.9399e-01, -1.0082e-01,  6.7946e-02, -2.7893e-01,  3.3482e-01,\n",
      "           2.0248e-01,  3.9799e-02,  1.2364e-01, -2.3375e-01,  1.0516e-01,\n",
      "           1.8025e-01,  1.0739e-01, -8.4354e-02, -3.4617e-01,  1.8177e-01,\n",
      "          -3.5085e-02, -6.0789e-02, -8.2130e-02, -1.3023e-01, -1.0594e-01,\n",
      "          -3.3588e-02, -1.8685e-01, -8.9643e-02,  3.0153e-01,  9.0216e-02,\n",
      "          -1.4056e-01, -1.5089e-01, -2.8819e-01, -2.7831e-02,  9.6306e-02,\n",
      "           7.9600e-02, -2.6660e-01, -3.7146e-01,  1.7160e-01,  1.8778e-02,\n",
      "           1.0041e-01, -1.0090e-01, -2.5725e-01, -1.8982e-01,  1.3501e-01,\n",
      "          -1.1118e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1546, -1.4812,  1.6542, -1.0093, -1.1129,  0.4008,  0.6460,\n",
      "           0.0000,  0.0000,  0.0943, -0.2102,  0.3158,  0.1262, -0.9576,\n",
      "          -0.3085,  0.3244, -1.8654, -2.1361,  0.6079, -0.5292,  0.7697,\n",
      "           0.2831, -1.2572, -0.9728,  1.1923,  1.4258, -1.6558,  1.0545,\n",
      "           0.9844, -1.2886,  0.3066, -0.9454, -0.7688, -1.5227, -0.3682,\n",
      "           0.4838,  0.0000, -0.3507,  0.3282,  0.6279,  0.6073,  0.0000,\n",
      "           0.3725,  1.2540, -1.7950,  1.9479, -1.4983, -0.4425, -0.2787,\n",
      "           1.1462,  0.8645,  0.0355, -0.0721, -1.0043, -0.2963, -0.8048,\n",
      "          -1.8690,  0.5101,  1.5726,  2.0572, -0.8821, -0.7340,  1.9471,\n",
      "          -0.9059, -0.8591,  0.1078,  0.6386, -0.6168,  0.0205,  0.4298,\n",
      "          -1.5891,  0.0000,  0.0000,  1.4261, -0.4464,  0.5576, -3.6194,\n",
      "          -0.6178, -1.4062, -0.3104,  0.0000,  1.3118,  0.8810, -0.9602,\n",
      "           0.6945,  0.6940,  0.0461, -2.9894,  0.8146, -0.0184,  0.0000,\n",
      "           0.3246, -1.2887,  2.3923,  1.8840,  0.2151, -1.1104,  1.0774,\n",
      "           1.5505,  0.0000,  0.0142, -0.6633, -1.1344, -1.8829,  0.4069,\n",
      "           1.4167, -1.9889, -0.9156,  0.0000,  0.0000, -1.4321,  0.1790,\n",
      "          -0.4971,  1.2999, -0.1464, -0.1101,  0.3375, -1.6422,  0.8515,\n",
      "          -1.2943, -1.3455, -0.0994,  0.8787,  0.5349,  0.2248,  0.8196,\n",
      "          -0.2031, -1.0701,  0.1244, -0.4277, -1.2482,  2.3284,  1.4194,\n",
      "           0.3275, -0.0093,  0.0000, -0.0639, -0.5993, -0.4515,  1.0986,\n",
      "           0.5455, -1.1798, -2.2947, -0.8854,  0.0000, -0.1876,  0.9173,\n",
      "          -0.0829,  1.5432,  0.0000,  0.3219, -1.3512,  1.8156, -1.9308,\n",
      "           0.0000, -0.3340, -0.2289, -0.7580,  0.0000, -0.0182,  0.2297,\n",
      "          -1.1458,  2.2615, -1.7644, -0.3898, -0.6918,  0.5297,  2.1351,\n",
      "          -1.6401, -2.7421,  1.2535, -2.0850, -0.0059, -1.1598, -0.9214,\n",
      "          -0.7982, -0.3060, -0.4303,  0.1177, -1.5136,  0.1503, -0.4531,\n",
      "           0.1991,  0.9699,  0.4839, -0.0759,  0.0000, -0.2137,  0.4031,\n",
      "          -1.4622,  1.0709,  0.6060,  0.5035, -0.5078,  0.7246, -0.0431,\n",
      "           1.8720,  0.0431, -0.8384, -0.2755,  0.1188, -0.2976,  0.2832,\n",
      "           0.3538, -0.0091, -0.7144,  0.6960,  2.0161, -0.7492,  1.8921,\n",
      "           2.7889,  0.1561,  0.0000,  0.1010, -0.5909, -0.0220, -0.1423,\n",
      "          -1.3819,  0.4087,  0.6371, -0.6887,  1.8592,  0.6068,  0.4731,\n",
      "           0.0295,  0.0000, -0.3648, -0.2609,  0.8420, -0.2542,  0.7767,\n",
      "          -0.5511,  1.2381,  0.0929,  2.0767,  0.0000, -1.7044,  2.7778,\n",
      "          -1.4948,  1.8029, -0.8493,  0.2571, -1.0495, -0.8531,  0.1358,\n",
      "          -1.7791,  0.3813,  1.9827,  0.5693,  0.5471, -1.7500,  0.3682,\n",
      "           0.1557,  0.0000, -2.7257,  0.4069]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0364, 0.1880, 0.1133, 0.0693, 0.1159, 0.1510, 0.0716, 0.0511, 0.1054,\n",
      "         0.0979]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1337,  0.0745, -0.1547, -0.0132, -0.1283, -0.0561, -0.1808,\n",
      "          -0.1413, -0.0905,  0.1490,  0.1953, -0.0286, -0.0436, -0.0082,\n",
      "           0.1986,  0.0237, -0.0107,  0.1607, -0.1674, -0.0150, -0.1856,\n",
      "          -0.0004, -0.0980, -0.0119, -0.1820, -0.0494, -0.0288, -0.2052,\n",
      "           0.0494, -0.0957,  0.1764, -0.0261, -0.1200, -0.2878, -0.0747,\n",
      "           0.0500,  0.1085, -0.0192, -0.0760,  0.0106, -0.0638,  0.2117,\n",
      "          -0.1682, -0.0603,  0.1754,  0.1149,  0.2264, -0.2909,  0.0574,\n",
      "          -0.0422, -0.0150, -0.0736, -0.1191,  0.0039, -0.1907,  0.0094,\n",
      "          -0.0270,  0.1483, -0.0240,  0.2245,  0.0678, -0.0466, -0.1479,\n",
      "           0.1503, -0.1905, -0.0873,  0.0486,  0.0852, -0.2069,  0.1200,\n",
      "           0.0008,  0.1870,  0.0704,  0.0628, -0.1057,  0.1533,  0.2409,\n",
      "           0.1489,  0.0595,  0.1627,  0.0552, -0.1034, -0.0722,  0.0916,\n",
      "           0.0279,  0.1003,  0.0850, -0.0267,  0.0621, -0.1545,  0.1260,\n",
      "           0.0901,  0.0795, -0.0832, -0.0921,  0.0782,  0.0404,  0.1638,\n",
      "           0.0708,  0.0114, -0.1190, -0.0430,  0.0640,  0.0567,  0.0346,\n",
      "          -0.1154, -0.0257,  0.3104, -0.0988,  0.2796,  0.1423,  0.0622,\n",
      "           0.0559, -0.1438,  0.0417,  0.1029,  0.1242, -0.0321, -0.0059,\n",
      "          -0.0194,  0.1014, -0.1996, -0.1652,  0.1147, -0.2475, -0.2231,\n",
      "           0.0915,  0.0800,  0.2112, -0.2025, -0.0878,  0.0418, -0.0025,\n",
      "           0.3708,  0.1227,  0.0010,  0.0598,  0.0819,  0.1469,  0.0367,\n",
      "          -0.0929,  0.1062, -0.0618,  0.0419, -0.0917,  0.0135, -0.0221,\n",
      "           0.1066,  0.0319,  0.1118, -0.1460,  0.0427, -0.0797,  0.0097,\n",
      "           0.1355,  0.0691, -0.0575,  0.3301, -0.1033,  0.0151, -0.1002,\n",
      "           0.1474, -0.0126,  0.1160,  0.0098, -0.0278,  0.0333,  0.0346,\n",
      "           0.1398,  0.1213, -0.1672,  0.1936,  0.1632,  0.0810,  0.0272,\n",
      "          -0.1419,  0.0955,  0.0143,  0.1257,  0.1054,  0.0160, -0.0500,\n",
      "          -0.0577, -0.1089, -0.0152,  0.0176, -0.0992, -0.0212,  0.0370,\n",
      "           0.1674, -0.0546,  0.1228, -0.2019, -0.1124, -0.0197, -0.0309,\n",
      "          -0.1204, -0.0359, -0.1294,  0.0837,  0.0586,  0.1582, -0.0717,\n",
      "           0.1509, -0.1831, -0.0145, -0.0790,  0.0133, -0.1502, -0.1040,\n",
      "           0.0413, -0.0340, -0.1645,  0.1666,  0.1394,  0.0613, -0.0123,\n",
      "          -0.0462, -0.1791,  0.2893,  0.1252,  0.0706,  0.0277, -0.1438,\n",
      "          -0.0851,  0.1201,  0.0522, -0.0052, -0.1967,  0.0901,  0.1436,\n",
      "          -0.0333, -0.0127,  0.0997, -0.0774, -0.0058, -0.1071, -0.0966,\n",
      "           0.2565,  0.0395, -0.0902, -0.0251, -0.1934,  0.0096,  0.0466,\n",
      "           0.0713, -0.0920, -0.2712,  0.1260, -0.0420,  0.0354, -0.0999,\n",
      "          -0.0922, -0.1288,  0.1716, -0.1770]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7783, -1.6519, -0.1830, -0.7321,  2.5182,  0.0000,\n",
      "          -0.0323,  0.9501,  1.1946,  1.4103, -0.7569, -0.0650,  0.0644,\n",
      "           1.0465,  1.8850,  0.8700, -0.7846, -0.6402, -1.4035, -0.4984,\n",
      "          -0.3791,  1.1427,  0.0000,  0.1892, -0.6130,  1.4040, -0.1509,\n",
      "          -1.0408,  0.4962,  0.0000,  0.6009,  0.0000,  0.2318, -0.0795,\n",
      "           0.1484,  0.0000, -2.2131,  1.0517,  0.1023, -0.6920, -0.4362,\n",
      "          -1.0641,  0.8179, -0.6327, -0.6562,  1.3726,  0.9365,  0.0000,\n",
      "           0.3694, -1.0082, -1.1722, -1.1124,  1.2530, -1.9745,  0.0000,\n",
      "           0.5930, -1.8923,  0.3414, -0.2937, -0.7702,  1.8692, -0.5939,\n",
      "           0.0000, -0.8354,  1.2344, -0.3574,  0.2899, -0.7527, -1.1645,\n",
      "           2.2476,  0.7805,  0.2706,  0.0000, -0.3983,  0.3548,  0.2297,\n",
      "          -0.1575, -0.9149,  0.2959, -0.1449,  1.2864,  0.4653,  1.2970,\n",
      "           0.7705,  0.6606,  1.0454, -0.3682,  0.0000, -1.4363,  1.3105,\n",
      "          -1.5854, -0.1111,  3.2389,  0.3469,  1.0034, -0.8684,  0.7312,\n",
      "           0.0000,  0.0000,  0.1908,  0.0286, -0.5965,  1.0585, -0.2310,\n",
      "           0.7758,  0.0000, -0.3678, -0.2785, -0.5476, -0.1379, -3.2783,\n",
      "           0.0000, -1.8785,  0.0000,  1.6883,  2.0295, -1.6459, -0.8963,\n",
      "           2.5843, -1.3262,  1.4237, -0.6275,  0.4670,  1.3157, -0.9869,\n",
      "           0.0736, -0.9854,  0.0000,  0.2475, -1.2008,  1.1298,  1.1405,\n",
      "           1.4885,  0.3787,  0.6466, -0.8378,  0.2416,  0.3446, -1.2616,\n",
      "           0.0305,  0.8639,  0.5015,  0.9069, -1.2681, -0.6409, -0.4416,\n",
      "           0.8728, -0.0675,  0.0425, -0.0565,  0.6208,  0.1452, -0.1962,\n",
      "           0.1078, -1.6722, -0.4024,  0.2513, -2.0698,  0.4120,  1.1555,\n",
      "           0.1996,  0.9130,  0.8435,  0.4175,  1.6038,  0.1773, -1.1144,\n",
      "          -0.3224,  0.2509,  0.4446, -0.4552,  0.4446, -1.3451,  1.7354,\n",
      "           0.5173,  0.0000,  0.2896, -1.8321, -1.8661,  0.2595, -0.6474,\n",
      "          -1.1657,  0.3290, -0.7441,  0.5922, -1.2415, -1.5175, -2.3035,\n",
      "           0.1465, -1.6242, -1.3209, -0.0498,  0.0000,  0.9803, -1.4146,\n",
      "          -1.1402,  3.0139, -0.2259,  1.0330,  0.0291,  0.1193, -1.3194,\n",
      "          -1.0708,  0.0566,  1.7330,  0.5271,  1.9822, -0.9788, -1.3424,\n",
      "           1.5993, -0.4016,  2.4608, -0.5198,  0.7545,  0.2066, -0.8210,\n",
      "           0.9058, -3.5300,  0.1758, -0.7814, -0.6932, -1.4187,  0.2511,\n",
      "          -0.0646, -1.4654,  0.0000, -0.5197,  0.0465, -0.6251, -0.0712,\n",
      "           0.7485, -2.0270, -1.0491, -0.4314, -0.1123,  0.5161, -2.7968,\n",
      "          -1.4577,  0.0000,  1.0259,  0.1328,  2.7509,  1.0027,  0.5473,\n",
      "          -0.1735, -1.5054,  2.2320,  0.0000, -0.0479,  0.7227,  0.0000,\n",
      "           0.0000, -0.0138, -0.8381, -0.5806]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0297, 0.1668, 0.1331, 0.0795, 0.0780, 0.1114, 0.0621, 0.0887, 0.1416,\n",
      "         0.1091]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0913,  0.0569, -0.1328, -0.0019, -0.1040, -0.0398, -0.1673,\n",
      "          -0.1023, -0.0950,  0.1724,  0.1713, -0.0130, -0.0138, -0.0217,\n",
      "           0.1430,  0.0320, -0.0109,  0.1375, -0.1188, -0.0131, -0.1718,\n",
      "           0.0300, -0.1241, -0.0167, -0.1484, -0.0253, -0.0337, -0.1746,\n",
      "           0.0606, -0.0942,  0.1479,  0.0027, -0.0987, -0.2528, -0.0608,\n",
      "           0.0356,  0.1303, -0.0036, -0.0539,  0.0038, -0.0735,  0.1935,\n",
      "          -0.1376, -0.0534,  0.1676,  0.0756,  0.2322, -0.2571,  0.0244,\n",
      "          -0.0256, -0.0049, -0.0541, -0.0920,  0.0144, -0.1771,  0.0009,\n",
      "          -0.0144,  0.1229, -0.0483,  0.1949,  0.0737, -0.0361, -0.1134,\n",
      "           0.1214, -0.1727, -0.0838,  0.0689,  0.0502, -0.1784,  0.0871,\n",
      "          -0.0133,  0.1504,  0.0778,  0.0565, -0.0688,  0.1165,  0.2106,\n",
      "           0.1233,  0.0499,  0.1370,  0.0696, -0.0854, -0.0268,  0.0804,\n",
      "           0.0248,  0.0749,  0.0740, -0.0354,  0.0313, -0.1425,  0.1152,\n",
      "           0.0950,  0.0812, -0.0768, -0.0949,  0.0698,  0.0146,  0.1338,\n",
      "           0.0622, -0.0290, -0.1075, -0.0606,  0.0557,  0.0434,  0.0359,\n",
      "          -0.1117, -0.0324,  0.2672, -0.0736,  0.2383,  0.1296,  0.0500,\n",
      "           0.0471, -0.1048,  0.0641,  0.0950,  0.1212, -0.0352,  0.0131,\n",
      "           0.0005,  0.1072, -0.1794, -0.1183,  0.1014, -0.2044, -0.2047,\n",
      "           0.0935,  0.0963,  0.1759, -0.1766, -0.0925,  0.0697, -0.0098,\n",
      "           0.3334,  0.1244, -0.0038,  0.0274,  0.0594,  0.1623,  0.0034,\n",
      "          -0.0628,  0.0677, -0.0372,  0.0328, -0.1022,  0.0156, -0.0265,\n",
      "           0.0603,  0.0160,  0.0840, -0.0721,  0.0198, -0.0707, -0.0167,\n",
      "           0.1110,  0.0220, -0.0394,  0.2949, -0.1057,  0.0446, -0.0691,\n",
      "           0.1551,  0.0313,  0.0637,  0.0202, -0.0406,  0.0415,  0.0468,\n",
      "           0.1258,  0.0971, -0.1411,  0.1754,  0.1292,  0.0674,  0.0347,\n",
      "          -0.1119,  0.0943, -0.0030,  0.0753,  0.1078,  0.0484, -0.0293,\n",
      "          -0.0216, -0.1035, -0.0327, -0.0010, -0.0616, -0.0275,  0.0414,\n",
      "           0.1725, -0.0563,  0.0980, -0.1489, -0.1067, -0.0188, -0.0147,\n",
      "          -0.1158, -0.0365, -0.0994,  0.0754,  0.0544,  0.1488, -0.0611,\n",
      "           0.1168, -0.1746,  0.0121, -0.0779, -0.0231, -0.1364, -0.0778,\n",
      "           0.0518, -0.0253, -0.1604,  0.1333,  0.1381,  0.0421,  0.0021,\n",
      "          -0.0708, -0.1473,  0.2665,  0.0785,  0.0777,  0.0029, -0.1297,\n",
      "          -0.1075,  0.0889,  0.0463,  0.0215, -0.1422,  0.0687,  0.1584,\n",
      "          -0.0188,  0.0078,  0.1307, -0.0612,  0.0042, -0.0856, -0.1006,\n",
      "           0.2225,  0.0179, -0.0524,  0.0040, -0.1694, -0.0096,  0.0280,\n",
      "           0.0765, -0.0749, -0.2274,  0.1149, -0.0333,  0.0245, -0.0946,\n",
      "          -0.0721, -0.0979,  0.1554, -0.1731]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.3106e-01, -8.3060e-01, -2.5498e-01,  3.9857e-01,  1.9360e-01,\n",
      "           6.1338e-01,  1.6555e-01, -4.1872e-01, -1.4690e+00,  5.9157e-02,\n",
      "          -3.0248e+00,  4.2487e-01,  5.8981e-01,  0.0000e+00, -3.7112e-02,\n",
      "           1.0813e+00,  7.6764e-02,  0.0000e+00, -9.9855e-01, -2.7002e-01,\n",
      "          -1.4123e+00, -5.4196e-01,  8.8805e-01, -1.0163e+00, -6.5147e-01,\n",
      "           4.4582e-01,  1.7871e+00, -5.3182e-02,  9.0657e-01, -6.5943e-01,\n",
      "           5.4175e-01,  1.1402e+00, -1.0073e+00,  7.9406e-01,  4.5921e-01,\n",
      "           2.1509e-01, -8.6813e-01,  2.6794e-01, -2.4542e+00,  8.0233e-01,\n",
      "          -5.9336e-01, -4.4846e-01,  0.0000e+00, -2.6084e-01, -1.1008e-01,\n",
      "           1.1293e+00, -4.2970e-01,  7.9744e-01, -1.3498e+00,  0.0000e+00,\n",
      "           7.0110e-01, -9.6602e-01,  1.8072e-01, -1.4472e+00, -3.0579e-01,\n",
      "           2.7700e-01, -1.3533e+00, -8.2861e-01,  8.0528e-01, -1.0914e+00,\n",
      "          -1.2045e+00, -1.0654e+00, -6.9919e-01,  5.5493e-01,  1.5445e+00,\n",
      "          -4.3756e-01,  2.9127e+00,  2.5572e+00, -1.4436e+00,  1.8086e+00,\n",
      "           4.9493e-01,  0.0000e+00,  3.5455e-01, -1.3759e+00,  8.2515e-01,\n",
      "           1.7005e+00, -1.1025e+00,  6.0874e-02, -8.0800e-01,  1.3906e+00,\n",
      "           1.5475e+00,  0.0000e+00,  7.6854e-01,  1.9526e-01,  1.6250e+00,\n",
      "           8.2122e-01, -7.7764e-01,  1.9401e+00, -1.5345e+00,  1.2125e+00,\n",
      "          -1.4805e+00,  1.0960e+00, -1.7629e+00, -9.4050e-01, -4.3915e-01,\n",
      "           1.7317e+00,  7.8505e-01, -1.7628e+00, -6.7819e-01,  8.8549e-01,\n",
      "          -2.8706e-01,  0.0000e+00,  1.5801e+00,  1.9724e+00, -1.5880e+00,\n",
      "          -8.7903e-02,  1.9644e+00,  1.3440e-01, -3.0951e+00,  9.1809e-01,\n",
      "           1.9892e+00, -3.5374e-01,  0.0000e+00,  0.0000e+00,  1.2823e+00,\n",
      "           1.5626e+00,  1.7676e-01,  1.2572e+00, -5.2612e-01, -5.5701e-01,\n",
      "          -5.2172e-01,  0.0000e+00, -2.0074e+00, -9.3169e-01, -5.9879e-01,\n",
      "          -1.2767e+00,  9.0108e-01,  4.3564e-01,  3.1687e-01,  1.3609e+00,\n",
      "           1.2784e+00,  1.0542e-02,  1.8753e+00,  8.3411e-01, -3.4287e-01,\n",
      "          -3.0404e-01,  7.3028e-01,  1.9282e+00, -1.7698e+00, -6.4126e-01,\n",
      "          -8.9623e-01, -2.6783e+00,  0.0000e+00, -5.8196e-02, -1.3070e+00,\n",
      "          -8.2546e-02,  3.1253e+00, -1.5181e+00,  1.0867e+00,  1.0220e+00,\n",
      "           1.3442e-01, -1.0886e-01, -1.0587e+00,  1.1563e-01, -2.6515e+00,\n",
      "           5.9657e-01,  1.4740e+00,  1.2391e+00,  0.0000e+00,  9.7036e-02,\n",
      "           1.4345e+00,  6.5948e-01, -1.3048e+00,  1.6049e+00, -5.8681e-01,\n",
      "           6.6594e-01,  7.2463e-02,  1.7837e+00, -1.6901e+00, -2.2446e+00,\n",
      "          -7.8907e-01, -3.5949e-01, -2.0299e+00,  8.2728e-01,  0.0000e+00,\n",
      "           2.1349e+00, -4.9794e-01,  2.2048e+00, -4.5738e-01,  2.2718e+00,\n",
      "          -4.0611e-01, -2.5274e-01, -1.5406e+00, -3.7601e-01,  8.5012e-02,\n",
      "          -1.9216e+00,  2.9505e-01,  0.0000e+00,  1.9828e+00, -2.2809e-01,\n",
      "          -8.6863e-01,  3.0236e-01,  3.7450e-01,  7.5171e-01,  5.6028e-02,\n",
      "          -4.2522e-01, -2.0860e+00,  8.0202e-01, -2.2096e-01,  1.0658e+00,\n",
      "          -1.7141e-01,  0.0000e+00, -7.8533e-01,  1.5704e+00, -1.3153e-01,\n",
      "          -1.7000e+00,  8.2043e-01, -2.2263e+00, -1.2566e-01,  1.7265e-01,\n",
      "           1.4797e-01,  2.1166e+00, -1.5629e+00, -1.2245e+00, -2.6222e-01,\n",
      "           1.6274e+00,  0.0000e+00,  1.2437e+00, -4.2566e-01,  1.8715e+00,\n",
      "           1.5470e+00, -3.8676e+00,  0.0000e+00,  2.3761e-01, -1.6835e+00,\n",
      "           8.1555e-01,  7.7786e-01, -8.2077e-01,  2.4708e-01,  5.8894e-01,\n",
      "          -6.2838e-01,  1.8722e-03, -1.3334e-01,  2.2607e+00,  5.6006e-01,\n",
      "           0.0000e+00,  1.4489e+00,  1.2746e+00, -1.4761e+00,  1.8639e+00,\n",
      "           0.0000e+00,  8.8314e-01,  2.1332e+00, -5.7521e-01, -6.1863e-01,\n",
      "           7.6653e-01, -3.1978e-02, -8.8060e-01,  1.2472e+00, -6.9893e-01,\n",
      "          -1.7887e+00, -5.7803e-01,  5.7429e-01,  1.8699e+00, -1.2900e+00,\n",
      "           1.1258e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1593, 0.0703, 0.0884, 0.0696, 0.1399, 0.0923, 0.0345, 0.1766, 0.1264,\n",
      "         0.0427]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1602,  0.0807, -0.1057, -0.0741, -0.1196, -0.0187, -0.1638,\n",
      "          -0.0910, -0.0779,  0.1227,  0.1480, -0.0197, -0.0294,  0.0184,\n",
      "           0.1896,  0.0179,  0.0113,  0.1327, -0.1579, -0.0575, -0.1102,\n",
      "          -0.0207, -0.0995, -0.0549, -0.1778,  0.0433, -0.0024, -0.1376,\n",
      "           0.0490, -0.0768,  0.1643, -0.0470, -0.0751, -0.2681, -0.0836,\n",
      "           0.0090,  0.0814, -0.0341, -0.0176, -0.0090, -0.0194,  0.1573,\n",
      "          -0.1288, -0.0548,  0.1503,  0.0644,  0.2223, -0.2001,  0.0508,\n",
      "          -0.0739,  0.0236, -0.1342, -0.1013, -0.0348, -0.1748, -0.0220,\n",
      "          -0.0475,  0.1138,  0.0049,  0.1812,  0.0720, -0.0885, -0.1720,\n",
      "           0.1715, -0.1128, -0.0569,  0.0095,  0.0590, -0.1979,  0.1095,\n",
      "          -0.0135,  0.1959,  0.0739,  0.0454, -0.0978,  0.1860,  0.2079,\n",
      "           0.0750,  0.0303,  0.1283,  0.0195, -0.0249, -0.0774,  0.0611,\n",
      "           0.0438,  0.1103,  0.0747,  0.0127,  0.0564, -0.1149,  0.0693,\n",
      "           0.1480,  0.0126, -0.0703, -0.0961,  0.1008,  0.0625,  0.1404,\n",
      "           0.0427, -0.0141, -0.0449, -0.0052,  0.0047,  0.0838,  0.0470,\n",
      "          -0.0651, -0.0180,  0.2351, -0.1046,  0.2381,  0.0733,  0.0557,\n",
      "          -0.0058, -0.1406,  0.0444,  0.0690,  0.1461, -0.0433, -0.0373,\n",
      "          -0.0576,  0.0594, -0.1783, -0.1162,  0.0910, -0.2053, -0.1314,\n",
      "           0.0699,  0.0361,  0.2078, -0.1471, -0.1081,  0.0311,  0.0155,\n",
      "           0.2752,  0.1589, -0.0432,  0.0133,  0.1248,  0.1703,  0.0107,\n",
      "          -0.0632,  0.1346, -0.0578,  0.0306, -0.1213,  0.0249, -0.0059,\n",
      "           0.1059, -0.0058,  0.0994, -0.1237,  0.0285, -0.0653, -0.0050,\n",
      "           0.0918,  0.0810, -0.0315,  0.2841, -0.1064,  0.0378, -0.0829,\n",
      "           0.1547, -0.0410,  0.1186, -0.0827,  0.0161,  0.0087,  0.0520,\n",
      "           0.0543,  0.0788, -0.1068,  0.1773,  0.1518,  0.0884,  0.0644,\n",
      "          -0.1423,  0.0866, -0.0175,  0.1243,  0.0921,  0.0325, -0.0086,\n",
      "          -0.0817, -0.0944,  0.0451, -0.0373, -0.0671, -0.0571, -0.0379,\n",
      "           0.1375,  0.0017,  0.0483, -0.1888, -0.1090, -0.0895, -0.0116,\n",
      "          -0.0601,  0.0073, -0.0794,  0.0679,  0.0728,  0.0888, -0.0111,\n",
      "           0.0869, -0.2212, -0.0163, -0.0956,  0.0275, -0.1172,  0.0085,\n",
      "           0.0332, -0.0092, -0.1887,  0.1300,  0.1189,  0.0336,  0.0358,\n",
      "           0.0274, -0.1918,  0.1627,  0.1061,  0.1016,  0.0712, -0.1706,\n",
      "          -0.0740,  0.0948,  0.0028, -0.0176, -0.2198,  0.0462,  0.1737,\n",
      "          -0.0431, -0.0620,  0.1164, -0.0386, -0.0381, -0.1351, -0.0544,\n",
      "           0.1924,  0.0520, -0.0248, -0.0952, -0.1707,  0.0531,  0.0289,\n",
      "           0.0714, -0.0941, -0.2755,  0.0740, -0.0783,  0.0370, -0.0704,\n",
      "          -0.0929, -0.1257,  0.1324, -0.1914]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0151,  2.5463, -1.2112,  0.3191,  2.8284,  0.1508, -1.1529,\n",
      "          -0.6595, -0.5220,  1.0088,  0.3144,  1.2841,  1.7831, -0.4716,\n",
      "          -0.1834,  0.7701,  0.2503, -1.3099,  0.3435, -0.5861,  0.9932,\n",
      "          -1.7861,  1.2512, -0.0230, -0.4594, -1.5185,  1.2492, -0.9561,\n",
      "          -0.4021, -1.9980,  0.0000, -1.3592,  0.0000, -0.2463,  0.0000,\n",
      "           0.6965, -0.1753, -0.0718, -1.4900, -0.4070, -0.2116,  0.5746,\n",
      "          -0.5175,  0.0000,  2.9502, -1.0839,  1.9783, -0.4246, -0.8231,\n",
      "           0.0000, -0.4982,  0.0000,  0.9427, -1.3952, -1.4161, -0.4912,\n",
      "          -0.6165, -0.9834,  0.0000,  0.8258, -1.9420, -0.8721, -1.7987,\n",
      "          -0.8693,  0.0000,  1.9302,  1.2441,  2.4603, -0.8381,  1.8602,\n",
      "           0.1747,  0.4342, -0.4101, -1.5721,  0.0000,  0.0000,  1.4309,\n",
      "          -0.4487, -2.3281,  0.0124, -0.8683,  0.6618,  0.0000, -1.0093,\n",
      "           1.2140, -0.2059, -0.1185,  2.4270,  1.5443,  0.0000, -1.9792,\n",
      "           0.0122, -0.0193,  0.5867, -1.6191,  1.0387,  0.0000,  0.4235,\n",
      "          -0.5803, -1.1147, -1.8122,  2.2470,  0.0000, -0.3550, -0.1248,\n",
      "          -1.2144,  1.4672, -0.3362,  0.7023,  0.0036,  0.0000,  0.1401,\n",
      "          -1.2520, -1.1835, -0.8975, -0.4377, -0.1025,  0.6816, -2.4225,\n",
      "          -0.1510,  1.6464,  0.0637,  0.3848,  1.4618, -1.7584, -0.6341,\n",
      "           0.5832, -0.2331, -1.3785, -0.1602, -0.6146,  1.4725,  0.0000,\n",
      "          -0.8592,  1.4125,  1.2602,  0.0000,  0.0665, -1.1273,  3.1109,\n",
      "           0.3730,  1.4630,  0.0000, -0.6865,  0.3430, -2.2446,  2.5398,\n",
      "          -1.9038,  0.0322, -0.5898, -0.4600,  0.2430, -0.4631,  0.2554,\n",
      "           0.0546, -0.1404,  0.0000,  1.3528,  0.8229,  1.2341,  0.0000,\n",
      "          -1.4113, -1.1295,  1.0924,  0.4921,  0.9735, -0.1907, -0.2346,\n",
      "           1.0662, -1.6279,  0.2402,  1.1247,  0.0000,  0.6054,  0.4388,\n",
      "           0.8534,  1.1224,  0.1387,  0.6315,  0.0000,  0.5851, -0.6843,\n",
      "           0.9186,  0.3967,  0.3372, -1.0975, -1.2381, -0.1655,  0.7088,\n",
      "           1.3704, -0.7438,  0.5762, -2.7100,  0.7346,  0.3630,  0.0000,\n",
      "          -1.3978, -0.1208,  0.4604, -0.4516,  0.0000, -0.6601,  0.0000,\n",
      "          -0.6046, -0.5704, -0.9368,  1.4328, -0.2282,  1.5362, -0.2149,\n",
      "           1.9453,  0.6196,  1.3287,  0.1458,  0.0000, -1.1880,  1.3856,\n",
      "           0.6195, -1.1440, -0.1003, -0.3127, -0.2548,  0.7936,  0.9800,\n",
      "           0.1588,  0.6327,  0.3745,  1.7762,  2.3053,  1.1872, -0.6699,\n",
      "          -1.8384,  0.9627,  1.1820,  0.0860,  2.4994,  0.5777,  0.8646,\n",
      "          -0.4955,  0.0000,  0.4951,  0.9813,  0.5527, -1.4942,  1.4722,\n",
      "          -1.3283, -0.1553,  0.6240, -1.4019,  1.9460,  1.4448, -0.0749,\n",
      "           0.0000,  0.9918,  2.0379,  0.5493]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1063, 0.1422, 0.1088, 0.0510, 0.0918, 0.1573, 0.1284, 0.0944, 0.0939,\n",
      "         0.0258]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1585,  0.0790, -0.1521, -0.0231, -0.1163, -0.0495, -0.1698,\n",
      "          -0.1275, -0.0830,  0.1341,  0.1719, -0.0551, -0.0310, -0.0199,\n",
      "           0.1957,  0.0323,  0.0119,  0.1454, -0.1673, -0.0182, -0.1685,\n",
      "          -0.0166, -0.1022, -0.0048, -0.1855, -0.0497, -0.0371, -0.1748,\n",
      "           0.0300, -0.0921,  0.1658, -0.0517, -0.1090, -0.2644, -0.0829,\n",
      "           0.0257,  0.1023, -0.0342, -0.0486, -0.0086, -0.0409,  0.1684,\n",
      "          -0.1660, -0.0591,  0.1893,  0.0849,  0.2107, -0.2469,  0.0551,\n",
      "          -0.0469, -0.0128, -0.1065, -0.1137, -0.0113, -0.1900, -0.0034,\n",
      "          -0.0388,  0.1554, -0.0073,  0.2088,  0.0664, -0.0589, -0.1712,\n",
      "           0.1507, -0.1508, -0.0683,  0.0294,  0.0806, -0.2133,  0.1106,\n",
      "          -0.0210,  0.2074,  0.0646,  0.0430, -0.1177,  0.1609,  0.2123,\n",
      "           0.1178,  0.0323,  0.1487,  0.0221, -0.1011, -0.0782,  0.0845,\n",
      "           0.0296,  0.1090,  0.0740, -0.0154,  0.0623, -0.1433,  0.1080,\n",
      "           0.1297,  0.0504, -0.0558, -0.0973,  0.0752,  0.0682,  0.1773,\n",
      "           0.0410,  0.0148, -0.0963, -0.0306,  0.0436,  0.0909,  0.0239,\n",
      "          -0.0758, -0.0189,  0.2696, -0.0987,  0.2656,  0.1144,  0.0435,\n",
      "           0.0283, -0.1484,  0.0312,  0.0875,  0.1332, -0.0348, -0.0330,\n",
      "          -0.0472,  0.1084, -0.2076, -0.1571,  0.1048, -0.2327, -0.1743,\n",
      "           0.0752,  0.0621,  0.2261, -0.1671, -0.0682,  0.0039,  0.0316,\n",
      "           0.3285,  0.1349,  0.0074,  0.0771,  0.0915,  0.1422,  0.0214,\n",
      "          -0.0805,  0.1210, -0.0650,  0.0468, -0.0974,  0.0152, -0.0055,\n",
      "           0.1125,  0.0117,  0.1221, -0.1422,  0.0182, -0.0598,  0.0015,\n",
      "           0.1097,  0.0846, -0.0411,  0.3055, -0.0796,  0.0013, -0.1061,\n",
      "           0.1285, -0.0403,  0.1290, -0.0119, -0.0086,  0.0292,  0.0408,\n",
      "           0.1152,  0.1243, -0.1379,  0.1818,  0.1608,  0.0807,  0.0383,\n",
      "          -0.1356,  0.0970,  0.0120,  0.1400,  0.1019,  0.0204, -0.0285,\n",
      "          -0.0703, -0.0961,  0.0123,  0.0121, -0.1010, -0.0220,  0.0295,\n",
      "           0.1408, -0.0365,  0.0949, -0.2096, -0.1166, -0.0286, -0.0261,\n",
      "          -0.1253, -0.0200, -0.1087,  0.0936,  0.0503,  0.1481, -0.0469,\n",
      "           0.1480, -0.1910, -0.0180, -0.0968,  0.0256, -0.1418, -0.0509,\n",
      "           0.0553, -0.0533, -0.1584,  0.1414,  0.1209,  0.0588, -0.0289,\n",
      "          -0.0084, -0.1901,  0.2294,  0.1332,  0.0625,  0.0674, -0.1713,\n",
      "          -0.0837,  0.1129,  0.0589, -0.0183, -0.2202,  0.0930,  0.1112,\n",
      "          -0.0462, -0.0211,  0.0954, -0.0685, -0.0197, -0.1362, -0.0787,\n",
      "           0.2236,  0.0412, -0.0497, -0.0686, -0.2016,  0.0257,  0.0337,\n",
      "           0.0859, -0.0777, -0.2715,  0.1287, -0.0266,  0.0416, -0.0783,\n",
      "          -0.1008, -0.1237,  0.1409, -0.1813]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.6420,  1.7370, -2.1024, -1.1851,  0.5803,  0.9499,  0.0000,\n",
      "           1.1674, -1.0369,  1.0189, -0.9867,  0.1508,  0.2434, -0.3837,\n",
      "           2.9274, -0.3388,  1.1772,  0.4226, -2.1749, -0.7296, -0.7122,\n",
      "          -0.2311,  0.0127,  0.0000, -1.4721,  1.2820, -0.0643, -0.4916,\n",
      "          -1.9715,  0.3204,  0.0000,  0.1358, -0.0229,  0.8380, -2.6093,\n",
      "          -1.8754,  0.7900, -0.3374, -0.2117,  0.6096, -0.3307,  0.0000,\n",
      "          -1.6758,  0.2248, -1.3313, -2.0092, -0.4182, -0.2394, -0.7892,\n",
      "           0.0000,  0.6939, -0.1663, -0.3080, -0.1682, -1.9091,  0.8539,\n",
      "           0.0000,  0.0000, -0.8394,  0.4832,  2.2082,  0.0000,  0.4139,\n",
      "          -0.4334,  0.2591,  0.3694, -1.0591,  0.4587, -1.2130,  1.1572,\n",
      "          -1.2901,  3.1683,  1.0881,  0.8878,  1.5805,  0.5910,  0.8856,\n",
      "          -0.4807, -0.1293, -0.2309, -1.2027, -1.8181,  0.0136, -0.4338,\n",
      "           0.8616, -0.2261,  2.2638,  0.0000, -2.3763,  0.1537,  0.5962,\n",
      "          -0.0324,  1.4256, -1.6163,  0.0000,  1.1068,  0.0000, -1.3206,\n",
      "          -0.5528,  0.7590,  0.1292, -0.9248, -0.9325, -0.2852,  1.0282,\n",
      "          -0.7388,  0.0680, -0.3274, -1.4972, -1.3594, -2.0284, -1.0705,\n",
      "           1.0466,  1.7700, -1.2184, -0.0421,  0.1390,  0.0633,  0.7356,\n",
      "          -0.8668, -0.7520, -1.5736,  0.0000,  1.9047, -0.9795, -0.6391,\n",
      "          -0.8198, -0.4946,  1.2766, -0.4027,  0.8497,  1.0601,  0.2260,\n",
      "          -0.5421,  0.5426,  0.4982,  1.6561, -1.0925, -0.4977,  0.0000,\n",
      "           0.5209,  0.4582,  0.0000, -0.9078, -0.1868,  0.4949,  1.2671,\n",
      "          -0.6359, -0.6064,  0.9711, -0.4895,  0.8396,  0.0000,  0.6919,\n",
      "          -0.4740, -0.5946, -0.9767, -2.2384,  0.3538, -1.0794,  0.7232,\n",
      "          -1.0066, -0.5363, -0.1645, -1.0761, -1.1092, -0.9951, -0.8285,\n",
      "           0.1317, -0.0537,  1.6693, -1.6451, -1.3241,  0.0671, -0.7270,\n",
      "          -1.5267, -3.8519,  1.1385,  0.0000, -0.3911, -0.8043, -1.0272,\n",
      "           0.6064, -1.1395,  1.5705, -2.2786,  0.0000, -0.2664,  1.2895,\n",
      "          -0.0386, -1.0558, -0.9619,  0.0000,  0.2856, -0.1738, -0.4510,\n",
      "           0.9478,  0.0000,  0.3328, -0.2894,  0.6092,  0.4867,  1.1384,\n",
      "           0.1297, -1.3219, -1.1811, -0.2880,  0.0384, -0.0708, -0.3987,\n",
      "           0.0000, -0.0574, -0.9808, -2.0176, -0.2716,  0.0000, -2.4904,\n",
      "           2.7646,  0.6586,  0.0000, -1.2953,  1.5162,  0.5415, -0.3185,\n",
      "           0.8188, -1.5243,  0.3112, -1.2621,  0.2441,  0.0000,  0.0000,\n",
      "           1.3160, -0.9495,  2.0936, -0.4692,  0.0000,  0.0000, -0.2753,\n",
      "          -0.3635,  0.5844, -1.4331,  2.0581,  0.0000, -1.0056, -0.9082,\n",
      "          -0.6274, -2.1825, -0.9633,  1.0142,  2.4826, -0.4953,  0.4079,\n",
      "           2.5138, -0.3826,  1.0960, -1.8665]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0500, 0.0734, 0.1712, 0.0578, 0.0810, 0.1502, 0.1055, 0.1546, 0.0663,\n",
      "         0.0900]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3568e-01,  1.0164e-01, -1.8630e-01, -4.9683e-02, -1.5460e-01,\n",
      "          -1.0037e-01, -1.2259e-01, -1.1159e-01, -7.9287e-02,  1.5609e-01,\n",
      "           1.7544e-01, -4.3959e-02, -3.4748e-02, -4.2557e-02,  1.1581e-01,\n",
      "          -9.8155e-03,  3.0073e-03,  1.3416e-01, -1.4313e-01, -2.1325e-02,\n",
      "          -1.6641e-01, -8.0496e-03, -8.4985e-02, -1.4011e-02, -1.4831e-01,\n",
      "           7.4736e-03, -3.8145e-02, -1.8154e-01,  4.0063e-02, -1.1755e-01,\n",
      "           1.5671e-01, -4.3158e-02, -1.1020e-01, -3.0042e-01, -3.9191e-02,\n",
      "           5.3417e-02,  8.8005e-02, -4.0772e-02, -1.0528e-01, -1.8445e-03,\n",
      "          -8.2890e-02,  1.7449e-01, -1.3664e-01, -4.3401e-03,  1.8264e-01,\n",
      "           6.7430e-02,  2.1438e-01, -2.8825e-01,  8.0175e-03, -2.5510e-02,\n",
      "          -1.8421e-02, -7.2180e-02, -1.2804e-01,  9.9146e-03, -1.7416e-01,\n",
      "          -1.0416e-02, -1.8202e-02,  1.1353e-01, -2.4117e-02,  2.2432e-01,\n",
      "           6.1614e-02, -8.1785e-02, -1.4824e-01,  1.3580e-01, -1.5686e-01,\n",
      "          -8.2632e-02,  4.7189e-02,  5.4105e-02, -1.8891e-01,  8.4025e-02,\n",
      "           3.7489e-03,  1.7512e-01,  8.3832e-02,  1.3161e-01, -7.6144e-02,\n",
      "           1.0477e-01,  2.4261e-01,  1.1581e-01,  2.6747e-02,  1.3760e-01,\n",
      "           4.0117e-02, -1.1402e-01, -6.2753e-02,  4.9269e-02, -4.6587e-04,\n",
      "           9.9252e-02,  6.6208e-02, -2.2651e-02,  5.3685e-02, -1.5784e-01,\n",
      "           1.3606e-01,  1.2230e-01,  7.4861e-02, -8.0010e-02, -1.2793e-01,\n",
      "           1.2521e-01,  2.1789e-02,  1.5156e-01,  3.7267e-02, -1.1309e-02,\n",
      "          -1.4926e-01, -2.3412e-02,  7.8422e-02,  5.0085e-02,  8.2022e-03,\n",
      "          -1.2604e-01,  2.9538e-02,  2.6769e-01, -4.8326e-02,  2.3507e-01,\n",
      "           1.4796e-01,  4.2801e-02,  6.8165e-02, -1.3553e-01,  2.6484e-02,\n",
      "           8.7971e-02,  1.3189e-01, -6.9416e-02, -4.1982e-03, -3.5390e-02,\n",
      "           1.1846e-01, -1.8400e-01, -1.2266e-01,  1.0317e-01, -1.9444e-01,\n",
      "          -1.8741e-01,  1.0472e-01,  6.8728e-02,  1.8285e-01, -1.9579e-01,\n",
      "          -1.0435e-01,  5.0708e-03,  5.2326e-02,  3.2424e-01,  1.0823e-01,\n",
      "          -1.3140e-02,  3.3627e-02,  7.5300e-02,  1.0862e-01,  8.9886e-03,\n",
      "          -3.4355e-02,  9.7821e-02, -3.9276e-02,  6.9800e-02, -9.7478e-02,\n",
      "          -5.2869e-03, -3.8593e-02,  7.6647e-02,  9.6452e-03,  1.1525e-01,\n",
      "          -7.9129e-02,  1.2760e-02, -9.3560e-02,  4.4301e-03,  1.1829e-01,\n",
      "           5.0326e-02, -3.4845e-02,  2.8304e-01, -7.9696e-02,  3.5493e-02,\n",
      "          -6.4024e-02,  1.2282e-01,  1.6345e-03,  1.1004e-01,  3.8922e-03,\n",
      "          -1.0126e-02,  9.9176e-03,  1.5666e-02,  1.5892e-01,  1.2339e-01,\n",
      "          -1.4924e-01,  1.6100e-01,  1.5516e-01,  2.5274e-02,  3.9253e-05,\n",
      "          -1.2877e-01,  5.7646e-02, -5.3457e-03,  1.1485e-01,  5.0909e-02,\n",
      "           2.5560e-02, -2.3395e-02, -4.8055e-02, -1.1445e-01,  1.3240e-02,\n",
      "          -6.1806e-03, -9.3680e-02, -2.3315e-03,  6.0672e-02,  1.1975e-01,\n",
      "          -5.1491e-02,  7.5600e-02, -1.6281e-01, -1.4423e-01, -2.9169e-02,\n",
      "          -5.4455e-02, -1.0302e-01, -3.8415e-02, -9.3917e-02,  1.0067e-01,\n",
      "           4.9035e-02,  1.4868e-01, -6.1231e-02,  1.2126e-01, -1.5619e-01,\n",
      "           2.7345e-02, -8.7809e-02,  3.2192e-02, -1.4314e-01, -5.2312e-02,\n",
      "           8.7615e-02, -7.1949e-02, -1.9424e-01,  1.4784e-01,  1.1997e-01,\n",
      "           8.0356e-02, -7.0847e-03, -4.3788e-02, -1.7771e-01,  2.6041e-01,\n",
      "           6.4708e-02,  8.7579e-02,  3.2089e-02, -1.7749e-01, -7.1007e-02,\n",
      "           8.4496e-02,  6.8062e-02,  4.9767e-03, -1.8555e-01,  9.6645e-02,\n",
      "           1.1829e-01, -3.6006e-02, -1.0300e-02,  7.9505e-02, -5.6462e-02,\n",
      "           1.3310e-03, -1.3025e-01, -1.0687e-01,  2.3113e-01,  2.4455e-02,\n",
      "          -1.3923e-02, -3.3853e-02, -2.0152e-01, -4.0562e-02,  2.4837e-02,\n",
      "           8.9760e-02, -1.4159e-01, -2.4623e-01,  1.3086e-01, -1.8019e-02,\n",
      "           5.4008e-02, -8.2630e-02, -1.3231e-01, -1.0814e-01,  1.4073e-01,\n",
      "          -1.6058e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5878,  0.4346, -0.8086,  2.0325, -1.2213,  1.6211, -0.3635,\n",
      "           0.0000, -0.3603,  0.2453, -0.2176,  0.2619,  0.7715, -0.6503,\n",
      "          -0.8685, -0.9264,  0.9266, -0.4877, -0.9154,  0.4100, -1.1407,\n",
      "           1.4701,  0.0000,  0.0795, -0.8694,  0.5627,  0.0188,  0.1408,\n",
      "           0.6192,  0.6649, -2.3397,  0.0000,  0.0000,  0.0000, -0.7014,\n",
      "          -1.5839, -0.2645,  0.5456, -0.5556,  0.8401,  1.7183, -1.0515,\n",
      "           1.0255,  0.0000,  0.0000, -1.0166,  0.6351, -0.1503,  0.1382,\n",
      "           1.1437, -2.5417, -0.8449, -0.0658,  0.8636,  0.4077,  0.2755,\n",
      "           0.8371,  0.1665,  1.5525, -0.2141,  0.0927, -0.3512,  1.1908,\n",
      "          -2.6282,  0.0627, -0.0281,  0.0000,  0.2388,  0.3708, -0.7557,\n",
      "          -0.7701,  0.3606,  0.1154,  1.0579,  1.6208,  0.7956,  0.3337,\n",
      "          -0.1174, -2.1244,  0.0000, -0.5880,  1.9411,  1.0389,  0.2749,\n",
      "          -0.1761,  1.6644, -0.7925, -2.0310,  0.0713, -2.7362,  0.6178,\n",
      "           0.0000, -1.4077, -0.7315,  0.0821,  0.0000, -3.0049,  0.0000,\n",
      "          -0.4033, -0.1838, -0.9759,  1.2647, -1.1687, -1.2788, -1.6226,\n",
      "           1.0246,  1.3111,  0.0000,  0.0000, -0.2941, -1.4330, -0.2650,\n",
      "           0.8823,  0.5495,  1.8261,  0.0000,  0.0000,  1.0939, -0.4894,\n",
      "           0.0300,  0.5261, -0.0435,  0.6772, -1.2659, -1.3435,  1.2074,\n",
      "           0.0000,  0.1372, -0.9092, -0.4238, -2.1550,  1.3439,  1.1319,\n",
      "          -0.5837,  1.6556, -0.2074,  2.1268,  0.3185, -0.6003, -1.1603,\n",
      "          -0.5506, -0.5423,  0.0215, -0.3961,  0.6093,  0.4917, -1.2131,\n",
      "           1.8402, -0.7116, -0.2310,  0.0000,  0.1207,  1.2288,  0.0000,\n",
      "          -2.0284,  1.0698,  0.0000, -1.6388, -1.1612,  0.0000,  0.0297,\n",
      "           0.0000, -0.6497,  1.2726,  2.8980, -0.7694,  2.3082, -0.3551,\n",
      "          -0.2993, -0.0442,  0.1590,  0.8683, -1.0690,  0.0088,  0.8816,\n",
      "           1.9274,  0.5056,  0.4877, -0.3494,  0.0000,  2.9562,  0.6076,\n",
      "           0.0456,  2.0906, -0.4162, -0.1769,  1.3193,  0.1674,  0.0000,\n",
      "           1.1938,  0.7550,  1.2123, -1.3817,  0.0000, -0.5505, -0.4081,\n",
      "          -0.9045, -0.2954, -0.9274, -1.3428,  1.3338, -1.7561,  1.1297,\n",
      "          -0.1794, -0.1513,  0.8274,  0.9613, -0.1003, -1.5628,  0.0000,\n",
      "           0.0000,  0.0000, -1.3152, -0.1559,  0.6401,  0.5571,  0.3513,\n",
      "           1.5467,  2.0978, -1.9458,  0.1045,  0.0000,  0.9080, -0.6826,\n",
      "           0.0000, -1.2146, -0.7371, -0.0764,  0.1733, -0.7207,  0.2530,\n",
      "          -0.4145,  0.0000,  1.2013,  1.5534, -0.8563,  0.0000,  0.0000,\n",
      "          -0.6196,  1.4775,  0.5752,  1.3580,  0.1880, -0.0353,  0.4935,\n",
      "          -0.1264,  0.1465, -0.7231, -0.5051,  0.1620, -0.9973, -2.9067,\n",
      "          -1.2506,  0.0000,  0.3540, -0.5434]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0444, 0.1265, 0.0968, 0.0901, 0.1216, 0.0909, 0.1685, 0.0666, 0.0463,\n",
      "         0.1482]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0425e-01,  6.9765e-02, -1.0884e-01, -3.9234e-02, -1.2305e-01,\n",
      "          -3.3259e-02, -1.5176e-01, -9.9302e-02, -7.7796e-02,  1.4058e-01,\n",
      "           1.6396e-01,  6.3507e-03, -3.4175e-02,  1.4959e-02,  1.6165e-01,\n",
      "           8.1912e-03, -1.2436e-02,  1.3257e-01, -1.3006e-01, -3.7267e-02,\n",
      "          -1.3308e-01,  8.6628e-03, -9.5937e-02, -4.1392e-02, -1.5250e-01,\n",
      "           1.7863e-02, -9.4406e-03, -1.6281e-01,  6.2962e-02, -8.3404e-02,\n",
      "           1.5197e-01, -8.3798e-03, -8.6287e-02, -2.6315e-01, -5.8515e-02,\n",
      "           4.2297e-02,  9.0268e-02, -1.0379e-02, -5.7069e-02,  9.5909e-03,\n",
      "          -5.5482e-02,  1.8800e-01, -1.2123e-01, -4.5148e-02,  1.3258e-01,\n",
      "           8.6097e-02,  2.1803e-01, -2.4189e-01,  3.8453e-02, -4.8596e-02,\n",
      "           7.7369e-03, -6.9033e-02, -9.6901e-02, -2.6332e-03, -1.5796e-01,\n",
      "          -4.0055e-03, -2.3564e-02,  9.8441e-02, -2.4174e-02,  1.8764e-01,\n",
      "           6.4946e-02, -5.4512e-02, -1.1969e-01,  1.3928e-01, -1.5379e-01,\n",
      "          -7.6323e-02,  4.4897e-02,  5.2102e-02, -1.6349e-01,  9.6749e-02,\n",
      "           4.7234e-03,  1.4300e-01,  7.2093e-02,  6.9667e-02, -7.1149e-02,\n",
      "           1.3770e-01,  2.1910e-01,  1.0932e-01,  5.4952e-02,  1.3040e-01,\n",
      "           5.8177e-02, -4.9197e-02, -5.1898e-02,  5.9314e-02,  3.1972e-02,\n",
      "           8.5565e-02,  7.3044e-02, -1.3305e-02,  4.2634e-02, -1.2698e-01,\n",
      "           9.0884e-02,  8.5216e-02,  5.9850e-02, -9.0376e-02, -8.5574e-02,\n",
      "           8.7141e-02,  1.6992e-02,  1.1554e-01,  6.4658e-02, -1.8923e-02,\n",
      "          -8.3876e-02, -3.4365e-02,  3.8681e-02,  3.3704e-02,  4.0836e-02,\n",
      "          -1.0997e-01, -2.3546e-02,  2.5727e-01, -8.5164e-02,  2.2691e-01,\n",
      "           1.1078e-01,  6.3403e-02,  3.8020e-02, -1.1734e-01,  5.2367e-02,\n",
      "           8.0091e-02,  1.1825e-01, -3.8705e-02,  6.4771e-03, -1.2535e-02,\n",
      "           5.9619e-02, -1.5618e-01, -1.1026e-01,  9.2256e-02, -1.9490e-01,\n",
      "          -1.8382e-01,  8.7421e-02,  6.4494e-02,  1.6668e-01, -1.7593e-01,\n",
      "          -1.1261e-01,  6.7339e-02, -1.8004e-02,  3.0112e-01,  1.2048e-01,\n",
      "          -3.0792e-02,  2.4933e-03,  8.4189e-02,  1.4948e-01,  1.7994e-02,\n",
      "          -6.2888e-02,  9.0805e-02, -4.0392e-02,  2.9183e-02, -9.7387e-02,\n",
      "           1.8956e-02, -3.0375e-02,  7.6455e-02,  1.5459e-02,  7.6223e-02,\n",
      "          -9.8584e-02,  4.3317e-02, -7.8279e-02,  1.4416e-03,  1.1123e-01,\n",
      "           4.0187e-02, -4.7585e-02,  2.8294e-01, -1.1258e-01,  4.8876e-02,\n",
      "          -6.1050e-02,  1.5323e-01,  8.0259e-03,  8.1011e-02, -2.1281e-02,\n",
      "          -1.2808e-02,  1.9575e-02,  3.8130e-02,  1.0057e-01,  8.1931e-02,\n",
      "          -1.3312e-01,  1.7057e-01,  1.3639e-01,  6.6320e-02,  3.8454e-02,\n",
      "          -1.2602e-01,  7.3728e-02, -1.0233e-02,  8.7018e-02,  9.0304e-02,\n",
      "           3.2543e-02, -3.5516e-02, -4.7860e-02, -9.8470e-02, -6.0275e-03,\n",
      "          -1.7319e-02, -6.5657e-02, -3.8995e-02, -1.8629e-04,  1.5668e-01,\n",
      "          -3.2099e-02,  8.2836e-02, -1.5490e-01, -9.8560e-02, -5.0371e-02,\n",
      "          -1.7165e-02, -6.6544e-02, -2.0590e-02, -9.7680e-02,  5.9118e-02,\n",
      "           6.9155e-02,  1.0483e-01, -4.6182e-02,  9.0606e-02, -1.7697e-01,\n",
      "          -7.7551e-04, -6.5186e-02,  2.8471e-03, -1.2048e-01, -5.8030e-02,\n",
      "           3.0374e-02,  3.1634e-03, -1.7182e-01,  1.4466e-01,  1.2884e-01,\n",
      "           3.9875e-02,  3.2557e-02, -3.6117e-02, -1.5307e-01,  2.3538e-01,\n",
      "           8.0261e-02,  9.1608e-02,  1.0060e-02, -1.2201e-01, -7.1323e-02,\n",
      "           9.0953e-02,  1.1874e-02,  8.8612e-03, -1.5477e-01,  4.7448e-02,\n",
      "           1.7539e-01, -1.7470e-02, -2.7744e-02,  1.0786e-01, -4.9888e-02,\n",
      "          -1.0194e-02, -8.1568e-02, -8.0239e-02,  2.1089e-01,  3.4557e-02,\n",
      "          -6.6509e-02, -2.0343e-02, -1.5108e-01,  1.0528e-02,  3.8262e-02,\n",
      "           5.6681e-02, -9.9043e-02, -2.3758e-01,  7.9234e-02, -6.4597e-02,\n",
      "           2.4988e-02, -9.2352e-02, -7.6788e-02, -1.0908e-01,  1.5020e-01,\n",
      "          -1.6274e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7260e-01, -4.3072e-01,  3.1513e-01, -1.0848e+00, -1.1726e+00,\n",
      "           0.0000e+00, -1.9144e+00,  1.3513e+00,  1.9028e-01,  6.1726e-01,\n",
      "           0.0000e+00,  6.0248e-01,  2.2892e-01, -9.1641e-01, -3.1829e+00,\n",
      "          -6.8325e-02, -1.6334e+00, -9.4351e-01,  1.3605e+00, -1.4353e+00,\n",
      "          -1.4054e-01, -5.2419e-01, -1.1197e+00,  0.0000e+00, -7.5811e-02,\n",
      "           1.3915e+00,  0.0000e+00,  0.0000e+00,  1.2768e-01,  5.5460e-01,\n",
      "           0.0000e+00, -3.6786e-03,  2.2248e-01,  2.0164e+00, -6.3664e-02,\n",
      "          -1.4085e+00, -1.1175e-01, -8.1751e-01,  3.1506e-01,  0.0000e+00,\n",
      "           8.6288e-01, -8.9934e-01,  1.0089e+00, -1.5636e+00,  1.9446e+00,\n",
      "          -3.0025e-01,  7.0567e-01,  0.0000e+00,  0.0000e+00,  1.1168e+00,\n",
      "          -1.3228e+00,  2.6773e+00,  0.0000e+00, -8.4687e-01,  2.2782e-01,\n",
      "          -3.0977e-01, -1.4340e+00, -9.6438e-02,  1.2757e+00,  2.1816e+00,\n",
      "           0.0000e+00,  3.6023e-02, -2.8013e-01,  2.6588e-01, -6.3022e-02,\n",
      "           3.9374e-01,  5.7801e-01,  1.1652e+00,  0.0000e+00, -1.4153e+00,\n",
      "           4.2749e-01,  2.9640e-01, -3.1189e-02, -7.9803e-01, -2.1433e-01,\n",
      "           1.3937e-01,  0.0000e+00,  1.3988e+00,  1.0272e+00, -7.9364e-01,\n",
      "           7.5810e-01, -1.0052e+00,  7.5784e-01,  1.0588e+00, -1.2150e+00,\n",
      "          -1.1313e-01, -1.1079e+00,  5.4874e-01,  0.0000e+00, -1.9013e+00,\n",
      "           5.2911e-01,  9.8708e-01,  1.7019e+00,  9.4381e-01,  0.0000e+00,\n",
      "          -1.5886e-02,  3.5390e-01, -1.1759e+00,  0.0000e+00,  0.0000e+00,\n",
      "           2.4354e-01,  4.4732e-02, -4.6654e-01, -9.8946e-01,  1.6404e+00,\n",
      "          -1.0236e+00,  0.0000e+00,  6.2024e-01, -1.0202e-01, -1.2355e+00,\n",
      "           1.8996e-01, -5.0309e-01, -5.7075e-01,  7.1241e-01, -7.8055e-01,\n",
      "           6.3253e-01,  4.0385e-01,  2.2385e-01, -2.3271e+00,  2.9333e-02,\n",
      "          -8.1425e-01, -1.4113e+00, -1.8380e+00,  6.0323e-01,  0.0000e+00,\n",
      "          -2.0069e-01,  3.9845e-02,  0.0000e+00,  1.3963e+00,  0.0000e+00,\n",
      "          -9.2633e-01,  4.4976e-01,  0.0000e+00,  4.2531e-01,  0.0000e+00,\n",
      "          -7.4563e-01, -1.0649e+00, -9.7518e-01, -1.9438e-02,  2.3978e+00,\n",
      "           6.9860e-01, -1.1217e+00,  1.6918e+00, -1.4033e-01, -6.6985e-01,\n",
      "           3.3556e-02,  7.5956e-01,  4.2295e-01, -1.0336e+00, -9.5428e-02,\n",
      "           1.5601e+00,  0.0000e+00, -3.3853e-01,  0.0000e+00,  1.8412e+00,\n",
      "           0.0000e+00, -2.1773e-01,  6.2376e-01, -2.3630e+00,  1.0558e+00,\n",
      "           3.0267e-01, -7.7289e-02,  1.5494e-01, -1.2120e+00, -2.1975e-02,\n",
      "           1.6823e+00,  1.8523e+00,  2.7121e-01, -1.2703e+00, -7.1317e-01,\n",
      "          -1.2243e+00, -1.0942e+00, -2.5907e+00,  5.0578e-01, -3.0597e+00,\n",
      "          -2.8728e-01,  4.9789e-01,  8.2963e-01,  3.1704e-01, -7.9298e-01,\n",
      "           2.7195e-01,  2.3398e+00,  1.0577e+00,  8.3859e-01, -4.0270e-01,\n",
      "           0.0000e+00,  5.9884e-01,  3.5963e-01,  0.0000e+00, -1.8306e+00,\n",
      "           1.3636e+00,  2.1594e+00,  3.3629e-01,  0.0000e+00, -1.1724e+00,\n",
      "          -2.2155e+00,  1.6670e+00,  2.1528e+00,  3.6343e-01,  2.3837e+00,\n",
      "           3.2457e-02, -5.0159e-01, -1.2766e+00, -5.4268e-01, -4.0750e-01,\n",
      "          -1.4471e+00,  9.5349e-01, -8.5190e-01,  8.3002e-01,  0.0000e+00,\n",
      "           6.3678e-01,  6.7584e-01,  2.3980e+00,  5.5227e-02,  1.8937e+00,\n",
      "           1.3085e+00,  5.8045e-01, -2.3174e+00,  1.5502e+00, -2.2256e-01,\n",
      "           0.0000e+00,  1.7337e+00,  2.7683e-01, -1.5521e+00,  0.0000e+00,\n",
      "          -1.2244e+00, -8.4850e-01,  0.0000e+00, -5.9658e-04,  3.7323e-01,\n",
      "          -1.5736e+00, -1.2368e-01,  9.6632e-01, -1.7368e+00,  1.6943e+00,\n",
      "          -1.4405e+00,  6.3406e-01, -1.7225e+00,  9.8030e-01, -1.7163e+00,\n",
      "           1.5610e+00, -2.7246e-01, -2.5970e+00,  1.2388e+00, -1.2283e+00,\n",
      "           1.8855e+00, -5.0837e-01,  5.4284e-01, -2.6131e-01, -1.0221e+00,\n",
      "           1.3336e+00,  3.1091e-01, -5.1251e-02, -2.2879e-01, -1.6123e+00,\n",
      "           1.8066e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0585, 0.1596, 0.1364, 0.0973, 0.1213, 0.0712, 0.1074, 0.0996, 0.0997,\n",
      "         0.0491]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3521, -0.0295,  0.0801,  ..., -0.1177, -0.0200, -0.4790],\n",
      "        [-0.0984, -0.3285,  0.0751,  ..., -0.0683,  0.2963, -0.3411],\n",
      "        [-0.0031,  0.0270, -0.5090,  ..., -0.0412,  0.3699, -0.4715],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 9.2286e-02,  5.1291e-02, -1.1135e-01, -2.4266e-02, -1.0392e-01,\n",
      "          -1.4994e-02, -1.9500e-01, -8.7506e-02, -1.1021e-01,  1.9038e-01,\n",
      "           1.7431e-01,  1.3783e-02, -9.1115e-03,  4.7140e-05,  1.5319e-01,\n",
      "           3.6166e-02, -1.8881e-02,  1.4814e-01, -1.2195e-01, -3.5971e-02,\n",
      "          -1.5832e-01,  4.0707e-02, -1.4200e-01, -5.3047e-02, -1.5564e-01,\n",
      "           2.7869e-02, -1.1787e-02, -1.7134e-01,  8.5738e-02, -8.9400e-02,\n",
      "           1.6335e-01,  1.7635e-02, -8.6303e-02, -2.7537e-01, -7.2078e-02,\n",
      "           2.3606e-02,  1.4382e-01,  3.6300e-03, -3.0254e-02,  7.7143e-03,\n",
      "          -6.9400e-02,  2.1641e-01, -1.2939e-01, -6.6556e-02,  1.5859e-01,\n",
      "           7.2910e-02,  2.7136e-01, -2.5214e-01,  2.4783e-02, -4.3018e-02,\n",
      "           2.1643e-02, -7.1585e-02, -8.6912e-02,  3.6099e-03, -1.9063e-01,\n",
      "          -7.1445e-03, -1.8480e-02,  1.1210e-01, -5.4498e-02,  1.9235e-01,\n",
      "           8.9985e-02, -5.1423e-02, -1.1791e-01,  1.4536e-01, -1.7431e-01,\n",
      "          -8.8171e-02,  6.9105e-02,  4.2426e-02, -1.9111e-01,  9.8551e-02,\n",
      "          -1.0227e-02,  1.5774e-01,  9.4670e-02,  5.0694e-02, -5.8631e-02,\n",
      "           1.4640e-01,  2.2487e-01,  1.1284e-01,  5.9736e-02,  1.4046e-01,\n",
      "           8.6297e-02, -3.9385e-02, -1.9125e-02,  8.6144e-02,  3.9080e-02,\n",
      "           7.6052e-02,  8.7770e-02, -2.5126e-02,  2.7075e-02, -1.3650e-01,\n",
      "           1.0530e-01,  1.1173e-01,  6.8631e-02, -9.4914e-02, -9.9392e-02,\n",
      "           8.5554e-02,  8.9400e-03,  1.2059e-01,  7.9902e-02, -5.7156e-02,\n",
      "          -8.1578e-02, -5.6756e-02,  3.5962e-02,  4.0676e-02,  6.5004e-02,\n",
      "          -1.1741e-01, -4.5964e-02,  2.7850e-01, -8.6773e-02,  2.4940e-01,\n",
      "           1.1644e-01,  6.5827e-02,  2.7882e-02, -1.0151e-01,  8.9385e-02,\n",
      "           9.9820e-02,  1.4092e-01, -3.7394e-02,  1.5941e-02,  3.3246e-03,\n",
      "           9.2201e-02, -1.7978e-01, -1.0612e-01,  1.0659e-01, -2.1439e-01,\n",
      "          -2.0663e-01,  9.9225e-02,  9.9581e-02,  1.8064e-01, -1.8134e-01,\n",
      "          -1.2644e-01,  1.1134e-01, -3.4534e-02,  3.4465e-01,  1.5764e-01,\n",
      "          -3.6749e-02, -1.3875e-02,  8.3220e-02,  2.1263e-01, -2.9856e-03,\n",
      "          -6.5549e-02,  7.4906e-02, -3.7425e-02,  1.7447e-02, -1.3220e-01,\n",
      "           2.4936e-02, -2.6102e-02,  5.7879e-02,  1.0938e-02,  7.4520e-02,\n",
      "          -6.3286e-02,  2.9655e-02, -8.0681e-02, -2.8963e-02,  1.1257e-01,\n",
      "           1.5929e-02, -3.5905e-02,  3.1693e-01, -1.4328e-01,  7.6370e-02,\n",
      "          -6.5193e-02,  1.9861e-01,  4.4396e-02,  5.3521e-02, -1.9890e-02,\n",
      "          -4.2220e-02,  4.0091e-02,  6.5161e-02,  9.3416e-02,  6.9298e-02,\n",
      "          -1.3765e-01,  1.9447e-01,  1.3080e-01,  9.0465e-02,  5.9415e-02,\n",
      "          -1.2492e-01,  1.0851e-01, -2.1936e-02,  6.3873e-02,  1.2215e-01,\n",
      "           6.4946e-02, -1.8165e-02, -2.1501e-02, -1.1529e-01, -2.5264e-02,\n",
      "          -3.2790e-02, -3.4161e-02, -5.8079e-02,  1.1272e-03,  2.0091e-01,\n",
      "          -4.1570e-02,  8.3548e-02, -1.4527e-01, -1.0705e-01, -5.8110e-02,\n",
      "          -9.6427e-04, -9.1621e-02, -2.5193e-02, -9.1111e-02,  6.1564e-02,\n",
      "           7.3953e-02,  1.3332e-01, -4.7926e-02,  9.0348e-02, -2.1740e-01,\n",
      "           1.3570e-02, -8.5151e-02, -3.8239e-02, -1.3587e-01, -6.0819e-02,\n",
      "           3.4933e-02,  5.3395e-03, -1.9137e-01,  1.3609e-01,  1.5756e-01,\n",
      "           2.2147e-02,  4.8769e-02, -6.6670e-02, -1.5760e-01,  2.5690e-01,\n",
      "           6.8686e-02,  1.1153e-01, -2.8834e-03, -1.3402e-01, -1.2738e-01,\n",
      "           8.6276e-02,  1.3044e-02,  2.8149e-02, -1.4910e-01,  4.2509e-02,\n",
      "           2.2858e-01, -1.8074e-02, -1.1868e-02,  1.7320e-01, -4.9874e-02,\n",
      "          -3.9299e-03, -8.7806e-02, -9.7794e-02,  2.3017e-01,  2.4557e-02,\n",
      "          -4.5967e-02, -5.4016e-04, -1.6211e-01,  1.0461e-02,  2.6793e-02,\n",
      "           7.2650e-02, -8.0044e-02, -2.4932e-01,  9.1078e-02, -7.6090e-02,\n",
      "           1.9853e-02, -1.0116e-01, -6.1827e-02, -1.0844e-01,  1.7444e-01,\n",
      "          -2.0256e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6043e-02,  3.9922e-01,  0.0000e+00, -6.8154e-01,  3.7605e-01,\n",
      "          -2.0185e-01,  1.4648e+00, -8.3339e-02, -3.5846e+00,  9.0671e-01,\n",
      "           4.2855e-01, -6.2910e-01,  2.6047e+00, -6.2972e-01, -5.4150e-01,\n",
      "          -1.5793e-01,  8.5141e-01,  1.0949e+00,  0.0000e+00,  4.3606e-01,\n",
      "          -6.3352e-01,  0.0000e+00,  1.6416e+00,  1.5111e+00,  0.0000e+00,\n",
      "          -7.5591e-02, -1.8783e-01, -7.5919e-01,  0.0000e+00,  8.6166e-01,\n",
      "           1.2319e+00,  1.2190e+00, -1.0343e+00, -8.2644e-02, -1.5346e+00,\n",
      "           1.3954e+00,  2.8095e-01, -3.7450e+00,  1.9803e-01,  1.6011e+00,\n",
      "           0.0000e+00, -1.3985e+00, -2.6844e-01, -1.7159e+00, -1.5244e+00,\n",
      "           6.6735e-01,  5.4108e-01,  3.7056e-01, -1.3408e+00,  1.4406e-01,\n",
      "          -6.2928e-01,  2.7524e+00,  6.1036e-01, -1.0292e+00, -2.5564e-02,\n",
      "           2.0323e-01, -8.8210e-01, -1.2525e+00, -2.3680e-01,  0.0000e+00,\n",
      "           1.1007e+00,  1.4082e+00, -2.0322e-01, -5.0162e-01, -2.9642e+00,\n",
      "           5.5065e-01,  1.2789e+00,  0.0000e+00,  4.1134e-01,  5.2648e-01,\n",
      "          -1.2671e+00, -3.0132e-02,  7.0738e-01, -3.6413e+00,  3.2601e-01,\n",
      "          -1.8451e-03, -1.5989e-01,  1.0626e+00, -5.8240e-02, -1.1967e-01,\n",
      "          -1.4003e+00,  2.1314e+00, -9.2476e-01,  1.0058e+00, -2.0779e-01,\n",
      "           4.3500e-01,  1.6617e+00, -9.7439e-01,  0.0000e+00, -5.8143e-01,\n",
      "          -2.2735e+00,  1.1004e+00, -6.2233e-01, -1.1355e+00,  4.6736e-01,\n",
      "          -1.1708e+00,  3.4114e-02,  6.2911e-01,  1.7202e+00,  0.0000e+00,\n",
      "           2.6975e+00, -1.4626e+00,  1.0761e+00,  1.4539e+00, -6.6640e-01,\n",
      "          -7.6258e-01,  1.2123e+00,  1.2723e-01, -1.4730e+00, -1.3261e-02,\n",
      "          -2.4866e-01,  1.3444e-01, -1.0482e+00,  0.0000e+00, -1.6535e+00,\n",
      "          -2.9897e+00,  0.0000e+00, -5.0082e-01, -1.9329e-01,  4.4502e-01,\n",
      "          -1.4665e+00,  7.0231e-01, -1.4606e+00, -7.2613e-01, -9.5848e-01,\n",
      "          -1.3090e+00,  8.9719e-01,  1.7010e-01,  1.2854e+00, -7.5221e-01,\n",
      "          -8.2349e-01,  5.3000e-01, -1.5832e+00,  9.8407e-01,  2.7612e-01,\n",
      "          -5.8964e-01,  6.5959e-01,  5.7413e-01, -1.1586e+00, -1.0101e+00,\n",
      "          -3.8870e-01,  6.7782e-01, -7.8997e-01,  0.0000e+00, -1.6858e+00,\n",
      "          -1.0102e-01, -5.4327e-01,  0.0000e+00, -7.5542e-01,  1.7754e-01,\n",
      "           1.9987e+00, -1.9965e-01, -1.9305e+00, -4.0611e-01,  4.4151e-01,\n",
      "          -1.9448e-01,  0.0000e+00, -1.2921e-01,  3.9290e-02,  5.3767e-01,\n",
      "          -2.6398e-02,  2.2065e+00,  4.8114e-01, -5.4992e-01, -5.2684e-01,\n",
      "          -8.9246e-01,  2.8163e-01,  8.4111e-02, -3.5805e-01, -4.7802e-01,\n",
      "           7.3757e-01, -3.1826e-02,  2.0054e-02,  0.0000e+00,  1.2777e+00,\n",
      "          -1.0986e+00, -9.8724e-01, -2.0771e+00,  1.9692e+00,  8.6514e-02,\n",
      "          -3.0279e-02,  3.5043e-02,  6.7130e-01,  9.7991e-01, -7.4699e-01,\n",
      "          -3.4083e-01, -2.7833e+00, -7.8417e-01,  0.0000e+00,  1.0124e+00,\n",
      "           3.0744e+00,  4.9441e-01, -1.4431e-01, -5.9422e-01,  5.6064e-01,\n",
      "           2.1652e+00, -1.1880e+00,  5.3499e-01,  1.8117e+00, -9.4705e-01,\n",
      "          -1.6623e+00, -1.0152e+00,  1.2419e+00, -1.2221e-01,  2.3194e-01,\n",
      "          -5.7519e-01, -2.2929e+00,  6.8182e-01, -1.0745e+00, -4.7123e-01,\n",
      "           2.8681e+00, -5.7342e-01,  0.0000e+00,  7.9318e-01,  3.0175e-02,\n",
      "          -6.8443e-01, -1.0190e+00,  9.6634e-01,  0.0000e+00,  2.1695e+00,\n",
      "          -1.0828e+00, -4.2730e-01, -1.8438e+00, -5.0107e-01,  3.3773e-01,\n",
      "           7.0493e-01, -6.9650e-01, -6.2819e-01,  2.9224e-01, -1.5786e+00,\n",
      "          -1.1086e+00,  1.5815e+00, -6.1419e-01,  1.3099e+00, -2.9799e+00,\n",
      "           4.0356e+00,  0.0000e+00,  4.3352e-02, -1.5799e+00, -2.8717e-01,\n",
      "           7.4181e-01, -3.2483e+00, -3.0446e-01, -8.5225e-01,  1.1306e-02,\n",
      "           2.7540e-01,  0.0000e+00,  2.5253e-01,  0.0000e+00,  3.8654e-01,\n",
      "          -3.6560e-01, -1.5874e-01, -5.5390e-01, -5.2663e-02, -1.1468e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0408, 0.0571, 0.0787, 0.0531, 0.1130, 0.3593, 0.0525, 0.0760, 0.0531,\n",
      "         0.1164]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2497, -0.0025, -0.0854,  ...,  0.1648,  0.0289,  0.0420],\n",
      "        [ 0.2146, -0.1052, -0.5294,  ...,  0.0446, -0.0400,  0.1088],\n",
      "        [ 0.0496, -0.3670, -0.0710,  ..., -0.0166,  0.0778,  0.3162],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0541e-01,  8.4918e-04, -1.3587e-01, -5.5395e-02,  2.1796e-02,\n",
      "          -2.6724e-02, -2.0376e-02, -4.8225e-02, -1.5943e-02, -3.3618e-02,\n",
      "           5.1322e-02, -2.3201e-03, -5.7733e-02,  2.0554e-03, -3.6202e-02,\n",
      "           6.1244e-04,  2.2770e-03, -5.3985e-03, -9.7721e-02,  4.8243e-02,\n",
      "          -1.2927e-02, -1.1432e-01,  1.0644e-01,  1.4861e-02, -1.1675e-02,\n",
      "          -7.8529e-02, -3.2080e-02, -7.0605e-02, -6.4351e-02, -3.3640e-02,\n",
      "           6.1001e-02, -1.1550e-01,  5.5062e-02, -7.7904e-02,  8.0271e-03,\n",
      "           5.5455e-02, -3.3775e-02, -4.5463e-02, -6.7510e-02,  4.7360e-02,\n",
      "          -4.5215e-02,  8.4632e-03, -3.0037e-02,  8.9840e-02, -2.3872e-03,\n",
      "           1.0075e-01, -7.1946e-02, -7.2563e-02,  7.7352e-02, -3.9017e-02,\n",
      "          -7.1540e-02, -6.8312e-02, -9.9311e-02, -4.7858e-02,  4.1187e-02,\n",
      "           4.4420e-02,  2.0507e-02,  6.0388e-02,  1.1074e-01,  8.1939e-02,\n",
      "          -9.5391e-03, -4.8629e-02, -1.2242e-01, -2.1540e-03,  1.3870e-02,\n",
      "           1.0712e-01, -7.2432e-02,  1.0708e-01, -1.2458e-01,  4.5536e-02,\n",
      "           1.6838e-02,  1.2282e-01, -2.0804e-04, -2.2884e-04, -1.0076e-01,\n",
      "           1.4282e-01,  7.0477e-02,  6.8777e-02, -1.0347e-01,  2.6476e-02,\n",
      "          -7.7172e-02, -6.3781e-02, -1.3065e-01,  2.3273e-02, -6.0293e-02,\n",
      "           4.1161e-02, -1.5266e-02,  5.6005e-02,  3.4223e-02, -4.0650e-02,\n",
      "           7.7208e-02,  6.5043e-02, -5.4436e-03,  3.2016e-02, -7.6727e-03,\n",
      "           1.2086e-01,  1.6056e-02,  1.4931e-01,  1.4004e-03,  1.6203e-01,\n",
      "          -1.2331e-01,  1.5397e-01,  6.2525e-02,  4.2383e-02, -1.1248e-01,\n",
      "          -1.5237e-01,  3.5762e-02,  1.5844e-01, -1.4698e-01,  5.0745e-02,\n",
      "           1.1518e-01, -2.2631e-02,  4.4424e-02, -1.8317e-01, -8.3901e-02,\n",
      "          -1.0454e-02, -1.9925e-02, -5.8870e-02, -7.4696e-02, -1.4782e-02,\n",
      "           3.3745e-02, -1.2304e-02, -1.1146e-01,  1.0541e-01, -3.0069e-02,\n",
      "          -7.6306e-02, -4.2148e-03, -6.9073e-02,  2.0776e-02, -1.1095e-01,\n",
      "           7.3237e-02, -1.7338e-01,  9.7453e-02,  7.7442e-02, -1.2876e-01,\n",
      "          -3.4098e-02,  2.1115e-01, -3.0462e-02, -1.0821e-01,  1.0070e-01,\n",
      "          -4.5186e-02,  1.1170e-01, -3.6489e-02,  8.5871e-02,  4.2814e-02,\n",
      "          -2.6508e-02, -1.9244e-02,  3.0911e-02,  8.2390e-02,  4.1777e-03,\n",
      "          -1.1724e-01,  5.7853e-02, -4.4996e-02,  2.7716e-02,  7.7637e-02,\n",
      "           5.8679e-02, -2.4789e-02,  8.2590e-02,  4.0056e-02, -1.2232e-01,\n",
      "          -6.1515e-02, -1.0479e-01, -5.6829e-02,  1.2534e-01, -4.2801e-02,\n",
      "          -5.8307e-03, -1.0430e-01,  1.6082e-02, -2.5133e-02,  1.1767e-01,\n",
      "          -1.6449e-01, -3.9816e-04, -3.4644e-03,  6.6331e-02, -9.7661e-02,\n",
      "          -8.6622e-02,  9.3314e-03,  7.5312e-02,  1.7975e-01, -1.3590e-01,\n",
      "           4.2809e-02, -8.5860e-02, -3.7846e-02, -1.8073e-02,  2.0696e-03,\n",
      "           1.8442e-03, -8.7969e-02,  4.6781e-02,  9.7343e-03, -8.9844e-02,\n",
      "          -5.0953e-03,  8.3025e-02, -1.3344e-01, -6.6891e-02, -4.2484e-02,\n",
      "           4.8795e-03, -1.0987e-01, -3.7003e-02, -5.2956e-02,  3.1972e-02,\n",
      "          -5.1113e-02,  3.5294e-02, -1.0423e-01,  1.3254e-01, -4.0455e-02,\n",
      "          -4.3949e-02,  1.1449e-01,  1.5168e-01, -1.0681e-02, -8.4970e-02,\n",
      "          -2.5098e-03, -1.0976e-01, -8.4192e-02,  1.4425e-01, -6.7434e-02,\n",
      "           1.2918e-01, -5.5507e-02,  5.9307e-02, -7.7821e-02,  5.1141e-02,\n",
      "           8.0411e-02, -1.8750e-02,  1.1984e-01, -3.7478e-02,  9.9809e-02,\n",
      "          -4.4276e-03,  9.8722e-02, -1.1958e-01, -1.5680e-01,  1.1965e-01,\n",
      "          -1.4649e-01, -2.9930e-02,  1.9312e-02, -5.8301e-02, -4.4064e-04,\n",
      "           8.4307e-02,  4.1921e-02, -5.7451e-02,  1.3678e-01,  7.6853e-02,\n",
      "           9.3059e-02, -1.7292e-02, -4.2902e-02,  4.4692e-02,  4.5850e-02,\n",
      "           7.1616e-02, -1.9609e-01, -4.9874e-02,  7.0305e-02,  5.0732e-02,\n",
      "           7.7111e-02, -8.9684e-02, -6.4118e-02, -5.5469e-02,  3.8252e-02,\n",
      "           6.3886e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4746, -0.4593, -1.2337, -0.1177,  0.4619,  0.0255,  0.6622,\n",
      "           0.5339,  0.6705,  0.9336,  0.0000, -1.0165,  0.9473, -0.2516,\n",
      "          -1.6343,  0.5130,  1.8778, -0.7565, -1.5629,  0.0000, -1.1339,\n",
      "           0.1678,  2.9304,  0.5542, -0.1166,  3.2100,  0.0000,  0.5193,\n",
      "          -2.2262, -1.2854,  0.0297,  1.0135,  0.3246,  0.8606, -0.7989,\n",
      "          -1.4656,  0.6200, -0.7714,  1.9919,  0.1027,  0.4676, -2.2046,\n",
      "          -0.5665, -0.1154, -0.7132, -0.6897,  1.9284,  0.1099, -0.2869,\n",
      "          -1.8509,  1.4683,  0.0000,  0.0000, -0.2838,  0.5317,  0.0000,\n",
      "          -1.2422, -0.9516,  1.8147, -0.0116,  0.2047, -1.8180,  0.0000,\n",
      "          -0.8067,  1.1796,  0.2653, -0.1665, -0.2561, -0.0040, -0.4613,\n",
      "          -0.3253, -0.3244,  0.1476,  0.0000,  0.6588,  0.0000,  0.0000,\n",
      "           0.0000,  0.0877, -0.5468,  1.2271,  0.0876,  0.3271, -1.8367,\n",
      "          -0.0722,  0.0000, -1.4586, -0.8910,  0.6232,  0.8106,  0.0000,\n",
      "          -1.1445,  1.9855, -0.3657, -0.7340,  0.1563,  0.0000,  0.0000,\n",
      "          -0.3041, -1.8398, -1.2905, -0.7221, -0.7664,  0.2380,  0.3822,\n",
      "           1.1139, -1.0695,  2.2530, -0.2629, -0.2880, -0.0533,  0.6109,\n",
      "          -0.2555, -0.2803, -1.9427,  1.1282,  1.0061, -2.4985, -0.5745,\n",
      "           0.0297, -1.6958, -0.4013, -0.3801, -0.0791, -0.5373,  0.0000,\n",
      "           1.3057,  0.0000,  0.3225,  1.3585,  2.0803, -2.6345,  0.3586,\n",
      "          -0.7228,  0.4296,  0.0000,  0.3273, -2.1033, -0.4969, -1.6781,\n",
      "          -0.6424,  0.2341, -1.1874, -1.2158, -0.6316, -0.0412,  0.4651,\n",
      "           1.7386,  1.5937,  1.4317,  0.0000, -0.5775, -0.4803, -0.0394,\n",
      "           0.0000, -0.1164,  1.3542, -0.0308, -1.9009, -1.8060, -1.4272,\n",
      "          -0.9004, -0.7053, -0.3891, -0.9822,  0.0000,  0.0000,  0.0000,\n",
      "           0.5179, -0.1472,  1.5153, -0.3733, -0.3160, -2.0089,  0.1288,\n",
      "          -0.3526, -0.8314, -0.7698, -0.0396, -0.9377,  0.7281,  1.0421,\n",
      "           0.0471,  0.0000,  0.3170, -0.1179, -0.5428, -0.6646,  0.7556,\n",
      "           0.0000, -0.5861,  0.0000,  1.2675, -0.9268,  0.0000, -0.3332,\n",
      "          -1.1571, -1.9609, -0.0720, -0.3760,  2.6985, -0.9216, -2.6325,\n",
      "          -0.5863, -0.7170, -1.3864, -1.2541,  0.0000,  0.2182, -1.1115,\n",
      "           0.9456, -0.6920, -1.5199,  0.3626,  0.0000, -1.4274, -2.3454,\n",
      "           0.0470, -1.4803,  0.4278,  0.0133, -0.9020,  0.0000, -1.1657,\n",
      "          -1.3025, -0.1875,  0.0000,  1.2667, -2.1882, -0.0567,  1.7372,\n",
      "          -1.1753,  0.9564,  1.9991,  0.5267,  0.0000, -0.6786,  0.1047,\n",
      "          -0.6808,  0.0000,  0.1677, -0.3149, -1.0437, -0.3822, -1.0801,\n",
      "           0.5583,  1.5005, -0.5647, -1.3777,  0.0000,  0.0000,  1.7535,\n",
      "           1.9512,  0.3622,  0.4870,  0.3904]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0201, 0.2092, 0.0757, 0.0457, 0.1303, 0.1440, 0.0348, 0.1796, 0.0987,\n",
      "         0.0618]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2497, -0.0025, -0.0854,  ...,  0.1648,  0.0289,  0.0420],\n",
      "        [ 0.2146, -0.1052, -0.5294,  ...,  0.0446, -0.0400,  0.1088],\n",
      "        [ 0.0496, -0.3670, -0.0710,  ..., -0.0166,  0.0778,  0.3162],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1406, -0.0059, -0.2245, -0.1013,  0.0483,  0.0304, -0.0336,\n",
      "          -0.0970, -0.0132, -0.0991,  0.0510,  0.0406, -0.0469, -0.0146,\n",
      "          -0.0133,  0.0323,  0.0756, -0.0120, -0.1065,  0.0760, -0.0216,\n",
      "          -0.1182,  0.1466,  0.0160,  0.0418, -0.1206,  0.0032, -0.0688,\n",
      "          -0.0972, -0.0476,  0.1139, -0.1542,  0.1194, -0.0843,  0.0717,\n",
      "           0.0303, -0.0571, -0.0118, -0.1170,  0.0534, -0.0258,  0.0112,\n",
      "          -0.0026,  0.0827, -0.0318,  0.0659, -0.0509, -0.0484,  0.1268,\n",
      "          -0.0286, -0.0861, -0.0400, -0.1417, -0.0680,  0.0425,  0.1006,\n",
      "           0.0372,  0.0686,  0.1640,  0.0927, -0.0286, -0.0429, -0.1375,\n",
      "          -0.0542,  0.0144,  0.1513, -0.1052,  0.1098, -0.1161,  0.0349,\n",
      "          -0.0174,  0.1454, -0.0204, -0.0496, -0.1634,  0.2334,  0.0737,\n",
      "           0.1278, -0.1108, -0.0060, -0.1296, -0.0585, -0.1483,  0.0055,\n",
      "          -0.0776,  0.0586, -0.0497,  0.0453, -0.0130, -0.0705,  0.0758,\n",
      "           0.0806, -0.0025,  0.0285, -0.0107,  0.1327, -0.0020,  0.1657,\n",
      "           0.0084,  0.1726, -0.1338,  0.2013,  0.0464,  0.0476, -0.2135,\n",
      "          -0.1921, -0.0180,  0.1900, -0.1947,  0.0425,  0.1668, -0.0063,\n",
      "           0.0482, -0.2461, -0.0220, -0.0727,  0.0091, -0.0437, -0.1092,\n",
      "           0.0365,  0.0538,  0.0134, -0.1330,  0.1269, -0.0093, -0.1334,\n",
      "           0.0089, -0.0559, -0.0209, -0.1560,  0.0050, -0.2327,  0.1217,\n",
      "           0.0769, -0.1986,  0.0423,  0.3081, -0.0479, -0.1774,  0.0874,\n",
      "          -0.0142,  0.1332, -0.0317,  0.1254,  0.0549, -0.0366, -0.0437,\n",
      "          -0.0045,  0.0841, -0.0602, -0.1221,  0.0620, -0.0981, -0.0163,\n",
      "           0.0765,  0.0487,  0.0213,  0.1263,  0.0488, -0.1395, -0.0850,\n",
      "          -0.1200, -0.0789,  0.1528, -0.0790, -0.0427, -0.1406,  0.0563,\n",
      "          -0.0324,  0.1654, -0.2134, -0.0112, -0.0055,  0.1114, -0.1554,\n",
      "          -0.1028,  0.0734,  0.1092,  0.2718, -0.1724,  0.0750, -0.1550,\n",
      "          -0.0324, -0.0407, -0.0154, -0.0092, -0.0569,  0.0311,  0.0134,\n",
      "          -0.1127, -0.0120,  0.1374, -0.1565, -0.0725, -0.0665,  0.0630,\n",
      "          -0.1576, -0.0274, -0.0584,  0.0447, -0.0866,  0.0866, -0.0992,\n",
      "           0.1795, -0.0825, -0.0369,  0.1421,  0.1911, -0.0167, -0.1109,\n",
      "          -0.0190, -0.1892, -0.1100,  0.1780, -0.0877,  0.1302, -0.0429,\n",
      "           0.1066, -0.0937,  0.0849,  0.1337, -0.0291,  0.1451, -0.0264,\n",
      "           0.1298, -0.0173,  0.1324, -0.1138, -0.1958,  0.1748, -0.2637,\n",
      "          -0.0617,  0.0512, -0.0258,  0.0042,  0.0962,  0.0821, -0.0718,\n",
      "           0.1509,  0.1172,  0.1395, -0.0022,  0.0085,  0.0147,  0.0533,\n",
      "           0.1021, -0.2765, -0.0434,  0.0890,  0.0940,  0.1458, -0.0741,\n",
      "          -0.0515, -0.0549,  0.0295,  0.0816]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00,  8.9453e-02, -5.4471e-01,  5.4053e-01, -5.6670e-01,\n",
      "           1.2814e+00,  2.8249e+00, -2.4709e-01,  1.6131e+00, -7.5653e-01,\n",
      "          -5.3092e-01, -1.9827e-01,  1.4270e-01,  9.6509e-01,  4.9983e-01,\n",
      "           0.0000e+00,  1.9364e+00,  6.1973e-01,  7.5097e-01,  1.0217e+00,\n",
      "           5.3147e-02,  0.0000e+00,  1.6814e+00,  3.0947e-01, -6.9749e-01,\n",
      "          -1.7924e+00,  9.4610e-01, -1.6200e+00,  0.0000e+00, -2.3745e-01,\n",
      "           1.0223e+00,  4.1287e-02,  1.2296e+00,  1.0355e+00, -2.2232e+00,\n",
      "          -1.1201e-01,  0.0000e+00,  2.8217e+00, -9.0151e-01,  7.7043e-01,\n",
      "           6.9281e-01,  1.3752e+00, -4.4736e-01,  0.0000e+00,  4.1207e-01,\n",
      "           7.2493e-01, -2.6711e-03,  1.3005e-01, -1.4963e+00, -5.1817e-01,\n",
      "          -1.6946e+00,  3.1130e-01, -1.8047e-01,  2.5761e-01,  5.9936e-01,\n",
      "           8.0397e-01, -8.5184e-01, -3.5923e-01, -1.7293e+00,  7.3649e-01,\n",
      "          -7.7576e-03, -3.9192e-01,  1.0846e+00, -1.0331e-01, -8.9449e-02,\n",
      "           1.5502e-02, -1.1195e-01, -1.0997e+00,  2.7160e-01,  3.5248e-01,\n",
      "           1.9232e+00,  4.2118e-01,  1.1189e+00, -1.2293e+00,  0.0000e+00,\n",
      "           1.9467e-01,  2.5249e+00,  1.5197e+00,  1.8507e+00,  3.8355e-01,\n",
      "          -3.5156e-01,  5.9837e-01, -1.8425e+00, -4.7889e-01,  0.0000e+00,\n",
      "           5.8883e-01,  7.3185e-01,  4.4388e-01,  1.3635e+00, -1.7613e-01,\n",
      "           5.8525e-01, -2.1565e+00, -2.1799e+00,  3.5397e-01,  1.1454e-02,\n",
      "           2.7016e+00, -1.7220e+00,  1.2751e+00, -4.4141e-02, -1.0986e+00,\n",
      "           0.0000e+00, -2.0436e+00, -6.6980e-01, -1.6084e-01,  1.6321e+00,\n",
      "          -1.0262e+00, -6.5260e-01,  0.0000e+00,  6.9369e-01, -2.8757e-01,\n",
      "          -1.1893e+00,  1.5880e-01, -5.9819e-01, -9.3722e-01,  4.8900e-01,\n",
      "           4.4228e-01,  0.0000e+00,  2.7248e-01,  7.8193e-01, -9.4790e-01,\n",
      "           7.6006e-01, -1.5560e-02, -1.1622e+00,  0.0000e+00,  3.9413e-01,\n",
      "          -3.3320e-01,  3.8098e-01,  9.3819e-01, -3.1029e-01, -1.2434e+00,\n",
      "           1.8613e+00, -7.2829e-01, -2.8891e+00,  2.1875e-01,  6.2545e-03,\n",
      "           1.6982e+00,  6.9462e-01,  1.1920e+00, -7.2225e-01,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  8.6713e-01, -1.4532e+00,  1.6866e+00,\n",
      "           3.4181e-01, -1.1809e+00, -1.0239e+00,  4.0608e-02,  1.0778e+00,\n",
      "          -1.9802e+00,  0.0000e+00,  3.2473e-01,  3.6253e-01, -1.5382e+00,\n",
      "           3.0206e+00, -5.1866e-01, -5.6367e-01, -7.0167e-01,  0.0000e+00,\n",
      "           0.0000e+00, -7.9475e-01, -5.2156e-01,  3.0365e-01,  0.0000e+00,\n",
      "          -2.1512e+00, -1.8746e-01,  1.3547e-01, -1.1577e+00, -1.4456e-01,\n",
      "           2.1995e-01,  0.0000e+00, -1.0981e-01, -6.6680e-01, -8.9375e-01,\n",
      "           1.0832e-01, -1.1213e+00, -1.8531e-01,  1.3381e+00,  1.3490e+00,\n",
      "           1.0814e+00,  4.8781e-01,  1.7312e+00,  2.2400e-02, -4.7366e-01,\n",
      "           7.0065e-01,  3.8602e-01, -8.2154e-02,  1.1607e+00, -5.2622e-01,\n",
      "           4.1151e-01,  0.0000e+00,  6.7033e-01, -7.9261e-01,  1.4955e+00,\n",
      "          -7.5046e-01,  1.2237e+00, -9.1379e-01,  6.2844e-01,  1.7518e+00,\n",
      "           1.1110e+00,  7.7649e-01, -8.5581e-01,  1.7859e+00, -1.3503e+00,\n",
      "          -1.0610e+00, -4.7625e-01, -3.5719e-01, -5.3729e-01, -1.1326e-01,\n",
      "           5.6410e-01, -1.8134e+00,  1.3914e+00, -3.2295e+00,  2.5845e+00,\n",
      "           1.3446e+00,  0.0000e+00,  7.5077e-01, -1.3996e+00, -1.5711e+00,\n",
      "          -8.1452e-01,  9.9589e-01,  2.1175e+00,  4.1981e-01, -9.0896e-01,\n",
      "           4.9427e-01,  9.6776e-01, -2.4499e+00,  5.2607e-01,  1.7593e-01,\n",
      "          -2.9660e-01, -2.2930e+00,  1.0925e-01,  1.9834e+00, -4.6571e-02,\n",
      "           9.6845e-01, -3.0774e-02, -2.6063e-01,  0.0000e+00,  1.0013e+00,\n",
      "          -4.1627e-01,  8.7412e-01,  1.1603e+00, -1.0516e+00,  1.6174e+00,\n",
      "           3.1712e-01,  1.2640e+00, -5.0357e-01,  1.7831e-01, -1.8398e+00,\n",
      "          -7.2776e-01,  2.6241e-01, -5.3301e-01,  0.0000e+00, -4.4619e-01,\n",
      "           1.4428e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1220, 0.1078, 0.0712, 0.1118, 0.0803, 0.1096, 0.0835, 0.0766, 0.1542,\n",
      "         0.0829]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2497, -0.0025, -0.0854,  ...,  0.1648,  0.0289,  0.0420],\n",
      "        [ 0.2146, -0.1052, -0.5294,  ...,  0.0446, -0.0400,  0.1088],\n",
      "        [ 0.0496, -0.3670, -0.0710,  ..., -0.0166,  0.0778,  0.3162],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1336, -0.0248, -0.1640, -0.0583,  0.0698,  0.0439, -0.0690,\n",
      "          -0.0442, -0.0376, -0.0279,  0.0265,  0.0439, -0.0605,  0.0247,\n",
      "          -0.0438,  0.0492,  0.0190,  0.0243, -0.0959,  0.0828,  0.0032,\n",
      "          -0.0954,  0.1710, -0.0169,  0.0270, -0.0594,  0.0147, -0.1028,\n",
      "          -0.0455,  0.0065,  0.1239, -0.1169,  0.0893, -0.0812,  0.0259,\n",
      "           0.0302, -0.0086, -0.0111, -0.0489,  0.0784, -0.0679,  0.0432,\n",
      "           0.0022,  0.0837, -0.0442,  0.1316, -0.0559, -0.0348,  0.1130,\n",
      "          -0.0398, -0.0761, -0.0336, -0.1245, -0.0814,  0.0663,  0.0926,\n",
      "           0.0364,  0.0964,  0.1132,  0.0617,  0.0043, -0.0519, -0.1182,\n",
      "          -0.0207,  0.0327,  0.1395, -0.1179,  0.1253, -0.1585,  0.0736,\n",
      "           0.0217,  0.1359,  0.0401, -0.0325, -0.1389,  0.1848,  0.0872,\n",
      "           0.0798, -0.0975,  0.0510, -0.0969, -0.0289, -0.1405,  0.0354,\n",
      "          -0.0751,  0.0292, -0.0407,  0.0844,  0.0217, -0.0350,  0.0769,\n",
      "           0.0572,  0.0109,  0.0297,  0.0084,  0.1492, -0.0140,  0.1697,\n",
      "           0.0499,  0.1776, -0.1302,  0.2260,  0.0297,  0.0417, -0.1543,\n",
      "          -0.2096, -0.0110,  0.1871, -0.1993,  0.0344,  0.1600,  0.0084,\n",
      "           0.0415, -0.2265, -0.0609, -0.0445, -0.0131, -0.0393, -0.0767,\n",
      "           0.0360,  0.0051,  0.0113, -0.1118,  0.1326, -0.0072, -0.0957,\n",
      "           0.0098, -0.0735, -0.0229, -0.1230,  0.0693, -0.1811,  0.0976,\n",
      "           0.0963, -0.1527, -0.0766,  0.2703, -0.0424, -0.1068,  0.1181,\n",
      "          -0.0346,  0.1405, -0.0378,  0.0938,  0.0514, -0.0148, -0.0423,\n",
      "          -0.0216,  0.1318, -0.0385, -0.1270,  0.1027, -0.0513,  0.0289,\n",
      "           0.0860,  0.0792, -0.0083,  0.0902, -0.0174, -0.1217, -0.0737,\n",
      "          -0.1326, -0.0632,  0.1456, -0.0850, -0.0300, -0.1245,  0.0546,\n",
      "          -0.1223,  0.0940, -0.1877,  0.0102, -0.0302,  0.1027, -0.1189,\n",
      "          -0.0853,  0.0839,  0.0840,  0.1895, -0.1953,  0.0918, -0.1213,\n",
      "          -0.0064, -0.0529, -0.0225, -0.0012, -0.0385,  0.0087, -0.0209,\n",
      "          -0.1125,  0.0157,  0.1178, -0.1702, -0.0518, -0.0882,  0.0380,\n",
      "          -0.1089, -0.0320, -0.0545, -0.0170, -0.0837,  0.0478, -0.1545,\n",
      "           0.1554, -0.0551, -0.0421,  0.1645,  0.1978,  0.0261, -0.1423,\n",
      "          -0.0227, -0.1583, -0.1399,  0.1739, -0.0887,  0.1144,  0.0073,\n",
      "           0.1058, -0.1146,  0.0201,  0.0902, -0.0221,  0.1511, -0.0494,\n",
      "           0.0811,  0.0064,  0.0976, -0.1383, -0.2071,  0.1470, -0.1602,\n",
      "          -0.0259,  0.0388, -0.0067,  0.0447,  0.1374,  0.0798, -0.0581,\n",
      "           0.1891,  0.0885,  0.1625,  0.0117,  0.0115,  0.0438,  0.0584,\n",
      "           0.0796, -0.2721, -0.0278,  0.0842,  0.0184,  0.0827, -0.1111,\n",
      "          -0.0733, -0.0544,  0.0617,  0.0700]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3895,  0.4085, -1.9831,  0.0000,  0.1700,  0.0000, -0.3162,\n",
      "          -0.0171, -0.6578,  0.2978, -0.4678,  0.0000, -0.3219, -0.3889,\n",
      "           0.0000, -0.0744,  0.1412,  0.0712,  0.4326,  1.2395, -0.1544,\n",
      "           1.9053, -1.8092,  0.8282,  0.4053,  0.6232,  1.7745, -0.7265,\n",
      "           0.2601,  2.5248, -0.2864,  0.0000,  0.2911,  0.7970, -0.9458,\n",
      "          -1.1544, -0.6291,  0.5036, -0.3715,  0.0000, -0.2010,  0.7060,\n",
      "           1.6318,  0.4857, -0.0090,  0.8798,  0.2932, -0.0944, -2.3884,\n",
      "           2.2119, -0.4571,  1.8297,  0.0000, -0.2134, -0.4246,  1.5648,\n",
      "           0.2665, -1.0174,  0.0000, -0.8054,  0.0000, -1.0132,  0.9061,\n",
      "           0.5893,  0.4544, -0.6461,  1.8136,  0.0000, -0.0587, -1.3869,\n",
      "          -0.7893, -0.3567,  0.7288,  0.0348,  1.4760, -0.9964, -0.3711,\n",
      "          -0.1721, -0.9063,  0.7271,  0.0403,  0.3025,  0.3283,  0.4104,\n",
      "          -1.0216, -2.4024,  0.1578,  0.6810,  0.4976,  0.0000,  0.1245,\n",
      "          -1.1674, -2.1036,  1.0471,  1.8103,  1.1550,  0.0487, -0.3944,\n",
      "           0.0000, -0.7310, -0.1624, -0.0538,  3.2151, -2.4825,  0.0000,\n",
      "           0.8047,  1.9704,  0.0000,  0.1608, -1.6725, -0.1179,  0.1333,\n",
      "           2.7433,  0.1062, -0.6076,  1.0176,  2.3865, -0.3298, -0.8327,\n",
      "          -0.3229, -0.6614, -1.1700, -1.7275, -2.5830, -0.6482,  0.0000,\n",
      "           1.2934, -1.0945,  0.4114,  0.4862, -1.4332, -0.3277,  0.8039,\n",
      "           0.1087,  0.3460,  0.0749,  1.4290, -2.1203,  1.9624, -0.9638,\n",
      "           0.1343,  0.0000, -0.7974,  2.3703,  0.0000, -2.1990, -0.5652,\n",
      "           0.4185,  0.1397, -0.4088, -0.8242, -1.2838,  0.2313, -0.1395,\n",
      "          -0.1646, -0.8460, -0.3742, -3.1073, -1.0711,  0.2189,  0.2345,\n",
      "           0.9416, -0.9018,  0.5593, -0.7496,  0.4937, -0.1463,  0.5714,\n",
      "           0.0086, -0.0348,  0.0318, -0.1644, -0.0494, -0.3735,  0.6965,\n",
      "           2.1766, -0.5536, -2.0448,  0.2204,  0.5236, -1.4422,  1.7046,\n",
      "           0.5384, -1.0367,  0.8399, -1.5085,  1.3062, -1.7788, -0.5079,\n",
      "           2.4773,  0.3714,  0.3243,  0.7682, -1.3982,  1.5098,  0.9040,\n",
      "           0.3599, -0.3223,  2.5730,  0.4920, -0.0171,  0.7731,  0.0280,\n",
      "          -0.1620,  0.0000,  1.2656,  0.0839,  0.8439, -1.1959,  1.2686,\n",
      "           1.1658, -0.7629,  2.8374,  0.6315,  2.4102,  0.0000,  1.9152,\n",
      "          -0.6225,  1.5780,  0.8250,  0.0000,  0.9541,  1.9986, -0.6557,\n",
      "           0.0000,  0.4421, -1.4339, -0.3452,  0.5092,  1.2540,  0.7522,\n",
      "           0.0000,  2.3865, -1.4787,  0.0000, -0.7415, -2.3072,  0.2187,\n",
      "           1.2882,  1.0818,  0.0000,  0.7839, -0.3206, -1.1766, -1.4056,\n",
      "           1.5697,  0.0000, -0.5165,  0.9537, -2.6776, -0.1218,  1.5877,\n",
      "          -0.1536,  0.5851, -0.2525, -0.2224]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1155, 0.0816, 0.1005, 0.1577, 0.0939, 0.0917, 0.0604, 0.0759, 0.1279,\n",
      "         0.0951]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2497, -0.0025, -0.0854,  ...,  0.1648,  0.0289,  0.0420],\n",
      "        [ 0.2146, -0.1052, -0.5294,  ...,  0.0446, -0.0400,  0.1088],\n",
      "        [ 0.0496, -0.3670, -0.0710,  ..., -0.0166,  0.0778,  0.3162],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1481, -0.0351, -0.1753, -0.0847,  0.0871,  0.0137, -0.0770,\n",
      "          -0.0397, -0.0483, -0.0314,  0.0484,  0.0380, -0.0857,  0.0357,\n",
      "          -0.0730,  0.0284, -0.0198,  0.0216, -0.1350,  0.0779,  0.0107,\n",
      "          -0.1423,  0.1877, -0.0278,  0.0152, -0.0581,  0.0048, -0.1157,\n",
      "          -0.0574, -0.0030,  0.1241, -0.1411,  0.1041, -0.1106,  0.0041,\n",
      "           0.0571, -0.0203, -0.0434, -0.0521,  0.1012, -0.0812,  0.0523,\n",
      "          -0.0157,  0.1175, -0.0498,  0.1731, -0.0878, -0.0629,  0.1219,\n",
      "          -0.0668, -0.0812, -0.0795, -0.1387, -0.0926,  0.0721,  0.0849,\n",
      "           0.0373,  0.0951,  0.1414,  0.0816,  0.0087, -0.0795, -0.1594,\n",
      "           0.0057,  0.0311,  0.1715, -0.1302,  0.1626, -0.2045,  0.0969,\n",
      "           0.0472,  0.1767,  0.0401, -0.0231, -0.1386,  0.2225,  0.1095,\n",
      "           0.0852, -0.1331,  0.0583, -0.0941, -0.0249, -0.1802,  0.0596,\n",
      "          -0.0872,  0.0349, -0.0188,  0.1104,  0.0503, -0.0285,  0.1057,\n",
      "           0.0790, -0.0091,  0.0345,  0.0067,  0.1964, -0.0005,  0.2027,\n",
      "           0.0588,  0.2270, -0.1591,  0.2706,  0.0622,  0.0487, -0.1335,\n",
      "          -0.2490,  0.0260,  0.2386, -0.2358,  0.0624,  0.1687, -0.0055,\n",
      "           0.0474, -0.2610, -0.1054, -0.0160, -0.0289, -0.0676, -0.1018,\n",
      "           0.0088,  0.0128,  0.0102, -0.1488,  0.1672, -0.0373, -0.1081,\n",
      "          -0.0013, -0.1022, -0.0035, -0.1548,  0.1068, -0.2207,  0.1100,\n",
      "           0.1237, -0.1741, -0.1239,  0.3026, -0.0349, -0.1156,  0.1607,\n",
      "          -0.0698,  0.1697, -0.0543,  0.1001,  0.0493, -0.0284, -0.0336,\n",
      "           0.0128,  0.1560, -0.0190, -0.1667,  0.1216, -0.0629,  0.0434,\n",
      "           0.1185,  0.0959, -0.0284,  0.1122, -0.0071, -0.1531, -0.0895,\n",
      "          -0.1459, -0.0700,  0.1757, -0.1092, -0.0309, -0.1556,  0.0462,\n",
      "          -0.1432,  0.1032, -0.2372,  0.0085, -0.0364,  0.1301, -0.1308,\n",
      "          -0.1212,  0.0577,  0.0971,  0.2283, -0.2303,  0.0888, -0.1205,\n",
      "          -0.0238, -0.0522, -0.0062, -0.0182, -0.0615,  0.0265, -0.0384,\n",
      "          -0.1304,  0.0162,  0.1197, -0.1925, -0.0730, -0.1076,  0.0232,\n",
      "          -0.1263, -0.0469, -0.0655, -0.0084, -0.0814,  0.0364, -0.1823,\n",
      "           0.1713, -0.0763, -0.0649,  0.1929,  0.2268,  0.0191, -0.1638,\n",
      "          -0.0395, -0.1547, -0.1524,  0.2118, -0.1045,  0.1579, -0.0091,\n",
      "           0.1013, -0.1256,  0.0194,  0.0956, -0.0089,  0.1764, -0.0474,\n",
      "           0.1085, -0.0037,  0.1123, -0.1844, -0.2427,  0.1600, -0.1616,\n",
      "          -0.0354,  0.0200, -0.0348,  0.0377,  0.1540,  0.0829, -0.0734,\n",
      "           0.2299,  0.1122,  0.1735, -0.0014, -0.0141,  0.0868,  0.0697,\n",
      "           0.0881, -0.3064, -0.0522,  0.0848,  0.0029,  0.0961, -0.1433,\n",
      "          -0.0754, -0.0824,  0.0867,  0.0844]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7259e-01, -4.3080e-01,  3.1515e-01, -1.0849e+00, -1.1727e+00,\n",
      "           0.0000e+00, -1.9145e+00,  1.3514e+00,  1.9021e-01,  6.1730e-01,\n",
      "           0.0000e+00,  6.0252e-01,  2.2906e-01,  0.0000e+00, -3.1832e+00,\n",
      "          -6.8304e-02, -1.6335e+00, -9.4353e-01,  1.3605e+00, -1.4355e+00,\n",
      "          -1.4051e-01, -5.2435e-01, -1.1198e+00, -2.5955e+00, -7.5837e-02,\n",
      "           1.3916e+00, -6.1971e-01,  0.0000e+00,  1.2771e-01,  5.5476e-01,\n",
      "           9.1561e-01,  0.0000e+00,  2.2239e-01,  2.0166e+00, -6.3645e-02,\n",
      "          -1.4085e+00, -1.1171e-01, -8.1751e-01,  3.1514e-01,  0.0000e+00,\n",
      "           8.6305e-01, -8.9933e-01,  1.0089e+00, -1.5638e+00,  0.0000e+00,\n",
      "          -3.0030e-01,  7.0592e-01, -6.0201e-01, -1.0209e+00,  1.1170e+00,\n",
      "          -1.3229e+00,  2.6776e+00,  0.0000e+00, -8.4694e-01,  2.2789e-01,\n",
      "          -3.0990e-01, -1.4340e+00, -9.6372e-02,  1.2758e+00,  2.1818e+00,\n",
      "          -1.0064e+00,  3.5981e-02, -2.8018e-01,  2.6584e-01, -6.3082e-02,\n",
      "           3.9370e-01,  5.7805e-01,  1.1652e+00,  1.5809e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00, -3.1149e-02,  0.0000e+00, -2.1431e-01,\n",
      "           1.3940e-01,  5.2586e-01,  0.0000e+00,  1.0273e+00, -7.9383e-01,\n",
      "           7.5823e-01, -1.0051e+00,  7.5800e-01,  1.0588e+00, -1.2153e+00,\n",
      "           0.0000e+00, -1.1080e+00,  5.4873e-01, -9.4484e-01,  0.0000e+00,\n",
      "           5.2911e-01,  9.8722e-01,  0.0000e+00,  9.4397e-01,  6.0801e-01,\n",
      "          -1.5914e-02,  3.5409e-01,  0.0000e+00,  1.3720e+00,  2.4481e+00,\n",
      "           2.4353e-01,  4.4493e-02, -4.6658e-01, -9.8947e-01,  1.6406e+00,\n",
      "          -1.0238e+00,  3.0294e+00,  6.2039e-01,  0.0000e+00, -1.2355e+00,\n",
      "           1.8999e-01, -5.0317e-01, -5.7090e-01,  7.1243e-01, -7.8065e-01,\n",
      "           0.0000e+00,  4.0383e-01,  2.2375e-01, -2.3271e+00,  2.9295e-02,\n",
      "          -8.1445e-01, -1.4115e+00, -1.8382e+00,  6.0323e-01, -9.5679e-01,\n",
      "          -2.0083e-01,  4.0022e-02,  2.1505e+00,  1.3964e+00, -2.0880e+00,\n",
      "          -9.2629e-01,  4.4978e-01, -1.1679e+00,  4.2539e-01, -4.6852e-01,\n",
      "          -7.4584e-01,  0.0000e+00, -9.7534e-01, -1.9446e-02,  2.3978e+00,\n",
      "           6.9861e-01, -1.1218e+00,  1.6918e+00, -1.4037e-01, -6.7000e-01,\n",
      "           3.3417e-02,  7.5966e-01,  4.2290e-01, -1.0338e+00, -9.5374e-02,\n",
      "           1.5601e+00,  5.8686e-01, -3.3851e-01,  6.5771e-01,  1.8413e+00,\n",
      "          -2.5267e-01, -2.1780e-01,  6.2384e-01, -2.3633e+00,  1.0559e+00,\n",
      "           0.0000e+00, -7.7213e-02,  1.5508e-01, -1.2121e+00, -2.2009e-02,\n",
      "           1.6824e+00,  1.8524e+00,  2.7134e-01, -1.2704e+00, -7.1315e-01,\n",
      "          -1.2243e+00, -1.0943e+00, -2.5909e+00,  5.0584e-01, -3.0601e+00,\n",
      "          -2.8735e-01,  4.9778e-01,  8.2965e-01,  3.1703e-01, -7.9301e-01,\n",
      "           2.7215e-01,  2.3399e+00,  1.0578e+00,  8.3870e-01, -4.0262e-01,\n",
      "           7.2769e-01,  5.9874e-01,  3.5969e-01,  0.0000e+00, -1.8308e+00,\n",
      "           0.0000e+00,  2.1596e+00,  3.3617e-01, -1.0155e+00, -1.1726e+00,\n",
      "          -2.2157e+00,  1.6673e+00,  2.1530e+00,  3.6345e-01,  2.3837e+00,\n",
      "           3.2494e-02, -5.0161e-01, -1.2768e+00, -5.4280e-01, -4.0758e-01,\n",
      "          -1.4473e+00,  9.5342e-01, -8.5195e-01,  8.2988e-01, -1.5602e+00,\n",
      "           6.3693e-01,  6.7577e-01,  2.3982e+00,  5.5253e-02,  1.8937e+00,\n",
      "           1.3087e+00,  5.8037e-01, -2.3176e+00,  1.5502e+00, -2.2253e-01,\n",
      "          -2.2721e-01,  1.7338e+00,  2.7671e-01, -1.5522e+00,  9.2283e-01,\n",
      "          -1.2244e+00, -8.4864e-01, -1.8021e+00, -6.4779e-04,  3.7321e-01,\n",
      "          -1.5737e+00, -1.2375e-01,  9.6634e-01, -1.7370e+00,  1.6945e+00,\n",
      "          -1.4404e+00,  6.3406e-01, -1.7227e+00,  9.8029e-01, -1.7165e+00,\n",
      "           1.5612e+00, -2.7263e-01, -2.5971e+00,  1.2389e+00, -1.2283e+00,\n",
      "           1.8858e+00, -5.0838e-01,  5.4286e-01, -2.6131e-01, -1.0222e+00,\n",
      "           1.3338e+00,  3.1105e-01, -5.1197e-02, -2.2878e-01, -1.6126e+00,\n",
      "           1.8068e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0590, 0.1011, 0.1501, 0.0724, 0.1708, 0.1185, 0.1140, 0.0711, 0.0957,\n",
      "         0.0474]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2497, -0.0025, -0.0854,  ...,  0.1648,  0.0289,  0.0420],\n",
      "        [ 0.2146, -0.1052, -0.5294,  ...,  0.0446, -0.0400,  0.1088],\n",
      "        [ 0.0496, -0.3670, -0.0710,  ..., -0.0166,  0.0778,  0.3162],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1613, -0.0104, -0.2128, -0.0924,  0.0459, -0.0332, -0.0324,\n",
      "          -0.0658, -0.0269, -0.0509,  0.0820,  0.0097, -0.0820,  0.0005,\n",
      "          -0.0708,  0.0032,  0.0050, -0.0226, -0.1455,  0.0792, -0.0133,\n",
      "          -0.1831,  0.1629,  0.0196, -0.0092, -0.1262, -0.0596, -0.1013,\n",
      "          -0.1029, -0.0594,  0.0848, -0.1810,  0.1046, -0.1118,  0.0187,\n",
      "           0.0899, -0.0449, -0.0696, -0.0996,  0.0711, -0.0666,  0.0115,\n",
      "          -0.0400,  0.1479, -0.0079,  0.1506, -0.1114, -0.1078,  0.1188,\n",
      "          -0.0625, -0.1124, -0.1117, -0.1513, -0.0767,  0.0692,  0.0698,\n",
      "           0.0403,  0.0894,  0.1778,  0.1248, -0.0107, -0.0725, -0.1897,\n",
      "          -0.0143,  0.0299,  0.1829, -0.1097,  0.1658, -0.1983,  0.0622,\n",
      "           0.0111,  0.1917, -0.0044, -0.0124, -0.1547,  0.2383,  0.0981,\n",
      "           0.1103, -0.1745,  0.0286, -0.1231, -0.0928, -0.2015,  0.0369,\n",
      "          -0.0976,  0.0612, -0.0301,  0.0878,  0.0374, -0.0655,  0.1191,\n",
      "           0.1129, -0.0080,  0.0574, -0.0125,  0.1943,  0.0158,  0.2372,\n",
      "          -0.0020,  0.2558, -0.1964,  0.2503,  0.0984,  0.0656, -0.1885,\n",
      "          -0.2473,  0.0493,  0.2505, -0.2398,  0.0719,  0.1848, -0.0443,\n",
      "           0.0686, -0.2931, -0.1253, -0.0175, -0.0331, -0.1020, -0.1199,\n",
      "          -0.0175,  0.0553, -0.0104, -0.1702,  0.1682, -0.0336, -0.1249,\n",
      "          -0.0080, -0.1046,  0.0190, -0.1797,  0.1103, -0.2789,  0.1532,\n",
      "           0.1139, -0.2119, -0.0566,  0.3392, -0.0572, -0.1697,  0.1557,\n",
      "          -0.0644,  0.1698, -0.0495,  0.1374,  0.0613, -0.0418, -0.0312,\n",
      "           0.0376,  0.1257, -0.0094, -0.1671,  0.0874, -0.0755,  0.0317,\n",
      "           0.1216,  0.0747, -0.0343,  0.1331,  0.0670, -0.2015, -0.0949,\n",
      "          -0.1616, -0.0698,  0.1837, -0.0748, -0.0217, -0.1690,  0.0386,\n",
      "          -0.0509,  0.1909, -0.2675, -0.0084, -0.0178,  0.1184, -0.1590,\n",
      "          -0.1360,  0.0174,  0.1193,  0.2896, -0.2195,  0.0872, -0.1370,\n",
      "          -0.0480, -0.0254, -0.0074, -0.0129, -0.1338,  0.0709,  0.0130,\n",
      "          -0.1369, -0.0092,  0.1314, -0.1999, -0.1059, -0.0740,  0.0250,\n",
      "          -0.1861, -0.0591, -0.0743,  0.0510, -0.0778,  0.0525, -0.1663,\n",
      "           0.2097, -0.0761, -0.0622,  0.1927,  0.2316, -0.0177, -0.1260,\n",
      "          -0.0067, -0.1695, -0.1379,  0.2328, -0.1080,  0.2055, -0.0880,\n",
      "           0.0903, -0.1146,  0.0805,  0.1220, -0.0247,  0.1874, -0.0526,\n",
      "           0.1635, -0.0261,  0.1596, -0.1863, -0.2393,  0.1887, -0.2399,\n",
      "          -0.0457,  0.0431, -0.0805,  0.0023,  0.1388,  0.0856, -0.0988,\n",
      "           0.2127,  0.1268,  0.1597, -0.0174, -0.0621,  0.0769,  0.0709,\n",
      "           0.1211, -0.3182, -0.0729,  0.1090,  0.0929,  0.1271, -0.1510,\n",
      "          -0.0919, -0.0807,  0.0561,  0.1070]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6049e-02,  3.9918e-01, -9.6638e-01, -6.8161e-01,  3.7610e-01,\n",
      "          -2.0183e-01,  1.4649e+00, -8.3303e-02, -3.5847e+00,  9.0668e-01,\n",
      "           0.0000e+00, -6.2912e-01,  2.6048e+00, -6.2976e-01,  0.0000e+00,\n",
      "          -1.5796e-01,  0.0000e+00,  1.0950e+00,  4.5513e-01,  4.3603e-01,\n",
      "          -6.3355e-01, -3.8321e-01,  1.6417e+00,  1.5111e+00,  7.5358e-01,\n",
      "          -7.5580e-02, -1.8785e-01, -7.5912e-01,  1.6538e+00,  8.6168e-01,\n",
      "           1.2320e+00,  1.2190e+00, -1.0343e+00, -8.2664e-02, -1.5346e+00,\n",
      "           0.0000e+00,  2.8096e-01, -3.7451e+00,  1.9807e-01,  1.6012e+00,\n",
      "          -4.5874e-01, -1.3985e+00, -2.6839e-01, -1.7160e+00,  0.0000e+00,\n",
      "           6.6740e-01,  5.4114e-01,  3.7057e-01, -1.3410e+00,  1.4405e-01,\n",
      "          -6.2931e-01,  2.7526e+00,  6.1039e-01, -1.0293e+00, -2.5586e-02,\n",
      "           2.0318e-01, -8.8220e-01, -1.2526e+00, -2.3676e-01, -4.2537e-01,\n",
      "           1.1008e+00,  1.4083e+00, -2.0324e-01, -5.0166e-01, -2.9644e+00,\n",
      "           5.5064e-01,  1.2790e+00, -1.2880e+00,  4.1144e-01,  5.2646e-01,\n",
      "          -1.2671e+00, -3.0183e-02,  7.0738e-01, -3.6414e+00,  3.2610e-01,\n",
      "          -1.9352e-03, -1.5987e-01,  1.0627e+00, -5.8258e-02,  0.0000e+00,\n",
      "          -1.4004e+00,  2.1314e+00, -9.2479e-01,  1.0059e+00, -2.0778e-01,\n",
      "           4.3491e-01,  1.6617e+00, -9.7444e-01, -1.0362e-01,  0.0000e+00,\n",
      "          -2.2737e+00,  1.1005e+00, -6.2234e-01, -1.1355e+00,  4.6739e-01,\n",
      "          -1.1707e+00,  3.4204e-02,  6.2912e-01,  1.7203e+00, -7.8005e-01,\n",
      "           2.6975e+00, -1.4626e+00,  1.0761e+00,  1.4540e+00,  0.0000e+00,\n",
      "          -7.6262e-01,  1.2125e+00,  1.2722e-01, -1.4730e+00, -1.3239e-02,\n",
      "           0.0000e+00,  1.3448e-01, -1.0483e+00,  1.3102e+00, -1.6536e+00,\n",
      "          -2.9898e+00, -5.6397e-02,  0.0000e+00, -1.9326e-01,  4.4498e-01,\n",
      "          -1.4666e+00,  7.0235e-01, -1.4607e+00, -7.2617e-01, -9.5857e-01,\n",
      "          -1.3090e+00,  8.9728e-01,  1.7023e-01,  0.0000e+00, -7.5233e-01,\n",
      "           0.0000e+00,  5.3003e-01, -1.5833e+00,  9.8408e-01,  2.7613e-01,\n",
      "          -5.8966e-01,  6.5966e-01,  5.7399e-01, -1.1586e+00, -1.0102e+00,\n",
      "          -3.8875e-01,  6.7783e-01,  0.0000e+00, -1.0151e-01, -1.6859e+00,\n",
      "          -1.0109e-01, -5.4330e-01, -8.4444e-01, -7.5547e-01,  1.7752e-01,\n",
      "           0.0000e+00, -1.9971e-01,  0.0000e+00, -4.0612e-01,  4.4151e-01,\n",
      "          -1.9448e-01, -6.4354e-02, -1.2916e-01,  3.9331e-02,  5.3765e-01,\n",
      "          -2.6360e-02,  2.2066e+00,  4.8115e-01,  0.0000e+00, -5.2688e-01,\n",
      "           0.0000e+00,  2.8164e-01,  0.0000e+00, -3.5805e-01, -4.7804e-01,\n",
      "           7.3766e-01,  0.0000e+00,  1.9984e-02,  0.0000e+00,  1.2777e+00,\n",
      "          -1.0987e+00, -9.8734e-01, -2.0771e+00,  1.9693e+00,  8.6487e-02,\n",
      "          -3.0174e-02,  3.5064e-02,  6.7139e-01,  0.0000e+00, -7.4697e-01,\n",
      "          -3.4083e-01,  0.0000e+00, -7.8424e-01,  1.2098e+00,  1.0125e+00,\n",
      "           3.0745e+00,  4.9447e-01, -1.4432e-01, -5.9432e-01,  5.6074e-01,\n",
      "           2.1653e+00, -1.1880e+00,  5.3496e-01,  1.8118e+00, -9.4708e-01,\n",
      "          -1.6624e+00, -1.0151e+00,  1.2419e+00,  0.0000e+00,  2.3198e-01,\n",
      "          -5.7523e-01, -2.2930e+00,  6.8178e-01, -1.0746e+00, -4.7126e-01,\n",
      "           0.0000e+00, -5.7348e-01, -3.4112e-01,  7.9320e-01,  3.0115e-02,\n",
      "          -6.8446e-01, -1.0192e+00,  9.6630e-01,  0.0000e+00,  2.1696e+00,\n",
      "          -1.0828e+00, -4.2731e-01, -1.8439e+00,  0.0000e+00,  3.3768e-01,\n",
      "           7.0496e-01, -6.9654e-01, -6.2823e-01,  0.0000e+00, -1.5787e+00,\n",
      "          -1.1087e+00,  1.5815e+00,  0.0000e+00,  0.0000e+00, -2.9800e+00,\n",
      "           4.0358e+00,  5.8527e-01,  4.3396e-02, -1.5800e+00, -2.8726e-01,\n",
      "           7.4181e-01, -3.2484e+00, -3.0452e-01, -8.5227e-01,  1.1309e-02,\n",
      "           0.0000e+00,  2.7480e-01,  2.5259e-01,  2.6115e-01,  3.8651e-01,\n",
      "          -3.6555e-01, -1.5871e-01, -5.5393e-01, -5.2697e-02, -1.1469e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0603, 0.0588, 0.0812, 0.0587, 0.1413, 0.2893, 0.0508, 0.1051, 0.0501,\n",
      "         0.1044]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3443, -0.0835,  0.0408,  ..., -0.3075,  0.0700,  0.1714],\n",
      "        [-0.1600,  0.2832, -0.1938,  ..., -0.1769,  0.0702, -0.0579],\n",
      "        [-0.1865,  0.2735, -0.1932,  ...,  0.0543,  0.2795, -0.1431],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1117,  0.1075, -0.1467,  0.0643, -0.1608, -0.0453, -0.0366,\n",
      "          -0.0694, -0.0276,  0.0011,  0.0993, -0.0284, -0.0723,  0.0155,\n",
      "           0.0741, -0.1344,  0.0030,  0.0618, -0.1600, -0.0403, -0.0272,\n",
      "          -0.1233,  0.0614,  0.0733,  0.0415, -0.1379, -0.0419, -0.1404,\n",
      "          -0.0521,  0.0361,  0.0690, -0.1485, -0.0556, -0.0262, -0.1110,\n",
      "           0.0511, -0.0412, -0.1106, -0.0320,  0.0022, -0.0139,  0.0326,\n",
      "          -0.0509,  0.0649, -0.0351,  0.1173, -0.0154, -0.0854,  0.1361,\n",
      "           0.0952, -0.0677, -0.0179, -0.1115,  0.0466,  0.0877, -0.0205,\n",
      "           0.0496,  0.0684,  0.0531,  0.1328,  0.0345, -0.0152, -0.0577,\n",
      "          -0.0315, -0.0352,  0.0114, -0.0917,  0.0903, -0.1830,  0.0830,\n",
      "           0.1028,  0.1243, -0.0255,  0.1366, -0.0374,  0.1258,  0.1261,\n",
      "           0.1255,  0.0121, -0.0008,  0.0054, -0.1860, -0.1809,  0.1001,\n",
      "          -0.0826,  0.1621,  0.0401,  0.0878,  0.0238,  0.0603,  0.1157,\n",
      "           0.0321, -0.1107, -0.0577,  0.0089,  0.0606,  0.1411,  0.1290,\n",
      "           0.0337,  0.1024, -0.0355,  0.0588,  0.0359, -0.0520, -0.0617,\n",
      "           0.0059,  0.0838,  0.0993, -0.0867,  0.1794, -0.0321,  0.0839,\n",
      "           0.1208, -0.1578, -0.0950,  0.0331,  0.0833, -0.0850, -0.0924,\n",
      "          -0.0987,  0.0678, -0.0314, -0.1657,  0.0393, -0.1497,  0.0193,\n",
      "           0.0325, -0.0453,  0.0390,  0.0982, -0.0533, -0.0169,  0.0709,\n",
      "           0.1084,  0.0211,  0.0472,  0.1690, -0.0482, -0.1214,  0.0463,\n",
      "          -0.0432,  0.1213, -0.0915,  0.0479,  0.0880,  0.0765,  0.0036,\n",
      "           0.0229,  0.1181,  0.1104, -0.1055, -0.0116, -0.1368, -0.0243,\n",
      "           0.0741,  0.1263,  0.0713,  0.1241, -0.0436, -0.0395, -0.0509,\n",
      "          -0.0705, -0.0921,  0.1549, -0.0572,  0.0667,  0.0131,  0.0075,\n",
      "           0.0894,  0.0612, -0.0946,  0.0791,  0.1181,  0.0695, -0.0528,\n",
      "          -0.1133,  0.0180,  0.1709,  0.1131,  0.0347, -0.0696, -0.1028,\n",
      "          -0.0598, -0.0298, -0.0271,  0.1351, -0.1813,  0.0496, -0.0134,\n",
      "          -0.0300, -0.0332,  0.0339, -0.1562, -0.1364,  0.0306, -0.0429,\n",
      "          -0.0757, -0.0540,  0.0024,  0.1363, -0.0044,  0.1292, -0.0550,\n",
      "           0.1311,  0.0850, -0.0327, -0.1310,  0.0381, -0.1682,  0.0207,\n",
      "           0.0055, -0.1218, -0.0042,  0.0144, -0.0331,  0.0548, -0.0180,\n",
      "           0.0154, -0.0908,  0.0832,  0.1190, -0.0088,  0.1539,  0.0214,\n",
      "           0.1075,  0.1045,  0.0136,  0.0344, -0.0799,  0.0749, -0.1310,\n",
      "          -0.0617, -0.0801, -0.0351, -0.0260,  0.0398, -0.0346,  0.0062,\n",
      "           0.1170,  0.0104, -0.0615, -0.1685,  0.0171,  0.0688,  0.0224,\n",
      "           0.0292, -0.1058, -0.0654,  0.0825,  0.0251,  0.0043, -0.0096,\n",
      "          -0.1149, -0.0834,  0.0712, -0.0111]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4747, -0.4594, -1.2338, -0.1176,  0.4619,  0.0255,  0.6622,\n",
      "           0.0000,  0.6704,  0.0000,  1.7087, -1.0165,  0.0000, -0.2517,\n",
      "          -1.6344,  0.5130,  1.8779, -0.7565, -1.5628, -2.6441,  0.0000,\n",
      "           0.0000,  2.9304,  0.5543, -0.1166,  3.2100,  1.8372,  0.5193,\n",
      "          -2.2262, -1.2854,  0.0296,  1.0135,  0.0000,  0.8606, -0.7990,\n",
      "          -1.4656,  0.0000,  0.0000,  1.9919,  0.1027,  0.4677,  0.0000,\n",
      "           0.0000, -0.1155, -0.7133, -0.6897,  1.9284,  0.1099, -0.2870,\n",
      "          -1.8509,  1.4683,  0.4633,  0.6679, -0.2839,  0.5317,  0.2747,\n",
      "          -1.2421, -0.9517,  1.8148,  0.0000,  0.2047, -1.8180, -1.4020,\n",
      "          -0.8067,  1.1795,  0.2653, -0.1665, -0.2562, -0.0040,  0.0000,\n",
      "          -0.3253, -0.3245,  0.1476, -0.1272,  0.6588, -0.8067,  2.0662,\n",
      "           1.6804,  0.0877, -0.5468,  1.2271,  0.0876,  0.3272, -1.8367,\n",
      "          -0.0722, -1.7330, -1.4585, -0.8911,  0.6232,  0.8106, -1.2239,\n",
      "          -1.1445,  1.9856, -0.3657,  0.0000,  0.1564,  2.1424, -0.4055,\n",
      "           0.0000, -1.8398, -1.2905, -0.7221,  0.0000,  0.2381,  0.3822,\n",
      "           0.0000, -1.0695,  2.2530, -0.2628,  0.0000, -0.0532,  0.0000,\n",
      "          -0.2556, -0.2803, -1.9427,  1.1282,  1.0061, -2.4986, -0.5745,\n",
      "           0.0297, -1.6958, -0.4013, -0.3801, -0.0792, -0.5373, -1.1119,\n",
      "           1.3057,  0.1703,  0.0000,  1.3585,  2.0803, -2.6345,  0.3585,\n",
      "          -0.7229,  0.4297,  0.0594,  0.3273, -2.1034, -0.4969, -1.6781,\n",
      "          -0.6424,  0.2340, -1.1874, -1.2158, -0.6316, -0.0412,  0.4651,\n",
      "           1.7386,  1.5937,  1.4317, -1.2628, -0.5776,  0.0000,  0.0000,\n",
      "           0.3270, -0.1163,  1.3542, -0.0308, -1.9010, -1.8060, -1.4271,\n",
      "          -0.9003, -0.7053, -0.3892, -0.9823, -0.1291,  0.4064,  0.9710,\n",
      "           0.5179, -0.1472,  1.5153, -0.3733, -0.3160, -2.0089,  0.1287,\n",
      "          -0.3526, -0.8314, -0.7699, -0.0397, -0.9378,  0.7281,  1.0422,\n",
      "           0.0471,  0.4635,  0.3170, -0.1179, -0.5428, -0.6646,  0.7556,\n",
      "          -1.0645, -0.5860,  0.0000,  1.2674, -0.9269, -1.6149, -0.3332,\n",
      "          -1.1571, -1.9610, -0.0720, -0.3760,  2.6986, -0.9216, -2.6326,\n",
      "          -0.5863, -0.7170, -1.3864, -1.2541,  0.1721,  0.2182, -1.1115,\n",
      "           0.9457, -0.6920, -1.5199,  0.3626,  0.2368, -1.4274, -2.3454,\n",
      "           0.0470, -1.4805,  0.4279,  0.0133, -0.9021,  0.3007, -1.1658,\n",
      "          -1.3025, -0.1875,  1.2726,  0.0000, -2.1882, -0.0567,  1.7372,\n",
      "          -1.1753,  0.9565,  1.9991,  0.5267,  0.7905, -0.6786,  0.1046,\n",
      "          -0.6809, -2.2628,  0.1677,  0.0000, -1.0437, -0.3821, -1.0802,\n",
      "           0.0000,  1.5006, -0.5647, -1.3778,  1.2436,  0.0000,  1.7535,\n",
      "           1.9512,  0.3623,  0.4869,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0240, 0.2396, 0.0759, 0.0474, 0.1080, 0.1912, 0.0277, 0.1655, 0.0774,\n",
      "         0.0432]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3443, -0.0835,  0.0408,  ..., -0.3075,  0.0700,  0.1714],\n",
      "        [-0.1600,  0.2832, -0.1938,  ..., -0.1769,  0.0702, -0.0579],\n",
      "        [-0.1865,  0.2735, -0.1932,  ...,  0.0543,  0.2795, -0.1431],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0450,  0.1431, -0.1543,  0.1525, -0.1849, -0.0107, -0.0303,\n",
      "           0.0192, -0.0214,  0.0720,  0.1212,  0.0170, -0.0517,  0.0244,\n",
      "           0.0945, -0.1737,  0.0197, -0.0068, -0.1221, -0.0049,  0.0026,\n",
      "          -0.1052,  0.0083,  0.1210,  0.1078, -0.1385, -0.0712, -0.0953,\n",
      "           0.0099,  0.0165,  0.0220, -0.1812, -0.0877,  0.0405, -0.1029,\n",
      "           0.0201, -0.0155, -0.2103,  0.0019, -0.0148, -0.0336,  0.0459,\n",
      "           0.0090,  0.1184, -0.1078,  0.0985,  0.0262, -0.1093,  0.1845,\n",
      "           0.1367, -0.0814,  0.0322, -0.1273,  0.0948,  0.1436, -0.0371,\n",
      "           0.0989,  0.0619, -0.0292,  0.1103,  0.0953, -0.0449, -0.0124,\n",
      "          -0.1015, -0.0149,  0.0297, -0.1417,  0.0683, -0.2184,  0.1598,\n",
      "           0.1365,  0.0881, -0.0167,  0.1859, -0.0037,  0.1546,  0.1039,\n",
      "           0.0633,  0.0568, -0.1066,  0.0199, -0.1802, -0.1517,  0.1750,\n",
      "          -0.1020,  0.1974,  0.0277,  0.1273, -0.0160,  0.1120,  0.0940,\n",
      "           0.1309, -0.2232, -0.0846, -0.0656,  0.0450,  0.1779,  0.1218,\n",
      "           0.0867,  0.0487,  0.0110,  0.1052, -0.0444, -0.0505, -0.0625,\n",
      "           0.0818,  0.0695,  0.0569, -0.1307,  0.1807, -0.0501,  0.1087,\n",
      "           0.1742, -0.1471, -0.1075, -0.0139,  0.0689, -0.1101, -0.1218,\n",
      "          -0.1133,  0.0449, -0.0123, -0.1572, -0.0115, -0.1545,  0.0538,\n",
      "           0.1082, -0.0856, -0.0072,  0.1440, -0.1238,  0.0451,  0.0422,\n",
      "           0.1108,  0.0550,  0.0976,  0.2063, -0.0836, -0.1178, -0.0138,\n",
      "          -0.0523,  0.0423, -0.0298,  0.0230,  0.0998,  0.0944,  0.0341,\n",
      "          -0.0755,  0.1462,  0.1578, -0.0383, -0.0381, -0.1616, -0.0786,\n",
      "           0.0357,  0.0985,  0.1372,  0.0962, -0.1275, -0.0152, -0.0341,\n",
      "          -0.0435, -0.0298,  0.0771, -0.1428,  0.0424,  0.0064,  0.0104,\n",
      "           0.0879,  0.0260, -0.0908,  0.1064,  0.1195,  0.0833, -0.0121,\n",
      "          -0.0707,  0.0645,  0.2210,  0.0720,  0.1155, -0.0323, -0.0897,\n",
      "          -0.0277, -0.0639, -0.0489,  0.1198, -0.2142,  0.0839, -0.0237,\n",
      "          -0.0020, -0.0674, -0.0188, -0.0943, -0.1705,  0.0675, -0.0437,\n",
      "          -0.1772, -0.1003,  0.0241,  0.1284, -0.0405,  0.1242, -0.0161,\n",
      "           0.1265,  0.0774,  0.0334, -0.1757, -0.0440, -0.2265,  0.0807,\n",
      "           0.0638, -0.0573,  0.0048, -0.0710, -0.0037, -0.0202,  0.0344,\n",
      "           0.0350, -0.0678,  0.1145,  0.0793, -0.0450,  0.1123,  0.0396,\n",
      "           0.1223,  0.0346, -0.0165,  0.0996,  0.0073, -0.0023, -0.0559,\n",
      "          -0.0277, -0.0814,  0.0126, -0.0254,  0.0680,  0.0122,  0.0137,\n",
      "           0.1396,  0.0074, -0.0693, -0.1298,  0.0156,  0.0776, -0.0357,\n",
      "           0.0285, -0.1226, -0.0733,  0.0946,  0.0857, -0.0733, -0.0683,\n",
      "          -0.1255, -0.0915,  0.0716, -0.0259]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00,  0.0000e+00, -1.8077e+00,  1.3220e+00,  5.1602e-01,\n",
      "          -3.7633e-01,  1.2765e-03, -7.2330e-01,  2.1178e+00, -2.1403e-01,\n",
      "           0.0000e+00,  8.3080e-01, -1.1107e+00,  0.0000e+00,  3.1205e-01,\n",
      "           3.5182e-01, -6.8297e-01,  1.6908e-01,  8.7469e-01,  5.4557e-01,\n",
      "           0.0000e+00,  0.0000e+00, -3.6509e-02, -5.3538e-01, -9.9877e-02,\n",
      "           6.5079e-01, -1.6088e+00, -1.3623e+00, -2.1269e+00, -1.0343e+00,\n",
      "           0.0000e+00, -1.4548e+00, -2.0765e+00,  3.1566e-01, -2.8500e-01,\n",
      "          -2.0018e+00,  2.1914e-01,  9.9693e-01,  6.0111e-01,  9.5382e-01,\n",
      "          -2.2530e-01, -2.2113e+00, -7.0641e-01,  1.3961e+00,  8.9494e-02,\n",
      "          -1.1387e+00,  2.4254e-01,  7.4196e-01, -7.0983e-01, -1.3358e+00,\n",
      "           1.6089e+00,  0.0000e+00,  6.6296e-01,  1.1162e+00,  5.6739e-01,\n",
      "           3.3339e-01, -4.4979e-01,  0.0000e+00,  1.3377e-01,  6.2862e-01,\n",
      "          -7.0521e-01,  5.6377e-01, -6.9331e-01, -1.5473e+00,  2.8940e-01,\n",
      "           9.5629e-02, -1.7762e-01,  5.9462e-01, -2.1383e+00,  5.5966e-01,\n",
      "           1.8289e-01, -5.1253e-01, -3.4115e-01, -1.1321e+00, -6.4717e-01,\n",
      "           4.6094e-01,  0.0000e+00,  0.0000e+00,  5.1734e-01, -1.8689e-01,\n",
      "          -3.8495e-01,  2.1583e+00,  7.7756e-01, -8.4567e-01,  3.9774e-01,\n",
      "           4.1923e-01,  1.6044e+00, -5.6424e-01,  0.0000e+00, -1.4906e+00,\n",
      "           4.0425e-01, -3.5174e-01,  4.9412e-01, -2.3209e+00,  1.2379e+00,\n",
      "          -9.6285e-01,  0.0000e+00, -9.0768e-01,  2.3909e+00,  9.5533e-01,\n",
      "          -1.2010e+00,  5.9435e-01,  1.0665e+00, -1.7337e+00,  3.6540e-01,\n",
      "           0.0000e+00, -1.2705e+00,  0.0000e+00,  1.9688e+00,  1.4949e-01,\n",
      "          -8.3219e-01,  5.3397e-01,  8.0822e-01,  6.6420e-01, -1.0548e+00,\n",
      "           0.0000e+00, -7.0271e-01, -8.4521e-01,  0.0000e+00,  8.7978e-01,\n",
      "          -8.7680e-01,  0.0000e+00, -3.6504e-01, -1.8466e+00, -1.3007e+00,\n",
      "           1.0693e+00, -8.1153e-01,  6.4926e-01,  2.5578e-01, -1.4894e+00,\n",
      "           0.0000e+00,  3.7796e-01, -1.3459e+00,  7.2248e-01,  3.2014e+00,\n",
      "          -7.5278e-01, -3.8346e-01,  1.2822e+00,  2.2523e+00,  1.9393e-01,\n",
      "          -3.9441e-02,  3.0303e+00,  3.6266e-01, -1.8688e-01, -1.1119e+00,\n",
      "           0.0000e+00,  7.7554e-01, -7.7457e-01, -4.4933e-02, -1.3872e+00,\n",
      "           2.3359e+00,  7.6463e-01,  0.0000e+00, -2.1308e+00, -5.8156e-01,\n",
      "           7.8582e-01, -1.8620e+00, -1.3047e+00,  1.9012e-01, -3.6290e+00,\n",
      "          -1.8685e+00,  1.1506e+00, -8.5955e-01,  9.5969e-01, -1.4614e+00,\n",
      "          -2.7089e-02,  1.9744e+00,  1.1272e+00, -4.8609e-01,  0.0000e+00,\n",
      "          -2.1191e-01, -1.3225e+00, -1.6393e+00, -7.7178e-01,  0.0000e+00,\n",
      "          -1.3796e+00, -1.2625e-01,  6.0656e-01, -7.4868e-01,  2.5918e-01,\n",
      "           1.3326e+00, -2.5535e+00,  2.7788e-01, -5.8385e-01,  1.6236e+00,\n",
      "          -1.2402e+00, -1.8407e-03, -5.0184e-02,  9.0156e-01,  5.6559e-01,\n",
      "          -4.1985e-01,  0.0000e+00, -1.1611e-01,  8.0971e-01,  1.0504e+00,\n",
      "          -7.8908e-01, -1.4388e+00, -4.1610e-01, -7.5042e-01, -4.5422e-01,\n",
      "          -5.4751e-01,  7.2220e-01, -1.8536e+00,  1.3574e+00,  8.3772e-01,\n",
      "          -1.5241e+00,  0.0000e+00,  6.4797e-01,  2.0074e-01, -2.1784e+00,\n",
      "           8.3561e-01, -1.2913e+00, -1.2839e+00,  2.6119e-01, -1.5634e+00,\n",
      "           2.0757e+00,  1.3427e-01,  2.5768e+00, -3.1134e-02, -5.7941e-01,\n",
      "          -1.4284e+00,  1.9011e+00, -3.8085e-01,  1.4694e+00,  8.0494e-01,\n",
      "           3.6907e-01,  6.6988e-01, -7.0068e-01,  8.9105e-02,  1.0255e+00,\n",
      "           9.7815e-01, -1.4086e+00,  0.0000e+00,  0.0000e+00, -1.6456e+00,\n",
      "          -6.0017e-01,  8.9084e-03, -7.1106e-01,  3.7055e-01, -2.2427e-01,\n",
      "          -7.5238e-01,  5.7212e-01,  5.3059e-01, -6.6354e-01,  1.5466e+00,\n",
      "           5.7850e-01,  1.8920e+00, -8.6437e-01,  4.9337e-01, -3.8736e-01,\n",
      "           5.0025e-01, -9.7527e-01,  1.7728e+00, -1.0636e+00, -8.0791e-01,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0522, 0.0952, 0.1479, 0.0981, 0.1146, 0.2031, 0.0846, 0.0542, 0.0485,\n",
      "         0.1016]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3443, -0.0835,  0.0408,  ..., -0.3075,  0.0700,  0.1714],\n",
      "        [-0.1600,  0.2832, -0.1938,  ..., -0.1769,  0.0702, -0.0579],\n",
      "        [-0.1865,  0.2735, -0.1932,  ...,  0.0543,  0.2795, -0.1431],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7827e-02,  1.2779e-01, -1.6171e-01,  8.5735e-02, -1.7922e-01,\n",
      "          -1.3451e-02, -8.1472e-02, -5.2600e-02, -3.5291e-02,  4.3285e-02,\n",
      "           1.1744e-01,  1.0631e-02, -6.5110e-02,  3.7551e-02,  5.5720e-02,\n",
      "          -1.7752e-01, -2.0880e-02,  6.2686e-02, -1.7132e-01, -7.4168e-02,\n",
      "          -1.8911e-03, -1.4656e-01,  4.9063e-02,  6.9347e-02,  1.0140e-01,\n",
      "          -1.5225e-01, -4.4055e-02, -1.5285e-01, -4.1338e-02,  6.3965e-02,\n",
      "           7.3742e-02, -1.6109e-01, -5.1776e-02, -3.2315e-03, -1.5506e-01,\n",
      "           5.1159e-02, -2.0457e-02, -1.2408e-01,  2.3944e-02,  9.1869e-03,\n",
      "          -8.1159e-03,  7.3323e-02, -2.9812e-02,  8.1387e-02, -8.9227e-02,\n",
      "           1.3345e-01,  9.7443e-03, -6.8523e-02,  1.6276e-01,  1.4610e-01,\n",
      "          -6.8679e-02, -1.1616e-02, -1.2533e-01,  7.2790e-02,  1.3430e-01,\n",
      "          -3.2174e-02,  7.8615e-02,  5.8862e-02,  3.7105e-02,  1.3244e-01,\n",
      "           6.8991e-02, -1.8964e-02, -3.5761e-02, -7.3259e-02, -4.0434e-02,\n",
      "           1.8213e-02, -1.2052e-01,  9.2615e-02, -2.3977e-01,  1.1460e-01,\n",
      "           1.3764e-01,  1.4722e-01, -1.8012e-02,  1.7003e-01, -8.8476e-06,\n",
      "           1.7493e-01,  1.4495e-01,  1.5173e-01,  3.0380e-02, -2.2409e-02,\n",
      "           4.1474e-02, -2.0278e-01, -2.0110e-01,  1.6560e-01, -1.1148e-01,\n",
      "           2.0024e-01,  4.9243e-02,  1.2801e-01, -5.5015e-03,  1.3220e-01,\n",
      "           1.3901e-01,  5.4436e-02, -1.6311e-01, -8.5765e-02,  2.6325e-02,\n",
      "           8.8992e-02,  1.7751e-01,  1.4273e-01,  8.9360e-02,  7.7197e-02,\n",
      "           3.3131e-03,  7.2962e-02,  1.9947e-02, -9.1214e-02, -3.3068e-02,\n",
      "           2.2190e-02,  9.3205e-02,  1.0636e-01, -1.1056e-01,  2.2656e-01,\n",
      "          -7.5312e-02,  1.2817e-01,  1.3794e-01, -1.5352e-01, -8.9304e-02,\n",
      "           4.3766e-02,  1.1218e-01, -1.2502e-01, -1.2014e-01, -1.2125e-01,\n",
      "           6.2709e-02, -3.3953e-03, -1.7341e-01,  2.5812e-02, -1.7103e-01,\n",
      "           4.1528e-02,  4.8690e-02, -4.5204e-02,  8.7243e-05,  1.6294e-01,\n",
      "          -1.0606e-01,  4.9002e-02,  5.7006e-02,  1.4006e-01,  4.8405e-02,\n",
      "           5.5383e-02,  1.8236e-01, -6.5384e-02, -1.1332e-01,  2.3950e-02,\n",
      "          -3.7467e-02,  1.4232e-01, -1.1750e-01,  3.2813e-02,  9.0892e-02,\n",
      "           1.3139e-01,  7.7650e-03, -3.0413e-02,  1.6495e-01,  1.0888e-01,\n",
      "          -7.9400e-02, -3.6315e-02, -1.8743e-01, -6.2939e-02,  8.8695e-02,\n",
      "           1.5043e-01,  1.1445e-01,  1.4354e-01, -1.2748e-01, -2.1819e-02,\n",
      "          -5.5038e-02, -6.7940e-02, -8.0527e-02,  1.4152e-01, -1.2091e-01,\n",
      "           4.1535e-02,  4.4770e-02,  2.8497e-02,  7.1834e-02,  1.2818e-02,\n",
      "          -1.0648e-01,  1.0164e-01,  1.2512e-01,  1.1960e-01, -3.6383e-02,\n",
      "          -1.4450e-01,  5.4964e-02,  2.2154e-01,  8.8045e-02,  7.5814e-02,\n",
      "          -6.6874e-02, -1.1365e-01, -4.3129e-02, -4.3718e-02, -5.3783e-02,\n",
      "           1.6059e-01, -1.8088e-01,  2.6125e-02, -5.8811e-02,  7.7048e-04,\n",
      "          -4.8831e-02,  1.4118e-02, -1.7436e-01, -1.5104e-01,  3.0582e-02,\n",
      "          -1.3937e-02, -8.8500e-02, -7.9471e-02,  5.9531e-02,  1.4848e-01,\n",
      "          -1.4273e-02,  1.7083e-01, -5.9839e-02,  1.4315e-01,  9.1859e-02,\n",
      "          -2.5507e-02, -1.8226e-01, -1.5664e-02, -2.1490e-01,  4.0952e-02,\n",
      "          -2.2534e-02, -1.3286e-01, -1.0945e-04, -6.8930e-03, -4.3282e-02,\n",
      "           3.5201e-02,  3.9576e-02,  3.0857e-03, -8.3502e-02,  9.0205e-02,\n",
      "           1.3146e-01,  3.0063e-02,  1.7022e-01,  6.1924e-02,  1.0501e-01,\n",
      "           1.1563e-01, -2.2351e-02,  7.8550e-02, -5.1139e-02,  4.5416e-02,\n",
      "          -1.3170e-01, -7.4126e-02, -1.1685e-01,  3.7074e-03, -2.6938e-02,\n",
      "           6.6983e-02, -1.4277e-02,  4.7763e-02,  1.3845e-01, -4.5388e-03,\n",
      "          -7.9105e-02, -2.0781e-01,  8.2271e-02,  1.1257e-01,  9.4929e-03,\n",
      "           3.0418e-02, -1.2088e-01, -4.8905e-02,  7.8813e-02, -2.0418e-02,\n",
      "          -1.0940e-02, -3.2778e-02, -1.2709e-01, -8.9244e-02,  1.0725e-01,\n",
      "          -3.1094e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00,  3.9914e-01,  0.0000e+00, -6.8156e-01,  3.7610e-01,\n",
      "          -2.0190e-01,  0.0000e+00,  0.0000e+00, -3.5846e+00,  9.0668e-01,\n",
      "           4.2863e-01, -6.2906e-01,  2.6047e+00, -6.2976e-01, -5.4153e-01,\n",
      "          -1.5796e-01,  8.5145e-01,  1.0950e+00,  4.5516e-01,  4.3606e-01,\n",
      "          -6.3360e-01, -3.8318e-01,  1.6416e+00,  1.5112e+00,  7.5357e-01,\n",
      "          -7.5533e-02, -1.8790e-01, -7.5918e-01,  1.6538e+00,  8.6165e-01,\n",
      "           1.2320e+00,  1.2190e+00, -1.0343e+00,  0.0000e+00, -1.5346e+00,\n",
      "           1.3953e+00,  2.8092e-01, -3.7452e+00,  1.9807e-01,  0.0000e+00,\n",
      "          -4.5879e-01, -1.3984e+00,  0.0000e+00, -1.7160e+00, -1.5244e+00,\n",
      "           6.6742e-01,  0.0000e+00,  3.7060e-01, -1.3409e+00,  1.4406e-01,\n",
      "          -6.2926e-01,  2.7525e+00,  6.1037e-01,  0.0000e+00, -2.5573e-02,\n",
      "           2.0322e-01, -8.8218e-01, -1.2526e+00, -2.3676e-01, -4.2541e-01,\n",
      "           1.1008e+00,  1.4083e+00, -2.0330e-01, -5.0166e-01, -2.9644e+00,\n",
      "           5.5068e-01,  0.0000e+00, -1.2880e+00,  4.1140e-01,  5.2653e-01,\n",
      "          -1.2671e+00, -3.0261e-02,  7.0735e-01, -3.6414e+00,  3.2609e-01,\n",
      "          -1.8761e-03, -1.5988e-01,  1.0627e+00,  0.0000e+00, -1.1976e-01,\n",
      "          -1.4003e+00,  2.1314e+00, -9.2475e-01,  1.0059e+00, -2.0782e-01,\n",
      "           4.3494e-01,  1.6617e+00, -9.7441e-01, -1.0353e-01, -5.8141e-01,\n",
      "          -2.2737e+00,  0.0000e+00, -6.2230e-01, -1.1355e+00,  4.6737e-01,\n",
      "          -1.1707e+00,  3.4163e-02,  6.2914e-01,  1.7202e+00, -7.7999e-01,\n",
      "           2.6974e+00, -1.4626e+00,  1.0761e+00,  1.4540e+00,  0.0000e+00,\n",
      "           0.0000e+00,  1.2125e+00,  1.2725e-01, -1.4730e+00, -1.3234e-02,\n",
      "          -2.4867e-01,  1.3444e-01, -1.0483e+00,  1.3101e+00,  0.0000e+00,\n",
      "          -2.9897e+00, -5.6436e-02, -5.0090e-01, -1.9323e-01,  4.4500e-01,\n",
      "          -1.4665e+00,  7.0235e-01, -1.4607e+00, -7.2622e-01, -9.5851e-01,\n",
      "          -1.3090e+00,  8.9729e-01,  1.7019e-01,  1.2855e+00, -7.5231e-01,\n",
      "          -8.2350e-01,  5.3001e-01, -1.5833e+00,  9.8410e-01,  0.0000e+00,\n",
      "          -5.8957e-01,  6.5962e-01,  5.7404e-01, -1.1587e+00, -1.0102e+00,\n",
      "          -3.8875e-01,  6.7781e-01, -7.9000e-01, -1.0152e-01, -1.6859e+00,\n",
      "          -1.0109e-01, -5.4328e-01, -8.4448e-01, -7.5547e-01,  1.7753e-01,\n",
      "           1.9988e+00, -1.9971e-01, -1.9306e+00, -4.0617e-01,  4.4150e-01,\n",
      "          -1.9445e-01, -6.4354e-02, -1.2921e-01,  3.9361e-02,  5.3760e-01,\n",
      "          -2.6365e-02,  2.2065e+00,  4.8114e-01, -5.4988e-01, -5.2690e-01,\n",
      "          -8.9250e-01,  2.8166e-01,  0.0000e+00, -3.5803e-01, -4.7804e-01,\n",
      "           7.3764e-01, -3.1902e-02,  1.9960e-02, -1.0020e+00,  1.2778e+00,\n",
      "          -1.0987e+00, -9.8735e-01, -2.0771e+00,  1.9693e+00,  8.6417e-02,\n",
      "          -3.0203e-02,  3.5046e-02,  6.7139e-01,  9.7991e-01, -7.4695e-01,\n",
      "          -3.4084e-01,  0.0000e+00, -7.8426e-01,  1.2098e+00,  1.0125e+00,\n",
      "           3.0744e+00,  4.9446e-01, -1.4432e-01, -5.9432e-01,  5.6073e-01,\n",
      "           2.1653e+00, -1.1881e+00,  5.3495e-01,  1.8118e+00, -9.4707e-01,\n",
      "          -1.6624e+00, -1.0152e+00,  1.2420e+00, -1.2221e-01,  2.3200e-01,\n",
      "          -5.7525e-01, -2.2929e+00,  6.8176e-01, -1.0745e+00, -4.7126e-01,\n",
      "           2.8682e+00,  0.0000e+00, -3.4109e-01,  0.0000e+00,  3.0124e-02,\n",
      "          -6.8447e-01,  0.0000e+00,  9.6636e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.0829e+00, -4.2739e-01, -1.8439e+00, -5.0116e-01,  3.3774e-01,\n",
      "           0.0000e+00, -6.9653e-01, -6.2817e-01,  2.9223e-01,  0.0000e+00,\n",
      "          -1.1087e+00,  1.5815e+00, -6.1417e-01,  1.3097e+00, -2.9800e+00,\n",
      "           4.0357e+00,  5.8522e-01,  4.3413e-02, -1.5800e+00, -2.8727e-01,\n",
      "           7.4172e-01, -3.2484e+00, -3.0446e-01, -8.5228e-01,  1.1263e-02,\n",
      "           0.0000e+00,  2.7480e-01,  2.5253e-01,  2.6111e-01,  3.8655e-01,\n",
      "          -3.6557e-01, -1.5870e-01, -5.5401e-01, -5.2635e-02, -1.1469e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0422, 0.0607, 0.0740, 0.0765, 0.1146, 0.3184, 0.0582, 0.0664, 0.0599,\n",
      "         0.1292]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3504, -0.0319,  0.0788,  ..., -0.1159, -0.0192, -0.4808],\n",
      "        [ 0.1198,  0.1400,  0.2720,  ...,  0.1105,  0.0802,  0.0465],\n",
      "        [-0.2704, -0.2483, -0.0064,  ...,  0.3277,  0.2842,  0.1469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.3090e-01,  1.9200e-01, -2.4902e-01, -1.7097e-01, -3.0045e-03,\n",
      "          -2.4262e-01, -1.6272e-01, -2.0259e-01,  4.3711e-02, -1.7602e-01,\n",
      "           9.4781e-03, -1.2054e-01, -1.6411e-01, -2.7287e-02,  1.6627e-01,\n",
      "          -5.4360e-02,  4.1321e-02,  6.7491e-02, -3.7389e-01, -1.0241e-01,\n",
      "          -1.1217e-01, -1.4150e-01,  7.1935e-02, -2.5908e-02, -2.5709e-01,\n",
      "          -1.2407e-01, -5.8982e-02, -1.7688e-01, -3.2115e-02, -2.6142e-02,\n",
      "           1.5305e-01, -2.1986e-01, -1.8865e-01, -1.8257e-01, -3.0635e-01,\n",
      "           1.6625e-01, -2.0496e-01, -7.4905e-02, -2.7755e-01, -6.5105e-02,\n",
      "           4.5431e-02,  9.6817e-02, -2.2880e-01, -9.6652e-02,  3.1781e-01,\n",
      "           1.4872e-01,  1.4090e-01, -1.3549e-01,  1.9282e-01, -5.6859e-02,\n",
      "          -1.1676e-01, -3.2294e-01, -1.2204e-01, -3.4146e-02, -2.0041e-01,\n",
      "          -9.8348e-02, -5.5363e-02,  1.7623e-01,  2.5458e-01,  2.5987e-01,\n",
      "          -1.2350e-01, -1.3622e-01, -2.8215e-01,  1.2965e-01, -7.3064e-02,\n",
      "          -3.8033e-02,  4.0138e-02,  2.9169e-01, -2.7868e-01,  9.6522e-02,\n",
      "           1.3351e-01,  1.9012e-01, -4.4720e-02,  3.3830e-02, -3.5186e-01,\n",
      "           1.2241e-01,  3.3126e-01,  6.1946e-02, -1.2244e-01,  3.4374e-03,\n",
      "          -1.0071e-01, -1.3610e-01, -2.7476e-01, -1.0827e-03,  6.4366e-02,\n",
      "           4.6371e-02,  7.9007e-02,  9.7055e-02,  8.5171e-02, -6.9340e-03,\n",
      "           1.5346e-01,  4.8588e-02,  1.8861e-03, -1.2836e-02,  2.7100e-02,\n",
      "           2.0462e-01,  2.8140e-01,  1.4904e-01, -4.5962e-02,  2.6679e-01,\n",
      "          -1.7740e-01,  1.5705e-02,  1.2082e-01,  9.8828e-02, -8.4937e-02,\n",
      "          -2.1989e-02,  2.4193e-01,  1.2336e-01, -1.2603e-01,  1.9642e-01,\n",
      "          -1.2201e-01,  8.2502e-02,  1.2456e-02, -1.8981e-01, -3.2481e-02,\n",
      "          -1.0232e-01, -2.0039e-03, -7.8674e-02, -1.1111e-01, -2.7442e-01,\n",
      "           1.1208e-05, -1.9130e-01, -1.8133e-01,  9.6518e-02, -3.2949e-01,\n",
      "          -1.6887e-01,  5.3827e-03, -3.2975e-02,  3.7933e-01, -7.4178e-02,\n",
      "           9.8928e-02, -2.7035e-01,  1.6091e-01,  1.6736e-01, -1.1535e-01,\n",
      "          -1.0336e-02,  2.5387e-01,  1.2322e-01, -3.2746e-02,  1.1494e-01,\n",
      "          -1.9360e-01,  1.9910e-01, -1.2742e-01,  3.8046e-01, -2.4603e-03,\n",
      "           1.1387e-01,  1.7020e-02,  3.3181e-01, -1.1890e-01,  2.4134e-01,\n",
      "          -3.8021e-01,  7.1820e-04,  1.5479e-01,  2.7069e-01, -1.9199e-02,\n",
      "           2.2794e-01,  5.3449e-02,  2.5133e-01,  6.4832e-02, -5.4942e-02,\n",
      "          -8.0257e-02, -1.1711e-01, -3.2274e-01,  3.2820e-01, -1.3486e-02,\n",
      "           5.5155e-02, -3.0470e-02, -1.9463e-01,  2.3038e-01,  2.6028e-01,\n",
      "          -1.8424e-01, -6.6981e-02,  1.1398e-01, -7.7598e-03, -2.5014e-03,\n",
      "          -2.4842e-01, -1.2374e-01,  1.6630e-01,  3.9688e-01, -1.9813e-01,\n",
      "          -4.2956e-02, -2.4551e-02, -2.3423e-01, -1.5690e-01,  9.4636e-02,\n",
      "           1.0288e-01, -2.8936e-01,  1.4109e-01,  3.7260e-02, -1.5855e-01,\n",
      "           8.8352e-02,  8.9705e-02, -2.8489e-01, -1.4273e-01,  1.2008e-02,\n",
      "          -2.2227e-01,  4.6714e-03,  5.6809e-02, -2.0583e-01,  1.2672e-01,\n",
      "          -7.1585e-02,  4.2161e-02, -1.8567e-01,  1.0253e-01,  6.2505e-02,\n",
      "          -1.8846e-01, -3.0632e-02,  2.8136e-01, -6.7706e-02, -7.7580e-02,\n",
      "           5.2711e-02, -2.1842e-01, -9.8498e-02,  9.5417e-02, -8.9179e-02,\n",
      "           2.3940e-01, -1.1135e-01,  2.0130e-01, -2.5660e-01,  1.3414e-01,\n",
      "           3.3328e-01, -7.0762e-03,  1.7734e-01, -2.1555e-01,  1.7075e-01,\n",
      "           1.8843e-01,  4.0810e-02, -2.4281e-01, -3.8204e-01,  2.1977e-01,\n",
      "          -2.8735e-01, -1.5873e-01, -8.0208e-02, -2.8698e-01, -1.0763e-01,\n",
      "           2.7310e-02, -1.9636e-01, -2.3465e-02,  1.8235e-01,  9.7099e-02,\n",
      "           5.6638e-02, -2.8723e-01, -3.0838e-01, -5.1775e-02,  2.5731e-01,\n",
      "           1.2986e-02, -3.0108e-01, -4.4465e-01,  1.2850e-01,  1.7022e-02,\n",
      "           1.8115e-02, -5.0366e-02, -2.7411e-01, -1.4121e-01,  1.0677e-01,\n",
      "           9.8366e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1546, -1.4814,  1.6542, -1.0094, -1.1129,  0.4007,  0.6460,\n",
      "          -1.2222, -0.9021,  0.0942, -0.2101,  0.3159,  0.1265,  0.0000,\n",
      "           0.0000,  0.3245, -1.8654, -2.1361,  0.6080, -0.5292,  0.7696,\n",
      "           0.2830, -1.2571, -0.9728,  1.1923,  1.4260, -1.6559,  1.0545,\n",
      "           0.9844, -1.2885,  0.3066,  0.0000, -0.7688, -1.5227, -0.3682,\n",
      "           0.4839, -0.9885, -0.3508,  0.3282,  0.6280,  0.0000, -1.1764,\n",
      "           0.3726,  1.2540, -1.7951,  1.9479, -1.4982, -0.4426,  0.0000,\n",
      "           0.0000,  0.8646,  0.0357, -0.0721,  0.0000, -0.2962, -0.8049,\n",
      "          -1.8691,  0.0000,  1.5727,  2.0573, -0.8820, -0.7340,  0.0000,\n",
      "           0.0000, -0.8591,  0.1078,  0.0000, -0.6169,  0.0206,  0.4297,\n",
      "          -1.5891, -0.0279, -0.6441,  1.4260, -0.4463,  0.5576, -3.6194,\n",
      "          -0.6178, -1.4062, -0.3106,  0.8707,  1.3120,  0.8810, -0.9602,\n",
      "           0.6944,  0.6938,  0.0462, -2.9895,  0.8147, -0.0184, -1.4904,\n",
      "           0.3247, -1.2888,  2.3923,  1.8840,  0.2151, -1.1103,  1.0774,\n",
      "           1.5506, -2.1244,  0.0143, -0.6634,  0.0000, -1.8827,  0.4069,\n",
      "           1.4167, -1.9889, -0.9155,  0.4130,  1.8163, -1.4322,  0.1790,\n",
      "          -0.4972,  1.3000, -0.1464,  0.0000,  0.3374, -1.6423,  0.8515,\n",
      "          -1.2944, -1.3457, -0.0995,  0.8785,  0.5349,  0.2248,  0.8194,\n",
      "          -0.2030, -1.0700,  0.1244,  0.0000, -1.2481,  2.3284,  0.0000,\n",
      "           0.3274, -0.0092, -0.6383, -0.0638, -0.5994, -0.4516,  1.0986,\n",
      "           0.5455, -1.1799, -2.2948, -0.8855,  0.0000, -0.1877,  0.9173,\n",
      "          -0.0829,  1.5432,  0.0000,  0.3219, -1.3512,  1.8156, -1.9309,\n",
      "           0.5127, -0.3340, -0.2288, -0.7579,  0.0000, -0.0181,  0.2297,\n",
      "          -1.1457,  0.0000, -1.7645, -0.3898, -0.6919,  0.5297,  2.1353,\n",
      "          -1.6401, -2.7422,  0.0000, -2.0851, -0.0060, -1.1598, -0.9214,\n",
      "          -0.7983, -0.3062, -0.4304,  0.1177, -1.5137,  0.1503, -0.4531,\n",
      "           0.1991,  0.9699,  0.4839, -0.0759,  0.0000, -0.2138,  0.4032,\n",
      "          -1.4623,  1.0711,  0.6061,  0.5036, -0.5079,  0.7247, -0.0430,\n",
      "           1.8720,  0.0430, -0.8384, -0.2755,  0.1189,  0.0000,  0.2831,\n",
      "           0.3538,  0.0000, -0.7145,  0.0000,  2.0162, -0.7493,  1.8922,\n",
      "           2.7891,  0.1561,  1.5050,  0.1011, -0.5910, -0.0221, -0.1424,\n",
      "          -1.3819,  0.4086,  0.6373, -0.6886,  1.8592,  0.6068,  0.4730,\n",
      "           0.0293,  1.5296, -0.3649, -0.2609,  0.8420,  0.0000,  0.7766,\n",
      "          -0.5513,  0.0000,  0.0929,  2.0767,  0.5538, -1.7044,  2.7780,\n",
      "          -1.4950,  1.8028, -0.8493,  0.0000, -1.0496, -0.8533,  0.1358,\n",
      "          -1.7791,  0.0000,  1.9827,  0.5692,  0.5471, -1.7499,  0.3683,\n",
      "           0.1556,  1.5690,  0.0000,  0.4070]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0365, 0.1630, 0.0899, 0.0642, 0.1463, 0.2018, 0.0496, 0.0671, 0.1065,\n",
      "         0.0751]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3504, -0.0319,  0.0788,  ..., -0.1159, -0.0192, -0.4808],\n",
      "        [ 0.1198,  0.1400,  0.2720,  ...,  0.1105,  0.0802,  0.0465],\n",
      "        [-0.2704, -0.2483, -0.0064,  ...,  0.3277,  0.2842,  0.1469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.6385e-01,  1.4062e-01, -1.4612e-01, -1.3214e-01,  1.0811e-01,\n",
      "          -1.4292e-01, -2.2763e-01, -1.0292e-01,  4.9666e-02, -1.1604e-01,\n",
      "          -4.4519e-02, -5.8177e-02, -1.1471e-01, -4.6753e-03,  1.1406e-01,\n",
      "           2.3679e-02,  6.0230e-02,  5.1921e-02, -3.7118e-01, -1.2133e-01,\n",
      "          -1.0396e-01, -7.5074e-02,  1.5943e-02, -1.1266e-01, -2.1648e-01,\n",
      "          -1.0215e-01, -1.1642e-02, -1.2381e-01,  5.5850e-03, -7.3506e-03,\n",
      "           1.1846e-01, -1.2114e-01, -1.3152e-01, -1.0053e-01, -3.0494e-01,\n",
      "           1.1283e-01, -2.0597e-01, -4.6940e-02, -2.1639e-01, -8.7246e-02,\n",
      "           5.3732e-02,  1.0867e-01, -1.6646e-01, -1.0959e-01,  3.0648e-01,\n",
      "           9.4248e-02,  2.0054e-01, -1.2786e-02,  1.8811e-01, -5.6167e-02,\n",
      "          -8.6107e-02, -3.6779e-01, -3.1720e-02, -6.1537e-02, -2.1462e-01,\n",
      "          -1.0404e-01, -3.1908e-02,  1.7054e-01,  2.2000e-01,  2.2848e-01,\n",
      "          -8.2980e-02, -1.2535e-01, -2.1114e-01,  1.3395e-01, -5.1054e-02,\n",
      "          -3.7493e-02,  6.4594e-02,  2.1114e-01, -2.6893e-01,  5.7254e-02,\n",
      "           1.6158e-01,  2.0133e-01, -9.3788e-02, -1.1526e-03, -3.2218e-01,\n",
      "           1.2039e-01,  2.8835e-01,  7.8207e-03, -7.7852e-02, -5.2569e-02,\n",
      "          -1.1814e-01, -5.8082e-02, -1.9823e-01,  3.9283e-02,  1.0435e-01,\n",
      "           2.4037e-02,  1.0630e-01,  1.1167e-01,  2.9497e-02,  7.2510e-02,\n",
      "           7.6274e-02,  7.7709e-02, -9.3483e-03, -3.6557e-02,  6.2976e-02,\n",
      "           2.0847e-01,  2.7243e-01,  1.1754e-01, -4.6959e-02,  2.0229e-01,\n",
      "          -1.3918e-01,  6.9122e-03,  9.8404e-02,  8.4460e-02, -3.7853e-02,\n",
      "           1.1050e-03,  2.1835e-01,  4.6046e-02, -1.4368e-01,  1.6883e-01,\n",
      "          -2.0091e-01,  8.5780e-02, -3.1466e-02, -9.1057e-02,  7.5718e-02,\n",
      "          -1.1548e-01,  1.6507e-02, -8.2874e-02, -8.5807e-02, -2.7469e-01,\n",
      "           1.8890e-02, -1.6153e-01, -1.1795e-01,  9.2891e-02, -3.3534e-01,\n",
      "          -1.5076e-01,  5.0191e-02,  1.6750e-03,  3.8226e-01,  5.0885e-03,\n",
      "           4.2155e-02, -1.9812e-01,  1.2271e-01,  1.0894e-01, -1.0929e-01,\n",
      "          -8.8416e-02,  2.2563e-01,  1.1786e-01,  1.0930e-01,  1.0064e-01,\n",
      "          -1.2209e-01,  1.8322e-01, -5.1761e-02,  3.6385e-01, -7.7713e-02,\n",
      "           1.2918e-01,  8.0034e-02,  2.7682e-01, -1.6099e-01,  1.7539e-01,\n",
      "          -3.0925e-01, -2.0348e-02,  1.7959e-01,  2.6917e-01, -6.8047e-02,\n",
      "           2.0778e-01,  7.5405e-02,  2.5239e-01,  7.2819e-03,  4.3588e-02,\n",
      "          -4.4493e-02, -2.6863e-02, -2.5350e-01,  2.6017e-01, -7.8304e-02,\n",
      "          -2.1383e-02, -2.8016e-02, -1.5523e-01,  8.6069e-02,  2.0320e-01,\n",
      "          -1.0215e-01, -9.7717e-02,  3.0114e-02,  8.3031e-02,  7.3784e-02,\n",
      "          -2.1923e-01, -9.4407e-02,  1.2799e-01,  3.0950e-01, -1.7928e-01,\n",
      "          -7.9748e-03,  5.0031e-02, -2.2118e-01, -1.6403e-01,  8.3204e-02,\n",
      "           6.0184e-02, -1.6508e-01,  6.6228e-02, -6.9715e-04, -1.3441e-01,\n",
      "           1.2732e-01,  9.1725e-03, -2.1976e-01, -1.0587e-01, -5.8069e-02,\n",
      "          -1.2663e-01,  7.5559e-02,  8.8258e-02, -1.5056e-01,  6.9443e-02,\n",
      "          -6.4466e-02,  8.7209e-03, -1.5105e-01,  3.3132e-02,  1.3991e-02,\n",
      "          -1.6401e-01, -4.4566e-02,  2.0638e-01, -3.9906e-02, -5.2826e-02,\n",
      "           4.3759e-02, -1.7564e-01, -1.1874e-01,  1.0351e-02, -6.4371e-02,\n",
      "           1.3871e-01,  2.1953e-02,  2.0875e-01, -2.6399e-01,  5.6364e-02,\n",
      "           2.8424e-01,  2.6286e-02,  1.5285e-01, -1.8058e-01,  7.6932e-02,\n",
      "           2.1112e-01, -4.3947e-03, -2.2520e-01, -3.7588e-01,  1.6410e-01,\n",
      "          -2.2788e-01, -1.6917e-01, -7.0036e-02, -2.0540e-01, -7.5324e-02,\n",
      "          -5.2154e-07, -1.8076e-01, -4.1859e-02,  1.3402e-01,  9.9645e-02,\n",
      "           1.0563e-01, -2.3429e-01, -3.0000e-01, -1.6941e-02,  2.7122e-01,\n",
      "           5.4570e-03, -2.7239e-01, -4.1450e-01,  2.3487e-02, -6.0055e-02,\n",
      "          -1.6048e-02, -2.3474e-02, -2.0724e-01, -9.7449e-02,  1.2199e-01,\n",
      "           8.3071e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000,  0.7783, -1.6520, -0.1830, -0.7321,  2.5182, -1.9079,\n",
      "          -0.0323,  0.9500,  1.1946,  1.4103, -0.7569, -0.0650,  0.0645,\n",
      "           1.0464,  1.8850,  0.8700, -0.7846, -0.6403, -1.4035, -0.4984,\n",
      "          -0.3792,  1.1427,  0.2329,  0.1892, -0.6130,  1.4040, -0.1508,\n",
      "          -1.0407,  0.4962, -0.5712,  0.6009, -1.6986,  0.2318, -0.0795,\n",
      "           0.1484,  0.0000, -2.2132,  1.0517,  0.1024, -0.6919, -0.4363,\n",
      "          -1.0641,  0.8179, -0.6328, -0.6562,  1.3726,  0.9366,  1.6035,\n",
      "           0.3694, -1.0082, -1.1721, -1.1124,  1.2530, -1.9746,  1.7088,\n",
      "           0.5930, -1.8924,  0.3414, -0.2938, -0.7703,  1.8692, -0.5939,\n",
      "          -1.6815, -0.8355,  0.0000, -0.3574,  0.2899, -0.7528, -1.1646,\n",
      "           0.0000,  0.7806,  0.2706,  1.2050, -0.3983,  0.3548,  0.2296,\n",
      "          -0.1575, -0.9149,  0.2958, -0.1449,  1.2865,  0.4653,  0.0000,\n",
      "           0.7706,  0.6606,  1.0454, -0.3682, -1.2412, -1.4364,  0.0000,\n",
      "           0.0000, -0.1110,  3.2389,  0.3469,  1.0035, -0.8683,  0.7313,\n",
      "          -1.6814, -0.9243,  0.0000,  0.0286, -0.5965,  1.0585, -0.2309,\n",
      "           0.7758, -0.9058, -0.3678, -0.2786, -0.5476, -0.1379, -3.2782,\n",
      "          -0.1010, -1.8785,  1.6977,  1.6882,  2.0296, -1.6460, -0.8963,\n",
      "           2.5843, -1.3263,  1.4237, -0.6275,  0.4669,  1.3157, -0.9871,\n",
      "           0.0737, -0.9854, -0.6749,  0.2475, -1.2008,  1.1298,  1.1405,\n",
      "           0.0000,  0.3788,  0.6465,  0.0000,  0.2415,  0.3446, -1.2617,\n",
      "           0.0304,  0.8639,  0.5015,  0.9070, -1.2681, -0.6409, -0.4417,\n",
      "           0.8728, -0.0675,  0.0425, -0.0565,  0.0000,  0.1451, -0.1962,\n",
      "           0.1077, -1.6722, -0.4024,  0.2514, -2.0697,  0.4119,  1.1554,\n",
      "           0.1996,  0.9131,  0.8435,  0.4175,  1.6038,  0.1772, -1.1143,\n",
      "          -0.3224,  0.2509,  0.4447, -0.4552,  0.4447, -1.3451,  1.7354,\n",
      "           0.5173,  1.1774,  0.2896, -1.8322, -1.8661,  0.2595, -0.6474,\n",
      "          -1.1657,  0.3291, -0.7440,  0.5921, -1.2416, -1.5175, -2.3035,\n",
      "           0.1465, -1.6242, -1.3209, -0.0499,  1.2995,  0.9803, -1.4147,\n",
      "          -1.1401,  3.0139, -0.2259,  1.0330,  0.0000,  0.1193, -1.3195,\n",
      "          -1.0708,  0.0567,  1.7330,  0.5271,  1.9822, -0.9788, -1.3424,\n",
      "           1.5993, -0.4016,  2.4608,  0.0000,  0.7545,  0.2066, -0.8210,\n",
      "           0.9057, -3.5300,  0.1758, -0.7814,  0.0000, -1.4187,  0.2511,\n",
      "          -0.0647, -1.4654,  0.4268, -0.5197,  0.0464, -0.6252, -0.0712,\n",
      "           0.7485, -2.0269, -1.0491, -0.4314, -0.1123,  0.5161, -2.7968,\n",
      "          -1.4577,  0.0000,  1.0259,  0.1328,  2.7509,  1.0026,  0.5473,\n",
      "           0.0000, -1.5055,  2.2320,  1.1874, -0.0480,  0.7228,  0.1089,\n",
      "          -2.8554, -0.0139,  0.0000, -0.5807]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0335, 0.1584, 0.1009, 0.0908, 0.1109, 0.1178, 0.0738, 0.1072, 0.1185,\n",
      "         0.0882]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3504, -0.0319,  0.0788,  ..., -0.1159, -0.0192, -0.4808],\n",
      "        [ 0.1198,  0.1400,  0.2720,  ...,  0.1105,  0.0802,  0.0465],\n",
      "        [-0.2704, -0.2483, -0.0064,  ...,  0.3277,  0.2842,  0.1469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9699e-01,  9.4847e-02, -7.7844e-02, -1.0862e-01,  1.4211e-01,\n",
      "          -9.4227e-02, -2.3077e-01, -4.2651e-02,  3.6224e-02, -7.3694e-02,\n",
      "          -6.8117e-02, -1.2102e-02, -6.7575e-02, -6.0779e-03,  5.8268e-02,\n",
      "           5.4963e-02,  6.3469e-02,  2.6213e-02, -2.9111e-01, -1.2042e-01,\n",
      "          -7.0762e-02, -1.0885e-02, -2.1847e-02, -1.3954e-01, -1.7124e-01,\n",
      "          -6.1096e-02, -8.0980e-03, -7.7430e-02,  3.6549e-02,  3.2188e-04,\n",
      "           7.7433e-02, -5.6169e-02, -9.2562e-02, -3.7448e-02, -2.7099e-01,\n",
      "           8.4945e-02, -1.5359e-01, -8.8240e-03, -1.5341e-01, -9.7416e-02,\n",
      "           5.3494e-02,  9.8215e-02, -1.1828e-01, -1.0796e-01,  2.7997e-01,\n",
      "           4.7582e-02,  2.1797e-01,  4.7892e-02,  1.5099e-01, -4.5800e-02,\n",
      "          -5.7720e-02, -3.4867e-01,  1.7302e-02, -5.8532e-02, -1.8327e-01,\n",
      "          -1.2584e-01, -2.1203e-02,  1.3900e-01,  1.7908e-01,  1.7138e-01,\n",
      "          -6.7642e-02, -1.0017e-01, -1.4041e-01,  1.0351e-01, -1.5136e-02,\n",
      "          -2.8812e-02,  8.9130e-02,  1.6027e-01, -2.3162e-01,  2.1578e-02,\n",
      "           1.5672e-01,  1.5242e-01, -8.7604e-02, -3.1951e-02, -2.5774e-01,\n",
      "           8.8853e-02,  2.3111e-01, -1.9850e-02, -6.0379e-02, -8.2651e-02,\n",
      "          -9.5366e-02,  9.8008e-04, -1.1910e-01,  3.8775e-02,  1.1824e-01,\n",
      "          -8.4147e-03,  9.0161e-02,  1.0716e-01, -2.2881e-02,  9.1494e-02,\n",
      "           3.4946e-02,  9.0362e-02,  6.3421e-03, -3.6157e-02,  7.7806e-02,\n",
      "           1.7954e-01,  2.2399e-01,  6.0827e-02, -3.8807e-02,  1.3107e-01,\n",
      "          -9.4006e-02, -2.7768e-02,  5.6986e-02,  6.9866e-02, -1.4961e-02,\n",
      "           2.2274e-02,  1.7570e-01, -1.8709e-02, -1.3095e-01,  1.2443e-01,\n",
      "          -2.1989e-01,  8.2224e-02, -4.7550e-02, -2.9733e-02,  1.2679e-01,\n",
      "          -1.1741e-01,  1.4279e-02, -5.4393e-02, -5.4859e-02, -2.3674e-01,\n",
      "           4.7823e-03, -1.2529e-01, -4.7148e-02,  7.4384e-02, -2.9546e-01,\n",
      "          -1.2394e-01,  4.2992e-02,  1.8174e-02,  3.3062e-01,  3.7134e-02,\n",
      "           4.0626e-03, -1.2512e-01,  7.0608e-02,  5.3826e-02, -8.5311e-02,\n",
      "          -1.0658e-01,  1.6301e-01,  8.8909e-02,  1.7344e-01,  6.7450e-02,\n",
      "          -7.8216e-02,  1.2697e-01, -1.3575e-02,  3.1353e-01, -1.0590e-01,\n",
      "           1.3282e-01,  7.6013e-02,  2.1368e-01, -1.7638e-01,  1.1716e-01,\n",
      "          -2.0937e-01, -3.5705e-02,  1.7658e-01,  2.1491e-01, -1.1155e-01,\n",
      "           1.3291e-01,  8.5290e-02,  2.1924e-01, -2.5695e-02,  8.5203e-02,\n",
      "          -1.2070e-02,  2.0045e-02, -1.7617e-01,  1.6687e-01, -8.0416e-02,\n",
      "          -5.5422e-02, -7.8889e-03, -1.1534e-01,  3.7739e-02,  1.4249e-01,\n",
      "          -4.3372e-02, -1.0380e-01, -2.5557e-02,  8.8718e-02,  1.0295e-01,\n",
      "          -1.7201e-01, -7.1668e-02,  9.3205e-02,  2.3609e-01, -1.4568e-01,\n",
      "           3.3745e-02,  8.3851e-02, -1.7116e-01, -1.4057e-01,  4.4569e-02,\n",
      "           2.2789e-02, -9.7580e-02,  1.9993e-02, -2.1304e-02, -8.2074e-02,\n",
      "           1.2770e-01, -2.3383e-02, -1.4483e-01, -7.7244e-02, -7.8564e-02,\n",
      "          -6.8904e-02,  8.8697e-02,  8.4632e-02, -1.0293e-01,  3.1129e-02,\n",
      "          -4.9056e-02, -2.0425e-02, -1.2455e-01, -2.5248e-02, -1.0187e-02,\n",
      "          -1.3379e-01, -3.9985e-02,  1.3224e-01, -1.8572e-02, -2.1428e-02,\n",
      "           3.4364e-02, -1.2277e-01, -1.1270e-01, -3.2258e-02, -4.5525e-02,\n",
      "           8.6100e-02,  6.4261e-02,  1.7548e-01, -2.0820e-01,  1.4356e-02,\n",
      "           2.3352e-01,  4.8945e-02,  9.9841e-02, -1.4687e-01,  3.0599e-02,\n",
      "           1.7034e-01, -3.4242e-02, -1.7345e-01, -2.9264e-01,  1.2009e-01,\n",
      "          -1.6670e-01, -1.4293e-01, -4.2974e-02, -1.3512e-01, -5.0493e-02,\n",
      "           6.3153e-03, -1.3615e-01, -3.8567e-02,  7.2942e-02,  7.3595e-02,\n",
      "           1.2408e-01, -1.8077e-01, -2.4519e-01, -1.8328e-02,  2.3506e-01,\n",
      "           9.5223e-03, -2.2638e-01, -3.5717e-01, -1.8874e-02, -7.2791e-02,\n",
      "          -4.0037e-02, -2.1873e-02, -1.5148e-01, -5.1067e-02,  1.0585e-01,\n",
      "           7.5529e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1419, -1.3596, -0.6634,  1.6814,  2.4830,  0.0000,  1.3996,\n",
      "          -0.9368, -0.7144, -0.2962, -0.5818, -0.2200,  2.5561, -1.0552,\n",
      "           2.1830,  0.0000,  0.3038, -1.1562,  0.9578,  0.2219, -1.5415,\n",
      "          -1.1546,  0.9478, -1.8147, -0.3956,  1.5212,  1.7256, -0.8835,\n",
      "          -0.2970, -0.3666,  0.0000, -1.3883, -0.6738,  0.0891,  1.0594,\n",
      "           0.6829, -1.4604,  0.0000,  0.1806,  1.9588,  0.3991, -0.1961,\n",
      "           1.3082,  0.8320,  1.4219,  0.3937,  0.3495,  0.1076, -1.1252,\n",
      "          -0.8445,  0.6895,  0.9796, -2.5885,  1.2124,  1.6781,  0.2128,\n",
      "           0.0177,  1.0910,  0.0000,  1.4963, -0.8581, -1.2764, -2.4446,\n",
      "          -0.1825, -0.8672, -0.1022,  0.0000, -1.1792,  1.1063, -0.3298,\n",
      "          -0.4427,  0.4201, -0.4835, -1.3156,  1.7190,  1.4826, -0.6504,\n",
      "           2.5034,  0.0000, -0.8126,  0.8009,  0.3516, -0.0582,  0.0000,\n",
      "          -0.6170, -2.7816,  2.1726, -0.0544, -1.7540,  0.2434, -0.1546,\n",
      "          -0.5268, -1.8710,  1.9172,  1.0335, -0.8282,  0.0980, -0.2966,\n",
      "          -0.1611, -1.0472, -1.1855,  0.0130, -0.0582, -0.2456,  0.1054,\n",
      "          -0.9797,  2.6332,  0.0000,  0.4400,  0.1307,  0.2424,  0.5216,\n",
      "           0.0000,  0.0000, -0.0771, -1.0748,  1.5986, -0.2631, -0.7200,\n",
      "          -0.2745, -0.2474,  1.7814,  0.6796, -0.6457,  0.0189,  0.6758,\n",
      "          -1.3009, -0.1074, -1.6209, -0.9824,  0.0000, -1.1602, -1.4886,\n",
      "          -0.5447, -2.3545, -0.8533, -3.4683, -0.9831,  1.4212, -1.0900,\n",
      "           0.5350,  1.8844,  0.4641, -0.8877,  1.3428, -0.8940,  2.4421,\n",
      "          -0.3703, -1.5687, -0.7333, -0.8484, -0.5475, -2.5834,  0.9101,\n",
      "           0.0000, -0.7973, -0.0163,  0.9334, -0.4493, -1.7377,  0.6848,\n",
      "           1.1302,  0.9740,  0.2741,  0.4456, -2.8163,  0.1089, -1.1758,\n",
      "          -0.1289,  0.5757, -0.1558, -1.2322, -0.6540, -0.1765, -0.1688,\n",
      "          -0.5095, -0.7969, -0.1947,  0.9826,  0.0000,  1.1967, -0.1845,\n",
      "          -0.7671,  0.3473, -2.4943, -1.8722,  0.9572, -0.9258,  0.0000,\n",
      "           0.5710,  0.1742,  2.1622, -0.6164,  1.3763, -0.0819, -0.5877,\n",
      "           1.7685,  0.3900, -0.1345,  0.9390,  0.0000,  0.0000, -1.6428,\n",
      "           1.4438,  0.7060,  0.1421,  0.0916, -0.6063, -1.1036, -1.2552,\n",
      "           0.0000, -1.8651,  2.1895, -1.7825,  0.7082, -0.9349, -1.7241,\n",
      "          -1.9958, -1.1669, -0.4401,  0.0000, -0.7354, -1.3407, -0.3619,\n",
      "           0.0958,  0.3168, -1.1971, -1.2608, -1.4066,  0.3964, -0.3269,\n",
      "          -1.5161,  1.1266, -0.6660, -0.0694,  0.8231, -1.2880, -0.6049,\n",
      "          -0.6456,  0.5977,  0.0849,  0.8709,  0.4314,  0.0000,  0.0607,\n",
      "           0.5829,  0.0000,  1.2979, -0.4212, -1.1536, -1.6780, -1.5688,\n",
      "          -1.2526, -0.0130,  0.3589, -0.4895]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0604, 0.1311, 0.1868, 0.0382, 0.1343, 0.2189, 0.0681, 0.0488, 0.0835,\n",
      "         0.0300]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3504, -0.0319,  0.0788,  ..., -0.1159, -0.0192, -0.4808],\n",
      "        [ 0.1198,  0.1400,  0.2720,  ...,  0.1105,  0.0802,  0.0465],\n",
      "        [-0.2704, -0.2483, -0.0064,  ...,  0.3277,  0.2842,  0.1469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2329,  0.1126, -0.1609, -0.1336,  0.0969, -0.1646, -0.2526,\n",
      "          -0.0982,  0.0429, -0.1271, -0.0629, -0.0763, -0.1233, -0.0418,\n",
      "           0.0746,  0.0379,  0.1190,  0.0821, -0.3628, -0.1266, -0.0771,\n",
      "          -0.0784,  0.0380, -0.1213, -0.2297, -0.1088, -0.0201, -0.1355,\n",
      "           0.0171, -0.0131,  0.1189, -0.1382, -0.1211, -0.1210, -0.3412,\n",
      "           0.1260, -0.1874, -0.0441, -0.2189, -0.0954,  0.0360,  0.0936,\n",
      "          -0.1915, -0.1095,  0.3549,  0.1042,  0.2196, -0.0091,  0.2239,\n",
      "          -0.0431, -0.0915, -0.4024, -0.0447, -0.0725, -0.2104, -0.1592,\n",
      "          -0.0352,  0.1849,  0.2544,  0.2534, -0.1114, -0.1661, -0.2104,\n",
      "           0.1436, -0.0507, -0.0039,  0.0755,  0.2662, -0.3126,  0.0675,\n",
      "           0.1749,  0.2421, -0.0903, -0.0169, -0.3337,  0.1482,  0.2975,\n",
      "           0.0059, -0.0797, -0.0650, -0.1403, -0.0654, -0.1850,  0.0634,\n",
      "           0.1305,  0.0307,  0.1315,  0.1388,  0.0365,  0.0700,  0.0690,\n",
      "           0.1291,  0.0036, -0.0654,  0.0594,  0.2200,  0.2971,  0.1223,\n",
      "          -0.0450,  0.2388, -0.1388,  0.0211,  0.0871,  0.1264, -0.0543,\n",
      "           0.0311,  0.2572,  0.0517, -0.1836,  0.1844, -0.2257,  0.0983,\n",
      "          -0.0388, -0.1030,  0.0917, -0.1395,  0.0017, -0.0811, -0.1031,\n",
      "          -0.3124,  0.0140, -0.1857, -0.1120,  0.1104, -0.3743, -0.1653,\n",
      "           0.0439, -0.0407,  0.4060,  0.0303,  0.0350, -0.1913,  0.1626,\n",
      "           0.1232, -0.0939, -0.0806,  0.2681,  0.1132,  0.1025,  0.1068,\n",
      "          -0.1309,  0.1674, -0.0686,  0.3983, -0.1031,  0.1313,  0.0733,\n",
      "           0.2797, -0.1817,  0.1853, -0.2784, -0.0227,  0.1944,  0.2717,\n",
      "          -0.1051,  0.2272,  0.0802,  0.2771, -0.0154,  0.0503, -0.0439,\n",
      "           0.0120, -0.2258,  0.3079, -0.0956, -0.0237, -0.0353, -0.1585,\n",
      "           0.1146,  0.1916, -0.0808, -0.0663,  0.0016,  0.0960,  0.0908,\n",
      "          -0.2233, -0.0782,  0.1307,  0.3460, -0.1786,  0.0065,  0.0533,\n",
      "          -0.2202, -0.1546,  0.0865,  0.0683, -0.1733,  0.0406,  0.0038,\n",
      "          -0.1184,  0.1365,  0.0031, -0.2522, -0.1442, -0.0824, -0.1026,\n",
      "           0.0506,  0.0780, -0.1261,  0.0759, -0.0606,  0.0135, -0.1771,\n",
      "           0.0168, -0.0133, -0.2199, -0.0625,  0.1967, -0.0278, -0.0409,\n",
      "           0.0504, -0.1736, -0.1188, -0.0026, -0.0615,  0.1594,  0.0116,\n",
      "           0.2315, -0.2742,  0.0378,  0.3170,  0.0286,  0.1444, -0.2269,\n",
      "           0.0529,  0.2372,  0.0069, -0.2422, -0.4439,  0.1986, -0.2238,\n",
      "          -0.1654, -0.0808, -0.1891, -0.0683, -0.0102, -0.2278, -0.0631,\n",
      "           0.1562,  0.1281,  0.1303, -0.2908, -0.2994, -0.0252,  0.2685,\n",
      "           0.0408, -0.2762, -0.4704,  0.0011, -0.0397, -0.0188, -0.0292,\n",
      "          -0.2308, -0.0705,  0.1403,  0.0766]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.1731e+00, -3.2099e-01, -6.8874e-01,  1.1027e+00, -2.3846e-03,\n",
      "           7.3380e-01,  4.3181e-01,  8.3074e-01,  1.7067e+00, -6.1794e-01,\n",
      "          -1.2747e+00,  0.0000e+00, -6.8291e-01,  1.1534e-01, -1.1745e+00,\n",
      "          -9.8583e-02,  5.3097e-01,  1.9231e-02, -4.2941e-01, -1.3713e+00,\n",
      "           4.3768e-01,  0.0000e+00, -2.2140e+00,  2.5625e+00, -2.0554e+00,\n",
      "          -1.6408e+00, -2.0456e+00, -5.0511e-01,  1.0249e+00,  1.8199e+00,\n",
      "           3.7584e-01,  1.0435e-02, -9.6332e-01, -3.0763e-01, -7.7655e-01,\n",
      "           1.1523e+00,  6.2990e-01,  1.7062e+00, -5.5513e-01, -3.2805e-01,\n",
      "          -4.0026e-01, -5.7359e-01, -2.4280e-01, -7.3030e-01, -2.6322e+00,\n",
      "          -7.3630e-02,  7.7265e-01,  6.5576e-01, -1.7930e-02,  0.0000e+00,\n",
      "           1.5192e+00,  8.7895e-01, -3.6125e-01, -3.3428e+00, -4.2882e-01,\n",
      "           1.7649e+00, -6.1901e-01,  0.0000e+00,  5.8325e-03, -1.0135e-01,\n",
      "          -2.5046e+00, -2.4596e-01,  2.1582e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.8648e-01, -8.2392e-01, -3.9015e-01,  5.1551e-01, -4.6055e-01,\n",
      "           0.0000e+00, -5.1100e-01, -3.7181e-01,  7.3346e-03,  6.9299e-01,\n",
      "           2.5765e+00,  8.2742e-01, -3.9467e-01,  0.0000e+00,  1.4832e+00,\n",
      "          -1.2261e+00, -6.1778e-01, -3.1336e-02, -1.6632e-01, -1.5660e+00,\n",
      "           8.8725e-01, -1.6070e+00,  1.5803e+00, -1.4412e+00, -7.4456e-02,\n",
      "           7.8599e-02,  7.8178e-01,  1.2661e+00, -7.4759e-02, -1.2816e-01,\n",
      "          -1.5031e+00, -1.7240e-01,  0.0000e+00,  0.0000e+00, -1.4437e+00,\n",
      "           9.9773e-01,  2.6375e-01,  3.0566e-01, -2.7275e-01, -1.7048e+00,\n",
      "           3.8399e-01,  8.9048e-01,  1.0546e+00,  6.1772e-01,  3.3810e-01,\n",
      "           0.0000e+00,  1.1777e+00,  0.0000e+00,  2.6827e-01,  7.1479e-01,\n",
      "          -1.4459e+00,  1.8224e+00,  0.0000e+00, -3.5723e-02, -1.0668e+00,\n",
      "           1.1309e+00, -1.9835e-01, -1.4275e+00,  1.1182e+00, -1.0629e+00,\n",
      "          -9.1590e-02,  1.9998e-01,  1.9056e+00,  1.3281e+00, -1.0828e-01,\n",
      "           2.1038e+00,  0.0000e+00, -2.9708e-01,  1.5353e-01, -1.3193e+00,\n",
      "          -1.8141e-01, -1.9197e-01, -2.8025e-01, -2.7563e-01,  0.0000e+00,\n",
      "          -1.3127e+00,  2.0225e-01,  7.4668e-01, -9.7034e-01,  5.2753e-01,\n",
      "           7.2732e-01,  7.7158e-01,  1.4787e+00,  5.9938e-02, -8.3052e-01,\n",
      "           1.2980e+00, -8.3179e-01, -1.3273e-02, -8.8220e-01,  1.8713e+00,\n",
      "           2.2473e+00, -6.7808e-01,  2.4066e+00, -5.3448e-02, -1.1550e+00,\n",
      "          -3.7987e-01,  4.2351e-02,  2.0799e+00, -1.0098e+00, -3.2600e-02,\n",
      "          -5.5601e-01, -9.0472e-01, -5.1666e-01, -7.1913e-02, -1.6922e-01,\n",
      "          -4.9275e-02,  8.7244e-01, -1.2456e+00, -1.3420e+00,  3.5163e-02,\n",
      "          -1.3458e-01,  0.0000e+00,  3.8040e-01, -2.8313e-01,  1.8447e+00,\n",
      "           5.3617e-01,  6.9456e-01, -1.1875e+00,  3.2849e-01,  9.1472e-01,\n",
      "           6.3837e-02,  0.0000e+00,  3.9608e-01,  5.8899e-01,  2.5724e+00,\n",
      "          -4.4764e-01,  5.2640e-02,  3.3479e-01,  1.2619e+00,  3.0768e-01,\n",
      "           0.0000e+00,  0.0000e+00,  2.4146e+00,  9.8428e-01,  9.5553e-01,\n",
      "           0.0000e+00,  5.8745e-01,  1.5029e+00,  1.8438e-01, -1.6333e+00,\n",
      "          -1.0933e-02,  0.0000e+00, -1.0135e+00,  7.6701e-01, -3.7450e-02,\n",
      "          -2.0626e+00, -1.6474e+00,  8.4228e-01,  6.3811e-01,  5.8154e-01,\n",
      "           3.4876e-01, -7.9030e-02,  1.3085e+00,  7.0661e-01,  1.0862e+00,\n",
      "           2.9898e-01,  7.6966e-01, -5.2282e-01,  1.6159e+00, -4.3737e-01,\n",
      "           6.6338e-01, -7.8559e-01,  8.5080e-01,  2.5895e-01,  6.7809e-01,\n",
      "          -8.1723e-01,  3.2181e-02, -3.6834e-01, -1.0266e+00,  2.6968e-01,\n",
      "          -9.7370e-01, -1.1804e+00,  7.0589e-01,  1.2472e+00,  1.5026e+00,\n",
      "           4.1872e-01,  5.5064e-01,  2.8505e-01, -1.7449e-01, -7.9478e-01,\n",
      "           2.0838e+00, -3.4217e-01, -8.9536e-01, -1.5286e+00,  2.3831e-01,\n",
      "          -8.6981e-01, -2.4097e-01, -4.9738e-01,  2.8613e-01,  2.0715e+00,\n",
      "          -2.1983e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0476, 0.0985, 0.1106, 0.1222, 0.0791, 0.1208, 0.1511, 0.0800, 0.1385,\n",
      "         0.0516]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3504, -0.0319,  0.0788,  ..., -0.1159, -0.0192, -0.4808],\n",
      "        [ 0.1198,  0.1400,  0.2720,  ...,  0.1105,  0.0802,  0.0465],\n",
      "        [-0.2704, -0.2483, -0.0064,  ...,  0.3277,  0.2842,  0.1469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1959,  0.0893, -0.0874, -0.1241,  0.1174, -0.1179, -0.2180,\n",
      "          -0.0550,  0.0191, -0.0816, -0.0613, -0.0123, -0.0629, -0.0199,\n",
      "           0.0491,  0.0400,  0.0585,  0.0215, -0.2466, -0.1190, -0.0489,\n",
      "           0.0004, -0.0207, -0.1234, -0.1712, -0.0363, -0.0299, -0.0756,\n",
      "           0.0453, -0.0008,  0.0736, -0.0672, -0.0981, -0.0410, -0.2671,\n",
      "           0.0953, -0.1151,  0.0058, -0.1408, -0.0977,  0.0532,  0.0910,\n",
      "          -0.1260, -0.1115,  0.2828,  0.0460,  0.2153,  0.0318,  0.1364,\n",
      "          -0.0435, -0.0507, -0.3327,  0.0039, -0.0466, -0.1633, -0.1508,\n",
      "          -0.0300,  0.1263,  0.1793,  0.1512, -0.0822, -0.0974, -0.1379,\n",
      "           0.0878,  0.0011, -0.0218,  0.0972,  0.1819, -0.2285,  0.0237,\n",
      "           0.1450,  0.1217, -0.0538, -0.0453, -0.2397,  0.0795,  0.2245,\n",
      "          -0.0130, -0.0768, -0.0773, -0.0702,  0.0129, -0.1078,  0.0218,\n",
      "           0.1159, -0.0229,  0.0698,  0.1059, -0.0316,  0.0684,  0.0491,\n",
      "           0.0949,  0.0223, -0.0255,  0.0722,  0.1663,  0.2071,  0.0358,\n",
      "          -0.0285,  0.1188, -0.0778, -0.0493,  0.0346,  0.0759, -0.0176,\n",
      "           0.0312,  0.1648, -0.0232, -0.1220,  0.1165, -0.2090,  0.0862,\n",
      "          -0.0441, -0.0414,  0.1147, -0.1173,  0.0046, -0.0305, -0.0523,\n",
      "          -0.2227, -0.0197, -0.1234, -0.0314,  0.0689, -0.2825, -0.1192,\n",
      "           0.0099,  0.0092,  0.3103,  0.0195,  0.0058, -0.1120,  0.0515,\n",
      "           0.0512, -0.0668, -0.0852,  0.1364,  0.0799,  0.1594,  0.0535,\n",
      "          -0.0950,  0.0996, -0.0330,  0.3002, -0.0960,  0.1361,  0.0408,\n",
      "           0.2106, -0.1743,  0.1187, -0.1839, -0.0364,  0.1696,  0.1813,\n",
      "          -0.1252,  0.0953,  0.0875,  0.2090, -0.0268,  0.0671, -0.0112,\n",
      "           0.0117, -0.1668,  0.1454, -0.0573, -0.0412,  0.0069, -0.1100,\n",
      "           0.0810,  0.1279, -0.0457, -0.0921, -0.0230,  0.0505,  0.0925,\n",
      "          -0.1647, -0.0694,  0.0921,  0.2460, -0.1366,  0.0503,  0.0752,\n",
      "          -0.1492, -0.1271,  0.0262,  0.0146, -0.1182,  0.0222, -0.0257,\n",
      "          -0.0549,  0.1158, -0.0048, -0.1339, -0.0812, -0.0654, -0.0822,\n",
      "           0.0627,  0.0697, -0.1008,  0.0346, -0.0420, -0.0265, -0.1312,\n",
      "          -0.0367, -0.0110, -0.1373, -0.0334,  0.1228, -0.0181, -0.0093,\n",
      "           0.0285, -0.1110, -0.1042, -0.0197, -0.0466,  0.1070,  0.0271,\n",
      "           0.1581, -0.1731,  0.0190,  0.2389,  0.0553,  0.0792, -0.1530,\n",
      "           0.0458,  0.1338, -0.0389, -0.1548, -0.2535,  0.1231, -0.1552,\n",
      "          -0.1254, -0.0354, -0.1277, -0.0509,  0.0271, -0.1229, -0.0258,\n",
      "           0.0604,  0.0587,  0.1209, -0.1873, -0.2188, -0.0347,  0.2103,\n",
      "           0.0182, -0.2170, -0.3571,  0.0067, -0.0482, -0.0416, -0.0369,\n",
      "          -0.1539, -0.0450,  0.0937,  0.0768]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7260e-01, -4.3083e-01,  3.1517e-01, -1.0850e+00, -1.1728e+00,\n",
      "           7.4161e-01, -1.9146e+00,  1.3514e+00,  1.9018e-01,  0.0000e+00,\n",
      "           1.9036e+00,  6.0255e-01,  2.2915e-01, -9.1652e-01, -3.1834e+00,\n",
      "          -6.8289e-02,  0.0000e+00, -9.4354e-01,  1.3604e+00, -1.4356e+00,\n",
      "          -1.4049e-01,  0.0000e+00, -1.1198e+00, -2.5957e+00, -7.5856e-02,\n",
      "           1.3917e+00, -6.1979e-01,  1.9979e+00,  1.2773e-01,  5.5489e-01,\n",
      "           9.1575e-01, -3.7041e-03,  2.2230e-01,  2.0168e+00, -6.3636e-02,\n",
      "          -1.4086e+00,  0.0000e+00, -8.1750e-01,  3.1523e-01,  8.5918e-02,\n",
      "           8.6320e-01, -8.9932e-01,  0.0000e+00, -1.5639e+00,  1.9447e+00,\n",
      "          -3.0036e-01,  7.0612e-01, -6.0211e-01, -1.0210e+00,  1.1171e+00,\n",
      "          -1.3231e+00,  2.6779e+00,  6.6692e-01, -8.4700e-01,  2.2795e-01,\n",
      "          -3.1000e-01, -1.4340e+00, -9.6305e-02,  1.2760e+00,  2.1820e+00,\n",
      "          -1.0065e+00,  3.5945e-02, -2.8019e-01,  2.6582e-01, -6.3142e-02,\n",
      "           3.9367e-01,  5.7809e-01,  1.1653e+00,  0.0000e+00, -1.4154e+00,\n",
      "           4.2745e-01,  2.9640e-01, -3.1136e-02, -7.9815e-01, -2.1428e-01,\n",
      "           1.3944e-01,  5.2592e-01,  1.3989e+00,  1.0274e+00, -7.9398e-01,\n",
      "           7.5832e-01, -1.0050e+00,  7.5814e-01,  1.0588e+00, -1.2154e+00,\n",
      "          -1.1317e-01, -1.1081e+00,  5.4871e-01, -9.4489e-01, -1.9014e+00,\n",
      "           5.2913e-01,  9.8732e-01,  1.7020e+00,  9.4407e-01,  6.0799e-01,\n",
      "          -1.5908e-02,  0.0000e+00, -1.1760e+00,  1.3722e+00,  2.4481e+00,\n",
      "           2.4348e-01,  4.4356e-02, -4.6663e-01, -9.8953e-01,  1.6408e+00,\n",
      "          -1.0239e+00,  3.0297e+00,  6.2050e-01, -1.0201e-01, -1.2355e+00,\n",
      "           1.8999e-01, -5.0322e-01, -5.7099e-01,  7.1248e-01, -7.8074e-01,\n",
      "           6.3258e-01,  4.0380e-01,  2.2366e-01, -2.3272e+00,  0.0000e+00,\n",
      "          -8.1461e-01, -1.4118e+00, -1.8384e+00,  6.0321e-01, -9.5692e-01,\n",
      "           0.0000e+00,  0.0000e+00,  2.1506e+00,  1.3965e+00, -2.0881e+00,\n",
      "          -9.2626e-01,  4.4983e-01, -1.1680e+00,  4.2543e-01, -4.6843e-01,\n",
      "          -7.4600e-01, -1.0650e+00, -9.7546e-01, -1.9443e-02,  2.3979e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4043e-01, -6.7009e-01,\n",
      "           0.0000e+00,  7.5974e-01,  4.2289e-01, -1.0339e+00,  0.0000e+00,\n",
      "           1.5601e+00,  5.8683e-01, -3.3848e-01,  6.5773e-01,  1.8414e+00,\n",
      "          -2.5271e-01, -2.1786e-01,  6.2391e-01, -2.3635e+00,  1.0560e+00,\n",
      "           3.0275e-01,  0.0000e+00,  0.0000e+00, -1.2122e+00, -2.2023e-02,\n",
      "           1.6825e+00,  1.8526e+00,  2.7148e-01, -1.2704e+00, -7.1313e-01,\n",
      "          -1.2243e+00,  0.0000e+00, -2.5910e+00,  5.0587e-01, -3.0604e+00,\n",
      "          -2.8739e-01,  4.9771e-01,  8.2970e-01,  0.0000e+00, -7.9304e-01,\n",
      "           2.7231e-01,  2.3399e+00,  1.0580e+00,  8.3880e-01, -4.0256e-01,\n",
      "           7.2780e-01,  5.9868e-01,  3.5975e-01,  0.0000e+00, -1.8309e+00,\n",
      "           1.3637e+00,  2.1597e+00,  3.3605e-01, -1.0156e+00, -1.1728e+00,\n",
      "          -2.2159e+00,  1.6675e+00,  2.1531e+00,  0.0000e+00,  2.3837e+00,\n",
      "           3.2531e-02, -5.0166e-01, -1.2770e+00, -5.4289e-01, -4.0761e-01,\n",
      "          -1.4475e+00,  9.5338e-01, -8.5200e-01,  8.2977e-01, -1.5604e+00,\n",
      "           6.3707e-01,  6.7572e-01,  2.3984e+00,  5.5291e-02,  1.8937e+00,\n",
      "           1.3088e+00,  5.8030e-01, -2.3177e+00,  1.5503e+00, -2.2253e-01,\n",
      "          -2.2725e-01,  1.7340e+00,  2.7664e-01, -1.5523e+00,  9.2283e-01,\n",
      "          -1.2244e+00, -8.4873e-01, -1.8023e+00, -6.8233e-04,  3.7318e-01,\n",
      "          -1.5738e+00, -1.2380e-01,  9.6635e-01, -1.7371e+00,  1.6946e+00,\n",
      "          -1.4405e+00,  6.3405e-01,  0.0000e+00,  9.8028e-01, -1.7167e+00,\n",
      "           1.5614e+00, -2.7273e-01, -2.5973e+00,  1.2391e+00, -1.2283e+00,\n",
      "           1.8861e+00, -5.0840e-01,  5.4288e-01, -2.6131e-01, -1.0223e+00,\n",
      "           0.0000e+00,  3.1115e-01, -5.1136e-02, -2.2877e-01, -1.6128e+00,\n",
      "           1.8069e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0401, 0.1268, 0.1650, 0.0813, 0.1540, 0.1214, 0.1059, 0.0625, 0.0909,\n",
      "         0.0521]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3504, -0.0319,  0.0788,  ..., -0.1159, -0.0192, -0.4808],\n",
      "        [ 0.1198,  0.1400,  0.2720,  ...,  0.1105,  0.0802,  0.0465],\n",
      "        [-0.2704, -0.2483, -0.0064,  ...,  0.3277,  0.2842,  0.1469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9762e-01,  7.8842e-02, -1.0118e-01, -1.4501e-01,  1.5502e-01,\n",
      "          -1.3271e-01, -2.7648e-01, -5.5543e-02,  2.2341e-02, -1.1069e-01,\n",
      "          -8.4205e-02, -1.3514e-02, -9.3570e-02, -1.6734e-02,  3.9169e-02,\n",
      "           5.0952e-02,  7.6740e-02,  5.9488e-02, -3.1043e-01, -1.4133e-01,\n",
      "          -4.6854e-02, -1.9413e-02,  1.2666e-02, -1.6821e-01, -1.8786e-01,\n",
      "          -3.1779e-02,  3.5586e-03, -1.0002e-01,  6.0020e-02,  1.3509e-02,\n",
      "           9.9089e-02, -7.6845e-02, -9.6014e-02, -7.1492e-02, -3.2157e-01,\n",
      "           1.0709e-01, -1.5531e-01, -2.5290e-03, -1.7262e-01, -9.3494e-02,\n",
      "           4.4764e-02,  1.1816e-01, -1.4628e-01, -1.2845e-01,  3.0966e-01,\n",
      "           7.8106e-02,  2.4682e-01,  4.7278e-02,  1.8871e-01, -4.8736e-02,\n",
      "          -5.0679e-02, -3.8388e-01,  2.5079e-05, -6.7818e-02, -1.9101e-01,\n",
      "          -1.6656e-01, -2.6405e-02,  1.4500e-01,  2.1869e-01,  1.8579e-01,\n",
      "          -9.5917e-02, -1.4242e-01, -1.5607e-01,  1.2539e-01, -2.1863e-02,\n",
      "          -1.5506e-02,  9.3829e-02,  2.2892e-01, -2.8199e-01,  5.4271e-02,\n",
      "           1.9142e-01,  1.8043e-01, -6.9807e-02, -4.4827e-02, -2.8024e-01,\n",
      "           1.2425e-01,  2.6849e-01, -1.3381e-02, -6.6143e-02, -8.8331e-02,\n",
      "          -8.9550e-02,  3.1319e-02, -1.3247e-01,  5.8796e-02,  1.3836e-01,\n",
      "          -2.0437e-02,  1.1686e-01,  1.4257e-01, -8.4633e-03,  1.0608e-01,\n",
      "           5.1688e-02,  1.0797e-01,  1.2730e-02, -6.4790e-02,  8.2499e-02,\n",
      "           2.1247e-01,  2.5017e-01,  4.4935e-02, -8.8286e-03,  1.6588e-01,\n",
      "          -9.0317e-02, -1.0935e-02,  5.1992e-02,  8.8514e-02,  1.4628e-03,\n",
      "           3.1070e-02,  2.1794e-01,  4.7639e-03, -1.5823e-01,  1.4757e-01,\n",
      "          -2.6183e-01,  1.1745e-01, -5.6891e-02, -4.2995e-02,  1.4017e-01,\n",
      "          -1.3268e-01, -1.2522e-03, -5.1531e-02, -7.1188e-02, -2.7125e-01,\n",
      "          -1.9354e-02, -1.3694e-01, -5.5037e-02,  9.8236e-02, -3.4760e-01,\n",
      "          -1.5126e-01,  2.9281e-02, -1.2904e-02,  3.5749e-01,  3.4481e-02,\n",
      "          -2.1627e-03, -1.1866e-01,  6.9893e-02,  8.3769e-02, -8.2343e-02,\n",
      "          -1.2389e-01,  1.7576e-01,  1.0748e-01,  1.7956e-01,  8.9932e-02,\n",
      "          -1.1558e-01,  1.2392e-01, -4.3314e-02,  3.5643e-01, -1.2430e-01,\n",
      "           1.4380e-01,  6.3606e-02,  2.4374e-01, -1.8511e-01,  1.4152e-01,\n",
      "          -2.2184e-01, -2.0031e-02,  1.8482e-01,  2.3236e-01, -1.2686e-01,\n",
      "           1.5601e-01,  9.5840e-02,  2.5145e-01, -5.9266e-02,  9.3389e-02,\n",
      "          -1.8337e-02,  4.0489e-02, -1.8453e-01,  2.1440e-01, -1.0750e-01,\n",
      "          -6.0227e-02, -1.4919e-02, -1.3451e-01,  6.3056e-02,  1.2032e-01,\n",
      "          -5.1568e-02, -9.3178e-02, -4.0321e-02,  9.6974e-02,  1.1157e-01,\n",
      "          -2.0188e-01, -7.0333e-02,  1.0544e-01,  2.8715e-01, -1.7479e-01,\n",
      "           3.4451e-02,  8.7115e-02, -1.8198e-01, -1.5575e-01,  5.4692e-02,\n",
      "           1.8286e-02, -1.0667e-01,  6.8422e-03, -4.5691e-02, -7.7966e-02,\n",
      "           1.4382e-01, -1.7107e-02, -1.6806e-01, -1.0051e-01, -1.0650e-01,\n",
      "          -8.5066e-02,  9.3192e-02,  8.1230e-02, -1.0332e-01,  2.8530e-02,\n",
      "          -4.8692e-02, -2.6618e-02, -1.6597e-01, -5.0739e-02, -2.5033e-02,\n",
      "          -1.8875e-01, -4.2435e-02,  1.4471e-01, -9.3912e-03, -3.7832e-02,\n",
      "           1.1420e-02, -1.2772e-01, -1.2031e-01, -3.0744e-02, -5.2839e-02,\n",
      "           1.1585e-01,  7.2074e-02,  1.9627e-01, -2.1939e-01, -9.3476e-04,\n",
      "           2.7202e-01,  6.9655e-02,  9.0678e-02, -1.7542e-01,  3.1771e-02,\n",
      "           1.8629e-01, -5.2422e-02, -2.0379e-01, -3.5007e-01,  1.4414e-01,\n",
      "          -1.6486e-01, -1.5129e-01, -7.0329e-02, -1.4383e-01, -4.9632e-02,\n",
      "           1.4995e-02, -1.6990e-01, -4.7332e-02,  1.1222e-01,  1.0059e-01,\n",
      "           1.4026e-01, -2.3197e-01, -2.4582e-01, -2.1381e-02,  2.5480e-01,\n",
      "           1.2365e-02, -2.5660e-01, -4.2490e-01, -2.8732e-02, -8.9969e-02,\n",
      "          -4.3016e-02, -2.9410e-02, -1.7668e-01, -5.4435e-02,  1.3871e-01,\n",
      "           8.1667e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6011e-02,  3.9912e-01, -9.6640e-01, -6.8168e-01,  3.7618e-01,\n",
      "          -2.0184e-01,  1.4649e+00, -8.3316e-02, -3.5848e+00,  9.0673e-01,\n",
      "           0.0000e+00,  0.0000e+00,  2.6050e+00, -6.2974e-01,  0.0000e+00,\n",
      "          -1.5794e-01,  8.5153e-01,  1.0951e+00,  4.5515e-01,  4.3603e-01,\n",
      "          -6.3364e-01, -3.8328e-01,  1.6417e+00,  1.5113e+00,  7.5365e-01,\n",
      "          -7.5504e-02, -1.8783e-01, -7.5915e-01,  1.6538e+00,  8.6169e-01,\n",
      "           1.2320e+00,  1.2191e+00, -1.0344e+00,  0.0000e+00, -1.5347e+00,\n",
      "           1.3953e+00,  0.0000e+00, -3.7453e+00,  1.9811e-01,  1.6012e+00,\n",
      "          -4.5880e-01, -1.3986e+00, -2.6842e-01, -1.7161e+00, -1.5245e+00,\n",
      "           6.6738e-01,  5.4101e-01,  3.7048e-01, -1.3410e+00,  1.4400e-01,\n",
      "          -6.2920e-01,  2.7528e+00,  6.1042e-01, -1.0293e+00, -2.5627e-02,\n",
      "           2.0318e-01, -8.8226e-01, -1.2527e+00, -2.3673e-01, -4.2529e-01,\n",
      "           1.1009e+00,  1.4084e+00, -2.0339e-01, -5.0172e-01, -2.9646e+00,\n",
      "           5.5063e-01,  1.2790e+00, -1.2881e+00,  4.1148e-01,  5.2649e-01,\n",
      "          -1.2672e+00,  0.0000e+00,  7.0737e-01, -3.6416e+00,  3.2617e-01,\n",
      "          -1.9847e-03, -1.5981e-01,  1.0629e+00, -5.8204e-02, -1.1985e-01,\n",
      "          -1.4004e+00,  2.1316e+00,  0.0000e+00,  1.0059e+00, -2.0784e-01,\n",
      "           4.3481e-01,  1.6618e+00, -9.7451e-01, -1.0346e-01, -5.8149e-01,\n",
      "          -2.2738e+00,  1.1004e+00, -6.2230e-01, -1.1355e+00,  4.6742e-01,\n",
      "          -1.1708e+00,  3.4208e-02,  6.2920e-01,  1.7204e+00, -7.8017e-01,\n",
      "           2.6976e+00, -1.4627e+00,  1.0761e+00,  1.4542e+00, -6.6643e-01,\n",
      "          -7.6261e-01,  1.2126e+00,  1.2732e-01, -1.4730e+00, -1.3211e-02,\n",
      "           0.0000e+00,  1.3450e-01, -1.0484e+00,  1.3102e+00, -1.6536e+00,\n",
      "          -2.9899e+00, -5.6399e-02,  0.0000e+00, -1.9321e-01,  4.4496e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.4608e+00,  0.0000e+00, -9.5864e-01,\n",
      "          -1.3091e+00,  8.9742e-01,  1.7027e-01,  1.2856e+00, -7.5241e-01,\n",
      "          -8.2343e-01,  5.2996e-01, -1.5834e+00,  9.8413e-01,  2.7615e-01,\n",
      "          -5.8959e-01,  6.5973e-01,  5.7385e-01, -1.1586e+00, -1.0103e+00,\n",
      "          -3.8882e-01,  6.7782e-01, -7.9006e-01,  0.0000e+00, -1.6860e+00,\n",
      "          -1.0119e-01, -5.4329e-01,  0.0000e+00, -7.5550e-01,  0.0000e+00,\n",
      "           1.9989e+00, -1.9973e-01, -1.9307e+00, -4.0615e-01,  4.4159e-01,\n",
      "          -1.9448e-01,  0.0000e+00, -1.2912e-01,  3.9342e-02,  5.3765e-01,\n",
      "          -2.6316e-02,  2.2066e+00,  4.8116e-01,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  2.8171e-01,  8.4188e-02, -3.5804e-01, -4.7805e-01,\n",
      "           7.3779e-01,  0.0000e+00,  1.9952e-02, -1.0020e+00,  1.2777e+00,\n",
      "          -1.0988e+00, -9.8751e-01, -2.0773e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -3.0093e-02,  0.0000e+00,  6.7147e-01,  9.7994e-01, -7.4700e-01,\n",
      "          -3.4084e-01, -2.7835e+00, -7.8442e-01,  1.2099e+00,  1.0125e+00,\n",
      "           3.0747e+00,  4.9449e-01, -1.4431e-01, -5.9444e-01,  5.6077e-01,\n",
      "           2.1654e+00, -1.1882e+00,  5.3487e-01,  1.8119e+00, -9.4722e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2419e+00,  0.0000e+00,  2.3194e-01,\n",
      "           0.0000e+00, -2.2931e+00,  6.8180e-01, -1.0746e+00, -4.7133e-01,\n",
      "           2.8684e+00, -5.7341e-01, -3.4113e-01,  7.9319e-01,  3.0060e-02,\n",
      "          -6.8457e-01, -1.0192e+00,  9.6636e-01, -2.4571e-01,  2.1696e+00,\n",
      "          -1.0829e+00, -4.2742e-01, -1.8440e+00, -5.0130e-01,  3.3759e-01,\n",
      "           7.0497e-01, -6.9658e-01,  0.0000e+00,  2.9224e-01, -1.5787e+00,\n",
      "          -1.1087e+00,  1.5816e+00, -6.1424e-01,  1.3097e+00, -2.9801e+00,\n",
      "           4.0360e+00,  5.8522e-01,  4.3424e-02,  0.0000e+00, -2.8738e-01,\n",
      "           7.4176e-01, -3.2486e+00,  0.0000e+00, -8.5238e-01,  1.1243e-02,\n",
      "           2.7538e-01,  2.7486e-01,  0.0000e+00,  2.6102e-01,  3.8658e-01,\n",
      "          -3.6557e-01, -1.5858e-01, -5.5403e-01, -5.2621e-02,  0.0000e+00,\n",
      "          -1.1315e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0307, 0.0488, 0.0712, 0.0669, 0.1054, 0.3641, 0.0613, 0.0802, 0.0569,\n",
      "         0.1146]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2872, -0.5102,  0.3511,  ...,  0.0045, -0.0189,  0.1244],\n",
      "        [-0.0439, -0.5529,  0.4883,  ..., -0.4023,  0.0024, -0.2309],\n",
      "        [ 0.2218, -0.0888, -0.0847,  ..., -0.2527, -0.4300, -0.6023],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.0537e-01,  1.9815e-01, -2.6814e-01,  7.1725e-02, -2.8238e-01,\n",
      "          -1.6622e-01, -1.0241e-01, -3.6040e-01, -5.8119e-03, -9.1819e-02,\n",
      "           9.0774e-02, -2.1972e-01, -4.8806e-02, -5.4628e-02,  1.4927e-01,\n",
      "          -1.4053e-01, -1.5589e-01,  1.5328e-01, -3.0464e-01, -3.0609e-02,\n",
      "          -1.5795e-01, -3.0394e-01,  2.5654e-01,  1.4476e-01, -9.0487e-02,\n",
      "          -2.5841e-01, -1.6612e-01, -1.8051e-01, -4.8219e-02, -1.1646e-01,\n",
      "           2.1059e-01, -1.6322e-01, -3.4695e-01, -2.7669e-01, -1.3965e-01,\n",
      "           6.8803e-02, -2.3343e-01, -1.4508e-01, -1.6841e-01, -3.6134e-02,\n",
      "           5.1595e-02,  5.2953e-02, -2.7462e-01,  1.0398e-01,  5.6481e-02,\n",
      "           3.7575e-01, -2.4297e-01, -3.0248e-01,  1.1080e-01, -1.4142e-01,\n",
      "          -2.7797e-01, -8.1269e-02, -1.8234e-01, -4.7241e-02, -1.7143e-02,\n",
      "           1.3789e-01,  3.2157e-02,  9.4558e-02,  9.4101e-02,  1.8280e-01,\n",
      "          -1.1609e-01, -1.9046e-01, -9.9374e-02,  2.2310e-01, -2.5429e-02,\n",
      "           1.1322e-01, -1.0587e-01,  2.2920e-01, -1.4236e-01,  1.1878e-01,\n",
      "           1.6243e-01,  3.9782e-01, -6.0821e-02,  1.7812e-01, -1.4459e-01,\n",
      "           5.9166e-02,  1.3935e-01,  1.7248e-01,  9.8331e-02,  2.5611e-01,\n",
      "          -1.6991e-01, -2.4582e-01, -1.7467e-01, -1.0775e-01,  1.5965e-02,\n",
      "           3.5236e-01,  1.3542e-01, -3.1264e-03,  2.6202e-01, -6.7217e-02,\n",
      "           9.4908e-02, -1.7903e-01, -6.2460e-02,  7.8516e-03, -2.9480e-02,\n",
      "           1.7943e-01,  2.1340e-01,  3.4396e-01,  1.5632e-02,  3.0663e-01,\n",
      "          -3.4779e-01,  9.6228e-02,  9.8533e-02,  4.5525e-02, -2.0960e-01,\n",
      "           5.0801e-03,  1.9742e-01,  8.0519e-02, -1.5406e-01,  2.5471e-01,\n",
      "           1.2026e-01,  9.3082e-02,  2.2817e-01, -3.5132e-01, -1.7206e-01,\n",
      "           9.5854e-03,  1.5782e-01, -1.2928e-01, -1.0997e-01, -1.0084e-01,\n",
      "           2.4159e-02, -1.6099e-01, -1.9871e-01,  2.0325e-01, -2.8595e-01,\n",
      "          -2.4682e-02, -6.5493e-02, -2.1522e-01,  1.7711e-01,  7.0127e-02,\n",
      "           2.0628e-01, -2.1865e-01,  2.2066e-01,  2.6213e-01, -2.1846e-01,\n",
      "           6.5247e-02,  2.6501e-01,  4.0461e-04, -2.2841e-01,  1.0214e-01,\n",
      "          -1.5834e-01,  7.8003e-02, -1.7972e-01,  1.9367e-01,  2.4517e-01,\n",
      "           1.0833e-02,  9.8649e-02,  2.2264e-01,  1.3811e-01,  2.3184e-01,\n",
      "          -3.6268e-01,  3.3125e-02, -7.0975e-02,  1.8575e-01,  2.1889e-01,\n",
      "           3.5785e-01, -6.5595e-02,  1.7889e-01,  6.4019e-02, -1.2018e-01,\n",
      "          -5.1083e-03, -1.6725e-01, -2.5732e-01,  3.6845e-01,  9.9505e-02,\n",
      "           1.3833e-01,  2.0708e-02, -9.2789e-02,  3.0853e-01,  2.6044e-01,\n",
      "          -2.2789e-01,  1.4245e-01,  1.7483e-01,  1.6115e-03, -2.3872e-01,\n",
      "          -1.9832e-01,  3.3332e-02,  9.0775e-02,  3.1495e-01, -1.1260e-01,\n",
      "          -3.7816e-01, -1.7122e-01, -2.1250e-01,  6.4630e-02, -3.5557e-03,\n",
      "           1.6251e-01, -3.7103e-01,  2.7986e-02,  4.4923e-02, -1.6755e-01,\n",
      "          -1.2577e-02,  1.1121e-01, -3.0945e-01, -2.9871e-01,  2.0475e-03,\n",
      "          -3.2151e-01, -1.8628e-01, -5.8779e-02, -2.5951e-01,  1.4468e-01,\n",
      "           1.1638e-01,  1.7123e-01, -2.4431e-02,  1.8796e-01,  1.0276e-01,\n",
      "          -2.0003e-01, -6.9811e-02,  3.3863e-01, -2.6201e-01, -2.1346e-01,\n",
      "           1.4212e-01, -1.1063e-01,  4.0911e-02,  2.4395e-01, -6.5871e-02,\n",
      "           9.1377e-02, -1.8999e-01,  1.1378e-01, -2.1314e-01,  2.9991e-01,\n",
      "           2.4334e-01, -1.3424e-01,  2.7833e-01,  2.3654e-02,  1.7808e-01,\n",
      "           3.3960e-01,  2.0653e-01, -2.8201e-01, -3.3716e-01,  2.1205e-01,\n",
      "          -2.9839e-01, -4.0506e-02, -4.9231e-02, -3.2178e-01,  3.4046e-02,\n",
      "          -9.4957e-02, -2.3186e-01, -1.5167e-01,  1.9942e-01,  1.7194e-01,\n",
      "          -2.7670e-01, -3.7472e-01, -1.9395e-01, -5.4945e-02,  7.1438e-02,\n",
      "           6.9348e-02, -1.6741e-01, -1.5201e-01,  1.5147e-01,  1.3763e-04,\n",
      "           2.9588e-02,  2.4854e-01, -3.0539e-01, -3.2388e-01, -1.5489e-01,\n",
      "          -2.0297e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4747, -0.4594, -1.2339,  0.0000,  0.4619,  0.0254,  0.6622,\n",
      "           0.5339,  0.6704,  0.9336,  1.7087, -1.0165,  0.9473, -0.2517,\n",
      "           0.0000,  0.5130,  1.8779, -0.7565, -1.5628, -2.6441,  0.0000,\n",
      "           0.1679,  2.9304,  0.5544, -0.1167,  3.2100,  1.8373,  0.5192,\n",
      "          -2.2262, -1.2855,  0.0296,  1.0134,  0.3245,  0.8605, -0.7990,\n",
      "          -1.4657,  0.6200, -0.7714,  1.9920,  0.1027,  0.4676, -2.2045,\n",
      "           0.0000, -0.1155, -0.7133, -0.6898,  1.9283,  0.1099, -0.2871,\n",
      "          -1.8508,  1.4684,  0.4633,  0.6678, -0.2838,  0.5317,  0.2747,\n",
      "          -1.2421, -0.9517,  1.8148, -0.0116,  0.2046, -1.8180, -1.4020,\n",
      "           0.0000,  1.1795,  0.2653, -0.1665, -0.2562, -0.0041, -0.4613,\n",
      "          -0.3253, -0.3246,  0.1475, -0.1271,  0.6588, -0.8066,  2.0662,\n",
      "           0.0000,  0.0877, -0.5468,  1.2272,  0.0876,  0.3272, -1.8368,\n",
      "          -0.0723, -1.7330, -1.4585, -0.8910,  0.6232,  0.8106, -1.2238,\n",
      "          -1.1446,  1.9856, -0.3657, -0.7340,  0.0000,  2.1424, -0.4055,\n",
      "          -0.3041, -1.8397,  0.0000, -0.7221, -0.7664,  0.2382,  0.3822,\n",
      "           1.1139,  0.0000,  2.2531, -0.2628, -0.2880, -0.0532,  0.6109,\n",
      "          -0.2556, -0.2803, -1.9427,  1.1283,  1.0061, -2.4987, -0.5744,\n",
      "           0.0000, -1.6958, -0.4014, -0.3800, -0.0792, -0.5373,  0.0000,\n",
      "           1.3057,  0.1702,  0.3225,  1.3585,  0.0000, -2.6345,  0.3584,\n",
      "          -0.7229,  0.4298,  0.0595,  0.3273, -2.1034, -0.4969, -1.6781,\n",
      "          -0.6424,  0.0000,  0.0000, -1.2158, -0.6316, -0.0411,  0.4651,\n",
      "           1.7386,  1.5937,  1.4317, -1.2628, -0.5776, -0.4803, -0.0395,\n",
      "           0.3269,  0.0000,  1.3541, -0.0308, -1.9010, -1.8060, -1.4271,\n",
      "          -0.9003, -0.7053, -0.3891, -0.9823, -0.1291,  0.4064,  0.9709,\n",
      "           0.5179, -0.1472,  1.5153, -0.3733, -0.3160, -2.0088,  0.1287,\n",
      "          -0.3526, -0.8315, -0.7699, -0.0397, -0.9379,  0.0000,  1.0422,\n",
      "           0.0000,  0.4634,  0.3169, -0.1180, -0.5428, -0.6646,  0.0000,\n",
      "          -1.0645,  0.0000, -1.7886,  0.0000, -0.9268, -1.6149,  0.0000,\n",
      "          -1.1572, -1.9611,  0.0000, -0.3760,  2.6986, -0.9216, -2.6327,\n",
      "          -0.5862,  0.0000,  0.0000, -1.2542,  0.1721,  0.2183, -1.1115,\n",
      "           0.9457, -0.6920, -1.5199,  0.3626,  0.2369, -1.4274, -2.3455,\n",
      "           0.0470, -1.4805,  0.4279,  0.0133, -0.9022,  0.3007, -1.1659,\n",
      "          -1.3024, -0.1875,  1.2725,  1.2667, -2.1882, -0.0567,  0.0000,\n",
      "          -1.1753,  0.9565,  1.9992,  0.5267,  0.7904,  0.0000,  0.1046,\n",
      "          -0.6809, -2.2628,  0.1677, -0.3150, -1.0437, -0.3821, -1.0802,\n",
      "           0.5584,  1.5006, -0.5647,  0.0000,  1.2436,  0.5825,  1.7536,\n",
      "           0.0000,  0.3623,  0.4869,  0.3904]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0210, 0.2323, 0.0743, 0.0483, 0.1454, 0.1649, 0.0264, 0.1801, 0.0551,\n",
      "         0.0523]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2872, -0.5102,  0.3511,  ...,  0.0045, -0.0189,  0.1244],\n",
      "        [-0.0439, -0.5529,  0.4883,  ..., -0.4023,  0.0024, -0.2309],\n",
      "        [ 0.2218, -0.0888, -0.0847,  ..., -0.2527, -0.4300, -0.6023],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.8042e-01, -7.1379e-03, -5.0783e-02,  1.1643e-01, -1.0485e-01,\n",
      "           3.3685e-02, -1.2740e-01, -2.0990e-01, -3.4652e-02,  1.8094e-02,\n",
      "           6.0896e-02, -1.3905e-01,  5.1155e-02, -7.0010e-02,  1.1320e-01,\n",
      "          -8.2264e-02, -2.0167e-01,  1.6239e-01, -1.5019e-01, -8.3195e-02,\n",
      "          -1.6440e-01, -2.4891e-01,  2.0464e-01,  3.4735e-02,  3.6696e-02,\n",
      "          -3.6976e-02, -1.2550e-01, -2.0931e-01,  3.4939e-02, -1.2371e-01,\n",
      "           1.4748e-01, -1.0644e-02, -2.7606e-01, -1.8965e-01, -1.8620e-01,\n",
      "           8.2873e-02, -1.1875e-01, -3.9927e-02,  1.6406e-02, -2.3954e-02,\n",
      "           1.6715e-01,  1.0573e-01, -2.5635e-01,  6.2484e-02, -6.1131e-02,\n",
      "           3.1814e-01, -1.7365e-01, -1.4553e-01, -2.1734e-02, -1.7400e-01,\n",
      "          -2.2584e-01, -1.4283e-01, -8.7773e-02, -6.6430e-02,  8.0056e-02,\n",
      "           1.4583e-01,  9.7141e-02, -5.1649e-03,  8.0095e-02,  1.5787e-01,\n",
      "          -5.7148e-02, -2.2763e-01,  8.9591e-03,  2.0435e-01,  2.0764e-02,\n",
      "           9.0754e-02, -4.6311e-02,  2.0805e-01, -5.4631e-02,  1.6093e-01,\n",
      "           1.3750e-01,  3.5071e-01, -8.9134e-02,  7.8243e-02, -4.0448e-02,\n",
      "           1.0161e-01,  7.8471e-02,  1.5229e-01,  1.7958e-01,  2.0249e-01,\n",
      "          -1.6033e-02, -1.6848e-02,  2.7104e-02, -8.1936e-02,  1.4265e-01,\n",
      "           2.8499e-01,  1.6718e-01,  4.1878e-02,  2.1099e-01, -1.1554e-02,\n",
      "          -1.3118e-02, -2.3356e-01, -1.4975e-01,  1.0197e-01, -1.2054e-01,\n",
      "           2.0456e-01,  9.8203e-02,  2.6147e-01,  1.0949e-01,  2.2777e-01,\n",
      "          -2.6569e-01,  1.0993e-01,  2.9326e-02, -7.3993e-02, -8.5988e-02,\n",
      "           6.6827e-02,  6.3937e-02, -4.1143e-02, -1.5263e-01,  1.7594e-01,\n",
      "           7.4806e-02,  1.5113e-01,  6.5281e-02, -2.2029e-01, -1.0101e-01,\n",
      "          -3.3224e-02,  1.5061e-01, -8.7337e-02, -5.4174e-02, -5.0876e-02,\n",
      "           1.6222e-02, -8.2563e-02, -6.9858e-02,  1.7263e-01, -2.7192e-01,\n",
      "          -1.6496e-02, -1.1117e-01, -1.8296e-01,  8.4466e-02,  1.2790e-01,\n",
      "           1.3741e-01,  1.9646e-02,  1.3966e-01,  2.1340e-01, -1.1065e-01,\n",
      "          -8.7841e-02,  1.6163e-01,  1.9940e-03, -1.1179e-01,  4.2361e-02,\n",
      "          -1.3194e-01, -9.3327e-02, -1.2730e-01,  2.7012e-02,  1.5040e-01,\n",
      "           2.9924e-02,  6.8704e-02,  1.1531e-01,  1.2481e-01,  3.9800e-02,\n",
      "          -1.8803e-01,  3.4531e-02, -2.0354e-02,  1.6878e-01,  1.9343e-01,\n",
      "           2.4760e-01, -7.6559e-02,  1.6579e-01, -4.1595e-02,  5.6916e-02,\n",
      "           9.4362e-02, -6.9174e-02, -9.2196e-02,  2.7950e-01,  7.7851e-03,\n",
      "           9.1708e-02,  8.1341e-02,  7.0032e-02,  1.9586e-01,  1.1624e-01,\n",
      "          -8.5944e-02,  1.8944e-01,  1.0810e-01,  3.7858e-02, -1.5459e-01,\n",
      "          -3.0893e-02,  1.0792e-01,  1.0856e-02,  1.6096e-01,  4.7746e-02,\n",
      "          -4.0231e-01, -1.2558e-01, -6.2331e-02,  3.8041e-02, -6.6551e-02,\n",
      "           1.0211e-01, -1.4294e-01, -9.7139e-02, -1.0895e-01, -2.5275e-02,\n",
      "           1.1301e-02,  6.4141e-02, -1.8988e-01, -2.6694e-01, -1.5241e-01,\n",
      "          -3.6243e-01, -1.4358e-01, -2.3924e-02, -2.3803e-01,  4.1390e-02,\n",
      "           1.9072e-01,  4.1147e-02,  4.3421e-02,  7.8068e-02, -3.4759e-02,\n",
      "          -1.7996e-01, -2.6801e-02,  2.9357e-01, -1.9858e-01, -1.5890e-01,\n",
      "           9.0779e-02,  1.8104e-02,  6.4752e-02,  2.4573e-01,  3.3460e-03,\n",
      "           3.4771e-04, -8.4464e-03,  1.0283e-02, -9.4901e-02,  2.5048e-01,\n",
      "           1.2804e-01, -5.0778e-02,  1.4146e-01,  1.3390e-01,  1.0092e-01,\n",
      "           3.0532e-01,  2.5652e-02, -2.0721e-01, -2.4063e-01,  1.2175e-01,\n",
      "          -1.5372e-01,  6.0561e-02,  1.8068e-02, -1.4233e-01,  4.7621e-02,\n",
      "          -9.3658e-02, -1.4479e-01, -1.3894e-01,  1.0899e-01,  1.8199e-01,\n",
      "          -1.7291e-01, -3.4102e-01, -1.1287e-01, -3.8045e-02,  2.9098e-02,\n",
      "           5.3506e-02, -9.8410e-02, -4.4258e-02,  1.2420e-01, -1.5104e-01,\n",
      "          -6.2671e-02,  2.9363e-01, -2.5620e-01, -3.1653e-01, -1.0301e-01,\n",
      "          -2.2776e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00,  0.0000e+00, -1.8077e+00,  1.3220e+00,  5.1608e-01,\n",
      "           0.0000e+00,  1.2478e-03, -7.2333e-01,  2.1178e+00, -2.1398e-01,\n",
      "           2.8251e-01,  8.3074e-01, -1.1107e+00,  1.9994e-01,  3.1205e-01,\n",
      "           3.5182e-01, -6.8299e-01,  0.0000e+00,  8.7475e-01,  5.4565e-01,\n",
      "           1.8834e+00,  6.0181e-01, -3.6568e-02,  0.0000e+00, -9.9875e-02,\n",
      "           6.5083e-01, -1.6087e+00, -1.3624e+00, -2.1269e+00, -1.0343e+00,\n",
      "           3.9092e-02, -1.4549e+00, -2.0765e+00,  3.1566e-01, -2.8500e-01,\n",
      "          -2.0018e+00,  2.1916e-01,  9.9693e-01,  6.0114e-01,  9.5381e-01,\n",
      "           0.0000e+00,  0.0000e+00, -7.0641e-01,  0.0000e+00,  8.9521e-02,\n",
      "          -1.1387e+00,  0.0000e+00,  7.4191e-01, -7.0986e-01, -1.3358e+00,\n",
      "           0.0000e+00, -1.3717e-01,  6.6296e-01,  1.1162e+00,  0.0000e+00,\n",
      "           3.3337e-01, -4.4975e-01, -8.8825e-01,  1.3371e-01,  6.2857e-01,\n",
      "          -7.0521e-01,  5.6369e-01,  0.0000e+00, -1.5473e+00,  2.8933e-01,\n",
      "           9.5686e-02, -1.7764e-01,  5.9467e-01, -2.1383e+00,  5.5966e-01,\n",
      "           1.8292e-01,  0.0000e+00,  0.0000e+00, -1.1320e+00, -6.4719e-01,\n",
      "           4.6097e-01,  0.0000e+00,  0.0000e+00,  5.1731e-01, -1.8686e-01,\n",
      "          -3.8488e-01,  2.1583e+00,  7.7756e-01, -8.4571e-01,  3.9771e-01,\n",
      "           0.0000e+00,  1.6043e+00, -5.6422e-01, -1.4134e+00, -1.4906e+00,\n",
      "           4.0431e-01, -3.5178e-01,  4.9412e-01, -2.3209e+00,  1.2379e+00,\n",
      "          -9.6280e-01,  1.3204e+00, -9.0767e-01,  2.3909e+00,  9.5535e-01,\n",
      "          -1.2010e+00,  5.9436e-01,  0.0000e+00, -1.7337e+00,  3.6544e-01,\n",
      "           4.0222e-01, -1.2705e+00,  4.5517e-01,  1.9688e+00,  0.0000e+00,\n",
      "          -8.3217e-01,  5.3392e-01,  8.0817e-01,  6.6420e-01, -1.0548e+00,\n",
      "           9.1752e-01,  0.0000e+00,  0.0000e+00,  2.5776e-01,  8.7980e-01,\n",
      "          -8.7678e-01, -1.3968e+00, -3.6501e-01, -1.8465e+00, -1.3007e+00,\n",
      "           1.0693e+00, -8.1157e-01,  6.4932e-01,  2.5579e-01, -1.4894e+00,\n",
      "           2.5026e+00,  3.7794e-01, -1.3459e+00,  7.2246e-01,  3.2015e+00,\n",
      "          -7.5276e-01, -3.8348e-01,  1.2822e+00,  2.2523e+00,  1.9395e-01,\n",
      "          -3.9434e-02,  3.0303e+00,  3.6268e-01, -1.8693e-01, -1.1119e+00,\n",
      "           1.2471e+00,  7.7551e-01, -7.7455e-01, -4.5009e-02, -1.3873e+00,\n",
      "           2.3359e+00,  7.6460e-01, -2.8971e-01, -2.1307e+00, -5.8156e-01,\n",
      "           7.8585e-01,  0.0000e+00,  0.0000e+00,  1.9011e-01, -3.6290e+00,\n",
      "          -1.8685e+00,  1.1506e+00, -8.5954e-01,  9.5973e-01, -1.4614e+00,\n",
      "          -2.7072e-02,  1.9744e+00,  1.1272e+00, -4.8605e-01, -1.2414e+00,\n",
      "          -2.1196e-01, -1.3225e+00, -1.6393e+00, -7.7176e-01,  6.8257e-01,\n",
      "          -1.3796e+00, -1.2625e-01,  6.0657e-01, -7.4862e-01,  2.5915e-01,\n",
      "           1.3326e+00, -2.5535e+00,  2.7789e-01, -5.8384e-01,  1.6235e+00,\n",
      "          -1.2402e+00, -1.8097e-03, -5.0166e-02,  9.0155e-01,  5.6565e-01,\n",
      "          -4.1984e-01,  3.8806e-01, -1.1618e-01,  8.0971e-01,  1.0504e+00,\n",
      "          -7.8908e-01, -1.4388e+00, -4.1613e-01, -7.5043e-01, -4.5424e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.8536e+00,  1.3574e+00,  8.3771e-01,\n",
      "          -1.5241e+00, -3.5882e-01,  0.0000e+00,  2.0070e-01, -2.1784e+00,\n",
      "           8.3557e-01, -1.2913e+00, -1.2839e+00,  2.6116e-01, -1.5635e+00,\n",
      "           2.0757e+00,  1.3420e-01,  0.0000e+00, -3.1140e-02, -5.7935e-01,\n",
      "          -1.4285e+00,  1.9011e+00, -3.8086e-01,  0.0000e+00,  8.0496e-01,\n",
      "           3.6908e-01,  6.6984e-01, -7.0073e-01,  8.9147e-02,  0.0000e+00,\n",
      "           9.7815e-01, -1.4086e+00,  6.5973e-01, -1.1450e+00, -1.6456e+00,\n",
      "          -6.0020e-01,  8.8813e-03, -7.1110e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -7.5237e-01,  5.7212e-01,  5.3062e-01, -6.6354e-01,  1.5466e+00,\n",
      "           5.7856e-01,  1.8920e+00, -8.6433e-01,  4.9334e-01, -3.8733e-01,\n",
      "           5.0023e-01, -9.7526e-01,  1.7728e+00, -1.0635e+00, -8.0792e-01,\n",
      "          -6.2177e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0540, 0.1572, 0.1186, 0.1076, 0.0848, 0.1812, 0.0685, 0.0529, 0.0732,\n",
      "         0.1019]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2872, -0.5102,  0.3511,  ...,  0.0045, -0.0189,  0.1244],\n",
      "        [-0.0439, -0.5529,  0.4883,  ..., -0.4023,  0.0024, -0.2309],\n",
      "        [ 0.2218, -0.0888, -0.0847,  ..., -0.2527, -0.4300, -0.6023],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.7514e-01,  3.0795e-02, -7.5761e-02,  1.4291e-01, -1.5069e-01,\n",
      "           1.4003e-04, -1.3651e-01, -2.1220e-01, -2.4104e-02,  3.3508e-02,\n",
      "           3.6798e-02, -1.4856e-01,  8.4173e-02, -6.8939e-02,  7.3110e-02,\n",
      "          -8.2602e-02, -2.0782e-01,  1.2735e-01, -1.5375e-01, -8.1210e-02,\n",
      "          -1.6153e-01, -2.3555e-01,  2.0274e-01,  4.6782e-02,  3.0299e-02,\n",
      "          -1.1300e-01, -1.9379e-01, -1.8386e-01,  3.2905e-02, -1.2517e-01,\n",
      "           1.4759e-01,  1.7021e-02, -2.9404e-01, -1.7871e-01, -1.8259e-01,\n",
      "           6.4215e-02, -1.3608e-01, -2.9546e-02, -2.1724e-04, -4.5791e-02,\n",
      "           1.2250e-01,  7.6607e-02, -2.5749e-01,  6.8428e-02, -4.6875e-02,\n",
      "           3.4287e-01, -1.8967e-01, -1.5330e-01, -1.1532e-02, -1.5675e-01,\n",
      "          -2.4267e-01, -9.9746e-02, -8.1217e-02, -6.0218e-02,  6.9058e-02,\n",
      "           1.7948e-01,  1.3149e-01, -1.5759e-02,  6.0713e-02,  1.1563e-01,\n",
      "          -5.6672e-02, -2.0031e-01,  4.1444e-02,  1.8415e-01,  7.0229e-02,\n",
      "           1.1336e-01, -6.0498e-02,  1.8622e-01, -4.2915e-02,  1.2910e-01,\n",
      "           1.4636e-01,  3.6665e-01, -7.0820e-02,  8.9144e-02, -4.5586e-02,\n",
      "           5.3986e-02,  2.4547e-02,  1.1465e-01,  1.8216e-01,  1.9694e-01,\n",
      "          -3.5949e-02, -5.6340e-02,  5.8293e-02, -1.2365e-01,  1.2128e-01,\n",
      "           2.9659e-01,  1.5658e-01,  1.2556e-02,  1.7816e-01, -1.9328e-02,\n",
      "          -1.8728e-02, -2.4603e-01, -1.1740e-01,  8.9420e-02, -7.9149e-02,\n",
      "           1.8446e-01,  9.6167e-02,  2.7462e-01,  8.9629e-02,  2.0748e-01,\n",
      "          -2.8703e-01,  6.4541e-02,  2.4718e-02, -5.9266e-02, -1.4031e-01,\n",
      "           5.1004e-02,  8.5706e-02, -9.2977e-02, -1.4035e-01,  1.8190e-01,\n",
      "           6.7136e-02,  1.4458e-01,  1.1678e-01, -2.2055e-01, -5.9376e-02,\n",
      "          -2.5886e-02,  1.8855e-01, -9.9938e-02, -7.5932e-02, -4.6344e-02,\n",
      "           5.4185e-03, -9.6105e-02, -3.6710e-02,  1.8310e-01, -2.4112e-01,\n",
      "           4.3742e-02, -9.5469e-02, -1.7321e-01,  1.0540e-01,  1.6005e-01,\n",
      "           1.5306e-01,  4.0676e-03,  1.2587e-01,  1.7490e-01, -1.2165e-01,\n",
      "          -5.3013e-02,  1.4877e-01, -3.1449e-02, -1.1766e-01,  3.3339e-03,\n",
      "          -1.1799e-01, -9.7249e-02, -8.8809e-02,  8.1445e-02,  1.7981e-01,\n",
      "           2.5725e-02,  8.9523e-02,  8.6269e-02,  1.2849e-01,  7.1958e-02,\n",
      "          -1.5581e-01, -1.9933e-02, -2.9639e-02,  1.3610e-01,  1.8235e-01,\n",
      "           2.4789e-01, -7.3068e-02,  1.5049e-01, -3.6792e-02,  5.5970e-02,\n",
      "           9.5223e-02, -6.6574e-02, -8.8374e-02,  2.4978e-01,  7.9105e-02,\n",
      "           9.3689e-02,  1.2816e-01,  4.0996e-02,  2.3478e-01,  1.1323e-01,\n",
      "          -1.0566e-01,  1.6594e-01,  9.9182e-02,  4.0267e-02, -1.6245e-01,\n",
      "          -6.0487e-02,  1.2669e-01, -6.8951e-05,  1.2360e-01,  2.2071e-02,\n",
      "          -3.9066e-01, -1.0217e-01, -4.9433e-02,  9.1691e-02, -1.2067e-01,\n",
      "           8.7569e-02, -1.9864e-01, -8.5472e-02, -6.3891e-02, -3.4282e-02,\n",
      "           1.5292e-03,  6.3200e-02, -1.9059e-01, -2.8846e-01, -1.0892e-01,\n",
      "          -3.3483e-01, -1.5774e-01, -3.4294e-02, -2.1704e-01,  7.3639e-02,\n",
      "           1.8421e-01,  7.2320e-02,  4.5809e-02,  6.0506e-02, -2.1166e-02,\n",
      "          -1.6605e-01, -3.8201e-02,  2.6035e-01, -2.3316e-01, -1.6447e-01,\n",
      "           1.1835e-01,  1.5905e-02,  6.7222e-02,  2.2858e-01,  7.5414e-03,\n",
      "          -3.3963e-03, -4.2280e-02,  1.7981e-02, -8.6763e-02,  2.4727e-01,\n",
      "           1.5351e-01, -5.3616e-02,  1.4983e-01,  1.1573e-01,  9.1657e-02,\n",
      "           3.0159e-01,  7.0555e-02, -1.8220e-01, -2.0231e-01,  1.1351e-01,\n",
      "          -1.8632e-01,  4.8413e-02,  3.9869e-02, -1.4377e-01,  5.6317e-02,\n",
      "          -7.9496e-02, -1.3840e-01, -1.5207e-01,  9.1284e-02,  1.7706e-01,\n",
      "          -2.0086e-01, -3.3594e-01, -1.1336e-01, -4.3974e-02,  1.4690e-02,\n",
      "           5.4213e-02, -7.6777e-02, -1.6091e-02,  1.1424e-01, -1.1499e-01,\n",
      "          -8.5394e-02,  2.8650e-01, -2.6806e-01, -2.9975e-01, -1.6015e-01,\n",
      "          -2.4468e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5948e-02,  3.9910e-01, -9.6642e-01, -6.8163e-01,  3.7617e-01,\n",
      "          -2.0187e-01,  1.4649e+00, -8.3285e-02, -3.5848e+00,  9.0672e-01,\n",
      "           0.0000e+00, -6.2911e-01,  2.6050e+00, -6.2975e-01, -5.4156e-01,\n",
      "          -1.5793e-01,  8.5146e-01,  1.0950e+00,  4.5518e-01,  4.3607e-01,\n",
      "          -6.3368e-01, -3.8333e-01,  1.6417e+00,  1.5113e+00,  7.5365e-01,\n",
      "          -7.5457e-02, -1.8781e-01, -7.5918e-01,  1.6538e+00,  8.6174e-01,\n",
      "           1.2320e+00,  1.2190e+00, -1.0344e+00, -8.2677e-02, -1.5347e+00,\n",
      "           1.3953e+00,  2.8089e-01, -3.7453e+00,  1.9807e-01,  1.6012e+00,\n",
      "          -4.5886e-01, -1.3986e+00, -2.6840e-01, -1.7162e+00, -1.5246e+00,\n",
      "           0.0000e+00,  5.4099e-01,  3.7044e-01,  0.0000e+00,  1.4396e-01,\n",
      "          -6.2915e-01,  2.7528e+00,  6.1042e-01, -1.0294e+00,  0.0000e+00,\n",
      "           2.0319e-01, -8.8225e-01, -1.2528e+00, -2.3669e-01, -4.2529e-01,\n",
      "           1.1009e+00,  1.4084e+00, -2.0342e-01, -5.0169e-01, -2.9646e+00,\n",
      "           5.5060e-01,  1.2790e+00, -1.2881e+00,  4.1149e-01,  5.2645e-01,\n",
      "          -1.2672e+00, -3.0306e-02,  7.0738e-01, -3.6417e+00,  3.2615e-01,\n",
      "          -1.9942e-03, -1.5980e-01,  1.0629e+00, -5.8240e-02, -1.1984e-01,\n",
      "           0.0000e+00,  2.1316e+00, -9.2481e-01,  0.0000e+00, -2.0782e-01,\n",
      "           4.3482e-01,  1.6618e+00, -9.7455e-01, -1.0343e-01, -5.8149e-01,\n",
      "          -2.2739e+00,  1.1003e+00, -6.2231e-01, -1.1354e+00,  4.6741e-01,\n",
      "          -1.1708e+00,  3.4203e-02,  6.2917e-01,  0.0000e+00, -7.8026e-01,\n",
      "           2.6975e+00, -1.4627e+00,  1.0761e+00,  1.4542e+00, -6.6645e-01,\n",
      "          -7.6263e-01,  1.2126e+00,  1.2730e-01, -1.4730e+00, -1.3146e-02,\n",
      "          -2.4872e-01,  1.3450e-01, -1.0485e+00,  1.3102e+00, -1.6536e+00,\n",
      "          -2.9899e+00, -5.6436e-02, -5.0103e-01, -1.9322e-01,  4.4496e-01,\n",
      "          -1.4667e+00,  7.0236e-01, -1.4608e+00, -7.2630e-01, -9.5860e-01,\n",
      "          -1.3091e+00,  0.0000e+00,  1.7031e-01,  1.2856e+00, -7.5247e-01,\n",
      "          -8.2345e-01,  5.2992e-01, -1.5834e+00,  9.8414e-01,  2.7613e-01,\n",
      "          -5.8962e-01,  6.5974e-01,  5.7392e-01, -1.1586e+00,  0.0000e+00,\n",
      "          -3.8879e-01,  6.7786e-01, -7.9005e-01, -1.0161e-01, -1.6860e+00,\n",
      "          -1.0115e-01, -5.4330e-01, -8.4449e-01, -7.5552e-01,  1.7747e-01,\n",
      "           1.9989e+00, -1.9969e-01, -1.9307e+00, -4.0616e-01,  4.4152e-01,\n",
      "          -1.9443e-01, -6.4325e-02, -1.2912e-01,  3.9365e-02,  5.3764e-01,\n",
      "           0.0000e+00,  2.2066e+00,  4.8115e-01, -5.4988e-01, -5.2704e-01,\n",
      "          -8.9266e-01,  2.8171e-01,  8.4218e-02, -3.5800e-01, -4.7805e-01,\n",
      "           0.0000e+00, -3.2026e-02,  1.9964e-02, -1.0020e+00,  1.2778e+00,\n",
      "          -1.0988e+00, -9.8755e-01, -2.0774e+00,  1.9694e+00,  8.6429e-02,\n",
      "          -3.0065e-02,  0.0000e+00,  6.7149e-01,  9.7985e-01, -7.4701e-01,\n",
      "          -3.4088e-01,  0.0000e+00, -7.8442e-01,  0.0000e+00,  1.0125e+00,\n",
      "           3.0747e+00,  4.9445e-01, -1.4429e-01, -5.9447e-01,  5.6081e-01,\n",
      "           2.1654e+00, -1.1881e+00,  5.3490e-01,  1.8119e+00, -9.4726e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2419e+00,  0.0000e+00,  2.3195e-01,\n",
      "          -5.7530e-01, -2.2930e+00,  6.8185e-01, -1.0746e+00, -4.7134e-01,\n",
      "           2.8684e+00, -5.7339e-01, -3.4115e-01,  7.9318e-01,  3.0052e-02,\n",
      "          -6.8460e-01, -1.0191e+00,  9.6636e-01, -2.4573e-01,  2.1696e+00,\n",
      "          -1.0829e+00, -4.2746e-01, -1.8440e+00,  0.0000e+00,  0.0000e+00,\n",
      "           7.0496e-01, -6.9655e-01, -6.2817e-01,  2.9221e-01, -1.5787e+00,\n",
      "          -1.1087e+00,  1.5816e+00, -6.1430e-01,  1.3098e+00, -2.9801e+00,\n",
      "           4.0360e+00,  5.8521e-01,  4.3411e-02, -1.5802e+00, -2.8738e-01,\n",
      "           0.0000e+00, -3.2486e+00, -3.0454e-01, -8.5240e-01,  1.1223e-02,\n",
      "           0.0000e+00,  2.7490e-01,  2.5253e-01,  2.6104e-01,  3.8661e-01,\n",
      "          -3.6552e-01, -1.5856e-01, -5.5405e-01, -5.2619e-02, -1.1470e+00,\n",
      "          -1.1315e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0447, 0.0498, 0.0787, 0.0619, 0.1284, 0.3233, 0.0513, 0.1007, 0.0439,\n",
      "         0.1174]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0333,  0.0764,  ..., -0.1154, -0.0157, -0.4831],\n",
      "        [ 0.1234,  0.1372,  0.2678,  ...,  0.1102,  0.0869,  0.0405],\n",
      "        [ 0.1627, -0.3496, -0.2363,  ...,  0.0133, -0.0440, -0.2127],\n",
      "        ...,\n",
      "        [ 0.4151,  0.1555, -0.2900,  ..., -0.4519,  0.1956, -0.0367],\n",
      "        [ 0.6753,  0.4965, -0.7253,  ..., -0.3573, -0.0695,  0.1355],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1305,  0.0979,  0.0044, -0.0674,  0.0900, -0.2180, -0.2372,\n",
      "          -0.0802, -0.1010,  0.0088,  0.2214, -0.2877,  0.1920,  0.1236,\n",
      "           0.0184,  0.0819,  0.1066, -0.1139, -0.0309,  0.0245, -0.3633,\n",
      "          -0.0005,  0.0534, -0.0678, -0.2056, -0.2818,  0.2547,  0.0507,\n",
      "          -0.0992, -0.0255, -0.2332, -0.1391,  0.0899,  0.2019, -0.0301,\n",
      "           0.0517,  0.0541, -0.1742, -0.3488, -0.0840, -0.0936,  0.0625,\n",
      "           0.0768,  0.1450,  0.3183, -0.1573, -0.0668, -0.0875,  0.0801,\n",
      "           0.1206, -0.1402, -0.0019, -0.0677, -0.1945, -0.1757,  0.1818,\n",
      "          -0.1221,  0.2113,  0.1407, -0.0874,  0.0808,  0.0634, -0.1594,\n",
      "          -0.0568, -0.2150,  0.1305,  0.0695,  0.0377, -0.0584, -0.0407,\n",
      "           0.1800,  0.1510, -0.0751,  0.1515, -0.1674,  0.0266, -0.1785,\n",
      "           0.2073,  0.2157, -0.1122, -0.2384,  0.0499,  0.0332,  0.2283,\n",
      "           0.0241,  0.1457,  0.0899, -0.0716, -0.0553, -0.0319, -0.0163,\n",
      "           0.3203,  0.0092, -0.0147,  0.0886, -0.1350,  0.1230,  0.3247,\n",
      "          -0.1106, -0.0901, -0.1800, -0.2382,  0.0385,  0.1593,  0.0399,\n",
      "          -0.0103,  0.1890,  0.2797, -0.1131,  0.1806, -0.0997, -0.0165,\n",
      "          -0.2267, -0.2711,  0.1543, -0.0391, -0.1452,  0.0175,  0.2215,\n",
      "          -0.1086,  0.1076, -0.0395, -0.1627,  0.0906, -0.2249, -0.0612,\n",
      "          -0.1333,  0.0088,  0.0819,  0.1722, -0.0313, -0.2203,  0.2686,\n",
      "           0.1619, -0.0820, -0.0998,  0.0282,  0.1276,  0.2332,  0.1227,\n",
      "          -0.1087,  0.1183, -0.2229,  0.0620, -0.1611,  0.2238,  0.0585,\n",
      "           0.2894, -0.2053,  0.0366, -0.2262, -0.0468, -0.0177,  0.0509,\n",
      "          -0.0522,  0.2580, -0.0513,  0.4491, -0.2630,  0.1928, -0.0144,\n",
      "           0.0664, -0.0206, -0.0787, -0.1016, -0.0753, -0.2165, -0.0610,\n",
      "          -0.0704,  0.1917, -0.0563,  0.1424, -0.1480,  0.3103, -0.0628,\n",
      "          -0.2914,  0.0384,  0.1240,  0.2414,  0.2047, -0.0692,  0.0906,\n",
      "          -0.2115,  0.1094, -0.2293,  0.0508,  0.0549,  0.0050,  0.1462,\n",
      "           0.1750, -0.1480, -0.1336, -0.0079,  0.1489, -0.3217, -0.0587,\n",
      "           0.0339,  0.0729,  0.0302, -0.2955,  0.0503, -0.1331, -0.0470,\n",
      "           0.0393,  0.0586,  0.3014, -0.3328, -0.1309, -0.0354, -0.0560,\n",
      "          -0.0360,  0.1549,  0.1657,  0.0493, -0.1860, -0.1854, -0.0110,\n",
      "          -0.1850, -0.2516,  0.0923, -0.0955,  0.1432,  0.0581, -0.0979,\n",
      "          -0.2636, -0.0328,  0.1624, -0.1227, -0.1666, -0.0357,  0.0500,\n",
      "          -0.2357, -0.2192,  0.0674,  0.1571, -0.0654,  0.1421,  0.1565,\n",
      "          -0.0778,  0.0940,  0.0110,  0.0048,  0.1332, -0.0297,  0.1268,\n",
      "           0.3328, -0.0682,  0.1317, -0.0343, -0.1882, -0.1480,  0.1960,\n",
      "          -0.0857, -0.1653, -0.2260,  0.1003]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4747, -0.4593, -1.2339, -0.1176,  0.4619,  0.0254,  0.6623,\n",
      "           0.5340,  0.6704,  0.9336,  1.7087, -1.0165,  0.9473, -0.2517,\n",
      "          -1.6345,  0.5130,  1.8779, -0.7564, -1.5627, -2.6440, -1.1339,\n",
      "           0.1679,  2.9303,  0.0000,  0.0000,  3.2100,  1.8373,  0.5193,\n",
      "          -2.2262, -1.2855,  0.0296,  1.0135,  0.3245,  0.8604, -0.7990,\n",
      "          -1.4656,  0.6200, -0.7715,  1.9919,  0.1027,  0.4676, -2.2045,\n",
      "          -0.5665,  0.0000, -0.7132, -0.6897,  1.9282,  0.1099, -0.2870,\n",
      "          -1.8508,  1.4684,  0.4633,  0.6678,  0.0000,  0.0000,  0.2747,\n",
      "          -1.2421, -0.9517,  1.8147, -0.0116,  0.2047, -1.8180, -1.4021,\n",
      "          -0.8067,  1.1795,  0.2653,  0.0000, -0.2562, -0.0041, -0.4613,\n",
      "           0.0000, -0.3245,  0.1476, -0.1271,  0.0000, -0.8066,  2.0663,\n",
      "           1.6804,  0.0877, -0.5467,  0.0000,  0.0876,  0.3272, -1.8368,\n",
      "          -0.0722, -1.7330, -1.4584, -0.8910,  0.6233,  0.0000, -1.2239,\n",
      "          -1.1446,  1.9856, -0.3657, -0.7340,  0.1565,  2.1423, -0.4055,\n",
      "          -0.3041, -1.8397, -1.2905, -0.7221, -0.7665,  0.2382,  0.3821,\n",
      "           1.1139, -1.0695,  2.2531, -0.2628, -0.2879, -0.0532,  0.6109,\n",
      "          -0.2556, -0.2803, -1.9427,  1.1282,  1.0061, -2.4986, -0.5745,\n",
      "           0.0298, -1.6957, -0.4014, -0.3799, -0.0792, -0.5372, -1.1119,\n",
      "           1.3056,  0.1702,  0.3225,  1.3584,  2.0804, -2.6345,  0.3585,\n",
      "           0.0000,  0.4298,  0.0000,  0.3273, -2.1033, -0.4968,  0.0000,\n",
      "          -0.6424,  0.2340,  0.0000, -1.2158, -0.6316, -0.0411,  0.4651,\n",
      "           1.7386,  1.5938,  0.0000, -1.2628, -0.5776, -0.4803,  0.0000,\n",
      "           0.3270, -0.1163,  1.3541, -0.0309, -1.9010,  0.0000, -1.4271,\n",
      "          -0.9003, -0.7053, -0.3892, -0.9823, -0.1292,  0.4064,  0.9709,\n",
      "           0.5179, -0.1472,  1.5152, -0.3732, -0.3160, -2.0088,  0.0000,\n",
      "          -0.3526, -0.8314, -0.7699, -0.0397, -0.9379,  0.7281,  0.0000,\n",
      "           0.0471,  0.4633,  0.3168, -0.1179, -0.5428, -0.6646,  0.7556,\n",
      "          -1.0645, -0.5860, -1.7885,  1.2674, -0.9268, -1.6149, -0.3331,\n",
      "          -1.1572, -1.9610, -0.0720, -0.3760,  2.6985, -0.9216, -2.6327,\n",
      "          -0.5862, -0.7171, -1.3864, -1.2542,  0.1721,  0.2183, -1.1114,\n",
      "           0.9457, -0.6919, -1.5199,  0.3626,  0.2369, -1.4274, -2.3454,\n",
      "           0.0470, -1.4805,  0.4279,  0.0000, -0.9022,  0.3008, -1.1659,\n",
      "          -1.3024, -0.1875,  1.2725,  1.2667, -2.1882, -0.0567,  1.7372,\n",
      "          -1.1753,  0.9565,  1.9992,  0.5267,  0.7904, -0.6786,  0.1046,\n",
      "          -0.6809, -2.2627,  0.1676, -0.3149, -1.0436, -0.3820, -1.0803,\n",
      "           0.5584,  1.5006, -0.5648, -1.3778,  1.2436,  0.5825,  1.7536,\n",
      "           1.9512,  0.3623,  0.4869,  0.3905]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0202, 0.2745, 0.0818, 0.0415, 0.0955, 0.1655, 0.0295, 0.1644, 0.0769,\n",
      "         0.0502]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0333,  0.0764,  ..., -0.1154, -0.0157, -0.4831],\n",
      "        [ 0.1234,  0.1372,  0.2678,  ...,  0.1102,  0.0869,  0.0405],\n",
      "        [ 0.1627, -0.3496, -0.2363,  ...,  0.0133, -0.0440, -0.2127],\n",
      "        ...,\n",
      "        [ 0.4151,  0.1555, -0.2900,  ..., -0.4519,  0.1956, -0.0367],\n",
      "        [ 0.6753,  0.4965, -0.7253,  ..., -0.3573, -0.0695,  0.1355],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1874,  0.1146, -0.0089,  0.0029,  0.1812, -0.0846, -0.2890,\n",
      "          -0.0381, -0.0076,  0.0139,  0.0962, -0.1878,  0.0883,  0.1156,\n",
      "           0.0565,  0.1215,  0.1448, -0.0604, -0.2533,  0.0173, -0.3922,\n",
      "          -0.0432, -0.0022, -0.1446, -0.2054, -0.3263,  0.2307, -0.0032,\n",
      "          -0.1010, -0.0573, -0.1304, -0.0803,  0.0595,  0.1822, -0.1177,\n",
      "           0.0363, -0.1625, -0.1637, -0.3253, -0.1189, -0.0506,  0.0884,\n",
      "           0.0173,  0.0633,  0.3449, -0.1063,  0.0108,  0.0281,  0.1420,\n",
      "           0.0498, -0.1408, -0.1675, -0.0177, -0.2184, -0.2580,  0.1214,\n",
      "          -0.0461,  0.2242,  0.1474,  0.0900,  0.0675,  0.0275, -0.1495,\n",
      "           0.0367, -0.1814,  0.0727,  0.0782,  0.0065, -0.1418, -0.0508,\n",
      "           0.1778,  0.2284, -0.1831,  0.1524, -0.2503,  0.0665,  0.0038,\n",
      "           0.1015,  0.1595, -0.1120, -0.2968, -0.0364, -0.0643,  0.2276,\n",
      "           0.0794,  0.1587,  0.1636, -0.0282, -0.0249,  0.0569, -0.0447,\n",
      "           0.2622, -0.0108, -0.0764,  0.0937, -0.0316,  0.2164,  0.3461,\n",
      "          -0.1362,  0.0362, -0.2273, -0.1413,  0.1275,  0.1245,  0.0213,\n",
      "          -0.0068,  0.2220,  0.1534, -0.1490,  0.1850, -0.1479, -0.0025,\n",
      "          -0.1679, -0.1704,  0.1730, -0.0436, -0.0452, -0.0761,  0.1204,\n",
      "          -0.1921,  0.1656, -0.0623, -0.1764,  0.1173, -0.3115, -0.0824,\n",
      "           0.0543,  0.0375,  0.2691,  0.1948,  0.0040, -0.2559,  0.2735,\n",
      "           0.1250, -0.1378, -0.1568,  0.1872,  0.1138,  0.2972,  0.1446,\n",
      "          -0.0018,  0.2435, -0.1184,  0.1766, -0.1913,  0.1952,  0.1727,\n",
      "           0.2792, -0.2144,  0.1070, -0.2926, -0.0770,  0.0549,  0.2270,\n",
      "          -0.0508,  0.3164, -0.0296,  0.4098, -0.1959,  0.2025, -0.0268,\n",
      "           0.0532, -0.1108,  0.0549, -0.1610, -0.0932, -0.1832, -0.0781,\n",
      "          -0.1834,  0.2524, -0.0207,  0.0167, -0.0964,  0.3630, -0.0044,\n",
      "          -0.2895,  0.0019,  0.0937,  0.2333,  0.1121, -0.0883,  0.1131,\n",
      "          -0.2617,  0.0043, -0.1011,  0.0734,  0.0521, -0.0146,  0.1299,\n",
      "          -0.0009, -0.0475, -0.2105, -0.0986,  0.0685, -0.2540,  0.0280,\n",
      "           0.1550,  0.1105, -0.0199, -0.2123, -0.0065, -0.0656, -0.0585,\n",
      "           0.0838,  0.0353,  0.1678, -0.3175,  0.0043, -0.0134, -0.0765,\n",
      "           0.0183,  0.0293,  0.0399, -0.0299, -0.1418, -0.1562,  0.0849,\n",
      "          -0.0389, -0.3575,  0.0611,  0.0437,  0.0695,  0.1294, -0.1196,\n",
      "          -0.2225,  0.1717,  0.1281, -0.1926, -0.3379,  0.0277, -0.0611,\n",
      "          -0.2573, -0.1867,  0.0005,  0.1185, -0.1193,  0.0010,  0.0729,\n",
      "           0.0062,  0.1272,  0.0356, -0.0230, -0.0744,  0.0255,  0.2684,\n",
      "           0.1952, -0.1644, -0.0116, -0.1160, -0.2040, -0.0618,  0.1772,\n",
      "          -0.0943, -0.1207, -0.0987,  0.0710]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00,  0.0000e+00, -1.8077e+00,  1.3220e+00,  5.1606e-01,\n",
      "          -3.7637e-01,  1.2842e-03, -7.2332e-01,  2.1179e+00, -2.1396e-01,\n",
      "           2.8237e-01,  8.3068e-01, -1.1108e+00,  1.9999e-01,  3.1217e-01,\n",
      "           3.5183e-01, -6.8295e-01,  1.6909e-01,  8.7480e-01,  5.4570e-01,\n",
      "           0.0000e+00,  6.0181e-01, -3.6630e-02, -5.3536e-01, -9.9934e-02,\n",
      "           6.5078e-01, -1.6087e+00, -1.3625e+00, -2.1269e+00, -1.0344e+00,\n",
      "           0.0000e+00, -1.4548e+00, -2.0765e+00,  3.1559e-01, -2.8494e-01,\n",
      "          -2.0018e+00,  2.1916e-01,  9.9689e-01,  6.0110e-01,  9.5380e-01,\n",
      "          -2.2532e-01, -2.2113e+00,  0.0000e+00,  1.3961e+00,  8.9483e-02,\n",
      "          -1.1386e+00,  0.0000e+00,  7.4184e-01, -7.0979e-01, -1.3359e+00,\n",
      "           1.6089e+00, -1.3729e-01,  0.0000e+00,  1.1163e+00,  0.0000e+00,\n",
      "           0.0000e+00, -4.4972e-01, -8.8828e-01,  0.0000e+00,  6.2853e-01,\n",
      "          -7.0521e-01,  5.6366e-01, -6.9333e-01,  0.0000e+00,  2.8932e-01,\n",
      "           0.0000e+00, -1.7769e-01,  5.9466e-01, -2.1383e+00,  5.5970e-01,\n",
      "           1.8291e-01, -5.1253e-01, -3.4116e-01, -1.1319e+00, -6.4720e-01,\n",
      "           4.6093e-01, -1.0494e+00,  1.1907e-01,  0.0000e+00, -1.8678e-01,\n",
      "          -3.8488e-01,  2.1582e+00,  7.7751e-01, -8.4566e-01,  3.9775e-01,\n",
      "           4.1923e-01,  1.6044e+00, -5.6418e-01, -1.4134e+00, -1.4906e+00,\n",
      "           0.0000e+00, -3.5178e-01,  0.0000e+00, -2.3209e+00,  1.2379e+00,\n",
      "          -9.6279e-01,  1.3204e+00, -9.0765e-01,  2.3908e+00,  9.5534e-01,\n",
      "          -1.2010e+00,  5.9440e-01,  1.0665e+00, -1.7337e+00,  3.6536e-01,\n",
      "           4.0220e-01, -1.2706e+00,  4.5515e-01,  1.9686e+00,  1.4944e-01,\n",
      "          -8.3218e-01,  5.3391e-01,  8.0819e-01,  6.6419e-01, -1.0548e+00,\n",
      "           9.1751e-01, -7.0277e-01, -8.4524e-01,  2.5779e-01,  8.7974e-01,\n",
      "          -8.7672e-01, -1.3968e+00, -3.6490e-01, -1.8465e+00,  0.0000e+00,\n",
      "           0.0000e+00, -8.1165e-01,  6.4922e-01,  2.5577e-01, -1.4894e+00,\n",
      "           2.5025e+00,  3.7796e-01, -1.3458e+00,  7.2238e-01,  3.2015e+00,\n",
      "          -7.5267e-01, -3.8348e-01,  1.2823e+00,  2.2522e+00,  1.9401e-01,\n",
      "          -3.9428e-02,  3.0303e+00,  3.6271e-01, -1.8696e-01, -1.1119e+00,\n",
      "           1.2472e+00,  7.7548e-01, -7.7457e-01, -4.5020e-02, -1.3874e+00,\n",
      "           2.3359e+00,  7.6467e-01, -2.8966e-01,  0.0000e+00, -5.8153e-01,\n",
      "           7.8586e-01, -1.8620e+00,  0.0000e+00,  1.9015e-01, -3.6290e+00,\n",
      "          -1.8684e+00,  1.1506e+00, -8.5952e-01,  9.5973e-01, -1.4614e+00,\n",
      "           0.0000e+00,  1.9744e+00,  0.0000e+00, -4.8604e-01, -1.2414e+00,\n",
      "          -2.1203e-01, -1.3224e+00, -1.6393e+00, -7.7182e-01,  6.8261e-01,\n",
      "          -1.3797e+00,  0.0000e+00,  6.0660e-01, -7.4863e-01,  2.5912e-01,\n",
      "           1.3326e+00, -2.5535e+00,  2.7785e-01, -5.8387e-01,  1.6235e+00,\n",
      "          -1.2402e+00, -1.7629e-03,  0.0000e+00,  0.0000e+00,  5.6571e-01,\n",
      "          -4.1990e-01,  3.8807e-01, -1.1622e-01,  8.0966e-01,  1.0503e+00,\n",
      "          -7.8908e-01, -1.4389e+00, -4.1610e-01, -7.5047e-01, -4.5420e-01,\n",
      "          -5.4750e-01,  7.2224e-01, -1.8536e+00,  1.3574e+00,  8.3774e-01,\n",
      "           0.0000e+00, -3.5875e-01,  6.4797e-01,  2.0069e-01, -2.1783e+00,\n",
      "           8.3549e-01, -1.2913e+00, -1.2838e+00,  2.6117e-01, -1.5635e+00,\n",
      "           0.0000e+00,  1.3424e-01,  2.5768e+00, -3.1107e-02, -5.7940e-01,\n",
      "          -1.4285e+00,  0.0000e+00, -3.8085e-01,  1.4693e+00,  8.0504e-01,\n",
      "           3.6910e-01,  6.6980e-01, -7.0067e-01,  8.9122e-02,  0.0000e+00,\n",
      "           9.7818e-01,  0.0000e+00,  6.5965e-01, -1.1451e+00, -1.6456e+00,\n",
      "           0.0000e+00,  8.9113e-03, -7.1112e-01,  3.7055e-01, -2.2432e-01,\n",
      "          -7.5242e-01,  5.7212e-01,  0.0000e+00, -6.6352e-01,  1.5466e+00,\n",
      "           5.7851e-01,  1.8919e+00, -8.6436e-01,  4.9338e-01, -3.8736e-01,\n",
      "           5.0025e-01, -9.7528e-01,  1.7728e+00, -1.0635e+00, -8.0788e-01,\n",
      "          -6.2177e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0412, 0.1354, 0.1106, 0.1316, 0.0940, 0.1793, 0.0721, 0.0661, 0.0644,\n",
      "         0.1054]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0333,  0.0764,  ..., -0.1154, -0.0157, -0.4831],\n",
      "        [ 0.1234,  0.1372,  0.2678,  ...,  0.1102,  0.0869,  0.0405],\n",
      "        [ 0.1627, -0.3496, -0.2363,  ...,  0.0133, -0.0440, -0.2127],\n",
      "        ...,\n",
      "        [ 0.4151,  0.1555, -0.2900,  ..., -0.4519,  0.1956, -0.0367],\n",
      "        [ 0.6753,  0.4965, -0.7253,  ..., -0.3573, -0.0695,  0.1355],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1151,  0.0492, -0.0056, -0.0141,  0.1202, -0.1231, -0.2593,\n",
      "          -0.0086, -0.0532,  0.0474,  0.1518, -0.1823,  0.1666,  0.1247,\n",
      "           0.0435,  0.1211,  0.1078, -0.1160, -0.1680,  0.0313, -0.3531,\n",
      "          -0.0038,  0.0263, -0.1379, -0.1827, -0.2755,  0.2297,  0.0101,\n",
      "          -0.1280, -0.0270, -0.2097, -0.0885,  0.0843,  0.2220, -0.0268,\n",
      "           0.0723, -0.0460, -0.1400, -0.3186, -0.1312, -0.0761,  0.0559,\n",
      "           0.0127,  0.0641,  0.3579, -0.1821,  0.0062, -0.0237,  0.0653,\n",
      "           0.0779, -0.1340, -0.0260, -0.0307, -0.1419, -0.2212,  0.1028,\n",
      "          -0.0469,  0.2262,  0.1286,  0.0246,  0.0450,  0.0645, -0.1143,\n",
      "          -0.0216, -0.1594,  0.1070,  0.0992, -0.0314, -0.0820, -0.0981,\n",
      "           0.1212,  0.1579, -0.1192,  0.1283, -0.1765,  0.0539, -0.0914,\n",
      "           0.1575,  0.1377, -0.1381, -0.2630,  0.0105, -0.0149,  0.2067,\n",
      "           0.0661,  0.1284,  0.1377, -0.0630, -0.0406, -0.0205, -0.0531,\n",
      "           0.2890,  0.0427, -0.0584,  0.0913, -0.0880,  0.1331,  0.2812,\n",
      "          -0.1354, -0.0579, -0.1702, -0.2494,  0.0914,  0.1517,  0.0413,\n",
      "          -0.0175,  0.1778,  0.1588, -0.1485,  0.1406, -0.1564, -0.0096,\n",
      "          -0.1908, -0.1820,  0.2039, -0.0340, -0.0979, -0.0274,  0.1515,\n",
      "          -0.1082,  0.1244, -0.0133, -0.1231,  0.1136, -0.2393, -0.0890,\n",
      "          -0.0559,  0.0881,  0.1919,  0.2167, -0.0120, -0.2136,  0.2449,\n",
      "           0.0755, -0.0757, -0.1208,  0.1167,  0.0522,  0.2794,  0.1095,\n",
      "          -0.0078,  0.1786, -0.1653,  0.1447, -0.1693,  0.2230,  0.1082,\n",
      "           0.2493, -0.2409,  0.0650, -0.2103, -0.0680,  0.0507,  0.1473,\n",
      "          -0.0342,  0.2250, -0.0602,  0.3995, -0.2329,  0.2038,  0.0243,\n",
      "           0.0743, -0.0258, -0.0341, -0.0907, -0.0503, -0.1757, -0.0983,\n",
      "          -0.1226,  0.1836,  0.0103,  0.0792, -0.1250,  0.3369, -0.0666,\n",
      "          -0.2374, -0.0143,  0.0858,  0.2358,  0.1989,  0.0138,  0.1294,\n",
      "          -0.1950,  0.0875, -0.1945,  0.0436,  0.1001, -0.0382,  0.1651,\n",
      "           0.0844, -0.0732, -0.1773,  0.0031,  0.0922, -0.2699,  0.0246,\n",
      "           0.0888,  0.0854,  0.0584, -0.2544, -0.0019, -0.0862, -0.0150,\n",
      "           0.0478,  0.0031,  0.2413, -0.2996, -0.0618,  0.0007, -0.0572,\n",
      "           0.0460,  0.0635,  0.0836,  0.0470, -0.1508, -0.1136,  0.0369,\n",
      "          -0.1162, -0.2968,  0.0580,  0.0270,  0.0808,  0.0532, -0.1680,\n",
      "          -0.2589,  0.0638,  0.1145, -0.1015, -0.2157, -0.0089, -0.0186,\n",
      "          -0.2598, -0.2180,  0.0695,  0.1324, -0.1132,  0.1118,  0.1466,\n",
      "          -0.0654,  0.0921,  0.0181, -0.0032,  0.0128,  0.0013,  0.2081,\n",
      "           0.2899, -0.1062,  0.0586, -0.0913, -0.1425, -0.1076,  0.1313,\n",
      "          -0.0832, -0.0777, -0.1845,  0.0637]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5946e-02,  3.9908e-01, -9.6646e-01, -6.8160e-01,  3.7619e-01,\n",
      "          -2.0188e-01,  1.4648e+00,  0.0000e+00, -3.5848e+00,  9.0671e-01,\n",
      "           4.2877e-01, -6.2915e-01,  2.6050e+00, -6.2978e-01, -5.4159e-01,\n",
      "          -1.5800e-01,  8.5146e-01,  0.0000e+00,  0.0000e+00,  4.3607e-01,\n",
      "           0.0000e+00, -3.8337e-01,  1.6417e+00,  1.5113e+00,  7.5365e-01,\n",
      "          -7.5396e-02, -1.8783e-01, -7.5921e-01,  1.6538e+00,  8.6169e-01,\n",
      "           1.2320e+00,  1.2191e+00,  0.0000e+00, -8.2693e-02, -1.5348e+00,\n",
      "           1.3953e+00,  2.8085e-01, -3.7453e+00,  1.9808e-01,  1.6012e+00,\n",
      "          -4.5888e-01, -1.3985e+00, -2.6840e-01, -1.7163e+00, -1.5245e+00,\n",
      "           6.6735e-01,  5.4096e-01,  3.7039e-01,  0.0000e+00,  1.4397e-01,\n",
      "          -6.2909e-01,  2.7528e+00,  6.1041e-01, -1.0294e+00, -2.5643e-02,\n",
      "           2.0318e-01, -8.8219e-01, -1.2528e+00, -2.3664e-01, -4.2531e-01,\n",
      "           1.1009e+00,  0.0000e+00, -2.0342e-01, -5.0169e-01, -2.9646e+00,\n",
      "           5.5062e-01,  1.2789e+00, -1.2881e+00,  4.1142e-01,  5.2645e-01,\n",
      "          -1.2672e+00, -3.0355e-02,  7.0742e-01, -3.6418e+00,  3.2613e-01,\n",
      "          -1.9749e-03, -1.5980e-01,  1.0628e+00,  0.0000e+00, -1.1980e-01,\n",
      "          -1.4004e+00,  0.0000e+00, -9.2478e-01,  1.0058e+00, -2.0781e-01,\n",
      "           4.3481e-01,  0.0000e+00, -9.7461e-01,  0.0000e+00, -5.8149e-01,\n",
      "          -2.2739e+00,  1.1003e+00, -6.2226e-01, -1.1354e+00,  4.6741e-01,\n",
      "          -1.1708e+00,  3.4152e-02,  6.2914e-01,  1.7204e+00,  0.0000e+00,\n",
      "           2.6975e+00, -1.4627e+00,  1.0761e+00,  1.4543e+00, -6.6643e-01,\n",
      "          -7.6264e-01,  1.2125e+00,  1.2736e-01, -1.4730e+00, -1.3171e-02,\n",
      "          -2.4875e-01,  1.3440e-01, -1.0485e+00,  1.3102e+00, -1.6536e+00,\n",
      "          -2.9899e+00, -5.6427e-02, -5.0106e-01, -1.9322e-01,  4.4494e-01,\n",
      "          -1.4667e+00,  7.0238e-01, -1.4608e+00,  0.0000e+00, -9.5858e-01,\n",
      "          -1.3091e+00,  8.9745e-01,  1.7035e-01,  1.2856e+00, -7.5251e-01,\n",
      "          -8.2341e-01,  5.2990e-01, -1.5834e+00,  9.8417e-01,  2.7614e-01,\n",
      "          -5.8964e-01,  6.5971e-01,  5.7391e-01, -1.1586e+00, -1.0104e+00,\n",
      "          -3.8881e-01,  6.7781e-01,  0.0000e+00, -1.0164e-01, -1.6861e+00,\n",
      "          -1.0113e-01,  0.0000e+00, -8.4451e-01, -7.5553e-01,  1.7747e-01,\n",
      "           1.9989e+00, -1.9973e-01, -1.9308e+00, -4.0620e-01,  4.4148e-01,\n",
      "          -1.9438e-01,  0.0000e+00, -1.2911e-01,  3.9369e-02,  5.3765e-01,\n",
      "          -2.6288e-02,  2.2066e+00,  4.8118e-01, -5.4986e-01, -5.2706e-01,\n",
      "          -8.9265e-01,  2.8172e-01,  8.4226e-02, -3.5800e-01, -4.7806e-01,\n",
      "           7.3775e-01, -3.2019e-02,  0.0000e+00, -1.0020e+00,  1.2778e+00,\n",
      "          -1.0989e+00, -9.8753e-01, -2.0774e+00,  1.9694e+00,  8.6404e-02,\n",
      "          -2.9983e-02,  3.5035e-02,  6.7146e-01,  9.7978e-01, -7.4705e-01,\n",
      "          -3.4094e-01, -2.7835e+00, -7.8439e-01,  1.2098e+00,  1.0125e+00,\n",
      "           3.0747e+00,  4.9441e-01, -1.4425e-01, -5.9450e-01,  0.0000e+00,\n",
      "           2.1655e+00,  0.0000e+00,  5.3489e-01,  1.8119e+00, -9.4731e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2419e+00, -1.2222e-01,  2.3196e-01,\n",
      "          -5.7535e-01, -2.2930e+00,  6.8184e-01, -1.0745e+00, -4.7133e-01,\n",
      "           2.8684e+00,  0.0000e+00, -3.4120e-01,  7.9321e-01,  3.0072e-02,\n",
      "          -6.8464e-01, -1.0192e+00,  9.6635e-01, -2.4573e-01,  2.1696e+00,\n",
      "          -1.0829e+00, -4.2755e-01, -1.8440e+00, -5.0130e-01,  3.3759e-01,\n",
      "           7.0494e-01, -6.9660e-01, -6.2814e-01,  2.9223e-01, -1.5787e+00,\n",
      "          -1.1087e+00,  1.5815e+00, -6.1426e-01,  1.3098e+00, -2.9801e+00,\n",
      "           4.0360e+00,  5.8520e-01,  4.3404e-02, -1.5802e+00, -2.8741e-01,\n",
      "           7.4167e-01, -3.2486e+00, -3.0454e-01, -8.5234e-01,  1.1189e-02,\n",
      "           2.7539e-01,  2.7494e-01,  2.5253e-01,  2.6102e-01,  3.8666e-01,\n",
      "          -3.6556e-01,  0.0000e+00, -5.5407e-01, -5.2598e-02, -1.1470e+00,\n",
      "          -1.1314e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0427, 0.0576, 0.0925, 0.0605, 0.1120, 0.3038, 0.0525, 0.0901, 0.0663,\n",
      "         0.1219]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-3.4926e-02, -1.3870e-01, -2.0817e-01,  1.0614e-01, -4.8985e-02,\n",
      "           8.8758e-02, -2.3253e-01, -2.9129e-01,  2.0415e-01, -1.0684e-01,\n",
      "           9.9532e-02, -8.6319e-02, -1.1264e-01, -2.9087e-02,  1.2280e-02,\n",
      "           3.8174e-03, -1.3959e-01,  1.9749e-01, -4.0491e-01,  4.8604e-01,\n",
      "          -4.0959e-01, -2.1280e-01,  3.1628e-01,  2.1230e-01,  9.5341e-05,\n",
      "          -1.2405e-01, -1.0469e-02, -2.6885e-01, -2.8419e-01,  1.6649e-02,\n",
      "           1.6385e-01, -1.9058e-01,  8.5637e-02, -2.0799e-01,  2.8816e-01,\n",
      "          -2.2330e-01, -4.4027e-02,  1.3659e-01, -7.3119e-02, -5.0918e-02,\n",
      "           2.7082e-01, -1.1480e-01, -3.5651e-02, -2.9240e-02,  1.0384e-01,\n",
      "          -7.9398e-02,  1.7662e-01, -1.3026e-01,  2.5028e-01, -1.7110e-01,\n",
      "          -1.9774e-01, -7.6341e-02, -4.4476e-01, -1.5221e-01, -1.7991e-01,\n",
      "           1.2821e-02,  1.1201e-02,  2.7409e-02, -3.6716e-02,  4.7256e-02,\n",
      "          -1.0281e-02, -3.4094e-01, -3.1351e-01,  1.8938e-01,  1.1800e-01,\n",
      "           1.8476e-01, -3.3232e-01,  2.3090e-02, -1.3274e-01, -4.6310e-02,\n",
      "           1.9084e-01,  9.3816e-02, -5.1869e-02,  4.5168e-02,  5.2655e-03,\n",
      "           8.4251e-02,  2.6605e-01,  8.2061e-02, -5.2701e-02,  4.6685e-02,\n",
      "          -2.6705e-01,  1.0570e-02, -3.3493e-01, -1.4574e-01, -9.1807e-02,\n",
      "           1.8678e-01,  6.6184e-02, -3.9014e-02, -1.1310e-01, -1.1614e-01,\n",
      "          -1.0833e-02, -2.1864e-02, -3.8721e-02, -9.4711e-02, -1.3377e-01,\n",
      "           2.2875e-01, -1.1954e-01,  2.1391e-01,  2.5492e-01, -9.2014e-02,\n",
      "          -7.7651e-03,  9.1858e-02,  3.2078e-01,  6.9994e-02, -6.2846e-02,\n",
      "          -7.3070e-02,  7.6942e-02,  1.4278e-01,  1.1298e-01,  8.7577e-02,\n",
      "           4.8011e-01,  1.0114e-02,  8.4872e-03, -1.0024e-01,  2.8306e-03,\n",
      "          -2.3081e-01, -4.9047e-02, -2.3138e-01, -6.8282e-02, -7.6070e-02,\n",
      "           1.0833e-01, -2.4629e-02, -1.0734e-01,  2.2444e-02, -1.9077e-01,\n",
      "           5.1068e-02, -1.0804e-01, -2.8932e-01, -4.0281e-02, -1.6474e-01,\n",
      "          -1.1341e-01, -2.5332e-01,  2.1011e-01,  1.1433e-01, -2.0089e-01,\n",
      "           2.2068e-01,  3.8744e-01,  1.7808e-01, -4.2941e-01,  4.1240e-02,\n",
      "          -1.3102e-01,  3.7825e-01, -3.6042e-01,  1.8297e-01,  1.2154e-01,\n",
      "          -7.3588e-02,  2.2573e-02,  2.1928e-01,  1.5139e-01,  1.3223e-01,\n",
      "          -1.7442e-01, -1.2259e-01, -1.2046e-01, -1.2619e-01,  3.3205e-02,\n",
      "           3.3337e-01,  1.7744e-02,  2.0812e-01, -1.3442e-01, -2.5713e-02,\n",
      "          -6.3145e-02,  5.8310e-02, -7.2446e-02,  2.2424e-01, -2.7008e-01,\n",
      "           3.0219e-02, -1.0259e-01, -9.5389e-02, -1.1135e-02,  1.2485e-01,\n",
      "          -3.0798e-01,  2.5994e-01,  2.0835e-01, -9.4028e-02, -1.2216e-02,\n",
      "          -1.7199e-01,  2.2506e-01,  1.4529e-01,  3.4209e-01, -9.5840e-02,\n",
      "          -2.1154e-01, -2.6036e-01, -1.0247e-01,  1.0953e-01,  1.1343e-01,\n",
      "           1.4422e-01,  1.2376e-01,  7.9944e-02, -2.2357e-01, -3.3394e-01,\n",
      "          -2.3964e-01,  1.8727e-01, -6.8485e-02, -2.3997e-01,  1.6404e-02,\n",
      "          -7.7557e-02,  2.3166e-01, -6.4289e-02, -4.4963e-02, -7.0917e-02,\n",
      "          -4.4398e-02,  2.6861e-02, -1.7919e-01,  4.4699e-01,  2.0639e-01,\n",
      "          -1.1002e-01,  1.9057e-01,  3.9301e-01,  9.8775e-03,  9.2469e-02,\n",
      "           1.0448e-01, -1.3764e-01, -1.8241e-01,  1.4949e-01, -2.0680e-02,\n",
      "           2.6496e-01,  1.2360e-01,  2.1499e-01,  7.3373e-02,  1.3207e-01,\n",
      "           6.0688e-02, -4.0532e-01,  2.4383e-01, -9.6300e-02, -1.3648e-01,\n",
      "          -2.7436e-02,  1.7384e-01, -2.5384e-01, -2.8316e-01,  3.5557e-01,\n",
      "          -2.3525e-01, -2.1509e-02, -2.3655e-02,  9.4818e-03, -5.3540e-02,\n",
      "           8.6176e-02, -1.5068e-04,  5.8376e-02,  3.3466e-01,  1.6229e-01,\n",
      "          -9.0939e-02,  1.2880e-01,  2.2844e-01, -1.1704e-01,  8.4557e-02,\n",
      "          -5.9898e-02, -1.8027e-01, -1.4143e-01, -1.3419e-01, -5.9688e-02,\n",
      "           1.7231e-01,  6.0598e-02, -1.0408e-01, -2.5165e-02,  1.4901e-01,\n",
      "          -1.6909e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4747, -0.4593, -1.2340, -0.1176,  0.4619,  0.0254,  0.6623,\n",
      "           0.5340,  0.6704,  0.9337,  1.7087, -1.0165,  0.9473, -0.2518,\n",
      "          -1.6345,  0.5130,  1.8780, -0.7565, -1.5627, -2.6441, -1.1340,\n",
      "           0.1679,  2.9302,  0.5544, -0.1167,  3.2100,  1.8374,  0.5193,\n",
      "          -2.2262, -1.2856,  0.0295,  1.0135,  0.3245,  0.8604, -0.7990,\n",
      "          -1.4657,  0.6199, -0.7715,  1.9919,  0.0000,  0.4676, -2.2045,\n",
      "          -0.5666, -0.1155, -0.7133, -0.6897,  1.9282,  0.1099, -0.2871,\n",
      "          -1.8508,  1.4684,  0.4634,  0.6678, -0.2838,  0.5317,  0.2748,\n",
      "          -1.2420, -0.9518,  1.8148, -0.0116,  0.2047, -1.8179, -1.4021,\n",
      "          -0.8066,  1.1795,  0.2652, -0.1665, -0.2562, -0.0041,  0.0000,\n",
      "          -0.3253, -0.3246,  0.1475,  0.0000,  0.0000, -0.8066,  2.0662,\n",
      "           1.6804,  0.0877, -0.5467,  1.2272,  0.0875,  0.3272, -1.8368,\n",
      "           0.0000, -1.7331, -1.4584, -0.8910,  0.6233,  0.8107, -1.2239,\n",
      "          -1.1446,  1.9856, -0.3656, -0.7340,  0.1565,  2.1423, -0.4056,\n",
      "          -0.3041, -1.8397, -1.2905, -0.7221, -0.7665,  0.2383,  0.3821,\n",
      "           1.1138, -1.0696,  2.2531, -0.2628, -0.2879, -0.0533,  0.0000,\n",
      "          -0.2557, -0.2803, -1.9428,  1.1283,  1.0061, -2.4987, -0.5744,\n",
      "           0.0298, -1.6957, -0.4014, -0.3799, -0.0792, -0.5373, -1.1119,\n",
      "           1.3056,  0.1702,  0.0000,  1.3584,  0.0000, -2.6345,  0.3584,\n",
      "          -0.7229,  0.4298,  0.0596,  0.3273, -2.1034, -0.4968, -1.6781,\n",
      "          -0.6424,  0.0000, -1.1874,  0.0000, -0.6316, -0.0411,  0.4651,\n",
      "           0.0000,  1.5938,  1.4316, -1.2628, -0.5776, -0.4803, -0.0395,\n",
      "           0.3270, -0.1162,  1.3541,  0.0000, -1.9010, -1.8060, -1.4271,\n",
      "          -0.9003, -0.7053, -0.3892, -0.9823,  0.0000,  0.4064,  0.0000,\n",
      "           0.5179, -0.1472,  1.5152, -0.3732, -0.3160, -2.0088,  0.1287,\n",
      "          -0.3526, -0.8315, -0.7700, -0.0397, -0.9380,  0.7282,  1.0422,\n",
      "           0.0471,  0.4633,  0.3168, -0.1179, -0.5428, -0.6645,  0.7556,\n",
      "          -1.0645, -0.5860,  0.0000,  0.0000, -0.9269, -1.6148, -0.3331,\n",
      "          -1.1572, -1.9611, -0.0720,  0.0000,  2.6986, -0.9216, -2.6328,\n",
      "          -0.5862, -0.7171,  0.0000,  0.0000,  0.1721,  0.2183, -1.1115,\n",
      "           0.9457, -0.6919, -1.5200,  0.3626,  0.2370, -1.4274, -2.3455,\n",
      "           0.0469, -1.4806,  0.4280,  0.0133, -0.9023,  0.3007,  0.0000,\n",
      "          -1.3024, -0.1875,  1.2725,  1.2667, -2.1883,  0.0000,  0.0000,\n",
      "          -1.1753,  0.9566,  1.9992,  0.5267,  0.7904, -0.6786,  0.1046,\n",
      "          -0.6809, -2.2628,  0.1676, -0.3149, -1.0436, -0.3820, -1.0803,\n",
      "           0.5584,  1.5006, -0.5648, -1.3778,  1.2436,  0.5824,  1.7536,\n",
      "           1.9512,  0.3623,  0.4868,  0.3905]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0195, 0.2600, 0.0838, 0.0473, 0.1157, 0.1431, 0.0257, 0.1908, 0.0747,\n",
      "         0.0394]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-9.8751e-02, -1.4301e-01, -2.1867e-01,  1.1769e-01, -6.7840e-02,\n",
      "           4.0395e-02, -2.8976e-01, -2.3007e-01,  1.3794e-01,  3.7401e-02,\n",
      "          -2.6465e-02,  6.4558e-02, -9.5344e-02,  1.1836e-01,  6.4710e-02,\n",
      "           1.6519e-01, -5.7363e-02,  2.0947e-01, -2.7330e-01,  4.5803e-01,\n",
      "          -3.5046e-01, -1.2601e-01,  3.3146e-01,  2.1346e-01,  2.1633e-02,\n",
      "          -1.0905e-01,  1.8306e-02, -2.3896e-01, -1.6054e-01,  2.3738e-02,\n",
      "           1.3915e-01, -4.2962e-04,  1.4266e-01, -6.9057e-02,  2.3637e-01,\n",
      "          -2.2848e-01,  1.3195e-01,  9.0568e-03, -5.0402e-02, -8.3608e-02,\n",
      "           1.5596e-01, -2.0275e-01,  1.0707e-01, -5.0275e-03,  3.0900e-02,\n",
      "           8.6893e-04,  2.1943e-01, -2.1657e-02,  2.3097e-01, -4.0193e-02,\n",
      "          -2.0324e-01,  7.4958e-02, -3.3108e-01, -1.3142e-01, -4.3356e-03,\n",
      "           1.5266e-01, -1.6774e-02,  7.8587e-02, -5.5684e-02, -5.0209e-02,\n",
      "           4.1923e-02, -3.1971e-01, -1.0865e-01,  1.4312e-01,  6.6250e-02,\n",
      "           3.3288e-01, -3.0509e-01,  7.9449e-02, -1.5050e-01, -2.9820e-02,\n",
      "           2.2897e-01,  7.0447e-02, -4.4704e-02,  8.0080e-02,  1.1156e-01,\n",
      "           8.0144e-02,  1.3874e-01,  7.8037e-02, -9.9848e-02,  9.7506e-03,\n",
      "          -1.9399e-01,  9.6958e-02, -1.9867e-01, -1.1606e-01, -4.3551e-02,\n",
      "           2.0793e-02,  2.8499e-03, -1.2675e-03, -1.3217e-01, -1.0446e-02,\n",
      "           7.4343e-02, -8.8326e-02, -5.2070e-02, -4.7507e-02, -8.1333e-02,\n",
      "           1.8912e-01, -2.0594e-01,  1.2738e-01,  1.5598e-01, -1.9544e-01,\n",
      "           8.1490e-02,  1.6661e-01,  2.7213e-01, -5.1449e-03, -1.4258e-01,\n",
      "           3.3034e-02, -5.6475e-02,  9.3153e-02,  2.5483e-02, -5.2709e-02,\n",
      "           4.4831e-01,  3.3634e-02,  2.1605e-02, -1.4009e-02,  6.9514e-02,\n",
      "          -3.2116e-01,  7.1769e-02, -2.1903e-01,  5.2668e-02,  8.0698e-02,\n",
      "          -2.7774e-02, -1.0170e-01, -1.2820e-01, -4.5260e-02,  6.2995e-04,\n",
      "           6.8824e-02, -5.4025e-02, -2.2044e-01, -1.1407e-01, -9.7290e-02,\n",
      "          -1.6228e-01, -6.1215e-02,  1.0383e-01,  1.0639e-01, -1.6884e-01,\n",
      "           1.3516e-02,  3.3502e-01,  9.7407e-02, -3.4486e-01,  1.2278e-01,\n",
      "          -1.0674e-01,  3.1738e-01, -3.6970e-01,  2.0080e-01,  8.8017e-02,\n",
      "          -5.5135e-02, -4.8292e-02,  1.4044e-01,  2.7713e-01, -2.1379e-02,\n",
      "          -1.4883e-01, -4.3699e-02, -1.0360e-01, -3.9670e-02, -6.8315e-02,\n",
      "           3.0419e-01,  1.3054e-01,  1.0110e-01, -1.0835e-01,  5.5393e-02,\n",
      "          -3.8141e-02,  1.1408e-01,  3.0146e-03,  1.2312e-01, -2.9985e-01,\n",
      "          -5.1755e-02, -1.5068e-01, -3.1556e-02, -3.5616e-02,  6.3937e-02,\n",
      "          -1.8506e-01,  2.4484e-01,  4.3056e-02, -6.0497e-02,  1.5830e-03,\n",
      "          -7.8510e-02,  2.6017e-01,  1.5516e-01,  3.1297e-01, -1.8090e-01,\n",
      "          -1.9280e-01, -3.1049e-01, -1.0912e-01,  1.3675e-01,  1.0610e-01,\n",
      "           3.5655e-02,  2.2993e-01, -7.0712e-02, -2.1065e-01, -2.5622e-01,\n",
      "          -1.2225e-01,  1.9753e-01, -1.2350e-01, -2.1697e-01,  5.7112e-02,\n",
      "           7.8947e-02,  2.8558e-01, -3.0502e-02,  3.4543e-02, -5.1139e-02,\n",
      "           9.9068e-03, -8.4834e-02, -2.5599e-01,  3.1833e-01,  2.2381e-01,\n",
      "          -4.8853e-02,  2.0999e-01,  2.6605e-01,  3.1623e-02,  8.6027e-02,\n",
      "           7.2525e-03,  4.2846e-02, -1.6516e-01,  1.6452e-01, -8.3188e-03,\n",
      "           2.2724e-01,  1.2615e-01,  1.1581e-01,  3.2628e-03,  5.9070e-02,\n",
      "           6.3084e-02, -3.9335e-01,  3.1515e-01, -2.0150e-01, -1.5152e-01,\n",
      "          -4.6470e-02,  1.8612e-01, -1.9239e-01, -2.1511e-01,  3.0683e-01,\n",
      "          -2.2505e-01,  9.3119e-02,  4.2542e-02,  5.7744e-02,  8.0177e-02,\n",
      "           8.4682e-02,  7.5561e-02,  8.4473e-02,  2.6032e-01,  1.4032e-01,\n",
      "           2.1427e-02,  2.1064e-01,  2.3334e-01, -4.6870e-02,  1.6080e-02,\n",
      "          -1.2840e-02, -1.5460e-01,  3.6991e-03, -1.6130e-01, -7.7176e-02,\n",
      "           1.5035e-01, -1.0241e-01, -1.0563e-01,  3.8671e-02,  1.8385e-01,\n",
      "          -1.4731e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00, -6.9819e-02,  0.0000e+00,  1.3220e+00,  5.1607e-01,\n",
      "          -3.7637e-01,  1.2139e-03, -7.2328e-01,  2.1179e+00, -2.1397e-01,\n",
      "           2.8238e-01,  8.3067e-01,  0.0000e+00,  1.9996e-01,  3.1221e-01,\n",
      "           3.5178e-01, -6.8298e-01,  1.6906e-01,  0.0000e+00,  5.4573e-01,\n",
      "           1.8833e+00,  6.0182e-01, -3.6693e-02, -5.3538e-01, -9.9931e-02,\n",
      "           6.5077e-01, -1.6087e+00, -1.3624e+00, -2.1269e+00, -1.0343e+00,\n",
      "           3.8987e-02, -1.4548e+00, -2.0764e+00,  3.1559e-01, -2.8492e-01,\n",
      "          -2.0018e+00,  2.1914e-01,  9.9693e-01,  6.0106e-01,  9.5371e-01,\n",
      "          -2.2534e-01, -2.2112e+00, -7.0642e-01,  1.3962e+00,  8.9472e-02,\n",
      "          -1.1385e+00,  2.4254e-01,  7.4181e-01,  0.0000e+00, -1.3358e+00,\n",
      "           1.6089e+00, -1.3727e-01,  6.6295e-01,  1.1163e+00,  5.6739e-01,\n",
      "           3.3339e-01, -4.4976e-01, -8.8830e-01,  1.3369e-01,  6.2850e-01,\n",
      "          -7.0520e-01,  5.6363e-01,  0.0000e+00, -1.5472e+00,  2.8935e-01,\n",
      "           9.5689e-02,  0.0000e+00,  5.9467e-01, -2.1383e+00,  5.5968e-01,\n",
      "           1.8295e-01, -5.1251e-01, -3.4122e-01, -1.1318e+00, -6.4725e-01,\n",
      "           4.6086e-01, -1.0495e+00,  1.1902e-01,  5.1729e-01, -1.8671e-01,\n",
      "          -3.8488e-01,  2.1581e+00,  7.7755e-01, -8.4565e-01,  0.0000e+00,\n",
      "           4.1925e-01,  1.6044e+00, -5.6416e-01, -1.4134e+00, -1.4906e+00,\n",
      "           4.0435e-01, -3.5173e-01,  0.0000e+00, -2.3209e+00,  1.2379e+00,\n",
      "          -9.6281e-01,  0.0000e+00, -9.0764e-01,  2.3909e+00,  9.5536e-01,\n",
      "          -1.2011e+00,  5.9446e-01,  1.0665e+00, -1.7337e+00,  3.6538e-01,\n",
      "           4.0221e-01, -1.2707e+00,  4.5513e-01,  1.9686e+00,  1.4939e-01,\n",
      "          -8.3213e-01,  5.3386e-01,  8.0820e-01,  6.6416e-01, -1.0547e+00,\n",
      "           9.1755e-01, -7.0271e-01, -8.4523e-01,  2.5783e-01,  8.7977e-01,\n",
      "          -8.7669e-01, -1.3968e+00, -3.6488e-01, -1.8465e+00, -1.3007e+00,\n",
      "           1.0693e+00, -8.1168e-01,  6.4921e-01,  2.5577e-01, -1.4894e+00,\n",
      "           2.5024e+00,  3.7792e-01, -1.3458e+00,  7.2241e-01,  3.2014e+00,\n",
      "          -7.5270e-01, -3.8351e-01,  1.2823e+00,  2.2522e+00,  1.9405e-01,\n",
      "          -3.9417e-02,  3.0304e+00,  3.6274e-01, -1.8698e-01, -1.1118e+00,\n",
      "           1.2472e+00,  7.7544e-01, -7.7461e-01, -4.5052e-02, -1.3874e+00,\n",
      "           2.3360e+00,  7.6462e-01, -2.8962e-01, -2.1307e+00,  0.0000e+00,\n",
      "           7.8588e-01, -1.8620e+00, -1.3047e+00,  1.9021e-01, -3.6290e+00,\n",
      "          -1.8685e+00,  1.1506e+00, -8.5947e-01,  9.5970e-01, -1.4614e+00,\n",
      "          -2.7135e-02,  1.9743e+00,  1.1271e+00, -4.8606e-01, -1.2414e+00,\n",
      "          -2.1204e-01, -1.3224e+00, -1.6393e+00, -7.7184e-01,  6.8262e-01,\n",
      "          -1.3796e+00, -1.2624e-01,  6.0667e-01, -7.4863e-01,  2.5912e-01,\n",
      "           1.3325e+00, -2.5535e+00,  2.7783e-01, -5.8386e-01,  1.6236e+00,\n",
      "          -1.2403e+00, -1.7536e-03, -5.0152e-02,  9.0145e-01,  5.6572e-01,\n",
      "          -4.1991e-01,  3.8807e-01, -1.1626e-01,  8.0962e-01,  1.0504e+00,\n",
      "          -7.8916e-01, -1.4388e+00,  0.0000e+00, -7.5046e-01,  0.0000e+00,\n",
      "           0.0000e+00,  7.2228e-01, -1.8536e+00,  1.3574e+00,  8.3777e-01,\n",
      "          -1.5241e+00, -3.5873e-01,  6.4793e-01,  2.0073e-01, -2.1784e+00,\n",
      "           8.3547e-01, -1.2912e+00, -1.2838e+00,  2.6106e-01, -1.5634e+00,\n",
      "           2.0757e+00,  1.3428e-01,  0.0000e+00, -3.1100e-02, -5.7937e-01,\n",
      "          -1.4285e+00,  1.9010e+00, -3.8089e-01,  0.0000e+00,  8.0513e-01,\n",
      "           3.6918e-01,  0.0000e+00, -7.0060e-01,  0.0000e+00,  1.0255e+00,\n",
      "           9.7816e-01, -1.4085e+00,  6.5967e-01, -1.1451e+00, -1.6455e+00,\n",
      "          -6.0024e-01,  8.9154e-03, -7.1113e-01,  3.7058e-01, -2.2431e-01,\n",
      "           0.0000e+00,  5.7214e-01,  5.3069e-01, -6.6347e-01,  1.5465e+00,\n",
      "           5.7850e-01,  1.8918e+00, -8.6434e-01,  4.9340e-01, -3.8736e-01,\n",
      "           0.0000e+00, -9.7534e-01,  1.7728e+00, -1.0634e+00, -8.0786e-01,\n",
      "          -6.2175e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0524, 0.1233, 0.1273, 0.1048, 0.1292, 0.1837, 0.0642, 0.0520, 0.0669,\n",
      "         0.0962]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0488, -0.1395, -0.2466,  0.0846, -0.0892,  0.0684, -0.2430,\n",
      "          -0.2712,  0.1681, -0.0937,  0.0510,  0.0019, -0.0999,  0.0403,\n",
      "           0.0568,  0.1034, -0.0826,  0.2200, -0.2814,  0.4504, -0.4019,\n",
      "          -0.1550,  0.3191,  0.1944,  0.0118, -0.1312, -0.0014, -0.2605,\n",
      "          -0.2447,  0.0027,  0.1522, -0.1316,  0.1321, -0.1826,  0.2904,\n",
      "          -0.2404,  0.0220,  0.1075, -0.0798, -0.0265,  0.2081, -0.1178,\n",
      "           0.0755, -0.0542,  0.0459, -0.0613,  0.2204, -0.0778,  0.2587,\n",
      "          -0.0988, -0.2155,  0.0262, -0.4003, -0.1573, -0.1124,  0.1009,\n",
      "           0.0197,  0.0305, -0.0368,  0.0405, -0.0157, -0.3163, -0.2125,\n",
      "           0.1410,  0.1042,  0.2493, -0.3190,  0.0027, -0.1149, -0.0702,\n",
      "           0.2234,  0.0868, -0.0286,  0.0149,  0.0266,  0.0819,  0.2120,\n",
      "           0.1443, -0.0732,  0.0128, -0.2524,  0.0472, -0.2381, -0.0998,\n",
      "          -0.0670,  0.0928, -0.0167, -0.0138, -0.1273, -0.1131,  0.0543,\n",
      "          -0.0341, -0.0198, -0.0907, -0.0732,  0.2323, -0.1445,  0.1813,\n",
      "           0.2422, -0.1256, -0.0051,  0.1715,  0.3103,  0.0487, -0.1437,\n",
      "          -0.0839, -0.0065,  0.0642,  0.0547,  0.0070,  0.4541,  0.0207,\n",
      "           0.0468, -0.0684,  0.0506, -0.2751, -0.0029, -0.1838,  0.0141,\n",
      "           0.0318,  0.0817,  0.0068, -0.0931,  0.0260, -0.0918,  0.0005,\n",
      "          -0.1036, -0.2539, -0.0539, -0.1615, -0.1179, -0.2137,  0.1707,\n",
      "           0.1283, -0.2240,  0.1607,  0.4079,  0.1226, -0.3693,  0.0643,\n",
      "          -0.0360,  0.3330, -0.3786,  0.2296,  0.1281, -0.0647, -0.0130,\n",
      "           0.1789,  0.1726,  0.0424, -0.1804, -0.0414, -0.1510, -0.0877,\n",
      "          -0.0112,  0.3022,  0.1186,  0.1706, -0.0732,  0.0148, -0.1268,\n",
      "           0.0428, -0.0956,  0.1466, -0.2687, -0.0218, -0.1608, -0.0217,\n",
      "          -0.0250,  0.1264, -0.2512,  0.2594,  0.1014, -0.0553, -0.0030,\n",
      "          -0.1086,  0.2570,  0.1307,  0.3600, -0.1588, -0.1563, -0.2928,\n",
      "          -0.0901,  0.0808,  0.0794,  0.0461,  0.1196,  0.0045, -0.1647,\n",
      "          -0.2814, -0.1867,  0.1803, -0.1225, -0.2222,  0.0191,  0.0619,\n",
      "           0.1993, -0.0666, -0.0158, -0.0583, -0.0282, -0.0191, -0.1787,\n",
      "           0.3850,  0.1561, -0.0923,  0.2345,  0.3367,  0.0121,  0.0344,\n",
      "           0.0915, -0.0630, -0.1557,  0.2189, -0.0330,  0.1973,  0.0807,\n",
      "           0.1997,  0.0459,  0.1444,  0.1210, -0.3724,  0.2950, -0.1330,\n",
      "          -0.1637, -0.0289,  0.2200, -0.2045, -0.2802,  0.3340, -0.2735,\n",
      "          -0.0384,  0.0409,  0.0317,  0.0051,  0.0763,  0.0343,  0.0422,\n",
      "           0.2894,  0.1941, -0.0181,  0.1551,  0.2188, -0.0945,  0.0616,\n",
      "          -0.0120, -0.2064, -0.0751, -0.1245, -0.0124,  0.2162,  0.0109,\n",
      "          -0.1136,  0.0337,  0.1131, -0.1648]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5702e+00, -1.4751e+00,  2.2743e-01, -7.8594e-02,  3.5246e-01,\n",
      "           5.5347e-01, -2.0049e-01,  2.0888e+00,  1.3115e+00, -1.0356e+00,\n",
      "           6.8480e-01,  2.1686e+00,  1.1881e+00,  0.0000e+00, -1.0885e-01,\n",
      "          -1.1277e+00,  1.9605e+00, -2.9140e-01,  8.4323e-03,  4.2650e-01,\n",
      "          -1.9755e+00, -1.8383e+00, -1.2584e+00,  1.9420e-01, -1.6706e-01,\n",
      "           1.3754e+00, -2.9788e-01, -9.7436e-01,  1.8410e+00,  0.0000e+00,\n",
      "           0.0000e+00,  3.1162e-01,  5.3681e-01,  9.4192e-01,  6.9770e-01,\n",
      "           4.5398e-01, -2.8990e+00,  6.7982e-02,  3.9893e-02,  1.2315e+00,\n",
      "          -7.2215e-01, -1.0137e+00,  2.4826e-01,  1.0036e+00,  6.7002e-02,\n",
      "           0.0000e+00, -1.0371e+00, -1.1820e+00, -4.4474e-01, -1.6405e+00,\n",
      "          -1.5658e+00,  0.0000e+00,  8.6338e-01,  7.6390e-01,  2.2064e+00,\n",
      "           5.5897e-01,  5.9266e-01,  5.6758e-01, -7.5501e-01,  4.1315e-01,\n",
      "           6.2638e-01, -7.1967e-01, -3.6505e-01,  8.9442e-01, -1.3381e+00,\n",
      "           2.3298e+00, -2.4167e+00,  9.2027e-02,  1.1605e+00, -7.1802e-01,\n",
      "           7.5209e-02,  5.5117e-01,  1.8998e-01,  2.3274e-02,  4.0860e-01,\n",
      "          -9.0035e-01, -4.8581e-01,  4.3277e-01, -1.3789e+00, -2.4958e+00,\n",
      "           0.0000e+00,  0.0000e+00,  4.9731e-01, -3.8147e-01, -2.3206e+00,\n",
      "           0.0000e+00, -6.3272e-01,  1.8183e+00, -1.9084e+00, -6.5422e-01,\n",
      "           0.0000e+00, -6.6938e-01, -1.9175e+00,  1.0181e+00, -1.3664e+00,\n",
      "          -1.1212e+00,  2.1709e-01,  1.7976e-02,  3.0409e-01,  7.6354e-01,\n",
      "           0.0000e+00,  9.3359e-01,  2.2433e-01, -1.6317e+00,  2.2439e+00,\n",
      "          -1.4418e-01,  0.0000e+00, -1.0130e+00, -1.2049e+00, -1.4857e+00,\n",
      "           0.0000e+00, -1.3434e+00,  1.5148e-01, -1.7880e+00, -1.1431e+00,\n",
      "          -1.0661e+00, -1.7873e+00, -1.2149e-01, -1.8688e+00,  9.3966e-02,\n",
      "           6.7204e-01,  5.5181e-01,  1.5532e+00,  4.8415e-01,  1.2906e-01,\n",
      "           0.0000e+00,  0.0000e+00,  5.8585e-02,  0.0000e+00, -5.9760e-02,\n",
      "          -8.6286e-02, -5.3683e-01,  7.0342e-01,  1.1586e+00,  3.2930e-01,\n",
      "          -2.5089e-01,  1.1910e-01, -1.3306e+00, -3.6596e-01, -7.7333e-01,\n",
      "          -5.9703e-01, -1.4722e+00,  0.0000e+00,  2.9618e-02,  5.0132e-01,\n",
      "           2.5941e-01,  1.2102e+00,  1.2554e+00,  6.3330e-01,  3.1595e-01,\n",
      "           7.8684e-02, -5.5444e-02, -7.0965e-01,  1.5831e+00,  0.0000e+00,\n",
      "           2.7982e-01,  1.1351e+00,  0.0000e+00,  2.6073e-01,  0.0000e+00,\n",
      "          -1.7485e-01,  6.8415e-01, -2.1212e-01, -7.2110e-01, -4.6788e-01,\n",
      "          -9.4147e-01,  3.2957e-01,  2.5662e-01,  1.7295e+00,  7.0256e-01,\n",
      "           3.1424e+00,  2.0556e+00,  5.6335e-01,  1.0304e-01, -3.9338e-01,\n",
      "          -9.6627e-01, -4.0510e-01,  1.1920e+00, -2.6508e-01, -1.5079e+00,\n",
      "          -1.3464e-01, -1.2929e-02, -6.0223e-01, -1.5680e+00, -1.8515e+00,\n",
      "          -1.6855e-01,  0.0000e+00,  1.3398e+00,  1.2952e+00,  7.3878e-01,\n",
      "           9.6799e-01,  0.0000e+00, -5.3607e-01,  5.3546e-01, -4.7116e-02,\n",
      "          -1.2979e+00, -1.5638e+00,  3.1397e+00,  0.0000e+00, -4.6135e-02,\n",
      "           8.1014e-01, -2.1875e+00, -2.6967e+00,  1.4469e+00, -9.9701e-01,\n",
      "           9.7211e-01, -1.6694e+00, -6.1197e-01, -9.3258e-01, -1.1370e+00,\n",
      "           8.7219e-01,  7.9562e-02, -1.3189e+00, -7.9111e-01,  1.3113e+00,\n",
      "          -2.8294e-01,  1.3732e+00,  2.4500e-01, -2.3518e+00,  1.9031e+00,\n",
      "           1.0278e+00, -1.4199e+00,  1.7823e+00,  1.0654e+00, -5.7295e-01,\n",
      "          -5.7353e-01, -1.5896e+00,  1.5794e-03, -3.3777e-01,  0.0000e+00,\n",
      "          -6.4344e-01,  1.5655e+00,  9.3264e-02, -6.2731e-01,  1.6770e+00,\n",
      "           2.2890e+00, -2.1839e+00,  0.0000e+00,  1.5120e+00, -5.3515e-01,\n",
      "          -1.8332e+00,  0.0000e+00, -1.1128e-01,  1.4428e+00, -4.7771e-01,\n",
      "           1.4840e+00, -5.8509e-01,  7.7600e-01, -1.4379e+00,  0.0000e+00,\n",
      "           4.3564e-01,  3.1981e-01, -3.3685e-01,  1.6171e+00,  2.5956e-01,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0664, 0.1614, 0.0504, 0.0997, 0.2267, 0.0656, 0.1119, 0.0870, 0.0693,\n",
      "         0.0615]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0893, -0.1735, -0.1923,  0.1611, -0.1040,  0.0913, -0.2680,\n",
      "          -0.2415,  0.0984, -0.0283, -0.0016, -0.0075, -0.0671,  0.0683,\n",
      "           0.0337,  0.1516, -0.0916,  0.2099, -0.2543,  0.4457, -0.3814,\n",
      "          -0.1070,  0.2828,  0.1758,  0.0192, -0.1059, -0.0045, -0.2601,\n",
      "          -0.1833, -0.0303,  0.1671, -0.0315,  0.1332, -0.1263,  0.2610,\n",
      "          -0.2638,  0.0879,  0.0771, -0.0122, -0.0689,  0.1702, -0.1039,\n",
      "           0.1640, -0.0583,  0.0425, -0.0565,  0.2453, -0.0319,  0.2245,\n",
      "          -0.0779, -0.3004,  0.0129, -0.3646, -0.1460, -0.0697,  0.1324,\n",
      "          -0.0531,  0.0760, -0.0946, -0.0293,  0.0386, -0.3101, -0.1602,\n",
      "           0.1455,  0.1431,  0.2795, -0.3245,  0.0206, -0.1158, -0.0790,\n",
      "           0.2643,  0.0681, -0.0121, -0.0303,  0.0462,  0.0184,  0.2037,\n",
      "           0.1700, -0.0679,  0.0082, -0.2123,  0.0487, -0.1644, -0.0661,\n",
      "          -0.0719,  0.0480, -0.0103,  0.0090, -0.1298, -0.0986,  0.0729,\n",
      "          -0.0437, -0.0128, -0.0957, -0.0565,  0.2138, -0.1585,  0.1117,\n",
      "           0.2604, -0.1311,  0.0191,  0.1768,  0.3232,  0.0159, -0.1310,\n",
      "          -0.0586, -0.1014,  0.0118,  0.0476, -0.0127,  0.4328,  0.0415,\n",
      "           0.1242, -0.0158,  0.0726, -0.3355, -0.0024, -0.1539,  0.0834,\n",
      "           0.1057,  0.0355, -0.0436, -0.0965, -0.0111, -0.0623,  0.0044,\n",
      "          -0.1068, -0.2400, -0.0425, -0.1285, -0.0911, -0.1338,  0.1473,\n",
      "           0.1467, -0.2568,  0.0615,  0.3573,  0.0633, -0.3343,  0.0697,\n",
      "          -0.0222,  0.3332, -0.3807,  0.2143,  0.0647, -0.0385, -0.0288,\n",
      "           0.1520,  0.1692,  0.0393, -0.1613, -0.0152, -0.1370, -0.0465,\n",
      "          -0.0211,  0.2665,  0.1593,  0.1107, -0.0728,  0.0648, -0.1638,\n",
      "           0.0757,  0.0118,  0.0991, -0.2980, -0.0355, -0.1200, -0.0262,\n",
      "          -0.0499,  0.1013, -0.1956,  0.2569,  0.0571, -0.0653,  0.0342,\n",
      "          -0.1064,  0.2797,  0.0828,  0.3125, -0.2118, -0.1545, -0.2235,\n",
      "          -0.1276,  0.0817,  0.0797,  0.0265,  0.1418, -0.0319, -0.1465,\n",
      "          -0.2089, -0.1713,  0.1575, -0.1288, -0.1986,  0.0020,  0.0749,\n",
      "           0.2624, -0.0564, -0.0307, -0.0505,  0.0295, -0.0665, -0.2291,\n",
      "           0.3706,  0.1861, -0.0575,  0.2403,  0.2841,  0.0313,  0.0171,\n",
      "           0.0525,  0.0224, -0.1632,  0.2234, -0.0648,  0.1711,  0.0335,\n",
      "           0.1760,  0.0483,  0.0525,  0.0689, -0.3576,  0.3533, -0.1732,\n",
      "          -0.1782, -0.0367,  0.1833, -0.1763, -0.2603,  0.3585, -0.2401,\n",
      "          -0.0687,  0.0346,  0.0164,  0.0316,  0.0842,  0.0537,  0.0551,\n",
      "           0.3115,  0.1783,  0.0090,  0.1372,  0.2078, -0.0353,  0.0225,\n",
      "          -0.0181, -0.1697, -0.0230, -0.1408, -0.0158,  0.1633, -0.0568,\n",
      "          -0.0654,  0.0878,  0.1279, -0.1432]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0507,  0.0000, -1.2214,  0.1080, -0.8038, -0.0744,  0.1358,\n",
      "          -1.0208, -0.3500,  0.6069,  0.5421,  1.4546,  0.1340, -1.7006,\n",
      "          -0.3715, -2.3566, -0.7013,  0.0000, -1.8744,  1.1428,  0.7345,\n",
      "          -1.9031,  0.4699,  0.7692, -0.3141, -0.4287, -0.3101, -0.2256,\n",
      "           0.0000,  0.0963,  1.4813, -2.2024,  0.8983,  0.0000, -0.7504,\n",
      "           2.4262,  1.0766,  0.1914, -0.3676,  0.0000,  0.3716, -0.4465,\n",
      "           2.2501, -1.2588,  1.5157, -0.3134,  0.7477, -1.1212, -0.3446,\n",
      "           0.1405, -0.7955,  1.7995, -0.7626, -0.4866, -0.4768,  1.2273,\n",
      "           0.4435,  1.6410, -0.8594,  0.1733, -1.4062,  0.6265, -2.4135,\n",
      "           0.0000, -0.5695, -0.6561, -0.2815,  0.0357, -1.5837,  1.6461,\n",
      "          -1.4249,  0.0000,  0.0000,  1.7224, -1.0821,  0.0000,  0.0090,\n",
      "           0.0000,  1.3214,  0.2863,  0.0000, -0.5739, -0.5292,  1.2607,\n",
      "          -1.1710,  2.7706,  0.0000, -0.3126, -0.3952, -0.6793, -0.6998,\n",
      "          -1.2072, -0.1374, -1.2539, -0.3586,  1.9074,  0.6110,  0.4665,\n",
      "           1.2742,  0.9408,  0.0986,  0.0000,  1.1925, -0.7315,  1.1344,\n",
      "          -2.1752,  0.5374,  2.2626,  0.5054,  1.8176,  1.3765, -0.3851,\n",
      "           1.0509,  0.5284,  0.0389,  0.0000,  0.7164,  0.0828, -0.4988,\n",
      "           0.0000, -1.9371, -0.1452,  0.3462,  0.9736,  0.0000, -0.0721,\n",
      "          -0.3567, -1.1980,  0.9572,  0.7302, -1.1508,  0.6041, -0.1354,\n",
      "          -1.7473,  0.5434, -1.1582, -1.1250, -0.1607,  0.6992, -1.1833,\n",
      "           1.1297,  0.3956,  1.8452, -0.8988,  1.9361,  0.7250, -1.1345,\n",
      "           0.2226,  0.9148,  0.5005, -0.6788,  0.0381,  0.4276,  0.0568,\n",
      "           1.2493,  0.8824, -1.2593, -1.2798,  0.0000, -0.6548, -0.0675,\n",
      "          -1.6398, -1.0454, -0.2558, -0.3493, -0.3369,  0.0187, -1.9615,\n",
      "           0.5776, -0.4899,  0.2925,  1.3032,  3.1645,  0.9586,  1.0212,\n",
      "          -1.0056,  0.7561,  0.0000,  0.4547, -0.8265,  0.9847, -1.4254,\n",
      "          -0.0713, -0.0151,  0.0000,  0.5258, -1.3847,  0.0000,  0.0000,\n",
      "           2.4804,  0.7481,  0.0000,  1.9217, -0.0911, -0.1427,  0.0000,\n",
      "          -0.1705, -1.1476,  1.9328,  1.4633, -0.1506, -0.2662,  0.7295,\n",
      "          -1.5531,  1.3349,  0.6863,  0.9932,  0.4499, -0.9492,  2.2194,\n",
      "          -0.8902,  0.8170,  0.1870,  0.4399,  1.7619,  0.3605, -0.9268,\n",
      "           1.2921, -0.4946, -0.2085,  0.2803, -1.9130,  0.6171, -0.6300,\n",
      "           0.0494,  0.0000,  0.0661, -0.5981, -0.4547, -0.3997,  1.0923,\n",
      "          -1.5175, -2.0323, -0.5675, -1.1072,  1.9827,  1.8105, -0.1327,\n",
      "           1.7837, -0.1125, -0.4887,  0.0000, -0.7952,  0.7567,  0.0000,\n",
      "          -1.6559, -0.2755, -0.4580, -0.5621,  0.6714,  0.0075, -0.2975,\n",
      "           0.0000,  0.6649, -2.0469, -0.1355]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0358, 0.0428, 0.0884, 0.0708, 0.1005, 0.2940, 0.0746, 0.1222, 0.1200,\n",
      "         0.0510]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-7.0934e-02, -1.8396e-01, -1.9291e-01,  1.0648e-01,  4.6731e-04,\n",
      "           1.3518e-01, -2.7501e-01, -2.7633e-01,  1.8179e-01, -1.0309e-01,\n",
      "           6.4169e-02, -6.7902e-02, -9.6487e-02, -2.4104e-02, -9.7545e-03,\n",
      "           2.6478e-02, -1.5034e-01,  1.7778e-01, -4.1143e-01,  4.8996e-01,\n",
      "          -3.6810e-01, -1.8741e-01,  3.0914e-01,  1.9484e-01,  4.6948e-02,\n",
      "          -7.1314e-02,  4.1497e-02, -2.4115e-01, -2.4056e-01,  4.0541e-02,\n",
      "           1.7443e-01, -1.3426e-01,  1.0951e-01, -1.7917e-01,  2.7892e-01,\n",
      "          -2.5383e-01, -3.0798e-02,  1.3847e-01, -2.0847e-02, -5.8541e-02,\n",
      "           2.7976e-01, -1.0017e-01, -1.0301e-02, -3.4486e-02,  5.7356e-02,\n",
      "          -9.8458e-02,  2.0538e-01, -7.3374e-02,  2.4248e-01, -2.0557e-01,\n",
      "          -1.9179e-01, -8.1767e-02, -4.2133e-01, -1.5866e-01, -1.8871e-01,\n",
      "           2.6299e-02,  1.1984e-02,  2.5728e-02, -5.4552e-02, -8.3367e-03,\n",
      "           1.3547e-02, -3.5505e-01, -2.9050e-01,  2.0250e-01,  1.2067e-01,\n",
      "           1.8897e-01, -3.4383e-01,  2.1819e-02, -1.2127e-01, -5.1543e-02,\n",
      "           1.9037e-01,  1.0461e-01, -3.5081e-02,  6.8231e-03,  4.1484e-02,\n",
      "           1.0844e-01,  2.6823e-01,  5.9818e-02, -4.6187e-02,  3.1404e-02,\n",
      "          -2.4668e-01,  6.7073e-02, -3.2012e-01, -1.3645e-01, -7.8799e-02,\n",
      "           1.8469e-01,  9.7765e-02, -4.7510e-02, -1.2880e-01, -7.9669e-02,\n",
      "          -1.9456e-03, -2.4291e-02, -8.5403e-02, -1.0535e-01, -1.3541e-01,\n",
      "           2.1367e-01, -1.4032e-01,  1.5536e-01,  2.9514e-01, -1.0554e-01,\n",
      "           7.1780e-02,  9.1025e-02,  3.0351e-01,  4.0400e-02, -1.6027e-02,\n",
      "          -5.9940e-02,  5.4209e-02,  1.4256e-01,  1.1820e-01,  8.5850e-02,\n",
      "           4.5829e-01,  4.1058e-02, -2.3807e-03, -9.9151e-02,  5.1391e-02,\n",
      "          -2.3716e-01, -3.4730e-02, -2.2600e-01, -6.2583e-02, -4.7871e-02,\n",
      "           9.6036e-02, -2.3844e-02, -1.1245e-01,  7.1853e-03, -1.9793e-01,\n",
      "           6.5244e-02, -1.1464e-01, -2.9259e-01, -6.4878e-02, -1.6774e-01,\n",
      "          -1.5176e-01, -1.9837e-01,  1.6930e-01,  1.0384e-01, -1.9137e-01,\n",
      "           1.9161e-01,  3.3765e-01,  1.9642e-01, -4.1792e-01,  5.0827e-02,\n",
      "          -1.5309e-01,  3.7267e-01, -3.5063e-01,  1.3023e-01,  7.6603e-02,\n",
      "          -7.5399e-02,  3.4542e-02,  2.2127e-01,  1.4643e-01,  1.1153e-01,\n",
      "          -1.6319e-01, -1.1859e-01, -1.4182e-01, -1.3544e-01,  5.0109e-02,\n",
      "           3.2743e-01,  2.9421e-02,  2.0770e-01, -1.6393e-01,  1.3396e-02,\n",
      "          -4.5094e-02,  1.1223e-01, -1.3179e-02,  2.0472e-01, -3.4177e-01,\n",
      "          -5.0692e-03, -1.0872e-01, -7.3001e-02, -6.6849e-02,  5.3747e-02,\n",
      "          -3.0110e-01,  2.4841e-01,  2.0804e-01, -6.2135e-02, -1.5904e-02,\n",
      "          -1.8627e-01,  2.4635e-01,  1.1489e-01,  3.1224e-01, -1.0900e-01,\n",
      "          -2.2609e-01, -2.2757e-01, -1.0884e-01,  1.2274e-01,  1.2350e-01,\n",
      "           1.1993e-01,  2.1332e-01,  5.1590e-02, -2.8631e-01, -3.1001e-01,\n",
      "          -2.4282e-01,  1.7362e-01, -1.8667e-02, -2.2229e-01, -1.5911e-02,\n",
      "          -7.2028e-02,  2.7674e-01, -4.2741e-02, -4.0801e-02, -8.4721e-02,\n",
      "          -9.4188e-03, -6.3460e-03, -1.8773e-01,  4.2753e-01,  1.7817e-01,\n",
      "          -1.0066e-01,  1.8369e-01,  3.7837e-01,  1.4075e-02,  9.7249e-02,\n",
      "           4.8001e-02, -9.5166e-02, -1.9103e-01,  1.1198e-01, -1.3465e-02,\n",
      "           2.2699e-01,  1.9621e-01,  1.9350e-01,  9.4937e-02,  2.9218e-02,\n",
      "           1.9900e-02, -3.7857e-01,  2.3648e-01, -8.2027e-02, -1.4534e-01,\n",
      "          -4.1180e-02,  1.3208e-01, -2.6351e-01, -2.6817e-01,  3.3989e-01,\n",
      "          -2.0220e-01, -3.3172e-02, -4.7728e-02,  4.7224e-02, -2.3462e-02,\n",
      "           7.0415e-02,  1.3699e-02,  7.9021e-02,  3.4491e-01,  1.5251e-01,\n",
      "          -7.8472e-02,  1.4603e-01,  2.9001e-01, -7.8760e-02,  8.9650e-02,\n",
      "          -8.3971e-02, -1.4514e-01, -1.2044e-01, -1.9166e-01, -1.1185e-01,\n",
      "           1.5183e-01,  5.8670e-02, -4.3993e-02, -2.6940e-02,  1.8219e-01,\n",
      "          -1.6678e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1716,  2.2165,  0.1178,  0.1084,  0.0000,  0.5949, -2.4006,\n",
      "           1.0327,  0.3783,  0.8371,  0.5755, -0.8234,  0.3605, -1.1043,\n",
      "           0.3660,  1.3475, -1.4909,  1.4502,  1.1970, -1.0120,  3.2072,\n",
      "           0.0000,  0.4219,  0.5880, -0.0791, -0.7454,  2.1829, -0.6690,\n",
      "           1.0300,  1.1227, -0.0482,  0.1381,  1.6808,  1.5776, -0.4095,\n",
      "          -0.5379, -0.2042, -1.8282,  3.1514,  0.4607,  1.3961, -0.9189,\n",
      "          -0.1389, -0.9999,  2.4246, -1.2481,  0.1430, -0.3118, -0.2347,\n",
      "          -0.2283, -1.8523, -0.7112, -0.3607, -2.1675, -1.0361,  0.0000,\n",
      "          -0.7650,  0.6167,  0.3321, -0.4505,  0.0000,  1.6134,  1.1452,\n",
      "           0.4676,  0.0997,  0.2068, -0.4711,  0.2687, -2.3582, -0.0916,\n",
      "           0.4628,  0.1484,  1.4338, -0.5919, -0.0667,  0.7244, -1.0018,\n",
      "           0.2845,  1.5414, -0.0298,  0.7441,  0.9256, -1.3774,  0.4664,\n",
      "           1.5270, -0.7973, -0.4792, -2.2059,  0.3723, -0.0535,  0.7314,\n",
      "           0.1630, -0.3994,  0.1744, -1.6439, -0.3950, -1.1385, -0.5805,\n",
      "           0.0000, -0.6414, -2.2939, -1.5493,  0.4524,  0.7300,  0.1953,\n",
      "          -1.3725, -0.4642, -0.4460, -1.0968,  0.0000,  0.0000,  1.9003,\n",
      "          -0.5994,  1.5085, -0.8129,  1.7866,  0.3487, -1.1691,  0.1064,\n",
      "           0.1202, -0.6061,  0.0000, -1.6116, -0.8294,  2.3661,  0.2559,\n",
      "           1.4513,  0.9299,  1.1321,  0.7115,  0.2847, -0.0145, -0.1305,\n",
      "          -0.1819,  0.5761,  1.4671, -0.4071, -0.8417, -0.7624,  0.0000,\n",
      "           0.9348, -0.6616,  0.0000,  0.6701, -0.0212, -0.6349,  0.4520,\n",
      "           0.9472,  0.1921, -0.2285,  3.6485,  0.6671,  0.0000, -2.5228,\n",
      "           0.0000, -0.6343,  0.0000, -1.1647, -0.6014,  0.1636, -1.6695,\n",
      "           0.1427,  0.1804,  0.2418, -2.4428, -0.4985, -0.6459,  1.0139,\n",
      "          -0.0749,  0.2802, -0.3944, -1.6191,  1.4116, -0.2716,  1.0259,\n",
      "          -0.0727,  0.3784,  0.4722, -1.3219,  0.9365,  0.4939,  0.7239,\n",
      "          -0.4106, -0.5028, -1.9863,  0.0471, -1.6681, -0.0473, -0.6446,\n",
      "          -0.4006,  0.0000,  0.0000,  0.1948,  0.0000, -0.9252,  0.0000,\n",
      "           0.0000, -0.8688, -0.0583,  1.3622, -0.2734,  0.0000, -1.3526,\n",
      "           1.2104,  0.4851,  0.4681, -1.7813, -1.4653,  1.3109,  0.1645,\n",
      "           0.4907, -0.6393,  0.2324, -0.2071,  0.3968,  1.5840,  1.4204,\n",
      "           0.0584,  0.0000,  2.0493,  0.1219,  0.2846,  1.0993, -0.0715,\n",
      "           0.0000, -0.3818,  0.0000, -0.3474,  0.7364,  1.1195, -1.2105,\n",
      "          -0.3962, -2.0880, -0.8841, -1.8136, -0.5054,  0.6672, -0.9863,\n",
      "          -1.2767,  2.0416,  0.4494,  0.0000, -1.1030,  2.8844, -0.4368,\n",
      "           0.7500, -0.7638,  0.6774,  0.6577,  0.0631,  0.0000, -1.5726,\n",
      "          -0.6507,  0.8922, -0.6515, -0.1560]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0307, 0.1018, 0.2013, 0.0923, 0.1233, 0.1072, 0.0904, 0.0952, 0.1033,\n",
      "         0.0544]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-7.3115e-02, -1.5523e-01, -2.7821e-01,  5.0969e-02, -4.9633e-02,\n",
      "           8.2292e-02, -2.6770e-01, -2.7533e-01,  1.2219e-01, -1.0928e-01,\n",
      "          -3.7193e-05,  4.8155e-02, -7.8742e-02,  5.6668e-02,  8.2050e-02,\n",
      "           1.4226e-01, -2.4644e-02,  1.7404e-01, -2.7765e-01,  4.2077e-01,\n",
      "          -3.4283e-01, -1.2934e-01,  3.0549e-01,  1.7594e-01,  7.2255e-02,\n",
      "          -1.2974e-01,  5.5037e-02, -2.0375e-01, -1.9285e-01, -7.9861e-03,\n",
      "           1.6732e-01, -7.2983e-02,  1.7787e-01, -1.3947e-01,  2.7480e-01,\n",
      "          -2.5256e-01,  3.4531e-02,  6.6293e-02, -6.6461e-02, -3.9912e-02,\n",
      "           1.9368e-01, -1.2914e-01,  1.2793e-01, -4.3198e-02, -1.6984e-02,\n",
      "          -8.2025e-02,  2.4144e-01, -7.1789e-03,  2.5177e-01, -9.4519e-02,\n",
      "          -2.1872e-01,  4.3059e-02, -3.6582e-01, -1.3905e-01, -7.9176e-02,\n",
      "           1.6130e-01,  1.2611e-02,  4.8259e-02, -8.6152e-03, -5.4268e-03,\n",
      "           1.1358e-02, -3.0883e-01, -1.6405e-01,  1.2015e-01,  7.0957e-02,\n",
      "           2.9203e-01, -3.1207e-01,  3.1482e-02, -9.5944e-02, -7.5142e-02,\n",
      "           2.0162e-01,  1.2091e-01, -3.5921e-02, -3.6205e-02,  4.2182e-02,\n",
      "           1.5944e-01,  1.9032e-01,  1.6534e-01, -9.4382e-02, -3.2224e-02,\n",
      "          -2.3616e-01,  7.9437e-02, -2.1106e-01, -8.2805e-02, -4.9856e-02,\n",
      "           8.4950e-02, -4.1320e-03, -1.7855e-02, -1.4397e-01, -8.1692e-02,\n",
      "           9.9592e-02, -3.5556e-02, -7.3635e-02, -8.5626e-02, -7.4964e-02,\n",
      "           1.9350e-01, -1.5336e-01,  1.0609e-01,  2.2032e-01, -1.2292e-01,\n",
      "           6.3012e-02,  1.8979e-01,  2.7092e-01,  7.9186e-03, -1.7027e-01,\n",
      "          -4.9962e-02, -6.4176e-02,  6.7694e-02,  1.8775e-02, -2.0128e-03,\n",
      "           4.2411e-01,  4.2961e-02,  5.9867e-02, -1.1608e-01,  1.2480e-01,\n",
      "          -3.1789e-01,  6.4110e-02, -1.6345e-01,  1.6876e-02,  1.0203e-01,\n",
      "           6.3304e-02, -1.9442e-02, -1.3744e-01,  8.9389e-03, -6.9283e-02,\n",
      "          -2.1267e-02, -8.2747e-02, -2.1283e-01, -8.5327e-02, -1.8165e-01,\n",
      "          -1.8066e-01, -1.7572e-01,  1.3278e-01,  1.2163e-01, -2.6050e-01,\n",
      "           1.3067e-01,  3.8519e-01,  1.1207e-01, -3.7851e-01,  8.9492e-02,\n",
      "          -4.7692e-02,  3.1244e-01, -3.4798e-01,  1.9283e-01,  7.2131e-02,\n",
      "          -6.4591e-02, -2.3070e-02,  1.6932e-01,  1.8112e-01, -2.5296e-02,\n",
      "          -1.8226e-01, -3.2919e-02, -1.9747e-01, -8.3197e-02, -2.1969e-03,\n",
      "           2.7120e-01,  1.7462e-01,  1.6323e-01, -3.7490e-02,  4.3715e-02,\n",
      "          -1.2648e-01,  9.9076e-02, -3.7924e-02,  1.3649e-01, -3.3543e-01,\n",
      "          -7.4247e-02, -1.9347e-01,  1.5906e-02, -4.4270e-02,  9.1129e-02,\n",
      "          -2.4465e-01,  2.1126e-01,  7.7926e-02,  2.3115e-02, -4.3674e-02,\n",
      "          -1.3109e-01,  2.7111e-01,  1.2449e-01,  3.7686e-01, -2.0068e-01,\n",
      "          -1.7308e-01, -2.9712e-01, -1.2229e-01,  7.7006e-02,  8.9783e-02,\n",
      "          -1.6813e-03,  1.9554e-01, -2.8692e-02, -1.8490e-01, -2.3777e-01,\n",
      "          -1.7459e-01,  1.8992e-01, -1.1056e-01, -2.1007e-01, -1.1128e-02,\n",
      "           1.0767e-01,  1.9842e-01, -2.8207e-02, -1.2756e-02, -1.8587e-02,\n",
      "           2.0030e-02, -3.5272e-02, -1.7953e-01,  3.4705e-01,  9.6784e-02,\n",
      "          -7.4626e-02,  2.1567e-01,  3.1136e-01, -2.5690e-04,  2.9830e-02,\n",
      "          -4.3741e-03, -1.5891e-02, -1.3944e-01,  2.0173e-01, -4.1275e-02,\n",
      "           1.6409e-01,  1.0467e-01,  1.6083e-01,  3.7668e-02,  6.5850e-02,\n",
      "           1.1555e-01, -3.2432e-01,  3.2016e-01, -1.3628e-01, -1.1656e-01,\n",
      "          -4.9979e-02,  2.1055e-01, -1.9412e-01, -2.6843e-01,  3.3661e-01,\n",
      "          -3.1767e-01, -5.8903e-02,  2.6390e-02,  4.7613e-02,  4.1929e-02,\n",
      "           4.1352e-02,  5.8941e-02,  5.1801e-02,  2.6812e-01,  1.9098e-01,\n",
      "           2.4202e-02,  1.5181e-01,  2.6079e-01, -3.3963e-02,  6.0315e-02,\n",
      "          -5.8508e-03, -1.9298e-01, -4.4409e-02, -1.6332e-01, -9.3466e-03,\n",
      "           2.2073e-01, -1.7628e-02, -4.7506e-02,  4.3513e-02,  1.4042e-01,\n",
      "          -1.2138e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 4.9846e-01, -2.7218e+00,  1.0395e+00, -7.7166e-01,  0.0000e+00,\n",
      "          -6.5282e-01, -1.4528e+00,  1.2585e+00, -1.6162e+00, -1.3411e+00,\n",
      "           2.7017e-01,  9.6866e-01,  1.8106e+00,  2.1071e+00,  8.5615e-02,\n",
      "           0.0000e+00,  1.0224e-01,  0.0000e+00,  0.0000e+00,  1.7338e+00,\n",
      "           0.0000e+00, -2.4022e-02,  0.0000e+00,  1.0043e+00, -2.2619e-02,\n",
      "          -1.4865e+00,  1.4713e+00, -8.9164e-01,  0.0000e+00,  1.4843e+00,\n",
      "          -4.1279e-01, -1.4792e+00, -1.0202e+00,  9.8337e-01,  1.2573e+00,\n",
      "          -1.7683e+00,  0.0000e+00,  1.0947e+00, -1.9841e-01,  5.4076e-01,\n",
      "          -4.2373e-01,  2.1608e-01,  1.5215e+00,  1.0420e+00, -1.0479e+00,\n",
      "          -1.0269e+00, -4.6266e-01,  1.2440e+00, -1.3961e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.2271e-01,  1.1926e+00, -8.9128e-01,  0.0000e+00,\n",
      "          -1.0613e+00,  0.0000e+00,  2.7394e-01,  1.6177e+00, -6.3939e-01,\n",
      "           9.6624e-02, -8.0753e-01,  5.2299e-02, -1.4418e+00,  6.6157e-01,\n",
      "           0.0000e+00, -2.5534e-01,  4.0755e-01,  1.0434e-01, -5.7136e-01,\n",
      "           8.6187e-03, -1.9858e-01,  0.0000e+00,  1.1817e-01, -1.8515e+00,\n",
      "          -7.8834e-01, -8.2773e-01,  7.4723e-01,  1.2679e+00,  2.4426e+00,\n",
      "          -1.4247e+00,  2.8931e+00, -1.0813e+00,  6.1171e-01, -1.2040e+00,\n",
      "           0.0000e+00, -9.8167e-01, -1.1934e+00,  6.9125e-01, -6.9524e-01,\n",
      "           3.6387e-01, -4.5880e-01, -2.1686e+00, -1.5254e-02, -2.0724e+00,\n",
      "          -8.7900e-01,  1.3053e+00, -2.5976e+00,  2.1872e+00,  4.5246e-01,\n",
      "          -1.1097e+00, -1.3532e+00, -3.3459e-01,  1.3245e+00,  2.7749e-01,\n",
      "           3.3188e-01, -8.4154e-01,  1.3122e+00, -1.9337e-01,  0.0000e+00,\n",
      "          -3.8698e-01, -2.3006e+00, -7.6007e-01, -1.3115e+00,  3.5401e-01,\n",
      "           4.4452e-01,  6.8645e-01, -1.0984e+00, -3.3350e-01, -6.9342e-01,\n",
      "           5.2935e-01, -9.9045e-01,  2.4237e-01, -8.2767e-01, -6.0132e-02,\n",
      "          -5.3978e-02, -1.6435e+00,  8.6471e-01,  0.0000e+00,  1.4224e+00,\n",
      "          -2.3232e-02,  1.0952e+00, -1.6868e+00,  1.0362e+00,  7.7540e-01,\n",
      "           1.2891e+00,  9.7690e-01,  0.0000e+00, -1.7509e-01,  7.6879e-01,\n",
      "           6.5472e-01, -7.8752e-01,  1.7546e+00, -3.5339e-01,  0.0000e+00,\n",
      "          -5.7508e-01,  2.2802e+00,  1.2672e+00,  0.0000e+00,  8.4448e-02,\n",
      "           7.3814e-01,  1.1980e-01,  0.0000e+00, -1.1125e+00, -1.7445e+00,\n",
      "           2.9237e+00, -1.1897e+00,  8.5704e-01, -5.3423e-01, -1.7700e+00,\n",
      "           2.2082e-01,  0.0000e+00, -1.4462e+00,  0.0000e+00, -2.6768e+00,\n",
      "           1.3082e+00,  5.7831e-01, -1.2044e+00,  2.3927e+00,  0.0000e+00,\n",
      "          -4.9027e-01, -8.7089e-01,  1.4530e+00,  1.6413e+00,  6.5603e-01,\n",
      "          -1.7588e+00, -3.8412e-01, -4.8978e-01,  1.7020e+00, -3.6935e-01,\n",
      "          -6.0719e-01,  3.1836e-01,  7.9886e-01, -9.2883e-01, -1.5866e+00,\n",
      "           0.0000e+00,  2.2789e+00,  1.9000e+00, -4.5633e-02, -1.5528e+00,\n",
      "          -2.3624e-03,  1.7408e+00,  5.5539e-01, -4.1915e-01,  5.8023e-01,\n",
      "          -2.1258e+00,  0.0000e+00, -2.1636e-01,  1.9123e+00,  1.7369e+00,\n",
      "          -8.7414e-01, -4.3269e-01, -4.5196e-02, -1.6975e+00, -4.3515e-01,\n",
      "          -7.4931e-01,  1.5178e-01,  1.3121e+00, -7.3181e-01, -8.3101e-02,\n",
      "           1.1180e+00, -1.9657e-01, -9.2269e-01,  2.0456e+00,  7.7653e-01,\n",
      "           0.0000e+00,  3.4228e-01, -1.4517e-01,  0.0000e+00,  3.2673e-01,\n",
      "          -8.1630e-01, -1.1667e+00,  8.5771e-01,  0.0000e+00, -5.6562e-01,\n",
      "           6.1677e-01,  7.0817e-01, -1.2110e+00, -2.4501e+00,  2.1527e+00,\n",
      "          -3.9337e-01,  0.0000e+00,  2.4986e-01, -1.9304e+00,  8.0039e-01,\n",
      "           8.4805e-01,  0.0000e+00,  0.0000e+00, -1.1834e-02, -2.1005e+00,\n",
      "           1.1550e+00,  0.0000e+00, -2.1878e+00,  7.2466e-01,  3.5233e-01,\n",
      "           8.2506e-01, -5.1009e-01, -1.1363e-01,  0.0000e+00,  5.1294e-02,\n",
      "          -1.5374e+00,  1.6707e-01, -1.4550e+00, -2.0569e+00, -6.0736e-02,\n",
      "           6.3590e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1858, 0.0549, 0.0484, 0.1869, 0.0767, 0.0790, 0.0638, 0.0486, 0.1253,\n",
      "         0.1306]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 7.4497e-02, -1.2078e-01, -3.3299e-01,  1.2870e-01, -1.0418e-01,\n",
      "           7.5813e-02, -2.3755e-01, -2.7191e-01,  9.2315e-02, -7.2098e-02,\n",
      "          -3.6241e-02, -4.4833e-02, -1.3039e-01,  3.6010e-02,  6.5610e-02,\n",
      "           1.8242e-01,  4.3710e-03,  2.3623e-01, -2.3049e-01,  3.9137e-01,\n",
      "          -2.8789e-01, -8.9206e-02,  3.2674e-01,  1.8119e-01,  9.0779e-04,\n",
      "          -8.6265e-02,  5.2991e-02, -3.0942e-01, -1.4415e-01,  5.2573e-02,\n",
      "           2.3877e-01, -9.0356e-02,  8.1408e-02, -1.5156e-01,  2.2018e-01,\n",
      "          -2.2403e-01,  1.1140e-02,  8.8347e-02, -6.6372e-02, -1.9522e-02,\n",
      "           9.4143e-02, -2.2165e-02,  8.2181e-02, -4.7296e-02,  2.8818e-02,\n",
      "           4.8762e-02,  1.5775e-01, -7.5038e-02,  2.5182e-01, -1.1165e-01,\n",
      "          -3.2135e-01,  4.8060e-02, -3.5613e-01, -1.6120e-01, -9.4775e-02,\n",
      "           1.3828e-01,  1.2698e-03,  1.5432e-01, -3.0083e-02,  6.8209e-02,\n",
      "          -4.1224e-03, -2.8523e-01, -1.6373e-01,  1.0578e-01,  8.6018e-02,\n",
      "           1.8971e-01, -3.0099e-01,  5.3593e-02, -1.3733e-01, -3.4094e-02,\n",
      "           1.7830e-01,  1.5839e-01,  4.7517e-02, -4.6383e-03, -6.6167e-02,\n",
      "           8.7473e-02,  2.7963e-01,  1.7034e-01, -6.9890e-02,  9.6319e-02,\n",
      "          -2.6290e-01, -5.2304e-02, -2.0541e-01, -7.2964e-02, -5.0785e-02,\n",
      "           9.9517e-02, -3.4334e-02, -7.5950e-03, -1.0914e-02, -1.0348e-01,\n",
      "           1.4502e-01, -4.5149e-02, -3.8904e-02, -7.5819e-02, -4.6435e-02,\n",
      "           1.9352e-01, -1.1346e-01,  1.8189e-01,  2.3865e-01,  4.4126e-02,\n",
      "          -2.0361e-02,  2.4018e-01,  2.3056e-01,  2.5507e-02, -1.8439e-01,\n",
      "          -1.6089e-01, -5.4824e-02,  1.1997e-01, -6.2469e-02,  3.1389e-03,\n",
      "           3.9476e-01,  9.6391e-02,  1.0943e-01, -1.9346e-01,  1.5598e-02,\n",
      "          -2.5508e-01,  8.5312e-03, -1.1807e-01,  2.8994e-02,  1.0140e-01,\n",
      "           7.5065e-02, -3.0920e-02, -1.7238e-01,  5.9738e-02, -7.9172e-02,\n",
      "          -5.7474e-02, -8.9727e-02, -2.7461e-01,  2.6803e-02, -1.5020e-01,\n",
      "          -3.5472e-02, -1.9000e-01,  2.0243e-01,  1.7924e-01, -2.5143e-01,\n",
      "           1.2708e-01,  4.1198e-01,  6.2762e-02, -3.1289e-01,  1.2578e-01,\n",
      "          -4.6452e-02,  3.5556e-01, -3.4324e-01,  2.0582e-01,  1.2115e-01,\n",
      "          -2.6703e-02, -3.8512e-02,  1.8672e-01,  1.9679e-01,  5.8947e-02,\n",
      "          -2.8800e-01,  8.9702e-02, -1.3818e-01,  8.3046e-02,  7.4316e-02,\n",
      "           3.4399e-01,  1.1641e-01,  1.4263e-01, -1.7728e-02, -1.4247e-02,\n",
      "          -1.6554e-01, -7.4899e-02, -1.3792e-01,  1.7043e-01, -2.4618e-01,\n",
      "          -7.6028e-04, -2.0039e-01,  8.9044e-03, -5.8178e-02,  1.1269e-01,\n",
      "          -2.4015e-01,  2.2710e-01,  1.4918e-01, -4.2298e-02, -4.7700e-02,\n",
      "          -9.4507e-02,  2.5973e-01,  7.1818e-02,  3.1973e-01, -2.4290e-01,\n",
      "          -1.2227e-01, -2.1040e-01, -1.4204e-01,  5.5598e-02,  9.3794e-02,\n",
      "           6.2453e-02,  4.3923e-02,  3.4916e-03, -9.9813e-02, -2.8128e-01,\n",
      "          -1.6603e-01,  2.1463e-01, -2.0581e-01, -2.0486e-01,  5.8478e-03,\n",
      "           3.3213e-02,  1.3924e-01, -4.0169e-02, -1.3261e-01, -5.1209e-02,\n",
      "           1.5813e-02, -2.5346e-02, -2.3822e-01,  4.1361e-01,  1.3749e-01,\n",
      "          -5.5018e-02,  1.9070e-01,  3.9001e-01,  1.7996e-02, -8.4470e-02,\n",
      "           9.4857e-02, -1.2741e-01, -1.9276e-01,  2.2970e-01, -7.6804e-02,\n",
      "           9.4815e-02,  9.3788e-02,  2.0649e-01, -6.6115e-02,  4.4403e-03,\n",
      "           1.5972e-01, -3.4926e-01,  3.5141e-01, -1.8572e-01, -8.5884e-02,\n",
      "           9.2927e-02,  2.0399e-01, -2.3628e-01, -3.5323e-01,  3.4345e-01,\n",
      "          -2.8799e-01, -7.9148e-02,  3.7216e-02,  1.6449e-04,  9.1692e-02,\n",
      "           3.7056e-02,  7.4906e-03,  4.4011e-02,  3.5790e-01,  1.4960e-01,\n",
      "           7.1468e-02,  1.1680e-01,  1.6227e-01, -7.0478e-02,  1.3422e-01,\n",
      "          -2.0389e-02, -2.5071e-01, -4.3780e-02, -7.0724e-02,  1.6601e-02,\n",
      "           1.4804e-01, -3.3184e-02, -1.4166e-01, -1.1152e-02,  1.2812e-01,\n",
      "          -9.6137e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9063e+00, -3.9838e-01,  1.7405e+00,  1.5009e-01, -2.2133e+00,\n",
      "           1.2332e+00, -1.1603e+00,  8.1208e-01,  3.5093e-01,  1.1000e+00,\n",
      "          -4.3506e-01,  7.4520e-01, -1.9264e+00, -1.3537e+00,  7.1012e-01,\n",
      "           1.3971e+00,  3.8088e-01, -1.7509e+00, -1.3437e+00, -2.7614e-01,\n",
      "          -1.0441e+00, -1.6525e-02, -5.8832e-01, -1.2967e-01,  8.8471e-01,\n",
      "           8.6906e-01,  2.2058e+00, -5.9891e-01,  0.0000e+00,  1.3020e-01,\n",
      "           1.7650e-01,  2.0790e+00,  0.0000e+00,  2.0977e+00,  1.2917e+00,\n",
      "           8.5036e-01,  5.5614e-01, -1.0968e+00, -2.0623e-03,  1.5468e+00,\n",
      "           1.7770e-01,  8.2380e-01, -1.3494e+00, -7.6295e-02, -7.2118e-01,\n",
      "          -1.5019e-01, -1.1207e+00, -1.3128e+00,  1.4816e+00, -4.1872e-01,\n",
      "           2.2415e-01, -1.3390e+00,  1.2969e+00,  0.0000e+00, -1.2900e-01,\n",
      "           4.6612e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.1097e-01,\n",
      "           1.1235e-01, -9.7327e-01,  1.1275e+00,  1.1066e+00, -6.4229e-01,\n",
      "           0.0000e+00,  1.2277e+00,  1.9880e+00,  3.1710e-01,  6.1357e-01,\n",
      "          -1.1846e+00,  2.7370e-01,  1.6056e+00, -1.2152e+00,  4.3263e-01,\n",
      "           7.2994e-01, -1.8633e+00,  0.0000e+00, -7.3918e-01, -1.4630e+00,\n",
      "           9.0056e-01,  8.2038e-01, -2.4644e-02, -6.9385e-01, -1.7128e-02,\n",
      "           2.3734e-01, -4.2469e-02, -1.3032e-01,  1.7551e-01, -2.4305e+00,\n",
      "          -1.1449e+00,  1.1266e-02, -7.3898e-01,  1.4369e-01, -3.1269e-01,\n",
      "          -1.8971e+00, -5.2890e-03, -1.5513e+00,  1.5177e+00,  1.0264e+00,\n",
      "           0.0000e+00, -1.5410e+00,  6.1686e-01,  1.1418e+00,  7.5443e-01,\n",
      "           0.0000e+00,  1.6270e-01, -4.6488e-01, -6.6922e-01,  1.0211e+00,\n",
      "           0.0000e+00, -1.9229e-01, -1.0079e+00,  5.2739e-01,  6.3170e-01,\n",
      "           1.0391e+00,  6.8150e-01, -1.4979e+00, -4.2767e-01,  1.6024e+00,\n",
      "           4.3387e-01, -3.5064e-01, -3.4573e-01,  4.5487e-01,  1.4562e+00,\n",
      "           9.6890e-01,  0.0000e+00, -3.2772e-01,  2.9182e-01,  3.9203e-01,\n",
      "           8.0144e-01, -5.7767e-01, -6.8421e-01, -2.0397e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00, -1.2494e+00, -1.5522e-01, -1.0904e+00,\n",
      "           1.0327e+00, -2.1919e-03, -9.1756e-01,  7.8182e-02,  2.2991e-01,\n",
      "           8.1667e-01,  8.6635e-02, -9.7201e-01, -2.5756e+00,  3.0930e-01,\n",
      "           1.2124e+00,  3.7793e-01, -1.0707e+00,  1.7412e+00,  9.8869e-01,\n",
      "           1.3038e+00,  1.8112e+00,  1.2148e-02,  4.6021e-02,  3.6723e-01,\n",
      "           7.6025e-02,  4.9569e-02, -7.9446e-01,  0.0000e+00,  1.8597e+00,\n",
      "           4.6423e-01,  1.9504e+00, -1.9395e+00,  1.2740e+00,  0.0000e+00,\n",
      "          -1.2957e+00,  0.0000e+00, -1.1444e+00, -6.1193e-01,  1.5682e+00,\n",
      "          -7.3192e-01, -1.0904e-01, -1.8585e+00,  6.0219e-01,  1.9363e+00,\n",
      "           7.6733e-01, -1.6041e-01, -1.4463e+00,  2.4676e+00, -4.1394e-01,\n",
      "           1.9395e+00,  0.0000e+00,  1.4199e+00, -4.6481e-01,  2.6827e-01,\n",
      "          -6.7528e-01,  1.8385e+00, -1.5400e+00,  0.0000e+00,  8.3210e-01,\n",
      "           2.9406e-01, -1.6162e+00, -2.0575e+00,  9.3534e-01, -5.2548e-01,\n",
      "          -5.0495e-01,  4.2854e-01, -2.3585e+00,  2.4577e-01,  4.8143e-01,\n",
      "          -8.4321e-01,  8.7972e-01,  1.4632e+00, -3.7804e-01, -8.9920e-03,\n",
      "           2.5373e+00,  6.2831e-01, -4.4126e-01, -2.4166e-01,  0.0000e+00,\n",
      "          -6.7038e-02,  0.0000e+00,  5.5925e-01, -6.9601e-01,  5.5031e-01,\n",
      "           4.4274e-01,  7.6355e-01,  4.1156e-01,  0.0000e+00, -1.7550e+00,\n",
      "           5.1195e-01, -1.3678e+00,  8.6261e-01, -1.9442e+00,  7.9496e-01,\n",
      "          -2.7369e+00, -1.2064e+00, -3.8570e-01,  3.2571e-01, -1.6976e+00,\n",
      "          -8.1518e-01,  5.5957e-02, -7.2227e-01, -1.8880e+00,  9.1409e-01,\n",
      "          -6.1236e-01,  1.1326e+00,  1.1355e+00,  6.8011e-01, -3.9387e-01,\n",
      "          -2.2642e+00, -8.2247e-01,  4.3029e-01,  1.9395e+00,  2.2023e-01,\n",
      "          -9.1795e-01, -5.5587e-02, -1.3464e+00, -3.1320e-02,  4.8415e-01,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0541, 0.0718, 0.1107, 0.0963, 0.1962, 0.1280, 0.0391, 0.0768, 0.1358,\n",
      "         0.0912]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0137, -0.1669, -0.2631,  0.0731, -0.0710,  0.0534, -0.2588,\n",
      "          -0.2939,  0.1112, -0.1234,  0.0290, -0.0340, -0.1160,  0.0347,\n",
      "           0.0405,  0.0740, -0.0821,  0.2379, -0.3321,  0.4158, -0.3624,\n",
      "          -0.1658,  0.2983,  0.1523,  0.0327, -0.0757,  0.0371, -0.2867,\n",
      "          -0.2293, -0.0122,  0.1982, -0.1109,  0.1502, -0.1699,  0.2681,\n",
      "          -0.2363, -0.0169,  0.0862, -0.0868, -0.0454,  0.1937, -0.0675,\n",
      "           0.0898, -0.0361,  0.0619, -0.0296,  0.1832, -0.0964,  0.2625,\n",
      "          -0.1057, -0.2810, -0.0455, -0.4066, -0.1541, -0.1235,  0.0862,\n",
      "          -0.0656,  0.0647, -0.0117,  0.0260,  0.0028, -0.3253, -0.2295,\n",
      "           0.1624,  0.0990,  0.2729, -0.3103,  0.0675, -0.1500, -0.0192,\n",
      "           0.2488,  0.1105, -0.0593, -0.0032, -0.0038,  0.1268,  0.2570,\n",
      "           0.2036, -0.0532,  0.0295, -0.2265,  0.0335, -0.2278, -0.0865,\n",
      "          -0.0833,  0.1069,  0.0388, -0.0126, -0.0675, -0.0906,  0.0595,\n",
      "          -0.0307, -0.0569, -0.1193, -0.0839,  0.2584, -0.1255,  0.1354,\n",
      "           0.2654, -0.0737, -0.0060,  0.2103,  0.3048,  0.0289, -0.0983,\n",
      "          -0.0771, -0.0578,  0.1406,  0.0047,  0.0450,  0.4230,  0.0600,\n",
      "           0.0755, -0.0942,  0.0416, -0.2940, -0.0101, -0.1581, -0.0152,\n",
      "           0.0497,  0.0802, -0.0298, -0.1673,  0.0506, -0.1317, -0.0556,\n",
      "          -0.0880, -0.2486, -0.0048, -0.1613, -0.1292, -0.1757,  0.1722,\n",
      "           0.1648, -0.2886,  0.1431,  0.3975,  0.1009, -0.3710,  0.0782,\n",
      "          -0.0864,  0.3821, -0.3672,  0.1942,  0.0758, -0.0461, -0.0212,\n",
      "           0.2134,  0.1903,  0.0811, -0.2257, -0.0163, -0.1670, -0.0312,\n",
      "           0.0316,  0.2885,  0.1353,  0.1706, -0.0731,  0.0040, -0.1724,\n",
      "           0.0794, -0.0604,  0.1781, -0.3045, -0.0132, -0.1396, -0.0764,\n",
      "          -0.0603,  0.0824, -0.2697,  0.2461,  0.1362, -0.0262,  0.0120,\n",
      "          -0.1555,  0.2334,  0.1228,  0.3859, -0.1904, -0.2200, -0.2096,\n",
      "          -0.1736,  0.0632,  0.1367,  0.0489,  0.1495,  0.0184, -0.1695,\n",
      "          -0.2854, -0.2053,  0.2049, -0.1243, -0.2357, -0.0216,  0.0052,\n",
      "           0.2366, -0.0580, -0.0698, -0.0276,  0.0126, -0.0064, -0.2043,\n",
      "           0.4091,  0.1687, -0.0588,  0.1868,  0.3420,  0.0130, -0.0021,\n",
      "           0.0266, -0.0839, -0.1599,  0.2015, -0.0702,  0.1865,  0.0692,\n",
      "           0.2077,  0.0165,  0.0636,  0.1166, -0.3743,  0.3281, -0.1111,\n",
      "          -0.0945, -0.0205,  0.1751, -0.2045, -0.2845,  0.3728, -0.2725,\n",
      "          -0.0781, -0.0246, -0.0122, -0.0167,  0.0299,  0.0343,  0.0446,\n",
      "           0.3375,  0.2171, -0.0260,  0.1024,  0.1990, -0.0562,  0.0479,\n",
      "          -0.0514, -0.2096, -0.0789, -0.1532, -0.0452,  0.2072, -0.0080,\n",
      "          -0.0380, -0.0022,  0.1558, -0.1378]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7259e-01, -4.3087e-01,  3.1519e-01, -1.0851e+00, -1.1728e+00,\n",
      "           7.4162e-01,  0.0000e+00,  1.3514e+00,  0.0000e+00,  6.1732e-01,\n",
      "           1.9038e+00,  6.0257e-01,  2.2923e-01, -9.1660e-01, -3.1836e+00,\n",
      "          -6.8276e-02, -1.6336e+00, -9.4355e-01,  1.3604e+00, -1.4357e+00,\n",
      "          -1.4046e-01, -5.2447e-01, -1.1198e+00, -2.5958e+00, -7.5874e-02,\n",
      "           1.3918e+00, -6.1986e-01,  0.0000e+00,  1.2776e-01,  5.5500e-01,\n",
      "           9.1588e-01, -3.7317e-03,  2.2223e-01,  2.0170e+00, -6.3652e-02,\n",
      "          -1.4086e+00, -1.1168e-01, -8.1750e-01,  3.1531e-01,  8.5999e-02,\n",
      "           8.6333e-01, -8.9931e-01,  0.0000e+00, -1.5640e+00,  1.9448e+00,\n",
      "          -3.0042e-01,  7.0628e-01, -6.0221e-01, -1.0210e+00,  1.1172e+00,\n",
      "          -1.3232e+00,  2.6781e+00,  6.6698e-01, -8.4706e-01,  2.2800e-01,\n",
      "          -3.1009e-01, -1.4340e+00, -9.6260e-02,  0.0000e+00,  2.1821e+00,\n",
      "          -1.0065e+00,  3.5916e-02, -2.8020e-01,  2.6580e-01,  0.0000e+00,\n",
      "           3.9364e-01,  5.7813e-01,  1.1653e+00,  1.5810e+00, -1.4154e+00,\n",
      "           4.2742e-01,  2.9640e-01, -3.1115e-02, -7.9821e-01, -2.1424e-01,\n",
      "           0.0000e+00,  5.2598e-01,  1.3990e+00,  1.0274e+00, -7.9412e-01,\n",
      "           7.5840e-01, -1.0049e+00,  7.5825e-01,  1.0588e+00, -1.2156e+00,\n",
      "          -1.1323e-01, -1.1082e+00,  5.4869e-01, -9.4493e-01, -1.9014e+00,\n",
      "           5.2914e-01,  0.0000e+00,  1.7021e+00,  9.4418e-01,  6.0798e-01,\n",
      "          -1.5904e-02,  3.5423e-01, -1.1760e+00,  1.3724e+00,  0.0000e+00,\n",
      "           2.4346e-01,  4.4221e-02, -4.6664e-01,  0.0000e+00,  1.6409e+00,\n",
      "          -1.0240e+00,  3.0299e+00,  6.2061e-01, -1.0200e-01, -1.2356e+00,\n",
      "           1.9001e-01, -5.0327e-01, -5.7108e-01,  7.1253e-01, -7.8082e-01,\n",
      "           6.3260e-01,  4.0379e-01,  2.2357e-01, -2.3273e+00,  0.0000e+00,\n",
      "          -8.1475e-01, -1.4120e+00, -1.8386e+00,  6.0320e-01, -9.5704e-01,\n",
      "          -2.0093e-01,  4.0135e-02,  2.1508e+00,  1.3965e+00, -2.0883e+00,\n",
      "          -9.2624e-01,  4.4988e-01, -1.1682e+00,  4.2547e-01, -4.6836e-01,\n",
      "          -7.4616e-01, -1.0650e+00, -9.7558e-01, -1.9413e-02,  2.3979e+00,\n",
      "           6.9862e-01, -1.1218e+00,  1.6919e+00,  0.0000e+00, -6.7017e-01,\n",
      "           3.3333e-02,  7.5982e-01,  4.2287e-01, -1.0340e+00, -9.5322e-02,\n",
      "           1.5601e+00,  5.8680e-01, -3.3844e-01,  6.5775e-01,  1.8416e+00,\n",
      "          -2.5275e-01,  0.0000e+00,  0.0000e+00, -2.3637e+00,  1.0560e+00,\n",
      "           3.0281e-01, -7.7187e-02,  1.5518e-01, -1.2123e+00,  0.0000e+00,\n",
      "           1.6826e+00,  1.8527e+00,  2.7159e-01, -1.2705e+00, -7.1310e-01,\n",
      "          -1.2243e+00, -1.0943e+00, -2.5912e+00,  5.0591e-01, -3.0606e+00,\n",
      "          -2.8744e-01,  4.9765e-01,  8.2973e-01,  0.0000e+00, -7.9307e-01,\n",
      "           2.7243e-01,  2.3400e+00,  1.0581e+00,  8.3889e-01, -4.0250e-01,\n",
      "           7.2790e-01,  0.0000e+00,  3.5977e-01,  8.4307e-01, -1.8311e+00,\n",
      "           1.3638e+00,  2.1599e+00,  3.3595e-01, -1.0157e+00, -1.1729e+00,\n",
      "          -2.2160e+00,  1.6677e+00,  2.1532e+00,  3.6346e-01,  2.3838e+00,\n",
      "           0.0000e+00, -5.0171e-01, -1.2771e+00, -5.4298e-01, -4.0765e-01,\n",
      "          -1.4476e+00,  9.5334e-01, -8.5203e-01,  8.2964e-01, -1.5605e+00,\n",
      "           6.3721e-01,  6.7564e-01,  2.3986e+00,  5.5321e-02,  1.8937e+00,\n",
      "           1.3090e+00,  5.8024e-01, -2.3178e+00,  1.5503e+00, -2.2252e-01,\n",
      "          -2.2729e-01,  1.7341e+00,  2.7659e-01, -1.5523e+00,  9.2282e-01,\n",
      "          -1.2244e+00, -8.4882e-01, -1.8025e+00, -7.1477e-04,  3.7317e-01,\n",
      "          -1.5739e+00, -1.2384e-01,  9.6640e-01, -1.7373e+00,  1.6947e+00,\n",
      "           0.0000e+00,  6.3405e-01,  0.0000e+00,  9.8029e-01, -1.7168e+00,\n",
      "           1.5615e+00, -2.7283e-01, -2.5974e+00,  1.2391e+00, -1.2283e+00,\n",
      "           1.8864e+00, -5.0842e-01,  5.4289e-01, -2.6130e-01, -1.0223e+00,\n",
      "           0.0000e+00,  3.1125e-01, -5.1073e-02, -2.2876e-01, -1.6130e+00,\n",
      "           1.8071e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0494, 0.1224, 0.1300, 0.0819, 0.1743, 0.1471, 0.0927, 0.0631, 0.0895,\n",
      "         0.0496]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.2488, -0.0080, -0.0885,  ...,  0.1655,  0.0282,  0.0370],\n",
      "        [-0.1747,  0.0627, -0.1480,  ...,  0.2350,  0.0783, -0.2426],\n",
      "        [-0.1185, -0.0723, -0.5364,  ...,  0.1765, -0.0225, -0.0569],\n",
      "        ...,\n",
      "        [-0.1564, -0.2710, -0.3436,  ..., -0.1014,  0.4969,  0.1277],\n",
      "        [ 0.3607, -0.1018, -0.4657,  ..., -0.4818,  0.5920,  0.0796],\n",
      "        [ 0.6527,  0.4334, -0.7484,  ..., -0.3801,  0.1875,  0.2148]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-8.6581e-02, -1.6811e-01, -2.0640e-01,  9.6423e-02, -6.3164e-02,\n",
      "           1.0229e-01, -2.6840e-01, -2.5424e-01,  1.3596e-01, -8.3183e-02,\n",
      "           3.2803e-02,  1.6737e-02, -7.5332e-02,  5.0609e-02,  4.2569e-02,\n",
      "           1.1225e-01, -9.7901e-02,  2.0399e-01, -2.8450e-01,  4.5088e-01,\n",
      "          -3.8814e-01, -1.3757e-01,  3.0224e-01,  1.6840e-01,  4.2516e-02,\n",
      "          -1.0822e-01,  1.5022e-02, -2.3923e-01, -2.1843e-01, -7.4373e-03,\n",
      "           1.5624e-01, -9.0197e-02,  1.5103e-01, -1.6284e-01,  2.8442e-01,\n",
      "          -2.5876e-01,  4.5072e-02,  1.0552e-01, -3.7531e-02, -3.7719e-02,\n",
      "           2.1316e-01, -1.0940e-01,  1.1775e-01, -5.9034e-02,  2.3402e-02,\n",
      "          -8.2671e-02,  2.4606e-01, -3.4779e-02,  2.4506e-01, -1.0072e-01,\n",
      "          -2.2261e-01,  1.1279e-02, -3.8761e-01, -1.5376e-01, -9.8992e-02,\n",
      "           1.1347e-01, -2.2954e-03,  3.1071e-02, -5.8200e-02, -1.1228e-02,\n",
      "           1.4367e-02, -3.1521e-01, -1.9656e-01,  1.4850e-01,  1.2226e-01,\n",
      "           2.6746e-01, -3.2657e-01,  5.3138e-03, -1.1075e-01, -7.1657e-02,\n",
      "           2.3954e-01,  7.5117e-02, -2.4967e-02, -2.3995e-02,  4.5990e-02,\n",
      "           8.0011e-02,  2.0079e-01,  1.4927e-01, -6.5204e-02, -5.2442e-03,\n",
      "          -2.2832e-01,  8.5484e-02, -2.1418e-01, -8.1227e-02, -7.1262e-02,\n",
      "           7.9444e-02, -3.3710e-04, -3.2308e-03, -1.5063e-01, -9.7411e-02,\n",
      "           4.5010e-02, -3.4836e-02, -2.7916e-02, -1.0104e-01, -7.0358e-02,\n",
      "           2.2605e-01, -1.5545e-01,  1.3172e-01,  2.6894e-01, -1.4903e-01,\n",
      "           3.0014e-02,  1.6899e-01,  3.0722e-01,  3.0697e-02, -1.2032e-01,\n",
      "          -6.6009e-02, -4.8425e-02,  3.9833e-02,  6.6898e-02,  7.7201e-03,\n",
      "           4.4528e-01,  3.0801e-02,  6.2509e-02, -4.4171e-02,  8.6592e-02,\n",
      "          -3.0239e-01,  1.6562e-03, -1.7092e-01,  3.2105e-02,  6.2695e-02,\n",
      "           5.8579e-02, -1.8722e-03, -8.3531e-02,  8.7796e-03, -9.0299e-02,\n",
      "           6.5653e-03, -1.0360e-01, -2.3501e-01, -7.7355e-02, -1.5617e-01,\n",
      "          -1.3595e-01, -1.7283e-01,  1.4137e-01,  1.2655e-01, -2.3624e-01,\n",
      "           1.1668e-01,  3.7317e-01,  1.1444e-01, -3.5863e-01,  5.7623e-02,\n",
      "          -3.4158e-02,  3.2539e-01, -3.6825e-01,  2.0072e-01,  8.5422e-02,\n",
      "          -5.7152e-02, -1.2419e-02,  1.5659e-01,  1.6553e-01,  2.7158e-02,\n",
      "          -1.5122e-01, -4.7975e-02, -1.5812e-01, -1.0736e-01, -1.6140e-02,\n",
      "           2.7259e-01,  1.3930e-01,  1.5395e-01, -9.9387e-02,  4.8257e-02,\n",
      "          -1.3525e-01,  9.3496e-02, -2.8669e-02,  1.2694e-01, -3.0922e-01,\n",
      "          -4.2964e-02, -1.3745e-01, -1.7103e-02, -6.2049e-02,  8.9015e-02,\n",
      "          -2.3295e-01,  2.5024e-01,  7.6135e-02, -3.3356e-02,  1.1011e-02,\n",
      "          -1.2231e-01,  2.7585e-01,  1.1342e-01,  3.3811e-01, -1.7428e-01,\n",
      "          -1.6087e-01, -2.6926e-01, -9.5253e-02,  7.1894e-02,  7.5245e-02,\n",
      "           3.0608e-02,  1.7574e-01, -1.7805e-02, -1.8895e-01, -2.4323e-01,\n",
      "          -1.8231e-01,  1.6512e-01, -9.8714e-02, -2.0152e-01, -1.1059e-02,\n",
      "           7.0877e-02,  2.4118e-01, -5.5909e-02, -4.1071e-03, -6.3390e-02,\n",
      "          -6.5030e-03, -3.3627e-02, -1.9024e-01,  3.6574e-01,  1.5002e-01,\n",
      "          -8.2746e-02,  2.4133e-01,  3.0707e-01,  2.4617e-02,  3.6509e-02,\n",
      "           4.4725e-02, -2.1118e-02, -1.5704e-01,  2.0452e-01, -4.1131e-02,\n",
      "           1.8659e-01,  9.1246e-02,  1.9041e-01,  6.6349e-02,  9.0308e-02,\n",
      "           8.2282e-02, -3.4935e-01,  3.0441e-01, -1.2841e-01, -1.7714e-01,\n",
      "          -5.5815e-02,  1.8800e-01, -1.8937e-01, -2.6233e-01,  3.3865e-01,\n",
      "          -2.5000e-01, -5.4567e-02,  2.7054e-02,  4.6552e-02,  9.1826e-03,\n",
      "           8.4731e-02,  5.2410e-02,  4.8301e-02,  2.9218e-01,  1.9403e-01,\n",
      "          -1.1589e-02,  1.4979e-01,  2.5090e-01, -5.8757e-02,  3.7030e-02,\n",
      "          -2.1943e-02, -1.8443e-01, -5.7460e-02, -1.5330e-01, -3.8393e-02,\n",
      "           2.0000e-01, -3.7618e-03, -6.3244e-02,  5.9622e-02,  1.2734e-01,\n",
      "          -1.5774e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5885e-02,  3.9903e-01, -9.6656e-01, -6.8167e-01,  3.7625e-01,\n",
      "           0.0000e+00,  1.4649e+00, -8.3320e-02, -3.5849e+00,  9.0669e-01,\n",
      "           4.2885e-01, -6.2914e-01,  2.6052e+00, -6.2980e-01, -5.4163e-01,\n",
      "          -1.5802e-01,  0.0000e+00,  1.0950e+00,  4.5522e-01,  4.3602e-01,\n",
      "          -6.3367e-01, -3.8339e-01,  1.6419e+00,  1.5113e+00,  7.5371e-01,\n",
      "          -7.5393e-02, -1.8784e-01, -7.5912e-01,  1.6539e+00,  8.6169e-01,\n",
      "           1.2320e+00,  1.2191e+00,  0.0000e+00, -8.2657e-02, -1.5348e+00,\n",
      "           1.3953e+00,  2.8091e-01, -3.7455e+00,  0.0000e+00,  1.6013e+00,\n",
      "          -4.5881e-01,  0.0000e+00, -2.6838e-01, -1.7164e+00, -1.5247e+00,\n",
      "           6.6738e-01,  5.4104e-01,  3.7041e-01, -1.3410e+00,  1.4392e-01,\n",
      "          -6.2913e-01,  0.0000e+00,  6.1047e-01, -1.0295e+00,  0.0000e+00,\n",
      "           2.0310e-01,  0.0000e+00, -1.2529e+00, -2.3661e-01, -4.2530e-01,\n",
      "           1.1010e+00,  1.4083e+00, -2.0343e-01, -5.0179e-01, -2.9648e+00,\n",
      "           5.5059e-01,  1.2791e+00, -1.2881e+00,  4.1154e-01,  5.2642e-01,\n",
      "          -1.2673e+00, -3.0344e-02,  7.0744e-01, -3.6419e+00,  3.2624e-01,\n",
      "          -2.0840e-03, -1.5984e-01,  0.0000e+00,  0.0000e+00, -1.1995e-01,\n",
      "          -1.4005e+00,  2.1316e+00, -9.2482e-01,  1.0059e+00, -2.0785e-01,\n",
      "           4.3469e-01,  1.6618e+00, -9.7467e-01, -1.0343e-01, -5.8146e-01,\n",
      "          -2.2740e+00,  1.1004e+00, -6.2228e-01, -1.1354e+00,  4.6741e-01,\n",
      "          -1.1709e+00,  3.4273e-02,  6.2914e-01,  1.7205e+00, -7.8023e-01,\n",
      "           2.6976e+00, -1.4628e+00,  1.0761e+00,  1.4544e+00, -6.6641e-01,\n",
      "          -7.6266e-01,  1.2127e+00,  0.0000e+00, -1.4731e+00, -1.3113e-02,\n",
      "          -2.4883e-01,  1.3446e-01, -1.0486e+00,  1.3103e+00, -1.6538e+00,\n",
      "          -2.9902e+00, -5.6346e-02, -5.0118e-01, -1.9325e-01,  4.4492e-01,\n",
      "          -1.4669e+00,  0.0000e+00, -1.4608e+00, -7.2632e-01, -9.5866e-01,\n",
      "          -1.3093e+00,  0.0000e+00,  1.7040e-01,  1.2857e+00, -7.5257e-01,\n",
      "          -8.2335e-01,  5.2984e-01, -1.5834e+00,  9.8419e-01,  2.7611e-01,\n",
      "          -5.8968e-01,  6.5980e-01,  5.7378e-01,  0.0000e+00, -1.0104e+00,\n",
      "          -3.8887e-01,  6.7780e-01, -7.9003e-01,  0.0000e+00, -1.6862e+00,\n",
      "          -1.0117e-01, -5.4329e-01, -8.4451e-01, -7.5559e-01,  1.7746e-01,\n",
      "           1.9990e+00,  0.0000e+00, -1.9309e+00, -4.0619e-01,  0.0000e+00,\n",
      "          -1.9441e-01, -6.4280e-02, -1.2901e-01,  3.9405e-02,  5.3768e-01,\n",
      "          -2.6281e-02,  2.2066e+00,  4.8120e-01,  0.0000e+00, -5.2717e-01,\n",
      "          -8.9273e-01,  2.8173e-01,  8.4317e-02,  0.0000e+00,  0.0000e+00,\n",
      "           7.3791e-01, -3.2139e-02,  1.9925e-02, -1.0020e+00,  1.2779e+00,\n",
      "          -1.0990e+00, -9.8762e-01, -2.0775e+00,  1.9695e+00,  8.6444e-02,\n",
      "          -2.9907e-02,  3.5077e-02,  6.7153e-01,  9.7982e-01, -7.4699e-01,\n",
      "          -3.4096e-01, -2.7837e+00,  0.0000e+00,  1.2099e+00,  1.0125e+00,\n",
      "           3.0750e+00,  0.0000e+00, -1.4423e-01,  0.0000e+00,  5.6079e-01,\n",
      "           2.1656e+00, -1.1882e+00,  5.3491e-01,  1.8120e+00, -9.4740e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2419e+00, -1.2220e-01,  0.0000e+00,\n",
      "          -5.7535e-01, -2.2932e+00,  6.8179e-01,  0.0000e+00, -4.7139e-01,\n",
      "           2.8685e+00, -5.7337e-01, -3.4120e-01,  7.9322e-01,  2.9997e-02,\n",
      "           0.0000e+00, -1.0193e+00,  9.6630e-01, -2.4580e-01,  2.1698e+00,\n",
      "          -1.0830e+00, -4.2752e-01, -1.8441e+00, -5.0138e-01,  3.3747e-01,\n",
      "           7.0500e-01, -6.9657e-01, -6.2817e-01,  2.9226e-01, -1.5789e+00,\n",
      "          -1.1088e+00,  1.5816e+00, -6.1422e-01,  1.3098e+00, -2.9802e+00,\n",
      "           4.0362e+00,  5.8523e-01,  4.3465e-02, -1.5803e+00,  0.0000e+00,\n",
      "           7.4168e-01, -3.2488e+00,  0.0000e+00, -8.5239e-01,  1.1179e-02,\n",
      "           2.7534e-01,  2.7494e-01,  2.5260e-01,  0.0000e+00,  3.8661e-01,\n",
      "          -3.6556e-01, -1.5860e-01, -5.5406e-01, -5.2650e-02, -1.1471e+00,\n",
      "          -1.1315e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0449, 0.0412, 0.0725, 0.0671, 0.1018, 0.3581, 0.0614, 0.0768, 0.0576,\n",
      "         0.1186]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3507, -0.0342,  0.0771,  ..., -0.1153, -0.0143, -0.4829],\n",
      "        [ 0.1221,  0.1359,  0.2683,  ...,  0.1107,  0.0887,  0.0403],\n",
      "        [ 0.1005, -0.0569, -0.0162,  ..., -0.4293,  0.1223,  0.3129],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2576e-01,  4.4180e-02, -7.8801e-02,  7.8419e-03,  7.9304e-02,\n",
      "           5.6531e-02, -3.9634e-02, -7.3723e-02,  2.1092e-04,  3.0596e-03,\n",
      "          -3.4356e-02, -5.0412e-02, -5.6036e-02, -2.8856e-02,  9.0842e-02,\n",
      "           4.5847e-02,  4.9161e-02,  2.4697e-02, -2.1797e-01, -8.4978e-02,\n",
      "          -1.1161e-01, -2.1818e-02, -2.9272e-04,  1.9770e-02, -1.0217e-01,\n",
      "          -7.1570e-02,  1.8327e-02, -6.4429e-02, -5.6689e-02, -5.5636e-02,\n",
      "           6.1358e-02, -3.8926e-02, -1.1222e-01, -8.8128e-02, -1.5177e-02,\n",
      "          -7.3686e-03, -7.3998e-02, -3.0852e-02, -8.7587e-02, -8.0861e-03,\n",
      "           9.8370e-03,  7.4398e-02, -4.5247e-02, -2.4363e-02,  8.8903e-02,\n",
      "           5.4558e-02,  3.8663e-02, -4.4040e-02,  3.4450e-02,  2.9291e-03,\n",
      "          -5.2966e-02, -1.3761e-01, -3.8554e-02, -9.4469e-03, -9.5798e-02,\n",
      "           2.8840e-02,  2.5147e-02,  1.2071e-01,  1.0282e-01,  8.5918e-02,\n",
      "          -2.3016e-02,  1.1081e-02, -5.5481e-02,  1.1864e-01, -2.5127e-02,\n",
      "           2.4007e-02, -4.6406e-03,  3.5234e-02, -1.2467e-01,  2.6468e-04,\n",
      "          -3.6081e-03,  1.1195e-01, -6.3646e-02,  2.9643e-02, -1.3648e-01,\n",
      "           1.0827e-01,  9.7314e-02, -3.5996e-02, -2.7944e-03,  2.8588e-02,\n",
      "          -1.3095e-01, -8.8537e-02, -8.1516e-02,  5.4317e-04,  1.5782e-02,\n",
      "           8.3874e-02,  2.4426e-02,  5.3019e-02,  7.4602e-02,  2.0623e-02,\n",
      "           4.9298e-02,  6.9975e-02, -1.6946e-02, -4.4717e-02,  4.1838e-02,\n",
      "           4.6439e-02,  1.2064e-01,  1.5852e-01, -4.0144e-02,  9.7318e-02,\n",
      "          -4.8944e-02,  5.5344e-02,  6.2188e-02,  3.0344e-02, -3.7375e-02,\n",
      "          -4.6120e-02,  8.6342e-02,  9.2788e-03, -6.2388e-02,  8.1232e-02,\n",
      "          -2.2936e-02, -1.1442e-02, -4.7964e-02, -9.6956e-02, -4.0413e-02,\n",
      "           3.1669e-02,  4.6209e-02, -9.0869e-02,  9.1237e-03, -1.5001e-01,\n",
      "           2.4193e-02, -1.0400e-01, -1.2928e-01,  9.6049e-02, -1.0056e-01,\n",
      "          -9.9400e-02,  5.5703e-02, -3.3302e-02,  1.3972e-01,  5.1469e-02,\n",
      "           6.8020e-02, -7.1557e-02,  8.6363e-02,  9.3189e-02, -2.6514e-02,\n",
      "          -4.8347e-02,  8.3188e-02,  5.3395e-02, -1.9540e-02,  6.0344e-02,\n",
      "          -1.0485e-02,  1.0154e-01, -7.7539e-02,  4.7854e-02,  1.6348e-03,\n",
      "          -5.6268e-02,  1.2840e-01,  1.5131e-01,  3.2289e-02,  3.5793e-02,\n",
      "          -1.6352e-01, -1.1969e-02,  1.0120e-01,  8.6421e-02,  4.8411e-02,\n",
      "           1.7056e-01, -8.9071e-03,  1.2530e-01, -2.0356e-02, -2.8040e-02,\n",
      "          -2.3381e-02, -4.5935e-02, -1.5635e-01,  1.3880e-01, -1.5382e-02,\n",
      "          -1.3174e-02, -8.1377e-02, -1.7701e-03,  2.4750e-03,  1.4153e-01,\n",
      "          -4.7614e-02, -2.8142e-02,  6.7117e-02,  8.3226e-02,  6.9573e-03,\n",
      "          -9.0328e-02, -7.2671e-02,  1.0027e-01,  1.1763e-01, -1.8673e-02,\n",
      "          -6.8257e-02,  3.3466e-02, -1.1230e-01, -7.4092e-02,  2.3898e-02,\n",
      "           8.5816e-02, -7.5377e-02,  3.8297e-02,  3.1676e-03, -6.7352e-02,\n",
      "           7.2629e-02, -7.7282e-03, -1.6601e-01, -8.8394e-03, -3.3815e-02,\n",
      "          -2.2810e-02, -3.1673e-02,  5.8856e-02, -5.7953e-02,  6.6349e-02,\n",
      "          -2.2628e-02,  1.0826e-01, -2.7168e-02,  8.3831e-02, -4.4600e-02,\n",
      "          -2.0317e-03, -8.5475e-02,  9.7717e-02,  6.7541e-03, -5.0954e-02,\n",
      "           2.0265e-02, -9.3992e-02, -6.4116e-02,  4.5668e-02,  2.5552e-02,\n",
      "           3.4989e-02, -9.2523e-03,  8.9276e-02, -1.4001e-01, -7.9090e-03,\n",
      "           1.1423e-01, -3.1112e-02,  9.2760e-02, -3.0774e-02,  2.8041e-02,\n",
      "           9.4074e-02,  3.7296e-02, -1.6388e-01, -2.0439e-01,  6.8516e-02,\n",
      "          -8.9796e-02, -7.4635e-02, -7.4531e-02, -5.3396e-02, -5.8712e-02,\n",
      "          -2.9628e-02, -1.0943e-01, -6.1580e-02,  5.0895e-02, -3.0755e-02,\n",
      "           3.7034e-02, -1.2345e-01, -1.4511e-01,  4.0963e-02,  4.4328e-02,\n",
      "          -1.5356e-02, -7.0080e-02, -1.4632e-01,  2.6528e-02,  1.3441e-02,\n",
      "          -2.9953e-03,  3.3440e-04, -7.2907e-02, -1.1113e-01,  4.6546e-02,\n",
      "           3.7876e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4749, -0.4594, -1.2340, -0.1175,  0.4620,  0.0254,  0.6622,\n",
      "           0.5340,  0.6703,  0.9337,  1.7088, -1.0166,  0.9475, -0.2519,\n",
      "          -1.6346,  0.0000,  1.8780, -0.7564, -1.5627, -2.6442, -1.1340,\n",
      "           0.1678,  2.9305,  0.5544, -0.1166,  0.0000,  0.0000,  0.0000,\n",
      "          -2.2262, -1.2856,  0.0296,  1.0135,  0.3244,  0.8606, -0.7991,\n",
      "          -1.4656,  0.6200, -0.7715,  1.9920,  0.1026,  0.4677, -2.2045,\n",
      "          -0.5666, -0.1156, -0.7133, -0.6898,  1.9283,  0.0000, -0.2871,\n",
      "          -1.8509,  1.4685,  0.4636,  0.6679, -0.2839,  0.5317,  0.2747,\n",
      "          -1.2420, -0.9519,  0.0000, -0.0115,  0.2046,  0.0000, -1.4022,\n",
      "          -0.8067,  1.1794,  0.2653, -0.1664, -0.2563,  0.0000,  0.0000,\n",
      "          -0.3254, -0.3246,  0.1476, -0.1271,  0.6588, -0.8067,  2.0663,\n",
      "           1.6806,  0.0877, -0.5468,  1.2272,  0.0000,  0.3273,  0.0000,\n",
      "          -0.0723, -1.7332, -1.4584,  0.0000,  0.6233,  0.8106,  0.0000,\n",
      "           0.0000,  0.0000, -0.3655, -0.7339,  0.1564,  2.1425,  0.0000,\n",
      "          -0.3040, -1.8398, -1.2905, -0.7222, -0.7664,  0.2384,  0.3822,\n",
      "           1.1138, -1.0694,  2.2532, -0.2628, -0.2879, -0.0533,  0.6109,\n",
      "          -0.2558, -0.2802, -1.9429,  1.1282,  1.0061, -2.4990, -0.5744,\n",
      "           0.0298, -1.6959, -0.4013, -0.3800, -0.0793, -0.5374, -1.1121,\n",
      "           1.3058,  0.0000,  0.3225,  1.3585,  2.0804, -2.6346,  0.3583,\n",
      "           0.0000,  0.0000,  0.0596,  0.3274, -2.1036, -0.4968, -1.6782,\n",
      "          -0.6425,  0.2340, -1.1875, -1.2158, -0.6317, -0.0412,  0.4652,\n",
      "           1.7386,  1.5937,  1.4316, -1.2628, -0.5776, -0.4804, -0.0395,\n",
      "           0.3271, -0.1161,  1.3541, -0.0309, -1.9011, -1.8060, -1.4272,\n",
      "           0.0000, -0.7053, -0.3892, -0.9825, -0.1292,  0.4065,  0.0000,\n",
      "           0.0000, -0.1471,  1.5154, -0.3733,  0.0000, -2.0089,  0.1287,\n",
      "          -0.3526, -0.8316, -0.7702, -0.0396, -0.9379,  0.7283,  1.0423,\n",
      "           0.0472,  0.4633,  0.3169, -0.1180, -0.5431, -0.6645,  0.7557,\n",
      "          -1.0646, -0.5858, -1.7886,  1.2674, -0.9270, -1.6149, -0.3330,\n",
      "           0.0000, -1.9611, -0.0720, -0.3759,  2.6987, -0.9217, -2.6329,\n",
      "          -0.5862, -0.7172, -1.3863, -1.2543,  0.1721,  0.2182, -1.1116,\n",
      "           0.9459, -0.6920, -1.5201,  0.0000,  0.2370, -1.4275,  0.0000,\n",
      "           0.0469, -1.4807,  0.4281,  0.0133, -0.9023,  0.3007, -1.1659,\n",
      "          -1.3025, -0.1874,  1.2725,  1.2668, -2.1883, -0.0567,  1.7372,\n",
      "          -1.1753,  0.9567,  1.9992,  0.5267,  0.7906,  0.0000,  0.1046,\n",
      "          -0.6810,  0.0000,  0.1677, -0.3151, -1.0437, -0.3820, -1.0803,\n",
      "           0.5585,  0.0000, -0.5648, -1.3779,  1.2437,  0.5824,  1.7537,\n",
      "           0.0000,  0.3623,  0.0000,  0.3905]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0199, 0.2212, 0.0627, 0.0754, 0.1204, 0.1597, 0.0363, 0.1613, 0.0898,\n",
      "         0.0532]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3507, -0.0342,  0.0771,  ..., -0.1153, -0.0143, -0.4829],\n",
      "        [ 0.1221,  0.1359,  0.2683,  ...,  0.1107,  0.0887,  0.0403],\n",
      "        [ 0.1005, -0.0569, -0.0162,  ..., -0.4293,  0.1223,  0.3129],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5417e-01,  7.8325e-02, -4.7939e-02,  5.1350e-02,  1.5537e-01,\n",
      "           1.0721e-01, -9.3533e-02, -3.1730e-02,  5.1126e-02,  4.5792e-02,\n",
      "          -7.3373e-02, -4.4103e-02, -4.5093e-02, -1.7359e-02,  1.0067e-01,\n",
      "           1.1427e-01,  1.0271e-01,  6.0638e-03, -3.3551e-01, -1.0488e-01,\n",
      "          -1.8162e-01, -9.1535e-03, -5.2887e-02, -3.3334e-02, -1.3219e-01,\n",
      "          -1.6963e-01,  2.8006e-02, -5.8539e-02, -7.3160e-02, -7.6577e-02,\n",
      "           4.9500e-02,  3.2340e-04, -1.1481e-01, -3.6836e-02, -5.3450e-02,\n",
      "          -1.9176e-02, -1.6925e-01, -4.8915e-02, -1.2964e-01, -5.4161e-02,\n",
      "           2.6832e-02,  8.2269e-02, -3.3588e-02, -2.0422e-02,  1.6763e-01,\n",
      "           2.5021e-02,  9.3977e-02,  1.9303e-02,  6.9580e-02,  8.3308e-04,\n",
      "          -9.7556e-02, -2.5668e-01,  2.1215e-02, -3.9186e-02, -1.6400e-01,\n",
      "           3.4607e-02,  4.3886e-02,  1.7871e-01,  1.2405e-01,  1.6128e-01,\n",
      "           4.5746e-04,  1.4712e-02, -5.5465e-02,  1.4184e-01, -3.8241e-02,\n",
      "           6.0823e-03,  2.9460e-02, -1.6977e-02, -1.5495e-01, -5.0044e-02,\n",
      "           4.5200e-02,  1.8008e-01, -1.7572e-01,  4.8484e-02, -2.1248e-01,\n",
      "           1.0139e-01,  1.3302e-01, -6.1507e-02,  1.6181e-02, -1.9296e-02,\n",
      "          -2.2321e-01, -1.3880e-01, -8.9519e-02,  2.5132e-02,  5.3891e-02,\n",
      "           1.1202e-01,  6.2790e-02,  6.1629e-02,  4.5765e-02,  7.5815e-02,\n",
      "          -1.0751e-03,  9.9691e-02, -2.7244e-02, -5.8467e-02,  8.1670e-02,\n",
      "           8.6362e-02,  1.8720e-01,  2.2231e-01, -1.1182e-01,  1.1735e-01,\n",
      "          -1.1093e-01,  5.0291e-02,  1.0980e-01,  3.3522e-02, -7.1799e-02,\n",
      "          -4.6696e-02,  1.2608e-01, -4.2867e-02, -1.0701e-01,  9.6819e-02,\n",
      "          -7.9491e-02, -3.1531e-02, -5.7117e-02, -5.6101e-02,  3.2050e-02,\n",
      "          -6.5699e-03,  7.2439e-02, -1.4427e-01,  1.0094e-02, -2.1973e-01,\n",
      "           8.8765e-02, -1.3481e-01, -1.3113e-01,  1.0530e-01, -1.6995e-01,\n",
      "          -1.2049e-01,  1.3817e-01,  7.7231e-03,  2.5072e-01,  1.2114e-01,\n",
      "           5.9009e-02, -1.2058e-01,  1.5175e-01,  6.5146e-02, -9.0654e-02,\n",
      "          -9.6191e-02,  1.7585e-01,  5.5725e-02,  6.9047e-02,  7.7325e-02,\n",
      "           5.3450e-02,  1.6246e-01, -5.0051e-03,  1.3273e-01, -4.5316e-02,\n",
      "          -2.8060e-02,  2.2141e-01,  1.7324e-01, -3.9580e-02,  2.6829e-02,\n",
      "          -2.0887e-01, -4.9154e-02,  1.7599e-01,  1.8590e-01,  8.1548e-03,\n",
      "           2.2945e-01,  1.0172e-02,  1.8018e-01, -2.4729e-03,  4.1734e-02,\n",
      "          -3.4688e-03, -1.8985e-02, -1.7727e-01,  1.6397e-01, -4.7710e-02,\n",
      "          -6.0708e-02, -9.8764e-02, -1.9869e-02, -7.6682e-02,  2.2310e-01,\n",
      "          -1.6976e-02, -8.5020e-02,  3.5645e-02,  1.6638e-01,  6.2104e-02,\n",
      "          -1.0753e-01, -9.4014e-02,  1.1251e-01,  1.1713e-01, -3.9493e-02,\n",
      "          -6.5040e-02,  8.2172e-02, -1.7717e-01, -1.0999e-01,  4.2710e-02,\n",
      "           1.1063e-01, -5.2087e-02,  3.2765e-02,  4.0051e-02, -1.2218e-01,\n",
      "           1.1957e-01, -6.7109e-02, -1.9338e-01, -1.7725e-02, -6.2431e-02,\n",
      "           2.8787e-02,  2.8473e-02,  1.0559e-01, -7.1555e-02,  6.5871e-02,\n",
      "          -4.1605e-02,  1.1314e-01, -1.5510e-02,  9.6266e-02, -4.1019e-02,\n",
      "           6.2094e-03, -1.1283e-01,  1.1802e-01,  3.8308e-03, -4.5203e-02,\n",
      "           7.8800e-02, -1.3341e-01, -1.0435e-01, -8.9467e-03,  2.6429e-02,\n",
      "          -8.9016e-03,  6.9913e-02,  1.5123e-01, -2.4140e-01, -1.3787e-03,\n",
      "           1.4085e-01, -4.6706e-02,  1.4306e-01, -4.5956e-02, -1.0523e-02,\n",
      "           1.9744e-01,  5.6883e-02, -2.0730e-01, -3.0149e-01,  8.6550e-02,\n",
      "          -1.5725e-01, -1.3152e-01, -5.8023e-02, -7.9094e-02, -6.4772e-02,\n",
      "          -7.4607e-02, -1.4248e-01, -1.0004e-01,  3.7626e-02, -8.8459e-03,\n",
      "           8.3695e-02, -1.1748e-01, -2.5895e-01,  4.9701e-02,  1.3335e-01,\n",
      "          -9.1727e-03, -1.2460e-01, -1.9566e-01, -3.9940e-02, -1.7531e-02,\n",
      "          -2.1730e-02,  2.4729e-02, -8.7262e-02, -9.6175e-02,  6.6270e-02,\n",
      "           5.9954e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0629e+00, -6.9873e-02,  0.0000e+00,  1.3221e+00,  5.1610e-01,\n",
      "          -3.7641e-01,  1.1921e-03, -7.2329e-01,  0.0000e+00, -2.1397e-01,\n",
      "           2.8244e-01,  0.0000e+00, -1.1108e+00,  0.0000e+00,  3.1216e-01,\n",
      "           3.5181e-01, -6.8295e-01,  1.6900e-01,  8.7477e-01,  5.4567e-01,\n",
      "           0.0000e+00,  6.0179e-01, -3.6620e-02,  0.0000e+00, -9.9799e-02,\n",
      "           0.0000e+00,  0.0000e+00, -1.3624e+00, -2.1269e+00, -1.0342e+00,\n",
      "           3.9011e-02,  0.0000e+00, -2.0765e+00,  3.1566e-01, -2.8500e-01,\n",
      "          -2.0018e+00,  2.1910e-01,  9.9694e-01,  6.0110e-01,  9.5377e-01,\n",
      "          -2.2535e-01,  0.0000e+00, -7.0645e-01,  1.3962e+00,  8.9440e-02,\n",
      "          -1.1386e+00,  2.4265e-01,  7.4174e-01, -7.0976e-01, -1.3358e+00,\n",
      "           1.6090e+00, -1.3709e-01,  6.6302e-01,  1.1163e+00,  5.6742e-01,\n",
      "           3.3337e-01, -4.4976e-01, -8.8837e-01,  0.0000e+00,  6.2858e-01,\n",
      "          -7.0521e-01,  5.6369e-01,  0.0000e+00, -1.5473e+00,  2.8932e-01,\n",
      "           9.5637e-02, -1.7770e-01,  5.9469e-01, -2.1382e+00,  5.5971e-01,\n",
      "           0.0000e+00,  0.0000e+00, -3.4118e-01, -1.1318e+00, -6.4721e-01,\n",
      "           0.0000e+00, -1.0495e+00,  1.1904e-01,  5.1727e-01, -1.8682e-01,\n",
      "          -3.8490e-01,  2.1582e+00,  7.7758e-01, -8.4574e-01,  3.9775e-01,\n",
      "           4.1924e-01,  1.6043e+00,  0.0000e+00,  0.0000e+00, -1.4906e+00,\n",
      "           4.0433e-01, -3.5172e-01,  4.9410e-01, -2.3208e+00,  1.2380e+00,\n",
      "          -9.6281e-01,  1.3203e+00, -9.0772e-01,  2.3910e+00,  9.5537e-01,\n",
      "          -1.2011e+00,  0.0000e+00,  0.0000e+00, -1.7336e+00,  3.6549e-01,\n",
      "           4.0226e-01, -1.2707e+00,  4.5520e-01,  1.9686e+00,  1.4935e-01,\n",
      "          -8.3214e-01,  5.3386e-01,  8.0818e-01,  6.6421e-01, -1.0547e+00,\n",
      "           9.1755e-01, -7.0265e-01, -8.4528e-01,  2.5780e-01,  8.7979e-01,\n",
      "          -8.7674e-01, -1.3968e+00, -3.6493e-01, -1.8464e+00, -1.3007e+00,\n",
      "           1.0693e+00, -8.1166e-01,  6.4931e-01,  2.5573e-01,  0.0000e+00,\n",
      "           2.5026e+00,  3.7796e-01, -1.3458e+00,  7.2249e-01,  3.2015e+00,\n",
      "          -7.5275e-01, -3.8348e-01,  0.0000e+00,  0.0000e+00,  1.9397e-01,\n",
      "          -3.9422e-02,  3.0304e+00,  0.0000e+00, -1.8698e-01, -1.1118e+00,\n",
      "           1.2471e+00,  7.7540e-01, -7.7459e-01, -4.5024e-02, -1.3874e+00,\n",
      "           2.3360e+00,  7.6463e-01, -2.8968e-01, -2.1308e+00,  0.0000e+00,\n",
      "           7.8590e-01, -1.8621e+00, -1.3046e+00,  1.9019e-01, -3.6290e+00,\n",
      "          -1.8685e+00,  1.1506e+00, -8.5945e-01,  9.5973e-01, -1.4615e+00,\n",
      "          -2.7167e-02,  1.9744e+00,  1.1271e+00, -4.8605e-01, -1.2414e+00,\n",
      "          -2.1191e-01, -1.3225e+00, -1.6393e+00, -7.7182e-01,  6.8266e-01,\n",
      "          -1.3797e+00, -1.2630e-01,  6.0659e-01,  0.0000e+00,  2.5912e-01,\n",
      "           1.3326e+00, -2.5535e+00,  2.7791e-01, -5.8388e-01,  1.6237e+00,\n",
      "           0.0000e+00, -1.7984e-03, -5.0157e-02,  9.0153e-01,  5.6566e-01,\n",
      "          -4.1988e-01,  3.8801e-01, -1.1631e-01,  8.0964e-01,  1.0504e+00,\n",
      "          -7.8916e-01, -1.4389e+00, -4.1608e-01, -7.5043e-01, -4.5422e-01,\n",
      "          -5.4753e-01,  7.2228e-01, -1.8537e+00,  0.0000e+00,  8.3777e-01,\n",
      "          -1.5241e+00, -3.5880e-01,  6.4795e-01,  2.0066e-01, -2.1784e+00,\n",
      "           8.3556e-01, -1.2913e+00,  0.0000e+00,  2.6114e-01, -1.5634e+00,\n",
      "           2.0757e+00,  1.3421e-01,  2.5767e+00, -3.1226e-02, -5.7931e-01,\n",
      "          -1.4285e+00,  1.9011e+00, -3.8094e-01,  1.4693e+00,  8.0506e-01,\n",
      "           0.0000e+00,  6.6985e-01, -7.0067e-01,  8.9171e-02,  1.0255e+00,\n",
      "           9.7814e-01, -1.4085e+00,  6.5973e-01, -1.1451e+00, -1.6456e+00,\n",
      "          -6.0016e-01,  8.9159e-03, -7.1115e-01,  3.7058e-01, -2.2441e-01,\n",
      "          -7.5247e-01,  5.7212e-01,  5.3066e-01, -6.6343e-01,  1.5465e+00,\n",
      "           5.7857e-01,  1.8919e+00, -8.6436e-01,  4.9338e-01, -3.8736e-01,\n",
      "           0.0000e+00, -9.7531e-01,  1.7728e+00, -1.0634e+00, -8.0795e-01,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0582, 0.1333, 0.0949, 0.1076, 0.1081, 0.2015, 0.0713, 0.0568, 0.0706,\n",
      "         0.0975]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3507, -0.0342,  0.0771,  ..., -0.1153, -0.0143, -0.4829],\n",
      "        [ 0.1221,  0.1359,  0.2683,  ...,  0.1107,  0.0887,  0.0403],\n",
      "        [ 0.1005, -0.0569, -0.0162,  ..., -0.4293,  0.1223,  0.3129],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.6544e-01,  5.6424e-02, -6.9988e-02,  2.5039e-02,  1.6360e-01,\n",
      "           1.2365e-01, -9.1478e-02, -6.1329e-02,  1.6158e-02,  3.0740e-02,\n",
      "          -7.0080e-02, -4.8543e-02, -5.8297e-02, -2.7258e-02,  1.1594e-01,\n",
      "           1.0148e-01,  8.0122e-02,  2.2483e-02, -3.2835e-01, -1.2771e-01,\n",
      "          -1.6541e-01, -8.6150e-03, -3.2709e-02, -1.4353e-02, -1.3656e-01,\n",
      "          -1.1321e-01,  4.1582e-02, -7.0804e-02, -6.8463e-02, -7.3051e-02,\n",
      "           7.2765e-02, -1.5863e-02, -1.3749e-01, -8.3447e-02, -4.1247e-02,\n",
      "          -2.7523e-02, -1.2500e-01, -3.9414e-02, -1.1055e-01, -3.0435e-02,\n",
      "           2.3476e-02,  1.0900e-01, -4.2254e-02, -4.1385e-02,  1.3874e-01,\n",
      "           4.9898e-02,  9.0737e-02, -5.6680e-03,  5.6101e-02,  2.3847e-05,\n",
      "          -6.9332e-02, -2.3494e-01, -8.9668e-03, -3.0618e-02, -1.5763e-01,\n",
      "           3.8553e-02,  4.1803e-02,  1.7745e-01,  1.3446e-01,  1.2598e-01,\n",
      "          -1.3030e-02,  1.5155e-02, -6.1311e-02,  1.6892e-01, -2.9444e-02,\n",
      "           2.5655e-02,  9.3458e-03,  1.3801e-02, -1.7678e-01, -1.9941e-02,\n",
      "           1.5302e-02,  1.7246e-01, -1.2600e-01,  2.9739e-02, -2.0013e-01,\n",
      "           1.4587e-01,  1.3238e-01, -7.3293e-02,  1.1232e-02,  8.9229e-03,\n",
      "          -2.0272e-01, -1.0699e-01, -9.4098e-02,  1.8632e-02,  4.3995e-02,\n",
      "           1.1223e-01,  5.2055e-02,  7.7341e-02,  7.4462e-02,  6.8702e-02,\n",
      "           3.2696e-02,  1.1032e-01, -3.4263e-02, -6.8628e-02,  7.6012e-02,\n",
      "           7.8572e-02,  1.8198e-01,  2.2253e-01, -7.0525e-02,  1.1762e-01,\n",
      "          -6.8676e-02,  7.0822e-02,  9.0336e-02,  3.7905e-02, -4.0749e-02,\n",
      "          -5.4571e-02,  1.1894e-01, -2.2494e-02, -1.0003e-01,  1.0885e-01,\n",
      "          -7.1717e-02, -1.5931e-02, -8.4939e-02, -9.2312e-02, -2.1125e-03,\n",
      "           2.6878e-02,  7.5497e-02, -1.3627e-01,  2.0531e-02, -2.2240e-01,\n",
      "           5.3659e-02, -1.4212e-01, -1.5806e-01,  1.2949e-01, -1.5950e-01,\n",
      "          -1.3328e-01,  1.0796e-01, -1.9325e-02,  2.2286e-01,  1.0825e-01,\n",
      "           7.3016e-02, -8.8141e-02,  1.1998e-01,  1.0238e-01, -4.8388e-02,\n",
      "          -1.0217e-01,  1.2675e-01,  7.6770e-02,  4.1485e-02,  7.8979e-02,\n",
      "           1.5641e-02,  1.5239e-01, -6.4406e-02,  8.3841e-02, -3.6276e-02,\n",
      "          -5.7836e-02,  2.1319e-01,  1.9830e-01,  7.5703e-03,  3.0364e-02,\n",
      "          -2.1861e-01, -3.2497e-02,  1.6303e-01,  1.4377e-01,  4.0271e-02,\n",
      "           2.3971e-01,  1.2646e-03,  1.8611e-01, -4.1755e-02,  1.0534e-02,\n",
      "          -1.9124e-02, -2.9201e-02, -2.0323e-01,  1.7637e-01, -5.0559e-02,\n",
      "          -5.4330e-02, -1.0948e-01,  1.6503e-03, -6.5075e-02,  1.9791e-01,\n",
      "          -3.4075e-02, -6.3487e-02,  5.9884e-02,  1.6355e-01,  4.9150e-02,\n",
      "          -1.2259e-01, -9.5125e-02,  1.2629e-01,  1.3626e-01, -2.9136e-02,\n",
      "          -7.8821e-02,  8.2962e-02, -1.6664e-01, -1.1599e-01,  3.6271e-02,\n",
      "           1.0812e-01, -5.8754e-02,  2.8848e-02, -2.3141e-03, -9.8688e-02,\n",
      "           1.2330e-01, -5.0863e-02, -2.1562e-01,  4.7292e-04, -7.4126e-02,\n",
      "           6.2692e-03, -2.1140e-03,  1.0400e-01, -6.7719e-02,  7.4704e-02,\n",
      "          -3.5813e-02,  1.3529e-01, -2.4186e-02,  9.7680e-02, -7.3589e-02,\n",
      "           6.6853e-03, -1.2490e-01,  1.1850e-01,  1.4955e-02, -5.9679e-02,\n",
      "           3.7291e-02, -1.2655e-01, -1.0514e-01,  2.1911e-02,  4.2953e-02,\n",
      "           5.5531e-03,  4.9438e-02,  1.4209e-01, -2.1982e-01, -3.5663e-02,\n",
      "           1.5161e-01, -3.3278e-02,  1.3610e-01, -4.0328e-02,  1.8520e-03,\n",
      "           1.5910e-01,  3.9068e-02, -2.2774e-01, -3.0225e-01,  7.8536e-02,\n",
      "          -1.2042e-01, -1.2077e-01, -9.2880e-02, -5.4619e-02, -7.3251e-02,\n",
      "          -5.9449e-02, -1.5257e-01, -9.3364e-02,  5.3530e-02, -3.1245e-02,\n",
      "           7.7691e-02, -1.5341e-01, -2.2618e-01,  6.9755e-02,  8.8514e-02,\n",
      "          -2.1275e-02, -1.0124e-01, -2.0738e-01, -9.2540e-03, -1.7811e-02,\n",
      "          -1.8134e-02,  1.0901e-02, -8.2581e-02, -1.3897e-01,  7.5066e-02,\n",
      "           5.0014e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5915e-02,  3.9901e-01, -9.6666e-01, -6.8176e-01,  3.7631e-01,\n",
      "          -2.0185e-01,  1.4648e+00, -8.3299e-02,  0.0000e+00,  9.0676e-01,\n",
      "           4.2891e-01, -6.2918e-01,  2.6054e+00, -6.2979e-01, -5.4166e-01,\n",
      "          -1.5800e-01,  8.5150e-01,  1.0950e+00,  4.5519e-01,  4.3605e-01,\n",
      "          -6.3370e-01, -3.8347e-01,  1.6419e+00,  1.5113e+00,  7.5374e-01,\n",
      "          -7.5390e-02,  0.0000e+00, -7.5910e-01,  1.6540e+00,  8.6170e-01,\n",
      "           1.2320e+00,  1.2191e+00, -1.0344e+00,  0.0000e+00, -1.5349e+00,\n",
      "           1.3954e+00,  2.8087e-01, -3.7456e+00,  1.9812e-01,  1.6013e+00,\n",
      "          -4.5884e-01, -1.3986e+00, -2.6836e-01, -1.7165e+00, -1.5247e+00,\n",
      "           6.6736e-01,  0.0000e+00,  3.7033e-01,  0.0000e+00,  1.4389e-01,\n",
      "          -6.2908e-01,  2.7530e+00,  6.1047e-01, -1.0295e+00, -2.5667e-02,\n",
      "           2.0308e-01, -8.8228e-01, -1.2530e+00, -2.3661e-01, -4.2525e-01,\n",
      "           0.0000e+00,  1.4084e+00, -2.0350e-01, -5.0181e-01, -2.9649e+00,\n",
      "           5.5058e-01,  1.2791e+00, -1.2882e+00,  4.1160e-01,  5.2641e-01,\n",
      "           0.0000e+00, -3.0368e-02,  7.0747e-01, -3.6421e+00,  3.2628e-01,\n",
      "          -2.1761e-03, -1.5982e-01,  1.0629e+00, -5.8217e-02, -1.2001e-01,\n",
      "          -1.4005e+00,  2.1318e+00, -9.2490e-01,  1.0058e+00, -2.0785e-01,\n",
      "           4.3463e-01,  1.6619e+00, -9.7475e-01, -1.0340e-01, -5.8154e-01,\n",
      "          -2.2741e+00,  1.1005e+00,  0.0000e+00, -1.1354e+00,  4.6747e-01,\n",
      "          -1.1709e+00,  0.0000e+00,  6.2922e-01,  0.0000e+00, -7.8034e-01,\n",
      "           2.6977e+00,  0.0000e+00,  1.0761e+00,  1.4545e+00, -6.6643e-01,\n",
      "          -7.6263e-01,  0.0000e+00,  1.2733e-01, -1.4731e+00,  0.0000e+00,\n",
      "          -2.4889e-01,  1.3450e-01, -1.0487e+00,  1.3103e+00, -1.6538e+00,\n",
      "          -2.9903e+00, -5.6330e-02, -5.0127e-01,  0.0000e+00,  4.4485e-01,\n",
      "          -1.4670e+00,  7.0245e-01, -1.4609e+00,  0.0000e+00, -9.5873e-01,\n",
      "          -1.3093e+00,  8.9755e-01,  1.7043e-01,  1.2857e+00, -7.5263e-01,\n",
      "          -8.2332e-01,  5.2982e-01, -1.5835e+00,  9.8420e-01,  2.7616e-01,\n",
      "          -5.8969e-01,  6.5987e-01,  5.7367e-01, -1.1586e+00, -1.0105e+00,\n",
      "          -3.8893e-01,  6.7782e-01, -7.9004e-01,  0.0000e+00, -1.6863e+00,\n",
      "          -1.0122e-01, -5.4331e-01, -8.4454e-01, -7.5558e-01,  1.7743e-01,\n",
      "           1.9991e+00,  0.0000e+00, -1.9310e+00, -4.0620e-01,  4.4150e-01,\n",
      "          -1.9443e-01, -6.4256e-02, -1.2897e-01,  3.9385e-02,  0.0000e+00,\n",
      "          -2.6205e-02,  2.2067e+00,  4.8120e-01, -5.4982e-01, -5.2727e-01,\n",
      "          -8.9283e-01,  0.0000e+00,  8.4388e-02, -3.5801e-01, -4.7811e-01,\n",
      "           7.3797e-01, -3.2226e-02,  1.9899e-02, -1.0020e+00,  1.2779e+00,\n",
      "          -1.0991e+00, -9.8771e-01, -2.0776e+00,  1.9696e+00,  8.6485e-02,\n",
      "          -2.9833e-02,  3.5063e-02,  6.7159e-01,  9.7988e-01, -7.4704e-01,\n",
      "          -3.4094e-01, -2.7838e+00, -7.8450e-01,  1.2099e+00,  1.0125e+00,\n",
      "           3.0751e+00,  4.9449e-01, -1.4419e-01, -5.9462e-01,  5.6079e-01,\n",
      "           2.1657e+00, -1.1882e+00,  5.3487e-01,  1.8121e+00, -9.4745e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2419e+00,  0.0000e+00,  2.3197e-01,\n",
      "          -5.7538e-01, -2.2933e+00,  6.8185e-01, -1.0746e+00, -4.7141e-01,\n",
      "           2.8686e+00, -5.7335e-01, -3.4120e-01,  7.9325e-01,  2.9962e-02,\n",
      "          -6.8473e-01, -1.0194e+00,  9.6628e-01, -2.4584e-01,  2.1699e+00,\n",
      "          -1.0830e+00, -4.2754e-01, -1.8442e+00, -5.0147e-01,  3.3740e-01,\n",
      "           7.0495e-01, -6.9661e-01, -6.2818e-01,  2.9225e-01, -1.5789e+00,\n",
      "          -1.1089e+00,  1.5816e+00, -6.1427e-01,  1.3098e+00, -2.9803e+00,\n",
      "           4.0364e+00,  5.8525e-01,  4.3473e-02, -1.5804e+00, -2.8747e-01,\n",
      "           7.4171e-01, -3.2489e+00, -3.0461e-01, -8.5250e-01,  1.1177e-02,\n",
      "           2.7534e-01,  2.7499e-01,  2.5264e-01,  0.0000e+00,  3.8663e-01,\n",
      "          -3.6561e-01, -1.5853e-01, -5.5406e-01, -5.2634e-02, -1.1472e+00,\n",
      "          -1.1315e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0350, 0.0561, 0.0966, 0.0926, 0.1232, 0.2835, 0.0559, 0.0787, 0.0727,\n",
      "         0.1057]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3508, -0.0341,  0.0779,  ..., -0.1149, -0.0136, -0.4830],\n",
      "        [ 0.1232,  0.1356,  0.2684,  ...,  0.1102,  0.0919,  0.0424],\n",
      "        [-0.0025,  0.2642, -0.0746,  ...,  0.1174, -0.1129, -0.4203],\n",
      "        ...,\n",
      "        [ 0.0724, -0.3265,  0.6051,  ..., -0.0250, -0.0708, -0.3244],\n",
      "        [ 0.4429, -0.0821,  0.1127,  ..., -0.3455,  0.3880, -0.2383],\n",
      "        [ 0.6952,  0.4474, -0.5897,  ..., -0.3215,  0.0456,  0.0459]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.6204e-01, -1.8211e-01, -3.5689e-02, -9.9708e-02,  8.3801e-02,\n",
      "          -1.3863e-01, -1.7393e-01,  9.1392e-02,  7.4472e-03,  1.6227e-01,\n",
      "           7.1107e-02, -7.2989e-02,  7.9688e-02, -2.8511e-02,  2.7657e-01,\n",
      "          -3.8693e-03,  1.8224e-01,  9.4350e-02, -2.0815e-01, -6.3310e-02,\n",
      "           8.9304e-02, -2.0330e-01, -2.0611e-02, -4.8592e-02, -5.7462e-02,\n",
      "          -2.3042e-01, -4.4690e-02, -1.2138e-01,  7.7992e-02,  1.7572e-01,\n",
      "          -8.6596e-02,  1.8793e-02,  1.1883e-02,  1.5860e-01, -1.1018e-01,\n",
      "          -1.6061e-01, -1.4926e-01, -8.7832e-02, -7.4248e-02, -1.8842e-01,\n",
      "           2.4875e-02,  1.4654e-01, -3.2632e-01, -1.0946e-01,  1.2785e-01,\n",
      "           1.6705e-01, -7.8626e-02, -7.1950e-02,  2.5184e-01, -5.3656e-02,\n",
      "          -1.0546e-01,  6.7410e-02,  1.2240e-01,  2.3525e-01, -6.4640e-02,\n",
      "          -1.5800e-01, -1.6880e-01,  1.6199e-01,  2.6476e-01,  1.9705e-01,\n",
      "          -1.1867e-01, -2.7543e-02, -1.4935e-01,  4.4686e-02,  1.2026e-01,\n",
      "          -7.1650e-03, -2.6596e-01,  9.0904e-02,  1.5608e-01,  1.0165e-01,\n",
      "          -1.2028e-02,  1.4070e-01, -4.9481e-02,  3.8822e-02, -2.4495e-01,\n",
      "           2.2054e-01, -1.1376e-01,  4.4365e-02, -4.9932e-02,  2.6009e-01,\n",
      "          -1.9409e-01, -6.1995e-02, -4.0511e-01, -4.0010e-02, -1.9761e-01,\n",
      "           1.3838e-01,  1.7640e-02,  4.0242e-02,  1.9929e-02,  7.3999e-02,\n",
      "          -2.1049e-02,  1.4129e-01, -1.7530e-01, -4.1765e-02, -1.5938e-02,\n",
      "           2.1340e-01,  4.6434e-02,  3.1403e-02, -1.1794e-02, -7.1032e-02,\n",
      "          -1.4780e-01, -1.9887e-01,  1.7569e-01, -5.4795e-02, -2.3463e-01,\n",
      "          -6.3350e-02, -2.2082e-01, -1.9816e-01, -3.0852e-01,  1.3613e-01,\n",
      "          -2.3108e-01,  4.4421e-01,  6.0098e-02, -7.7393e-02, -4.1208e-02,\n",
      "           6.5084e-03,  1.3398e-01, -2.1704e-01, -7.6931e-02, -3.9252e-01,\n",
      "           2.6558e-01, -3.6765e-01, -1.8915e-01, -3.7950e-03, -1.1586e-01,\n",
      "          -2.0555e-01,  2.6041e-01,  1.0310e-02,  2.1441e-01, -1.2730e-02,\n",
      "           2.7529e-01, -2.3672e-01, -1.1998e-01, -5.3174e-03, -1.3403e-01,\n",
      "           1.4009e-01,  2.5203e-01,  1.5140e-01,  2.5344e-01,  2.4433e-02,\n",
      "          -1.3498e-01,  2.0551e-01,  1.4448e-01,  2.0741e-01, -1.6001e-01,\n",
      "           2.1546e-01, -2.6816e-02,  1.4302e-02,  1.4447e-01,  1.8406e-01,\n",
      "          -4.5676e-02, -1.3917e-01,  1.3536e-01,  5.2628e-02,  8.3377e-03,\n",
      "           2.3298e-01, -7.5099e-02,  1.5813e-01,  5.2529e-02,  3.4423e-02,\n",
      "           2.4582e-01,  1.0513e-01,  6.0722e-02,  1.4448e-01, -1.9611e-01,\n",
      "          -5.9305e-02, -9.7652e-02, -1.8207e-01,  4.2225e-02, -1.6748e-02,\n",
      "          -2.0883e-02, -7.2703e-02,  2.4392e-01,  2.8724e-01,  2.8421e-01,\n",
      "          -4.3491e-01, -1.1928e-01,  9.6545e-02, -1.2672e-01, -7.2775e-02,\n",
      "           8.6527e-02, -9.8275e-02, -1.8562e-02, -2.3959e-01, -4.2271e-02,\n",
      "          -7.2931e-02,  1.5048e-01, -4.7534e-02,  3.5831e-02, -2.0757e-01,\n",
      "          -5.2316e-02, -1.4555e-01, -4.1438e-02, -1.0259e-01, -2.1769e-01,\n",
      "          -2.0597e-01, -1.6631e-01,  1.1911e-04, -1.7562e-01,  7.9739e-02,\n",
      "           2.9618e-02,  2.0554e-01, -1.2863e-02,  9.1915e-03,  2.2770e-02,\n",
      "          -1.1168e-01,  5.1864e-02, -2.3550e-01,  1.3413e-01, -2.8996e-01,\n",
      "           1.5193e-01, -3.1320e-01, -2.9007e-02,  3.6717e-01, -1.3555e-01,\n",
      "           9.0255e-02, -1.4390e-01,  3.4530e-01, -1.1153e-01, -1.3771e-01,\n",
      "           1.1136e-01,  2.6371e-03,  2.3916e-01,  1.4720e-01,  2.1739e-02,\n",
      "           1.8464e-01,  7.2905e-03,  1.3445e-01, -9.8192e-02,  5.8752e-02,\n",
      "           4.7963e-02, -2.5420e-01, -2.6570e-01,  1.7184e-01,  6.5073e-02,\n",
      "           8.3417e-03, -5.7381e-02, -2.7528e-01,  2.2362e-01,  1.4896e-01,\n",
      "           1.0507e-01, -3.0817e-01, -4.6444e-01,  1.4328e-01, -1.0289e-02,\n",
      "          -5.4969e-03, -1.7187e-01, -1.0404e-01, -1.1589e-01,  5.3782e-02,\n",
      "           1.3548e-02, -8.8687e-03, -9.3647e-04, -1.8903e-01, -8.5289e-02,\n",
      "          -3.1678e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4749, -0.4595, -1.2341, -0.1176,  0.4620,  0.0254,  0.6623,\n",
      "           0.5340,  0.6703,  0.9338,  1.7089, -1.0166,  0.9477, -0.2517,\n",
      "          -1.6346,  0.5131,  1.8781, -0.7564, -1.5628, -2.6443,  0.0000,\n",
      "           0.0000,  2.9305,  0.0000, -0.1166,  3.2101,  1.8374,  0.5194,\n",
      "          -2.2261, -1.2855,  0.0296,  1.0135,  0.3244,  0.8605, -0.7992,\n",
      "          -1.4656,  0.6200, -0.7716,  1.9921,  0.1027,  0.4677, -2.2046,\n",
      "          -0.5665, -0.1156,  0.0000, -0.6898,  1.9284,  0.1099, -0.2871,\n",
      "          -1.8510,  1.4685,  0.4637,  0.6679,  0.0000,  0.5317,  0.2748,\n",
      "          -1.2421, -0.9519,  1.8149, -0.0116,  0.2047, -1.8178, -1.4022,\n",
      "          -0.8067,  1.1793,  0.2652, -0.1663, -0.2564, -0.0040, -0.4613,\n",
      "          -0.3254, -0.3246,  0.1476, -0.1272,  0.6588, -0.8067,  2.0662,\n",
      "           1.6806,  0.0876, -0.5469,  1.2272,  0.0000,  0.3273, -1.8369,\n",
      "          -0.0723, -1.7333, -1.4584,  0.0000,  0.6233,  0.8106, -1.2240,\n",
      "          -1.1446,  1.9857, -0.3655, -0.7339,  0.1564,  2.1426,  0.0000,\n",
      "          -0.3040, -1.8399, -1.2905, -0.7223, -0.7664,  0.2385,  0.3822,\n",
      "           1.1138, -1.0694,  2.2533, -0.2628, -0.2879, -0.0533,  0.6109,\n",
      "          -0.2558,  0.0000, -1.9430,  1.1282,  1.0061, -2.4990, -0.5744,\n",
      "           0.0298, -1.6961, -0.4014,  0.0000, -0.0793, -0.5374, -1.1121,\n",
      "           0.0000,  0.1703,  0.3226,  1.3584,  0.0000, -2.6347,  0.3582,\n",
      "          -0.7229,  0.4299,  0.0595,  0.3274, -2.1037, -0.4969, -1.6782,\n",
      "          -0.6425,  0.2340, -1.1875, -1.2159, -0.6318, -0.0412,  0.4652,\n",
      "           1.7385,  1.5937,  1.4317, -1.2628, -0.5776, -0.4804, -0.0395,\n",
      "           0.3271, -0.1161,  1.3542, -0.0309, -1.9011, -1.8060, -1.4271,\n",
      "          -0.9004, -0.7053, -0.3892, -0.9825, -0.1292,  0.4065,  0.9709,\n",
      "           0.5180, -0.1471,  1.5156, -0.3734, -0.3159, -2.0089,  0.1286,\n",
      "          -0.3527, -0.8317, -0.7702, -0.0395, -0.9380,  0.0000,  1.0423,\n",
      "           0.0472,  0.4634,  0.3170, -0.1180, -0.5432,  0.0000,  0.7557,\n",
      "          -1.0646, -0.5857, -1.7886,  1.2674, -0.9271, -1.6148, -0.3330,\n",
      "          -1.1573, -1.9612, -0.0719, -0.3759,  2.6988, -0.9216, -2.6330,\n",
      "          -0.5862, -0.7172, -1.3863, -1.2543,  0.1722,  0.2181, -1.1116,\n",
      "           0.9459, -0.6920, -1.5201,  0.3626,  0.2370, -1.4275, -2.3457,\n",
      "           0.0468, -1.4807,  0.0000,  0.0133, -0.9023,  0.3007, -1.1660,\n",
      "          -1.3026, -0.1875,  1.2725,  1.2668, -2.1883, -0.0567,  1.7372,\n",
      "          -1.1753,  0.9566,  1.9992,  0.5266,  0.7907, -0.6786,  0.1047,\n",
      "          -0.6811, -2.2628,  0.1677,  0.0000, -1.0437,  0.0000, -1.0803,\n",
      "           0.5585,  1.5008, -0.5648, -1.3780,  1.2437,  0.5824,  1.7537,\n",
      "           1.9512,  0.3623,  0.4867,  0.3905]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0214, 0.2528, 0.0820, 0.0446, 0.1327, 0.1539, 0.0244, 0.1473, 0.0885,\n",
      "         0.0525]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3508, -0.0341,  0.0779,  ..., -0.1149, -0.0136, -0.4830],\n",
      "        [ 0.1232,  0.1356,  0.2684,  ...,  0.1102,  0.0919,  0.0424],\n",
      "        [-0.0025,  0.2642, -0.0746,  ...,  0.1174, -0.1129, -0.4203],\n",
      "        ...,\n",
      "        [ 0.0724, -0.3265,  0.6051,  ..., -0.0250, -0.0708, -0.3244],\n",
      "        [ 0.4429, -0.0821,  0.1127,  ..., -0.3455,  0.3880, -0.2383],\n",
      "        [ 0.6952,  0.4474, -0.5897,  ..., -0.3215,  0.0456,  0.0459]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1450, -0.1210,  0.1087, -0.0171,  0.1619,  0.0227, -0.2625,\n",
      "           0.1870,  0.0528,  0.1689, -0.0280, -0.0490,  0.1093, -0.0305,\n",
      "           0.2158,  0.1155,  0.1584,  0.0307, -0.2453, -0.0996,  0.0244,\n",
      "          -0.1337, -0.1353, -0.1647, -0.0631, -0.2508,  0.0033, -0.0458,\n",
      "           0.0308,  0.1441, -0.1015,  0.0691,  0.0496,  0.1792, -0.2093,\n",
      "          -0.1332, -0.1599, -0.0954,  0.0028, -0.2051,  0.0786,  0.1472,\n",
      "          -0.2430, -0.1325,  0.1866,  0.0420,  0.0372,  0.0851,  0.1785,\n",
      "          -0.0241, -0.0697, -0.1111,  0.1818,  0.1246, -0.1302, -0.1069,\n",
      "          -0.1570,  0.2027,  0.1856,  0.2111, -0.0540, -0.0584, -0.1343,\n",
      "           0.0546,  0.0967,  0.0006, -0.1532, -0.0173,  0.1138,  0.0100,\n",
      "           0.0717,  0.2004, -0.1190,  0.0110, -0.2414,  0.1769, -0.0426,\n",
      "          -0.0198, -0.0325,  0.1299, -0.2240, -0.0039, -0.3145,  0.0035,\n",
      "          -0.0775,  0.0940,  0.0634,  0.0142, -0.0040,  0.1399, -0.1286,\n",
      "           0.1852, -0.1416, -0.0091,  0.0186,  0.1943,  0.1299,  0.0866,\n",
      "          -0.0706, -0.0797, -0.1386, -0.1263,  0.1532,  0.0199, -0.1772,\n",
      "           0.0122, -0.1690, -0.2037, -0.3222,  0.1161, -0.2932,  0.3407,\n",
      "           0.0037,  0.0413,  0.1202,  0.0018,  0.1353, -0.1912, -0.0435,\n",
      "          -0.3905,  0.2686, -0.3178, -0.0855,  0.0059, -0.2180, -0.1637,\n",
      "           0.2739,  0.0444,  0.2582,  0.0854,  0.1341, -0.1816, -0.0745,\n",
      "          -0.0232, -0.1724,  0.0401,  0.2445,  0.1289,  0.3606,  0.0249,\n",
      "          -0.0434,  0.2257,  0.2187,  0.2406, -0.1931,  0.1808,  0.1144,\n",
      "           0.0344,  0.0171,  0.0945, -0.0488, -0.1489,  0.1903,  0.1599,\n",
      "          -0.0207,  0.2587,  0.0062,  0.1276, -0.0190,  0.1123,  0.2225,\n",
      "           0.1388,  0.0888,  0.1120, -0.2346, -0.0998, -0.0385, -0.1590,\n",
      "          -0.1154,  0.0109,  0.0022, -0.1254,  0.0904,  0.3666,  0.3255,\n",
      "          -0.3439, -0.0775,  0.1119, -0.1336, -0.0314,  0.1050,  0.0095,\n",
      "          -0.0543, -0.2353, -0.0096, -0.0604,  0.1987, -0.0761, -0.0079,\n",
      "          -0.2089,  0.0535, -0.2280, -0.0441, -0.0616, -0.2299, -0.0433,\n",
      "          -0.0449,  0.0845, -0.0674,  0.0731,  0.0194,  0.1457,  0.0018,\n",
      "          -0.0059, -0.0367, -0.0927,  0.0069, -0.1781,  0.0588, -0.1858,\n",
      "           0.1623, -0.2405, -0.0806,  0.1972, -0.1016, -0.0271,  0.0313,\n",
      "           0.3549, -0.1939, -0.1279,  0.1098,  0.0489,  0.2698,  0.0971,\n",
      "          -0.0226,  0.2512, -0.0152,  0.0528, -0.1840,  0.0481, -0.0165,\n",
      "          -0.2731, -0.2152,  0.1449,  0.0830, -0.0470, -0.0299, -0.2550,\n",
      "           0.1469,  0.1263,  0.1770, -0.2529, -0.4775,  0.1682,  0.1216,\n",
      "          -0.0463, -0.1269, -0.1206, -0.1791, -0.0359,  0.0113, -0.0162,\n",
      "           0.0247, -0.1117, -0.0335, -0.2404]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0628e+00, -6.9870e-02, -1.8077e+00,  1.3221e+00,  5.1616e-01,\n",
      "          -3.7642e-01,  1.2031e-03, -7.2329e-01,  2.1179e+00, -2.1394e-01,\n",
      "           2.8240e-01,  8.3070e-01, -1.1109e+00,  1.9999e-01,  0.0000e+00,\n",
      "           3.5168e-01,  0.0000e+00,  1.6907e-01,  8.7476e-01,  5.4573e-01,\n",
      "           1.8833e+00,  0.0000e+00, -3.6595e-02, -5.3543e-01, -9.9782e-02,\n",
      "           6.5078e-01, -1.6087e+00, -1.3624e+00, -2.1269e+00, -1.0342e+00,\n",
      "           0.0000e+00, -1.4549e+00,  0.0000e+00,  0.0000e+00, -2.8504e-01,\n",
      "          -2.0018e+00,  2.1911e-01,  9.9699e-01,  6.0108e-01,  9.5374e-01,\n",
      "          -2.2535e-01, -2.2112e+00, -7.0644e-01,  1.3963e+00,  8.9448e-02,\n",
      "          -1.1385e+00,  0.0000e+00,  7.4171e-01, -7.0973e-01, -1.3358e+00,\n",
      "           0.0000e+00, -1.3717e-01,  6.6295e-01,  1.1163e+00,  5.6742e-01,\n",
      "           3.3345e-01, -4.4976e-01,  0.0000e+00,  1.3372e-01,  6.2851e-01,\n",
      "          -7.0521e-01,  5.6371e-01, -6.9330e-01, -1.5472e+00,  2.8934e-01,\n",
      "           9.5722e-02, -1.7766e-01,  5.9468e-01, -2.1382e+00,  5.5975e-01,\n",
      "           1.8289e-01, -5.1253e-01, -3.4122e-01, -1.1318e+00, -6.4723e-01,\n",
      "           4.6087e-01, -1.0495e+00,  1.1902e-01,  5.1720e-01, -1.8676e-01,\n",
      "           0.0000e+00,  2.1581e+00,  7.7755e-01, -8.4566e-01,  0.0000e+00,\n",
      "           4.1922e-01,  1.6044e+00,  0.0000e+00, -1.4134e+00, -1.4906e+00,\n",
      "           4.0437e-01, -3.5169e-01,  4.9410e-01, -2.3208e+00,  1.2380e+00,\n",
      "          -9.6276e-01,  1.3203e+00, -9.0769e-01,  2.3910e+00,  9.5540e-01,\n",
      "          -1.2011e+00,  5.9440e-01,  1.0666e+00, -1.7337e+00,  3.6547e-01,\n",
      "           4.0224e-01, -1.2707e+00,  4.5520e-01,  1.9687e+00,  1.4924e-01,\n",
      "          -8.3222e-01,  5.3382e-01,  8.0817e-01,  6.6421e-01, -1.0547e+00,\n",
      "           9.1747e-01, -7.0260e-01, -8.4520e-01,  2.5780e-01,  8.7982e-01,\n",
      "          -8.7678e-01, -1.3968e+00, -3.6487e-01, -1.8465e+00, -1.3007e+00,\n",
      "           1.0693e+00, -8.1173e-01,  0.0000e+00,  2.5574e-01, -1.4894e+00,\n",
      "           0.0000e+00,  3.7796e-01, -1.3458e+00,  7.2243e-01,  3.2014e+00,\n",
      "          -7.5274e-01, -3.8346e-01,  0.0000e+00,  2.2522e+00,  1.9393e-01,\n",
      "          -3.9368e-02,  3.0304e+00,  3.6265e-01, -1.8689e-01, -1.1118e+00,\n",
      "           1.2471e+00,  7.7537e-01,  0.0000e+00, -4.5030e-02, -1.3874e+00,\n",
      "           2.3360e+00,  7.6459e-01,  0.0000e+00, -2.1308e+00, -5.8147e-01,\n",
      "           7.8592e-01, -1.8620e+00, -1.3046e+00,  1.9023e-01,  0.0000e+00,\n",
      "          -1.8684e+00,  1.1506e+00, -8.5936e-01,  9.5975e-01,  0.0000e+00,\n",
      "          -2.7146e-02,  1.9745e+00,  1.1271e+00, -4.8599e-01, -1.2415e+00,\n",
      "          -2.1196e-01,  0.0000e+00, -1.6393e+00, -7.7185e-01,  6.8264e-01,\n",
      "          -1.3795e+00, -1.2629e-01,  0.0000e+00,  0.0000e+00,  2.5913e-01,\n",
      "           1.3326e+00, -2.5535e+00,  2.7789e-01, -5.8383e-01,  1.6237e+00,\n",
      "          -1.2403e+00, -1.7536e-03, -5.0151e-02,  9.0149e-01,  5.6563e-01,\n",
      "          -4.1999e-01,  3.8797e-01, -1.1621e-01,  8.0968e-01,  1.0504e+00,\n",
      "          -7.8911e-01, -1.4389e+00, -4.1610e-01, -7.5047e-01, -4.5430e-01,\n",
      "          -5.4753e-01,  7.2228e-01, -1.8536e+00,  1.3575e+00,  8.3777e-01,\n",
      "          -1.5241e+00, -3.5876e-01,  0.0000e+00,  2.0067e-01, -2.1784e+00,\n",
      "           8.3547e-01,  0.0000e+00, -1.2838e+00,  2.6104e-01, -1.5635e+00,\n",
      "           2.0756e+00,  1.3421e-01,  0.0000e+00,  0.0000e+00, -5.7932e-01,\n",
      "          -1.4285e+00,  1.9010e+00, -3.8093e-01,  1.4693e+00,  8.0509e-01,\n",
      "           3.6915e-01,  6.6982e-01, -7.0063e-01,  8.9228e-02,  1.0254e+00,\n",
      "           9.7816e-01, -1.4085e+00,  6.5975e-01, -1.1451e+00, -1.6455e+00,\n",
      "          -6.0025e-01,  8.9271e-03, -7.1114e-01,  3.7057e-01, -2.2444e-01,\n",
      "          -7.5248e-01,  5.7214e-01,  5.3076e-01,  0.0000e+00,  1.5465e+00,\n",
      "           5.7857e-01,  0.0000e+00, -8.6434e-01,  0.0000e+00, -3.8734e-01,\n",
      "           5.0021e-01, -9.7535e-01,  1.7728e+00, -1.0634e+00, -8.0799e-01,\n",
      "          -6.2172e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0653, 0.1237, 0.1277, 0.1000, 0.1118, 0.1873, 0.0625, 0.0620, 0.0662,\n",
      "         0.0937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3508, -0.0341,  0.0779,  ..., -0.1149, -0.0136, -0.4830],\n",
      "        [ 0.1232,  0.1356,  0.2684,  ...,  0.1102,  0.0919,  0.0424],\n",
      "        [-0.0025,  0.2642, -0.0746,  ...,  0.1174, -0.1129, -0.4203],\n",
      "        ...,\n",
      "        [ 0.0724, -0.3265,  0.6051,  ..., -0.0250, -0.0708, -0.3244],\n",
      "        [ 0.4429, -0.0821,  0.1127,  ..., -0.3455,  0.3880, -0.2383],\n",
      "        [ 0.6952,  0.4474, -0.5897,  ..., -0.3215,  0.0456,  0.0459]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.6315e-01, -1.2225e-01,  1.2852e-02, -3.6238e-02,  1.2457e-01,\n",
      "          -3.9779e-02, -1.9626e-01,  1.0739e-01,  3.3113e-02,  1.7026e-01,\n",
      "           2.7391e-02, -4.6790e-02,  8.0006e-02, -2.1664e-02,  2.5307e-01,\n",
      "           7.4122e-02,  1.7988e-01,  9.8571e-02, -2.3641e-01, -6.0573e-02,\n",
      "           1.0941e-03, -1.4294e-01, -8.8643e-02, -6.6088e-02, -8.7944e-02,\n",
      "          -2.6248e-01, -2.3804e-02, -8.2132e-02,  6.2333e-02,  1.3420e-01,\n",
      "          -8.9584e-02,  3.4987e-02, -1.1882e-03,  1.4417e-01, -1.5777e-01,\n",
      "          -1.8292e-01, -1.6610e-01, -9.3944e-02, -4.9019e-02, -2.0653e-01,\n",
      "           3.1612e-02,  1.4253e-01, -2.8631e-01, -9.4716e-02,  1.9364e-01,\n",
      "           9.2681e-02, -6.6635e-04,  1.0142e-02,  2.4099e-01, -4.8374e-02,\n",
      "          -7.9323e-02, -1.8130e-02,  1.2162e-01,  1.7466e-01, -9.2162e-02,\n",
      "          -1.1824e-01, -1.5815e-01,  1.9381e-01,  2.4334e-01,  1.6423e-01,\n",
      "          -5.5307e-02, -3.4368e-02, -1.6126e-01,  3.3678e-02,  6.7202e-02,\n",
      "           4.0881e-03, -1.7449e-01,  4.8833e-02,  8.7914e-02,  4.9254e-02,\n",
      "          -8.4941e-03,  1.7877e-01, -1.2577e-01,  5.3670e-02, -2.5426e-01,\n",
      "           1.8720e-01, -6.0630e-02,  1.6004e-02, -4.9141e-02,  1.7266e-01,\n",
      "          -2.1014e-01, -5.6084e-02, -3.3723e-01, -3.1969e-02, -1.0561e-01,\n",
      "           1.5088e-01,  6.1205e-02,  3.0976e-02,  3.9488e-03,  9.3227e-02,\n",
      "          -6.1332e-02,  1.8166e-01, -1.9208e-01, -3.3894e-02,  1.6630e-02,\n",
      "           1.9247e-01,  1.1283e-01,  5.4333e-02, -8.4979e-02, -6.2065e-02,\n",
      "          -1.4586e-01, -1.5403e-01,  1.7060e-01, -8.5320e-03, -2.0661e-01,\n",
      "          -2.7533e-02, -1.7652e-01, -1.5667e-01, -2.7728e-01,  9.4785e-02,\n",
      "          -2.5989e-01,  3.4111e-01, -6.5487e-03, -4.0275e-02,  2.4471e-02,\n",
      "           5.9088e-03,  1.3704e-01, -2.2223e-01, -1.0357e-01, -3.6384e-01,\n",
      "           2.2246e-01, -3.5634e-01, -1.3285e-01,  5.7388e-03, -1.5961e-01,\n",
      "          -1.6335e-01,  2.7689e-01,  4.4475e-02,  2.0882e-01,  6.4115e-02,\n",
      "           1.9725e-01, -2.0524e-01, -8.2881e-02, -3.6303e-02, -1.2805e-01,\n",
      "           7.6762e-02,  2.2728e-01,  1.4541e-01,  2.7649e-01,  6.0885e-02,\n",
      "          -9.1042e-02,  2.4282e-01,  1.4911e-01,  2.1726e-01, -1.4294e-01,\n",
      "           1.6920e-01,  3.1456e-02,  4.4608e-02,  5.9431e-02,  1.4420e-01,\n",
      "          -8.8303e-02, -1.3584e-01,  1.2383e-01,  7.4306e-02, -6.0949e-02,\n",
      "           2.2907e-01, -4.2641e-02,  1.6152e-01,  2.2548e-02,  1.0262e-01,\n",
      "           2.1400e-01,  1.1897e-01,  3.0008e-02,  1.0546e-01, -1.9755e-01,\n",
      "          -6.8037e-02, -8.0574e-02, -1.6756e-01, -2.4976e-03,  4.5917e-02,\n",
      "           5.6659e-04, -7.3951e-02,  1.5442e-01,  3.0406e-01,  2.9428e-01,\n",
      "          -3.8095e-01, -1.0100e-01,  1.1770e-01, -9.5607e-02, -5.4484e-02,\n",
      "           7.0711e-02, -6.0632e-02, -6.9241e-02, -1.9072e-01,  8.0146e-03,\n",
      "          -3.8643e-02,  1.5303e-01, -3.8203e-02,  1.7230e-02, -2.0410e-01,\n",
      "           1.0886e-02, -1.5833e-01, -9.9563e-02, -9.0443e-02, -2.2106e-01,\n",
      "          -1.1844e-01, -1.1224e-01,  4.5595e-02, -1.5685e-01,  6.1641e-02,\n",
      "           2.5884e-02,  1.7952e-01,  2.5679e-02,  1.0486e-04, -2.2437e-02,\n",
      "          -7.3417e-02, -3.2954e-03, -2.2105e-01,  9.6632e-02, -2.0163e-01,\n",
      "           1.7387e-01, -2.7879e-01, -5.7933e-02,  2.6058e-01, -1.2025e-01,\n",
      "           3.5752e-02, -3.8330e-02,  3.4419e-01, -1.7520e-01, -1.2594e-01,\n",
      "           1.1289e-01, -1.7770e-02,  2.4425e-01,  8.6686e-02,  2.1257e-03,\n",
      "           2.1832e-01, -2.3823e-02,  6.2310e-02, -1.5787e-01,  7.0579e-02,\n",
      "           5.4040e-03, -2.3427e-01, -1.8816e-01,  1.7723e-01,  6.0919e-02,\n",
      "          -4.2519e-04, -7.9575e-02, -2.3397e-01,  1.8798e-01,  1.3729e-01,\n",
      "           1.2113e-01, -2.9523e-01, -4.6501e-01,  1.1748e-01,  5.4562e-02,\n",
      "          -1.3836e-02, -1.6385e-01, -1.0564e-01, -1.3685e-01,  3.1481e-02,\n",
      "          -4.0571e-03,  1.9536e-03,  2.3437e-02, -1.3431e-01, -6.2762e-02,\n",
      "          -2.8408e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5944e-02,  3.9903e-01, -9.6674e-01, -6.8180e-01,  3.7635e-01,\n",
      "          -2.0181e-01,  0.0000e+00, -8.3272e-02, -3.5850e+00,  0.0000e+00,\n",
      "           4.2893e-01, -6.2922e-01,  2.6054e+00,  0.0000e+00, -5.4165e-01,\n",
      "          -1.5798e-01,  8.5154e-01,  1.0951e+00,  4.5515e-01,  4.3611e-01,\n",
      "          -6.3372e-01, -3.8350e-01,  1.6419e+00,  1.5114e+00,  7.5378e-01,\n",
      "          -7.5424e-02, -1.8778e-01, -7.5914e-01,  1.6541e+00,  8.6169e-01,\n",
      "           0.0000e+00,  1.2191e+00, -1.0344e+00, -8.2654e-02, -1.5350e+00,\n",
      "           1.3954e+00,  2.8086e-01, -3.7456e+00,  0.0000e+00,  1.6014e+00,\n",
      "          -4.5886e-01, -1.3986e+00, -2.6837e-01, -1.7166e+00, -1.5248e+00,\n",
      "           6.6734e-01,  5.4107e-01,  3.7028e-01, -1.3410e+00,  1.4388e-01,\n",
      "          -6.2906e-01,  2.7530e+00,  6.1046e-01, -1.0296e+00, -2.5692e-02,\n",
      "           2.0308e-01, -8.8230e-01, -1.2530e+00, -2.3666e-01, -4.2523e-01,\n",
      "           1.1011e+00,  1.4084e+00, -2.0356e-01, -5.0180e-01, -2.9650e+00,\n",
      "           5.5055e-01,  1.2791e+00, -1.2882e+00,  4.1160e-01,  5.2643e-01,\n",
      "          -1.2674e+00, -3.0360e-02,  7.0749e-01, -3.6422e+00,  3.2629e-01,\n",
      "          -2.2474e-03, -1.5980e-01,  1.0630e+00, -5.8289e-02, -1.2001e-01,\n",
      "          -1.4005e+00,  2.1318e+00, -9.2499e-01,  1.0058e+00, -2.0782e-01,\n",
      "           4.3459e-01,  1.6619e+00, -9.7479e-01, -1.0335e-01, -5.8157e-01,\n",
      "          -2.2741e+00,  1.1005e+00, -6.2230e-01, -1.1354e+00,  0.0000e+00,\n",
      "          -1.1710e+00,  3.4303e-02,  6.2923e-01,  1.7206e+00, -7.8042e-01,\n",
      "           2.6978e+00, -1.4629e+00,  1.0761e+00,  0.0000e+00, -6.6645e-01,\n",
      "          -7.6264e-01,  1.2127e+00,  1.2734e-01,  0.0000e+00, -1.3118e-02,\n",
      "          -2.4893e-01,  1.3452e-01, -1.0487e+00,  0.0000e+00, -1.6538e+00,\n",
      "          -2.9905e+00, -5.6334e-02, -5.0133e-01, -1.9329e-01,  4.4481e-01,\n",
      "          -1.4670e+00,  7.0246e-01, -1.4609e+00, -7.2633e-01, -9.5879e-01,\n",
      "          -1.3094e+00,  8.9762e-01,  1.7040e-01,  1.2857e+00, -7.5266e-01,\n",
      "          -8.2332e-01,  0.0000e+00, -1.5835e+00,  9.8417e-01,  2.7620e-01,\n",
      "          -5.8969e-01,  6.5992e-01,  5.7363e-01, -1.1586e+00, -1.0105e+00,\n",
      "          -3.8896e-01,  6.7787e-01, -7.9005e-01,  0.0000e+00, -1.6863e+00,\n",
      "          -1.0124e-01, -5.4333e-01, -8.4455e-01, -7.5556e-01,  1.7740e-01,\n",
      "           1.9992e+00, -1.9979e-01, -1.9310e+00, -4.0618e-01,  4.4152e-01,\n",
      "          -1.9445e-01, -6.4260e-02,  0.0000e+00,  3.9403e-02,  5.3771e-01,\n",
      "          -2.6162e-02,  2.2067e+00,  4.8117e-01,  0.0000e+00, -5.2732e-01,\n",
      "          -8.9290e-01,  2.8174e-01,  8.4460e-02,  0.0000e+00,  0.0000e+00,\n",
      "           7.3799e-01, -3.2292e-02,  1.9886e-02, -1.0020e+00,  1.2779e+00,\n",
      "          -1.0991e+00, -9.8777e-01, -2.0777e+00,  1.9696e+00,  8.6507e-02,\n",
      "           0.0000e+00,  0.0000e+00,  6.7162e-01,  9.7990e-01, -7.4712e-01,\n",
      "          -3.4094e-01, -2.7838e+00, -7.8455e-01,  1.2100e+00,  1.0125e+00,\n",
      "           3.0752e+00,  4.9447e-01, -1.4418e-01, -5.9463e-01,  5.6079e-01,\n",
      "           2.1657e+00, -1.1883e+00,  5.3485e-01,  1.8122e+00, -9.4749e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2418e+00, -1.2220e-01,  2.3196e-01,\n",
      "          -5.7541e-01, -2.2933e+00,  6.8191e-01, -1.0747e+00,  0.0000e+00,\n",
      "           2.8687e+00, -5.7333e-01, -3.4119e-01,  7.9327e-01,  2.9941e-02,\n",
      "          -6.8479e-01, -1.0195e+00,  9.6630e-01, -2.4585e-01,  2.1699e+00,\n",
      "           0.0000e+00, -4.2759e-01,  0.0000e+00, -5.0152e-01,  3.3734e-01,\n",
      "           7.0487e-01, -6.9660e-01, -6.2819e-01,  2.9224e-01, -1.5789e+00,\n",
      "          -1.1089e+00,  1.5816e+00, -6.1433e-01,  0.0000e+00, -2.9804e+00,\n",
      "           4.0364e+00,  0.0000e+00,  4.3437e-02, -1.5806e+00, -2.8746e-01,\n",
      "           7.4171e-01, -3.2491e+00, -3.0463e-01, -8.5256e-01,  1.1154e-02,\n",
      "           0.0000e+00,  2.7502e-01,  2.5269e-01,  2.6106e-01,  3.8665e-01,\n",
      "          -3.6561e-01, -1.5851e-01, -5.5408e-01, -5.2616e-02, -1.1472e+00,\n",
      "          -1.1316e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0351, 0.0471, 0.0745, 0.0790, 0.1198, 0.3380, 0.0631, 0.0678, 0.0656,\n",
      "         0.1100]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3505, -0.0346,  0.0779,  ..., -0.1146, -0.0155, -0.4830],\n",
      "        [ 0.1224,  0.1345,  0.2680,  ...,  0.1107,  0.0882,  0.0426],\n",
      "        [ 0.1229,  0.3973,  0.0113,  ...,  0.1966,  0.2265,  0.1552],\n",
      "        ...,\n",
      "        [ 0.6954,  0.4860, -0.7744,  ..., -0.3679,  0.1379,  0.1288],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1696, -0.0628, -0.2455, -0.0386,  0.0842,  0.0404, -0.2299,\n",
      "           0.0244, -0.0324,  0.1890, -0.1312,  0.2747, -0.0581,  0.1249,\n",
      "           0.3664,  0.2909,  0.2553, -0.0358, -0.1113,  0.1268,  0.0548,\n",
      "          -0.1313, -0.2427, -0.0864, -0.1783, -0.2812,  0.0207, -0.2747,\n",
      "           0.1126, -0.0405,  0.0022, -0.0092,  0.0250,  0.1214,  0.1797,\n",
      "          -0.2840, -0.1178,  0.0152, -0.1963,  0.0249, -0.0285, -0.0327,\n",
      "          -0.1811, -0.2514,  0.2078, -0.1690, -0.0457, -0.0041,  0.0849,\n",
      "           0.1858, -0.0528,  0.0280,  0.1573, -0.0781, -0.0613,  0.0136,\n",
      "          -0.0815,  0.1267,  0.3260,  0.4163, -0.0417, -0.0515,  0.2179,\n",
      "           0.2756, -0.0078,  0.0305,  0.1152, -0.0499,  0.2457,  0.2708,\n",
      "           0.0395, -0.0190, -0.2886, -0.0195, -0.2452, -0.0765,  0.3268,\n",
      "          -0.0099, -0.1476,  0.0070, -0.3059,  0.0507, -0.1405,  0.0872,\n",
      "          -0.0834,  0.0590,  0.0853, -0.1088,  0.1837,  0.1379,  0.1070,\n",
      "          -0.1355, -0.1680,  0.1239,  0.1467,  0.1997, -0.0761,  0.2660,\n",
      "          -0.1540,  0.2757, -0.1349, -0.1349,  0.1642,  0.2090, -0.0534,\n",
      "          -0.0159, -0.2868, -0.3436, -0.1213,  0.0747, -0.2276,  0.1656,\n",
      "          -0.1486, -0.0628,  0.2653, -0.0355, -0.0789,  0.1131, -0.1832,\n",
      "           0.1883,  0.2329,  0.1363, -0.2986,  0.0316, -0.3460,  0.0119,\n",
      "           0.0544, -0.1573,  0.0878,  0.0038,  0.0620, -0.2036,  0.2297,\n",
      "           0.1581,  0.0599,  0.0311,  0.3755,  0.1104,  0.1315,  0.1927,\n",
      "           0.0463,  0.3333,  0.1930,  0.4197,  0.1410,  0.0831, -0.0623,\n",
      "           0.2106,  0.1499,  0.0983,  0.1287, -0.1057,  0.2638,  0.3214,\n",
      "          -0.1694,  0.0715,  0.1460,  0.1004,  0.1113,  0.1581, -0.2064,\n",
      "          -0.0778, -0.0744,  0.1339, -0.2188,  0.1115, -0.1968, -0.0386,\n",
      "          -0.1323,  0.3398,  0.0010,  0.0080,  0.0342,  0.1324,  0.0297,\n",
      "          -0.0023,  0.3185,  0.0749, -0.0123,  0.2823,  0.0404, -0.2213,\n",
      "           0.0586,  0.1412, -0.0137, -0.1467, -0.1107,  0.2424,  0.0418,\n",
      "           0.0732,  0.1044, -0.0592, -0.0740, -0.3876, -0.0084, -0.0121,\n",
      "          -0.1500,  0.3485,  0.0056, -0.1047,  0.0508,  0.1212, -0.0047,\n",
      "           0.0442, -0.1493,  0.1079,  0.1550,  0.0090,  0.1052,  0.0106,\n",
      "          -0.0228, -0.1758, -0.2987, -0.0587, -0.0013,  0.1828,  0.2792,\n",
      "           0.4155, -0.0361,  0.0649,  0.2132, -0.1578,  0.2745, -0.2552,\n",
      "          -0.0692,  0.3003, -0.1820, -0.0744, -0.3666, -0.0266, -0.2076,\n",
      "          -0.1336,  0.0232,  0.1596, -0.0040, -0.1011, -0.3312, -0.0276,\n",
      "           0.2509,  0.0581,  0.0954, -0.1529, -0.1338,  0.1366,  0.1811,\n",
      "          -0.1771, -0.1825, -0.1099,  0.0382, -0.0660,  0.1523,  0.1720,\n",
      "          -0.0353, -0.0582,  0.1768, -0.0643]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1548, -1.4816,  1.6542, -1.0095,  0.0000,  0.4007,  0.6461,\n",
      "          -1.2224, -0.9022,  0.0941, -0.2100,  0.0000,  0.1268, -0.9576,\n",
      "          -0.3085,  0.0000, -1.8654, -2.1362,  0.6082, -0.5293,  0.7695,\n",
      "           0.2830, -1.2570, -0.9729,  0.0000,  1.4261, -1.6559,  1.0545,\n",
      "           0.9845, -1.2885,  0.3067,  0.0000, -0.7689, -1.5226, -0.3682,\n",
      "           0.0000, -0.9886, -0.3510,  0.3282,  0.6281,  0.6073, -1.1766,\n",
      "           0.3727,  1.2540, -1.7952,  1.9479, -1.4981, -0.4427, -0.2787,\n",
      "           0.0000,  0.8648,  0.0361, -0.0720,  0.0000, -0.2962, -0.8050,\n",
      "          -1.8692,  0.5100,  1.5729,  2.0576, -0.8821, -0.7340,  1.9471,\n",
      "          -0.9060, -0.8592,  0.1078,  0.6387, -0.6171,  0.0209,  0.0000,\n",
      "          -1.5893, -0.0280,  0.0000,  1.4258, -0.4462,  0.5578, -3.6195,\n",
      "          -0.6177, -1.4063, -0.3108,  0.8706,  1.3121,  0.8811, -0.9602,\n",
      "           0.6943,  0.6936,  0.0462, -2.9897,  0.8148, -0.0184, -1.4906,\n",
      "           0.3247, -1.2888,  2.3923,  1.8841,  0.2151, -1.1102,  1.0775,\n",
      "           1.5507, -2.1245,  0.0144, -0.6637,  0.0000, -1.8826,  0.4069,\n",
      "           1.4167, -1.9888, -0.9155,  0.4130,  1.8163, -1.4323,  0.0000,\n",
      "          -0.4973,  1.3002, -0.1465, -0.1101,  0.3374, -1.6425,  0.8516,\n",
      "          -1.2944, -1.3459, -0.0995,  0.8784,  0.5348,  0.2247,  0.8192,\n",
      "          -0.2028, -1.0699,  0.1246, -0.4277, -1.2479,  2.3285,  0.0000,\n",
      "           0.3274, -0.0090, -0.6384, -0.0637, -0.5996, -0.4515,  1.0985,\n",
      "           0.0000, -1.1800, -2.2949, -0.8857,  0.2165, -0.1879,  0.9174,\n",
      "          -0.0829,  1.5431, -0.7186,  0.3219,  0.0000,  1.8155,  0.0000,\n",
      "           0.5127, -0.3341,  0.0000, -0.7579,  0.9342, -0.0180,  0.2298,\n",
      "          -1.1456,  2.2615, -1.7646, -0.3899, -0.6920,  0.5298,  2.1356,\n",
      "           0.0000, -2.7423,  1.2537, -2.0852, -0.0061, -1.1599, -0.9215,\n",
      "          -0.7984,  0.0000, -0.4304,  0.1178, -1.5137,  0.1503,  0.0000,\n",
      "           0.1992,  0.9700,  0.0000, -0.0758, -1.5018, -0.2140,  0.4034,\n",
      "          -1.4624,  1.0713,  0.6061,  0.5035, -0.5081,  0.7248, -0.0429,\n",
      "           1.8721,  0.0429,  0.0000, -0.2756,  0.1189, -0.2977,  0.0000,\n",
      "           0.0000, -0.0090, -0.7146,  0.0000,  2.0163, -0.7495,  1.8922,\n",
      "           2.7893,  0.1561,  1.5050,  0.1012, -0.5910, -0.0222, -0.1426,\n",
      "           0.0000,  0.4085,  0.6375, -0.6886,  1.8593,  0.6067,  0.4729,\n",
      "           0.0292,  1.5296, -0.3650, -0.2609,  0.8420, -0.2543,  0.0000,\n",
      "          -0.5514,  1.2381,  0.0929,  2.0767,  0.5540, -1.7044,  2.7782,\n",
      "          -1.4953,  1.8028, -0.8494,  0.2569, -1.0497, -0.8536,  0.1357,\n",
      "          -1.7792,  0.3814,  1.9828,  0.5691,  0.5471, -1.7499,  0.3683,\n",
      "           0.1556,  1.5690,  0.0000,  0.4071]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0339, 0.1397, 0.1085, 0.0492, 0.1527, 0.2260, 0.0531, 0.0611, 0.1015,\n",
      "         0.0744]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3505, -0.0346,  0.0779,  ..., -0.1146, -0.0155, -0.4830],\n",
      "        [ 0.1224,  0.1345,  0.2680,  ...,  0.1107,  0.0882,  0.0426],\n",
      "        [ 0.1229,  0.3973,  0.0113,  ...,  0.1966,  0.2265,  0.1552],\n",
      "        ...,\n",
      "        [ 0.6954,  0.4860, -0.7744,  ..., -0.3679,  0.1379,  0.1288],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.6313e-01, -2.2290e-02, -1.7151e-01,  9.0221e-03,  1.3202e-01,\n",
      "           1.1742e-01, -2.5911e-01,  5.0623e-02,  1.0638e-02,  1.8053e-01,\n",
      "          -1.4201e-01,  2.5067e-01,  1.6378e-03,  1.1671e-01,  3.0833e-01,\n",
      "           3.1078e-01,  2.2769e-01, -6.0955e-02, -1.4375e-01,  6.3638e-02,\n",
      "           2.1908e-02, -1.2333e-01, -2.5174e-01, -1.3065e-01, -1.4587e-01,\n",
      "          -3.0966e-01,  1.3878e-02, -2.2267e-01,  7.8615e-02, -1.1574e-02,\n",
      "           3.2228e-03,  2.7055e-02,  2.7226e-02,  1.5197e-01,  1.0367e-01,\n",
      "          -2.4085e-01, -1.4815e-01, -1.4491e-04, -1.5959e-01, -2.2982e-02,\n",
      "          -1.9753e-02,  1.7929e-03, -1.3356e-01, -2.3241e-01,  2.0936e-01,\n",
      "          -1.5754e-01,  1.3313e-02,  5.2298e-02,  1.0394e-01,  1.4116e-01,\n",
      "          -7.2175e-02, -5.8124e-02,  1.5560e-01, -6.3714e-02, -8.3306e-02,\n",
      "           3.1885e-02, -5.3372e-02,  1.3256e-01,  2.8352e-01,  3.8729e-01,\n",
      "          -4.1916e-02, -3.9271e-02,  1.7705e-01,  2.3345e-01, -1.3279e-02,\n",
      "           4.0874e-02,  9.4771e-02, -6.0905e-02,  1.9248e-01,  1.8118e-01,\n",
      "           2.8340e-02,  2.1998e-02, -2.7946e-01, -1.6510e-02, -2.7521e-01,\n",
      "          -7.1137e-02,  2.7271e-01, -3.2004e-02, -9.6457e-02, -2.1550e-02,\n",
      "          -3.2454e-01,  3.4395e-03, -1.3816e-01,  1.1550e-01, -6.0390e-02,\n",
      "           3.8009e-02,  1.1773e-01, -6.9888e-02,  1.0024e-01,  1.6741e-01,\n",
      "           6.3986e-02, -5.0195e-02, -1.4609e-01,  8.4321e-02,  1.5135e-01,\n",
      "           1.5639e-01, -1.6170e-02,  2.4589e-01, -1.7304e-01,  2.2951e-01,\n",
      "          -1.2288e-01, -1.5952e-01,  1.6394e-01,  1.8104e-01, -4.8108e-02,\n",
      "          -4.6491e-02, -2.1877e-01, -3.4483e-01, -1.5958e-01,  7.4037e-02,\n",
      "          -2.4157e-01,  1.4243e-01, -1.3249e-01, -6.0765e-02,  2.8652e-01,\n",
      "          -6.2603e-02, -3.2213e-02,  5.1266e-02, -1.4618e-01,  1.0337e-01,\n",
      "           2.7394e-01,  6.8819e-02, -2.4695e-01,  1.1324e-02, -3.4021e-01,\n",
      "           5.1491e-04,  1.1315e-01, -8.8992e-02,  1.7837e-01,  4.0069e-02,\n",
      "           7.6172e-02, -1.8092e-01,  1.8507e-01,  9.9660e-02,  1.7666e-02,\n",
      "          -9.5930e-03,  3.8011e-01,  8.0057e-02,  2.1614e-01,  1.5578e-01,\n",
      "           6.5046e-02,  3.1569e-01,  2.0411e-01,  4.2060e-01,  5.8535e-02,\n",
      "           8.1987e-02,  2.4388e-02,  1.7011e-01,  7.1697e-02,  9.1905e-02,\n",
      "           6.7938e-02, -1.3212e-01,  2.6454e-01,  3.4436e-01, -1.7685e-01,\n",
      "           8.8820e-02,  1.2188e-01,  1.4803e-01,  6.5082e-02,  1.8883e-01,\n",
      "          -1.4718e-01,  1.1870e-02, -5.3886e-02,  1.4042e-01, -2.1582e-01,\n",
      "           2.2699e-02, -1.6374e-01, -1.4117e-02, -1.6219e-01,  3.3224e-01,\n",
      "           2.2493e-02, -5.8946e-03,  3.6608e-02,  1.7570e-01,  7.6586e-02,\n",
      "          -6.2391e-03,  2.7754e-01,  7.9290e-02, -5.1184e-02,  2.3069e-01,\n",
      "           6.4888e-02, -1.6151e-01, -1.8865e-02,  9.5106e-02, -1.2145e-02,\n",
      "          -9.8699e-02, -3.9459e-02,  1.9925e-01,  4.7584e-02,  4.2510e-02,\n",
      "           1.2722e-01, -1.1679e-01, -6.5416e-02, -3.1815e-01, -4.3094e-02,\n",
      "           2.8850e-02, -8.3948e-02,  3.2416e-01, -9.0864e-03, -1.0850e-01,\n",
      "           8.8198e-03,  8.8138e-02,  3.8668e-02,  2.4896e-02, -1.2565e-01,\n",
      "           8.6903e-02,  1.0095e-01, -9.4979e-03,  1.0197e-01,  2.9073e-02,\n",
      "          -5.3056e-03, -1.5075e-01, -2.7422e-01, -1.0936e-01,  2.1950e-02,\n",
      "           1.0132e-01,  2.2722e-01,  3.7756e-01, -1.0415e-01,  2.0452e-02,\n",
      "           2.3588e-01, -1.2222e-01,  2.8837e-01, -2.4537e-01, -1.1552e-01,\n",
      "           2.9860e-01, -1.0336e-01, -2.2639e-02, -3.8717e-01, -5.3253e-03,\n",
      "          -2.1431e-01, -1.7553e-01,  6.7282e-03,  1.3708e-01, -9.9388e-03,\n",
      "          -1.2817e-01, -2.6412e-01, -4.5726e-02,  1.8512e-01,  7.2204e-02,\n",
      "           1.2377e-01, -1.1932e-01, -1.9187e-01,  1.4103e-01,  1.7608e-01,\n",
      "          -1.3443e-01, -1.7459e-01, -1.3133e-01, -3.5605e-02, -7.0817e-02,\n",
      "           1.3781e-01,  1.6267e-01, -1.8415e-02, -3.9562e-02,  1.4605e-01,\n",
      "          -5.2389e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1548, -1.4816,  1.6542, -1.0095, -1.1130,  0.4007,  0.6461,\n",
      "          -1.2224, -0.9022,  0.0000,  0.0000,  0.3159,  0.1268, -0.9576,\n",
      "          -0.3085,  0.3245, -1.8654, -2.1362,  0.6082, -0.5293,  0.7695,\n",
      "           0.2830,  0.0000, -0.9729,  1.1924,  1.4261, -1.6559,  1.0545,\n",
      "           0.0000, -1.2885,  0.3067, -0.9454, -0.7689, -1.5226, -0.3682,\n",
      "           0.4840, -0.9886, -0.3510,  0.3282,  0.6281,  0.6073, -1.1766,\n",
      "           0.3727,  1.2540, -1.7952,  1.9479, -1.4981, -0.4427, -0.2787,\n",
      "           1.1463,  0.8648,  0.0000, -0.0720, -1.0044, -0.2962, -0.8050,\n",
      "          -1.8692,  0.5100,  1.5729,  2.0576, -0.8821, -0.7340,  1.9471,\n",
      "          -0.9060, -0.8592,  0.1078,  0.6387, -0.6171,  0.0209,  0.4297,\n",
      "           0.0000, -0.0280, -0.6441,  1.4258, -0.4462,  0.5578, -3.6195,\n",
      "          -0.6177, -1.4063, -0.3108,  0.8706,  1.3121,  0.8811, -0.9602,\n",
      "           0.6943,  0.6936,  0.0000,  0.0000,  0.8148, -0.0184, -1.4906,\n",
      "           0.3247,  0.0000,  2.3923,  1.8841,  0.0000,  0.0000,  1.0775,\n",
      "           1.5507, -2.1245,  0.0144,  0.0000, -1.1344, -1.8826,  0.4069,\n",
      "           1.4167, -1.9888, -0.9155,  0.4130,  0.0000, -1.4323,  0.0000,\n",
      "           0.0000,  1.3002, -0.1465, -0.1101,  0.3374, -1.6425,  0.8516,\n",
      "          -1.2944, -1.3459, -0.0995,  0.8784,  0.5348,  0.2247,  0.0000,\n",
      "           0.0000, -1.0699,  0.1246, -0.4277, -1.2479,  0.0000,  1.4193,\n",
      "           0.0000, -0.0090, -0.6384, -0.0637, -0.5996, -0.4515,  1.0985,\n",
      "           0.5454, -1.1800, -2.2949, -0.8857,  0.2165, -0.1879,  0.9174,\n",
      "          -0.0829,  1.5431, -0.7186,  0.3219, -1.3512,  1.8155, -1.9310,\n",
      "           0.5127, -0.3341, -0.2287, -0.7579,  0.9342, -0.0180,  0.2298,\n",
      "          -1.1456,  2.2615,  0.0000, -0.3899,  0.0000,  0.0000,  2.1356,\n",
      "          -1.6403, -2.7423,  1.2537, -2.0852, -0.0061, -1.1599, -0.9215,\n",
      "          -0.7984, -0.3065,  0.0000,  0.1178, -1.5137,  0.1503, -0.4530,\n",
      "           0.1992,  0.9700,  0.4841, -0.0758, -1.5018, -0.2140,  0.4034,\n",
      "          -1.4624,  1.0713,  0.6061,  0.5035, -0.5081,  0.7248, -0.0429,\n",
      "           1.8721,  0.0429, -0.8385, -0.2756,  0.1189, -0.2977,  0.2828,\n",
      "           0.3538, -0.0090, -0.7146,  0.6960,  2.0163, -0.7495,  0.0000,\n",
      "           2.7893,  0.1561,  1.5050,  0.1012, -0.5910, -0.0222, -0.1426,\n",
      "          -1.3820,  0.4085,  0.6375, -0.6886,  1.8593,  0.6067,  0.4729,\n",
      "           0.0292,  0.0000, -0.3650, -0.2609,  0.8420, -0.2543,  0.7765,\n",
      "          -0.5514,  1.2381,  0.0929,  2.0767,  0.5540, -1.7044,  2.7782,\n",
      "          -1.4953,  0.0000,  0.0000,  0.2569, -1.0497,  0.0000,  0.1357,\n",
      "          -1.7792,  0.3814,  0.0000,  0.5691,  0.5471, -1.7499,  0.3683,\n",
      "           0.1556,  1.5690, -2.7258,  0.4071]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0378, 0.1794, 0.1013, 0.0439, 0.1817, 0.1556, 0.0608, 0.0567, 0.1131,\n",
      "         0.0697]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3505, -0.0346,  0.0779,  ..., -0.1146, -0.0155, -0.4830],\n",
      "        [ 0.1224,  0.1345,  0.2680,  ...,  0.1107,  0.0882,  0.0426],\n",
      "        [ 0.1229,  0.3973,  0.0113,  ...,  0.1966,  0.2265,  0.1552],\n",
      "        ...,\n",
      "        [ 0.6954,  0.4860, -0.7744,  ..., -0.3679,  0.1379,  0.1288],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1670, -0.0191, -0.1413,  0.0114,  0.1482,  0.1485, -0.2811,\n",
      "           0.0518,  0.0227,  0.1553, -0.1481,  0.2345,  0.0255,  0.1165,\n",
      "           0.2828,  0.3155,  0.2067, -0.0561, -0.1622,  0.0327,  0.0116,\n",
      "          -0.1248, -0.2361, -0.1472, -0.1241, -0.3132,  0.0113, -0.1969,\n",
      "           0.0539,  0.0161,  0.0220,  0.0352,  0.0318,  0.1582,  0.0494,\n",
      "          -0.2257, -0.1627,  0.0023, -0.1329, -0.0364, -0.0178,  0.0132,\n",
      "          -0.1147, -0.2204,  0.2094, -0.1338,  0.0353,  0.0696,  0.1119,\n",
      "           0.1089, -0.0889, -0.0962,  0.1466, -0.0574, -0.1037,  0.0218,\n",
      "          -0.0468,  0.1301,  0.2665,  0.3658, -0.0446, -0.0430,  0.1507,\n",
      "           0.2255, -0.0088,  0.0391,  0.0895, -0.0471,  0.1572,  0.1484,\n",
      "           0.0305,  0.0594, -0.2708, -0.0133, -0.2924, -0.0541,  0.2550,\n",
      "          -0.0269, -0.0800, -0.0188, -0.3265, -0.0209, -0.1375,  0.1288,\n",
      "          -0.0460,  0.0292,  0.1400, -0.0465,  0.0776,  0.1760,  0.0412,\n",
      "          -0.0138, -0.1427,  0.0646,  0.1435,  0.1340,  0.0172,  0.2176,\n",
      "          -0.1704,  0.2082, -0.1063, -0.1569,  0.1559,  0.1717, -0.0342,\n",
      "          -0.0658, -0.1857, -0.3274, -0.1866,  0.0803, -0.2473,  0.1407,\n",
      "          -0.1195, -0.0683,  0.2782, -0.0740, -0.0139,  0.0195, -0.1152,\n",
      "           0.0604,  0.2941,  0.0396, -0.2386,  0.0027, -0.3442,  0.0016,\n",
      "           0.1441, -0.0642,  0.2377,  0.0496,  0.0860, -0.1631,  0.1526,\n",
      "           0.0749, -0.0010, -0.0300,  0.3715,  0.0671,  0.2505,  0.1375,\n",
      "           0.0748,  0.3064,  0.2037,  0.4071,  0.0190,  0.0801,  0.0741,\n",
      "           0.1569,  0.0454,  0.0992,  0.0077, -0.1295,  0.2544,  0.3482,\n",
      "          -0.1685,  0.1093,  0.1028,  0.1771,  0.0310,  0.1913, -0.1184,\n",
      "           0.0563, -0.0462,  0.1668, -0.2094, -0.0198, -0.1323, -0.0051,\n",
      "          -0.1850,  0.3114,  0.0228, -0.0090,  0.0497,  0.1995,  0.0817,\n",
      "          -0.0120,  0.2582,  0.0787, -0.0657,  0.2080,  0.0692, -0.1427,\n",
      "          -0.0682,  0.0701, -0.0108, -0.0788, -0.0031,  0.1721,  0.0391,\n",
      "           0.0268,  0.1366, -0.1374, -0.0553, -0.2888, -0.0462,  0.0394,\n",
      "          -0.0520,  0.3125, -0.0187, -0.0968, -0.0109,  0.0821,  0.0664,\n",
      "           0.0325, -0.1120,  0.0608,  0.0766, -0.0065,  0.0957,  0.0343,\n",
      "           0.0063, -0.1422, -0.2549, -0.1277,  0.0293,  0.0634,  0.1922,\n",
      "           0.3567, -0.1319, -0.0063,  0.2519, -0.1008,  0.3097, -0.2310,\n",
      "          -0.1340,  0.2984, -0.0669,  0.0009, -0.3980,  0.0056, -0.2183,\n",
      "          -0.1886, -0.0180,  0.1243, -0.0065, -0.1424, -0.2507, -0.0466,\n",
      "           0.1632,  0.0937,  0.1248, -0.1215, -0.2146,  0.1510,  0.1703,\n",
      "          -0.1186, -0.1593, -0.1526, -0.0791, -0.0777,  0.1363,  0.1540,\n",
      "          -0.0161, -0.0413,  0.1302, -0.0589]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7782, -1.6520, -0.1829, -0.7320,  2.5181, -1.9079,\n",
      "          -0.0324,  0.9499,  1.1945,  1.4104, -0.7568, -0.0649,  0.0645,\n",
      "           1.0463,  1.8852,  0.8701, -0.7847,  0.0000, -1.4036, -0.4985,\n",
      "          -0.3792,  1.1428,  0.2329,  0.1892, -0.6129,  1.4041, -0.1509,\n",
      "          -1.0408,  0.4962, -0.5711,  0.6009,  0.0000,  0.2319, -0.0796,\n",
      "           0.1482,  0.6451, -2.2133,  1.0518,  0.1024, -0.6919,  0.0000,\n",
      "          -1.0642,  0.8180, -0.6328, -0.6564,  1.3727,  0.9366,  1.6035,\n",
      "           0.3694, -1.0082,  0.0000, -1.1123,  1.2530, -1.9747,  1.7089,\n",
      "           0.5929, -1.8924,  0.3415, -0.2937, -0.7703,  1.8692, -0.5940,\n",
      "          -1.6816, -0.8356,  1.2344, -0.3575,  0.2898, -0.7527, -1.1647,\n",
      "           2.2476,  0.7806,  0.2705,  1.2049, -0.3982,  0.3548,  0.0000,\n",
      "          -0.1575, -0.9149,  0.2958, -0.1449,  1.2866,  0.4653,  1.2969,\n",
      "           0.0000,  0.6606,  1.0454, -0.3682, -1.2412, -1.4364,  1.3105,\n",
      "          -1.5853, -0.1110,  3.2390,  0.3469,  1.0035, -0.8684,  0.7312,\n",
      "          -1.6814, -0.9243,  0.1907,  0.0285, -0.5965,  1.0586, -0.2309,\n",
      "           0.7758, -0.9058, -0.3677, -0.2786,  0.0000, -0.1379, -3.2782,\n",
      "          -0.1011, -1.8785,  1.6977,  1.6883,  2.0296, -1.6460, -0.8961,\n",
      "           2.5844, -1.3264,  1.4236, -0.6276,  0.4668,  1.3156, -0.9872,\n",
      "           0.0738,  0.0000, -0.6749,  0.2474, -1.2006,  1.1298,  1.1404,\n",
      "           0.0000,  0.3789,  0.0000,  0.0000,  0.2414,  0.0000, -1.2618,\n",
      "           0.0303,  0.8640,  0.5015,  0.9069, -1.2682, -0.6410, -0.4417,\n",
      "           0.8727, -0.0677,  0.0424, -0.0565,  0.6207,  0.1451,  0.0000,\n",
      "           0.1078, -1.6722,  0.0000,  0.2514, -2.0699,  0.4120,  1.1555,\n",
      "           0.1997,  0.9131,  0.8436,  0.4175,  1.6038,  0.1772, -1.1142,\n",
      "          -0.3225,  0.2508,  0.4448, -0.4553,  0.4446, -1.3451,  1.7354,\n",
      "           0.5174,  1.1772,  0.2895, -1.8322, -1.8662,  0.2595, -0.6474,\n",
      "           0.0000,  0.3290, -0.7440,  0.5922,  0.0000, -1.5176, -2.3033,\n",
      "           0.1464, -1.6242, -1.3209, -0.0501,  1.2995,  0.9804, -1.4147,\n",
      "          -1.1401,  3.0139, -0.2258,  1.0329,  0.0291,  0.1192, -1.3196,\n",
      "          -1.0708,  0.0566,  1.7329,  0.5271,  1.9823,  0.0000, -1.3425,\n",
      "           1.5995, -0.4015,  2.4609, -0.5198,  0.7544,  0.2066, -0.8212,\n",
      "           0.9057, -3.5302,  0.1759, -0.7814, -0.6932, -1.4188,  0.2512,\n",
      "          -0.0648, -1.4654,  0.4268, -0.5198,  0.0464, -0.6253, -0.0713,\n",
      "           0.7486, -2.0269, -1.0491,  0.0000, -0.1122,  0.5160, -2.7969,\n",
      "          -1.4578, -0.6646,  1.0259,  0.1327,  2.7509,  1.0025,  0.5472,\n",
      "          -0.1735, -1.5054,  2.2321,  1.1873,  0.0000,  0.0000,  0.1090,\n",
      "          -2.8555,  0.0000, -0.8381, -0.5807]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0328, 0.1581, 0.1148, 0.1123, 0.0922, 0.1050, 0.0658, 0.0961, 0.1272,\n",
      "         0.0956]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3505, -0.0346,  0.0779,  ..., -0.1146, -0.0155, -0.4830],\n",
      "        [ 0.1224,  0.1345,  0.2680,  ...,  0.1107,  0.0882,  0.0426],\n",
      "        [ 0.1229,  0.3973,  0.0113,  ...,  0.1966,  0.2265,  0.1552],\n",
      "        ...,\n",
      "        [ 0.6954,  0.4860, -0.7744,  ..., -0.3679,  0.1379,  0.1288],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2008,  0.0224, -0.1453,  0.0310,  0.0912,  0.1039, -0.2266,\n",
      "          -0.0075,  0.0281,  0.1536, -0.1134,  0.1754,  0.0097,  0.1394,\n",
      "           0.2761,  0.2850,  0.2033, -0.0158, -0.1570,  0.0448, -0.0504,\n",
      "          -0.1387, -0.1944, -0.1232, -0.1522, -0.2881,  0.0060, -0.1733,\n",
      "           0.0347, -0.0198,  0.0320,  0.0070, -0.0081,  0.1043,  0.0651,\n",
      "          -0.2153, -0.1737, -0.0028, -0.1302, -0.0009, -0.0203,  0.0067,\n",
      "          -0.0837, -0.1567,  0.1772, -0.1004,  0.0066,  0.0302,  0.1199,\n",
      "           0.1058, -0.0566, -0.1022,  0.0876, -0.0180, -0.1004,  0.0142,\n",
      "          -0.0163,  0.1872,  0.2661,  0.3379, -0.0091, -0.0734,  0.1132,\n",
      "           0.1858, -0.0478,  0.0444,  0.0693, -0.0578,  0.1036,  0.1230,\n",
      "          -0.0148,  0.0844, -0.2434,  0.0418, -0.2991, -0.0440,  0.2643,\n",
      "          -0.0146, -0.0793, -0.0282, -0.3065, -0.0408, -0.1098,  0.1221,\n",
      "          -0.0406,  0.0368,  0.1509, -0.0221,  0.0725,  0.1724,  0.0683,\n",
      "          -0.0057, -0.0925,  0.0609,  0.1462,  0.1446,  0.0586,  0.2451,\n",
      "          -0.1551,  0.2025, -0.1381, -0.1349,  0.1337,  0.1625, -0.0064,\n",
      "          -0.0820, -0.1154, -0.2276, -0.1628,  0.0762, -0.1868,  0.0794,\n",
      "          -0.1260, -0.0918,  0.2206, -0.0653,  0.0141, -0.0271, -0.1480,\n",
      "           0.0622,  0.2524, -0.0099, -0.1927,  0.0146, -0.3042, -0.0354,\n",
      "           0.1092, -0.0006,  0.2313,  0.0491,  0.0799, -0.1965,  0.2174,\n",
      "           0.0923,  0.0215, -0.0181,  0.3649,  0.0489,  0.2085,  0.1419,\n",
      "           0.0092,  0.2837,  0.1411,  0.3779,  0.0294,  0.0550,  0.0223,\n",
      "           0.1315,  0.0228,  0.0966, -0.0372, -0.0906,  0.2506,  0.3322,\n",
      "          -0.1634,  0.1343,  0.1130,  0.1730,  0.0645,  0.1728, -0.1369,\n",
      "           0.0286, -0.1246,  0.1813, -0.1702, -0.0291, -0.1848,  0.0084,\n",
      "          -0.1000,  0.3129,  0.0283, -0.0161,  0.0755,  0.1834,  0.0312,\n",
      "           0.0135,  0.2213,  0.1200, -0.0310,  0.1524,  0.0858, -0.1574,\n",
      "          -0.0891,  0.0565,  0.0823, -0.0095, -0.0298,  0.1995,  0.0844,\n",
      "           0.0073,  0.1174, -0.1579, -0.1027, -0.2768, -0.0636,  0.0227,\n",
      "          -0.0620,  0.2757, -0.0318, -0.0386, -0.0212,  0.0923,  0.0222,\n",
      "           0.0453, -0.1309,  0.0219,  0.0270,  0.0148,  0.0621,  0.0264,\n",
      "           0.0006, -0.1280, -0.2200, -0.1193,  0.0234,  0.0851,  0.1708,\n",
      "           0.3310, -0.1470,  0.0208,  0.2274, -0.1438,  0.2659, -0.2155,\n",
      "          -0.1291,  0.2846,  0.0062, -0.0403, -0.4140,  0.0376, -0.1876,\n",
      "          -0.1729, -0.0081,  0.1042, -0.0271, -0.1406, -0.2146,  0.0075,\n",
      "           0.1241,  0.0801,  0.1040, -0.0727, -0.2342,  0.1076,  0.1443,\n",
      "          -0.1035, -0.1647, -0.1301, -0.0367, -0.0619,  0.1424,  0.1596,\n",
      "          -0.0903, -0.0263,  0.1499, -0.0390]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5912e-02,  3.9900e-01,  0.0000e+00, -6.8188e-01,  3.7639e-01,\n",
      "          -2.0176e-01,  1.4649e+00, -8.3263e-02, -3.5852e+00,  9.0679e-01,\n",
      "           4.2899e-01, -6.2928e-01,  2.6057e+00, -6.2976e-01, -5.4166e-01,\n",
      "          -1.5796e-01,  8.5161e-01,  0.0000e+00,  4.5516e-01,  4.3610e-01,\n",
      "           0.0000e+00,  0.0000e+00,  1.6420e+00,  1.5114e+00,  7.5380e-01,\n",
      "          -7.5405e-02, -1.8774e-01, -7.5911e-01,  1.6542e+00,  8.6169e-01,\n",
      "           1.2321e+00,  1.2192e+00, -1.0344e+00, -8.2622e-02, -1.5350e+00,\n",
      "           1.3954e+00,  2.8084e-01, -3.7458e+00,  1.9812e-01,  1.6014e+00,\n",
      "          -4.5885e-01, -1.3988e+00, -2.6837e-01, -1.7166e+00,  0.0000e+00,\n",
      "           6.6732e-01,  5.4112e-01,  0.0000e+00, -1.3410e+00,  1.4385e-01,\n",
      "          -6.2900e-01,  2.7532e+00,  6.1048e-01, -1.0296e+00, -2.5712e-02,\n",
      "           2.0306e-01, -8.8238e-01, -1.2531e+00, -2.3663e-01, -4.2519e-01,\n",
      "           1.1012e+00,  1.4085e+00, -2.0362e-01, -5.0188e-01, -2.9652e+00,\n",
      "           5.5052e-01,  1.2792e+00, -1.2883e+00,  4.1169e-01,  5.2641e-01,\n",
      "           0.0000e+00, -3.0376e-02,  7.0752e-01, -3.6424e+00,  3.2636e-01,\n",
      "          -2.3277e-03, -1.5978e-01,  0.0000e+00, -5.8384e-02, -1.2009e-01,\n",
      "          -1.4005e+00,  2.1320e+00, -9.2503e-01,  1.0058e+00, -2.0784e-01,\n",
      "           4.3449e-01,  1.6620e+00, -9.7486e-01, -1.0331e-01, -5.8161e-01,\n",
      "           0.0000e+00,  1.1005e+00, -6.2231e-01, -1.1354e+00,  4.6753e-01,\n",
      "          -1.1710e+00,  3.4340e-02,  6.2929e-01,  1.7207e+00, -7.8053e-01,\n",
      "           2.6979e+00, -1.4630e+00,  1.0761e+00,  0.0000e+00, -6.6648e-01,\n",
      "          -7.6261e-01,  1.2128e+00,  1.2738e-01, -1.4731e+00,  0.0000e+00,\n",
      "          -2.4895e-01,  1.3454e-01,  0.0000e+00,  1.3103e+00,  0.0000e+00,\n",
      "          -2.9906e+00, -5.6295e-02, -5.0144e-01, -1.9329e-01,  4.4476e-01,\n",
      "          -1.4672e+00,  7.0251e-01, -1.4609e+00,  0.0000e+00, -9.5889e-01,\n",
      "          -1.3095e+00,  8.9772e-01,  1.7044e-01,  0.0000e+00, -7.5273e-01,\n",
      "          -8.2325e-01,  5.2980e-01, -1.5836e+00,  9.8419e-01,  2.7620e-01,\n",
      "          -5.8971e-01,  0.0000e+00,  0.0000e+00, -1.1585e+00,  0.0000e+00,\n",
      "          -3.8901e-01,  6.7788e-01, -7.9008e-01, -1.0169e-01, -1.6864e+00,\n",
      "          -1.0131e-01, -5.4336e-01, -8.4459e-01, -7.5558e-01,  1.7740e-01,\n",
      "           1.9993e+00, -1.9979e-01, -1.9311e+00, -4.0619e-01,  4.4161e-01,\n",
      "           0.0000e+00,  0.0000e+00, -1.2898e-01,  3.9397e-02,  5.3773e-01,\n",
      "          -2.6127e-02,  2.2068e+00,  4.8117e-01, -5.4980e-01, -5.2742e-01,\n",
      "          -8.9301e-01,  2.8177e-01,  8.4573e-02, -3.5803e-01, -4.7811e-01,\n",
      "           7.3814e-01,  0.0000e+00,  1.9901e-02, -1.0020e+00,  1.2779e+00,\n",
      "          -1.0992e+00, -9.8788e-01, -2.0778e+00,  1.9697e+00,  8.6507e-02,\n",
      "          -2.9810e-02,  3.5043e-02,  0.0000e+00,  9.7994e-01, -7.4715e-01,\n",
      "          -3.4093e-01, -2.7840e+00, -7.8464e-01,  1.2100e+00,  1.0125e+00,\n",
      "           3.0753e+00,  4.9449e-01, -1.4415e-01, -5.9471e-01,  5.6083e-01,\n",
      "           0.0000e+00, -1.1883e+00,  0.0000e+00,  1.8124e+00, -9.4756e-01,\n",
      "          -1.6623e+00, -1.0150e+00,  1.2418e+00, -1.2222e-01,  2.3191e-01,\n",
      "           0.0000e+00, -2.2934e+00,  0.0000e+00, -1.0748e+00, -4.7141e-01,\n",
      "           2.8688e+00, -5.7335e-01, -3.4122e-01,  7.9331e-01,  2.9927e-02,\n",
      "          -6.8490e-01, -1.0197e+00,  9.6630e-01, -2.4589e-01,  2.1701e+00,\n",
      "          -1.0830e+00, -4.2762e-01,  0.0000e+00, -5.0163e-01,  3.3724e-01,\n",
      "           7.0484e-01,  0.0000e+00, -6.2818e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.1089e+00,  1.5817e+00, -6.1436e-01,  1.3098e+00, -2.9804e+00,\n",
      "           4.0366e+00,  5.8526e-01,  4.3448e-02, -1.5807e+00, -2.8752e-01,\n",
      "           7.4172e-01,  0.0000e+00, -3.0470e-01, -8.5264e-01,  1.1145e-02,\n",
      "           2.7533e-01,  2.7507e-01,  2.5273e-01,  2.6100e-01,  3.8666e-01,\n",
      "          -3.6565e-01,  0.0000e+00, -5.5411e-01, -5.2618e-02,  0.0000e+00,\n",
      "          -1.1316e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0384, 0.0501, 0.0693, 0.0495, 0.1253, 0.3694, 0.0579, 0.0601, 0.0699,\n",
      "         0.1102]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1493, -0.2362, -0.0162,  ...,  0.2950,  0.3450,  0.1578],\n",
      "        [-0.2273,  0.1859, -0.2438,  ...,  0.0192, -0.0410,  0.0612],\n",
      "        [ 0.0351,  0.6079, -0.2740,  ..., -0.4105,  0.0137, -0.0738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3320,  0.3313, -0.3142,  0.0663, -0.0904, -0.3142,  0.0121,\n",
      "          -0.1627, -0.0463, -0.0292,  0.1794, -0.2312, -0.1121,  0.1189,\n",
      "           0.2221, -0.0987,  0.0429,  0.0647, -0.2779,  0.2090, -0.2552,\n",
      "          -0.1829,  0.2242,  0.0804, -0.0576, -0.1451, -0.0853, -0.2608,\n",
      "          -0.1655, -0.1690,  0.2602, -0.3707, -0.3405, -0.3135,  0.0365,\n",
      "           0.1048, -0.2546, -0.1887, -0.2538,  0.1405,  0.1877,  0.0157,\n",
      "          -0.1268,  0.0146,  0.2474,  0.1835, -0.0777, -0.1641,  0.0863,\n",
      "           0.0533, -0.0967, -0.1662, -0.1999,  0.0293,  0.0217, -0.1218,\n",
      "           0.0156,  0.2610,  0.1022,  0.2875, -0.0261, -0.0491, -0.1721,\n",
      "           0.0452, -0.1019, -0.1836, -0.0243,  0.2905, -0.0849,  0.2055,\n",
      "           0.0403,  0.2711, -0.1252,  0.2210, -0.2071,  0.0197,  0.2080,\n",
      "           0.1136, -0.0147,  0.0709, -0.1125, -0.2024, -0.3708, -0.1641,\n",
      "          -0.0701,  0.2197,  0.1708,  0.0068,  0.2512,  0.0500,  0.1742,\n",
      "          -0.0056,  0.1294,  0.0611,  0.0294, -0.0175,  0.1593,  0.2423,\n",
      "          -0.0795,  0.4237, -0.2776,  0.0852,  0.1686,  0.1095, -0.2173,\n",
      "          -0.0848,  0.2271,  0.1650, -0.1291,  0.1802,  0.2214, -0.1052,\n",
      "           0.2061, -0.2082, -0.2155, -0.0010, -0.0049, -0.1314, -0.1181,\n",
      "          -0.1038,  0.2903, -0.1176, -0.2545,  0.0087, -0.2104, -0.2141,\n",
      "           0.0581, -0.0545,  0.1861, -0.1417,  0.2572, -0.3426,  0.2002,\n",
      "           0.3356, -0.0090,  0.1022,  0.3785, -0.0416, -0.3387,  0.3147,\n",
      "          -0.1316,  0.1942, -0.0977,  0.2632,  0.0967,  0.0172, -0.0421,\n",
      "           0.3348,  0.1916,  0.0924, -0.3406,  0.0192,  0.0666,  0.2272,\n",
      "           0.1095,  0.2046, -0.1496,  0.0116,  0.1792, -0.0769, -0.1714,\n",
      "          -0.2317, -0.2872,  0.3344,  0.0519,  0.1813, -0.1013, -0.1682,\n",
      "           0.2734,  0.2014, -0.3163, -0.0239,  0.1202,  0.0079, -0.1489,\n",
      "          -0.1176, -0.0869,  0.1333,  0.4661,  0.0022, -0.1515, -0.0897,\n",
      "          -0.1695, -0.0794,  0.0403,  0.1623, -0.3910,  0.0145,  0.0567,\n",
      "          -0.1574, -0.0331,  0.0340, -0.3174, -0.1457, -0.0959, -0.1406,\n",
      "          -0.0509,  0.0014, -0.2343,  0.1610, -0.0169,  0.0223,  0.0310,\n",
      "           0.2314,  0.1998, -0.3197,  0.0179,  0.4090, -0.0226, -0.0796,\n",
      "           0.1123, -0.2408, -0.0309,  0.2142, -0.0490,  0.3154, -0.0476,\n",
      "           0.1226, -0.1784,  0.2098,  0.2587, -0.1791,  0.0643, -0.1974,\n",
      "           0.2505,  0.2007,  0.0802, -0.3144, -0.4790,  0.4386, -0.2778,\n",
      "          -0.1261, -0.1682, -0.2317,  0.0412,  0.2419, -0.2172, -0.0272,\n",
      "           0.2912,  0.0320, -0.0507, -0.1877, -0.1362,  0.0099,  0.2943,\n",
      "          -0.0302, -0.1889, -0.1522,  0.1923,  0.0515,  0.1520, -0.0007,\n",
      "          -0.3073, -0.2057,  0.1541,  0.0817]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9653e-01,  3.9367e-01, -1.8577e-01, -4.4482e-01,  6.1294e-01,\n",
      "          -5.8207e-01,  0.0000e+00,  5.2285e-02,  0.0000e+00,  1.4233e-01,\n",
      "           5.3543e-01, -1.2404e+00, -2.1939e+00,  6.8528e-02, -9.9926e-01,\n",
      "          -6.7849e-01, -5.8101e-01, -4.4150e-01, -4.8608e-01, -1.2060e+00,\n",
      "           1.5103e-01, -1.0446e+00,  2.7974e+00,  1.8031e+00, -1.1420e+00,\n",
      "          -5.2209e-01, -8.4449e-01, -1.1375e+00,  1.4688e+00,  1.2645e+00,\n",
      "           7.6032e-01, -1.6273e+00, -2.3013e+00,  1.3108e+00, -4.2335e-01,\n",
      "          -1.8317e+00, -7.6664e-01, -4.5425e-01,  4.8527e-01,  2.6368e-01,\n",
      "           4.3406e-01, -1.0887e+00,  1.5615e+00,  8.3584e-01, -6.0454e-01,\n",
      "          -7.2629e-01,  1.7360e-01,  9.4184e-01, -1.2005e+00, -6.1963e-02,\n",
      "          -1.1469e+00,  1.1846e-01,  3.1586e-01, -6.1965e-01, -3.6358e-02,\n",
      "           2.7607e-01, -1.3149e+00,  3.4977e-01,  2.1905e+00, -1.4666e+00,\n",
      "           7.8835e-01, -1.5034e+00,  4.9022e-01, -2.2225e+00, -1.2349e+00,\n",
      "          -1.4290e+00, -6.9541e-01,  2.6910e-01, -1.6410e+00, -9.4005e-01,\n",
      "          -7.4886e-01,  5.4207e-02, -9.4465e-01,  0.0000e+00,  1.8458e+00,\n",
      "           0.0000e+00,  2.4144e-02,  1.4425e+00, -2.1644e+00, -6.5344e-01,\n",
      "           1.2378e+00, -9.3958e-01,  1.1027e+00,  3.1616e-02,  7.5584e-01,\n",
      "          -7.1616e-01, -6.4904e-01,  2.0242e+00, -1.7432e+00,  6.5819e-01,\n",
      "          -1.1581e+00, -1.0933e+00, -1.7549e+00,  2.6479e-01,  2.0357e-01,\n",
      "           4.7772e-01,  1.5874e-01, -2.2111e+00,  4.5480e-01, -3.3004e-01,\n",
      "          -7.3934e-01, -6.0769e-01, -8.6609e-01,  1.1003e+00, -6.0115e-01,\n",
      "           2.7539e-01,  0.0000e+00,  1.3405e+00,  8.5204e-01,  1.1978e+00,\n",
      "          -6.3249e-01, -3.8478e-01,  1.0544e-02,  1.3287e+00,  0.0000e+00,\n",
      "          -5.2908e-02,  6.6454e-01,  0.0000e+00,  2.3137e+00,  0.0000e+00,\n",
      "           1.7428e+00,  0.0000e+00,  0.0000e+00, -8.6781e-02,  1.3808e-03,\n",
      "          -1.4872e-01, -8.5075e-01, -1.9631e+00, -1.1819e+00,  0.0000e+00,\n",
      "          -7.4212e-01,  1.1534e-01, -5.8385e-01,  4.3693e+00,  8.4748e-01,\n",
      "           3.8431e-01, -2.7350e-01, -1.4719e+00,  9.2895e-01, -4.4900e-01,\n",
      "          -1.5277e+00, -1.1548e+00, -6.3072e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.1057e+00,  1.2473e+00, -1.6844e+00,  1.2539e+00, -6.4411e-01,\n",
      "           3.9667e-01,  2.3852e-01,  4.7947e-01, -8.9865e-01, -4.4858e-01,\n",
      "           8.3804e-01,  1.9520e-02,  0.0000e+00, -5.6025e-01, -1.1272e-01,\n",
      "           2.7581e-01, -1.1258e+00, -1.3437e+00,  2.2332e-01, -2.9137e-01,\n",
      "          -1.3180e+00,  2.5570e-01,  1.2394e+00,  2.9599e+00, -2.3092e+00,\n",
      "          -8.2853e-01,  0.0000e+00,  1.5894e+00, -1.7438e+00, -1.5274e-01,\n",
      "           1.0291e+00, -6.4077e-01,  0.0000e+00, -6.7853e-01, -8.2812e-01,\n",
      "          -1.7654e+00, -1.7869e+00,  2.0350e+00,  3.1739e-01, -5.3336e-01,\n",
      "          -1.2808e+00,  1.2878e+00, -1.5354e-01,  5.4262e-01, -2.5316e+00,\n",
      "          -1.0516e-01,  1.9965e+00, -6.7442e-01,  0.0000e+00, -2.2161e+00,\n",
      "           2.2365e-01,  8.4280e-01, -1.6029e+00, -5.5895e-01,  1.1657e+00,\n",
      "           5.6779e-01, -2.5085e+00, -4.8009e-01,  0.0000e+00, -2.9158e-01,\n",
      "           0.0000e+00,  4.6097e-01, -1.2104e+00,  2.2942e+00,  1.4308e+00,\n",
      "           1.4479e-01, -9.0426e-01,  2.2841e-01, -6.0893e-01,  4.6847e-01,\n",
      "           2.1713e-01, -4.9726e-01,  1.3363e+00, -1.6200e+00, -4.0137e-01,\n",
      "           1.0954e+00, -5.9680e-01, -2.1235e+00,  1.5336e+00, -7.3079e-01,\n",
      "          -5.4081e-01, -2.9754e-01,  1.0200e+00,  2.6422e+00, -3.1740e-01,\n",
      "           0.0000e+00,  2.6378e-01,  1.7483e+00,  2.5129e+00, -2.1178e+00,\n",
      "          -9.9999e-01,  1.0432e+00,  2.5436e+00,  2.6918e-01, -1.4082e+00,\n",
      "           1.2338e+00,  0.0000e+00,  0.0000e+00,  9.2252e-01, -1.9999e+00,\n",
      "          -1.0680e+00, -1.1372e-01,  1.5906e+00, -1.0283e+00,  4.7430e-01,\n",
      "           3.6481e-01,  5.1328e-01,  4.2621e-01, -2.2986e-01,  1.9566e+00,\n",
      "           2.2115e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0397, 0.1595, 0.2034, 0.0580, 0.0823, 0.1700, 0.0742, 0.1391, 0.0296,\n",
      "         0.0441]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1493, -0.2362, -0.0162,  ...,  0.2950,  0.3450,  0.1578],\n",
      "        [-0.2273,  0.1859, -0.2438,  ...,  0.0192, -0.0410,  0.0612],\n",
      "        [ 0.0351,  0.6079, -0.2740,  ..., -0.4105,  0.0137, -0.0738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1497,  0.3014, -0.2261,  0.1509,  0.0034, -0.1552, -0.0780,\n",
      "          -0.0400,  0.0095,  0.0899,  0.1770, -0.1360,  0.0528,  0.1240,\n",
      "           0.2129, -0.1326, -0.1208, -0.1034, -0.1320,  0.2075, -0.1506,\n",
      "           0.0159,  0.2138, -0.0616,  0.0455,  0.0384, -0.1438, -0.1403,\n",
      "          -0.1359, -0.2539,  0.1165, -0.2771, -0.3251, -0.1460,  0.1073,\n",
      "          -0.0312, -0.1056, -0.1309, -0.0384,  0.1569,  0.2134, -0.0148,\n",
      "          -0.1093, -0.0398,  0.2871,  0.0707, -0.0245,  0.0161, -0.0631,\n",
      "          -0.0069, -0.0032, -0.1490, -0.0971, -0.0340,  0.0450, -0.2213,\n",
      "           0.0180,  0.2409, -0.1046,  0.2114,  0.0454,  0.0534,  0.0687,\n",
      "           0.0135, -0.0130, -0.2020,  0.0510,  0.2070,  0.0420,  0.2262,\n",
      "           0.0067,  0.2852, -0.0579,  0.1677, -0.0900, -0.0787,  0.0743,\n",
      "          -0.0269,  0.0869, -0.1007,  0.0702, -0.0041, -0.3115, -0.2447,\n",
      "          -0.0347,  0.2039,  0.1100,  0.0105,  0.0814,  0.0680,  0.0266,\n",
      "           0.0071,  0.1492,  0.1007,  0.0779, -0.1023,  0.0401,  0.1555,\n",
      "          -0.0969,  0.3028, -0.2303, -0.0437, -0.0115,  0.0782, -0.1523,\n",
      "          -0.0520,  0.1780, -0.0687, -0.0572,  0.1540,  0.1937, -0.1489,\n",
      "           0.1435, -0.0543, -0.1807, -0.0340, -0.0315, -0.1531,  0.0725,\n",
      "          -0.0678,  0.2851, -0.0608, -0.1031, -0.0222, -0.1290, -0.1842,\n",
      "           0.1078,  0.0835,  0.0726, -0.1119,  0.1987, -0.2538,  0.0695,\n",
      "           0.3168,  0.1037,  0.0008,  0.2291, -0.1267, -0.2110,  0.2550,\n",
      "          -0.1461,  0.0657,  0.0521,  0.1251,  0.0164,  0.0664, -0.1273,\n",
      "           0.2430,  0.1224, -0.0570, -0.0925, -0.0384,  0.0187,  0.1035,\n",
      "          -0.0180,  0.0275, -0.1979, -0.1158,  0.1171,  0.1100, -0.0450,\n",
      "          -0.0839, -0.0882,  0.1136, -0.0172,  0.1124,  0.0527, -0.1122,\n",
      "           0.0482, -0.0011, -0.2494, -0.0461,  0.0107,  0.0806, -0.0628,\n",
      "           0.0335, -0.0011,  0.0168,  0.3607,  0.1308,  0.0095,  0.0781,\n",
      "          -0.0019, -0.0947, -0.1368,  0.0632, -0.3101, -0.1711, -0.0598,\n",
      "          -0.0471, -0.0640, -0.0616, -0.1436, -0.0236, -0.2133,  0.0507,\n",
      "           0.0940, -0.0726, -0.0433,  0.1451, -0.0152, -0.1858,  0.1611,\n",
      "           0.0813,  0.1261, -0.3127,  0.0441,  0.3537,  0.0577,  0.0733,\n",
      "           0.1629, -0.0582, -0.0449,  0.1689,  0.0591,  0.2266,  0.1141,\n",
      "          -0.0250, -0.0274,  0.1015,  0.1191, -0.0492, -0.1107, -0.1429,\n",
      "           0.2005,  0.0858, -0.1577, -0.1519, -0.4178,  0.4024, -0.0809,\n",
      "          -0.0895, -0.1550, -0.0858,  0.1490,  0.3623, -0.0887,  0.0099,\n",
      "           0.1217, -0.0296, -0.0308, -0.1206, -0.0713,  0.0389,  0.2856,\n",
      "          -0.0545, -0.1202, -0.0983,  0.0714, -0.0426,  0.0494, -0.0274,\n",
      "          -0.2341, -0.1633,  0.1001,  0.0429]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9403e-01,  8.9378e-02, -5.4478e-01,  5.4053e-01, -5.6671e-01,\n",
      "           1.2814e+00,  2.8250e+00, -2.4715e-01,  1.6129e+00, -7.5657e-01,\n",
      "          -5.3081e-01, -1.9825e-01,  1.4281e-01,  9.6504e-01,  4.9978e-01,\n",
      "          -2.1831e-02,  1.9364e+00,  6.1966e-01,  7.5105e-01,  1.0217e+00,\n",
      "           5.3163e-02,  1.4897e+00,  1.6815e+00,  3.0949e-01, -6.9749e-01,\n",
      "          -1.7923e+00,  9.4618e-01, -1.6199e+00, -1.3355e+00, -2.3743e-01,\n",
      "           1.0224e+00,  4.1244e-02,  1.2296e+00,  1.0356e+00, -2.2232e+00,\n",
      "          -1.1213e-01,  8.0388e-01,  2.8217e+00, -9.0152e-01,  7.7045e-01,\n",
      "           6.9290e-01,  1.3752e+00, -4.4731e-01, -7.7367e-01,  4.1203e-01,\n",
      "           7.2489e-01, -2.6875e-03,  1.3008e-01, -1.4964e+00, -5.1813e-01,\n",
      "          -1.6946e+00,  3.1146e-01, -1.8044e-01,  2.5758e-01,  5.9940e-01,\n",
      "           8.0400e-01,  0.0000e+00, -3.5926e-01, -1.7293e+00,  7.3654e-01,\n",
      "          -7.7891e-03, -3.9192e-01,  1.0846e+00,  0.0000e+00, -8.9574e-02,\n",
      "           1.5460e-02, -1.1184e-01, -1.0999e+00,  2.7156e-01,  3.5246e-01,\n",
      "           1.9232e+00,  4.2112e-01,  0.0000e+00, -1.2294e+00,  8.9076e-01,\n",
      "           1.9466e-01,  2.5249e+00,  1.5198e+00,  1.8507e+00,  3.8338e-01,\n",
      "          -3.5148e-01,  5.9857e-01, -1.8425e+00, -4.7891e-01, -2.5805e-01,\n",
      "           5.8875e-01,  7.3192e-01,  4.4386e-01,  1.3635e+00, -1.7619e-01,\n",
      "           5.8523e-01, -2.1565e+00,  0.0000e+00,  3.5400e-01,  0.0000e+00,\n",
      "           2.7016e+00, -1.7219e+00,  1.2751e+00, -4.4097e-02, -1.0985e+00,\n",
      "          -7.0113e-01, -2.0438e+00, -6.6987e-01, -1.6072e-01,  1.6322e+00,\n",
      "          -1.0263e+00, -6.5250e-01, -2.4368e+00,  6.9377e-01, -2.8751e-01,\n",
      "          -1.1893e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8895e-01,\n",
      "           4.4230e-01, -1.6687e+00,  2.7232e-01,  7.8186e-01, -9.4794e-01,\n",
      "           7.5995e-01, -1.5665e-02, -1.1623e+00, -1.0949e+00,  3.9410e-01,\n",
      "          -3.3331e-01,  3.8105e-01,  9.3828e-01, -3.1022e-01, -1.2435e+00,\n",
      "           1.8615e+00,  0.0000e+00, -2.8893e+00,  2.1881e-01,  6.4110e-03,\n",
      "           1.6982e+00,  6.9473e-01,  1.1919e+00, -7.2225e-01, -1.7348e-01,\n",
      "           7.9508e-01,  0.0000e+00,  8.6710e-01, -1.4532e+00,  0.0000e+00,\n",
      "           3.4178e-01, -1.1809e+00, -1.0240e+00,  4.0515e-02,  1.0778e+00,\n",
      "          -1.9801e+00,  3.2429e-01,  0.0000e+00,  3.6255e-01, -1.5382e+00,\n",
      "           3.0207e+00,  0.0000e+00,  0.0000e+00, -7.0173e-01,  0.0000e+00,\n",
      "           1.8931e+00, -7.9466e-01, -5.2154e-01,  3.0363e-01, -6.0808e-01,\n",
      "          -2.1513e+00, -1.8741e-01,  1.3555e-01, -1.1577e+00, -1.4454e-01,\n",
      "           2.2001e-01, -1.0645e+00, -1.0992e-01, -6.6678e-01, -8.9389e-01,\n",
      "           1.0822e-01, -1.1214e+00, -1.8539e-01,  1.3380e+00,  1.3490e+00,\n",
      "           1.0815e+00,  0.0000e+00,  1.7313e+00,  2.2391e-02, -4.7360e-01,\n",
      "           7.0070e-01,  3.8602e-01, -8.2271e-02,  1.1609e+00, -5.2624e-01,\n",
      "           4.1170e-01,  8.9900e-02,  6.7028e-01, -7.9263e-01,  0.0000e+00,\n",
      "          -7.5049e-01,  1.2238e+00,  0.0000e+00,  6.2842e-01,  1.7517e+00,\n",
      "           1.1110e+00,  7.7643e-01,  0.0000e+00,  1.7859e+00, -1.3504e+00,\n",
      "          -1.0611e+00, -4.7629e-01,  0.0000e+00, -5.3732e-01, -1.1330e-01,\n",
      "           5.6427e-01, -1.8134e+00,  1.3914e+00, -3.2296e+00,  2.5845e+00,\n",
      "           1.3446e+00, -3.1818e-01,  7.5075e-01, -1.3998e+00, -1.5711e+00,\n",
      "          -8.1457e-01,  9.9598e-01,  2.1175e+00,  4.1975e-01, -9.0906e-01,\n",
      "           4.9429e-01,  9.6769e-01, -2.4501e+00,  5.2609e-01,  1.7585e-01,\n",
      "          -2.9660e-01, -2.2930e+00,  1.0924e-01,  0.0000e+00, -4.6619e-02,\n",
      "           9.6864e-01, -3.0724e-02, -2.6062e-01, -6.8859e-01,  1.0011e+00,\n",
      "           0.0000e+00,  8.7398e-01,  0.0000e+00, -1.0516e+00,  1.6174e+00,\n",
      "           3.1720e-01,  1.2641e+00,  0.0000e+00,  1.7831e-01, -1.8398e+00,\n",
      "          -7.2776e-01,  0.0000e+00, -5.3294e-01,  0.0000e+00, -4.4625e-01,\n",
      "           1.4436e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1288, 0.0998, 0.0985, 0.1208, 0.0729, 0.1228, 0.0700, 0.0534, 0.1394,\n",
      "         0.0936]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1493, -0.2362, -0.0162,  ...,  0.2950,  0.3450,  0.1578],\n",
      "        [-0.2273,  0.1859, -0.2438,  ...,  0.0192, -0.0410,  0.0612],\n",
      "        [ 0.0351,  0.6079, -0.2740,  ..., -0.4105,  0.0137, -0.0738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1463,  0.2050, -0.1409,  0.1015,  0.0373, -0.1879, -0.0970,\n",
      "           0.0195, -0.0499,  0.1281,  0.1464, -0.1218,  0.0552,  0.0783,\n",
      "           0.1044, -0.0892, -0.0541, -0.0950, -0.1349,  0.1596, -0.1044,\n",
      "          -0.0023,  0.1305, -0.1065,  0.0777,  0.0622, -0.0688, -0.0937,\n",
      "          -0.0883, -0.1832,  0.1216, -0.2200, -0.2856, -0.1306,  0.0486,\n",
      "          -0.0418, -0.0960, -0.1294, -0.0505,  0.0977,  0.2018,  0.0277,\n",
      "          -0.0365, -0.0475,  0.2036,  0.0252, -0.0289,  0.0473, -0.0541,\n",
      "           0.0246,  0.0316, -0.1654, -0.0218, -0.0077,  0.0409, -0.1725,\n",
      "           0.0334,  0.2017, -0.0606,  0.1164,  0.0542,  0.0315,  0.0688,\n",
      "          -0.0491,  0.0254, -0.1789,  0.0487,  0.1741,  0.0331,  0.1745,\n",
      "           0.0095,  0.1914, -0.0919,  0.1458, -0.0319, -0.0672,  0.0555,\n",
      "          -0.0069,  0.0277, -0.0594,  0.0636,  0.0452, -0.2017, -0.1839,\n",
      "          -0.0141,  0.1531,  0.1268,  0.0128,  0.0517,  0.1307,  0.0696,\n",
      "           0.0261,  0.1364,  0.0709,  0.0971, -0.1066,  0.0273,  0.0876,\n",
      "          -0.0349,  0.2416, -0.1666, -0.0561,  0.0473,  0.0414, -0.1547,\n",
      "          -0.0238,  0.1436, -0.0441, -0.0384,  0.1023,  0.1160, -0.0920,\n",
      "           0.1341, -0.0040, -0.1031, -0.0151,  0.0004, -0.0793,  0.0162,\n",
      "          -0.0026,  0.2602, -0.0326, -0.0680, -0.0319, -0.0716, -0.1478,\n",
      "           0.0813,  0.0894, -0.0022, -0.0827,  0.1922, -0.1790,  0.0034,\n",
      "           0.2116,  0.0775,  0.0015,  0.2124, -0.1157, -0.1896,  0.2176,\n",
      "          -0.1161,  0.0454,  0.0072,  0.1351, -0.0192,  0.0793, -0.0807,\n",
      "           0.1635,  0.1005, -0.0778, -0.0160, -0.0728,  0.0549,  0.0584,\n",
      "           0.0081, -0.0229, -0.1128, -0.1176,  0.1003,  0.1000, -0.0485,\n",
      "          -0.0738, -0.0169,  0.0897,  0.0059,  0.0776,  0.0484, -0.0995,\n",
      "           0.0661, -0.0419, -0.1922, -0.0211, -0.0659,  0.0936, -0.0618,\n",
      "           0.0372, -0.0196, -0.0299,  0.2965,  0.0757,  0.0139,  0.0742,\n",
      "           0.0133, -0.0884, -0.1266, -0.0035, -0.2128, -0.1456, -0.0701,\n",
      "           0.0107,  0.0021, -0.0655, -0.0556,  0.0125, -0.2113,  0.0483,\n",
      "           0.0649, -0.0842, -0.0465,  0.0784,  0.0131, -0.1509,  0.1447,\n",
      "           0.0324,  0.1149, -0.2419,  0.0613,  0.2695,  0.0539,  0.0297,\n",
      "           0.1006, -0.0481, -0.0319,  0.0990,  0.0363,  0.1897,  0.1035,\n",
      "          -0.0145,  0.0013,  0.0657,  0.0377, -0.0553, -0.1274, -0.0628,\n",
      "           0.1574,  0.0461, -0.0954, -0.2036, -0.3098,  0.3635, -0.0507,\n",
      "          -0.0635, -0.1258, -0.0497,  0.1302,  0.3274, -0.0468,  0.0169,\n",
      "           0.1310, -0.0578,  0.0355, -0.0913,  0.0032,  0.0387,  0.2354,\n",
      "          -0.0503, -0.0458, -0.0209,  0.0954, -0.0337,  0.0646, -0.0435,\n",
      "          -0.1971, -0.0684,  0.1386,  0.0631]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.6307,  0.0000,  0.0000, -0.7559,  0.2223, -1.3140,  1.5983,\n",
      "           1.8752, -2.0175,  0.8078,  0.0000, -0.9712,  1.0389,  0.1729,\n",
      "          -0.4915,  1.2320,  0.9880,  0.0000,  0.1170,  0.2086,  0.6336,\n",
      "           1.1296,  0.0000, -0.2919, -1.2370,  0.7131, -0.6949,  0.8036,\n",
      "           0.0000,  0.2626, -1.3182, -0.8586,  0.6753,  1.1297, -0.5384,\n",
      "           0.5337, -0.2759,  0.8773,  0.4020,  0.4132,  0.0000,  0.1291,\n",
      "          -1.4544,  0.1467, -1.3014, -0.5558,  0.5960, -1.7390, -1.3850,\n",
      "           0.3846,  0.0675,  1.6436, -0.5135,  0.0000, -1.0260,  0.5883,\n",
      "           3.0135,  1.0719, -0.2379,  0.6414,  0.7664,  0.8571,  0.9211,\n",
      "          -1.3334,  0.7773,  0.5604, -0.6900, -1.3412, -0.6050,  1.3593,\n",
      "          -1.6189,  0.0000,  1.3642, -1.5915,  0.6810,  0.0000, -0.8666,\n",
      "           2.5443, -0.2122,  0.0000, -1.4701,  0.4725,  1.1419, -2.1805,\n",
      "          -0.8493, -0.4238,  0.0000,  2.1799,  3.0923,  0.0000,  1.2676,\n",
      "           2.2273,  0.4478, -2.5435,  1.0833,  0.2058, -0.3619, -0.2438,\n",
      "           0.1913, -1.2148, -0.0720,  0.1940, -0.6018,  0.6967, -0.8139,\n",
      "           0.7305, -0.3326,  1.5438,  0.0511,  0.3195,  0.6045, -0.0331,\n",
      "           0.4187, -1.6215, -0.3931, -0.7641,  0.6183, -0.9853, -0.8210,\n",
      "          -0.6558, -0.3726, -0.5896,  0.4360,  0.8404, -0.4912, -0.2784,\n",
      "          -1.3502,  1.3770,  1.0660,  1.4466, -1.3095,  0.3118,  0.0000,\n",
      "           1.7056,  0.7472,  0.0182, -0.9717, -0.3418, -2.6542, -0.3500,\n",
      "          -1.3378, -0.0097,  0.0000,  0.2460, -1.0732,  0.9960, -0.0656,\n",
      "          -1.0825, -2.0522, -0.4458,  1.4475,  0.9387,  0.6503, -1.1843,\n",
      "           1.0806,  0.0000, -0.2321,  0.1856, -0.0620,  0.3850, -0.2152,\n",
      "           0.7094,  0.7717, -1.3827,  0.8241, -1.6749,  0.0969, -1.3061,\n",
      "           0.5661, -0.3926,  0.3602,  0.0000, -0.2326,  0.4382, -0.5382,\n",
      "           0.0751,  1.0371, -0.2009, -0.5966,  0.0000,  1.1222,  1.4704,\n",
      "          -0.9339, -0.5497,  0.0000, -0.1047,  0.4065,  0.4601, -1.1811,\n",
      "           2.0707, -0.1203, -1.7372, -0.4122,  0.2583,  1.0564,  0.2595,\n",
      "           0.1920, -1.4728,  1.7476,  0.0000, -0.2530,  0.6863,  1.6038,\n",
      "          -0.8528,  0.6743,  0.3713, -1.5251, -0.7055, -0.6948,  1.2024,\n",
      "          -0.5452,  0.0430,  0.4222,  0.0000, -0.2419,  0.0000, -0.5786,\n",
      "           0.5307, -0.9985, -0.2939, -1.2814,  0.3517, -0.1899, -0.6004,\n",
      "           0.9888,  0.0951,  0.4715, -0.3040, -0.3657, -1.0528, -0.8832,\n",
      "           0.4146,  0.9036,  1.1564, -1.5769,  2.1820, -0.0459,  0.8681,\n",
      "          -0.4795,  0.0521,  1.2139,  1.7965,  1.0003,  1.3697, -0.4828,\n",
      "          -1.0263,  0.3183,  0.0000, -0.4874, -0.2846, -1.0532,  0.0000,\n",
      "          -0.7071,  0.2640, -0.0805, -0.4922]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0502, 0.1160, 0.0952, 0.0589, 0.0957, 0.2858, 0.0530, 0.0582, 0.1224,\n",
      "         0.0646]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1493, -0.2362, -0.0162,  ...,  0.2950,  0.3450,  0.1578],\n",
      "        [-0.2273,  0.1859, -0.2438,  ...,  0.0192, -0.0410,  0.0612],\n",
      "        [ 0.0351,  0.6079, -0.2740,  ..., -0.4105,  0.0137, -0.0738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.4710e-01,  3.0111e-01, -2.7075e-01,  1.0063e-01, -5.1313e-02,\n",
      "          -2.2966e-01, -2.5489e-02, -1.0418e-01, -2.4460e-02,  2.9768e-02,\n",
      "           1.7923e-01, -1.9541e-01, -4.0505e-02,  1.0222e-01,  2.0600e-01,\n",
      "          -1.2192e-01, -3.0927e-02, -1.2445e-02, -2.2523e-01,  2.0133e-01,\n",
      "          -1.9812e-01, -1.0149e-01,  2.0473e-01,  1.3582e-02, -1.6018e-02,\n",
      "          -6.8523e-02, -1.0699e-01, -1.9773e-01, -1.5358e-01, -2.0029e-01,\n",
      "           1.9018e-01, -3.2883e-01, -3.3293e-01, -2.3753e-01,  5.8379e-02,\n",
      "           3.0848e-02, -1.8899e-01, -1.6453e-01, -1.5941e-01,  1.2577e-01,\n",
      "           1.8734e-01,  3.8075e-03, -1.1882e-01, -5.6540e-03,  2.6054e-01,\n",
      "           1.2350e-01, -6.4760e-02, -8.8549e-02,  1.6049e-02,  2.3102e-02,\n",
      "          -6.1054e-02, -1.7489e-01, -1.4184e-01,  4.4977e-03,  1.6178e-02,\n",
      "          -1.6094e-01,  1.5819e-02,  2.5178e-01,  1.8764e-02,  2.5782e-01,\n",
      "           2.9023e-03, -1.1960e-03, -6.7575e-02,  1.9319e-02, -5.2352e-02,\n",
      "          -1.8627e-01,  7.7702e-03,  2.3790e-01, -2.4679e-02,  1.9931e-01,\n",
      "           1.5072e-02,  2.6482e-01, -9.0412e-02,  1.9896e-01, -1.5779e-01,\n",
      "          -2.7245e-02,  1.5828e-01,  5.3494e-02,  1.8179e-02,  1.0301e-02,\n",
      "          -2.7942e-02, -1.0967e-01, -3.4174e-01, -1.9226e-01, -4.7298e-02,\n",
      "           2.1204e-01,  1.3914e-01,  3.1090e-03,  1.6750e-01,  5.6628e-02,\n",
      "           1.2870e-01,  9.4033e-03,  1.3671e-01,  8.4320e-02,  5.6200e-02,\n",
      "          -6.3417e-02,  1.0690e-01,  1.9744e-01, -8.1750e-02,  3.6763e-01,\n",
      "          -2.5852e-01,  2.4037e-02,  1.0556e-01,  8.5305e-02, -1.8870e-01,\n",
      "          -8.0830e-02,  2.0953e-01,  6.1912e-02, -8.2823e-02,  1.7244e-01,\n",
      "           1.9991e-01, -1.2193e-01,  1.7854e-01, -1.4090e-01, -2.0582e-01,\n",
      "           4.3069e-04, -1.8976e-02, -1.3331e-01, -4.2224e-02, -8.8614e-02,\n",
      "           2.8782e-01, -9.1474e-02, -1.9568e-01, -8.2516e-03, -1.7721e-01,\n",
      "          -1.9675e-01,  6.9480e-02,  1.6231e-02,  1.1607e-01, -1.3077e-01,\n",
      "           2.4408e-01, -3.0703e-01,  1.4827e-01,  3.1649e-01,  3.1522e-02,\n",
      "           5.3577e-02,  3.1221e-01, -8.3768e-02, -2.8982e-01,  2.8178e-01,\n",
      "          -1.4687e-01,  1.3829e-01, -4.5415e-02,  2.1512e-01,  5.7361e-02,\n",
      "           4.8067e-02, -7.0100e-02,  2.8750e-01,  1.4549e-01,  2.2936e-02,\n",
      "          -2.1952e-01, -1.2785e-02,  4.6582e-02,  1.7394e-01,  5.2051e-02,\n",
      "           1.3135e-01, -1.6753e-01, -4.7552e-02,  1.5753e-01,  5.4583e-03,\n",
      "          -1.1256e-01, -1.7299e-01, -1.9944e-01,  2.3003e-01,  2.7103e-02,\n",
      "           1.4436e-01, -3.7340e-02, -1.4064e-01,  1.8387e-01,  1.1453e-01,\n",
      "          -2.8768e-01, -2.1372e-02,  5.7589e-02,  4.3252e-02, -1.2142e-01,\n",
      "          -4.2379e-02, -6.2603e-02,  6.5370e-02,  4.0972e-01,  4.5617e-02,\n",
      "          -7.9562e-02, -1.7197e-02, -9.3955e-02, -8.8659e-02, -3.7751e-02,\n",
      "           1.0717e-01, -3.5749e-01, -5.4973e-02,  7.0006e-03, -1.0677e-01,\n",
      "          -4.9164e-02, -6.2968e-03, -2.2855e-01, -8.2670e-02, -1.4541e-01,\n",
      "          -5.7219e-02,  1.0775e-02, -4.2881e-02, -1.5939e-01,  1.5250e-01,\n",
      "          -1.7572e-02, -6.7941e-02,  7.6030e-02,  1.7030e-01,  1.6329e-01,\n",
      "          -3.1187e-01,  3.7476e-02,  3.7442e-01,  1.1368e-02, -1.4990e-02,\n",
      "           1.3153e-01, -1.4931e-01, -4.3753e-02,  1.8932e-01,  4.5625e-03,\n",
      "           2.7136e-01,  1.3167e-03,  4.9919e-02, -9.3563e-02,  1.6108e-01,\n",
      "           1.8479e-01, -1.3779e-01, -1.3556e-02, -1.5140e-01,  2.2785e-01,\n",
      "           1.4798e-01, -7.9869e-03, -2.4776e-01, -4.3521e-01,  4.2703e-01,\n",
      "          -1.8081e-01, -1.1163e-01, -1.4447e-01, -1.7267e-01,  7.8066e-02,\n",
      "           2.8611e-01, -1.5930e-01, -7.4988e-03,  2.1283e-01, -5.4975e-03,\n",
      "          -3.3920e-02, -1.6452e-01, -1.1583e-01,  2.5155e-02,  2.7862e-01,\n",
      "          -4.2584e-02, -1.5091e-01, -1.1657e-01,  1.4657e-01,  2.4249e-02,\n",
      "           1.0122e-01, -1.7411e-02, -2.7962e-01, -1.6667e-01,  1.2927e-01,\n",
      "           7.1683e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0507,  1.6141, -1.2214,  0.1080, -0.8038, -0.0744,  0.1358,\n",
      "          -1.0209, -0.3500,  0.6069,  0.0000,  1.4546,  0.1340, -1.7006,\n",
      "          -0.3716, -2.3566, -0.7013,  1.1501, -1.8744,  1.1428,  0.7345,\n",
      "          -1.9032,  0.4699,  0.0000, -0.3141, -0.4286, -0.3102, -0.2256,\n",
      "           1.2871,  0.0963,  1.4813, -2.2024,  0.8983,  1.8797, -0.7504,\n",
      "           2.4262,  1.0766,  0.1914, -0.3676,  0.7129,  0.3715, -0.4465,\n",
      "           2.2501,  0.0000,  1.5157, -0.3135,  0.7477, -1.1212, -0.3445,\n",
      "           0.1406,  0.0000,  1.7996, -0.7626, -0.4866, -0.4768,  1.2274,\n",
      "           0.4436,  1.6410, -0.8593,  0.1734, -1.4063,  0.6265, -2.4135,\n",
      "           0.0000, -0.5695, -0.6561, -0.2815,  0.0356, -1.5837,  0.0000,\n",
      "          -1.4249,  0.9807, -0.0848,  1.7224, -1.0821,  1.2172,  0.0090,\n",
      "           1.5482,  1.3214,  0.2863,  1.0364, -0.5739, -0.5292,  1.2606,\n",
      "          -1.1710,  0.0000,  0.0369, -0.3127, -0.3952, -0.6792, -0.6997,\n",
      "           0.0000, -0.1374, -1.2539,  0.0000,  1.9075,  0.0000,  0.4666,\n",
      "           1.2743,  0.9408,  0.0986, -1.6312,  1.1925,  0.0000,  1.1345,\n",
      "          -2.1752,  0.5375,  2.2627,  0.5055,  1.8176,  1.3766, -0.3851,\n",
      "           1.0509,  0.0000,  0.0389,  0.1987,  0.7164,  0.0828,  0.0000,\n",
      "           0.6507, -1.9371, -0.1453,  0.3462,  0.9735,  0.3104, -0.0721,\n",
      "          -0.3567, -1.1980,  0.9572,  0.7303, -1.1507,  0.6041, -0.1354,\n",
      "          -1.7473,  0.5434, -1.1582, -1.1250, -0.1607,  0.6993, -1.1833,\n",
      "           1.1297,  0.3956,  1.8452, -0.8988,  1.9360,  0.7250, -1.1345,\n",
      "           0.2226,  0.9149,  0.5005, -0.6787,  0.0000,  0.4276,  0.0568,\n",
      "           1.2494,  0.0000, -1.2593, -1.2798,  0.0000, -0.6549, -0.0675,\n",
      "          -1.6398, -1.0454, -0.2558, -0.3493, -0.3370,  0.0187,  0.0000,\n",
      "           0.5776, -0.4899,  0.2926,  1.3031,  0.0000,  0.9586,  1.0213,\n",
      "          -1.0057,  0.7561, -0.1309,  0.4548, -0.8265,  0.9848,  0.0000,\n",
      "          -0.0714, -0.0151, -2.3935,  0.5258, -1.3847, -0.3716, -1.3874,\n",
      "           2.4804,  0.7481,  0.7422,  1.9217, -0.0912, -0.1427,  0.6047,\n",
      "           0.0000, -1.1478,  1.9328,  1.4632, -0.1506, -0.2662,  0.7295,\n",
      "          -1.5532,  1.3350,  0.6862,  0.9932,  0.4499, -0.9493,  2.2195,\n",
      "           0.0000,  0.8170,  0.1870,  0.4399,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.2084,  0.2803,  0.0000,  0.0000, -0.6300,\n",
      "           0.0493, -0.5804,  0.0661, -0.5981, -0.4548, -0.3997,  1.0923,\n",
      "          -1.5175, -2.0323, -0.5674, -1.1073,  1.9828,  1.8105, -0.1326,\n",
      "           1.7837, -0.1125, -0.4887,  0.0000,  0.0000,  0.7567,  1.6990,\n",
      "           0.0000, -0.2755, -0.4580, -0.5621,  0.6714,  0.0075, -0.2975,\n",
      "          -0.4273,  0.6650, -2.0469, -0.1356]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0583, 0.0589, 0.1072, 0.0703, 0.1266, 0.2342, 0.0780, 0.1459, 0.0739,\n",
      "         0.0468]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1493, -0.2362, -0.0162,  ...,  0.2950,  0.3450,  0.1578],\n",
      "        [-0.2273,  0.1859, -0.2438,  ...,  0.0192, -0.0410,  0.0612],\n",
      "        [ 0.0351,  0.6079, -0.2740,  ..., -0.4105,  0.0137, -0.0738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.4200e-01,  2.7816e-01, -2.2917e-01,  7.7669e-02, -1.8684e-02,\n",
      "          -2.5412e-01, -4.1353e-02, -7.8226e-02, -4.6304e-02,  2.8615e-02,\n",
      "           1.5681e-01, -1.6396e-01, -3.7009e-02,  1.2260e-01,  1.7575e-01,\n",
      "          -8.2503e-02, -7.1283e-03,  1.5386e-03, -1.9863e-01,  1.8973e-01,\n",
      "          -1.9023e-01, -8.9321e-02,  1.9366e-01, -5.6903e-03,  1.4662e-02,\n",
      "          -3.7333e-02, -6.9936e-02, -1.9195e-01, -1.2019e-01, -1.6694e-01,\n",
      "           2.0051e-01, -2.9237e-01, -3.0305e-01, -2.3028e-01,  4.8372e-02,\n",
      "           4.8835e-02, -1.7849e-01, -1.5508e-01, -1.5041e-01,  1.4418e-01,\n",
      "           1.9823e-01,  2.3570e-02, -7.8478e-02, -2.0713e-02,  2.1512e-01,\n",
      "           1.2315e-01, -3.8922e-02, -5.6344e-02,  2.8830e-02,  4.0454e-02,\n",
      "          -2.7210e-02, -1.4741e-01, -1.2812e-01,  8.3304e-03,  4.1679e-02,\n",
      "          -1.4417e-01,  2.4530e-02,  2.2465e-01,  2.0066e-02,  1.9830e-01,\n",
      "           1.1926e-02, -1.6835e-02, -6.0159e-02,  2.1225e-02, -5.4724e-02,\n",
      "          -1.8230e-01,  5.8229e-03,  2.4373e-01, -3.6990e-02,  2.0662e-01,\n",
      "           3.5560e-02,  2.3971e-01, -1.0625e-01,  1.7493e-01, -1.2054e-01,\n",
      "          -9.8647e-03,  1.2964e-01,  5.4911e-02,  2.0898e-02, -8.9422e-05,\n",
      "          -3.1719e-02, -7.7083e-02, -2.9061e-01, -1.7038e-01, -4.8575e-02,\n",
      "           1.7990e-01,  1.5470e-01,  1.5719e-02,  1.6754e-01,  9.3389e-02,\n",
      "           1.0676e-01, -3.5704e-03,  1.2713e-01,  5.5128e-02,  5.2872e-02,\n",
      "          -4.4257e-02,  9.8071e-02,  1.6771e-01, -5.2916e-02,  3.3315e-01,\n",
      "          -2.1244e-01,  3.1401e-02,  9.4516e-02,  8.4880e-02, -1.6675e-01,\n",
      "          -5.2234e-02,  1.8024e-01,  7.2561e-02, -9.8004e-02,  1.3939e-01,\n",
      "           1.7331e-01, -9.5337e-02,  1.6409e-01, -1.0973e-01, -1.5089e-01,\n",
      "          -1.6720e-02, -3.1508e-03, -1.1113e-01, -5.1382e-02, -5.6529e-02,\n",
      "           2.6496e-01, -7.1296e-02, -1.5994e-01, -6.6350e-03, -1.4732e-01,\n",
      "          -1.8350e-01,  7.4530e-02, -2.5383e-04,  1.1243e-01, -1.0926e-01,\n",
      "           2.0624e-01, -2.4795e-01,  9.3984e-02,  2.8502e-01,  4.2890e-02,\n",
      "           4.8760e-02,  2.8917e-01, -6.2306e-02, -2.5068e-01,  2.7080e-01,\n",
      "          -1.1683e-01,  1.2269e-01, -3.6082e-02,  1.8407e-01,  4.3373e-02,\n",
      "           3.4427e-02, -6.2904e-02,  2.5928e-01,  1.6236e-01,  1.6328e-02,\n",
      "          -2.0493e-01, -6.8318e-03,  5.4719e-02,  1.4840e-01,  6.1119e-02,\n",
      "           1.0008e-01, -1.3408e-01, -4.0853e-02,  1.2245e-01,  7.9553e-03,\n",
      "          -1.1687e-01, -1.4712e-01, -1.6504e-01,  2.2007e-01,  1.6692e-02,\n",
      "           1.3024e-01, -3.4037e-02, -1.3146e-01,  1.5497e-01,  7.2964e-02,\n",
      "          -2.5141e-01, -3.4226e-02,  4.5760e-02,  4.9174e-02, -9.4298e-02,\n",
      "          -5.6334e-02, -4.0032e-02,  7.2784e-02,  3.8454e-01,  4.4421e-02,\n",
      "          -8.1055e-02, -1.0371e-02, -8.6396e-02, -8.2141e-02, -2.9874e-02,\n",
      "           9.1847e-02, -2.9152e-01, -7.6993e-02, -1.1065e-02, -8.2348e-02,\n",
      "          -1.6390e-02, -2.0552e-02, -2.0353e-01, -7.4367e-02, -1.5143e-01,\n",
      "          -5.5076e-02,  1.2291e-02, -2.0646e-02, -1.3949e-01,  1.1633e-01,\n",
      "          -1.0962e-03, -5.7401e-02,  9.4748e-02,  1.2982e-01,  1.5606e-01,\n",
      "          -2.8350e-01,  3.0359e-02,  3.4183e-01,  1.8496e-02, -3.2078e-02,\n",
      "           9.5652e-02, -1.5695e-01, -2.5137e-02,  1.5784e-01, -1.2417e-02,\n",
      "           2.4937e-01,  5.6430e-02,  6.6908e-02, -1.0891e-01,  1.3015e-01,\n",
      "           1.6734e-01, -1.0201e-01, -2.3476e-02, -1.5042e-01,  1.9841e-01,\n",
      "           1.3125e-01, -2.0324e-02, -2.5103e-01, -4.0799e-01,  3.8361e-01,\n",
      "          -1.6995e-01, -9.6448e-02, -1.6458e-01, -1.3338e-01,  8.9878e-02,\n",
      "           2.8143e-01, -1.3980e-01, -9.4018e-03,  2.1851e-01,  4.7938e-03,\n",
      "          -2.0577e-02, -1.3459e-01, -5.6981e-02,  2.3426e-02,  2.6896e-01,\n",
      "          -4.0593e-02, -1.2696e-01, -1.0035e-01,  1.2990e-01, -1.5375e-02,\n",
      "           1.1303e-01, -1.0769e-02, -2.4005e-01, -1.6199e-01,  1.4793e-01,\n",
      "           6.0954e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-7.8839e-01,  6.9375e-03,  7.8557e-01,  1.7144e+00,  1.5047e-01,\n",
      "           1.9299e+00, -1.1301e+00,  8.4509e-01,  1.4018e+00, -1.5128e-01,\n",
      "          -2.6517e-01, -3.0484e-01,  9.0225e-01,  8.3934e-01, -7.2925e-01,\n",
      "          -2.1799e+00, -7.2014e-01, -2.8414e-01, -1.2561e+00, -2.6606e-01,\n",
      "           3.0800e-01,  3.2877e-01, -1.7683e+00, -3.8020e-01,  1.2155e+00,\n",
      "           4.5084e-01,  4.9826e-01,  7.9267e-01,  4.1774e-01,  2.8997e-01,\n",
      "          -9.0799e-05, -2.3637e-01,  1.1819e+00, -7.0194e-01,  6.0860e-01,\n",
      "          -4.5830e-01, -7.3863e-02, -9.9786e-01, -1.3862e+00, -5.7453e-02,\n",
      "           1.4477e-01, -1.3559e+00, -5.3631e-01, -2.8616e+00,  2.1398e+00,\n",
      "          -2.3117e+00, -3.9418e-01,  1.0764e+00,  1.6986e-01,  1.1000e+00,\n",
      "          -1.7479e+00,  2.1492e-01,  8.1293e-01,  8.3910e-01,  3.3960e-01,\n",
      "          -7.3270e-01, -3.5088e-01,  1.1729e+00,  1.7132e+00,  3.4379e-01,\n",
      "           1.0811e+00, -1.5139e+00, -7.9549e-01,  0.0000e+00, -1.4012e+00,\n",
      "          -2.6773e-02,  9.1548e-01, -8.0257e-01,  7.6316e-01,  2.0161e-01,\n",
      "           1.6046e+00,  2.5480e-01, -2.6291e-01,  3.8176e-01,  9.8805e-01,\n",
      "           4.0890e-01, -1.1953e-01,  4.4814e-01,  0.0000e+00,  7.3496e-01,\n",
      "           0.0000e+00, -1.5882e-01, -1.2697e+00,  5.0851e-01, -1.4293e+00,\n",
      "          -6.0933e-01,  1.5104e+00,  1.1429e+00,  8.2001e-01, -6.4108e-01,\n",
      "           2.7549e+00,  7.2732e-01,  5.8536e-01,  8.4843e-01, -4.4509e-01,\n",
      "           1.6376e+00, -4.0835e-01, -1.1141e-01, -2.6877e+00,  8.9153e-02,\n",
      "          -1.3411e+00,  1.5463e+00, -2.4238e+00,  4.8018e-01, -2.7063e-02,\n",
      "          -8.5816e-01,  2.5958e-01, -1.2573e+00, -3.4334e-01,  1.1104e+00,\n",
      "           4.8661e-01,  1.1371e+00,  4.8096e-01,  0.0000e+00, -5.8179e-01,\n",
      "          -1.6096e+00,  6.6209e-02,  8.7363e-01,  1.0817e+00,  1.7929e+00,\n",
      "          -3.3768e-01, -6.6665e-01, -7.6381e-02,  0.0000e+00, -1.0516e+00,\n",
      "           1.2779e+00,  3.0340e-01, -9.3132e-01, -2.9031e-01,  2.1721e-01,\n",
      "          -6.5994e-01,  0.0000e+00, -3.1262e-01,  6.4064e-01,  6.2267e-01,\n",
      "          -5.8925e-01, -5.9580e-02,  8.5244e-01,  0.0000e+00, -5.3422e-01,\n",
      "          -4.0077e-02, -1.4625e+00,  1.8048e+00, -8.0208e-01,  0.0000e+00,\n",
      "           1.2070e+00,  4.0159e-01,  1.0397e+00,  1.7697e+00,  1.3603e+00,\n",
      "          -2.8364e-01,  8.0093e-01, -2.8318e-01,  6.2842e-01, -5.6889e-02,\n",
      "           3.5273e-01, -1.1517e+00,  1.3249e+00,  1.1623e+00,  3.7357e-01,\n",
      "           0.0000e+00, -9.6682e-01,  5.5318e-02,  0.0000e+00, -1.3086e+00,\n",
      "          -7.1705e-01,  1.8932e-01, -9.7004e-01, -1.0428e+00, -4.0763e-01,\n",
      "          -1.3466e+00,  8.8285e-01, -1.0515e+00, -3.8872e-01, -5.2881e-01,\n",
      "           1.0978e+00,  0.0000e+00,  5.2222e-01, -5.5024e-02,  9.3980e-01,\n",
      "          -7.5244e-01,  3.1719e-02,  2.6640e-01,  1.2727e-01,  2.4320e+00,\n",
      "           0.0000e+00, -3.6568e-01,  0.0000e+00,  1.6878e+00,  5.7322e-01,\n",
      "           1.2814e+00, -8.5639e-01,  8.8764e-01, -1.0840e+00, -2.0584e-01,\n",
      "          -3.5491e-02, -5.7013e-01,  1.0049e+00,  1.3619e+00,  2.3022e-01,\n",
      "          -3.2810e-01,  3.5092e-01,  0.0000e+00, -6.0117e-01, -8.6859e-01,\n",
      "          -8.6293e-01,  5.4785e-01,  5.8714e-01, -1.4633e-01, -2.8221e-01,\n",
      "           2.1504e-02, -3.3162e-01,  1.1493e+00, -8.8825e-01, -9.4146e-03,\n",
      "           6.7285e-02, -2.6745e+00, -1.3823e-01,  8.0968e-01, -1.5925e+00,\n",
      "           9.2819e-01, -1.5197e-02,  3.9929e-01,  1.0385e+00, -2.3686e-01,\n",
      "           7.3773e-01,  2.0811e+00,  1.2423e-01,  6.7507e-01,  1.2923e+00,\n",
      "          -1.3433e+00, -1.0482e+00, -6.7592e-01,  9.0283e-01, -2.6722e+00,\n",
      "           1.6540e+00, -1.6798e+00,  2.3507e+00, -4.7394e-01,  1.3260e+00,\n",
      "          -5.6674e-01, -7.2329e-01, -4.8928e-02,  1.0026e+00, -1.3492e+00,\n",
      "           3.6418e-01, -1.2029e+00,  0.0000e+00,  0.0000e+00,  1.0703e+00,\n",
      "           1.1277e+00, -1.2310e+00, -2.8047e-01, -1.6291e+00, -1.3516e+00,\n",
      "          -8.6373e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0526, 0.1353, 0.1964, 0.1498, 0.0611, 0.0740, 0.1015, 0.0884, 0.0727,\n",
      "         0.0683]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1493, -0.2362, -0.0162,  ...,  0.2950,  0.3450,  0.1578],\n",
      "        [-0.2273,  0.1859, -0.2438,  ...,  0.0192, -0.0410,  0.0612],\n",
      "        [ 0.0351,  0.6079, -0.2740,  ..., -0.4105,  0.0137, -0.0738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0950,  0.2699, -0.1344,  0.1606,  0.0707, -0.1571, -0.0977,\n",
      "           0.0582, -0.0194,  0.1393,  0.1558, -0.0917,  0.1247,  0.1302,\n",
      "           0.1567, -0.0854, -0.1011, -0.1576, -0.0645,  0.2212, -0.1226,\n",
      "           0.0934,  0.1723, -0.1183,  0.1152,  0.0930, -0.1291, -0.1046,\n",
      "          -0.0898, -0.2327,  0.0926, -0.2193, -0.3085, -0.1097,  0.1117,\n",
      "          -0.0377, -0.0561, -0.1141,  0.0188,  0.1554,  0.2463, -0.0170,\n",
      "          -0.0271, -0.0640,  0.2535,  0.0120,  0.0266,  0.1040, -0.0956,\n",
      "           0.0211,  0.0483, -0.1351, -0.0371, -0.0148,  0.0841, -0.2478,\n",
      "           0.0527,  0.2150, -0.1488,  0.1207,  0.0614,  0.0893,  0.1439,\n",
      "          -0.0312,  0.0298, -0.2069,  0.0815,  0.1640,  0.0849,  0.2139,\n",
      "          -0.0163,  0.2212, -0.0794,  0.1193, -0.0124, -0.1160, -0.0160,\n",
      "          -0.0569,  0.0960, -0.1592,  0.0994,  0.0890, -0.2090, -0.2574,\n",
      "          -0.0178,  0.1531,  0.1101,  0.0075,  0.0245,  0.1245, -0.0091,\n",
      "           0.0068,  0.1660,  0.1017,  0.0867, -0.1263,  0.0104,  0.0884,\n",
      "          -0.0698,  0.2321, -0.1710, -0.0889, -0.0331,  0.0725, -0.1346,\n",
      "          -0.0174,  0.1357, -0.1252, -0.0433,  0.0910,  0.1490, -0.1416,\n",
      "           0.1352,  0.0274, -0.0922, -0.0547, -0.0242, -0.1069,  0.0833,\n",
      "          -0.0047,  0.2804, -0.0120, -0.0020, -0.0617, -0.0528, -0.1544,\n",
      "           0.1251,  0.1206,  0.0017, -0.0626,  0.1623, -0.1552, -0.0282,\n",
      "           0.2471,  0.1437, -0.0205,  0.1772, -0.1483, -0.1617,  0.2181,\n",
      "          -0.0939, -0.0050,  0.0981,  0.0921, -0.0303,  0.0837, -0.1196,\n",
      "           0.1690,  0.1049, -0.1255,  0.0205, -0.0687,  0.0454,  0.0353,\n",
      "          -0.0853, -0.0846, -0.1744, -0.1610,  0.0724,  0.1598, -0.0164,\n",
      "          -0.0445,  0.0280,  0.0039, -0.0078,  0.0638,  0.0851, -0.0760,\n",
      "           0.0089, -0.0952, -0.1815, -0.0711, -0.0698,  0.1007, -0.0064,\n",
      "           0.0902,  0.0369, -0.0201,  0.3000,  0.1561,  0.0509,  0.1289,\n",
      "           0.0472, -0.0980, -0.2026,  0.0144, -0.2272, -0.2348, -0.0981,\n",
      "           0.0185, -0.0379, -0.1228, -0.0412,  0.0446, -0.2452,  0.1040,\n",
      "           0.1162, -0.0717, -0.0101,  0.0977,  0.0106, -0.2184,  0.2273,\n",
      "          -0.0022,  0.1225, -0.2733,  0.0605,  0.2760,  0.0951,  0.0969,\n",
      "           0.1332, -0.0226, -0.0351,  0.0922,  0.0701,  0.1822,  0.2044,\n",
      "          -0.0386,  0.0270,  0.0422,  0.0361, -0.0110, -0.1885, -0.1169,\n",
      "           0.1545,  0.0391, -0.1909, -0.1347, -0.3587,  0.3706, -0.0332,\n",
      "          -0.0588, -0.1448,  0.0018,  0.1810,  0.4077, -0.0304,  0.0196,\n",
      "           0.0715, -0.0678,  0.0095, -0.0733,  0.0137,  0.0163,  0.2659,\n",
      "          -0.0483, -0.0454, -0.0321,  0.0452, -0.0799,  0.0353, -0.0283,\n",
      "          -0.1847, -0.1045,  0.1070,  0.0419]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7261e-01, -4.3091e-01,  3.1520e-01, -1.0851e+00, -1.1728e+00,\n",
      "           7.4164e-01, -1.9147e+00,  1.3514e+00,  1.9013e-01,  6.1734e-01,\n",
      "           0.0000e+00,  6.0259e-01,  0.0000e+00, -9.1668e-01, -3.1838e+00,\n",
      "          -6.8265e-02, -1.6337e+00, -9.4356e-01,  1.3604e+00, -1.4358e+00,\n",
      "          -1.4045e-01, -5.2457e-01,  0.0000e+00, -2.5959e+00, -7.5895e-02,\n",
      "           1.3919e+00, -6.1993e-01,  1.9981e+00,  1.2778e-01,  5.5511e-01,\n",
      "           9.1599e-01, -3.7498e-03,  0.0000e+00,  0.0000e+00, -6.3666e-02,\n",
      "          -1.4087e+00, -1.1165e-01, -8.1750e-01,  3.1538e-01,  8.6077e-02,\n",
      "           8.6343e-01, -8.9930e-01,  1.0090e+00, -1.5641e+00,  1.9450e+00,\n",
      "          -3.0046e-01,  7.0643e-01, -6.0230e-01, -1.0211e+00,  1.1173e+00,\n",
      "           0.0000e+00,  2.6783e+00,  6.6703e-01,  0.0000e+00,  2.2805e-01,\n",
      "          -3.1016e-01, -1.4340e+00, -9.6218e-02,  1.2761e+00,  2.1823e+00,\n",
      "          -1.0066e+00,  3.5884e-02, -2.8022e-01,  2.6580e-01, -6.3184e-02,\n",
      "           3.9361e-01,  5.7815e-01,  1.1654e+00,  1.5811e+00, -1.4155e+00,\n",
      "           4.2740e-01,  2.9643e-01, -3.1095e-02, -7.9827e-01,  0.0000e+00,\n",
      "           1.3946e-01,  5.2603e-01,  1.3991e+00,  1.0275e+00, -7.9422e-01,\n",
      "           7.5848e-01, -1.0048e+00,  7.5836e-01,  1.0588e+00,  0.0000e+00,\n",
      "          -1.1328e-01, -1.1083e+00,  0.0000e+00, -9.4498e-01, -1.9015e+00,\n",
      "           5.2915e-01,  9.8742e-01,  1.7022e+00,  9.4430e-01,  6.0798e-01,\n",
      "          -1.5891e-02,  3.5433e-01, -1.1761e+00,  1.3725e+00,  2.4482e+00,\n",
      "           2.4345e-01,  4.4127e-02, -4.6665e-01,  0.0000e+00,  1.6411e+00,\n",
      "          -1.0241e+00,  3.0301e+00,  6.2071e-01, -1.0197e-01, -1.2356e+00,\n",
      "           1.9001e-01, -5.0333e-01, -5.7114e-01,  7.1256e-01, -7.8088e-01,\n",
      "           6.3263e-01,  0.0000e+00,  2.2350e-01, -2.3273e+00,  2.9285e-02,\n",
      "          -8.1486e-01, -1.4121e+00,  0.0000e+00,  6.0320e-01, -9.5715e-01,\n",
      "          -2.0101e-01,  4.0227e-02,  2.1509e+00,  1.3966e+00, -2.0884e+00,\n",
      "          -9.2622e-01,  4.4992e-01, -1.1683e+00,  4.2550e-01, -4.6831e-01,\n",
      "          -7.4628e-01, -1.0650e+00,  0.0000e+00, -1.9390e-02,  2.3980e+00,\n",
      "           6.9863e-01, -1.1219e+00,  1.6919e+00, -1.4046e-01,  0.0000e+00,\n",
      "           3.3254e-02,  0.0000e+00,  4.2287e-01,  0.0000e+00, -9.5287e-02,\n",
      "           1.5602e+00,  5.8677e-01, -3.3842e-01,  6.5775e-01,  1.8417e+00,\n",
      "           0.0000e+00, -2.1790e-01,  6.2397e-01, -2.3639e+00,  1.0561e+00,\n",
      "           3.0286e-01, -7.7173e-02,  1.5527e-01, -1.2124e+00, -2.2040e-02,\n",
      "           1.6826e+00,  1.8528e+00,  2.7168e-01, -1.2705e+00, -7.1308e-01,\n",
      "           0.0000e+00, -1.0944e+00, -2.5913e+00,  0.0000e+00, -3.0609e+00,\n",
      "          -2.8747e-01,  4.9759e-01,  8.2977e-01,  3.1706e-01, -7.9308e-01,\n",
      "           2.7253e-01,  2.3401e+00,  1.0582e+00,  8.3897e-01, -4.0245e-01,\n",
      "           7.2797e-01,  5.9863e-01,  3.5981e-01,  8.4322e-01, -1.8312e+00,\n",
      "           1.3638e+00,  2.1600e+00,  3.3588e-01, -1.0158e+00, -1.1731e+00,\n",
      "          -2.2161e+00,  1.6678e+00,  2.1533e+00,  3.6347e-01,  2.3838e+00,\n",
      "           3.2564e-02, -5.0174e-01, -1.2772e+00, -5.4306e-01, -4.0770e-01,\n",
      "          -1.4477e+00,  9.5332e-01, -8.5205e-01,  8.2955e-01, -1.5606e+00,\n",
      "           6.3732e-01,  6.7558e-01,  2.3988e+00,  5.5342e-02,  1.8938e+00,\n",
      "           1.3091e+00,  5.8020e-01, -2.3179e+00,  1.5503e+00, -2.2252e-01,\n",
      "          -2.2733e-01,  1.7342e+00,  2.7654e-01, -1.5524e+00,  9.2282e-01,\n",
      "          -1.2244e+00, -8.4890e-01, -1.8026e+00, -7.4729e-04,  3.7316e-01,\n",
      "          -1.5740e+00, -1.2389e-01,  9.6643e-01, -1.7374e+00,  1.6948e+00,\n",
      "          -1.4405e+00,  6.3405e-01, -1.7229e+00,  9.8031e-01, -1.7170e+00,\n",
      "           1.5617e+00, -2.7291e-01, -2.5975e+00,  1.2392e+00, -1.2283e+00,\n",
      "           1.8866e+00, -5.0844e-01,  0.0000e+00, -2.6130e-01, -1.0224e+00,\n",
      "           1.3339e+00,  3.1133e-01, -5.1036e-02, -2.2874e-01, -1.6131e+00,\n",
      "           1.8072e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0480, 0.1172, 0.1388, 0.0908, 0.1589, 0.0969, 0.1314, 0.0692, 0.0934,\n",
      "         0.0553]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1493, -0.2362, -0.0162,  ...,  0.2950,  0.3450,  0.1578],\n",
      "        [-0.2273,  0.1859, -0.2438,  ...,  0.0192, -0.0410,  0.0612],\n",
      "        [ 0.0351,  0.6079, -0.2740,  ..., -0.4105,  0.0137, -0.0738],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1495,  0.2448, -0.1594,  0.0993,  0.0704, -0.1666, -0.0958,\n",
      "           0.0101, -0.0421,  0.0771,  0.1480, -0.0991,  0.0394,  0.1444,\n",
      "           0.1563, -0.0840, -0.0918, -0.0638, -0.1389,  0.1994, -0.1349,\n",
      "           0.0162,  0.1868, -0.0998,  0.0986,  0.0777, -0.0589, -0.1419,\n",
      "          -0.0815, -0.1699,  0.1469, -0.2392, -0.2872, -0.1698,  0.0714,\n",
      "          -0.0181, -0.1121, -0.1294, -0.0333,  0.1643,  0.2155,  0.0279,\n",
      "          -0.0345, -0.0622,  0.1947,  0.0754,  0.0070,  0.0588, -0.0336,\n",
      "           0.0171,  0.0394, -0.1519, -0.0679, -0.0144,  0.0494, -0.1903,\n",
      "           0.0374,  0.2057, -0.0736,  0.1405,  0.0451,  0.0272,  0.0553,\n",
      "           0.0145, -0.0099, -0.1974,  0.0330,  0.1945,  0.0186,  0.2315,\n",
      "           0.0154,  0.2290, -0.0705,  0.1300, -0.0496, -0.0428,  0.0678,\n",
      "          -0.0102,  0.0761, -0.0724,  0.0639,  0.0777, -0.2506, -0.1932,\n",
      "          -0.0232,  0.1497,  0.1451,  0.0204,  0.0929,  0.1452,  0.0530,\n",
      "          -0.0047,  0.1332,  0.0639,  0.0789, -0.0779,  0.0479,  0.0975,\n",
      "          -0.0211,  0.2695, -0.1621, -0.0141,  0.0224,  0.0643, -0.0902,\n",
      "          -0.0526,  0.1550, -0.0227, -0.0592,  0.1230,  0.1375, -0.1004,\n",
      "           0.1273, -0.0198, -0.1062, -0.0141, -0.0203, -0.1044,  0.0145,\n",
      "          -0.0273,  0.2568, -0.0166, -0.0844, -0.0313, -0.1169, -0.1693,\n",
      "           0.0919,  0.0657,  0.0292, -0.0868,  0.1735, -0.1635, -0.0095,\n",
      "           0.2714,  0.1124, -0.0286,  0.2049, -0.0865, -0.1765,  0.2469,\n",
      "          -0.1281,  0.0557,  0.0296,  0.1180, -0.0131,  0.0603, -0.0821,\n",
      "           0.2144,  0.1342, -0.0704, -0.0904, -0.0157,  0.0331,  0.0920,\n",
      "          -0.0104,  0.0185, -0.1525, -0.1018,  0.0555,  0.1129, -0.0644,\n",
      "          -0.0737, -0.0699,  0.0943, -0.0321,  0.0712,  0.0206, -0.0892,\n",
      "           0.0279, -0.0747, -0.2112, -0.0477, -0.0339,  0.1087, -0.0439,\n",
      "           0.0148,  0.0054,  0.0086,  0.3233,  0.0918, -0.0228,  0.0815,\n",
      "          -0.0073, -0.1026, -0.1069,  0.0234, -0.2183, -0.1958, -0.0969,\n",
      "          -0.0237, -0.0264, -0.0999, -0.1010,  0.0141, -0.2293,  0.0286,\n",
      "           0.1034, -0.0420, -0.0676,  0.0824,  0.0093, -0.1572,  0.1735,\n",
      "           0.0412,  0.1140, -0.2835,  0.0534,  0.2930,  0.0777,  0.0169,\n",
      "           0.0752, -0.0654, -0.0334,  0.1082,  0.0453,  0.1872,  0.1871,\n",
      "           0.0052, -0.0222,  0.0384,  0.0914, -0.0381, -0.1244, -0.1071,\n",
      "           0.1566,  0.0804, -0.1378, -0.1881, -0.3750,  0.3566, -0.0476,\n",
      "          -0.0850, -0.1652, -0.0347,  0.1445,  0.3494, -0.0812,  0.0117,\n",
      "           0.1504, -0.0237, -0.0026, -0.1017,  0.0101,  0.0425,  0.2570,\n",
      "          -0.0630, -0.0757, -0.0551,  0.0585, -0.1044,  0.0655, -0.0127,\n",
      "          -0.1874, -0.1354,  0.1464,  0.0385]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5870e-02,  3.9895e-01, -9.6686e-01, -6.8183e-01,  3.7641e-01,\n",
      "          -2.0184e-01,  1.4649e+00, -8.3292e-02, -3.5851e+00,  9.0678e-01,\n",
      "           4.2893e-01, -6.2921e-01,  2.6056e+00, -6.2976e-01, -5.4164e-01,\n",
      "          -1.5796e-01,  8.5162e-01,  1.0951e+00,  4.5519e-01,  4.3609e-01,\n",
      "          -6.3376e-01, -3.8358e-01,  1.6420e+00,  1.5115e+00,  7.5379e-01,\n",
      "          -7.5288e-02, -1.8775e-01, -7.5914e-01,  1.6541e+00,  8.6166e-01,\n",
      "           1.2321e+00,  1.2192e+00, -1.0345e+00, -8.2645e-02, -1.5350e+00,\n",
      "           0.0000e+00,  2.8082e-01, -3.7458e+00,  1.9812e-01,  1.6014e+00,\n",
      "          -4.5886e-01, -1.3987e+00, -2.6839e-01,  0.0000e+00, -1.5249e+00,\n",
      "           6.6734e-01,  5.4102e-01,  3.7022e-01, -1.3410e+00,  1.4390e-01,\n",
      "          -6.2895e-01,  2.7532e+00,  6.1050e-01, -1.0296e+00, -2.5667e-02,\n",
      "           0.0000e+00, -8.8235e-01, -1.2531e+00, -2.3663e-01, -4.2523e-01,\n",
      "           1.1012e+00,  0.0000e+00, -2.0366e-01, -5.0192e-01, -2.9651e+00,\n",
      "           5.5056e-01,  0.0000e+00, -1.2883e+00,  4.1165e-01,  5.2647e-01,\n",
      "          -1.2675e+00, -3.0446e-02,  7.0748e-01, -3.6423e+00,  3.2637e-01,\n",
      "          -2.2203e-03, -1.5980e-01,  1.0631e+00, -5.8325e-02,  0.0000e+00,\n",
      "          -1.4005e+00,  2.1320e+00,  0.0000e+00,  1.0058e+00, -2.0790e-01,\n",
      "           4.3452e-01,  1.6619e+00, -9.7482e-01, -1.0326e-01, -5.8159e-01,\n",
      "           0.0000e+00,  1.1005e+00, -6.2231e-01,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  3.4314e-02,  6.2931e-01,  1.7206e+00,  0.0000e+00,\n",
      "           2.6978e+00, -1.4630e+00,  1.0761e+00,  1.4545e+00, -6.6647e-01,\n",
      "           0.0000e+00,  1.2128e+00,  0.0000e+00, -1.4731e+00, -1.3097e-02,\n",
      "          -2.4895e-01,  1.3450e-01, -1.0488e+00,  1.3103e+00, -1.6539e+00,\n",
      "          -2.9905e+00, -5.6319e-02, -5.0144e-01, -1.9323e-01,  4.4479e-01,\n",
      "          -1.4671e+00,  0.0000e+00, -1.4609e+00, -7.2639e-01, -9.5883e-01,\n",
      "          -1.3094e+00,  8.9772e-01,  1.7042e-01,  1.2858e+00,  0.0000e+00,\n",
      "          -8.2324e-01,  5.2980e-01, -1.5836e+00,  9.8423e-01,  2.7619e-01,\n",
      "          -5.8961e-01,  6.5999e-01,  5.7351e-01, -1.1585e+00, -1.0106e+00,\n",
      "          -3.8898e-01,  6.7785e-01, -7.9009e-01, -1.0168e-01, -1.6864e+00,\n",
      "           0.0000e+00, -5.4333e-01, -8.4460e-01, -7.5559e-01,  1.7739e-01,\n",
      "           1.9992e+00, -1.9981e-01, -1.9311e+00,  0.0000e+00,  4.4158e-01,\n",
      "          -1.9449e-01, -6.4203e-02, -1.2905e-01,  3.9414e-02,  5.3768e-01,\n",
      "          -2.6152e-02,  2.2068e+00,  4.8118e-01,  0.0000e+00, -5.2742e-01,\n",
      "          -8.9297e-01,  2.8178e-01,  8.4522e-02, -3.5798e-01, -4.7811e-01,\n",
      "           7.3813e-01, -3.2405e-02,  1.9898e-02, -1.0020e+00,  1.2779e+00,\n",
      "          -1.0992e+00, -9.8787e-01, -2.0778e+00,  1.9697e+00,  8.6421e-02,\n",
      "          -2.9832e-02,  3.5062e-02,  6.7168e-01,  9.7988e-01, -7.4711e-01,\n",
      "          -3.4094e-01, -2.7840e+00, -7.8469e-01,  1.2100e+00,  1.0125e+00,\n",
      "           3.0752e+00,  4.9447e-01, -1.4415e-01, -5.9469e-01,  5.6083e-01,\n",
      "           2.1658e+00, -1.1883e+00,  5.3479e-01,  1.8123e+00, -9.4757e-01,\n",
      "           0.0000e+00, -1.0151e+00,  1.2418e+00, -1.2218e-01,  2.3193e-01,\n",
      "          -5.7542e-01, -2.2934e+00,  6.8196e-01, -1.0748e+00, -4.7140e-01,\n",
      "           2.8688e+00, -5.7329e-01, -3.4119e-01,  7.9332e-01,  2.9940e-02,\n",
      "          -6.8489e-01, -1.0197e+00,  9.6633e-01,  0.0000e+00,  2.1701e+00,\n",
      "          -1.0830e+00, -4.2765e-01, -1.8442e+00, -5.0155e-01,  3.3729e-01,\n",
      "           7.0483e-01, -6.9661e-01, -6.2811e-01,  2.9224e-01, -1.5790e+00,\n",
      "          -1.1089e+00,  1.5817e+00, -6.1433e-01,  1.3098e+00, -2.9804e+00,\n",
      "           4.0366e+00,  5.8521e-01,  4.3477e-02, -1.5807e+00, -2.8753e-01,\n",
      "           7.4162e-01,  0.0000e+00, -3.0467e-01, -8.5262e-01,  1.1102e-02,\n",
      "           2.7536e-01,  0.0000e+00,  2.5267e-01,  2.6095e-01,  3.8669e-01,\n",
      "          -3.6566e-01, -1.5845e-01, -5.5417e-01,  0.0000e+00, -1.1473e+00,\n",
      "          -1.1316e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0355, 0.0508, 0.0817, 0.0547, 0.1368, 0.3583, 0.0635, 0.0716, 0.0496,\n",
      "         0.0975]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2887, -0.5092,  0.3514,  ...,  0.0054, -0.0189,  0.1247],\n",
      "        [-0.0463, -0.5531,  0.4880,  ..., -0.4019,  0.0023, -0.2296],\n",
      "        [-0.1100, -0.3312,  0.1285,  ..., -0.0108, -0.2698, -0.5469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3341,  0.0622, -0.2674,  0.1416, -0.2458, -0.1168,  0.1329,\n",
      "          -0.2410, -0.1035, -0.0661,  0.1912, -0.1652, -0.1932,  0.0145,\n",
      "           0.3049, -0.0804,  0.0650,  0.2336, -0.2874,  0.0685, -0.1882,\n",
      "          -0.3060,  0.2492,  0.1853, -0.2831, -0.1600, -0.0682, -0.3829,\n",
      "          -0.1285, -0.0683,  0.1311, -0.0983, -0.3102, -0.2174, -0.0145,\n",
      "           0.0553, -0.1188, -0.0938, -0.1581,  0.0737,  0.0211,  0.1038,\n",
      "          -0.4194,  0.0704,  0.2081,  0.2470, -0.2325, -0.1765,  0.0541,\n",
      "          -0.1512, -0.2481, -0.0221, -0.3072, -0.0631,  0.1318,  0.0326,\n",
      "           0.0374,  0.1265,  0.2990,  0.2338, -0.1378, -0.1553, -0.2620,\n",
      "           0.1497, -0.1886, -0.0042, -0.1337,  0.2648, -0.1018,  0.0859,\n",
      "           0.0839,  0.3031, -0.1642,  0.3003, -0.2204,  0.0650,  0.2096,\n",
      "           0.3124,  0.1417,  0.2210, -0.0693, -0.2787, -0.2415,  0.0361,\n",
      "          -0.0840,  0.2336,  0.1628,  0.0609,  0.3259, -0.0583,  0.1038,\n",
      "          -0.0112, -0.0957,  0.0811, -0.1892,  0.1939,  0.1104,  0.2835,\n",
      "          -0.0339,  0.3560, -0.3099,  0.2470,  0.2432,  0.0400, -0.1811,\n",
      "           0.0021,  0.0641,  0.2589, -0.2234,  0.1141,  0.1223,  0.0527,\n",
      "          -0.0717, -0.3072, -0.2818,  0.0308,  0.0410, -0.1287, -0.1444,\n",
      "          -0.0812,  0.1240, -0.3298, -0.2215,  0.0843, -0.2602, -0.1721,\n",
      "           0.0190, -0.1581,  0.0988, -0.1244,  0.2157, -0.1528,  0.1771,\n",
      "           0.2230, -0.1791, -0.0045,  0.3298,  0.0810, -0.2716,  0.1551,\n",
      "          -0.1573,  0.2453, -0.1667,  0.0908,  0.1589, -0.0897, -0.0699,\n",
      "           0.2788,  0.0997,  0.1638, -0.4096,  0.1638, -0.1440,  0.2720,\n",
      "           0.0469,  0.4085, -0.1885,  0.1341,  0.1676, -0.0894, -0.0439,\n",
      "          -0.2462, -0.2293,  0.3244, -0.0169,  0.1382, -0.0803, -0.1264,\n",
      "           0.3192,  0.3755, -0.1201,  0.1026,  0.3285, -0.0096, -0.2008,\n",
      "          -0.2361, -0.0748,  0.1482,  0.3531, -0.0122, -0.3370, -0.2082,\n",
      "          -0.1950,  0.0320,  0.3090,  0.1507, -0.2830,  0.2229,  0.0903,\n",
      "          -0.2385, -0.1252,  0.2882, -0.3329, -0.2327, -0.1441, -0.4078,\n",
      "          -0.2198, -0.0160, -0.3577,  0.1410,  0.0881,  0.0999,  0.0121,\n",
      "           0.2452, -0.0722, -0.2611, -0.0831,  0.3087, -0.0529, -0.1278,\n",
      "           0.1360, -0.1742, -0.0710,  0.4034, -0.2493,  0.1991, -0.1272,\n",
      "           0.0506, -0.1221,  0.3372,  0.2233, -0.2811,  0.1556,  0.1248,\n",
      "           0.1127,  0.3707,  0.0640, -0.2753, -0.3840,  0.3359, -0.3866,\n",
      "           0.0031, -0.0861, -0.2327, -0.1299, -0.0198, -0.1772, -0.0718,\n",
      "           0.2609,  0.1543, -0.2678, -0.1256, -0.1984, -0.0450,  0.1563,\n",
      "          -0.1624, -0.1687, -0.1830,  0.0921,  0.0372,  0.1693,  0.1991,\n",
      "          -0.2555, -0.1720, -0.0463, -0.0579]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1548, -1.4817,  1.6542, -1.0095, -1.1129,  0.4006,  0.6460,\n",
      "           0.0000, -0.9022,  0.0941,  0.0000,  0.3159,  0.0000, -0.9577,\n",
      "          -0.3086,  0.3245, -1.8654, -2.1363,  0.6083, -0.5293,  0.0000,\n",
      "           0.2829, -1.2569, -0.9729,  1.1924,  0.0000, -1.6559,  1.0545,\n",
      "           0.9845, -1.2884,  0.3067, -0.9454, -0.7690, -1.5226, -0.3682,\n",
      "           0.4840, -0.9886, -0.3511,  0.0000,  0.6281,  0.6073, -1.1766,\n",
      "           0.3727,  1.2539, -1.7953,  1.9479,  0.0000, -0.4428, -0.2787,\n",
      "           1.1463,  0.8649,  0.0363, -0.0721, -1.0043, -0.2961, -0.8050,\n",
      "          -1.8693,  0.5099,  1.5729,  2.0577, -0.8820,  0.0000,  1.9471,\n",
      "          -0.9061, -0.8593,  0.1078,  0.6388, -0.6173,  0.0210,  0.4296,\n",
      "          -1.5894, -0.0282, -0.6441,  1.4257, -0.4461,  0.5578,  0.0000,\n",
      "          -0.6177, -1.4065, -0.3109,  0.8705,  1.3122,  0.8811, -0.9603,\n",
      "           0.6943,  0.6933,  0.0000, -2.9898,  0.8148, -0.0185, -1.4907,\n",
      "           0.3248, -1.2889,  2.3924,  1.8842,  0.2150, -1.1101,  1.0775,\n",
      "           1.5508, -2.1247,  0.0145, -0.6639, -1.1344, -1.8825,  0.4070,\n",
      "           1.4167, -1.9888, -0.9153,  0.4129,  1.8164, -1.4324,  0.1791,\n",
      "          -0.4975,  1.3002, -0.1466, -0.1100,  0.3374, -1.6427,  0.8516,\n",
      "           0.0000, -1.3461, -0.0995,  0.8783,  0.5349,  0.2247,  0.8190,\n",
      "          -0.2026, -1.0699,  0.1246, -0.4277,  0.0000,  2.3284,  1.4193,\n",
      "           0.3274, -0.0091, -0.6385, -0.0636, -0.5997, -0.4515,  1.0985,\n",
      "           0.5455,  0.0000, -2.2950, -0.8858,  0.2164, -0.1879,  0.9174,\n",
      "          -0.0828,  1.5432, -0.7185,  0.3219, -1.3512,  1.8154, -1.9310,\n",
      "           0.0000, -0.3340, -0.2287, -0.7580,  0.0000, -0.0180,  0.2298,\n",
      "          -1.1455,  2.2616, -1.7647, -0.3901, -0.6921,  0.5299,  2.1357,\n",
      "           0.0000, -2.7422,  1.2540, -2.0854, -0.0061, -1.1599, -0.9214,\n",
      "          -0.7985, -0.3065, -0.4305,  0.1180, -1.5137,  0.1504, -0.4530,\n",
      "           0.1993,  0.9701,  0.4840, -0.0758,  0.0000, -0.2142,  0.4035,\n",
      "          -1.4625,  1.0714,  0.6061,  0.5036,  0.0000,  0.0000, -0.0429,\n",
      "           1.8720,  0.0426, -0.8384,  0.0000,  0.1191, -0.2977,  0.2828,\n",
      "           0.3538, -0.0091, -0.7146,  0.6959,  0.0000,  0.0000,  1.8921,\n",
      "           2.7895,  0.1561,  1.5049,  0.1013, -0.5909, -0.0224, -0.1426,\n",
      "          -1.3820,  0.4084,  0.6377, -0.6885,  1.8592,  0.6066,  0.0000,\n",
      "           0.0291,  1.5296, -0.3650, -0.2609,  0.8418, -0.2543,  0.0000,\n",
      "          -0.5516,  1.2382,  0.0929,  2.0767,  0.5542, -1.7045,  2.7784,\n",
      "           0.0000,  1.8028, -0.8494,  0.2568, -1.0498, -0.8537,  0.1357,\n",
      "          -1.7792,  0.0000,  1.9828,  0.0000,  0.5471, -1.7499,  0.3683,\n",
      "           0.1556,  0.0000, -2.7258,  0.4071]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0317, 0.1219, 0.1205, 0.0614, 0.1497, 0.2423, 0.0665, 0.0572, 0.0785,\n",
      "         0.0704]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2887, -0.5092,  0.3514,  ...,  0.0054, -0.0189,  0.1247],\n",
      "        [-0.0463, -0.5531,  0.4880,  ..., -0.4019,  0.0023, -0.2296],\n",
      "        [-0.1100, -0.3312,  0.1285,  ..., -0.0108, -0.2698, -0.5469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.4882e-01, -4.4125e-02, -1.5177e-01,  1.6793e-01, -1.5462e-01,\n",
      "           9.4046e-03,  1.1816e-01, -1.6707e-01, -1.0124e-01, -7.5141e-03,\n",
      "           1.7556e-01, -1.0991e-01, -1.1909e-01, -1.0925e-02,  2.6113e-01,\n",
      "          -4.8923e-02,  2.8395e-02,  2.3467e-01, -1.9247e-01,  3.6133e-02,\n",
      "          -1.8254e-01, -2.6078e-01,  2.2298e-01,  1.4039e-01, -2.1139e-01,\n",
      "          -6.3284e-02, -5.8350e-02, -3.7454e-01, -6.3950e-02, -6.8564e-02,\n",
      "           8.2221e-02, -9.8729e-03, -2.7941e-01, -1.6867e-01, -5.5879e-02,\n",
      "           4.2836e-02, -6.1258e-02, -5.7057e-02, -5.1127e-02,  5.1522e-02,\n",
      "           6.8086e-02,  1.2226e-01, -3.9715e-01,  5.3251e-02,  1.5180e-01,\n",
      "           2.2188e-01, -1.8204e-01, -8.8259e-02,  1.0705e-03, -1.6524e-01,\n",
      "          -2.1476e-01, -2.8494e-02, -2.4806e-01, -5.2222e-02,  1.7961e-01,\n",
      "           4.4902e-02,  5.6808e-02,  7.0444e-02,  2.7487e-01,  1.8235e-01,\n",
      "          -1.0787e-01, -1.5727e-01, -1.7880e-01,  1.3374e-01, -1.6470e-01,\n",
      "           6.0913e-03, -8.3229e-02,  2.3636e-01, -4.2044e-02,  9.8777e-02,\n",
      "           5.8645e-02,  2.8277e-01, -1.8395e-01,  2.4633e-01, -1.5132e-01,\n",
      "           7.2768e-02,  1.5936e-01,  2.8647e-01,  1.9282e-01,  1.8346e-01,\n",
      "           1.3204e-03, -1.6108e-01, -1.1858e-01,  1.2645e-02, -2.1798e-03,\n",
      "           2.1799e-01,  1.8033e-01,  6.9157e-02,  2.7657e-01, -1.9924e-02,\n",
      "           3.4568e-02, -3.3573e-02, -1.4147e-01,  1.1635e-01, -2.1341e-01,\n",
      "           2.0735e-01,  6.7694e-02,  2.2111e-01,  9.7736e-03,  2.9001e-01,\n",
      "          -2.5806e-01,  2.3146e-01,  2.0178e-01, -1.6477e-02, -1.2985e-01,\n",
      "           3.9003e-02, -1.8264e-02,  1.8691e-01, -2.0976e-01,  6.3231e-02,\n",
      "           8.8546e-02,  8.9202e-02, -1.3864e-01, -2.4368e-01, -2.2418e-01,\n",
      "           8.3635e-03,  4.8268e-02, -1.0682e-01, -1.2308e-01, -5.0730e-02,\n",
      "           8.8986e-02, -2.8394e-01, -1.3183e-01,  7.2888e-02, -2.3998e-01,\n",
      "          -1.6076e-01,  3.4355e-03, -1.3591e-01,  2.5536e-02, -5.4147e-02,\n",
      "           1.6893e-01, -6.4189e-03,  9.1424e-02,  1.8197e-01, -1.3080e-01,\n",
      "          -9.0954e-02,  2.4813e-01,  7.4212e-02, -2.0807e-01,  1.1612e-01,\n",
      "          -1.4362e-01,  1.6309e-01, -1.3032e-01,  1.8658e-02,  1.3052e-01,\n",
      "          -7.1765e-02, -7.7913e-02,  2.1341e-01,  7.4701e-02,  5.9246e-02,\n",
      "          -3.0619e-01,  1.6324e-01, -1.2453e-01,  2.3223e-01,  2.9190e-02,\n",
      "           3.4484e-01, -1.7914e-01,  1.2202e-01,  8.6482e-02,  2.8492e-02,\n",
      "           3.8201e-02, -1.8752e-01, -1.2984e-01,  2.3699e-01, -6.3307e-02,\n",
      "           9.2343e-02, -4.2426e-02, -4.9029e-02,  2.6810e-01,  3.0787e-01,\n",
      "          -3.7219e-02,  1.1918e-01,  2.7180e-01,  3.6695e-03, -1.4966e-01,\n",
      "          -1.5676e-01, -3.4345e-02,  1.0847e-01,  2.5060e-01,  5.6031e-02,\n",
      "          -3.5221e-01, -1.7303e-01, -1.1684e-01,  2.6966e-02,  2.4832e-01,\n",
      "           1.2328e-01, -1.4806e-01,  1.3549e-01, -3.7773e-03, -1.6026e-01,\n",
      "          -1.0110e-01,  2.5257e-01, -2.6583e-01, -2.0979e-01, -2.2102e-01,\n",
      "          -4.2013e-01, -2.0438e-01, -2.0764e-04, -3.3692e-01,  7.2876e-02,\n",
      "           1.3023e-01,  2.8430e-02,  7.0434e-02,  1.5021e-01, -1.2652e-01,\n",
      "          -2.2743e-01, -7.2356e-02,  2.4365e-01, -2.1967e-02, -1.1013e-01,\n",
      "           1.1266e-01, -1.0387e-01, -4.5587e-02,  3.8917e-01, -2.1850e-01,\n",
      "           1.3381e-01, -2.3321e-02,  1.1210e-02, -7.1240e-02,  3.1292e-01,\n",
      "           1.4585e-01, -2.3245e-01,  8.1428e-02,  1.8078e-01,  6.7988e-02,\n",
      "           3.5011e-01, -5.6237e-02, -2.3636e-01, -3.0801e-01,  2.7332e-01,\n",
      "          -3.0395e-01,  6.6024e-02, -3.1824e-02, -1.2054e-01, -1.0151e-01,\n",
      "          -1.7597e-02, -1.2747e-01, -7.5367e-02,  2.0746e-01,  1.6520e-01,\n",
      "          -2.2246e-01, -1.2953e-01, -1.5355e-01, -5.4687e-02,  1.2109e-01,\n",
      "          -1.5582e-01, -1.2504e-01, -1.1635e-01,  5.6646e-02, -3.8668e-02,\n",
      "           1.1243e-01,  2.4445e-01, -2.1554e-01, -1.6484e-01, -4.7525e-02,\n",
      "          -1.1052e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.0000, -1.6520, -0.1829, -0.7320,  2.5181, -1.9079,\n",
      "          -0.0324,  0.9500,  1.1945,  1.4104, -0.7569, -0.0649,  0.0644,\n",
      "           0.0000,  1.8851,  0.0000, -0.7847, -0.6402, -1.4035, -0.4985,\n",
      "          -0.3791,  1.1427,  0.2328,  0.1892, -0.6129,  1.4041, -0.1509,\n",
      "          -1.0408,  0.4962, -0.5711,  0.6009, -1.6988,  0.2319, -0.0796,\n",
      "           0.1483,  0.6451, -2.2133,  1.0518,  0.0000, -0.6919, -0.4365,\n",
      "           0.0000,  0.8179, -0.6327, -0.6564,  0.0000,  0.9366,  1.6035,\n",
      "           0.3694, -1.0082, -1.1719, -1.1123,  0.0000, -1.9747,  1.7089,\n",
      "           0.5930, -1.8923,  0.3415, -0.2937, -0.7703,  1.8692, -0.5940,\n",
      "          -1.6816, -0.8356,  0.0000, -0.3574,  0.2898, -0.7527, -1.1647,\n",
      "           2.2476,  0.7806,  0.2705,  1.2049, -0.3982,  0.3548,  0.2296,\n",
      "          -0.1574, -0.9149,  0.2958, -0.1448,  1.2866,  0.4653,  1.2969,\n",
      "           0.7705,  0.6606,  1.0454, -0.3682,  0.0000, -1.4364,  1.3105,\n",
      "          -1.5853, -0.1110,  3.2390,  0.3469,  1.0035, -0.8684,  0.7312,\n",
      "          -1.6814, -0.9243,  0.1907,  0.0285, -0.5964,  1.0586, -0.2308,\n",
      "           0.7758, -0.9058, -0.3677, -0.2786, -0.5476, -0.1379, -3.2782,\n",
      "          -0.1011, -1.8785,  1.6978,  1.6883,  2.0296, -1.6460, -0.8961,\n",
      "           2.5844, -1.3264,  1.4236, -0.6276,  0.4668,  1.3156,  0.0000,\n",
      "           0.0738, -0.9854, -0.6749,  0.2475, -1.2006,  0.0000,  1.1404,\n",
      "           1.4885,  0.3789,  0.6465, -0.8378,  0.2414,  0.0000, -1.2618,\n",
      "           0.0304,  0.8640,  0.5015,  0.9070, -1.2682, -0.6409, -0.4416,\n",
      "           0.8728, -0.0676,  0.0424, -0.0565,  0.6208,  0.1451, -0.1962,\n",
      "           0.0000, -1.6721, -0.4025,  0.2513, -2.0698,  0.4119,  1.1555,\n",
      "           0.1997,  0.9131,  0.8436,  0.4175,  1.6038,  0.1772, -1.1142,\n",
      "          -0.3225,  0.2508,  0.4448, -0.4552,  0.4446, -1.3451,  1.7354,\n",
      "           0.5174,  1.1773,  0.2895, -1.8322, -1.8662,  0.2595, -0.6473,\n",
      "          -1.1657,  0.3290, -0.7441,  0.5922, -1.2417,  0.0000, -2.3033,\n",
      "           0.1464, -1.6242, -1.3209, -0.0500,  1.2995,  0.9804, -1.4147,\n",
      "          -1.1402,  3.0138, -0.2258,  1.0329,  0.0292,  0.1192, -1.3196,\n",
      "          -1.0708,  0.0566,  1.7329,  0.5271,  1.9823, -0.9789, -1.3425,\n",
      "           1.5994, -0.4015,  2.4608, -0.5198,  0.7545,  0.2066, -0.8211,\n",
      "           0.0000, -3.5302,  0.1759, -0.7814, -0.6932, -1.4188,  0.2511,\n",
      "          -0.0648, -1.4654,  0.4269, -0.5198,  0.0464,  0.0000, -0.0713,\n",
      "           0.7485, -2.0269, -1.0491, -0.4315, -0.1122,  0.5160, -2.7969,\n",
      "          -1.4578, -0.6646,  1.0259,  0.1327,  2.7509,  0.0000,  0.5472,\n",
      "          -0.1734, -1.5054,  2.2321,  1.1873, -0.0479,  0.7228,  0.1090,\n",
      "           0.0000, -0.0138, -0.8380, -0.5806]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0345, 0.1678, 0.1368, 0.0872, 0.0886, 0.1176, 0.0686, 0.0848, 0.1285,\n",
      "         0.0856]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2887, -0.5092,  0.3514,  ...,  0.0054, -0.0189,  0.1247],\n",
      "        [-0.0463, -0.5531,  0.4880,  ..., -0.4019,  0.0023, -0.2296],\n",
      "        [-0.1100, -0.3312,  0.1285,  ..., -0.0108, -0.2698, -0.5469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2218e-01, -1.3220e-01, -2.0091e-02,  1.9156e-01, -5.9627e-02,\n",
      "           1.2028e-01,  1.0285e-01, -6.4480e-02, -7.5991e-02,  6.3043e-02,\n",
      "           1.3978e-01, -5.4176e-02, -1.6464e-02, -4.5404e-02,  1.7993e-01,\n",
      "          -1.0886e-02,  8.0399e-03,  1.8672e-01, -5.9098e-02,  7.5098e-03,\n",
      "          -1.5985e-01, -1.7610e-01,  1.5820e-01,  9.5289e-02, -1.1887e-01,\n",
      "           1.5422e-02, -6.7178e-02, -3.0877e-01, -5.2841e-03, -7.6661e-02,\n",
      "          -1.1563e-04,  8.4474e-02, -2.1110e-01, -7.9019e-02, -7.7396e-02,\n",
      "           3.3826e-02,  5.7485e-03, -1.7480e-02,  4.9625e-02,  5.7137e-03,\n",
      "           9.4249e-02,  9.8331e-02, -3.2040e-01,  3.2101e-02,  9.5696e-02,\n",
      "           1.5205e-01, -1.0809e-01,  2.0778e-03, -5.9996e-02, -1.4107e-01,\n",
      "          -1.6670e-01, -2.0571e-02, -1.5818e-01, -2.6069e-02,  2.0072e-01,\n",
      "           4.6725e-02,  7.4643e-02,  9.7504e-03,  2.0957e-01,  1.0929e-01,\n",
      "          -7.5504e-02, -1.1529e-01, -6.7227e-02,  8.0247e-02, -1.1200e-01,\n",
      "           1.5086e-02, -2.0128e-02,  1.6535e-01,  4.0617e-02,  7.0521e-02,\n",
      "           8.0890e-03,  2.1394e-01, -1.8039e-01,  1.6206e-01, -6.6399e-02,\n",
      "           3.9672e-02,  6.8862e-02,  2.1635e-01,  2.0978e-01,  1.1101e-01,\n",
      "           6.2630e-02, -5.2203e-02,  2.6780e-02, -1.6121e-02,  7.6408e-02,\n",
      "           1.7167e-01,  1.5784e-01,  5.7999e-02,  1.7594e-01,  1.8971e-03,\n",
      "          -4.3201e-02, -4.7279e-02, -1.4802e-01,  1.4827e-01, -2.0738e-01,\n",
      "           1.7747e-01,  1.0030e-02,  1.3857e-01,  2.2246e-02,  1.8417e-01,\n",
      "          -1.8251e-01,  1.6250e-01,  1.3780e-01, -5.9669e-02, -9.1380e-02,\n",
      "           7.5625e-02, -1.0678e-01,  7.2801e-02, -1.6266e-01, -4.6731e-03,\n",
      "           5.2348e-02,  9.5320e-02, -1.6826e-01, -1.4713e-01, -1.3551e-01,\n",
      "          -2.3392e-02,  4.7497e-02, -6.6624e-02, -8.3215e-02, -1.4294e-02,\n",
      "           5.0289e-02, -2.1164e-01, -1.3503e-02,  4.2720e-02, -1.6553e-01,\n",
      "          -1.2096e-01, -6.8361e-03, -8.7177e-02, -4.4134e-02,  2.5692e-02,\n",
      "           1.0583e-01,  1.2142e-01,  1.0615e-02,  9.3914e-02, -7.0373e-02,\n",
      "          -1.4131e-01,  1.3812e-01,  3.6843e-02, -1.2696e-01,  3.6599e-02,\n",
      "          -9.3713e-02,  5.1620e-02, -6.1800e-02, -4.1629e-02,  9.0752e-02,\n",
      "          -4.4120e-02, -7.7800e-02,  1.0722e-01,  2.7258e-02, -5.4119e-02,\n",
      "          -1.4438e-01,  1.2851e-01, -7.9206e-02,  1.5567e-01, -6.7158e-03,\n",
      "           2.2557e-01, -1.4988e-01,  8.2060e-02,  1.7962e-02,  1.3914e-01,\n",
      "           1.2417e-01, -1.1707e-01, -5.4605e-03,  1.0188e-01, -7.3347e-02,\n",
      "           3.8444e-02,  6.6607e-03,  2.8009e-02,  2.0259e-01,  2.2119e-01,\n",
      "           5.4874e-02,  1.1440e-01,  1.7925e-01, -4.4966e-03, -7.3149e-02,\n",
      "          -4.5334e-02,  4.5270e-03,  5.9724e-02,  1.0949e-01,  1.2256e-01,\n",
      "          -2.9951e-01, -1.1397e-01, -1.9640e-02,  2.1346e-02,  1.4383e-01,\n",
      "           8.8128e-02, -1.9637e-02,  4.2577e-02, -6.5799e-02, -6.4764e-02,\n",
      "          -6.9289e-02,  1.8165e-01, -1.5971e-01, -1.6361e-01, -2.4448e-01,\n",
      "          -3.6295e-01, -1.7379e-01,  1.2386e-02, -2.6379e-01,  1.1714e-02,\n",
      "           1.5081e-01, -4.0092e-02,  1.1355e-01,  4.8152e-02, -1.4783e-01,\n",
      "          -1.5577e-01, -5.4778e-02,  1.3845e-01,  4.8215e-03, -6.0163e-02,\n",
      "           9.8812e-02, -2.3393e-02, -1.4896e-02,  3.1814e-01, -1.5613e-01,\n",
      "           6.1193e-02,  5.1633e-02, -3.4197e-02, -5.4500e-03,  2.5717e-01,\n",
      "           5.0871e-02, -1.5971e-01, -5.6766e-03,  1.9834e-01,  1.8566e-02,\n",
      "           2.7569e-01, -1.4668e-01, -1.5437e-01, -1.7783e-01,  1.8146e-01,\n",
      "          -1.9927e-01,  1.2346e-01,  4.1830e-02,  1.0684e-03, -6.6088e-02,\n",
      "          -1.1083e-02, -5.2358e-02, -6.8892e-02,  1.0203e-01,  1.4470e-01,\n",
      "          -1.4552e-01, -9.9645e-02, -1.0329e-01, -7.1422e-02,  6.5899e-02,\n",
      "          -1.1378e-01, -6.1495e-02, -3.2102e-02,  2.9903e-02, -6.8710e-02,\n",
      "           4.0004e-02,  2.4532e-01, -1.5857e-01, -1.1968e-01, -6.4666e-02,\n",
      "          -1.3487e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7263e-01, -4.3094e-01,  3.1522e-01, -1.0852e+00, -1.1729e+00,\n",
      "           7.4165e-01, -1.9147e+00,  1.3514e+00,  1.9011e-01,  6.1737e-01,\n",
      "           1.9040e+00,  6.0261e-01,  2.2931e-01, -9.1675e-01,  0.0000e+00,\n",
      "          -6.8252e-02,  0.0000e+00, -9.4360e-01,  1.3604e+00, -1.4359e+00,\n",
      "          -1.4044e-01, -5.2466e-01, -1.1199e+00, -2.5960e+00, -7.5912e-02,\n",
      "           1.3920e+00, -6.1997e-01,  0.0000e+00,  1.2781e-01,  5.5522e-01,\n",
      "           9.1611e-01, -3.7591e-03,  2.2217e-01,  2.0172e+00, -6.3673e-02,\n",
      "          -1.4087e+00, -1.1162e-01, -8.1748e-01,  3.1544e-01,  8.6151e-02,\n",
      "           8.6355e-01, -8.9930e-01,  1.0089e+00, -1.5642e+00,  1.9451e+00,\n",
      "          -3.0049e-01,  7.0656e-01,  0.0000e+00, -1.0212e+00,  1.1173e+00,\n",
      "          -1.3233e+00,  2.6785e+00,  6.6708e-01, -8.4712e-01,  2.2809e-01,\n",
      "          -3.1024e-01, -1.4341e+00, -9.6169e-02,  1.2762e+00,  2.1824e+00,\n",
      "          -1.0067e+00,  3.5854e-02, -2.8023e-01,  2.6579e-01, -6.3217e-02,\n",
      "           3.9359e-01,  5.7818e-01,  1.1654e+00,  1.5811e+00, -1.4155e+00,\n",
      "           4.2737e-01,  2.9645e-01, -3.1083e-02, -7.9832e-01, -2.1421e-01,\n",
      "           0.0000e+00,  5.2607e-01,  1.3992e+00,  1.0275e+00, -7.9433e-01,\n",
      "           7.5856e-01, -1.0048e+00,  7.5845e-01,  1.0588e+00, -1.2157e+00,\n",
      "          -1.1331e-01,  0.0000e+00,  5.4869e-01, -9.4503e-01, -1.9015e+00,\n",
      "           5.2916e-01,  9.8749e-01,  1.7022e+00,  9.4440e-01,  6.0797e-01,\n",
      "          -1.5892e-02,  3.5442e-01, -1.1762e+00,  1.3727e+00,  2.4483e+00,\n",
      "           2.4344e-01,  4.4026e-02, -4.6666e-01, -9.8958e-01,  1.6412e+00,\n",
      "          -1.0242e+00,  3.0303e+00,  6.2080e-01, -1.0196e-01, -1.2357e+00,\n",
      "           1.9002e-01, -5.0338e-01, -5.7121e-01,  7.1260e-01, -7.8094e-01,\n",
      "           6.3266e-01,  4.0380e-01,  2.2343e-01, -2.3274e+00,  2.9273e-02,\n",
      "          -8.1498e-01, -1.4123e+00, -1.8388e+00,  6.0320e-01,  0.0000e+00,\n",
      "          -2.0108e-01,  0.0000e+00,  2.1510e+00,  0.0000e+00, -2.0885e+00,\n",
      "          -9.2621e-01,  4.4997e-01, -1.1684e+00,  0.0000e+00, -4.6827e-01,\n",
      "          -7.4641e-01, -1.0650e+00, -9.7569e-01,  0.0000e+00,  2.3980e+00,\n",
      "           6.9864e-01,  0.0000e+00,  1.6920e+00, -1.4049e-01, -6.7025e-01,\n",
      "           3.3184e-02,  7.5988e-01,  4.2287e-01, -1.0341e+00, -9.5260e-02,\n",
      "           1.5602e+00,  5.8675e-01, -3.3839e-01,  6.5777e-01,  1.8418e+00,\n",
      "          -2.5278e-01, -2.1795e-01,  6.2402e-01, -2.3640e+00,  1.0561e+00,\n",
      "           3.0290e-01, -7.7148e-02,  1.5536e-01, -1.2125e+00,  0.0000e+00,\n",
      "           1.6827e+00,  1.8529e+00,  2.7177e-01, -1.2706e+00, -7.1307e-01,\n",
      "          -1.2243e+00, -1.0944e+00, -2.5915e+00,  5.0594e-01, -3.0611e+00,\n",
      "          -2.8750e-01,  4.9754e-01,  8.2981e-01,  3.1709e-01, -7.9309e-01,\n",
      "           2.7263e-01,  2.3402e+00,  1.0583e+00,  0.0000e+00, -4.0242e-01,\n",
      "           7.2805e-01,  5.9861e-01,  3.5985e-01,  8.4336e-01, -1.8313e+00,\n",
      "           1.3639e+00,  2.1602e+00,  3.3579e-01, -1.0158e+00, -1.1732e+00,\n",
      "          -2.2163e+00,  1.6680e+00,  2.1534e+00,  3.6348e-01,  2.3839e+00,\n",
      "           3.2579e-02, -5.0178e-01, -1.2773e+00, -5.4313e-01, -4.0773e-01,\n",
      "          -1.4478e+00,  9.5330e-01,  0.0000e+00,  8.2946e-01, -1.5607e+00,\n",
      "           0.0000e+00,  6.7552e-01,  2.3989e+00,  5.5373e-02,  1.8938e+00,\n",
      "           1.3092e+00,  5.8016e-01, -2.3180e+00,  1.5503e+00, -2.2251e-01,\n",
      "          -2.2736e-01,  1.7343e+00,  2.7650e-01, -1.5525e+00,  9.2282e-01,\n",
      "          -1.2244e+00, -8.4900e-01, -1.8028e+00, -7.8838e-04,  3.7316e-01,\n",
      "          -1.5741e+00, -1.2393e-01,  9.6644e-01, -1.7376e+00,  1.6949e+00,\n",
      "          -1.4405e+00,  0.0000e+00, -1.7230e+00,  9.8032e-01,  0.0000e+00,\n",
      "           1.5618e+00, -2.7297e-01, -2.5977e+00,  1.2393e+00, -1.2283e+00,\n",
      "           1.8868e+00, -5.0847e-01,  5.4289e-01, -2.6130e-01, -1.0225e+00,\n",
      "           0.0000e+00,  3.1141e-01, -5.0998e-02, -2.2872e-01, -1.6133e+00,\n",
      "           1.8073e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0358, 0.1242, 0.1468, 0.0859, 0.1350, 0.1251, 0.0916, 0.0724, 0.1311,\n",
      "         0.0521]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2887, -0.5092,  0.3514,  ...,  0.0054, -0.0189,  0.1247],\n",
      "        [-0.0463, -0.5531,  0.4880,  ..., -0.4019,  0.0023, -0.2296],\n",
      "        [-0.1100, -0.3312,  0.1285,  ..., -0.0108, -0.2698, -0.5469],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1534, -0.1138, -0.0611,  0.1769, -0.0833,  0.1009,  0.1034,\n",
      "          -0.0857, -0.0931,  0.0347,  0.1485, -0.0494, -0.0525, -0.0208,\n",
      "           0.1949, -0.0156,  0.0096,  0.2035, -0.1027,  0.0210, -0.1463,\n",
      "          -0.1883,  0.1809,  0.0996, -0.1499,  0.0038, -0.0474, -0.3228,\n",
      "          -0.0086, -0.0495,  0.0218,  0.0730, -0.2256, -0.1015, -0.0657,\n",
      "           0.0151, -0.0085, -0.0294,  0.0317,  0.0266,  0.0682,  0.1157,\n",
      "          -0.3379,  0.0327,  0.1109,  0.1707, -0.1207, -0.0029, -0.0310,\n",
      "          -0.1514, -0.1630, -0.0041, -0.1843, -0.0358,  0.1953,  0.0444,\n",
      "           0.0645,  0.0238,  0.2285,  0.0961, -0.0836, -0.1188, -0.0961,\n",
      "           0.0971, -0.1336,  0.0166, -0.0436,  0.1797,  0.0144,  0.0799,\n",
      "           0.0238,  0.2292, -0.1754,  0.1918, -0.0837,  0.0500,  0.0902,\n",
      "           0.2328,  0.2125,  0.1303,  0.0516, -0.0670, -0.0188, -0.0005,\n",
      "           0.0412,  0.1765,  0.1710,  0.0596,  0.1981,  0.0180, -0.0204,\n",
      "          -0.0300, -0.1503,  0.1180, -0.1939,  0.1895,  0.0247,  0.1390,\n",
      "           0.0305,  0.1981, -0.1860,  0.1887,  0.1597, -0.0419, -0.0853,\n",
      "           0.0554, -0.0903,  0.1199, -0.1758,  0.0055,  0.0452,  0.1042,\n",
      "          -0.1737, -0.1675, -0.1484, -0.0006,  0.0460, -0.0768, -0.1005,\n",
      "          -0.0178,  0.0480, -0.2355, -0.0415,  0.0500, -0.1783, -0.1344,\n",
      "           0.0093, -0.0929, -0.0434,  0.0039,  0.1141,  0.1067, -0.0082,\n",
      "           0.1102, -0.0848, -0.1431,  0.1500,  0.0587, -0.1342,  0.0643,\n",
      "          -0.1132,  0.1048, -0.0767, -0.0269,  0.0986, -0.0594, -0.0797,\n",
      "           0.1375,  0.0401, -0.0155, -0.1939,  0.1512, -0.1118,  0.1653,\n",
      "          -0.0085,  0.2630, -0.1558,  0.0866,  0.0166,  0.1188,  0.0974,\n",
      "          -0.1235, -0.0336,  0.1172, -0.0868,  0.0364, -0.0131, -0.0075,\n",
      "           0.1970,  0.2294,  0.0338,  0.1009,  0.2010,  0.0151, -0.0882,\n",
      "          -0.1012, -0.0094,  0.0723,  0.1407,  0.0899, -0.3098, -0.1184,\n",
      "          -0.0469,  0.0234,  0.1890,  0.0787, -0.0386,  0.0672, -0.0598,\n",
      "          -0.0996, -0.0791,  0.2046, -0.1782, -0.1585, -0.2511, -0.3697,\n",
      "          -0.1721,  0.0125, -0.2752,  0.0174,  0.1431, -0.0229,  0.1127,\n",
      "           0.0553, -0.1506, -0.1731, -0.0647,  0.1399,  0.0094, -0.0825,\n",
      "           0.0843, -0.0438, -0.0267,  0.3331, -0.1892,  0.0693,  0.0551,\n",
      "          -0.0163, -0.0210,  0.2594,  0.0700, -0.1802,  0.0116,  0.2055,\n",
      "           0.0129,  0.2923, -0.1407, -0.1783, -0.2047,  0.1982, -0.2190,\n",
      "           0.1021,  0.0075, -0.0172, -0.0720, -0.0061, -0.0675, -0.0649,\n",
      "           0.1428,  0.1538, -0.1793, -0.0897, -0.0970, -0.0590,  0.0805,\n",
      "          -0.1482, -0.0693, -0.0522,  0.0042, -0.0764,  0.0713,  0.2485,\n",
      "          -0.1488, -0.1185, -0.0584, -0.1382]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00,  3.9896e-01, -9.6684e-01, -6.8178e-01,  3.7639e-01,\n",
      "          -2.0188e-01,  1.4649e+00, -8.3300e-02, -3.5851e+00,  9.0672e-01,\n",
      "           4.2889e-01, -6.2923e-01,  2.6056e+00, -6.2974e-01, -5.4161e-01,\n",
      "          -1.5799e-01,  8.5158e-01,  1.0951e+00,  0.0000e+00,  4.3611e-01,\n",
      "          -6.3381e-01, -3.8359e-01,  1.6420e+00,  1.5114e+00,  7.5382e-01,\n",
      "          -7.5283e-02, -1.8778e-01, -7.5920e-01,  1.6541e+00,  8.6169e-01,\n",
      "           1.2321e+00,  1.2192e+00,  0.0000e+00, -8.2697e-02, -1.5350e+00,\n",
      "           1.3954e+00,  2.8080e-01, -3.7458e+00,  0.0000e+00,  1.6014e+00,\n",
      "           0.0000e+00, -1.3987e+00, -2.6838e-01, -1.7166e+00, -1.5249e+00,\n",
      "           6.6733e-01,  5.4098e-01,  3.7023e-01, -1.3409e+00,  1.4388e-01,\n",
      "          -6.2892e-01,  2.7531e+00,  6.1051e-01, -1.0297e+00, -2.5686e-02,\n",
      "           2.0310e-01, -8.8232e-01, -1.2531e+00, -2.3660e-01, -4.2528e-01,\n",
      "           1.1012e+00,  1.4085e+00, -2.0366e-01, -5.0190e-01, -2.9650e+00,\n",
      "           5.5055e-01,  1.2791e+00, -1.2883e+00,  0.0000e+00,  5.2650e-01,\n",
      "          -1.2674e+00, -3.0409e-02,  0.0000e+00, -3.6424e+00,  3.2636e-01,\n",
      "          -2.2098e-03, -1.5981e-01,  0.0000e+00, -5.8339e-02, -1.1999e-01,\n",
      "          -1.4005e+00,  2.1320e+00, -9.2497e-01,  1.0058e+00,  0.0000e+00,\n",
      "           4.3452e-01,  1.6619e+00, -9.7482e-01, -1.0325e-01, -5.8153e-01,\n",
      "          -2.2742e+00,  1.1004e+00, -6.2231e-01, -1.1354e+00,  4.6750e-01,\n",
      "          -1.1709e+00,  3.4306e-02,  6.2927e-01,  1.7206e+00, -7.8047e-01,\n",
      "           2.6978e+00, -1.4630e+00,  1.0761e+00,  1.4545e+00, -6.6649e-01,\n",
      "          -7.6258e-01,  1.2128e+00,  1.2742e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -2.4892e-01,  1.3446e-01,  0.0000e+00,  1.3103e+00, -1.6539e+00,\n",
      "          -2.9905e+00, -5.6352e-02, -5.0143e-01,  0.0000e+00,  4.4480e-01,\n",
      "          -1.4671e+00,  7.0249e-01, -1.4609e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -1.3094e+00,  8.9775e-01,  1.7042e-01,  1.2858e+00, -7.5274e-01,\n",
      "          -8.2326e-01,  5.2978e-01, -1.5835e+00,  9.8423e-01,  2.7618e-01,\n",
      "          -5.8961e-01,  6.5997e-01,  5.7355e-01, -1.1586e+00, -1.0106e+00,\n",
      "          -3.8898e-01,  6.7785e-01, -7.9009e-01, -1.0171e-01, -1.6864e+00,\n",
      "          -1.0132e-01, -5.4335e-01, -8.4459e-01, -7.5558e-01,  1.7739e-01,\n",
      "           1.9991e+00, -1.9981e-01, -1.9311e+00, -4.0625e-01,  4.4149e-01,\n",
      "          -1.9445e-01, -6.4175e-02,  0.0000e+00,  3.9478e-02,  5.3766e-01,\n",
      "          -2.6181e-02,  2.2067e+00,  4.8115e-01, -5.4978e-01, -5.2746e-01,\n",
      "          -8.9293e-01,  2.8176e-01,  8.4546e-02, -3.5796e-01, -4.7812e-01,\n",
      "           7.3816e-01,  0.0000e+00,  1.9885e-02, -1.0021e+00,  1.2780e+00,\n",
      "          -1.0992e+00, -9.8787e-01, -2.0778e+00,  1.9697e+00,  8.6399e-02,\n",
      "          -2.9837e-02,  3.5073e-02,  0.0000e+00,  9.7981e-01, -7.4705e-01,\n",
      "          -3.4094e-01, -2.7841e+00, -7.8469e-01,  1.2099e+00,  1.0125e+00,\n",
      "           3.0752e+00,  4.9446e-01, -1.4414e-01, -5.9469e-01,  5.6087e-01,\n",
      "           2.1659e+00, -1.1883e+00,  5.3482e-01,  1.8123e+00, -9.4761e-01,\n",
      "          -1.6622e+00, -1.0151e+00,  1.2418e+00, -1.2212e-01,  2.3196e-01,\n",
      "          -5.7544e-01, -2.2933e+00,  6.8199e-01, -1.0747e+00, -4.7140e-01,\n",
      "           2.8687e+00, -5.7330e-01, -3.4119e-01,  7.9333e-01,  2.9941e-02,\n",
      "           0.0000e+00, -1.0196e+00,  0.0000e+00, -2.4590e-01,  2.1701e+00,\n",
      "          -1.0830e+00,  0.0000e+00, -1.8442e+00, -5.0153e-01,  3.3729e-01,\n",
      "           7.0482e-01, -6.9656e-01, -6.2810e-01,  2.9226e-01, -1.5791e+00,\n",
      "          -1.1089e+00,  1.5817e+00, -6.1434e-01,  1.3099e+00, -2.9805e+00,\n",
      "           4.0366e+00,  5.8519e-01,  4.3488e-02, -1.5806e+00, -2.8754e-01,\n",
      "           7.4154e-01, -3.2493e+00, -3.0465e-01, -8.5264e-01,  1.1110e-02,\n",
      "           2.7531e-01,  2.7508e-01,  2.5262e-01,  0.0000e+00,  3.8668e-01,\n",
      "          -3.6562e-01, -1.5844e-01, -5.5418e-01, -5.2581e-02, -1.1473e+00,\n",
      "          -1.1315e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0334, 0.0393, 0.0884, 0.0537, 0.1330, 0.3336, 0.0527, 0.0787, 0.0614,\n",
      "         0.1257]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3506, -0.0350,  0.0764,  ..., -0.1129, -0.0154, -0.4834],\n",
      "        [ 0.1242,  0.1336,  0.2660,  ...,  0.1120,  0.0871,  0.0424],\n",
      "        [-0.0022,  0.2628, -0.0759,  ...,  0.1141, -0.1164, -0.4187],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3024,  0.1691, -0.2449,  0.0666, -0.0734, -0.2162,  0.0325,\n",
      "          -0.3065,  0.0408, -0.1160,  0.0393, -0.1475, -0.2752, -0.0277,\n",
      "           0.2992, -0.0035,  0.1491,  0.2171, -0.4037,  0.0865, -0.2681,\n",
      "          -0.1653,  0.1331,  0.1420, -0.1939, -0.2399, -0.0442, -0.2617,\n",
      "          -0.1022, -0.0933,  0.1074, -0.2631, -0.2358, -0.2426, -0.1312,\n",
      "          -0.1193, -0.2584, -0.1254, -0.1895, -0.0443,  0.0257,  0.1545,\n",
      "          -0.0890,  0.2081,  0.3195,  0.1530, -0.0047, -0.2134,  0.2011,\n",
      "          -0.0608, -0.0085, -0.0689, -0.2606,  0.0667,  0.0471,  0.0355,\n",
      "          -0.1173,  0.1594,  0.2874,  0.2496,  0.0049, -0.0679, -0.3239,\n",
      "           0.0696, -0.2537,  0.0481,  0.0079,  0.2195, -0.1409,  0.0671,\n",
      "           0.0124,  0.3051, -0.2364,  0.3195, -0.3900,  0.0845,  0.3174,\n",
      "           0.2567, -0.0408,  0.1064, -0.2714, -0.3159, -0.2377, -0.0541,\n",
      "           0.0047,  0.2179,  0.0665, -0.0678,  0.2697, -0.0078,  0.1212,\n",
      "           0.0014, -0.1764, -0.0491,  0.0665,  0.1939,  0.2288,  0.1778,\n",
      "          -0.1046,  0.2569, -0.2936,  0.1889,  0.1523,  0.0866, -0.1408,\n",
      "          -0.0691,  0.0935,  0.2132, -0.1708,  0.1355, -0.0071, -0.0622,\n",
      "          -0.0931, -0.2910, -0.1501, -0.0328,  0.0470, -0.1427, -0.2808,\n",
      "          -0.0798,  0.1754, -0.2119, -0.1548,  0.1371, -0.2534, -0.0983,\n",
      "           0.0809,  0.0345,  0.2161,  0.0288,  0.1459, -0.2183,  0.2712,\n",
      "           0.0712, -0.0889, -0.0307,  0.2797,  0.0554, -0.2468,  0.1597,\n",
      "          -0.1423,  0.4129, -0.1663,  0.2179,  0.1529,  0.0572,  0.0816,\n",
      "           0.3106,  0.0957,  0.2554, -0.4838,  0.0613, -0.0489,  0.1283,\n",
      "          -0.0172,  0.4015, -0.0677,  0.2836,  0.1751, -0.0020, -0.0337,\n",
      "          -0.1203, -0.3428,  0.2585, -0.0468,  0.1685, -0.2104, -0.1773,\n",
      "           0.2998,  0.3753, -0.2686, -0.0389,  0.2316,  0.0280, -0.1861,\n",
      "          -0.2165, -0.0078,  0.0989,  0.3395, -0.1645, -0.2351, -0.1843,\n",
      "          -0.3584,  0.0137,  0.2535,  0.1937, -0.2332,  0.2672,  0.0083,\n",
      "          -0.2400, -0.1582,  0.2077, -0.3700, -0.1789,  0.1056, -0.1878,\n",
      "          -0.2152,  0.1401, -0.3273,  0.1697, -0.0148,  0.1126, -0.0301,\n",
      "           0.1508, -0.1091, -0.0084, -0.2027,  0.1866, -0.0027, -0.0903,\n",
      "           0.1887, -0.3350, -0.1620,  0.1221, -0.1094,  0.1920,  0.0020,\n",
      "           0.2424, -0.3252,  0.2869,  0.2540, -0.2321,  0.2677, -0.1797,\n",
      "           0.0987,  0.3982,  0.0964, -0.2325, -0.4074,  0.2925, -0.2166,\n",
      "          -0.0018, -0.0998, -0.1222, -0.0663,  0.0506, -0.2237, -0.0228,\n",
      "           0.3046,  0.0813, -0.0257, -0.2539, -0.3502, -0.0191,  0.2896,\n",
      "          -0.1287, -0.2095, -0.2888,  0.0620,  0.0383,  0.0559,  0.0433,\n",
      "          -0.1049, -0.2005,  0.0720, -0.1514]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1549, -1.4816,  1.6542, -1.0094,  0.0000,  0.4006,  0.0000,\n",
      "          -1.2224, -0.9021,  0.0941, -0.2099,  0.3159,  0.1269, -0.9577,\n",
      "          -0.3085,  0.3244, -1.8654, -2.1363,  0.6082,  0.0000,  0.7696,\n",
      "           0.2830, -1.2569, -0.9729,  1.1925,  1.4263, -1.6558,  1.0544,\n",
      "           0.0000, -1.2885,  0.3066, -0.9454, -0.7689, -1.5226, -0.3682,\n",
      "           0.0000, -0.9885, -0.3510,  0.3282,  0.6281,  0.6073, -1.1767,\n",
      "           0.3727,  1.2541, -1.7953,  1.9479, -1.4981, -0.4427, -0.2786,\n",
      "           1.1463,  0.0000,  0.0362, -0.0721, -1.0042, -0.2961, -0.8049,\n",
      "          -1.8693,  0.5100,  1.5730,  2.0576, -0.8820, -0.7340,  1.9471,\n",
      "          -0.9061, -0.8592,  0.1078,  0.6387, -0.6172,  0.0209,  0.4297,\n",
      "          -1.5893, -0.0282, -0.6441,  1.4258, -0.4461,  0.5578, -3.6196,\n",
      "          -0.6177, -1.4064, -0.3109,  0.8705,  1.3122,  0.8810, -0.9603,\n",
      "           0.6944,  0.0000,  0.0462, -2.9897,  0.8147, -0.0184, -1.4907,\n",
      "           0.0000, -1.2889,  2.3923,  1.8841,  0.0000, -1.1102,  1.0776,\n",
      "           1.5506, -2.1246,  0.0145, -0.6637, -1.1343, -1.8826,  0.4070,\n",
      "           1.4168, -1.9889, -0.9154,  0.4130,  1.8164, -1.4323,  0.1790,\n",
      "          -0.4974,  1.3003, -0.1465, -0.1099,  0.3374,  0.0000,  0.8516,\n",
      "          -1.2944, -1.3461,  0.0000,  0.8784,  0.0000,  0.2248,  0.8191,\n",
      "          -0.2026, -1.0700,  0.1245, -0.4277, -1.2478,  2.3284,  1.4195,\n",
      "           0.0000, -0.0091, -0.6384, -0.0636, -0.5996, -0.4515,  1.0984,\n",
      "           0.5454, -1.1800, -2.2950, -0.8857,  0.0000, -0.1879,  0.9173,\n",
      "          -0.0828,  1.5432, -0.7186,  0.0000, -1.3512,  1.8154, -1.9311,\n",
      "           0.5128, -0.3341, -0.2287, -0.7581,  0.9342, -0.0180,  0.2297,\n",
      "          -1.1455,  2.2617, -1.7646, -0.3901, -0.6921,  0.5299,  2.1356,\n",
      "          -1.6403, -2.7423,  1.2540, -2.0853, -0.0062,  0.0000, -0.9213,\n",
      "           0.0000, -0.3064, -0.4305,  0.1179, -1.5137,  0.1503,  0.0000,\n",
      "           0.1993,  0.9700,  0.4841, -0.0758, -1.5019, -0.2142,  0.4035,\n",
      "          -1.4624,  1.0713,  0.0000,  0.5036, -0.5082,  0.7249, -0.0428,\n",
      "           0.0000,  0.0425, -0.8385, -0.2756,  0.1191, -0.2977,  0.2828,\n",
      "           0.3538, -0.0092, -0.7146,  0.6959,  2.0163, -0.7496,  1.8922,\n",
      "           2.7894,  0.0000,  1.5049,  0.1013, -0.5909, -0.0225, -0.1425,\n",
      "          -1.3819,  0.4083,  0.0000, -0.6885,  1.8591,  0.6067,  0.4727,\n",
      "           0.0290,  1.5296, -0.3650, -0.2608,  0.0000, -0.2542,  0.0000,\n",
      "          -0.5516,  0.0000,  0.0930,  2.0766,  0.0000,  0.0000,  2.7784,\n",
      "           0.0000,  1.8028, -0.8495,  0.2569, -1.0498, -0.8538,  0.1357,\n",
      "          -1.7792,  0.3815,  1.9827,  0.5691,  0.5472, -1.7499,  0.3683,\n",
      "           0.1556,  1.5690, -2.7258,  0.4072]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0436, 0.1494, 0.1094, 0.0513, 0.1329, 0.2152, 0.0559, 0.0655, 0.1038,\n",
      "         0.0730]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3506, -0.0350,  0.0764,  ..., -0.1129, -0.0154, -0.4834],\n",
      "        [ 0.1242,  0.1336,  0.2660,  ...,  0.1120,  0.0871,  0.0424],\n",
      "        [-0.0022,  0.2628, -0.0759,  ...,  0.1141, -0.1164, -0.4187],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.3726e-01,  1.3340e-01, -1.3548e-01,  8.7350e-02,  4.5824e-02,\n",
      "          -8.1026e-02, -3.7317e-02, -1.8572e-01,  6.2024e-02, -3.8487e-02,\n",
      "          -1.2033e-02, -7.7520e-02, -1.8856e-01, -8.2293e-03,  2.3830e-01,\n",
      "           8.5028e-02,  1.6081e-01,  1.6305e-01, -3.8805e-01,  4.8886e-02,\n",
      "          -2.4814e-01, -8.5502e-02,  4.3814e-02,  5.6083e-02, -1.6815e-01,\n",
      "          -2.3245e-01, -1.0493e-02, -1.8820e-01, -5.7432e-02, -6.8532e-02,\n",
      "           5.7000e-02, -1.5163e-01, -1.7572e-01, -1.3352e-01, -1.5169e-01,\n",
      "          -1.5502e-01, -2.5418e-01, -1.0111e-01, -1.2178e-01, -8.9360e-02,\n",
      "           2.7768e-02,  1.4096e-01, -4.1423e-02,  1.6145e-01,  3.1951e-01,\n",
      "           7.1962e-02,  7.9332e-02, -6.9844e-02,  1.9385e-01, -5.7693e-02,\n",
      "           1.1839e-02, -1.2849e-01, -1.4093e-01,  3.2281e-02, -9.9598e-03,\n",
      "           2.3416e-02, -9.1136e-02,  1.6171e-01,  2.4128e-01,  2.0100e-01,\n",
      "           4.1358e-02, -4.4132e-02, -2.4286e-01,  6.2157e-02, -2.0641e-01,\n",
      "           3.9192e-02,  4.8459e-02,  1.1568e-01, -1.2770e-01,  1.3771e-02,\n",
      "           2.2465e-02,  2.9356e-01, -2.7861e-01,  2.4602e-01, -3.5805e-01,\n",
      "           7.4412e-02,  2.5402e-01,  1.6014e-01,  2.0549e-04,  2.6118e-02,\n",
      "          -2.6944e-01, -2.3927e-01, -1.5660e-01, -2.8257e-02,  4.7627e-02,\n",
      "           1.8782e-01,  9.2131e-02, -5.3183e-02,  1.6394e-01,  7.0021e-02,\n",
      "           2.7974e-02,  5.7186e-02, -1.8333e-01, -6.2551e-02,  9.5639e-02,\n",
      "           1.8770e-01,  2.3479e-01,  1.4994e-01, -1.2110e-01,  1.6504e-01,\n",
      "          -2.4200e-01,  1.4287e-01,  1.3462e-01,  8.0202e-02, -1.0624e-01,\n",
      "          -4.1958e-02,  6.7122e-02,  1.1875e-01, -1.6884e-01,  9.7137e-02,\n",
      "          -9.4046e-02, -5.7829e-02, -1.3012e-01, -1.7747e-01, -2.0916e-02,\n",
      "          -4.9013e-02,  7.1782e-02, -1.4724e-01, -2.4000e-01, -1.0227e-01,\n",
      "           1.6827e-01, -1.8824e-01, -8.4420e-02,  1.1347e-01, -2.4279e-01,\n",
      "          -8.4545e-02,  1.3400e-01,  8.1199e-02,  2.2075e-01,  1.1810e-01,\n",
      "           8.1479e-02, -1.4277e-01,  2.0377e-01,  1.1364e-02, -7.7814e-02,\n",
      "          -9.6670e-02,  2.4112e-01,  5.7980e-02, -7.9166e-02,  1.2208e-01,\n",
      "          -6.9753e-02,  3.8030e-01, -5.7323e-02,  2.1451e-01,  6.4972e-02,\n",
      "           7.6346e-02,  1.3640e-01,  2.4704e-01, -2.7171e-03,  1.8045e-01,\n",
      "          -3.9685e-01,  1.8731e-02,  3.4724e-03,  1.3198e-01, -8.9073e-02,\n",
      "           3.5194e-01, -2.9467e-02,  2.6817e-01,  1.0983e-01,  1.0686e-01,\n",
      "           5.4755e-03, -3.3799e-02, -2.6751e-01,  1.6812e-01, -1.0017e-01,\n",
      "           6.9323e-02, -1.7693e-01, -1.3932e-01,  1.4314e-01,  3.2849e-01,\n",
      "          -1.6184e-01, -7.5982e-02,  1.3732e-01,  1.1552e-01, -6.4956e-02,\n",
      "          -1.8632e-01, -1.8818e-03,  7.1827e-02,  2.2834e-01, -1.2938e-01,\n",
      "          -1.6827e-01, -8.2865e-02, -3.2601e-01, -1.7019e-02,  2.2046e-01,\n",
      "           1.4788e-01, -1.0066e-01,  1.7598e-01, -1.8368e-02, -2.0849e-01,\n",
      "          -7.7463e-02,  1.0399e-01, -3.0228e-01, -1.2097e-01,  2.3991e-02,\n",
      "          -7.9849e-02, -1.2065e-01,  1.6250e-01, -2.5082e-01,  1.1085e-01,\n",
      "          -1.9798e-02,  6.7101e-02,  2.0310e-02,  6.8889e-02, -1.3638e-01,\n",
      "           2.0313e-02, -2.0257e-01,  9.7022e-02,  1.5737e-02, -4.8311e-02,\n",
      "           1.8089e-01, -2.7780e-01, -1.6795e-01,  2.9220e-02, -8.6093e-02,\n",
      "           8.0382e-02,  1.2460e-01,  2.4721e-01, -3.3814e-01,  2.0392e-01,\n",
      "           1.9995e-01, -1.8364e-01,  2.3785e-01, -1.4880e-01,  1.2277e-03,\n",
      "           3.8696e-01,  3.5596e-02, -2.0361e-01, -3.7288e-01,  2.1784e-01,\n",
      "          -1.5804e-01, -3.1385e-02, -5.9863e-02, -3.6828e-02, -4.2343e-02,\n",
      "           1.3079e-02, -1.9842e-01, -4.0041e-02,  2.2267e-01,  8.1428e-02,\n",
      "           3.1387e-02, -1.9966e-01, -3.5293e-01,  4.8783e-03,  2.8719e-01,\n",
      "          -1.0927e-01, -1.7591e-01, -2.5198e-01, -4.1103e-02, -2.7011e-02,\n",
      "           2.0740e-02,  6.2688e-02, -4.4834e-02, -1.3543e-01,  7.0019e-02,\n",
      "          -1.5245e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7782, -1.6520, -0.1828, -0.7320,  2.5180, -1.9079,\n",
      "          -0.0325,  0.9500,  0.0000,  1.4103, -0.7569, -0.0650,  0.0645,\n",
      "           1.0463,  1.8851,  0.8701, -0.7847, -0.6402, -1.4033, -0.4985,\n",
      "          -0.3791,  1.1427,  0.2329,  0.1893, -0.6129,  1.4041, -0.1510,\n",
      "          -1.0409,  0.4962, -0.5711,  0.6009, -1.6987,  0.2318, -0.0796,\n",
      "           0.1483,  0.6451, -2.2132,  1.0517,  0.0000, -0.6921,  0.0000,\n",
      "          -1.0643,  0.8180, -0.6327, -0.6565,  1.3726,  0.9366,  1.6036,\n",
      "           0.3695, -1.0081, -1.1720, -1.1123,  1.2530, -1.9747,  1.7089,\n",
      "           0.5929, -1.8923,  0.3415, -0.2937, -0.7703,  1.8691, -0.5940,\n",
      "          -1.6817, -0.8355,  1.2344, -0.3575,  0.2898, -0.7528, -1.1647,\n",
      "           2.2477,  0.0000,  0.2705,  1.2049, -0.3981,  0.3548,  0.2296,\n",
      "          -0.1574, -0.9149,  0.2959, -0.1448,  1.2866,  0.4652,  1.2969,\n",
      "           0.7705,  0.6607,  0.0000, -0.3683, -1.2412, -1.4363,  1.3105,\n",
      "          -1.5853, -0.1110,  0.0000,  0.3469,  1.0035,  0.0000,  0.7311,\n",
      "          -1.6815, -0.9243,  0.1908,  0.0286, -0.5965,  1.0585, -0.2309,\n",
      "           0.0000, -0.9059, -0.3677, -0.2786, -0.5476,  0.0000, -3.2782,\n",
      "          -0.1010, -1.8784,  1.6978,  1.6883,  2.0296, -1.6461, -0.8960,\n",
      "           0.0000, -1.3263,  1.4236, -0.6275,  0.4668,  1.3156, -0.9872,\n",
      "           0.0738, -0.9855, -0.6749,  0.2475, -1.2006,  1.1298,  1.1405,\n",
      "           1.4886,  0.3789,  0.6466,  0.0000,  0.2414,  0.0000, -1.2617,\n",
      "           0.0303,  0.8640,  0.5015,  0.9070, -1.2681, -0.6409, -0.4416,\n",
      "           0.8728, -0.0677,  0.0423, -0.0566,  0.6208,  0.1451, -0.1964,\n",
      "           0.1078, -1.6722, -0.4025,  0.2513, -2.0697,  0.0000,  1.1555,\n",
      "           0.0000,  0.9130,  0.8437,  0.4175,  1.6038,  0.1771, -1.1142,\n",
      "          -0.3224,  0.2508,  0.4448, -0.4551,  0.4446, -1.3452,  1.7356,\n",
      "           0.5174,  1.1773,  0.2896, -1.8322,  0.0000,  0.2595, -0.6474,\n",
      "          -1.1658,  0.3288, -0.7440,  0.5921, -1.2417, -1.5176, -2.3033,\n",
      "           0.1465,  0.0000, -1.3210, -0.0500,  1.2995,  0.9805,  0.0000,\n",
      "          -1.1402,  3.0137, -0.2259,  1.0329,  0.0291,  0.1191, -1.3196,\n",
      "          -1.0708,  0.0567,  1.7329,  0.5271,  1.9824, -0.9788, -1.3424,\n",
      "           1.5994, -0.4014,  2.4608, -0.5198,  0.7545,  0.0000, -0.8211,\n",
      "           0.9057, -3.5302,  0.1759, -0.7814, -0.6932, -1.4187,  0.2512,\n",
      "          -0.0648, -1.4655,  0.4269,  0.0000,  0.0463, -0.6253, -0.0713,\n",
      "           0.7484, -2.0270, -1.0490, -0.4316, -0.1122,  0.5160, -2.7970,\n",
      "          -1.4578, -0.6645,  1.0258,  0.1328,  2.7509,  1.0025,  0.5471,\n",
      "          -0.1735, -1.5053,  2.2320,  1.1873, -0.0479,  0.7229,  0.1089,\n",
      "          -2.8555,  0.0000, -0.8380, -0.5805]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0398, 0.1723, 0.1002, 0.1171, 0.0825, 0.1357, 0.0707, 0.0797, 0.1180,\n",
      "         0.0839]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3506, -0.0350,  0.0764,  ..., -0.1129, -0.0154, -0.4834],\n",
      "        [ 0.1242,  0.1336,  0.2660,  ...,  0.1120,  0.0871,  0.0424],\n",
      "        [-0.0022,  0.2628, -0.0759,  ...,  0.1141, -0.1164, -0.4187],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5642e-01,  8.8202e-02, -5.5860e-02,  1.1181e-01,  9.6490e-02,\n",
      "          -1.9372e-02, -4.4819e-02, -1.2228e-01,  6.7583e-02,  8.1607e-03,\n",
      "          -3.9482e-02, -4.4200e-02, -1.2449e-01, -2.7194e-02,  1.9129e-01,\n",
      "           1.2381e-01,  1.6488e-01,  1.1220e-01, -3.2652e-01,  4.9586e-02,\n",
      "          -2.1518e-01, -2.0721e-02,  1.4913e-02,  3.1182e-02, -1.2530e-01,\n",
      "          -1.8788e-01, -2.4349e-02, -1.3748e-01, -2.2457e-02, -6.2159e-02,\n",
      "          -8.3521e-03, -8.6675e-02, -1.4711e-01, -6.0060e-02, -1.3179e-01,\n",
      "          -1.7969e-01, -2.1949e-01, -7.7902e-02, -5.1944e-02, -1.2997e-01,\n",
      "           2.7835e-02,  1.2584e-01,  6.9296e-03,  1.5265e-01,  3.0882e-01,\n",
      "           1.4584e-02,  1.3313e-01, -5.7946e-04,  1.7701e-01, -4.6138e-02,\n",
      "           4.2003e-02, -9.6532e-02, -8.2964e-02,  2.8131e-02, -1.2640e-02,\n",
      "           1.2856e-02, -9.4080e-02,  1.2846e-01,  2.0544e-01,  1.5158e-01,\n",
      "           5.5556e-02, -2.4313e-03, -1.7674e-01,  2.0727e-02, -1.7320e-01,\n",
      "           3.9037e-02,  1.0444e-01,  5.1336e-02, -6.3111e-02, -3.7296e-02,\n",
      "           4.9967e-03,  2.4764e-01, -2.7953e-01,  2.1290e-01, -3.0906e-01,\n",
      "           2.4101e-02,  1.9198e-01,  1.1524e-01,  1.9768e-02, -2.9716e-02,\n",
      "          -2.4201e-01, -2.0242e-01, -5.9943e-02, -3.6191e-02,  6.5476e-02,\n",
      "           1.5762e-01,  7.1818e-02, -7.2043e-02,  9.3146e-02,  9.6120e-02,\n",
      "          -1.8525e-02,  7.6117e-02, -1.6556e-01, -7.2678e-02,  1.2581e-01,\n",
      "           1.6086e-01,  2.1023e-01,  9.0321e-02, -1.2055e-01,  7.7898e-02,\n",
      "          -2.0404e-01,  1.0735e-01,  9.8862e-02,  7.2557e-02, -7.8590e-02,\n",
      "          -3.9168e-02,  1.5844e-02,  3.8860e-02, -1.5776e-01,  3.3516e-02,\n",
      "          -1.2569e-01, -6.1705e-02, -1.5026e-01, -9.8688e-02,  4.7508e-02,\n",
      "          -7.2041e-02,  7.3925e-02, -1.1377e-01, -2.0394e-01, -7.4856e-02,\n",
      "           1.6308e-01, -1.4444e-01,  1.0434e-02,  8.4886e-02, -1.8635e-01,\n",
      "          -6.4070e-02,  1.5015e-01,  1.2145e-01,  1.8786e-01,  1.7147e-01,\n",
      "           3.4591e-02, -5.7125e-02,  1.5270e-01, -4.6947e-02, -5.3588e-02,\n",
      "          -1.2609e-01,  1.8082e-01,  2.6519e-02, -1.4495e-02,  4.8536e-02,\n",
      "          -2.1155e-02,  3.2524e-01,  3.3309e-03,  1.8687e-01,  1.9624e-02,\n",
      "           9.1745e-02,  1.4358e-01,  1.5540e-01, -5.3037e-02,  1.2304e-01,\n",
      "          -3.1415e-01, -9.6128e-03,  2.5324e-02,  9.0848e-02, -1.6789e-01,\n",
      "           2.8437e-01, -2.3954e-02,  2.5102e-01,  8.4994e-02,  1.7134e-01,\n",
      "           4.8336e-02,  2.1356e-02, -1.8673e-01,  6.0930e-02, -1.0071e-01,\n",
      "           2.3253e-02, -1.5548e-01, -1.1661e-01,  8.7477e-02,  2.9025e-01,\n",
      "          -1.0626e-01, -1.1175e-01,  8.0450e-02,  1.2081e-01, -2.8874e-02,\n",
      "          -1.3126e-01,  1.7379e-02,  3.3803e-02,  1.4214e-01, -9.4563e-02,\n",
      "          -1.1720e-01, -4.2802e-02, -2.9613e-01, -2.5330e-02,  1.6877e-01,\n",
      "           1.1001e-01, -2.5373e-02,  1.2861e-01, -5.1369e-02, -1.6079e-01,\n",
      "          -5.9880e-02,  6.7912e-02, -2.2404e-01, -7.2310e-02,  2.4471e-02,\n",
      "          -2.0336e-02, -1.0983e-01,  1.6738e-01, -2.0482e-01,  8.4773e-02,\n",
      "          -1.3003e-02,  2.7866e-02,  4.7076e-02, -2.4201e-03, -1.5164e-01,\n",
      "           6.4765e-02, -1.9540e-01,  1.2267e-02,  2.8143e-02, -2.0135e-05,\n",
      "           1.9390e-01, -2.2998e-01, -1.6745e-01, -3.5323e-02, -5.6207e-02,\n",
      "           2.4879e-02,  1.8015e-01,  2.1732e-01, -3.0405e-01,  1.6888e-01,\n",
      "           1.5140e-01, -1.4682e-01,  1.9147e-01, -1.2317e-01, -5.3739e-02,\n",
      "           3.4436e-01, -5.2166e-03, -1.5452e-01, -3.0044e-01,  1.5727e-01,\n",
      "          -1.0247e-01, -7.5457e-03, -2.6831e-02,  3.1217e-02, -2.7287e-02,\n",
      "           1.6286e-02, -1.5587e-01, -4.1889e-02,  1.5970e-01,  5.5775e-02,\n",
      "           5.5036e-02, -1.5599e-01, -3.2095e-01, -6.4202e-03,  2.6765e-01,\n",
      "          -9.2638e-02, -1.2983e-01, -2.0205e-01, -8.7737e-02, -4.1600e-02,\n",
      "          -1.1229e-02,  5.2572e-02,  1.5991e-02, -7.6657e-02,  5.1118e-02,\n",
      "          -1.5809e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7261e-01, -4.3091e-01,  3.1519e-01, -1.0851e+00, -1.1728e+00,\n",
      "           7.4164e-01, -1.9147e+00,  1.3514e+00,  0.0000e+00,  6.1738e-01,\n",
      "           1.9038e+00,  6.0258e-01,  2.2917e-01, -9.1666e-01, -3.1840e+00,\n",
      "          -6.8293e-02, -1.6338e+00, -9.4354e-01,  1.3603e+00, -1.4358e+00,\n",
      "          -1.4038e-01, -5.2457e-01, -1.1198e+00, -2.5959e+00, -7.5925e-02,\n",
      "           1.3918e+00, -6.1989e-01,  1.9982e+00,  1.2779e-01,  5.5511e-01,\n",
      "           9.1600e-01, -3.7332e-03,  2.2227e-01,  2.0171e+00, -6.3603e-02,\n",
      "          -1.4086e+00, -1.1165e-01, -8.1741e-01,  3.1535e-01,  8.6145e-02,\n",
      "           8.6340e-01, -8.9933e-01,  0.0000e+00, -1.5641e+00,  1.9450e+00,\n",
      "          -3.0046e-01,  7.0645e-01, -6.0237e-01, -1.0210e+00,  1.1173e+00,\n",
      "           0.0000e+00,  2.6783e+00,  6.6702e-01, -8.4707e-01,  2.2805e-01,\n",
      "          -3.1019e-01, -1.4341e+00, -9.6223e-02,  1.2761e+00,  2.1823e+00,\n",
      "          -1.0066e+00,  3.5872e-02, -2.8023e-01,  0.0000e+00, -6.3194e-02,\n",
      "           3.9361e-01,  5.7810e-01,  1.1654e+00,  1.5811e+00, -1.4155e+00,\n",
      "           4.2735e-01,  2.9641e-01, -3.1051e-02, -7.9825e-01, -2.1419e-01,\n",
      "           1.3950e-01,  5.2605e-01,  0.0000e+00,  1.0274e+00, -7.9424e-01,\n",
      "           7.5850e-01, -1.0048e+00,  7.5838e-01,  0.0000e+00, -1.2156e+00,\n",
      "          -1.1333e-01,  0.0000e+00,  5.4873e-01, -9.4502e-01, -1.9014e+00,\n",
      "           5.2921e-01,  9.8741e-01,  1.7022e+00,  9.4430e-01,  0.0000e+00,\n",
      "          -1.5886e-02,  3.5435e-01, -1.1761e+00,  1.3726e+00,  2.4482e+00,\n",
      "           2.4344e-01,  4.4105e-02, -4.6663e-01, -9.8958e-01,  1.6411e+00,\n",
      "          -1.0241e+00,  3.0301e+00,  6.2075e-01, -1.0195e-01, -1.2357e+00,\n",
      "           1.9002e-01, -5.0334e-01, -5.7116e-01,  0.0000e+00, -7.8089e-01,\n",
      "           6.3265e-01,  0.0000e+00,  0.0000e+00, -2.3273e+00,  2.9237e-02,\n",
      "          -8.1487e-01, -1.4121e+00, -1.8387e+00,  6.0324e-01, -9.5725e-01,\n",
      "          -2.0105e-01,  4.0307e-02,  2.1509e+00,  1.3966e+00, -2.0884e+00,\n",
      "           0.0000e+00,  4.4992e-01, -1.1683e+00,  4.2553e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.0649e+00, -9.7560e-01, -1.9366e-02,  2.3980e+00,\n",
      "           6.9866e-01, -1.1219e+00,  1.6919e+00, -1.4045e-01, -6.7017e-01,\n",
      "           3.3261e-02,  7.5986e-01,  4.2290e-01, -1.0340e+00, -9.5295e-02,\n",
      "           1.5601e+00,  5.8680e-01, -3.3845e-01,  6.5776e-01,  1.8416e+00,\n",
      "          -2.5283e-01, -2.1787e-01,  6.2396e-01,  0.0000e+00,  1.0561e+00,\n",
      "           3.0287e-01, -7.7187e-02,  1.5528e-01, -1.2124e+00, -2.2046e-02,\n",
      "           1.6827e+00,  1.8528e+00,  2.7168e-01, -1.2705e+00,  0.0000e+00,\n",
      "          -1.2243e+00, -1.0943e+00, -2.5913e+00,  5.0588e-01, -3.0609e+00,\n",
      "          -2.8747e-01,  0.0000e+00,  8.2977e-01,  3.1711e-01, -7.9309e-01,\n",
      "           2.7253e-01,  2.3401e+00,  0.0000e+00,  8.3905e-01, -4.0245e-01,\n",
      "           7.2802e-01,  5.9868e-01,  3.5982e-01,  8.4321e-01, -1.8312e+00,\n",
      "           1.3638e+00,  2.1601e+00,  3.3584e-01,  0.0000e+00, -1.1731e+00,\n",
      "          -2.2161e+00,  1.6678e+00,  2.1533e+00,  3.6341e-01,  2.3838e+00,\n",
      "           3.2533e-02, -5.0167e-01,  0.0000e+00,  0.0000e+00, -4.0770e-01,\n",
      "          -1.4477e+00,  9.5334e-01,  0.0000e+00,  8.2958e-01, -1.5606e+00,\n",
      "           6.3745e-01,  6.7555e-01,  2.3988e+00,  5.5359e-02,  1.8938e+00,\n",
      "           1.3091e+00,  5.8025e-01, -2.3179e+00,  1.5503e+00,  0.0000e+00,\n",
      "          -2.2734e-01,  0.0000e+00,  2.7655e-01, -1.5524e+00,  0.0000e+00,\n",
      "          -1.2244e+00, -8.4897e-01, -1.8027e+00, -7.7061e-04,  3.7321e-01,\n",
      "          -1.5740e+00, -1.2388e-01,  9.6642e-01, -1.7374e+00,  1.6948e+00,\n",
      "           0.0000e+00,  6.3403e-01, -1.7229e+00,  9.8030e-01, -1.7171e+00,\n",
      "           1.5617e+00, -2.7295e-01,  0.0000e+00,  1.2392e+00, -1.2283e+00,\n",
      "           1.8866e+00,  0.0000e+00,  5.4282e-01, -2.6129e-01, -1.0224e+00,\n",
      "           1.3340e+00,  3.1136e-01,  0.0000e+00, -2.2876e-01, -1.6131e+00,\n",
      "           1.8072e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0431, 0.1206, 0.1527, 0.0531, 0.1532, 0.1638, 0.0981, 0.0705, 0.0864,\n",
      "         0.0585]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3506, -0.0350,  0.0764,  ..., -0.1129, -0.0154, -0.4834],\n",
      "        [ 0.1242,  0.1336,  0.2660,  ...,  0.1120,  0.0871,  0.0424],\n",
      "        [-0.0022,  0.2628, -0.0759,  ...,  0.1141, -0.1164, -0.4187],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2063,  0.1152, -0.1153,  0.0872,  0.0736, -0.0490, -0.0402,\n",
      "          -0.1670,  0.0576, -0.0295, -0.0176, -0.0421, -0.1778,  0.0004,\n",
      "           0.2177,  0.0992,  0.1534,  0.1679, -0.3575,  0.0466, -0.2289,\n",
      "          -0.0571,  0.0426,  0.0486, -0.1548, -0.2077,  0.0079, -0.1819,\n",
      "          -0.0273, -0.0483,  0.0397, -0.1282, -0.1637, -0.1207, -0.1543,\n",
      "          -0.1833, -0.2431, -0.0929, -0.0909, -0.0930,  0.0105,  0.1498,\n",
      "          -0.0253,  0.1620,  0.3072,  0.0600,  0.0957, -0.0403,  0.1984,\n",
      "          -0.0587,  0.0471, -0.0895, -0.1321,  0.0434,  0.0061,  0.0207,\n",
      "          -0.0947,  0.1459,  0.2381,  0.1493,  0.0500, -0.0343, -0.2169,\n",
      "           0.0453, -0.2090,  0.0496,  0.0634,  0.1042, -0.1100,  0.0176,\n",
      "           0.0097,  0.2763, -0.2807,  0.2413, -0.3386,  0.0742,  0.2333,\n",
      "           0.1507,  0.0196,  0.0097, -0.2442, -0.2000, -0.1300, -0.0404,\n",
      "           0.0499,  0.1786,  0.1006, -0.0579,  0.1425,  0.0940,  0.0088,\n",
      "           0.0658, -0.2033, -0.0785,  0.1046,  0.1909,  0.2239,  0.1068,\n",
      "          -0.1030,  0.1242, -0.2159,  0.1407,  0.1279,  0.0745, -0.0868,\n",
      "          -0.0448,  0.0457,  0.1236, -0.1525,  0.0700, -0.1200, -0.0484,\n",
      "          -0.1519, -0.1611,  0.0027, -0.0367,  0.0705, -0.1443, -0.2502,\n",
      "          -0.0833,  0.1360, -0.1764, -0.0537,  0.1092, -0.2229, -0.0866,\n",
      "           0.1405,  0.0926,  0.1670,  0.1416,  0.0591, -0.0876,  0.1408,\n",
      "          -0.0089, -0.0565, -0.1236,  0.1899,  0.0651, -0.0622,  0.1207,\n",
      "          -0.0788,  0.3763, -0.0404,  0.1948,  0.0665,  0.0729,  0.1220,\n",
      "           0.2327, -0.0153,  0.1647, -0.3768,  0.0287, -0.0183,  0.0994,\n",
      "          -0.1166,  0.3363, -0.0230,  0.2533,  0.0732,  0.1479,  0.0250,\n",
      "          -0.0141, -0.2445,  0.1192, -0.1198,  0.0475, -0.1769, -0.1387,\n",
      "           0.1331,  0.2991, -0.1438, -0.0790,  0.1182,  0.1234, -0.0421,\n",
      "          -0.1873,  0.0012,  0.0655,  0.1903, -0.1255, -0.1645, -0.0722,\n",
      "          -0.3088, -0.0156,  0.2201,  0.1341, -0.0483,  0.1560, -0.0528,\n",
      "          -0.1948, -0.0678,  0.0979, -0.2855, -0.0976, -0.0032, -0.0644,\n",
      "          -0.1094,  0.1621, -0.2368,  0.0864, -0.0170,  0.0474,  0.0436,\n",
      "           0.0143, -0.1567,  0.0354, -0.2075,  0.0425,  0.0359, -0.0515,\n",
      "           0.1616, -0.2595, -0.1649,  0.0212, -0.0960,  0.0592,  0.1698,\n",
      "           0.2417, -0.3282,  0.1897,  0.1686, -0.1769,  0.2124, -0.1283,\n",
      "          -0.0251,  0.3719, -0.0138, -0.1907, -0.3318,  0.1968, -0.1092,\n",
      "          -0.0172, -0.0491,  0.0135, -0.0315,  0.0262, -0.1839, -0.0366,\n",
      "           0.2191,  0.0824,  0.0318, -0.1898, -0.3311,  0.0026,  0.2750,\n",
      "          -0.1268, -0.1602, -0.2220, -0.0742, -0.0500,  0.0163,  0.0698,\n",
      "          -0.0085, -0.1213,  0.0667, -0.1776]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0858,  0.3989, -0.9670, -0.6819,  0.3764, -0.2018,  1.4649,\n",
      "           0.0000, -3.5852,  0.9068,  0.4290, -0.6293,  2.6058, -0.6297,\n",
      "          -0.5416, -0.1580,  0.8517,  1.0951,  0.4552,  0.0000, -0.6338,\n",
      "          -0.3837,  1.6421,  1.5115,  0.7539, -0.0753, -0.1877, -0.7592,\n",
      "           1.6541,  0.8617,  1.2321,  1.2192, -1.0344,  0.0000, -1.5351,\n",
      "           1.3954,  0.2808, -3.7459,  0.0000,  1.6015, -0.4589, -1.3989,\n",
      "          -0.2684, -1.7167, -1.5250,  0.6673,  0.5410,  0.3702, -1.3410,\n",
      "           0.1438, -0.6289,  2.7533,  0.6105, -1.0297, -0.0257,  0.2030,\n",
      "          -0.8824, -1.2532, -0.2366,  0.0000,  1.1013,  1.4086, -0.2037,\n",
      "          -0.5020, -2.9652,  0.5505,  1.2792, -1.2884,  0.4116,  0.5265,\n",
      "          -1.2675, -0.0304,  0.7075, -3.6425,  0.3264,  0.0000, -0.1598,\n",
      "           1.0631, -0.0584,  0.0000, -1.4005,  2.1321, -0.9250,  0.0000,\n",
      "          -0.2079,  0.4344,  1.6620, -0.9749, -0.1032, -0.5816, -2.2743,\n",
      "           1.1005, -0.6223, -1.1354,  0.4675, -1.1710,  0.0343,  0.6293,\n",
      "           0.0000,  0.0000,  2.6979,  0.0000,  1.0761,  1.4546, -0.6666,\n",
      "          -0.7626,  1.2129,  0.1274, -1.4731, -0.0131, -0.2489,  0.1345,\n",
      "           0.0000,  1.3104, -1.6540, -2.9907, -0.0563,  0.0000, -0.1932,\n",
      "           0.4447, -1.4672,  0.7025,  0.0000, -0.7264, -0.9588, -1.3095,\n",
      "           0.0000,  0.1705,  1.2859, -0.7528, -0.8232,  0.5298, -1.5836,\n",
      "           0.0000,  0.2762, -0.5896,  0.6600,  0.5734, -1.1585, -1.0107,\n",
      "          -0.3890,  0.6778, -0.7901, -0.1018, -1.6865, -0.1014, -0.5434,\n",
      "          -0.8446, -0.7556,  0.1774,  1.9992, -0.1999, -1.9312, -0.4063,\n",
      "           0.4416, -0.1945, -0.0641, -0.1291,  0.0395,  0.5377, -0.0261,\n",
      "           0.0000,  0.4812, -0.5498,  0.0000, -0.8931,  0.2818,  0.0846,\n",
      "          -0.3580, -0.4781,  0.7383, -0.0324,  0.0199, -1.0021,  1.2780,\n",
      "          -1.0992, -0.9880, -2.0780,  1.9698,  0.0864, -0.0298,  0.0351,\n",
      "           0.6717,  0.9799, -0.7471, -0.3409, -2.7842, -0.7848,  1.2100,\n",
      "           1.0126,  3.0754,  0.4945, -0.1441, -0.5948,  0.0000,  2.1660,\n",
      "          -1.1884,  0.5348,  1.8124, -0.9477, -1.6622, -1.0151,  1.2418,\n",
      "          -0.1221,  0.2319, -0.5755, -2.2934,  0.6820, -1.0748, -0.4714,\n",
      "           2.8689,  0.0000, -0.3412,  0.7934,  0.0299, -0.6849, -1.0198,\n",
      "           0.9663, -0.2459,  0.0000,  0.0000, -0.4277, -1.8443, -0.5016,\n",
      "           0.0000,  0.7048,  0.0000, -0.6281,  0.2923, -1.5791, -1.1090,\n",
      "           1.5817, -0.6144,  1.3098, -2.9806,  4.0368,  0.0000,  0.0435,\n",
      "          -1.5808, -0.2876,  0.0000, -3.2495, -0.3047, -0.8527,  0.0111,\n",
      "           0.0000,  0.2751,  0.2527,  0.2609,  0.3867, -0.3656, -0.1584,\n",
      "          -0.5542, -0.0526, -1.1473, -1.1316]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0388, 0.0506, 0.0792, 0.0720, 0.1256, 0.3178, 0.0583, 0.0864, 0.0589,\n",
      "         0.1124]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0052,  0.4047, -0.0120,  ...,  0.1333,  0.0975, -0.2313],\n",
      "        [ 0.2553,  0.2838, -0.3162,  ..., -0.1561,  0.2047, -0.2780],\n",
      "        [-0.2428, -0.0796, -0.3676,  ...,  0.1311,  0.2009,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1031,  0.0598, -0.0817, -0.2257, -0.1877, -0.2126, -0.2294,\n",
      "          -0.1006, -0.1438, -0.0404, -0.1019,  0.0473, -0.1986, -0.0653,\n",
      "           0.0825, -0.0493, -0.0279,  0.2957, -0.1229, -0.0358,  0.1017,\n",
      "          -0.2156,  0.1684, -0.2151, -0.1810,  0.1540,  0.0470, -0.1342,\n",
      "           0.0195,  0.1291,  0.2732, -0.2380, -0.0279, -0.2781,  0.0679,\n",
      "          -0.0618, -0.1690, -0.1225, -0.1332,  0.0690, -0.0775,  0.1172,\n",
      "          -0.2340, -0.1898,  0.1586,  0.0631,  0.1106, -0.2215,  0.1942,\n",
      "           0.1130,  0.1202, -0.2196, -0.2237, -0.0745, -0.0583, -0.1050,\n",
      "           0.0470,  0.0987,  0.1590,  0.1926, -0.2622, -0.1943, -0.2326,\n",
      "          -0.0158, -0.0485,  0.0289, -0.0407,  0.2422, -0.1949,  0.2237,\n",
      "          -0.0121,  0.0617,  0.1199,  0.2041,  0.0052,  0.2566,  0.2854,\n",
      "           0.0745, -0.2059,  0.1835,  0.1216,  0.0351, -0.2096,  0.1318,\n",
      "          -0.0500,  0.0649,  0.1390,  0.2162,  0.2281, -0.0051, -0.0098,\n",
      "           0.0525,  0.1343, -0.1086,  0.0773,  0.1838, -0.0165,  0.1053,\n",
      "           0.3303,  0.3463, -0.0382,  0.0963, -0.0281, -0.0310,  0.1825,\n",
      "          -0.0455,  0.1762,  0.3319, -0.0013,  0.2345, -0.0173,  0.1168,\n",
      "           0.0746, -0.1304, -0.0498,  0.0595, -0.0403, -0.0123, -0.0093,\n",
      "          -0.2440,  0.0279,  0.1716, -0.1754,  0.1226, -0.4165,  0.0408,\n",
      "          -0.1380,  0.0148,  0.2153,  0.0170, -0.0223, -0.0427,  0.2041,\n",
      "           0.2081,  0.0721, -0.1718,  0.0293,  0.2332,  0.0386,  0.2406,\n",
      "          -0.2532,  0.3071, -0.3069,  0.1415, -0.1536, -0.0367, -0.1916,\n",
      "           0.1665,  0.1803,  0.1593, -0.2665,  0.1459, -0.0232,  0.2487,\n",
      "           0.0310,  0.2384,  0.0992,  0.1707, -0.2036, -0.0491, -0.0755,\n",
      "          -0.0321, -0.2534,  0.2318, -0.0169,  0.1785, -0.0407, -0.1080,\n",
      "          -0.0065,  0.0042, -0.2108,  0.1255,  0.0246,  0.2144, -0.1098,\n",
      "          -0.1867, -0.0253,  0.0788,  0.3906, -0.1572,  0.0005, -0.0296,\n",
      "           0.1286, -0.0888,  0.2418, -0.1298,  0.0438, -0.1519, -0.0887,\n",
      "          -0.0213,  0.0224,  0.1111, -0.2236, -0.0711, -0.1302, -0.1555,\n",
      "          -0.1267,  0.1364, -0.0533, -0.0427, -0.2036,  0.1606, -0.3558,\n",
      "           0.1814, -0.1798, -0.3042, -0.1321,  0.2033,  0.0057, -0.0746,\n",
      "          -0.1410, -0.2732,  0.0416,  0.1126, -0.2467,  0.3023,  0.1478,\n",
      "           0.1869,  0.0598, -0.0706,  0.2895, -0.0617,  0.1283, -0.1176,\n",
      "          -0.0221,  0.1507,  0.0720, -0.2408, -0.4269,  0.1136,  0.1307,\n",
      "           0.0184, -0.2898, -0.0162,  0.0272,  0.0528, -0.1300,  0.1599,\n",
      "           0.3171,  0.1724, -0.0371, -0.2335,  0.0298,  0.0887,  0.0156,\n",
      "           0.0447, -0.2578, -0.2596,  0.0975, -0.2931,  0.2528, -0.0114,\n",
      "          -0.1736, -0.0266,  0.3249,  0.0170]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.4749, -0.4594, -1.2340, -0.1175,  0.4620,  0.0253,  0.6623,\n",
      "           0.0000,  0.6703,  0.0000,  1.7088, -1.0166,  0.9475, -0.2517,\n",
      "          -1.6346,  0.5131,  1.8780, -0.7564, -1.5627, -2.6442, -1.1340,\n",
      "           0.1678,  2.9304,  0.5543, -0.1166,  3.2100,  1.8373,  0.5192,\n",
      "          -2.2261, -1.2855,  0.0296,  1.0135,  0.3244,  0.8604, -0.7992,\n",
      "          -1.4656,  0.0000, -0.7715,  1.9920,  0.1026,  0.4676, -2.2045,\n",
      "          -0.5665, -0.1156, -0.7133, -0.6898,  0.0000,  0.0000,  0.0000,\n",
      "          -1.8509,  1.4685,  0.4637,  0.0000, -0.2840,  0.5318,  0.0000,\n",
      "          -1.2420, -0.9518,  1.8148,  0.0000,  0.2046, -1.8178, -1.4022,\n",
      "           0.0000,  1.1794,  0.2652, -0.1664, -0.2563,  0.0000, -0.4612,\n",
      "          -0.3254, -0.3246,  0.1476, -0.1270,  0.6588, -0.8067,  2.0662,\n",
      "           1.6804,  0.0877, -0.5469,  1.2272,  0.0000,  0.3272, -1.8368,\n",
      "          -0.0723, -1.7333, -1.4585, -0.8910,  0.6233,  0.8106, -1.2239,\n",
      "          -1.1446,  1.9857, -0.3655, -0.7339,  0.1564,  2.1425, -0.4056,\n",
      "          -0.3040, -1.8398, -1.2905, -0.7222, -0.7664,  0.2385,  0.3822,\n",
      "           1.1138, -1.0696,  2.2532, -0.2628, -0.2880, -0.0534,  0.0000,\n",
      "          -0.2557, -0.2803, -1.9429,  0.0000,  1.0061, -2.4990, -0.5745,\n",
      "           0.0299, -1.6960, -0.4013,  0.0000, -0.0792, -0.5373, -1.1121,\n",
      "           1.3058,  0.1702,  0.3225,  1.3584,  0.0000, -2.6347,  0.0000,\n",
      "          -0.7229,  0.4299,  0.0000,  0.3274,  0.0000, -0.4969, -1.6782,\n",
      "          -0.6425,  0.0000, -1.1874, -1.2158, -0.6317,  0.0000,  0.4652,\n",
      "           1.7385,  1.5937,  1.4317, -1.2629,  0.0000, -0.4804, -0.0395,\n",
      "           0.3271, -0.1161,  1.3541, -0.0310,  0.0000, -1.8060, -1.4271,\n",
      "           0.0000, -0.7052, -0.3892, -0.9825, -0.1292,  0.0000,  0.9709,\n",
      "           0.5179, -0.1472,  1.5155, -0.3734, -0.3159, -2.0089,  0.1286,\n",
      "          -0.3527,  0.0000,  0.0000,  0.0000, -0.9380,  0.7283,  1.0422,\n",
      "           0.0472,  0.4633,  0.3170, -0.1180, -0.5430, -0.6646,  0.7556,\n",
      "          -1.0646, -0.5858, -1.7886,  1.2674, -0.9271, -1.6148, -0.3331,\n",
      "          -1.1573, -1.9611, -0.0719, -0.3759,  2.6987, -0.9216, -2.6330,\n",
      "          -0.5862,  0.0000, -1.3864, -1.2543,  0.1722,  0.2182, -1.1116,\n",
      "           0.9458, -0.6919, -1.5201,  0.0000,  0.2370,  0.0000, -2.3456,\n",
      "           0.0468, -1.4808,  0.4281,  0.0133, -0.9024,  0.3007, -1.1659,\n",
      "          -1.3025, -0.1875,  1.2725,  1.2668, -2.1882, -0.0567,  1.7373,\n",
      "          -1.1753,  0.9566,  1.9993,  0.5267,  0.7906, -0.6786,  0.1047,\n",
      "          -0.6809, -2.2628,  0.1677, -0.3152, -1.0437, -0.3821, -1.0802,\n",
      "           0.5584,  1.5007, -0.5648, -1.3779,  1.2437,  0.5824,  1.7536,\n",
      "           1.9512,  0.3623,  0.4868,  0.3906]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0179, 0.2005, 0.0918, 0.0383, 0.1149, 0.1893, 0.0272, 0.1677, 0.0961,\n",
      "         0.0565]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0052,  0.4047, -0.0120,  ...,  0.1333,  0.0975, -0.2313],\n",
      "        [ 0.2553,  0.2838, -0.3162,  ..., -0.1561,  0.2047, -0.2780],\n",
      "        [-0.2428, -0.0796, -0.3676,  ...,  0.1311,  0.2009,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 7.0649e-02,  6.9429e-02, -1.0479e-01, -1.0425e-01, -1.2253e-01,\n",
      "          -1.7958e-01, -2.1395e-01, -6.7899e-02, -5.6969e-02,  2.2696e-02,\n",
      "          -1.2775e-01,  7.5835e-02, -1.8529e-01, -7.9792e-02, -9.4768e-03,\n",
      "          -4.5733e-02,  5.6296e-02,  2.3365e-01,  3.4275e-03, -2.8102e-04,\n",
      "           4.8240e-02, -1.7507e-01,  1.2321e-01, -1.9496e-01, -1.8476e-01,\n",
      "           1.4398e-01,  8.7290e-02, -1.1241e-01,  3.0938e-02,  7.7169e-02,\n",
      "           2.2974e-01, -2.6842e-01, -2.8247e-02, -2.1332e-01,  7.8630e-02,\n",
      "           2.8320e-03, -1.3746e-01, -1.2078e-01, -1.3931e-01,  1.1648e-02,\n",
      "          -1.3017e-01,  1.2158e-01, -1.4867e-01, -1.0256e-01,  1.6618e-01,\n",
      "          -4.5231e-02,  1.1362e-01, -1.5713e-01,  1.5716e-01,  1.6170e-01,\n",
      "           7.8851e-02, -1.3082e-01, -2.1214e-01, -1.0427e-01, -7.1196e-02,\n",
      "          -7.0393e-02,  2.2624e-02, -2.3401e-02,  1.0655e-01,  9.3622e-02,\n",
      "          -2.8050e-01, -1.6775e-01, -1.5012e-01, -7.1503e-02, -2.2988e-02,\n",
      "          -1.9897e-02,  3.8661e-02,  1.9867e-01, -1.7540e-01,  1.5982e-01,\n",
      "          -2.8606e-02, -1.3319e-02,  1.2328e-01,  2.4448e-01,  3.6688e-02,\n",
      "           1.1035e-01,  2.3513e-01, -1.0725e-02, -1.3318e-01,  1.4058e-01,\n",
      "           7.5539e-02,  3.8309e-02, -1.6299e-01,  1.5044e-01, -5.1722e-02,\n",
      "          -2.5407e-02,  8.3939e-02,  1.2190e-01,  1.2762e-01,  3.2975e-03,\n",
      "          -6.5854e-02,  9.5964e-02,  7.4251e-02, -1.5239e-01,  6.0953e-02,\n",
      "           1.1410e-01, -5.0988e-02,  7.3936e-02,  2.9272e-01,  3.1331e-01,\n",
      "          -9.4603e-02, -3.8948e-02, -5.4314e-02,  4.1476e-02,  1.6330e-01,\n",
      "           1.8807e-02,  2.0156e-01,  2.2332e-01,  1.4351e-03,  1.5740e-01,\n",
      "           1.7637e-02,  1.1191e-01,  3.6763e-02, -6.1372e-02, -3.9864e-03,\n",
      "           4.7650e-02, -4.9653e-02,  2.4418e-02, -6.3660e-02, -1.5236e-01,\n",
      "           3.1935e-02,  1.8843e-01, -6.9127e-02,  5.6285e-02, -3.2454e-01,\n",
      "           7.2437e-02, -6.5806e-02,  8.8437e-03,  1.6140e-01,  8.7500e-02,\n",
      "          -4.8074e-02,  7.9433e-02,  7.3504e-02,  7.8397e-02,  5.5750e-02,\n",
      "          -1.0100e-01,  4.7486e-02,  1.4063e-01,  9.9885e-02,  9.4363e-02,\n",
      "          -1.7075e-01,  1.9905e-01, -2.6839e-01,  1.1964e-01, -1.3251e-01,\n",
      "          -1.2894e-02, -1.5262e-01,  1.4323e-01,  1.1405e-01,  1.2973e-01,\n",
      "          -1.5232e-01,  4.5562e-02, -3.2895e-02,  2.0945e-01, -3.1843e-02,\n",
      "           1.9129e-01,  5.5087e-02,  1.8159e-01, -2.1081e-01, -7.9784e-02,\n",
      "          -3.5153e-02, -6.5101e-02, -1.5373e-01,  1.3498e-01, -4.5700e-02,\n",
      "           1.0317e-01, -7.3076e-02, -1.4959e-01,  8.1134e-02, -2.2426e-02,\n",
      "          -1.7260e-01,  1.1867e-01,  5.3586e-02,  7.5809e-02, -7.4995e-02,\n",
      "          -1.7970e-01,  2.8154e-02,  6.1192e-02,  3.4793e-01, -5.9740e-02,\n",
      "          -3.5613e-03, -1.0451e-02,  1.3520e-01, -2.7753e-02,  1.5406e-01,\n",
      "          -1.5094e-01,  5.5798e-03, -1.4860e-01, -1.5239e-01, -5.2848e-02,\n",
      "           9.2987e-02,  5.9531e-02, -1.1789e-01, -5.7922e-02, -4.8497e-02,\n",
      "          -1.6935e-01, -8.4684e-02,  4.8869e-02,  3.8555e-02, -8.4440e-02,\n",
      "          -2.3043e-01,  1.1167e-01, -3.0524e-01,  1.2192e-01, -1.8801e-01,\n",
      "          -1.3838e-01, -1.7873e-01,  2.0824e-01,  9.9843e-02, -2.6140e-02,\n",
      "          -1.7424e-01, -1.8188e-01,  6.9281e-02, -1.0719e-02, -2.6044e-01,\n",
      "           2.4215e-01,  9.3852e-02,  7.6182e-02,  1.0621e-01, -3.5923e-02,\n",
      "           2.1282e-01,  2.5621e-02,  6.5592e-02, -9.3609e-02, -5.6680e-02,\n",
      "           7.6211e-02,  6.0586e-02, -1.1624e-01, -3.8955e-01,  3.8171e-02,\n",
      "           1.4852e-01, -1.1039e-02, -1.6718e-01, -1.2525e-02,  3.6945e-02,\n",
      "           4.8665e-02, -1.6304e-01,  1.4154e-01,  3.0017e-01,  1.0546e-01,\n",
      "          -1.0343e-02, -1.4668e-01,  7.2786e-02,  5.6750e-02,  9.4597e-02,\n",
      "          -1.0378e-02, -2.2259e-01, -2.3505e-01,  4.4783e-02, -2.7005e-01,\n",
      "           2.2136e-01, -5.1904e-02, -1.7366e-01, -2.6728e-02,  2.5342e-01,\n",
      "          -3.5687e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0627e+00,  0.0000e+00, -1.8076e+00,  1.3221e+00,  5.1615e-01,\n",
      "          -3.7646e-01,  1.1996e-03, -7.2317e-01,  2.1179e+00, -2.1399e-01,\n",
      "           2.8231e-01,  0.0000e+00, -1.1109e+00,  1.9997e-01,  3.1225e-01,\n",
      "           3.5167e-01, -6.8293e-01,  1.6904e-01,  8.7474e-01,  5.4582e-01,\n",
      "           1.8833e+00,  6.0179e-01, -3.6623e-02, -5.3543e-01, -9.9778e-02,\n",
      "           6.5073e-01, -1.6087e+00, -1.3625e+00, -2.1269e+00, -1.0342e+00,\n",
      "           3.9031e-02, -1.4549e+00, -2.0764e+00,  3.1557e-01, -2.8502e-01,\n",
      "          -2.0017e+00,  2.1912e-01,  0.0000e+00,  6.0109e-01,  9.5374e-01,\n",
      "          -2.2532e-01, -2.2112e+00, -7.0639e-01,  1.3962e+00,  8.9390e-02,\n",
      "          -1.1385e+00,  0.0000e+00,  7.4169e-01, -7.0967e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.3715e-01,  6.6298e-01,  1.1163e+00,  5.6741e-01,\n",
      "           3.3345e-01, -4.4979e-01, -8.8835e-01,  1.3375e-01,  6.2843e-01,\n",
      "          -7.0519e-01,  0.0000e+00, -6.9330e-01, -1.5472e+00,  2.8933e-01,\n",
      "           9.5708e-02, -1.7773e-01,  5.9468e-01, -2.1383e+00,  5.5981e-01,\n",
      "           1.8283e-01, -5.1253e-01, -3.4126e-01, -1.1317e+00, -6.4719e-01,\n",
      "           4.6089e-01, -1.0494e+00,  1.1902e-01,  5.1720e-01, -1.8674e-01,\n",
      "          -3.8490e-01,  2.1581e+00,  7.7750e-01, -8.4561e-01,  3.9770e-01,\n",
      "           4.1920e-01,  1.6044e+00, -5.6419e-01, -1.4134e+00, -1.4906e+00,\n",
      "           0.0000e+00,  0.0000e+00,  4.9407e-01, -2.3208e+00,  0.0000e+00,\n",
      "          -9.6275e-01,  1.3202e+00, -9.0767e-01,  0.0000e+00,  9.5537e-01,\n",
      "          -1.2011e+00,  5.9447e-01,  1.0666e+00, -1.7337e+00,  3.6545e-01,\n",
      "           4.0219e-01,  0.0000e+00,  4.5517e-01,  1.9687e+00,  1.4922e-01,\n",
      "          -8.3225e-01,  5.3383e-01,  8.0815e-01,  6.6411e-01, -1.0547e+00,\n",
      "           9.1746e-01, -7.0265e-01, -8.4523e-01,  2.5778e-01,  8.7982e-01,\n",
      "          -8.7675e-01, -1.3968e+00, -3.6490e-01, -1.8465e+00, -1.3007e+00,\n",
      "           0.0000e+00, -8.1170e-01,  6.4918e-01,  2.5566e-01,  0.0000e+00,\n",
      "           2.5025e+00,  3.7796e-01, -1.3458e+00,  7.2244e-01,  3.2013e+00,\n",
      "          -7.5274e-01, -3.8341e-01,  1.2822e+00,  2.2522e+00,  1.9393e-01,\n",
      "          -3.9392e-02,  0.0000e+00,  3.6264e-01, -1.8691e-01, -1.1118e+00,\n",
      "           1.2471e+00,  0.0000e+00, -7.7463e-01, -4.5010e-02, -1.3874e+00,\n",
      "           2.3360e+00,  7.6457e-01, -2.8968e-01,  0.0000e+00, -5.8148e-01,\n",
      "           7.8598e-01, -1.8620e+00, -1.3047e+00,  1.9029e-01, -3.6289e+00,\n",
      "          -1.8684e+00,  1.1506e+00, -8.5932e-01,  9.5978e-01, -1.4615e+00,\n",
      "          -2.7135e-02,  0.0000e+00,  1.1271e+00, -4.8598e-01, -1.2414e+00,\n",
      "          -2.1200e-01, -1.3225e+00, -1.6392e+00, -7.7191e-01,  6.8262e-01,\n",
      "          -1.3796e+00, -1.2632e-01,  6.0664e-01, -7.4857e-01,  0.0000e+00,\n",
      "           1.3326e+00, -2.5535e+00,  2.7781e-01, -5.8387e-01,  1.6236e+00,\n",
      "          -1.2403e+00, -1.7417e-03, -5.0162e-02,  9.0150e-01,  0.0000e+00,\n",
      "          -4.1997e-01,  3.8797e-01, -1.1621e-01,  8.0962e-01,  1.0504e+00,\n",
      "           0.0000e+00, -1.4390e+00, -4.1608e-01, -7.5048e-01, -4.5427e-01,\n",
      "          -5.4755e-01,  7.2224e-01,  0.0000e+00,  1.3575e+00,  8.3773e-01,\n",
      "          -1.5241e+00, -3.5874e-01,  6.4794e-01,  0.0000e+00, -2.1784e+00,\n",
      "           8.3539e-01, -1.2913e+00, -1.2839e+00,  0.0000e+00, -1.5634e+00,\n",
      "           2.0756e+00,  1.3423e-01,  2.5768e+00, -3.1265e-02, -5.7934e-01,\n",
      "          -1.4285e+00,  1.9009e+00, -3.8089e-01,  1.4693e+00,  0.0000e+00,\n",
      "           3.6912e-01,  6.6978e-01,  0.0000e+00,  8.9242e-02,  1.0254e+00,\n",
      "           9.7821e-01,  0.0000e+00,  6.5977e-01, -1.1451e+00, -1.6454e+00,\n",
      "          -6.0026e-01,  8.9369e-03, -7.1116e-01,  3.7058e-01,  0.0000e+00,\n",
      "          -7.5246e-01,  5.7215e-01,  5.3078e-01, -6.6343e-01,  1.5466e+00,\n",
      "           5.7852e-01,  1.8918e+00, -8.6438e-01,  4.9336e-01, -3.8733e-01,\n",
      "           5.0025e-01,  0.0000e+00,  0.0000e+00, -1.0634e+00, -8.0798e-01,\n",
      "          -6.2172e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0481, 0.0964, 0.1225, 0.1325, 0.1516, 0.1593, 0.0556, 0.0725, 0.0468,\n",
      "         0.1148]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0052,  0.4047, -0.0120,  ...,  0.1333,  0.0975, -0.2313],\n",
      "        [ 0.2553,  0.2838, -0.3162,  ..., -0.1561,  0.2047, -0.2780],\n",
      "        [-0.2428, -0.0796, -0.3676,  ...,  0.1311,  0.2009,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0419,  0.0622, -0.0828, -0.1682, -0.1817, -0.2305, -0.1930,\n",
      "          -0.0403, -0.0931, -0.0220, -0.1384,  0.0631, -0.1288, -0.1539,\n",
      "          -0.0154, -0.0841,  0.0696,  0.2517,  0.0158,  0.0218,  0.0992,\n",
      "          -0.2122,  0.1204, -0.2207, -0.2084,  0.1539,  0.0436, -0.0983,\n",
      "           0.0161,  0.0876,  0.2323, -0.2745,  0.0051, -0.2183,  0.0391,\n",
      "          -0.0115, -0.1204, -0.1130, -0.1180,  0.0246, -0.1000,  0.0796,\n",
      "          -0.1784, -0.1449,  0.2356, -0.0169,  0.1561, -0.1569,  0.1914,\n",
      "           0.1600,  0.0686, -0.1664, -0.1940, -0.0818, -0.0631, -0.1897,\n",
      "           0.0367,  0.0266,  0.1304,  0.1494, -0.3114, -0.1810, -0.1457,\n",
      "          -0.0707, -0.0147,  0.0041,  0.0547,  0.2215, -0.1897,  0.1660,\n",
      "          -0.0558, -0.0247,  0.1304,  0.2093,  0.0273,  0.1482,  0.2082,\n",
      "          -0.0061, -0.1844,  0.1490,  0.1102,  0.0151, -0.1057,  0.1603,\n",
      "          -0.0481,  0.0447,  0.0895,  0.1711,  0.1105, -0.0290, -0.0548,\n",
      "           0.1223,  0.1502, -0.1542,  0.0730,  0.1277, -0.0426,  0.0726,\n",
      "           0.2941,  0.3305, -0.0493, -0.0495, -0.0310,  0.0169,  0.1451,\n",
      "           0.0360,  0.1887,  0.2232,  0.0305,  0.1900,  0.0172,  0.1396,\n",
      "           0.0441, -0.0759, -0.0171,  0.0110, -0.0672,  0.0524, -0.0584,\n",
      "          -0.1908,  0.0470,  0.2029, -0.0784,  0.0948, -0.3735,  0.0455,\n",
      "          -0.1410,  0.0319,  0.2145,  0.0781, -0.0261,  0.0293,  0.1647,\n",
      "           0.0999,  0.0724, -0.1201,  0.0236,  0.1312,  0.0778,  0.1003,\n",
      "          -0.1922,  0.2581, -0.3065,  0.1961, -0.1867,  0.0065, -0.2105,\n",
      "           0.0908,  0.1154,  0.1590, -0.1548,  0.0456, -0.0093,  0.2177,\n",
      "          -0.0891,  0.1641,  0.0723,  0.1758, -0.2444, -0.0607, -0.0215,\n",
      "          -0.0525, -0.1438,  0.1599, -0.0105,  0.1326,  0.0036, -0.1401,\n",
      "           0.0973,  0.0109, -0.1591,  0.0937,  0.0096,  0.1291, -0.1132,\n",
      "          -0.1922,  0.0137,  0.0528,  0.3568, -0.1185,  0.0409,  0.0080,\n",
      "           0.1723, -0.0488,  0.1327, -0.1361, -0.0216, -0.1752, -0.0968,\n",
      "           0.0054,  0.0557,  0.0861, -0.1783, -0.0812, -0.0445, -0.1422,\n",
      "          -0.1391,  0.1151,  0.0270, -0.0648, -0.2586,  0.1457, -0.3474,\n",
      "           0.1054, -0.1598, -0.2625, -0.1821,  0.2068,  0.0443, -0.0108,\n",
      "          -0.1427, -0.1946,  0.0471,  0.0092, -0.2583,  0.3099,  0.0541,\n",
      "           0.1281,  0.1383, -0.0278,  0.2736, -0.0132,  0.0461, -0.1517,\n",
      "          -0.0805,  0.0707,  0.0820, -0.1877, -0.3806,  0.1041,  0.1224,\n",
      "           0.0494, -0.2361, -0.0119,  0.0228,  0.0428, -0.1795,  0.1723,\n",
      "           0.2864,  0.1778, -0.0208, -0.2192,  0.0633,  0.0366,  0.0947,\n",
      "           0.0045, -0.2466, -0.2711,  0.0863, -0.2313,  0.2392, -0.0569,\n",
      "          -0.1596,  0.0477,  0.2766, -0.0011]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1419, -1.3597, -0.6634,  1.6814,  2.4831,  0.3643,  1.3996,\n",
      "          -0.9368, -0.7145, -0.2962, -0.5817, -0.2201,  2.5563, -1.0552,\n",
      "           2.1829,  0.2162,  0.3038,  0.0000,  0.9578,  0.2218, -1.5416,\n",
      "          -1.1547,  0.9480, -1.8147,  0.0000,  1.5214,  1.7257, -0.8834,\n",
      "          -0.2970, -0.3665, -1.4558, -1.3883, -0.6739,  0.0893,  1.0594,\n",
      "           0.6829, -1.4603,  2.1382,  0.1808,  1.9590,  0.3993, -0.1963,\n",
      "           1.3082,  0.8319,  1.4218,  0.3936,  0.3496,  0.1075, -1.1253,\n",
      "          -0.8444,  0.0000,  0.9799, -2.5886,  1.2122,  1.6780,  0.2126,\n",
      "           0.0177,  0.0000,  1.0115,  1.4964, -0.8581, -1.2764, -2.4447,\n",
      "          -0.1825, -0.8674, -0.1021,  0.3198, -1.1793,  1.1064, -0.3299,\n",
      "          -0.4428,  0.4201, -0.4835, -1.3158,  1.7192,  1.4826, -0.6503,\n",
      "           2.5036, -0.3946, -0.8127,  0.0000,  0.3517, -0.0580,  0.0000,\n",
      "           0.0000,  0.0000,  2.1727, -0.0545, -1.7540,  0.2433, -0.1547,\n",
      "          -0.5267, -1.8709,  1.9172,  1.0335,  0.0000,  0.0982, -0.2966,\n",
      "           0.0000, -1.0472, -1.1854,  0.0000, -0.0581, -0.2456,  0.1055,\n",
      "          -0.9798,  2.6333,  2.2529,  0.4400,  0.1307,  0.0000,  0.5217,\n",
      "          -0.3205,  0.2415, -0.0771, -1.0749,  1.5986, -0.2633, -0.7199,\n",
      "          -0.2745, -0.2476,  1.7813,  0.0000, -0.6458,  0.0187,  0.6757,\n",
      "          -1.3007, -0.1072,  0.0000, -0.9825,  1.2401, -1.1603, -1.4888,\n",
      "          -0.5446, -2.3546, -0.8535,  0.0000, -0.9834,  1.4212, -1.0899,\n",
      "           0.5350,  1.8844,  0.4641, -0.8877,  0.0000, -0.8941,  2.4422,\n",
      "          -0.3703, -1.5689, -0.7335, -0.8483, -0.5475, -2.5835,  0.9103,\n",
      "          -0.3373, -0.7973, -0.0163,  0.9336, -0.4494, -1.7376,  0.6849,\n",
      "           1.1303,  0.9740,  0.2741,  0.4456, -2.8164,  0.1089, -1.1756,\n",
      "          -0.1290,  0.5756, -0.1556,  0.0000,  0.0000, -0.1765, -0.1689,\n",
      "          -0.5096, -0.7970, -0.1949,  0.9826,  0.1115,  1.1969, -0.1844,\n",
      "          -0.7670,  0.0000, -2.4943, -1.8722,  0.9570, -0.9258, -0.1131,\n",
      "           0.5709,  0.1744,  2.1623, -0.6165,  1.3762, -0.0819, -0.5877,\n",
      "           1.7686,  0.3900, -0.1344,  0.9389, -0.4709, -1.1040, -1.6429,\n",
      "           1.4438,  0.7059,  0.0000,  0.0000, -0.6063,  0.0000, -1.2553,\n",
      "          -0.6819, -1.8652,  2.1896, -1.7825,  0.7082, -0.9350, -1.7242,\n",
      "          -1.9960, -1.1670, -0.4401,  0.0801,  0.0000, -1.3408, -0.3620,\n",
      "           0.0957,  0.3167, -1.1972, -1.2609, -1.4067,  0.3963,  0.0000,\n",
      "          -1.5161,  1.1266, -0.6660, -0.0695,  0.8233, -1.2880, -0.6049,\n",
      "          -0.6457,  0.5976,  0.0850,  0.8707,  0.4313, -1.8476,  0.0607,\n",
      "           0.5830,  0.6049,  1.2980, -0.4213, -1.1536, -1.6780, -1.5688,\n",
      "          -1.2527,  0.0000,  0.3588, -0.4895]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0487, 0.1228, 0.1781, 0.0383, 0.1482, 0.2340, 0.0631, 0.0537, 0.0890,\n",
      "         0.0242]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0052,  0.4047, -0.0120,  ...,  0.1333,  0.0975, -0.2313],\n",
      "        [ 0.2553,  0.2838, -0.3162,  ..., -0.1561,  0.2047, -0.2780],\n",
      "        [-0.2428, -0.0796, -0.3676,  ...,  0.1311,  0.2009,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 5.5775e-02,  7.1890e-02, -1.3265e-01, -1.7034e-01, -1.7073e-01,\n",
      "          -2.4414e-01, -2.6400e-01, -8.9545e-02, -1.0302e-01, -1.8351e-02,\n",
      "          -1.4086e-01,  6.3000e-02, -2.3135e-01, -1.1563e-01, -2.5784e-04,\n",
      "          -6.0047e-02,  7.7619e-02,  2.9195e-01, -1.6134e-02, -1.9130e-02,\n",
      "           8.4373e-02, -2.0349e-01,  1.8068e-01, -2.2429e-01, -2.1401e-01,\n",
      "           1.5470e-01,  5.5520e-02, -1.5332e-01,  3.6708e-02,  9.2800e-02,\n",
      "           2.6893e-01, -3.0616e-01, -3.9009e-02, -2.6523e-01,  5.2011e-02,\n",
      "           1.3956e-02, -1.5384e-01, -1.3392e-01, -1.7785e-01,  2.1361e-02,\n",
      "          -1.4471e-01,  1.2025e-01, -2.3922e-01, -1.4707e-01,  2.3108e-01,\n",
      "          -8.0486e-03,  1.2994e-01, -1.9445e-01,  2.0543e-01,  1.8788e-01,\n",
      "           9.7245e-02, -2.0243e-01, -2.3664e-01, -9.7360e-02, -6.0229e-02,\n",
      "          -1.4437e-01,  2.7281e-02,  2.3198e-02,  1.7048e-01,  1.5624e-01,\n",
      "          -3.4399e-01, -2.1496e-01, -1.9333e-01, -6.9941e-02, -1.9633e-02,\n",
      "           1.6643e-02,  3.7057e-02,  2.7581e-01, -2.2636e-01,  2.0259e-01,\n",
      "          -1.3482e-02,  1.1172e-02,  1.5091e-01,  2.5678e-01,  2.0822e-02,\n",
      "           1.9445e-01,  3.0429e-01,  2.4718e-02, -1.9795e-01,  1.5824e-01,\n",
      "           9.8840e-02,  2.7338e-02, -1.9149e-01,  1.6695e-01, -3.5708e-02,\n",
      "          -7.3923e-05,  1.2188e-01,  1.8880e-01,  1.8216e-01, -7.5449e-03,\n",
      "          -4.4997e-02,  1.2222e-01,  1.3533e-01, -1.6647e-01,  5.9422e-02,\n",
      "           1.6343e-01, -2.8060e-02,  8.8557e-02,  3.4439e-01,  3.9945e-01,\n",
      "          -9.8401e-02,  1.4255e-02, -5.6208e-02,  3.2249e-02,  1.6472e-01,\n",
      "           2.3243e-02,  2.5723e-01,  3.0034e-01, -2.5618e-02,  2.0215e-01,\n",
      "          -2.9792e-03,  1.3779e-01,  6.4358e-02, -1.0958e-01, -1.3423e-02,\n",
      "           3.0279e-02, -7.3606e-02,  1.8676e-02, -5.1680e-02, -2.4271e-01,\n",
      "           2.0017e-02,  2.0750e-01, -1.0501e-01,  1.0175e-01, -4.2895e-01,\n",
      "           5.2509e-02, -1.0400e-01, -2.9801e-02,  2.1416e-01,  7.3064e-02,\n",
      "          -4.6918e-02,  4.3989e-02,  1.7043e-01,  1.5349e-01,  7.6815e-02,\n",
      "          -1.2388e-01,  7.1775e-02,  1.8928e-01,  8.6938e-02,  1.7189e-01,\n",
      "          -2.2449e-01,  2.4061e-01, -3.0865e-01,  1.8470e-01, -1.7614e-01,\n",
      "          -1.3899e-03, -2.1168e-01,  1.5954e-01,  1.2779e-01,  1.6475e-01,\n",
      "          -1.7128e-01,  8.5165e-02, -2.8372e-02,  2.5163e-01, -3.3346e-02,\n",
      "           2.3321e-01,  8.4317e-02,  2.0378e-01, -2.4434e-01, -1.0105e-01,\n",
      "          -5.7426e-02, -4.9829e-02, -1.9630e-01,  2.1034e-01, -3.7145e-02,\n",
      "           1.4682e-01, -6.7853e-02, -1.6733e-01,  1.0329e-01,  1.0403e-04,\n",
      "          -1.8725e-01,  1.4291e-01,  4.5483e-02,  1.2369e-01, -9.6337e-02,\n",
      "          -2.0703e-01,  5.6621e-03,  7.5151e-02,  4.3876e-01, -1.0867e-01,\n",
      "           1.7774e-02, -2.4917e-02,  1.5833e-01, -3.9665e-02,  1.9261e-01,\n",
      "          -1.4635e-01,  5.6053e-04, -1.6900e-01, -1.4491e-01, -2.5675e-02,\n",
      "           6.9440e-02,  8.0539e-02, -1.9965e-01, -1.0457e-01, -1.0046e-01,\n",
      "          -1.7683e-01, -1.2212e-01,  6.4900e-02,  1.0547e-02, -7.6489e-02,\n",
      "          -2.6192e-01,  1.3664e-01, -3.9557e-01,  1.2693e-01, -2.0005e-01,\n",
      "          -2.7086e-01, -1.9558e-01,  2.2911e-01,  9.9587e-02, -4.8074e-02,\n",
      "          -1.8640e-01, -2.3868e-01,  6.7526e-02,  3.1857e-02, -2.7754e-01,\n",
      "           3.2149e-01,  9.7078e-02,  1.1207e-01,  1.0570e-01, -4.5797e-02,\n",
      "           2.9429e-01, -1.2640e-02,  5.9438e-02, -1.4364e-01, -4.6957e-02,\n",
      "           1.2122e-01,  7.5662e-02, -1.9175e-01, -4.8224e-01,  1.0959e-01,\n",
      "           1.4192e-01,  1.3154e-02, -2.3364e-01, -2.4197e-02,  4.8520e-02,\n",
      "           7.4846e-02, -1.8288e-01,  1.6034e-01,  3.5829e-01,  1.6166e-01,\n",
      "          -9.8916e-03, -2.2519e-01,  6.4136e-02,  4.8437e-02,  7.7648e-02,\n",
      "           3.2540e-02, -2.8574e-01, -3.0427e-01,  6.5529e-02, -2.8836e-01,\n",
      "           2.6886e-01, -4.3972e-02, -2.2538e-01, -1.1453e-02,  3.0839e-01,\n",
      "          -8.2487e-03]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0158,  0.0000,  0.3342,  1.5342,  1.4536,  0.0000,  0.0586,\n",
      "           1.4329, -1.2099,  0.5222, -0.3813, -0.5976, -0.6195, -3.6032,\n",
      "          -0.5597, -2.9972, -1.8805,  0.1566,  1.5818, -0.8009, -1.2239,\n",
      "           1.5984,  0.9079, -3.5174, -1.1440,  0.0000,  0.3023,  0.0480,\n",
      "          -0.8930,  2.1373, -0.0177,  0.4403,  0.8259, -0.4084, -1.0905,\n",
      "          -1.3907,  0.0000,  0.0000, -1.2988,  0.8931, -0.3284,  1.2294,\n",
      "          -0.3898,  0.5367,  2.1238,  0.0000,  0.2665, -0.0955,  2.0129,\n",
      "          -0.2960,  1.0795,  1.6321, -0.2084, -0.0089, -0.4891, -1.4275,\n",
      "           0.5720,  1.1553,  0.8962,  0.7171, -0.5675,  0.0297,  0.0000,\n",
      "          -0.1848,  0.2420,  0.0000,  1.4207, -0.4456,  0.3431,  1.7293,\n",
      "           0.0000, -0.6311,  2.7000,  0.3195,  1.5180,  0.8984,  1.6061,\n",
      "          -0.4704,  0.0000,  0.8594,  0.0593, -0.7682, -0.7797,  1.3584,\n",
      "           0.8048,  0.0000, -0.6461,  0.0000, -0.2369,  0.4543, -0.4125,\n",
      "           0.3489, -1.4365, -0.1565, -0.7525,  0.9902, -0.4041, -0.1232,\n",
      "          -1.4354, -0.9299, -1.2557, -2.3297,  2.8097, -2.0200, -0.2309,\n",
      "           0.3845, -0.6110,  1.3838,  1.0431, -0.9131,  0.1094,  0.6949,\n",
      "          -0.7565,  0.0000, -0.6487,  2.2081,  0.0236,  0.3517,  0.3078,\n",
      "           0.2626,  0.0000,  0.4032, -0.7460, -0.3065,  0.3121,  1.3444,\n",
      "          -2.9820,  0.2526, -2.2848,  0.8225,  0.1404,  0.5378,  0.0378,\n",
      "           0.0000,  0.9057,  0.6496,  1.2877, -0.8051,  0.9272,  0.6093,\n",
      "          -0.8743,  1.1540,  0.6978, -0.0554,  0.5371,  0.9662,  1.2913,\n",
      "           1.5008,  0.1403, -1.1057,  0.2927, -1.5330, -0.0251,  0.0000,\n",
      "           0.6010,  0.7956, -1.3342,  2.3698, -0.4097,  1.0964, -0.3905,\n",
      "           0.1987, -0.5917, -1.9579,  3.0988, -0.4004,  0.1329,  0.7598,\n",
      "           0.0000,  0.9235,  2.2765, -0.0830, -1.0744, -0.1260, -0.5775,\n",
      "          -0.0077, -0.1820,  0.5838, -1.3325, -0.2691,  0.6170,  0.1904,\n",
      "          -0.6725, -0.6157,  0.1016, -0.6313, -0.1083, -0.5689, -1.2352,\n",
      "           0.0000,  1.6211, -1.0027, -0.3643,  0.0796,  1.0316,  1.0638,\n",
      "           0.0000,  0.0000, -1.1227, -1.6262,  1.6046, -0.8299,  0.4840,\n",
      "          -0.2218,  1.4008,  0.0000,  0.3005, -0.5277, -1.2539, -0.1524,\n",
      "           0.1547, -0.7677, -0.6322,  1.9749, -0.2695, -1.1452,  2.3264,\n",
      "           2.3894,  1.0577,  0.0832,  1.5381,  1.3391, -0.0460, -0.7570,\n",
      "          -0.8246,  1.6277, -3.1527, -0.4989,  1.7203,  0.9963,  1.1950,\n",
      "           0.4302,  0.0000,  0.8688,  0.0000, -1.6457,  0.4951,  0.2143,\n",
      "          -1.9270,  0.4541, -1.5748,  0.2428, -1.4219, -0.7874,  0.4437,\n",
      "          -0.8336, -1.7103, -0.0364, -0.0480,  1.0825, -0.5091, -0.1538,\n",
      "           1.9502, -1.0377,  0.0455, -0.0646]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0519, 0.1112, 0.1531, 0.0488, 0.1614, 0.1738, 0.0643, 0.0982, 0.0650,\n",
      "         0.0725]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0052,  0.4047, -0.0120,  ...,  0.1333,  0.0975, -0.2313],\n",
      "        [ 0.2553,  0.2838, -0.3162,  ..., -0.1561,  0.2047, -0.2780],\n",
      "        [-0.2428, -0.0796, -0.3676,  ...,  0.1311,  0.2009,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0335,  0.0684, -0.1103, -0.1479, -0.1632, -0.2231, -0.2262,\n",
      "          -0.0705, -0.0934, -0.0060, -0.1282,  0.0591, -0.1884, -0.1258,\n",
      "          -0.0046, -0.0577,  0.0790,  0.2546,  0.0086, -0.0055,  0.0756,\n",
      "          -0.1847,  0.1493, -0.2017, -0.1991,  0.1299,  0.0307, -0.1262,\n",
      "           0.0290,  0.0753,  0.2321, -0.2691, -0.0337, -0.2208,  0.0534,\n",
      "           0.0146, -0.1306, -0.1191, -0.1557,  0.0094, -0.1281,  0.0916,\n",
      "          -0.2132, -0.1343,  0.2264, -0.0281,  0.1264, -0.1732,  0.1822,\n",
      "           0.1786,  0.0825, -0.1826, -0.2093, -0.0840, -0.0567, -0.1551,\n",
      "           0.0301,  0.0220,  0.1468,  0.1457, -0.3220, -0.1835, -0.1668,\n",
      "          -0.0779, -0.0079,  0.0150,  0.0435,  0.2348, -0.1909,  0.1710,\n",
      "          -0.0420, -0.0133,  0.1348,  0.2323,  0.0246,  0.1634,  0.2601,\n",
      "           0.0139, -0.1880,  0.1416,  0.0931,  0.0107, -0.1576,  0.1469,\n",
      "          -0.0320,  0.0070,  0.0971,  0.1635,  0.1496, -0.0189, -0.0525,\n",
      "           0.1196,  0.1355, -0.1481,  0.0553,  0.1333, -0.0353,  0.0833,\n",
      "           0.3021,  0.3574, -0.0908, -0.0118, -0.0521,  0.0265,  0.1400,\n",
      "           0.0311,  0.2247,  0.2589, -0.0115,  0.1718,  0.0047,  0.1184,\n",
      "           0.0606, -0.0941, -0.0112,  0.0211, -0.0696,  0.0243, -0.0388,\n",
      "          -0.2206,  0.0250,  0.1932, -0.0797,  0.0847, -0.3801,  0.0544,\n",
      "          -0.1008, -0.0096,  0.1946,  0.0758, -0.0377,  0.0328,  0.1638,\n",
      "           0.1230,  0.0705, -0.1059,  0.0585,  0.1560,  0.0786,  0.1369,\n",
      "          -0.1902,  0.2233, -0.2840,  0.1772, -0.1660,  0.0035, -0.2016,\n",
      "           0.1214,  0.1088,  0.1478, -0.1375,  0.0609, -0.0168,  0.2238,\n",
      "          -0.0505,  0.1924,  0.0834,  0.1785, -0.2219, -0.0931, -0.0379,\n",
      "          -0.0510, -0.1675,  0.1730, -0.0129,  0.1369, -0.0382, -0.1477,\n",
      "           0.1059,  0.0181, -0.1645,  0.1226,  0.0332,  0.1098, -0.0954,\n",
      "          -0.1793,  0.0095,  0.0622,  0.3900, -0.0924,  0.0340, -0.0132,\n",
      "           0.1567, -0.0327,  0.1607, -0.1299, -0.0128, -0.1530, -0.1125,\n",
      "          -0.0137,  0.0561,  0.0723, -0.1802, -0.0935, -0.0766, -0.1487,\n",
      "          -0.1282,  0.0668,  0.0166, -0.0632, -0.2553,  0.1279, -0.3619,\n",
      "           0.1207, -0.1737, -0.2434, -0.1844,  0.1970,  0.0825, -0.0224,\n",
      "          -0.1538, -0.2133,  0.0586,  0.0203, -0.2538,  0.2992,  0.0708,\n",
      "           0.1013,  0.1103, -0.0308,  0.2695, -0.0193,  0.0472, -0.1350,\n",
      "          -0.0531,  0.1039,  0.0775, -0.1700, -0.4223,  0.0983,  0.1182,\n",
      "           0.0287, -0.2104, -0.0171,  0.0414,  0.0687, -0.1587,  0.1576,\n",
      "           0.3064,  0.1468, -0.0093, -0.2010,  0.0546,  0.0326,  0.0756,\n",
      "           0.0326, -0.2550, -0.2671,  0.0702, -0.2459,  0.2465, -0.0441,\n",
      "          -0.2018,  0.0108,  0.2736, -0.0075]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7262e-01, -4.3095e-01,  3.1516e-01, -1.0851e+00, -1.1729e+00,\n",
      "           7.4160e-01, -1.9147e+00,  1.3514e+00,  1.9012e-01,  6.1734e-01,\n",
      "           1.9037e+00,  6.0256e-01,  2.2915e-01, -9.1658e-01, -3.1839e+00,\n",
      "          -6.8320e-02, -1.6337e+00, -9.4355e-01,  1.3604e+00, -1.4358e+00,\n",
      "          -1.4036e-01,  0.0000e+00, -1.1198e+00, -2.5958e+00, -7.5913e-02,\n",
      "           1.3918e+00, -6.1985e-01,  1.9981e+00,  1.2774e-01,  5.5513e-01,\n",
      "           0.0000e+00, -3.7754e-03,  2.2233e-01,  0.0000e+00, -6.3585e-02,\n",
      "          -1.4086e+00, -1.1163e-01,  0.0000e+00,  0.0000e+00,  8.6107e-02,\n",
      "           8.6338e-01, -8.9931e-01,  1.0090e+00, -1.5640e+00,  1.9449e+00,\n",
      "          -3.0039e-01,  7.0635e-01, -6.0232e-01, -1.0209e+00,  1.1172e+00,\n",
      "          -1.3232e+00,  2.6782e+00,  6.6699e-01, -8.4706e-01,  0.0000e+00,\n",
      "          -3.1018e-01,  0.0000e+00, -9.6256e-02,  0.0000e+00,  2.1822e+00,\n",
      "          -1.0066e+00,  3.5885e-02, -2.8020e-01,  2.6578e-01, -6.3198e-02,\n",
      "           3.9363e-01,  5.7811e-01,  0.0000e+00,  1.5811e+00, -1.4154e+00,\n",
      "           4.2735e-01,  2.9638e-01, -3.1072e-02, -7.9829e-01, -2.1420e-01,\n",
      "           1.3948e-01,  5.2603e-01,  1.3992e+00,  1.0274e+00, -7.9421e-01,\n",
      "           7.5849e-01, -1.0048e+00,  7.5836e-01,  1.0588e+00, -1.2155e+00,\n",
      "          -1.1330e-01, -1.1084e+00,  5.4869e-01, -9.4499e-01, -1.9014e+00,\n",
      "           5.2921e-01,  9.8735e-01,  1.7021e+00,  9.4428e-01,  6.0795e-01,\n",
      "          -1.5905e-02,  3.5435e-01,  0.0000e+00,  1.3725e+00,  0.0000e+00,\n",
      "           2.4348e-01,  4.4154e-02, -4.6664e-01, -9.8952e-01,  1.6411e+00,\n",
      "          -1.0240e+00,  3.0300e+00,  6.2079e-01, -1.0196e-01, -1.2357e+00,\n",
      "           0.0000e+00, -5.0330e-01, -5.7110e-01,  7.1254e-01, -7.8087e-01,\n",
      "           6.3263e-01,  4.0379e-01,  2.2346e-01, -2.3273e+00,  2.9218e-02,\n",
      "          -8.1480e-01,  0.0000e+00, -1.8386e+00,  6.0325e-01, -9.5720e-01,\n",
      "          -2.0100e-01,  4.0297e-02,  2.1508e+00,  1.3966e+00,  0.0000e+00,\n",
      "           0.0000e+00,  4.4987e-01, -1.1682e+00,  4.2553e-01, -4.6829e-01,\n",
      "          -7.4629e-01, -1.0649e+00, -9.7552e-01, -1.9425e-02,  2.3980e+00,\n",
      "           6.9863e-01, -1.1219e+00,  1.6919e+00, -1.4043e-01,  0.0000e+00,\n",
      "           3.3291e-02,  0.0000e+00,  0.0000e+00, -1.0339e+00, -9.5266e-02,\n",
      "           1.5601e+00,  5.8676e-01, -3.3846e-01,  6.5775e-01,  0.0000e+00,\n",
      "          -2.5282e-01, -2.1785e-01,  6.2397e-01, -2.3638e+00,  1.0560e+00,\n",
      "           3.0286e-01, -7.7206e-02,  1.5524e-01, -1.2123e+00,  0.0000e+00,\n",
      "           1.6826e+00,  1.8527e+00,  2.7168e-01, -1.2704e+00, -7.1308e-01,\n",
      "          -1.2243e+00, -1.0943e+00, -2.5912e+00,  5.0587e-01, -3.0608e+00,\n",
      "          -2.8744e-01,  4.9760e-01,  8.2976e-01,  3.1708e-01,  0.0000e+00,\n",
      "           2.7248e-01,  2.3400e+00,  1.0583e+00,  8.3903e-01, -4.0245e-01,\n",
      "           7.2794e-01,  5.9869e-01,  3.5979e-01,  8.4314e-01, -1.8311e+00,\n",
      "           1.3638e+00,  2.1600e+00,  3.3588e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -2.2161e+00,  1.6677e+00,  2.1533e+00,  3.6340e-01,  2.3837e+00,\n",
      "           3.2524e-02,  0.0000e+00,  0.0000e+00, -5.4303e-01, -4.0767e-01,\n",
      "          -1.4477e+00,  9.5337e-01, -8.5208e-01,  8.2961e-01, -1.5605e+00,\n",
      "           6.3738e-01,  6.7556e-01,  0.0000e+00,  5.5273e-02,  1.8937e+00,\n",
      "           1.3090e+00,  5.8031e-01, -2.3179e+00,  1.5503e+00, -2.2253e-01,\n",
      "          -2.2734e-01,  1.7342e+00,  2.7657e-01, -1.5524e+00,  9.2283e-01,\n",
      "          -1.2244e+00, -8.4888e-01, -1.8025e+00, -7.0614e-04,  3.7323e-01,\n",
      "          -1.5739e+00, -1.2383e-01,  9.6636e-01, -1.7374e+00,  1.6947e+00,\n",
      "          -1.4405e+00,  6.3403e-01, -1.7229e+00,  9.8027e-01, -1.7171e+00,\n",
      "           1.5616e+00, -2.7297e-01, -2.5976e+00,  1.2392e+00, -1.2283e+00,\n",
      "           1.8865e+00, -5.0846e-01,  5.4285e-01, -2.6130e-01, -1.0224e+00,\n",
      "           1.3339e+00,  3.1130e-01, -5.1005e-02,  0.0000e+00, -1.6130e+00,\n",
      "           1.8071e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0413, 0.1134, 0.1187, 0.0820, 0.2137, 0.1142, 0.1141, 0.0495, 0.0900,\n",
      "         0.0632]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0052,  0.4047, -0.0120,  ...,  0.1333,  0.0975, -0.2313],\n",
      "        [ 0.2553,  0.2838, -0.3162,  ..., -0.1561,  0.2047, -0.2780],\n",
      "        [-0.2428, -0.0796, -0.3676,  ...,  0.1311,  0.2009,  0.0110],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.6659e-02,  8.7871e-02, -1.0964e-01, -1.4834e-01, -2.1188e-01,\n",
      "          -2.4754e-01, -1.8937e-01, -7.2666e-02, -1.0302e-01,  1.3604e-02,\n",
      "          -1.2112e-01,  5.1827e-02, -1.6279e-01, -1.6171e-01,  2.2245e-02,\n",
      "          -6.6883e-02,  8.2516e-02,  2.5092e-01,  6.4711e-03,  7.4469e-03,\n",
      "           7.2881e-02, -2.0597e-01,  1.2728e-01, -1.8425e-01, -2.2996e-01,\n",
      "           9.1207e-02, -2.0989e-02, -1.1407e-01,  1.9480e-03,  6.7759e-02,\n",
      "           2.3533e-01, -2.7219e-01, -5.1515e-02, -2.2240e-01,  8.6246e-02,\n",
      "           1.8370e-03, -1.3024e-01, -1.2211e-01, -1.6090e-01,  6.2682e-03,\n",
      "          -1.0896e-01,  5.8683e-02, -2.1915e-01, -1.3100e-01,  2.6293e-01,\n",
      "          -4.9210e-02,  1.3807e-01, -2.1458e-01,  1.8260e-01,  1.8666e-01,\n",
      "           5.4072e-02, -1.9360e-01, -2.2412e-01, -6.2377e-02, -5.9692e-02,\n",
      "          -1.9557e-01,  4.1926e-02,  5.6938e-02,  1.4290e-01,  1.8458e-01,\n",
      "          -3.3992e-01, -1.7720e-01, -1.8953e-01, -1.0014e-01, -9.1759e-03,\n",
      "           1.1212e-02,  3.6498e-02,  2.1783e-01, -1.6892e-01,  1.4699e-01,\n",
      "          -1.0348e-01, -3.0499e-02,  1.2295e-01,  2.4325e-01,  1.2794e-02,\n",
      "           1.5803e-01,  2.4636e-01,  2.4421e-02, -2.2073e-01,  1.5175e-01,\n",
      "           8.9046e-02, -4.2278e-02, -1.5888e-01,  1.2388e-01, -5.1797e-02,\n",
      "           4.1552e-02,  7.1760e-02,  1.6684e-01,  1.5668e-01, -5.5525e-02,\n",
      "          -6.9867e-02,  1.2182e-01,  1.6326e-01, -1.2355e-01,  6.7103e-02,\n",
      "           1.2678e-01, -5.2097e-02,  1.1280e-01,  2.7619e-01,  3.6459e-01,\n",
      "          -1.0346e-01, -2.9280e-02, -4.6958e-02,  2.2603e-02,  1.0374e-01,\n",
      "           2.4750e-02,  2.0605e-01,  2.6744e-01,  9.2887e-03,  1.8276e-01,\n",
      "           3.0300e-02,  9.2533e-02,  8.5931e-02, -1.0590e-01, -3.5157e-02,\n",
      "           1.7181e-02, -6.6138e-02,  2.6323e-02, -2.8195e-02, -2.3401e-01,\n",
      "           5.1430e-02,  1.8307e-01, -8.3032e-02,  7.5415e-02, -3.8867e-01,\n",
      "           6.5746e-02, -1.3081e-01,  3.6494e-02,  2.1612e-01,  7.8473e-02,\n",
      "          -1.7815e-02, -1.2624e-02,  2.1419e-01,  1.1180e-01,  5.9033e-02,\n",
      "          -8.3651e-02,  6.7797e-02,  1.4215e-01,  4.8919e-02,  1.3520e-01,\n",
      "          -1.9223e-01,  2.6483e-01, -3.0565e-01,  2.0718e-01, -1.6007e-01,\n",
      "          -4.5317e-03, -2.2604e-01,  9.6785e-02,  1.1852e-01,  1.4979e-01,\n",
      "          -1.6360e-01,  5.3128e-02,  4.9049e-03,  2.3835e-01, -6.8570e-02,\n",
      "           1.8263e-01,  9.8410e-02,  1.7487e-01, -1.9055e-01, -1.0169e-01,\n",
      "          -1.8612e-02, -7.6546e-02, -1.8231e-01,  1.6811e-01,  4.1079e-02,\n",
      "           1.7838e-01, -6.9247e-03, -1.4518e-01,  1.4287e-01,  7.3856e-02,\n",
      "          -1.8817e-01,  1.2497e-01,  2.8698e-02,  1.1907e-01, -1.1416e-01,\n",
      "          -1.6407e-01, -1.0502e-04,  7.4604e-02,  4.0521e-01, -1.0187e-01,\n",
      "           6.3499e-02, -1.3424e-02,  1.6328e-01, -4.1240e-02,  1.6958e-01,\n",
      "          -1.0946e-01, -5.6800e-02, -1.3463e-01, -5.3574e-02, -1.8862e-02,\n",
      "           4.0967e-02,  1.0573e-01, -1.9961e-01, -1.0063e-01, -4.4826e-02,\n",
      "          -1.4689e-01, -1.9111e-01,  1.0413e-01,  1.8780e-03, -3.1909e-02,\n",
      "          -2.8259e-01,  1.5898e-01, -3.6650e-01,  1.7372e-01, -1.6612e-01,\n",
      "          -2.4903e-01, -1.8443e-01,  2.0482e-01,  4.1509e-02,  1.3915e-02,\n",
      "          -1.0325e-01, -2.4354e-01,  4.9798e-02,  4.1757e-02, -2.7275e-01,\n",
      "           3.3666e-01,  3.4453e-02,  1.3730e-01,  1.2069e-01,  7.8484e-03,\n",
      "           2.9645e-01, -5.7011e-02,  8.0168e-02, -1.5517e-01, -4.8331e-02,\n",
      "           1.1608e-01,  1.1989e-01, -1.8422e-01, -4.2355e-01,  1.1493e-01,\n",
      "           7.5253e-02,  5.2962e-02, -2.2623e-01, -3.4317e-02,  2.1749e-02,\n",
      "           6.7108e-02, -1.5492e-01,  1.8242e-01,  2.7994e-01,  1.5147e-01,\n",
      "          -1.3119e-02, -2.2454e-01,  2.0026e-02,  2.1945e-02,  7.6914e-02,\n",
      "           5.2591e-02, -2.6499e-01, -2.7066e-01,  1.1344e-01, -2.0461e-01,\n",
      "           2.5686e-01, -5.5182e-02, -2.1670e-01,  3.4850e-02,  2.7386e-01,\n",
      "           6.8125e-03]]], device='cuda:0', grad_fn=<BmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5780e-02,  0.0000e+00, -9.6700e-01, -6.8192e-01,  3.7638e-01,\n",
      "          -2.0185e-01,  1.4649e+00, -8.3284e-02, -3.5853e+00,  9.0676e-01,\n",
      "           4.2897e-01, -6.2924e-01,  2.6059e+00, -6.2974e-01, -5.4163e-01,\n",
      "          -1.5801e-01,  8.5169e-01,  1.0951e+00,  4.5519e-01,  4.3611e-01,\n",
      "          -6.3384e-01, -3.8365e-01,  1.6422e+00,  1.5115e+00,  7.5389e-01,\n",
      "          -7.5330e-02, -1.8776e-01, -7.5909e-01,  1.6541e+00,  8.6169e-01,\n",
      "           1.2321e+00,  1.2192e+00, -1.0344e+00, -8.2655e-02, -1.5351e+00,\n",
      "           1.3954e+00,  2.8085e-01, -3.7460e+00,  1.9807e-01,  1.6015e+00,\n",
      "          -4.5883e-01, -1.3989e+00,  0.0000e+00, -1.7168e+00,  0.0000e+00,\n",
      "           6.6734e-01,  0.0000e+00,  3.7020e-01, -1.3411e+00,  1.4383e-01,\n",
      "          -6.2892e-01,  2.7534e+00,  0.0000e+00, -1.0298e+00, -2.5753e-02,\n",
      "           2.0299e-01, -8.8243e-01, -1.2532e+00, -2.3656e-01, -4.2521e-01,\n",
      "           1.1014e+00,  1.4086e+00, -2.0369e-01, -5.0202e-01, -2.9653e+00,\n",
      "           5.5052e-01,  1.2793e+00, -1.2884e+00,  4.1170e-01,  5.2646e-01,\n",
      "          -1.2675e+00, -3.0435e-02,  7.0746e-01, -3.6426e+00,  3.2649e-01,\n",
      "          -2.2984e-03, -1.5986e-01,  1.0631e+00,  0.0000e+00, -1.2007e-01,\n",
      "          -1.4006e+00,  2.1321e+00, -9.2505e-01,  1.0058e+00, -2.0791e-01,\n",
      "           0.0000e+00,  0.0000e+00, -9.7495e-01, -1.0323e-01, -5.8155e-01,\n",
      "          -2.2744e+00,  1.1005e+00, -6.2231e-01, -1.1354e+00,  4.6750e-01,\n",
      "          -1.1710e+00,  3.4382e-02,  6.2928e-01,  1.7207e+00, -7.8060e-01,\n",
      "           2.6980e+00, -1.4631e+00,  1.0761e+00,  0.0000e+00, -6.6655e-01,\n",
      "          -7.6261e-01,  1.2130e+00,  1.2745e-01, -1.4732e+00, -1.3041e-02,\n",
      "          -2.4894e-01,  1.3454e-01,  0.0000e+00,  1.3104e+00, -1.6541e+00,\n",
      "          -2.9908e+00, -5.6260e-02, -5.0154e-01, -1.9319e-01,  4.4474e-01,\n",
      "          -1.4673e+00,  0.0000e+00, -1.4610e+00, -7.2641e-01, -9.5881e-01,\n",
      "          -1.3096e+00,  8.9787e-01,  1.7050e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -8.2323e-01,  5.2974e-01, -1.5836e+00,  9.8426e-01,  2.7616e-01,\n",
      "          -5.8964e-01,  6.6007e-01,  5.7331e-01, -1.1586e+00, -1.0107e+00,\n",
      "          -3.8907e-01,  6.7786e-01, -7.9023e-01, -1.0175e-01,  0.0000e+00,\n",
      "           0.0000e+00, -5.4334e-01, -8.4462e-01, -7.5562e-01,  1.7740e-01,\n",
      "           1.9993e+00,  0.0000e+00, -1.9313e+00, -4.0628e-01,  4.4158e-01,\n",
      "          -1.9448e-01, -6.4064e-02, -1.2902e-01,  3.9501e-02,  5.3771e-01,\n",
      "          -2.6163e-02,  2.2068e+00,  4.8119e-01, -5.4973e-01, -5.2756e-01,\n",
      "          -8.9307e-01,  2.8178e-01,  8.4680e-02, -3.5802e-01, -4.7818e-01,\n",
      "           7.3836e-01, -3.2422e-02,  1.9858e-02,  0.0000e+00,  0.0000e+00,\n",
      "          -1.0993e+00, -9.8804e-01, -2.0780e+00,  1.9699e+00,  8.6417e-02,\n",
      "          -2.9759e-02,  3.5084e-02,  6.7170e-01,  9.7987e-01, -7.4698e-01,\n",
      "          -3.4098e-01, -2.7844e+00, -7.8484e-01,  0.0000e+00,  1.0126e+00,\n",
      "           3.0755e+00,  4.9456e-01, -1.4417e-01, -5.9483e-01,  5.6091e-01,\n",
      "           2.1660e+00, -1.1884e+00,  5.3481e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2418e+00, -1.2216e-01,  2.3194e-01,\n",
      "          -5.7550e-01, -2.2935e+00,  6.8195e-01, -1.0749e+00, -4.7150e-01,\n",
      "           0.0000e+00, -5.7333e-01, -3.4124e-01,  7.9340e-01,  2.9855e-02,\n",
      "          -6.8492e-01, -1.0198e+00,  9.6632e-01,  0.0000e+00,  2.1702e+00,\n",
      "           0.0000e+00, -4.2769e-01, -1.8443e+00, -5.0166e-01,  3.3719e-01,\n",
      "           7.0484e-01, -6.9657e-01, -6.2813e-01,  2.9227e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.5817e+00, -6.1434e-01,  1.3098e+00,  0.0000e+00,\n",
      "           4.0369e+00,  5.8518e-01,  4.3555e-02, -1.5808e+00, -2.8764e-01,\n",
      "           7.4155e-01, -3.2495e+00, -3.0474e-01, -8.5271e-01,  1.1091e-02,\n",
      "           2.7530e-01,  2.7507e-01,  2.5271e-01,  2.6100e-01,  0.0000e+00,\n",
      "          -3.6562e-01, -1.5837e-01, -5.5421e-01, -5.2661e-02, -1.1473e+00,\n",
      "          -1.1316e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0483, 0.0620, 0.0627, 0.0510, 0.1558, 0.3088, 0.0417, 0.0713, 0.0558,\n",
      "         0.1426]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1881, -0.2015,  0.5954,  ...,  0.0925, -0.1263, -0.4134],\n",
      "        [ 0.0225, -0.5021,  0.5810,  ..., -0.3205, -0.0868, -0.2771],\n",
      "        [ 0.1102,  0.0330,  0.2879,  ...,  0.0649,  0.0909,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1984, -0.1270, -0.1547,  0.1177,  0.0076, -0.1339,  0.0688,\n",
      "          -0.1280, -0.0750,  0.1830,  0.0435,  0.0097, -0.0621,  0.0447,\n",
      "           0.1518, -0.1032, -0.0271,  0.1544, -0.1805,  0.0857, -0.2220,\n",
      "          -0.2970,  0.0522, -0.0579,  0.0096, -0.0210, -0.0820, -0.2842,\n",
      "          -0.0876,  0.2019,  0.1756, -0.1720, -0.2528, -0.1904,  0.1348,\n",
      "          -0.0387,  0.1331,  0.0693,  0.0282,  0.1232,  0.1190,  0.3485,\n",
      "          -0.0892,  0.0270, -0.0217,  0.0964, -0.1446, -0.1067, -0.0862,\n",
      "          -0.0778, -0.0986,  0.0194, -0.1245, -0.0707,  0.1380,  0.0289,\n",
      "          -0.0352, -0.0488,  0.1393,  0.3381, -0.0423, -0.0732, -0.0083,\n",
      "           0.2647, -0.1340, -0.0157, -0.0871,  0.1627, -0.1158,  0.1597,\n",
      "           0.1507, -0.0129, -0.0437,  0.0822, -0.2125,  0.0436,  0.1685,\n",
      "           0.2671,  0.1132,  0.0656,  0.1352,  0.0228, -0.1606,  0.1096,\n",
      "          -0.0879,  0.1409,  0.1484,  0.2061,  0.0596,  0.1844,  0.3400,\n",
      "          -0.0227,  0.0594,  0.0873, -0.0066,  0.1832, -0.0207,  0.0887,\n",
      "           0.2633,  0.2037, -0.1047,  0.1444,  0.1248, -0.0493,  0.1577,\n",
      "          -0.1463,  0.1792,  0.1620,  0.0718,  0.1951,  0.0225,  0.1814,\n",
      "          -0.3136, -0.0559, -0.2254,  0.0524, -0.1202, -0.0169, -0.1457,\n",
      "          -0.0111,  0.1625, -0.0027, -0.2653,  0.2354, -0.3052, -0.2361,\n",
      "          -0.0807, -0.0025,  0.0043, -0.0896,  0.1940, -0.2951,  0.2116,\n",
      "           0.2760,  0.2170,  0.0653,  0.1932,  0.2625,  0.0677,  0.3634,\n",
      "          -0.2109,  0.0942, -0.3100,  0.0809,  0.0506, -0.1797,  0.0361,\n",
      "           0.1618,  0.1482,  0.2343, -0.1662,  0.1744, -0.2274,  0.0700,\n",
      "           0.0794,  0.2305,  0.1047,  0.1097, -0.0907, -0.0864, -0.1410,\n",
      "          -0.1374, -0.1022,  0.0820, -0.1958, -0.0154, -0.2843,  0.0821,\n",
      "           0.1464,  0.2885, -0.0518, -0.0462,  0.2362, -0.0056, -0.1311,\n",
      "          -0.0147,  0.0856,  0.2932,  0.1438, -0.0524, -0.2219, -0.0513,\n",
      "          -0.1306, -0.0048,  0.2108,  0.0961, -0.0398,  0.2536, -0.0136,\n",
      "           0.0900,  0.0818, -0.1318, -0.1634, -0.1801, -0.3429, -0.2706,\n",
      "           0.0330, -0.0120, -0.1143, -0.2684,  0.0485, -0.0729, -0.1804,\n",
      "           0.0589, -0.0612,  0.0248, -0.0951,  0.1068,  0.1534, -0.2496,\n",
      "          -0.2589,  0.1326, -0.1008,  0.1250, -0.0243,  0.1799,  0.0910,\n",
      "          -0.1969, -0.0041,  0.1532,  0.0731, -0.1561, -0.1421, -0.0317,\n",
      "          -0.0467,  0.1908,  0.0331, -0.1754, -0.1835,  0.1640,  0.0757,\n",
      "          -0.2183, -0.1345,  0.1393,  0.0915, -0.0052, -0.1840, -0.0009,\n",
      "           0.2914,  0.1369,  0.1853, -0.1688, -0.0836, -0.1161,  0.0955,\n",
      "          -0.0546, -0.1236,  0.0849,  0.1084, -0.2621,  0.1369,  0.2228,\n",
      "          -0.0924, -0.0669,  0.1759, -0.0541]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1549, -1.4817,  1.6542, -1.0095, -1.1128,  0.4006,  0.6460,\n",
      "          -1.2225, -0.9023,  0.0000, -0.2097,  0.3159,  0.1272, -0.9577,\n",
      "          -0.3085,  0.3244, -1.8654, -2.1363,  0.6083,  0.0000,  0.7695,\n",
      "           0.2829, -1.2568, -0.9729,  1.1925,  0.0000,  0.0000,  1.0544,\n",
      "           0.9845, -1.2884,  0.3067, -0.9455, -0.7690, -1.5226, -0.3683,\n",
      "           0.4840,  0.0000, -0.3510,  0.3282,  0.6282,  0.6073, -1.1768,\n",
      "           0.3727,  1.2540, -1.7954,  1.9479, -1.4980, -0.4428, -0.2787,\n",
      "           1.1464,  0.8651,  0.0365, -0.0721, -1.0044, -0.2961, -0.8050,\n",
      "           0.0000,  0.5099,  1.5731,  2.0578, -0.8819,  0.0000,  1.9471,\n",
      "          -0.9063, -0.8593,  0.1078,  0.6388, -0.6173,  0.0211,  0.4296,\n",
      "           0.0000, -0.0283, -0.6441,  1.4257, -0.4461,  0.5579, -3.6197,\n",
      "          -0.6177, -1.4065, -0.3110,  0.0000,  1.3124,  0.8811, -0.9604,\n",
      "           0.6943,  0.6933,  0.0461, -2.9899,  0.8148, -0.0185, -1.4909,\n",
      "           0.3247, -1.2889,  2.3924,  1.8842,  0.2150, -1.1102,  1.0776,\n",
      "           1.5508, -2.1247,  0.0145, -0.6639, -1.1343, -1.8825,  0.4069,\n",
      "           1.4168, -1.9889, -0.9154,  0.4129,  0.0000, -1.4324,  0.1791,\n",
      "          -0.4976,  1.3004, -0.1466,  0.0000,  0.0000, -1.6426,  0.0000,\n",
      "          -1.2944,  0.0000, -0.0995,  0.8783,  0.5348,  0.2247,  0.0000,\n",
      "          -0.2024, -1.0699,  0.1247, -0.4278, -1.2477,  2.3284,  1.4194,\n",
      "           0.3274, -0.0090, -0.6385,  0.0000,  0.0000, -0.4515,  1.0983,\n",
      "           0.5454,  0.0000, -2.2952, -0.8858,  0.2166, -0.1880,  0.9174,\n",
      "           0.0000,  1.5432, -0.7186,  0.3218, -1.3513,  1.8153, -1.9311,\n",
      "           0.5129, -0.3341, -0.2286, -0.7581,  0.9341, -0.0179,  0.2298,\n",
      "          -1.1455,  2.2618,  0.0000, -0.3901, -0.6922,  0.5300,  2.1358,\n",
      "           0.0000, -2.7424,  1.2543, -2.0855, -0.0063, -1.1601, -0.9213,\n",
      "          -0.7984,  0.0000, -0.4306,  0.0000, -1.5138,  0.1503, -0.4530,\n",
      "           0.1994,  0.9701,  0.0000, -0.0759, -1.5022, -0.2143,  0.4036,\n",
      "          -1.4625,  1.0715,  0.6060,  0.5036, -0.5082,  0.7250, -0.0427,\n",
      "           1.8720,  0.0424, -0.8385, -0.2757,  0.1192, -0.2978,  0.2827,\n",
      "           0.3538, -0.0092, -0.7147,  0.0000,  2.0165, -0.7498,  1.8922,\n",
      "           2.7897,  0.1562,  1.5048,  0.1013,  0.0000, -0.0226, -0.1426,\n",
      "          -1.3819,  0.4082,  0.6376, -0.6885,  1.8592,  0.6066,  0.4727,\n",
      "           0.0289,  1.5295,  0.0000, -0.2608,  0.8418, -0.2543,  0.7766,\n",
      "          -0.5517,  1.2382,  0.0930,  2.0765,  0.5541, -1.7044,  0.0000,\n",
      "           0.0000,  1.8027, -0.8495,  0.2568, -1.0499, -0.8540,  0.1357,\n",
      "           0.0000,  0.3816,  0.0000,  0.5691,  0.5472, -1.7499,  0.3683,\n",
      "           0.0000,  1.5691, -2.7259,  0.4072]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0399, 0.1529, 0.1081, 0.0738, 0.1374, 0.1783, 0.0653, 0.0647, 0.0975,\n",
      "         0.0821]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1881, -0.2015,  0.5954,  ...,  0.0925, -0.1263, -0.4134],\n",
      "        [ 0.0225, -0.5021,  0.5810,  ..., -0.3205, -0.0868, -0.2771],\n",
      "        [ 0.1102,  0.0330,  0.2879,  ...,  0.0649,  0.0909,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1612, -0.1433, -0.0350,  0.1659,  0.0664, -0.0015,  0.0708,\n",
      "          -0.1246, -0.0357,  0.2581,  0.0459,  0.0311,  0.0644, -0.0317,\n",
      "           0.1479, -0.0634, -0.0543,  0.0829, -0.0462,  0.0341, -0.2290,\n",
      "          -0.2969,  0.0110, -0.0833,  0.0452, -0.0331, -0.1511, -0.3153,\n",
      "          -0.0534,  0.1272,  0.1107, -0.1083, -0.2783, -0.1928,  0.1273,\n",
      "          -0.0177,  0.1765,  0.0729,  0.0865,  0.1075,  0.1677,  0.3501,\n",
      "          -0.0695,  0.0629, -0.0245,  0.0488, -0.1388, -0.0774, -0.1506,\n",
      "          -0.0719, -0.0883,  0.0117, -0.1135, -0.0356,  0.2158,  0.0582,\n",
      "          -0.0422, -0.0547,  0.1059,  0.3663,  0.0180, -0.1029,  0.0292,\n",
      "           0.1989, -0.1116,  0.0668, -0.0423,  0.1175, -0.0302,  0.1384,\n",
      "           0.0492, -0.0068, -0.0478,  0.0419, -0.1614, -0.0338,  0.1257,\n",
      "           0.2865,  0.1117,  0.0272,  0.1024, -0.0008, -0.0612,  0.0714,\n",
      "          -0.0806,  0.2052,  0.1488,  0.1721,  0.0257,  0.1326,  0.3074,\n",
      "          -0.0151,  0.0594,  0.1468, -0.0576,  0.1355, -0.0400,  0.1045,\n",
      "           0.1862,  0.1455, -0.1180,  0.0744,  0.0911, -0.0678,  0.1694,\n",
      "          -0.1071,  0.0634,  0.0533,  0.0617,  0.1158,  0.0575,  0.1282,\n",
      "          -0.2934, -0.0669, -0.1694, -0.0220, -0.0769,  0.0162, -0.1005,\n",
      "           0.0102,  0.1661, -0.0376, -0.1453,  0.2095, -0.2514, -0.2652,\n",
      "          -0.1302,  0.0085, -0.0029, -0.0702,  0.1818, -0.2173,  0.2558,\n",
      "           0.2994,  0.1909,  0.0144,  0.2071,  0.2095,  0.0352,  0.3018,\n",
      "          -0.1711,  0.0393, -0.2617,  0.0979,  0.0296, -0.1258, -0.0164,\n",
      "           0.0750,  0.0991,  0.1144, -0.0644,  0.0809, -0.1369,  0.0917,\n",
      "           0.0366,  0.1528,  0.0570,  0.1111, -0.1126, -0.0096, -0.0495,\n",
      "          -0.0869, -0.0122,  0.0586, -0.1420,  0.0116, -0.2582,  0.1590,\n",
      "           0.2075,  0.3094,  0.0234, -0.0348,  0.2311, -0.0199, -0.1208,\n",
      "           0.0864,  0.1339,  0.2450,  0.0578,  0.0632, -0.1729, -0.0808,\n",
      "          -0.0841,  0.0270,  0.1270,  0.1311,  0.0237,  0.2197, -0.0118,\n",
      "           0.1353,  0.0296, -0.1325, -0.1365, -0.1754, -0.3645, -0.2921,\n",
      "          -0.0776, -0.0084, -0.1350, -0.2703,  0.0609, -0.1058, -0.0801,\n",
      "           0.0130, -0.1169,  0.0631, -0.0391,  0.1047,  0.1663, -0.1573,\n",
      "          -0.1685,  0.1447, -0.1196,  0.1733,  0.0044,  0.1722,  0.0731,\n",
      "          -0.2021,  0.0380,  0.1512,  0.0490, -0.1596, -0.1208, -0.0412,\n",
      "          -0.1038,  0.1740,  0.0619, -0.1504, -0.1675,  0.1913,  0.0501,\n",
      "          -0.1648, -0.0500,  0.1617,  0.0604,  0.0008, -0.1064, -0.0305,\n",
      "           0.2334,  0.1307,  0.1942, -0.1613, -0.0877, -0.1923,  0.0685,\n",
      "           0.0173, -0.0832,  0.1383,  0.1416, -0.1749,  0.1058,  0.2579,\n",
      "          -0.1218, -0.0624,  0.1092, -0.0553]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7782, -1.6519, -0.1827, -0.7320,  2.5180, -1.9079,\n",
      "          -0.0327,  0.9500,  1.1944,  1.4103, -0.7568, -0.0650,  0.0645,\n",
      "           1.0463,  0.0000,  0.8701, -0.7848, -0.6402, -1.4034, -0.4985,\n",
      "          -0.3791,  1.1426,  0.2329,  0.1893, -0.6130,  1.4042, -0.1511,\n",
      "          -1.0409,  0.4962, -0.5711,  0.6008,  0.0000,  0.2318, -0.0797,\n",
      "           0.1482,  0.6450, -2.2132,  0.0000,  0.1024, -0.6922, -0.4365,\n",
      "          -1.0644,  0.8181,  0.0000,  0.0000,  1.3726,  0.9367,  1.6036,\n",
      "           0.3696, -1.0080, -1.1720,  0.0000,  1.2530, -1.9748,  1.7090,\n",
      "           0.5928, -1.8922,  0.3416,  0.0000,  0.0000,  1.8690, -0.5940,\n",
      "          -1.6818, -0.8355,  1.2344, -0.3576,  0.2898,  0.0000, -1.1648,\n",
      "           2.2478,  0.7807,  0.2704,  0.0000, -0.3980,  0.3547,  0.2295,\n",
      "          -0.1574,  0.0000,  0.2959,  0.0000,  1.2866,  0.4651,  1.2969,\n",
      "           0.7705,  0.6607,  1.0453, -0.3683, -1.2412, -1.4363,  1.3106,\n",
      "          -1.5854, -0.1109,  3.2389,  0.3468,  1.0035, -0.8685,  0.7311,\n",
      "          -1.6815, -0.9243,  0.1908,  0.0000,  0.0000,  1.0585, -0.2310,\n",
      "           0.7759, -0.9059, -0.3677, -0.2785, -0.5476, -0.1378, -3.2782,\n",
      "          -0.1010,  0.0000,  1.6979,  1.6883,  2.0296, -1.6462, -0.8960,\n",
      "           2.5844, -1.3263,  1.4236, -0.6276,  0.4668,  1.3156, -0.9871,\n",
      "           0.0000, -0.9856, -0.6750,  0.2476, -1.2005,  1.1298,  1.1405,\n",
      "           1.4886,  0.3790,  0.6467, -0.8378,  0.2413,  0.0000, -1.2618,\n",
      "           0.0302,  0.8640,  0.5015,  0.9071, -1.2681, -0.6409, -0.4416,\n",
      "           0.8728, -0.0677,  0.0422, -0.0566,  0.6207,  0.1451,  0.0000,\n",
      "           0.1078, -1.6722, -0.4025,  0.2513, -2.0698,  0.4119,  0.0000,\n",
      "           0.1996,  0.0000,  0.8438,  0.4174,  1.6038,  0.1771, -1.1141,\n",
      "          -0.3225,  0.2508,  0.0000, -0.4550,  0.0000, -1.3452,  1.7357,\n",
      "           0.5175,  1.1772,  0.2896, -1.8322, -1.8662,  0.2595, -0.6475,\n",
      "          -1.1658,  0.3287,  0.0000,  0.5921, -1.2417, -1.5176, -2.3033,\n",
      "           0.1465, -1.6242, -1.3210,  0.0000,  1.2995,  0.9805, -1.4146,\n",
      "          -1.1402,  3.0137,  0.0000,  1.0328,  0.0000,  0.1190, -1.3197,\n",
      "          -1.0708,  0.0567,  1.7329,  0.5270,  1.9825, -0.9788, -1.3424,\n",
      "           1.5995, -0.4014,  2.4609, -0.5197,  0.7545,  0.2065, -0.8211,\n",
      "           0.9058, -3.5303,  0.1759, -0.7813, -0.6932, -1.4187,  0.2513,\n",
      "          -0.0649,  0.0000,  0.4269,  0.0000,  0.0463, -0.6253,  0.0000,\n",
      "           0.7483, -2.0271, -1.0489, -0.4316, -0.1122,  0.5160, -2.7971,\n",
      "          -1.4579, -0.6645,  1.0258,  0.1328,  2.7510,  1.0025,  0.0000,\n",
      "          -0.1735, -1.5053,  2.2319,  1.1872, -0.0478,  0.7229,  0.1090,\n",
      "          -2.8556, -0.0138, -0.8379, -0.5805]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0332, 0.1665, 0.1005, 0.0873, 0.0897, 0.1165, 0.0597, 0.1030, 0.1335,\n",
      "         0.1102]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1881, -0.2015,  0.5954,  ...,  0.0925, -0.1263, -0.4134],\n",
      "        [ 0.0225, -0.5021,  0.5810,  ..., -0.3205, -0.0868, -0.2771],\n",
      "        [ 0.1102,  0.0330,  0.2879,  ...,  0.0649,  0.0909,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1240, -0.1345,  0.0233,  0.1476,  0.0812,  0.0540,  0.0548,\n",
      "          -0.1026, -0.0245,  0.2376,  0.0383,  0.0399,  0.1024, -0.0475,\n",
      "           0.1253, -0.0406, -0.0705,  0.0463,  0.0112,  0.0054, -0.1952,\n",
      "          -0.2552,  0.0022, -0.0874,  0.0581, -0.0283, -0.1445, -0.2793,\n",
      "          -0.0341,  0.0828,  0.0703, -0.0645, -0.2461, -0.1791,  0.0975,\n",
      "          -0.0117,  0.1626,  0.0616,  0.0977,  0.0912,  0.1649,  0.3013,\n",
      "          -0.0532,  0.0700, -0.0305,  0.0288, -0.1099, -0.0548, -0.1462,\n",
      "          -0.0606, -0.0689,  0.0049, -0.0962, -0.0255,  0.2076,  0.0592,\n",
      "          -0.0403, -0.0517,  0.0717,  0.3216,  0.0481, -0.1079,  0.0399,\n",
      "           0.1467, -0.0933,  0.0928, -0.0204,  0.0941, -0.0011,  0.1175,\n",
      "           0.0004,  0.0048, -0.0395,  0.0113, -0.1114, -0.0438,  0.1016,\n",
      "           0.2566,  0.0985,  0.0044,  0.0750, -0.0061, -0.0089,  0.0470,\n",
      "          -0.0662,  0.2090,  0.1396,  0.1352,  0.0169,  0.0936,  0.2476,\n",
      "          -0.0188,  0.0433,  0.1444, -0.0759,  0.1061, -0.0398,  0.0893,\n",
      "           0.1275,  0.0960, -0.1030,  0.0407,  0.0625, -0.0635,  0.1641,\n",
      "          -0.0741,  0.0077,  0.0119,  0.0473,  0.0726,  0.0578,  0.0918,\n",
      "          -0.2422, -0.0615, -0.1144, -0.0404, -0.0419,  0.0269, -0.0675,\n",
      "           0.0123,  0.1356, -0.0474, -0.0778,  0.1719, -0.1938, -0.2411,\n",
      "          -0.1377,  0.0013, -0.0035, -0.0574,  0.1478, -0.1502,  0.2276,\n",
      "           0.2716,  0.1499, -0.0179,  0.1834,  0.1635,  0.0238,  0.2378,\n",
      "          -0.1307,  0.0187, -0.2051,  0.0864,  0.0197, -0.0857, -0.0250,\n",
      "           0.0280,  0.0725,  0.0503, -0.0272,  0.0300, -0.0843,  0.0874,\n",
      "           0.0172,  0.1035,  0.0247,  0.0995, -0.1181,  0.0248, -0.0075,\n",
      "          -0.0466,  0.0138,  0.0481, -0.1071,  0.0232, -0.2104,  0.1619,\n",
      "           0.1914,  0.2652,  0.0473, -0.0260,  0.1981, -0.0075, -0.0977,\n",
      "           0.1076,  0.1308,  0.1870,  0.0173,  0.0962, -0.1318, -0.0795,\n",
      "          -0.0570,  0.0281,  0.0810,  0.1240,  0.0559,  0.1711, -0.0144,\n",
      "           0.1208,  0.0026, -0.1174, -0.1077, -0.1397, -0.3190, -0.2596,\n",
      "          -0.1042, -0.0077, -0.1207, -0.2306,  0.0531, -0.0996, -0.0249,\n",
      "          -0.0122, -0.1266,  0.0670, -0.0121,  0.0948,  0.1488, -0.1033,\n",
      "          -0.1087,  0.1238, -0.1031,  0.1707,  0.0144,  0.1369,  0.0686,\n",
      "          -0.1691,  0.0443,  0.1207,  0.0418, -0.1257, -0.0925, -0.0380,\n",
      "          -0.1088,  0.1401,  0.0557, -0.1235, -0.1475,  0.1728,  0.0387,\n",
      "          -0.1173, -0.0211,  0.1472,  0.0448,  0.0004, -0.0670, -0.0437,\n",
      "           0.1844,  0.1161,  0.1660, -0.1372, -0.0714, -0.1875,  0.0436,\n",
      "           0.0452, -0.0573,  0.1382,  0.1291, -0.1251,  0.0769,  0.2336,\n",
      "          -0.1176, -0.0568,  0.0722, -0.0517]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7263e-01, -4.3096e-01,  3.1519e-01, -1.0851e+00, -1.1729e+00,\n",
      "           7.4164e-01, -1.9147e+00,  1.3514e+00,  1.9010e-01,  6.1736e-01,\n",
      "           1.9039e+00,  6.0258e-01,  2.2921e-01, -9.1667e-01, -3.1841e+00,\n",
      "          -6.8316e-02, -1.6338e+00, -9.4356e-01,  1.3603e+00, -1.4359e+00,\n",
      "          -1.4035e-01, -5.2456e-01, -1.1199e+00, -2.5959e+00, -7.5932e-02,\n",
      "           1.3919e+00, -6.1989e-01,  1.9983e+00,  1.2777e-01,  5.5523e-01,\n",
      "           9.1590e-01, -3.8077e-03,  2.2228e-01,  0.0000e+00, -6.3594e-02,\n",
      "          -1.4086e+00, -1.1161e-01, -8.1737e-01,  3.1531e-01,  8.6156e-02,\n",
      "           8.6349e-01, -8.9930e-01,  1.0090e+00, -1.5641e+00,  1.9450e+00,\n",
      "          -3.0044e-01,  7.0648e-01, -6.0241e-01, -1.0210e+00,  1.1173e+00,\n",
      "           0.0000e+00,  2.6784e+00,  6.6705e-01, -8.4711e-01,  2.2804e-01,\n",
      "          -3.1024e-01,  0.0000e+00, -9.6214e-02,  1.2760e+00,  2.1824e+00,\n",
      "          -1.0067e+00,  3.5842e-02, -2.8022e-01,  2.6576e-01, -6.3249e-02,\n",
      "           3.9362e-01,  5.7815e-01,  1.1653e+00,  0.0000e+00,  0.0000e+00,\n",
      "           4.2733e-01,  2.9640e-01, -3.1037e-02, -7.9835e-01, -2.1417e-01,\n",
      "           1.3952e-01,  5.2606e-01,  1.3992e+00,  1.0274e+00, -7.9430e-01,\n",
      "           7.5856e-01, -1.0047e+00,  7.5846e-01,  1.0588e+00,  0.0000e+00,\n",
      "          -1.1333e-01, -1.1085e+00,  5.4868e-01, -9.4503e-01, -1.9015e+00,\n",
      "           5.2924e-01,  9.8742e-01,  1.7022e+00,  9.4438e-01,  0.0000e+00,\n",
      "          -1.5902e-02,  3.5445e-01, -1.1761e+00,  1.3727e+00,  2.4482e+00,\n",
      "           0.0000e+00,  4.4051e-02, -4.6666e-01, -9.8956e-01,  1.6412e+00,\n",
      "          -1.0241e+00,  0.0000e+00,  6.2086e-01, -1.0196e-01, -1.2357e+00,\n",
      "           1.8999e-01, -5.0335e-01,  0.0000e+00,  7.1259e-01, -7.8092e-01,\n",
      "           6.3265e-01,  4.0379e-01,  2.2340e-01, -2.3273e+00,  2.9200e-02,\n",
      "          -8.1490e-01, -1.4120e+00, -1.8387e+00,  6.0326e-01, -9.5731e-01,\n",
      "          -2.0107e-01,  4.0381e-02,  2.1509e+00,  1.3967e+00, -2.0883e+00,\n",
      "          -9.2621e-01,  4.4991e-01, -1.1684e+00,  4.2556e-01, -4.6826e-01,\n",
      "          -7.4642e-01, -1.0649e+00, -9.7561e-01, -1.9406e-02,  2.3981e+00,\n",
      "           6.9866e-01, -1.1219e+00,  1.6919e+00, -1.4046e-01, -6.7011e-01,\n",
      "           3.3221e-02,  0.0000e+00,  4.2292e-01, -1.0340e+00, -9.5228e-02,\n",
      "           1.5601e+00,  0.0000e+00, -3.3842e-01,  6.5777e-01,  1.8416e+00,\n",
      "          -2.5284e-01, -2.1791e-01,  6.2402e-01, -2.3640e+00,  1.0561e+00,\n",
      "           3.0290e-01, -7.7197e-02,  1.5530e-01, -1.2124e+00, -2.2022e-02,\n",
      "           1.6827e+00,  1.8529e+00,  0.0000e+00, -1.2705e+00, -7.1307e-01,\n",
      "          -1.2243e+00, -1.0943e+00, -2.5913e+00,  5.0590e-01, -3.0610e+00,\n",
      "          -2.8747e-01,  4.9757e-01,  0.0000e+00,  3.1711e-01, -7.9307e-01,\n",
      "           2.7260e-01,  2.3401e+00,  1.0584e+00,  8.3912e-01, -4.0240e-01,\n",
      "           7.2802e-01,  5.9866e-01,  3.5983e-01,  8.4327e-01, -1.8312e+00,\n",
      "           1.3639e+00,  2.1602e+00,  3.3582e-01, -1.0157e+00, -1.1730e+00,\n",
      "          -2.2162e+00,  1.6679e+00,  2.1534e+00,  3.6345e-01,  2.3838e+00,\n",
      "           3.2528e-02, -5.0167e-01, -1.2771e+00, -5.4310e-01,  0.0000e+00,\n",
      "          -1.4478e+00,  9.5335e-01, -8.5210e-01,  8.2950e-01, -1.5606e+00,\n",
      "           6.3750e-01,  0.0000e+00,  2.3987e+00,  0.0000e+00,  1.8938e+00,\n",
      "           1.3092e+00,  5.8029e-01, -2.3180e+00,  1.5503e+00, -2.2253e-01,\n",
      "          -2.2736e-01,  1.7344e+00,  2.7652e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.2244e+00, -8.4895e-01, -1.8027e+00, -7.4514e-04,  3.7322e-01,\n",
      "          -1.5740e+00,  0.0000e+00,  9.6638e-01, -1.7375e+00,  1.6948e+00,\n",
      "          -1.4405e+00,  6.3403e-01, -1.7230e+00,  9.8030e-01, -1.7172e+00,\n",
      "           1.5617e+00, -2.7303e-01,  0.0000e+00,  1.2392e+00, -1.2283e+00,\n",
      "           1.8867e+00, -5.0850e-01,  5.4284e-01, -2.6130e-01, -1.0224e+00,\n",
      "           1.3339e+00,  3.1137e-01, -5.0964e-02, -2.2877e-01, -1.6131e+00,\n",
      "           1.8073e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0367, 0.1436, 0.1176, 0.0695, 0.1585, 0.1226, 0.1385, 0.0523, 0.0973,\n",
      "         0.0633]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.1881, -0.2015,  0.5954,  ...,  0.0925, -0.1263, -0.4134],\n",
      "        [ 0.0225, -0.5021,  0.5810,  ..., -0.3205, -0.0868, -0.2771],\n",
      "        [ 0.1102,  0.0330,  0.2879,  ...,  0.0649,  0.0909,  0.1078],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1917, -0.1016, -0.0772,  0.1968,  0.0209, -0.0398,  0.0969,\n",
      "          -0.1547, -0.0137,  0.2648,  0.0581, -0.0039,  0.0511, -0.0540,\n",
      "           0.1711, -0.0744, -0.0202,  0.0850, -0.0615,  0.0514, -0.2547,\n",
      "          -0.3226,  0.0035, -0.0383,  0.0089, -0.0880, -0.1918, -0.3334,\n",
      "          -0.0831,  0.1003,  0.1112, -0.1468, -0.3077, -0.1966,  0.1481,\n",
      "           0.0023,  0.1627,  0.0538,  0.0423,  0.0977,  0.1657,  0.3274,\n",
      "          -0.0971,  0.0843,  0.0179,  0.0504, -0.1643, -0.1197, -0.1464,\n",
      "          -0.0617, -0.1254,  0.0171, -0.1360, -0.0178,  0.2217,  0.0587,\n",
      "          -0.0433, -0.0271,  0.1297,  0.4056, -0.0075, -0.0887,  0.0032,\n",
      "           0.1964, -0.1226,  0.0633, -0.0493,  0.1235, -0.0264,  0.1185,\n",
      "           0.0423, -0.0081, -0.0661,  0.0686, -0.1975, -0.0560,  0.1369,\n",
      "           0.3009,  0.0995,  0.0351,  0.0666, -0.0715, -0.0915,  0.0575,\n",
      "          -0.0941,  0.2188,  0.1309,  0.1657,  0.0280,  0.0984,  0.3299,\n",
      "          -0.0035,  0.0772,  0.1664, -0.0613,  0.1295, -0.0288,  0.1480,\n",
      "           0.1482,  0.1826, -0.1609,  0.0698,  0.1139, -0.0546,  0.1068,\n",
      "          -0.1121,  0.0856,  0.0633,  0.0527,  0.1306,  0.0889,  0.1042,\n",
      "          -0.2656, -0.1023, -0.2019, -0.0255, -0.0839,  0.0032, -0.1198,\n",
      "          -0.0005,  0.1934, -0.0673, -0.1727,  0.2069, -0.2629, -0.2733,\n",
      "          -0.1239,  0.0071,  0.0233, -0.0812,  0.2116, -0.2638,  0.3052,\n",
      "           0.3039,  0.1727,  0.0622,  0.2542,  0.2029, -0.0146,  0.3131,\n",
      "          -0.1756,  0.0552, -0.2767,  0.1436,  0.0555, -0.1330, -0.0231,\n",
      "           0.0965,  0.0954,  0.1389, -0.0776,  0.0800, -0.1341,  0.1078,\n",
      "           0.0382,  0.1691,  0.0531,  0.1173, -0.0600, -0.0483, -0.0644,\n",
      "          -0.1238, -0.0369,  0.0817, -0.1090,  0.0384, -0.2750,  0.1444,\n",
      "           0.2752,  0.3689, -0.0024, -0.0323,  0.2604, -0.0566, -0.1406,\n",
      "           0.0844,  0.1197,  0.2758,  0.0888,  0.0563, -0.1737, -0.1085,\n",
      "          -0.1062,  0.0400,  0.1388,  0.1707, -0.0433,  0.2589,  0.0378,\n",
      "           0.1206,  0.0198, -0.1086, -0.1734, -0.2094, -0.3325, -0.3069,\n",
      "          -0.1151, -0.0161, -0.1585, -0.2379,  0.0537, -0.0866, -0.0933,\n",
      "           0.0500, -0.0886,  0.0578, -0.0491,  0.1247,  0.1503, -0.1530,\n",
      "          -0.1339,  0.1142, -0.1282,  0.1940, -0.0054,  0.2125,  0.0081,\n",
      "          -0.2018,  0.0174,  0.1948,  0.0748, -0.1967, -0.0987, -0.0729,\n",
      "          -0.0750,  0.1931,  0.1089, -0.1549, -0.1906,  0.2280, -0.0148,\n",
      "          -0.1756, -0.0387,  0.1182,  0.0417,  0.0042, -0.1223, -0.0317,\n",
      "           0.2389,  0.1238,  0.1907, -0.1751, -0.1278, -0.2121,  0.0845,\n",
      "           0.0308, -0.1080,  0.1216,  0.1731, -0.1119,  0.1190,  0.2526,\n",
      "          -0.1612, -0.0601,  0.0919, -0.0355]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5715e-02,  3.9891e-01,  0.0000e+00, -6.8189e-01,  3.7639e-01,\n",
      "          -2.0187e-01,  1.4650e+00, -8.3284e-02, -3.5853e+00,  9.0675e-01,\n",
      "           0.0000e+00, -6.2927e-01,  2.6059e+00, -6.2973e-01, -5.4161e-01,\n",
      "          -1.5804e-01,  8.5167e-01,  1.0951e+00,  4.5520e-01,  0.0000e+00,\n",
      "           0.0000e+00, -3.8367e-01,  0.0000e+00,  1.5115e+00,  7.5393e-01,\n",
      "          -7.5301e-02, -1.8777e-01, -7.5911e-01,  1.6542e+00,  8.6174e-01,\n",
      "           1.2321e+00,  1.2192e+00, -1.0344e+00, -8.2721e-02, -1.5351e+00,\n",
      "           1.3954e+00,  2.8080e-01,  0.0000e+00,  0.0000e+00,  1.6015e+00,\n",
      "          -4.5888e-01, -1.3989e+00, -2.6836e-01, -1.7168e+00, -1.5251e+00,\n",
      "           6.6733e-01,  5.4107e-01,  3.7016e-01, -1.3410e+00,  1.4378e-01,\n",
      "           0.0000e+00,  2.7534e+00,  0.0000e+00, -1.0298e+00, -2.5763e-02,\n",
      "           2.0300e-01, -8.8242e-01,  0.0000e+00, -2.3653e-01, -4.2524e-01,\n",
      "           1.1014e+00,  1.4086e+00, -2.0369e-01, -5.0201e-01, -2.9652e+00,\n",
      "           5.5049e-01,  1.2793e+00, -1.2884e+00,  4.1172e-01,  5.2647e-01,\n",
      "          -1.2675e+00, -3.0421e-02,  7.0745e-01, -3.6427e+00,  3.2649e-01,\n",
      "          -2.2962e-03, -1.5986e-01,  1.0631e+00, -5.8405e-02, -1.2007e-01,\n",
      "          -1.4006e+00,  2.1321e+00, -9.2504e-01,  1.0057e+00, -2.0791e-01,\n",
      "           4.3440e-01,  1.6620e+00, -9.7499e-01, -1.0321e-01, -5.8152e-01,\n",
      "           0.0000e+00,  1.1005e+00, -6.2233e-01, -1.1354e+00,  4.6748e-01,\n",
      "          -1.1710e+00,  3.4387e-02,  6.2924e-01,  1.7207e+00, -7.8064e-01,\n",
      "           2.6979e+00, -1.4631e+00,  1.0761e+00,  1.4547e+00, -6.6657e-01,\n",
      "          -7.6263e-01,  1.2130e+00,  1.2743e-01, -1.4732e+00, -1.3004e-02,\n",
      "           0.0000e+00,  0.0000e+00, -1.0489e+00,  1.3104e+00, -1.6541e+00,\n",
      "           0.0000e+00, -5.6291e-02, -5.0153e-01, -1.9318e-01,  4.4476e-01,\n",
      "           0.0000e+00,  7.0261e-01, -1.4610e+00, -7.2640e-01, -9.5876e-01,\n",
      "          -1.3096e+00,  8.9791e-01,  1.7051e-01,  1.2860e+00,  0.0000e+00,\n",
      "          -8.2326e-01,  5.2970e-01, -1.5835e+00,  0.0000e+00,  2.7614e-01,\n",
      "          -5.8968e-01,  6.6004e-01,  0.0000e+00, -1.1586e+00, -1.0107e+00,\n",
      "          -3.8906e-01,  6.7784e-01, -7.9023e-01, -1.0180e-01, -1.6865e+00,\n",
      "          -1.0139e-01, -5.4337e-01, -8.4462e-01, -7.5561e-01,  1.7742e-01,\n",
      "           1.9993e+00,  0.0000e+00, -1.9313e+00, -4.0631e-01,  4.4151e-01,\n",
      "          -1.9441e-01, -6.4068e-02, -1.2901e-01,  3.9560e-02,  5.3768e-01,\n",
      "          -2.6180e-02,  2.2068e+00,  4.8120e-01, -5.4972e-01, -5.2760e-01,\n",
      "          -8.9306e-01,  0.0000e+00,  8.4721e-02, -3.5801e-01, -4.7818e-01,\n",
      "           7.3842e-01, -3.2399e-02,  1.9854e-02, -1.0021e+00,  1.2781e+00,\n",
      "          -1.0993e+00, -9.8804e-01, -2.0781e+00,  1.9699e+00,  8.6387e-02,\n",
      "          -2.9741e-02,  0.0000e+00,  6.7170e-01,  9.7982e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.7844e+00, -7.8486e-01,  1.2101e+00,  1.0126e+00,\n",
      "           3.0755e+00,  4.9457e-01, -1.4415e-01, -5.9486e-01,  0.0000e+00,\n",
      "           2.1660e+00, -1.1884e+00,  5.3483e-01,  1.8124e+00, -9.4773e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2419e+00, -1.2212e-01,  0.0000e+00,\n",
      "          -5.7553e-01, -2.2934e+00,  6.8200e-01, -1.0749e+00, -4.7148e-01,\n",
      "           2.8689e+00, -5.7331e-01, -3.4121e-01,  7.9339e-01,  2.9869e-02,\n",
      "          -6.8497e-01, -1.0198e+00,  9.6631e-01, -2.4597e-01,  2.1702e+00,\n",
      "          -1.0831e+00, -4.2771e-01, -1.8444e+00, -5.0167e-01,  3.3718e-01,\n",
      "           0.0000e+00, -6.9654e-01, -6.2815e-01,  2.9226e-01, -1.5792e+00,\n",
      "          -1.1090e+00,  1.5817e+00, -6.1434e-01,  1.3099e+00, -2.9806e+00,\n",
      "           4.0369e+00,  5.8517e-01,  4.3560e-02, -1.5808e+00, -2.8767e-01,\n",
      "           7.4146e-01, -3.2495e+00, -3.0473e-01, -8.5274e-01,  0.0000e+00,\n",
      "           2.7527e-01,  2.7507e-01,  2.5267e-01,  2.6099e-01,  3.8661e-01,\n",
      "          -3.6558e-01, -1.5835e-01, -5.5423e-01, -5.2650e-02,  0.0000e+00,\n",
      "          -1.1316e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0374, 0.0579, 0.0670, 0.0567, 0.1019, 0.3816, 0.0426, 0.0782, 0.0548,\n",
      "         0.1220]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1862,  0.3289, -0.0950, -0.0743, -0.2056, -0.2504, -0.1545,\n",
      "          -0.1108,  0.0315,  0.0007,  0.1117, -0.0574,  0.1201,  0.3383,\n",
      "           0.3582,  0.1259,  0.1851,  0.0588,  0.1100,  0.2954, -0.3122,\n",
      "           0.1345,  0.0571, -0.0157,  0.0343, -0.0609, -0.2059,  0.0320,\n",
      "           0.0341, -0.1504,  0.0349, -0.0330, -0.1901,  0.1531,  0.1116,\n",
      "          -0.0613, -0.1790, -0.0051, -0.1026,  0.1199,  0.2270, -0.0042,\n",
      "          -0.0695, -0.2339,  0.1441, -0.1087,  0.1209, -0.1542,  0.2313,\n",
      "           0.1654,  0.0554,  0.2203, -0.3182, -0.1081,  0.0952, -0.0394,\n",
      "           0.0614,  0.0444, -0.1978, -0.0299,  0.1943, -0.2263,  0.0268,\n",
      "           0.1708, -0.0450, -0.1574,  0.0747,  0.1967,  0.0267,  0.1038,\n",
      "           0.1608,  0.2535, -0.0155, -0.0114,  0.0642,  0.0633,  0.0477,\n",
      "           0.2072, -0.0460, -0.2210, -0.1062, -0.1308, -0.1029, -0.1643,\n",
      "          -0.0439,  0.2140, -0.0047,  0.1171,  0.1083, -0.2194, -0.2096,\n",
      "           0.0963,  0.0264, -0.1070, -0.1984,  0.0328, -0.0034,  0.1594,\n",
      "          -0.0753, -0.0041,  0.0142, -0.1977,  0.0980,  0.2829, -0.0916,\n",
      "           0.0782,  0.0015, -0.1737, -0.0254,  0.1811,  0.0898, -0.0484,\n",
      "          -0.0914,  0.0409,  0.2328, -0.1480,  0.0602, -0.1929,  0.1820,\n",
      "           0.1439,  0.2492,  0.0202,  0.0873,  0.0706, -0.0325, -0.0424,\n",
      "           0.3080, -0.2841,  0.3258,  0.0532,  0.0877, -0.0844,  0.0719,\n",
      "           0.2101,  0.1193,  0.0497,  0.1152,  0.1083, -0.0997,  0.2167,\n",
      "           0.2634,  0.1342, -0.1383, -0.1302,  0.1318, -0.1549, -0.0657,\n",
      "           0.1657,  0.3401,  0.1040, -0.2958,  0.1077, -0.2875, -0.0247,\n",
      "          -0.1869,  0.2444,  0.1976, -0.1172,  0.0418,  0.1132, -0.1992,\n",
      "           0.0183, -0.0949,  0.0834, -0.2594, -0.0035,  0.0101, -0.0027,\n",
      "           0.1083, -0.0065, -0.0661,  0.1162,  0.1192, -0.2024,  0.1450,\n",
      "           0.0387,  0.0176,  0.2301,  0.4611,  0.2454,  0.0368, -0.1199,\n",
      "          -0.0790, -0.0494, -0.0464, -0.0014, -0.2218, -0.2102, -0.2105,\n",
      "          -0.0375,  0.0738, -0.0397, -0.1527, -0.2066, -0.0127,  0.1027,\n",
      "          -0.0185, -0.1042,  0.1928,  0.0504,  0.1043, -0.2692,  0.2852,\n",
      "           0.1175,  0.0856, -0.1308,  0.0282,  0.2238, -0.0046,  0.2355,\n",
      "           0.1136,  0.1423, -0.0527,  0.2002,  0.0647,  0.1169,  0.0583,\n",
      "           0.0606, -0.1200,  0.1059,  0.1642,  0.0443,  0.2157, -0.2421,\n",
      "           0.1129, -0.0242, -0.1079, -0.0478, -0.4801,  0.0542, -0.1301,\n",
      "          -0.0632, -0.1355,  0.1557,  0.2611,  0.0956,  0.0118, -0.0656,\n",
      "           0.1930,  0.1438,  0.0365, -0.0413, -0.0216,  0.1094,  0.1564,\n",
      "          -0.0039,  0.0218, -0.2311,  0.0742, -0.0828,  0.2278,  0.1596,\n",
      "           0.0127, -0.1703,  0.0436, -0.0179]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4817,  1.6543, -1.0094, -1.1127,  0.4006,  0.6460,\n",
      "          -1.2226, -0.9022,  0.0940,  0.0000,  0.3159,  0.1271, -0.9577,\n",
      "          -0.3084,  0.3244, -1.8655, -2.1364,  0.6082, -0.5293,  0.0000,\n",
      "           0.2829, -1.2568, -0.9729,  1.1926,  0.0000, -1.6557,  1.0544,\n",
      "           0.9845, -1.2884,  0.3067,  0.0000, -0.7690, -1.5226, -0.3682,\n",
      "           0.4841, -0.9885, -0.3510,  0.3282,  0.6282,  0.6072, -1.1769,\n",
      "           0.3728,  1.2540, -1.7955,  1.9479, -1.4980, -0.4429, -0.2786,\n",
      "           1.1464,  0.8651,  0.0365, -0.0721, -1.0043, -0.2961, -0.8049,\n",
      "          -1.8694,  0.5100,  1.5731,  2.0578, -0.8819, -0.7340,  0.0000,\n",
      "          -0.9063, -0.8592,  0.1078,  0.6389, -0.6173,  0.0211,  0.0000,\n",
      "          -1.5894, -0.0283, -0.6441,  1.4257, -0.4461,  0.5579,  0.0000,\n",
      "          -0.6177, -1.4065, -0.3109,  0.8704,  1.3124,  0.8811,  0.0000,\n",
      "           0.0000,  0.6933,  0.0461, -2.9899,  0.8148, -0.0184,  0.0000,\n",
      "           0.3246,  0.0000,  2.3924,  1.8841,  0.2151, -1.1102,  1.0776,\n",
      "           1.5507,  0.0000,  0.0145, -0.6638,  0.0000, -1.8825,  0.4070,\n",
      "           1.4168, -1.9889, -0.9153,  0.4129,  1.8165, -1.4324,  0.1791,\n",
      "          -0.4976,  1.3005, -0.1466, -0.1099,  0.3373, -1.6426,  0.8516,\n",
      "          -1.2943, -1.3462, -0.0994,  0.8783,  0.0000,  0.2248,  0.0000,\n",
      "          -0.2024, -1.0699,  0.1246, -0.4278, -1.2476,  0.0000,  1.4195,\n",
      "           0.3274, -0.0090, -0.6385, -0.0635,  0.0000, -0.4514,  1.0983,\n",
      "           0.5453, -1.1801,  0.0000, -0.8858,  0.2167,  0.0000,  0.9173,\n",
      "          -0.0827,  1.5432,  0.0000,  0.0000, -1.3513,  1.8153, -1.9312,\n",
      "           0.5128, -0.3341, -0.2286, -0.7582,  0.9342, -0.0180,  0.2297,\n",
      "          -1.1455,  2.2618, -1.7646, -0.3902, -0.6922,  0.0000,  2.1357,\n",
      "          -1.6403,  0.0000,  1.2543, -2.0855, -0.0063, -1.1602, -0.9213,\n",
      "          -0.7984, -0.3066, -0.4306,  0.1180,  0.0000,  0.1503, -0.4529,\n",
      "           0.1994,  0.9701,  0.4841, -0.0759, -1.5022, -0.2143,  0.4037,\n",
      "          -1.4624,  1.0714,  0.6060,  0.5036, -0.5081,  0.7250, -0.0427,\n",
      "           1.8720,  0.0423,  0.0000,  0.0000,  0.1192, -0.2978,  0.2827,\n",
      "           0.3538, -0.0092, -0.7147,  0.6959,  2.0165, -0.7498,  1.8922,\n",
      "           2.7896,  0.1563,  1.5049,  0.1013, -0.5909, -0.0227, -0.1425,\n",
      "          -1.3819,  0.4081,  0.6376, -0.6885,  1.8591,  0.6066,  0.0000,\n",
      "           0.0289,  1.5296,  0.0000, -0.2608,  0.8418, -0.2543,  0.7766,\n",
      "          -0.5517,  1.2382,  0.0931,  2.0765,  0.5541,  0.0000,  2.7786,\n",
      "          -1.4955,  1.8027, -0.8495,  0.2568, -1.0499, -0.8540,  0.1357,\n",
      "          -1.7793,  0.3816,  1.9828,  0.0000,  0.5473, -1.7499,  0.3684,\n",
      "           0.1555,  1.5690, -2.7260,  0.4073]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0296, 0.1353, 0.1047, 0.0488, 0.1328, 0.2405, 0.0778, 0.0803, 0.1011,\n",
      "         0.0492]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1630,  0.3059, -0.1368, -0.0940, -0.2394, -0.2439, -0.1756,\n",
      "          -0.1330,  0.0461,  0.0094,  0.1227, -0.0280,  0.0500,  0.3467,\n",
      "           0.3932,  0.1448,  0.1670,  0.1024, -0.0136,  0.2798, -0.3599,\n",
      "           0.0666,  0.0503,  0.0275, -0.0344, -0.1302, -0.1827,  0.0262,\n",
      "           0.0315, -0.1277,  0.0459, -0.0503, -0.2053,  0.1174,  0.0462,\n",
      "          -0.0774, -0.1746, -0.0666, -0.1364,  0.0494,  0.1967, -0.0468,\n",
      "          -0.0794, -0.2099,  0.1274, -0.1002,  0.1013, -0.2108,  0.2486,\n",
      "           0.1510,  0.0399,  0.2057, -0.3247, -0.0794,  0.0469,  0.0123,\n",
      "           0.0524,  0.0327, -0.1260, -0.0023,  0.1928, -0.2789, -0.0443,\n",
      "           0.1871, -0.0438, -0.1003,  0.0489,  0.2003, -0.0220,  0.0698,\n",
      "           0.1687,  0.2335, -0.0045,  0.0193,  0.0435,  0.0853,  0.0717,\n",
      "           0.2100, -0.1123, -0.1722, -0.1426, -0.1121, -0.1472, -0.0994,\n",
      "          -0.0071,  0.1873, -0.0292,  0.1381,  0.0940, -0.2264, -0.1003,\n",
      "           0.1231,  0.0006, -0.0866, -0.2161,  0.0588,  0.0174,  0.1774,\n",
      "          -0.0603, -0.0278,  0.0084, -0.1476,  0.2007,  0.3012, -0.0765,\n",
      "           0.0798,  0.0330, -0.1420,  0.0346,  0.1738,  0.1063, -0.0537,\n",
      "          -0.1023,  0.0232,  0.1757, -0.0944,  0.0821, -0.1786,  0.1259,\n",
      "           0.1207,  0.2017, -0.0533, -0.0052,  0.0465, -0.0816, -0.0169,\n",
      "           0.2711, -0.2896,  0.3173,  0.0403,  0.1147, -0.0958,  0.1013,\n",
      "           0.2065,  0.0983,  0.0172,  0.1390,  0.1212, -0.1207,  0.2358,\n",
      "           0.2456,  0.1875, -0.2483, -0.0497,  0.1395, -0.1687, -0.0166,\n",
      "           0.2197,  0.3458,  0.1402, -0.3311,  0.1170, -0.2818, -0.0198,\n",
      "          -0.2197,  0.3566,  0.1831, -0.0987,  0.0442,  0.0977, -0.2153,\n",
      "           0.0150, -0.1761,  0.1098, -0.2549,  0.0224, -0.0543,  0.0062,\n",
      "           0.1967,  0.0610, -0.0908,  0.1830,  0.0547, -0.1828,  0.1393,\n",
      "           0.0276, -0.0414,  0.2373,  0.5119,  0.1934, -0.0415, -0.2295,\n",
      "          -0.1564, -0.0482, -0.0407, -0.0257, -0.2430, -0.1739, -0.2388,\n",
      "          -0.0859,  0.0648,  0.0013, -0.2162, -0.2021,  0.0440,  0.0642,\n",
      "           0.0254, -0.1284,  0.1471,  0.0614,  0.0567, -0.2593,  0.2178,\n",
      "           0.1688,  0.0667, -0.1497,  0.0600,  0.2238, -0.0268,  0.2477,\n",
      "           0.0493,  0.1830, -0.0296,  0.1997,  0.0782,  0.1237, -0.0256,\n",
      "           0.0601, -0.1252,  0.1566,  0.2219, -0.0412,  0.3232, -0.2640,\n",
      "           0.1198, -0.0180, -0.0101, -0.0950, -0.4909,  0.0892, -0.1320,\n",
      "          -0.0669, -0.0775,  0.1062,  0.2086,  0.0974, -0.0548, -0.0644,\n",
      "           0.1948,  0.1687,  0.0305, -0.0891, -0.1161,  0.1283,  0.0982,\n",
      "          -0.0103, -0.0009, -0.2464,  0.0881, -0.0423,  0.2434,  0.1194,\n",
      "          -0.0188, -0.1231,  0.0251,  0.0079]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7782, -1.6519, -0.1827, -0.7321,  2.5180, -1.9079,\n",
      "          -0.0326,  0.9501,  1.1944,  1.4103, -0.7569, -0.0650,  0.0645,\n",
      "           1.0464,  1.8852,  0.8701, -0.7848, -0.6402, -1.4034, -0.4985,\n",
      "          -0.3791,  1.1426,  0.2329,  0.1893,  0.0000,  1.4042, -0.1512,\n",
      "          -1.0410,  0.0000, -0.5712,  0.0000, -1.6989,  0.0000, -0.0796,\n",
      "           0.1482,  0.6450, -2.2132,  1.0517,  0.1024, -0.6923, -0.4366,\n",
      "          -1.0643,  0.8180, -0.6328, -0.6566,  1.3725,  0.9366,  1.6036,\n",
      "           0.3695, -1.0081, -1.1720, -1.1123,  1.2530, -1.9747,  1.7089,\n",
      "           0.5928,  0.0000,  0.3415,  0.0000, -0.7704,  1.8690, -0.5940,\n",
      "           0.0000,  0.0000,  0.0000, -0.3576,  0.2897, -0.7528, -1.1648,\n",
      "           2.2478,  0.7807,  0.0000,  0.0000, -0.3980,  0.0000,  0.2295,\n",
      "          -0.1575, -0.9149,  0.2959, -0.1447,  1.2866,  0.4651,  1.2969,\n",
      "           0.7706,  0.6607,  1.0453,  0.0000,  0.0000, -1.4363,  1.3106,\n",
      "          -1.5854, -0.1109,  3.2388,  0.3468,  0.0000, -0.8685,  0.7311,\n",
      "           0.0000, -0.9242,  0.1908,  0.0286, -0.5965,  1.0584, -0.2310,\n",
      "           0.7759, -0.9059, -0.3677, -0.2785, -0.5477, -0.1378, -3.2782,\n",
      "          -0.1010,  0.0000,  1.6979,  1.6883,  0.0000, -1.6461, -0.8960,\n",
      "           2.5844, -1.3262,  1.4237,  0.0000,  0.4668,  1.3156,  0.0000,\n",
      "           0.0739, -0.9856, -0.6750,  0.0000,  0.0000,  1.1297,  1.1406,\n",
      "           1.4886,  0.3790,  0.6467, -0.8378,  0.2414,  0.3447,  0.0000,\n",
      "           0.0303,  0.8640,  0.5015,  0.9070, -1.2681, -0.6409, -0.4416,\n",
      "           0.8728, -0.0676,  0.0422, -0.0566,  0.6207,  0.1450, -0.1965,\n",
      "           0.1078, -1.6722, -0.4024,  0.2512,  0.0000,  0.0000,  1.1554,\n",
      "           0.1996,  0.9130,  0.8437,  0.4174,  1.6038,  0.1771,  0.0000,\n",
      "          -0.3225,  0.2508,  0.4449, -0.4551,  0.4445, -1.3453,  1.7357,\n",
      "           0.5175,  1.1773,  0.2896, -1.8322, -1.8661,  0.2594, -0.6475,\n",
      "          -1.1658,  0.3287, -0.7440,  0.5921, -1.2417, -1.5176, -2.3034,\n",
      "           0.1466,  0.0000, -1.3210, -0.0501,  0.0000,  0.9805, -1.4146,\n",
      "          -1.1402,  3.0136, -0.2259,  1.0328,  0.0291,  0.0000, -1.3197,\n",
      "          -1.0708,  0.0566,  1.7329,  0.5270,  1.9824, -0.9787, -1.3423,\n",
      "           1.5994, -0.4014,  2.4608, -0.5197,  0.7545,  0.2065, -0.8210,\n",
      "           0.9058, -3.5302,  0.1759, -0.7813,  0.0000,  0.0000,  0.2512,\n",
      "           0.0000, -1.4656,  0.4269, -0.5198,  0.0464,  0.0000, -0.0714,\n",
      "           0.7483,  0.0000,  0.0000, -0.4316, -0.1122,  0.5160, -2.7971,\n",
      "           0.0000, -0.6645,  1.0257,  0.0000,  2.7510,  1.0025,  0.5471,\n",
      "          -0.1735, -1.5053,  2.2319,  1.1873, -0.0478,  0.0000,  0.1090,\n",
      "           0.0000, -0.0138, -0.8379, -0.5805]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0246, 0.1671, 0.1131, 0.0907, 0.1237, 0.1306, 0.0525, 0.1204, 0.1119,\n",
      "         0.0654]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.4263e-01,  2.1408e-01, -1.8597e-01, -1.0531e-01, -2.4949e-01,\n",
      "          -2.1308e-01, -1.9391e-01, -1.4783e-01,  6.1075e-02,  2.6471e-03,\n",
      "           1.0258e-01, -2.7010e-02, -1.9365e-02,  3.2872e-01,  3.7469e-01,\n",
      "           1.5960e-01,  1.2968e-01,  1.5272e-01, -1.0047e-01,  2.3098e-01,\n",
      "          -3.7388e-01,  1.3195e-02,  6.8691e-02,  6.2510e-02, -9.2521e-02,\n",
      "          -1.3211e-01, -1.2857e-01, -8.1706e-03,  3.7674e-02, -9.5884e-02,\n",
      "           6.4543e-02, -4.7757e-02, -1.7906e-01,  6.3624e-02, -5.3990e-03,\n",
      "          -1.0516e-01, -1.5738e-01, -7.6757e-02, -1.3742e-01,  3.1819e-03,\n",
      "           1.5073e-01, -3.6464e-02, -5.6156e-02, -1.8318e-01,  1.1961e-01,\n",
      "          -5.7604e-02,  9.5886e-02, -2.3033e-01,  2.5413e-01,  9.9230e-02,\n",
      "           6.6966e-03,  1.5700e-01, -3.0811e-01, -7.1945e-02, -1.3784e-02,\n",
      "           5.7439e-02,  3.2601e-02,  1.6424e-02, -6.4701e-02,  2.9135e-02,\n",
      "           1.5670e-01, -3.2124e-01, -9.0194e-02,  2.1451e-01, -4.3893e-02,\n",
      "          -4.9071e-02,  4.8427e-03,  1.6954e-01, -8.9514e-02,  3.9094e-02,\n",
      "           2.0253e-01,  2.1940e-01,  1.9904e-02,  2.7935e-02,  2.4434e-02,\n",
      "           1.1058e-01,  1.1396e-01,  2.0281e-01, -1.2725e-01, -1.0848e-01,\n",
      "          -1.5756e-01, -6.7506e-02, -1.5255e-01, -4.2452e-02,  3.8585e-02,\n",
      "           1.4696e-01, -3.1041e-02,  1.3334e-01,  9.0432e-02, -2.0892e-01,\n",
      "          -5.0478e-04,  1.4058e-01, -2.6975e-02, -8.8344e-02, -1.9980e-01,\n",
      "           1.0002e-01,  2.3523e-02,  1.7450e-01, -3.1065e-03, -3.5346e-02,\n",
      "           4.6528e-03, -5.4510e-02,  2.7006e-01,  2.7366e-01, -3.3858e-02,\n",
      "           6.0803e-02,  4.3072e-02, -8.7952e-02,  5.1243e-02,  1.7044e-01,\n",
      "           1.1044e-01, -3.2371e-02, -9.4566e-02,  9.7479e-03,  1.2419e-01,\n",
      "          -4.9641e-02,  8.7195e-02, -1.6305e-01,  7.1175e-02,  9.1621e-02,\n",
      "           1.6322e-01, -7.5803e-02, -1.0441e-01,  2.9281e-02, -1.2441e-01,\n",
      "          -1.4996e-02,  1.8116e-01, -3.0491e-01,  2.9975e-01,  5.5740e-03,\n",
      "           1.1305e-01, -8.5190e-02,  1.1475e-01,  2.1251e-01,  7.5351e-02,\n",
      "           1.5572e-02,  1.5429e-01,  1.4657e-01, -1.1597e-01,  2.4463e-01,\n",
      "           2.0208e-01,  2.2977e-01, -3.2916e-01,  2.7909e-02,  1.2912e-01,\n",
      "          -1.7642e-01,  2.8793e-02,  2.7145e-01,  3.0780e-01,  1.7267e-01,\n",
      "          -3.6271e-01,  1.3321e-01, -2.5890e-01,  1.0002e-02, -1.8105e-01,\n",
      "           4.2132e-01,  1.7327e-01, -5.3030e-02,  3.9283e-02,  9.3313e-02,\n",
      "          -2.2841e-01,  1.4760e-03, -2.5956e-01,  1.1806e-01, -2.5784e-01,\n",
      "           1.9179e-02, -1.2918e-01,  2.3748e-02,  2.1188e-01,  7.9289e-02,\n",
      "          -1.1274e-01,  2.3299e-01,  2.5033e-02, -1.4305e-01,  1.2047e-01,\n",
      "           2.1378e-02, -6.5983e-02,  1.9457e-01,  5.1167e-01,  1.2995e-01,\n",
      "          -1.2027e-01, -2.6597e-01, -2.1508e-01, -2.5652e-02, -1.6728e-03,\n",
      "          -5.1819e-02, -2.3040e-01, -1.3693e-01, -2.4920e-01, -1.1082e-01,\n",
      "           4.6225e-02,  4.1666e-02, -2.3729e-01, -1.9372e-01,  6.8068e-02,\n",
      "           2.6412e-02,  6.2536e-02, -1.2424e-01,  9.1859e-02,  5.9297e-02,\n",
      "           8.6649e-03, -2.3535e-01,  1.4358e-01,  2.0032e-01,  2.9816e-02,\n",
      "          -1.4169e-01,  7.9018e-02,  2.2727e-01, -4.4483e-02,  2.0155e-01,\n",
      "           9.5042e-03,  1.9325e-01, -1.4838e-02,  1.9826e-01,  7.8046e-02,\n",
      "           8.8646e-02, -6.0872e-02,  7.3728e-02, -1.3744e-01,  1.5888e-01,\n",
      "           2.5230e-01, -1.1469e-01,  3.8374e-01, -2.4921e-01,  1.0014e-01,\n",
      "           2.2630e-03,  4.1633e-02, -1.2836e-01, -4.7236e-01,  1.0570e-01,\n",
      "          -1.1714e-01, -7.4098e-02, -6.1500e-02,  5.7821e-02,  1.7138e-01,\n",
      "           7.0213e-02, -1.0555e-01, -5.1610e-02,  2.0866e-01,  1.7047e-01,\n",
      "           2.2234e-02, -1.1353e-01, -1.6725e-01,  1.3857e-01,  8.0837e-02,\n",
      "          -3.5095e-02, -1.5321e-02, -2.5765e-01,  6.2103e-02, -5.4485e-02,\n",
      "           2.6254e-01,  9.0566e-02, -2.7315e-02, -1.0038e-01,  8.4877e-03,\n",
      "          -3.0962e-03]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5702e+00, -1.4752e+00,  2.2742e-01, -7.8531e-02,  3.5256e-01,\n",
      "           5.5342e-01, -2.0054e-01,  2.0888e+00,  1.3115e+00,  0.0000e+00,\n",
      "           6.8485e-01,  2.1685e+00,  1.1881e+00, -8.0512e-01, -1.0887e-01,\n",
      "          -1.1277e+00,  1.9605e+00, -2.9144e-01,  8.4954e-03,  4.2646e-01,\n",
      "          -1.9755e+00, -1.8383e+00, -1.2583e+00,  1.9420e-01, -1.6700e-01,\n",
      "           1.3755e+00, -2.9787e-01, -9.7441e-01,  1.8410e+00,  7.8347e-01,\n",
      "           3.4927e-01,  3.1158e-01,  5.3677e-01,  9.4194e-01,  6.9765e-01,\n",
      "           4.5393e-01, -2.8990e+00,  6.7934e-02,  3.9933e-02,  1.2315e+00,\n",
      "          -7.2217e-01, -1.0137e+00,  2.4819e-01,  1.0037e+00,  6.7037e-02,\n",
      "           3.1138e-01, -1.0371e+00, -1.1821e+00, -4.4478e-01, -1.6405e+00,\n",
      "          -1.5658e+00,  3.1698e+00,  8.6340e-01,  7.6393e-01,  2.2065e+00,\n",
      "           5.5897e-01,  5.9271e-01,  5.6761e-01, -7.5501e-01,  0.0000e+00,\n",
      "           6.2642e-01, -7.1967e-01, -3.6513e-01,  8.9446e-01, -1.3381e+00,\n",
      "           2.3298e+00, -2.4167e+00,  0.0000e+00,  1.1605e+00,  0.0000e+00,\n",
      "           7.5242e-02,  5.5117e-01,  1.8994e-01,  0.0000e+00,  4.0865e-01,\n",
      "          -9.0035e-01, -4.8582e-01,  4.3283e-01, -1.3788e+00, -2.4958e+00,\n",
      "          -3.6230e+00,  4.0205e-01,  4.9730e-01, -3.8153e-01, -2.3206e+00,\n",
      "          -1.0349e+00, -6.3274e-01,  1.8182e+00, -1.9083e+00,  0.0000e+00,\n",
      "          -4.3661e-01, -6.6935e-01, -1.9175e+00,  1.0182e+00, -1.3664e+00,\n",
      "          -1.1212e+00,  2.1715e-01,  1.7982e-02,  3.0416e-01,  7.6350e-01,\n",
      "           9.4168e-01,  9.3354e-01,  2.2435e-01, -1.6316e+00,  2.2439e+00,\n",
      "           0.0000e+00,  1.2464e-01, -1.0130e+00,  0.0000e+00, -1.4857e+00,\n",
      "          -1.5566e+00, -1.3434e+00,  1.5146e-01, -1.7880e+00, -1.1431e+00,\n",
      "          -1.0662e+00, -1.7873e+00, -1.2156e-01, -1.8689e+00,  9.4022e-02,\n",
      "           6.7202e-01,  5.5178e-01,  1.5531e+00,  4.8412e-01,  0.0000e+00,\n",
      "           0.0000e+00,  7.9535e-01,  5.8607e-02,  3.9308e-01, -5.9761e-02,\n",
      "          -8.6214e-02,  0.0000e+00,  0.0000e+00,  1.1586e+00,  3.2931e-01,\n",
      "          -2.5087e-01,  1.1914e-01, -1.3306e+00, -3.6594e-01, -7.7343e-01,\n",
      "          -5.9710e-01, -1.4721e+00, -1.1960e+00,  2.9562e-02,  5.0124e-01,\n",
      "           2.5939e-01,  1.2102e+00,  1.2554e+00,  0.0000e+00,  3.1589e-01,\n",
      "           7.8730e-02, -5.5415e-02, -7.0970e-01,  0.0000e+00,  0.0000e+00,\n",
      "           2.7989e-01,  1.1351e+00,  3.0530e-01,  0.0000e+00,  1.4422e+00,\n",
      "          -1.7483e-01,  6.8411e-01, -2.1210e-01,  0.0000e+00, -4.6792e-01,\n",
      "          -9.4152e-01,  3.2957e-01,  2.5664e-01,  1.7295e+00,  7.0251e-01,\n",
      "           3.1424e+00,  2.0556e+00,  5.6332e-01,  1.0307e-01, -3.9337e-01,\n",
      "           0.0000e+00, -4.0510e-01,  1.1919e+00, -2.6500e-01, -1.5079e+00,\n",
      "          -1.3459e-01, -1.2953e-02, -6.0216e-01, -1.5680e+00, -1.8515e+00,\n",
      "          -1.6855e-01,  6.7904e-03,  1.3397e+00,  1.2952e+00,  7.3873e-01,\n",
      "           0.0000e+00,  1.6023e-01, -5.3607e-01,  5.3541e-01, -4.7132e-02,\n",
      "          -1.2979e+00, -1.5639e+00,  0.0000e+00, -1.0837e+00, -4.6221e-02,\n",
      "           0.0000e+00, -2.1875e+00, -2.6967e+00,  1.4469e+00, -9.9697e-01,\n",
      "           9.7209e-01,  0.0000e+00, -6.1192e-01, -9.3265e-01, -1.1370e+00,\n",
      "           8.7223e-01,  7.9567e-02, -1.3189e+00, -7.9111e-01,  1.3113e+00,\n",
      "          -2.8299e-01,  1.3732e+00,  2.4497e-01,  0.0000e+00,  1.9031e+00,\n",
      "           1.0278e+00, -1.4199e+00,  1.7823e+00,  1.0654e+00, -5.7298e-01,\n",
      "          -5.7357e-01, -1.5896e+00,  1.5125e-03, -3.3777e-01, -2.9544e+00,\n",
      "          -6.4346e-01,  1.5655e+00,  9.3285e-02, -6.2737e-01,  1.6769e+00,\n",
      "           2.2891e+00, -2.1839e+00,  3.2574e-01,  1.5120e+00,  0.0000e+00,\n",
      "          -1.8332e+00, -1.1668e+00, -1.1128e-01,  1.4428e+00, -4.7770e-01,\n",
      "           1.4840e+00,  0.0000e+00,  7.7604e-01, -1.4380e+00, -2.5939e-01,\n",
      "           4.3563e-01,  3.1983e-01, -3.3689e-01,  1.6171e+00,  0.0000e+00,\n",
      "          -7.0415e-02]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0626, 0.1527, 0.0541, 0.0912, 0.2093, 0.1067, 0.0924, 0.0742, 0.0760,\n",
      "         0.0809]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3758e-01,  2.1529e-01, -1.2361e-01, -1.0130e-01, -2.4005e-01,\n",
      "          -1.5237e-01, -1.8639e-01, -1.1313e-01,  3.5760e-02,  1.6545e-03,\n",
      "           1.1234e-01, -2.4071e-02,  4.1165e-02,  2.9414e-01,  3.4124e-01,\n",
      "           1.5561e-01,  1.3008e-01,  1.1949e-01, -2.9874e-02,  2.8380e-01,\n",
      "          -3.1634e-01,  5.4074e-02, -1.6095e-02,  1.2207e-02, -2.9013e-02,\n",
      "          -1.1256e-01, -1.4701e-01,  3.7109e-02,  3.3745e-02, -6.2148e-02,\n",
      "           3.4589e-02, -1.1405e-02, -1.6818e-01,  1.0821e-01,  1.6768e-02,\n",
      "          -1.4975e-01, -1.4731e-01, -6.4735e-02, -9.4161e-02, -2.9226e-02,\n",
      "           1.7832e-01, -2.7922e-02, -6.9844e-02, -2.2610e-01,  6.3483e-02,\n",
      "          -1.4039e-01,  1.1127e-01, -2.0199e-01,  2.4869e-01,  1.1298e-01,\n",
      "           1.1624e-02,  1.6524e-01, -2.7435e-01, -1.0832e-01, -6.3023e-02,\n",
      "           3.9045e-02,  4.8668e-02,  1.2305e-02, -1.1656e-01,  6.4232e-03,\n",
      "           1.6610e-01, -2.7216e-01, -7.0619e-02,  1.6612e-01,  2.3237e-03,\n",
      "          -5.4807e-02,  2.2947e-02,  1.2081e-01,  3.3422e-04, -1.3731e-02,\n",
      "           1.0957e-01,  1.8816e-01,  3.7650e-02, -2.3743e-02,  4.5379e-02,\n",
      "           7.0509e-02,  1.1998e-01,  2.0624e-01, -1.5978e-01, -1.1999e-01,\n",
      "          -1.5004e-01, -6.9099e-02, -1.2226e-01, -5.4784e-02,  1.9766e-02,\n",
      "           1.6106e-01, -4.8258e-02,  1.1484e-01,  6.2652e-02, -2.2345e-01,\n",
      "          -2.6253e-02,  1.7396e-01, -3.5829e-02, -7.5289e-02, -1.8183e-01,\n",
      "           5.7363e-02, -5.8857e-03,  1.5894e-01,  7.8576e-03, -8.7429e-02,\n",
      "           4.8069e-02, -1.1998e-01,  2.6574e-01,  2.8502e-01, -2.5482e-02,\n",
      "           2.1759e-02,  3.1321e-02, -1.2360e-01,  8.3707e-02,  1.5833e-01,\n",
      "           4.9290e-02, -2.7766e-02, -1.1423e-01,  5.2590e-02,  1.6994e-01,\n",
      "          -2.4100e-02,  5.4747e-02, -1.4652e-01,  1.0036e-01,  1.2303e-01,\n",
      "           2.0471e-01, -1.7031e-02, -7.6789e-03,  4.3690e-02, -9.0931e-02,\n",
      "          -3.0662e-03,  2.1086e-01, -2.5860e-01,  2.9927e-01,  4.7960e-02,\n",
      "           1.2422e-01, -6.7618e-02,  1.0090e-01,  1.7302e-01,  8.7131e-02,\n",
      "          -9.1900e-03,  1.1557e-01,  1.2204e-01, -9.4266e-02,  1.9193e-01,\n",
      "           2.2157e-01,  2.0170e-01, -3.0986e-01, -3.8105e-02,  1.2472e-01,\n",
      "          -1.2984e-01,  4.4220e-02,  2.3751e-01,  2.8690e-01,  1.2825e-01,\n",
      "          -3.0823e-01,  1.3289e-01, -2.9015e-01, -6.7990e-03, -2.4137e-01,\n",
      "           3.9319e-01,  2.0088e-01, -5.8361e-02,  3.8010e-02,  1.0833e-01,\n",
      "          -2.2586e-01,  1.3415e-02, -1.8459e-01,  6.1449e-02, -2.7717e-01,\n",
      "          -1.7795e-02, -8.6864e-02,  4.7039e-02,  1.7745e-01,  6.0753e-02,\n",
      "          -7.6157e-02,  2.3621e-01,  1.0494e-02, -1.5749e-01,  1.5333e-01,\n",
      "           5.2168e-02, -5.1131e-02,  1.7140e-01,  4.5392e-01,  1.3433e-01,\n",
      "          -3.8487e-02, -1.9608e-01, -1.5621e-01, -5.5001e-02, -2.6791e-02,\n",
      "          -1.0905e-01, -2.2431e-01, -1.6545e-01, -2.4472e-01, -1.1697e-01,\n",
      "           3.5599e-02, -2.6777e-02, -1.8096e-01, -1.8497e-01,  4.8977e-02,\n",
      "           8.6464e-02,  4.4430e-02, -1.6284e-01,  9.0756e-02,  3.2290e-02,\n",
      "           8.1794e-02, -2.6745e-01,  1.7960e-01,  1.9228e-01,  3.1160e-02,\n",
      "          -1.2741e-01,  9.2722e-02,  1.4915e-01, -1.8748e-02,  2.3129e-01,\n",
      "           2.8379e-02,  2.2766e-01, -3.7705e-02,  1.8445e-01,  9.3140e-02,\n",
      "           3.0430e-02, -6.4083e-02,  7.8504e-02, -5.4917e-02,  1.0377e-01,\n",
      "           2.1530e-01, -8.6382e-02,  3.4836e-01, -1.9525e-01,  3.8518e-02,\n",
      "          -3.6353e-03,  7.3295e-02, -1.1606e-01, -4.2973e-01,  5.8462e-02,\n",
      "          -8.3881e-02, -1.0910e-01, -1.1669e-02,  1.1327e-01,  1.6403e-01,\n",
      "           2.7997e-03, -6.6981e-02, -3.2811e-02,  1.9019e-01,  1.6974e-01,\n",
      "           6.4923e-02, -9.4859e-02, -1.2168e-01,  1.2994e-01,  2.5758e-02,\n",
      "           1.6746e-03,  3.9762e-02, -2.0667e-01,  8.1273e-02, -8.4209e-03,\n",
      "           2.1389e-01,  1.1116e-01, -1.7146e-02, -3.4090e-02,  1.9667e-02,\n",
      "          -2.6887e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0394, -0.4267, -0.2466,  0.1937,  0.1465, -0.4245, -1.5298,\n",
      "          -0.9175,  1.3980,  1.1103, -0.2703, -0.3033, -1.0034,  0.0000,\n",
      "           1.5613, -1.2038, -0.0532, -1.8694,  0.7891,  0.1962,  0.0000,\n",
      "           0.7632,  1.6765, -1.3704, -2.1558,  0.0000, -0.1971,  0.4926,\n",
      "          -0.9014, -2.1858, -0.0561,  0.3273,  1.0573,  0.5797, -2.5347,\n",
      "           0.8797, -0.3903, -1.1069, -0.2391, -2.1789,  0.9869,  1.6867,\n",
      "           0.0000, -1.1843,  0.6218,  1.7397, -0.3195,  0.0000, -1.3453,\n",
      "          -0.3663, -0.4185,  1.9343,  1.1802,  1.2790,  0.6504,  0.0000,\n",
      "           0.8983,  0.1087,  0.6338,  0.3860,  0.0000, -0.4990,  0.2710,\n",
      "           0.2612, -1.6095, -0.4380,  0.5112,  0.2509, -0.2766,  0.2435,\n",
      "           1.0418,  2.3376,  0.1950, -0.9187, -1.4961,  0.3977,  0.1923,\n",
      "          -1.0913, -0.5153, -0.1304,  0.1944, -0.0569,  0.5752, -0.5537,\n",
      "           0.8108, -2.6684, -0.3577,  0.0000,  0.0000, -1.0068,  0.0000,\n",
      "          -0.1166, -1.1056,  0.0000, -0.4773, -0.9459,  0.6340, -2.1726,\n",
      "          -0.0402,  0.3322,  0.3403,  0.1943, -0.6104, -1.6471,  0.3935,\n",
      "           1.0382,  0.5977, -0.5834, -0.1308, -1.4160, -0.5555, -0.5479,\n",
      "           0.2284,  0.0000,  1.1701, -0.2292,  0.8997,  0.6790, -1.5587,\n",
      "           0.5697,  0.3582,  0.0000,  0.0455,  0.4339,  0.4159, -0.5510,\n",
      "          -0.8370, -0.3672, -1.3221, -1.9074, -1.0077, -0.1428,  0.7310,\n",
      "           0.5127, -0.2584,  1.1108, -1.1860,  0.1306, -1.3158,  0.5397,\n",
      "           0.6319,  0.5882, -0.0693, -0.1962,  0.5708,  1.4906, -0.2074,\n",
      "           3.1558,  2.2906,  0.0000,  0.0000, -0.6853,  0.9786,  1.1226,\n",
      "          -0.3530,  0.6414, -0.1179, -0.3576, -0.8346,  0.9615, -1.8404,\n",
      "          -1.0017, -1.0322, -0.5765, -2.2594,  1.4160,  0.9077, -0.5910,\n",
      "          -0.9056, -0.4631, -1.0688, -1.0964, -1.0745,  0.0000,  0.2158,\n",
      "           0.3833, -1.4547, -0.0977, -1.1115,  2.5165,  0.0000,  1.2000,\n",
      "          -0.4899,  0.6194, -0.0682, -0.6032,  0.1400, -1.2709, -0.7078,\n",
      "           1.3329,  0.1750,  0.0000,  0.8847, -1.0422, -0.0804,  1.6641,\n",
      "          -1.1205, -0.7741,  0.4020,  0.6212, -1.2729, -2.4198, -1.4286,\n",
      "           0.2998, -0.9242, -0.9390,  1.1742,  0.0000, -0.0398, -0.5756,\n",
      "          -1.9199, -1.3511,  0.6104,  0.0000, -2.1564,  0.0000,  0.0556,\n",
      "           0.5840,  0.1927, -0.4860,  1.1580, -0.0410,  1.5460, -0.1737,\n",
      "           2.0208, -0.9502,  1.4252,  0.0000, -2.2174,  2.0664, -2.0117,\n",
      "           0.1096, -0.1182, -1.6063,  0.9172,  0.0000,  0.4371, -0.3564,\n",
      "          -0.8804,  0.5723, -1.1537, -0.2187, -1.0338,  0.2680,  1.7358,\n",
      "          -0.7924,  0.1975, -1.1026, -0.3399, -2.2733, -0.7344,  2.2742,\n",
      "           1.5974,  1.5761, -0.7970, -0.2901]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0578, 0.1152, 0.1666, 0.1040, 0.0793, 0.0882, 0.0362, 0.1171, 0.1124,\n",
      "         0.1232]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1293,  0.1495, -0.2040, -0.1009, -0.2182, -0.1745, -0.1853,\n",
      "          -0.1362,  0.0721,  0.0123,  0.0798, -0.0493, -0.0359,  0.2899,\n",
      "           0.3493,  0.1571,  0.1365,  0.1487, -0.1384,  0.1509, -0.3584,\n",
      "           0.0157,  0.0585,  0.0888, -0.1454, -0.1245, -0.1041, -0.0122,\n",
      "           0.0636, -0.1001,  0.0646, -0.0415, -0.1577,  0.0720, -0.0466,\n",
      "          -0.0975, -0.1527, -0.0575, -0.1085, -0.0351,  0.0901, -0.0317,\n",
      "          -0.0356, -0.1482,  0.1692, -0.0302,  0.0926, -0.2282,  0.2357,\n",
      "           0.0525, -0.0134,  0.0958, -0.2886, -0.0413, -0.0275,  0.0664,\n",
      "           0.0095,  0.0084, -0.0125,  0.0244,  0.1323, -0.3184, -0.1041,\n",
      "           0.2277, -0.0264, -0.0471, -0.0093,  0.1506, -0.1392,  0.0381,\n",
      "           0.2079,  0.2069,  0.0412,  0.0032, -0.0176,  0.1347,  0.1156,\n",
      "           0.1649, -0.0950, -0.0879, -0.1526, -0.0585, -0.1304, -0.0137,\n",
      "           0.0829,  0.1410, -0.0287,  0.1119,  0.0751, -0.1988,  0.0164,\n",
      "           0.1710, -0.0224, -0.0844, -0.1960,  0.1000,  0.0451,  0.1518,\n",
      "           0.0089, -0.0223, -0.0186, -0.0255,  0.2579,  0.2488, -0.0154,\n",
      "           0.0752,  0.0008, -0.0703,  0.0249,  0.1757,  0.1218, -0.0251,\n",
      "          -0.0934, -0.0272,  0.1079, -0.0517,  0.0987, -0.1227,  0.0166,\n",
      "           0.0444,  0.1304, -0.1169, -0.1730, -0.0014, -0.1455, -0.0151,\n",
      "           0.1172, -0.3161,  0.2821, -0.0186,  0.0833, -0.0647,  0.1291,\n",
      "           0.1969,  0.0686,  0.0515,  0.1527,  0.1614, -0.0997,  0.2187,\n",
      "           0.1746,  0.2310, -0.3102,  0.0814,  0.0899, -0.1804,  0.0545,\n",
      "           0.2532,  0.2392,  0.2057, -0.3426,  0.1076, -0.1937,  0.0055,\n",
      "          -0.1318,  0.4102,  0.1481, -0.0297,  0.0215,  0.0854, -0.2224,\n",
      "          -0.0160, -0.2908,  0.1174, -0.2324,  0.0378, -0.1401,  0.0392,\n",
      "           0.1995,  0.0685, -0.1042,  0.2419,  0.0243, -0.1078,  0.1140,\n",
      "           0.0182, -0.0741,  0.1493,  0.4811,  0.1240, -0.1584, -0.2517,\n",
      "          -0.2442, -0.0019,  0.0013, -0.0205, -0.2111, -0.1037, -0.2639,\n",
      "          -0.0917,  0.0454,  0.0870, -0.2278, -0.1838,  0.0617, -0.0191,\n",
      "           0.0622, -0.0983,  0.0846,  0.0666, -0.0502, -0.1876,  0.1127,\n",
      "           0.2003, -0.0190, -0.0981,  0.0565,  0.2340, -0.0629,  0.1960,\n",
      "          -0.0063,  0.1621, -0.0140,  0.1553,  0.0704,  0.0720, -0.0721,\n",
      "           0.0880, -0.1705,  0.1369,  0.2420, -0.1499,  0.3894, -0.2347,\n",
      "           0.1374, -0.0076,  0.0132, -0.1052, -0.4460,  0.1203, -0.1017,\n",
      "          -0.0552, -0.0590,  0.0340,  0.1478,  0.0702, -0.1299, -0.0472,\n",
      "           0.2023,  0.1398,  0.0284, -0.1528, -0.2157,  0.1365,  0.0964,\n",
      "          -0.0587, -0.0194, -0.2711,  0.0400, -0.0627,  0.2569,  0.0716,\n",
      "           0.0012, -0.1188, -0.0356,  0.0141]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.7719, -2.7755, -1.7268,  0.4413, -1.6523, -0.7617, -1.2330,\n",
      "           1.6356,  0.0000,  1.3138, -1.9155, -0.5448,  1.3864,  1.1179,\n",
      "           1.1885, -0.7653, -1.0501,  0.1154, -1.2338, -0.5361, -0.4016,\n",
      "           0.5830, -1.5798, -0.6264,  0.4949, -0.9057,  0.0000, -0.5902,\n",
      "           0.8779,  1.6735, -0.7736, -1.0550, -1.9929, -0.2947,  0.2496,\n",
      "          -0.1000, -0.7749,  0.0000,  1.0477,  0.0000,  0.3197, -0.0051,\n",
      "           0.3615,  0.4770,  0.0000,  0.1362,  2.0012, -1.6447, -0.5773,\n",
      "           1.5252,  1.0370,  0.3927, -0.6897,  0.1844, -0.7846,  0.0000,\n",
      "          -0.4195,  0.4979, -1.2082, -0.3022, -0.2426,  0.6798,  0.2227,\n",
      "           1.6242,  0.7100, -0.7305, -0.8209, -1.8327,  0.5513, -0.9164,\n",
      "          -2.9503, -0.2475,  0.2593, -0.7585,  0.0597, -0.1119,  0.5869,\n",
      "          -1.2855, -0.3083, -0.0853,  0.0000, -1.3159,  1.4157, -0.2203,\n",
      "           0.0000, -0.0428, -0.2575,  0.0000, -0.2304,  0.8900,  0.0288,\n",
      "          -0.2120, -0.2233, -0.2816, -1.5521, -1.6415,  1.6718, -0.5077,\n",
      "           0.0896, -0.1412, -0.5179, -1.8936, -1.1983, -0.8760, -0.8277,\n",
      "          -0.2511,  0.1154,  0.6087, -0.8374,  1.7025,  0.0000, -0.9160,\n",
      "          -1.3331, -0.5048, -0.2309, -0.7321, -1.3972, -0.4244,  0.0000,\n",
      "           0.5810, -0.0489,  0.0000, -1.2111, -0.3241,  0.0000,  0.1068,\n",
      "           0.3720, -0.6405,  0.8435,  2.4113, -0.1695, -1.4203, -0.6761,\n",
      "           0.9547,  0.7352, -0.5837, -3.6651,  1.1265,  1.6562,  0.8797,\n",
      "           0.9297, -0.4669,  0.2888,  1.5357,  1.0736,  1.6722,  0.1635,\n",
      "           0.7084, -1.1396,  0.9681,  0.9195, -2.6182, -1.4200,  0.3481,\n",
      "           0.3331,  0.7717,  0.6941, -0.7485, -0.3000,  0.3065,  0.0000,\n",
      "           0.2664, -0.9413, -0.2393,  0.2680,  0.1292, -1.4760, -1.9394,\n",
      "          -0.2574, -1.5009, -1.4831,  0.4009,  0.6207, -1.7494,  1.3100,\n",
      "          -0.9200, -0.5191,  2.5056,  1.2912,  0.0000, -0.8772, -1.6041,\n",
      "          -0.5939, -1.6926, -1.8962,  0.0000, -0.9750,  1.6778,  0.0000,\n",
      "           0.1842, -0.8903, -0.2925, -1.7448,  1.0326,  0.7650, -1.1044,\n",
      "          -0.3988,  0.0183,  0.6344,  0.0000,  1.8779, -0.1021,  0.7440,\n",
      "           0.0000,  0.2120,  0.0000,  0.7013,  1.7251,  0.5315,  0.0000,\n",
      "           0.2773, -1.9694, -1.6656,  0.0000,  2.1452, -0.2556,  0.3522,\n",
      "           0.8926, -0.6679,  0.2821, -0.7370, -0.8950,  0.6225,  0.0895,\n",
      "          -0.3233,  0.0000,  2.1434, -1.9777, -0.8420,  1.5641, -0.3258,\n",
      "          -1.0518,  1.6389, -1.7177, -0.2692,  0.0939, -0.6588,  0.0000,\n",
      "           2.2521,  0.0000, -1.4814,  2.4646,  1.0233,  2.0899,  1.6134,\n",
      "          -0.5221,  0.0000, -0.3739, -1.3323,  0.6963, -0.0887,  1.3407,\n",
      "           0.0000, -0.1989, -0.3119, -0.2724]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0847, 0.0864, 0.0794, 0.1422, 0.1143, 0.1847, 0.1103, 0.0655, 0.1019,\n",
      "         0.0306]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.6166e-01,  2.3819e-01, -1.8508e-01, -7.7210e-02, -2.4873e-01,\n",
      "          -1.9516e-01, -1.9172e-01, -1.3096e-01,  5.2609e-02,  1.1506e-02,\n",
      "           1.1103e-01, -5.6236e-02,  3.6405e-02,  2.8961e-01,  3.4851e-01,\n",
      "           1.6476e-01,  1.7803e-01,  1.2449e-01, -2.7666e-02,  2.7743e-01,\n",
      "          -3.5755e-01,  8.2097e-02,  1.2465e-02,  3.8683e-02, -6.2203e-02,\n",
      "          -1.0016e-01, -1.6580e-01, -2.2408e-03,  4.8838e-02, -1.2616e-01,\n",
      "           6.4303e-02, -4.0605e-02, -1.9505e-01,  1.4613e-01,  4.0302e-02,\n",
      "          -1.2576e-01, -1.7003e-01, -4.2856e-02, -1.0381e-01,  1.9952e-03,\n",
      "           1.8719e-01, -2.6174e-02, -4.9151e-02, -2.1291e-01,  1.5493e-01,\n",
      "          -1.1825e-01,  1.1665e-01, -2.1286e-01,  2.5273e-01,  9.5477e-02,\n",
      "          -1.8024e-02,  1.7102e-01, -3.1800e-01, -1.1885e-01, -3.6932e-02,\n",
      "           2.3782e-02,  1.1469e-02,  2.3041e-02, -1.1075e-01,  7.4740e-03,\n",
      "           1.6293e-01, -2.9629e-01, -7.7101e-02,  1.9306e-01,  7.4262e-03,\n",
      "          -9.5121e-02,  3.2520e-02,  1.5513e-01, -2.0907e-02,  1.7106e-02,\n",
      "           1.6668e-01,  2.3624e-01,  2.1634e-02, -4.0157e-02,  1.1068e-02,\n",
      "           7.8188e-02,  9.7679e-02,  2.2236e-01, -9.6723e-02, -1.4992e-01,\n",
      "          -1.6491e-01, -1.1219e-01, -1.2407e-01, -6.5586e-02,  1.8236e-02,\n",
      "           1.9172e-01, -4.7081e-02,  1.0983e-01,  8.8212e-02, -2.5848e-01,\n",
      "          -5.8800e-02,  1.7743e-01, -1.1513e-02, -1.0424e-01, -2.1476e-01,\n",
      "           7.8924e-02,  3.6989e-02,  1.6239e-01,  1.1896e-02, -1.6522e-02,\n",
      "          -3.2491e-03, -1.1593e-01,  2.2479e-01,  3.0266e-01, -5.1226e-02,\n",
      "           4.8090e-02, -3.7954e-03, -1.3993e-01,  2.4525e-02,  1.4941e-01,\n",
      "           8.9630e-02, -3.1905e-02, -8.0255e-02, -4.5505e-03,  1.6699e-01,\n",
      "          -8.5537e-02,  5.7923e-02, -1.3013e-01,  9.9345e-02,  1.0742e-01,\n",
      "           2.3113e-01, -3.3681e-02, -3.4851e-02,  5.5366e-02, -1.0334e-01,\n",
      "          -2.9650e-02,  2.0751e-01, -3.1744e-01,  3.5431e-01,  2.8442e-02,\n",
      "           1.2521e-01, -9.1949e-02,  1.2667e-01,  1.9524e-01,  7.7949e-02,\n",
      "           6.9845e-02,  1.4844e-01,  1.2636e-01, -1.0575e-01,  2.1464e-01,\n",
      "           2.6140e-01,  2.1935e-01, -2.7898e-01, -1.2726e-02,  1.1666e-01,\n",
      "          -1.5926e-01,  2.3591e-02,  2.5554e-01,  2.7184e-01,  1.8560e-01,\n",
      "          -3.4149e-01,  1.2759e-01, -2.7280e-01,  3.8684e-04, -1.9401e-01,\n",
      "           3.8096e-01,  1.7739e-01, -6.3284e-02,  2.9020e-02,  8.7437e-02,\n",
      "          -2.5674e-01, -4.2183e-03, -1.8248e-01,  7.6639e-02, -2.5193e-01,\n",
      "           3.5582e-02, -7.1864e-02,  2.7812e-02,  1.8397e-01,  6.2276e-02,\n",
      "          -1.1743e-01,  2.1141e-01,  7.6055e-02, -1.8382e-01,  1.4604e-01,\n",
      "           3.8582e-02, -5.6334e-02,  1.6618e-01,  5.0219e-01,  1.8236e-01,\n",
      "          -5.5891e-02, -1.6333e-01, -1.9522e-01, -1.9778e-02, -4.6452e-02,\n",
      "          -5.9559e-02, -2.5265e-01, -1.5187e-01, -2.5656e-01, -8.5758e-02,\n",
      "           1.9058e-02,  1.0525e-02, -1.9725e-01, -2.0913e-01,  4.4842e-02,\n",
      "           4.0433e-02,  1.8299e-02, -1.5003e-01,  1.0883e-01,  4.4278e-02,\n",
      "           4.3501e-02, -2.6821e-01,  2.2113e-01,  2.1734e-01,  1.0085e-02,\n",
      "          -1.1275e-01,  5.7215e-02,  2.4155e-01, -3.4457e-02,  2.4714e-01,\n",
      "           5.7430e-02,  1.7727e-01, -3.3585e-02,  1.9228e-01,  7.6245e-02,\n",
      "           3.8588e-02, -3.0140e-02,  9.1896e-02, -1.1948e-01,  1.0026e-01,\n",
      "           2.5472e-01, -7.2313e-02,  3.6285e-01, -2.3743e-01,  1.1035e-01,\n",
      "          -2.7766e-04, -2.0021e-03, -1.1186e-01, -4.9001e-01,  1.1020e-01,\n",
      "          -1.4075e-01, -1.2155e-01, -3.8883e-02,  9.6070e-02,  1.9204e-01,\n",
      "           5.3747e-02, -7.8063e-02, -5.2764e-02,  2.3913e-01,  1.8673e-01,\n",
      "           3.2173e-02, -1.2111e-01, -1.5485e-01,  9.5618e-02,  1.0681e-01,\n",
      "          -3.3966e-02,  1.4855e-02, -2.5017e-01,  7.3138e-02,  1.1733e-03,\n",
      "           2.5840e-01,  1.1775e-01,  1.8961e-02, -1.0425e-01, -3.0741e-02,\n",
      "          -1.4465e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000, -0.9458, -0.8553, -1.6620,  0.3462, -0.5441, -0.4662,\n",
      "          -2.7859,  1.2865, -0.3292,  0.0000, -0.1751,  1.1944,  0.1951,\n",
      "           0.0000,  1.0567, -1.0770,  0.2407, -2.0399, -0.6266,  1.3866,\n",
      "          -0.7012, -1.9255,  0.0000,  0.4598,  0.3261,  1.0399, -1.1749,\n",
      "           0.0000,  1.0926, -0.4214,  0.0000,  0.0000,  0.7889,  0.0000,\n",
      "          -0.5730,  0.2489,  2.1969, -0.6030,  1.2853,  0.1189,  1.5285,\n",
      "          -1.1620,  0.7428,  0.0000,  0.6818,  1.8612, -0.7747, -0.5097,\n",
      "          -0.2510, -2.0461, -0.5433, -0.9145, -1.0314, -0.1374,  1.9738,\n",
      "           0.4837,  0.4450, -0.8521,  1.1361,  0.0989, -0.5714, -1.8687,\n",
      "           1.9916,  1.1094,  1.0249,  0.1660, -0.4772,  0.5161,  0.9240,\n",
      "           1.2489,  0.9660, -1.0313, -0.0967,  0.5933, -0.6078,  0.0000,\n",
      "          -1.0709, -0.7551, -0.5178, -1.8023, -0.6840, -0.3919,  0.1991,\n",
      "           0.0000, -0.8886,  0.0000,  1.0887, -1.4831,  0.9210,  0.0000,\n",
      "          -1.2998,  0.0000, -1.7212,  0.0000, -0.5867, -0.0263, -0.9061,\n",
      "          -1.7372,  0.8018,  1.7627,  0.0000,  0.0000, -0.6608,  0.0000,\n",
      "          -0.2466, -1.0543,  0.0000, -0.2254, -0.1937, -1.6376,  1.3214,\n",
      "           0.0273,  0.0533, -0.6652, -0.7494, -0.6272, -0.8533,  0.1132,\n",
      "           1.0047, -1.1557, -1.1397, -0.5170,  0.0145, -0.9736, -0.2732,\n",
      "          -0.6060, -0.1319, -0.1723, -0.0954, -0.8499,  0.0475, -0.0179,\n",
      "           0.2337, -0.4043,  0.7885, -0.0784,  0.6850,  0.2331, -0.8108,\n",
      "           0.0000,  0.4995,  0.8457, -0.8095, -0.5832,  0.0000, -1.6286,\n",
      "          -1.0329,  0.6612, -0.6513, -0.5422,  1.9303, -0.5846,  0.8119,\n",
      "          -0.7266,  0.2983,  0.0000, -0.0594, -0.7950,  0.7898,  0.4763,\n",
      "          -0.1317, -0.8020, -1.9466,  1.2840,  0.0000, -0.6625,  0.0000,\n",
      "           0.0000,  2.4346,  0.4024,  0.0000,  0.0000,  0.7238, -0.8984,\n",
      "          -0.1678, -0.6240, -0.3743,  0.1260,  1.2847,  0.5654,  0.3202,\n",
      "           0.8298, -0.2894,  0.0000, -2.5888, -1.5761, -1.0892, -1.7530,\n",
      "          -1.1157, -0.0055, -0.2996, -1.0784, -0.2015,  0.0000, -0.2876,\n",
      "           0.7163,  1.7857,  0.8915, -0.5039,  0.0000, -2.2371, -1.8052,\n",
      "           0.2289, -1.9064,  0.0421,  0.0000,  0.1969,  1.9940, -1.3883,\n",
      "          -0.8055, -0.1590,  0.4579, -1.1302, -0.7722, -1.1337, -0.4054,\n",
      "           0.0000,  0.0000,  0.0954, -0.1889, -0.2927,  0.5407,  0.2161,\n",
      "          -0.6989,  0.5117, -0.2418,  2.3457, -1.0347,  0.4749,  0.0776,\n",
      "           1.1164, -0.8065,  1.1515,  1.7955,  0.3266, -0.1292,  0.2401,\n",
      "          -0.0861,  0.5506,  0.0762, -0.9607, -0.8298, -0.9496, -0.7274,\n",
      "          -0.1232,  0.1744, -0.8961,  1.1234, -0.3239,  1.2054, -0.4131,\n",
      "          -0.8030,  0.1134,  0.3283,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.2046, 0.0952, 0.0904, 0.2129, 0.0749, 0.0726, 0.0574, 0.0704, 0.0717,\n",
      "         0.0498]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1384,  0.0711, -0.1992, -0.0748, -0.2056, -0.0762, -0.2387,\n",
      "          -0.1060,  0.0656,  0.0509,  0.0539, -0.0780,  0.0182,  0.2305,\n",
      "           0.3178,  0.2345,  0.1562,  0.1650, -0.0815,  0.1579, -0.3373,\n",
      "           0.0620, -0.0409,  0.0736, -0.1763, -0.0625, -0.1067, -0.0080,\n",
      "           0.0669, -0.0915,  0.0606, -0.0042, -0.1048,  0.1161, -0.0544,\n",
      "          -0.2023, -0.0632, -0.0116,  0.0161, -0.0986,  0.1288, -0.0204,\n",
      "          -0.0033, -0.2054,  0.2153, -0.1042,  0.1858, -0.1477,  0.2384,\n",
      "          -0.0054, -0.0437,  0.0328, -0.2400, -0.1187, -0.1454,  0.0536,\n",
      "          -0.0275,  0.0255, -0.0550,  0.0215,  0.1185, -0.3156, -0.1181,\n",
      "           0.2346,  0.0543, -0.0148, -0.0357,  0.0649, -0.1368, -0.0353,\n",
      "           0.1584,  0.2414,  0.0712, -0.1182, -0.0181,  0.1439,  0.1017,\n",
      "           0.1385, -0.0934, -0.0833, -0.1745, -0.0225, -0.0570,  0.0033,\n",
      "           0.1208,  0.1346, -0.0492,  0.0807,  0.0353, -0.2092,  0.0051,\n",
      "           0.2812, -0.0595, -0.0782, -0.1637,  0.0979,  0.0524,  0.1647,\n",
      "           0.0569, -0.0811,  0.0543, -0.0217,  0.2210,  0.2807,  0.0228,\n",
      "           0.0888, -0.0706, -0.1188, -0.0252,  0.1498,  0.0583, -0.0174,\n",
      "          -0.1231,  0.0020,  0.1603, -0.0609,  0.1120, -0.0908,  0.0151,\n",
      "           0.0373,  0.1898, -0.0773, -0.1297,  0.0042, -0.1340,  0.0102,\n",
      "           0.0416, -0.3186,  0.3545,  0.0146,  0.0704, -0.0305,  0.1311,\n",
      "           0.1779,  0.1331,  0.0983,  0.1568,  0.1812,  0.0048,  0.1494,\n",
      "           0.1977,  0.2508, -0.3315,  0.0922,  0.0313, -0.1424,  0.1085,\n",
      "           0.2791,  0.1344,  0.2049, -0.3164,  0.0862, -0.1705, -0.0109,\n",
      "          -0.1562,  0.3972,  0.1944,  0.0230,  0.0136,  0.1118, -0.2731,\n",
      "           0.0099, -0.2702,  0.0389, -0.2806,  0.0132, -0.1263,  0.1168,\n",
      "           0.1010,  0.0399, -0.0662,  0.2919,  0.0413, -0.0897,  0.1962,\n",
      "           0.0625, -0.0050,  0.0565,  0.4382,  0.1600, -0.0955, -0.1247,\n",
      "          -0.2295,  0.0347,  0.0102, -0.1070, -0.1884, -0.1448, -0.2764,\n",
      "          -0.0508,  0.0237,  0.0405, -0.1960, -0.1852,  0.0234,  0.0530,\n",
      "           0.0260, -0.0994,  0.0872,  0.0544, -0.0069, -0.2191,  0.1606,\n",
      "           0.2115, -0.1211, -0.0593,  0.0328,  0.1800, -0.0700,  0.2518,\n",
      "           0.0558,  0.1826, -0.0448,  0.1409,  0.0868, -0.0575, -0.0560,\n",
      "           0.1406, -0.1613,  0.0315,  0.2690, -0.1509,  0.4171, -0.2376,\n",
      "           0.0127,  0.0010,  0.0146, -0.1005, -0.4483,  0.0826, -0.0671,\n",
      "          -0.1043, -0.0261,  0.1223,  0.1608, -0.0281, -0.1398, -0.0063,\n",
      "           0.1987,  0.1595,  0.0910, -0.1646, -0.2070,  0.1448,  0.0882,\n",
      "          -0.0237,  0.0705, -0.2869,  0.0130, -0.0290,  0.2563,  0.0851,\n",
      "           0.0264, -0.0744, -0.0774, -0.1034]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7264e-01,  0.0000e+00,  3.1517e-01, -1.0851e+00, -1.1729e+00,\n",
      "           7.4160e-01, -1.9146e+00,  1.3513e+00,  1.9010e-01,  0.0000e+00,\n",
      "           0.0000e+00,  6.0257e-01,  2.2919e-01, -9.1658e-01, -3.1840e+00,\n",
      "          -6.8280e-02, -1.6337e+00, -9.4356e-01,  1.3603e+00, -1.4358e+00,\n",
      "          -1.4034e-01, -5.2454e-01, -1.1198e+00, -2.5958e+00,  0.0000e+00,\n",
      "           1.3918e+00, -6.1988e-01,  1.9982e+00,  1.2776e-01,  5.5515e-01,\n",
      "           9.1579e-01, -3.7970e-03,  0.0000e+00,  2.0170e+00, -6.3595e-02,\n",
      "          -1.4086e+00, -1.1162e-01, -8.1740e-01,  3.1527e-01,  8.6075e-02,\n",
      "           8.6340e-01, -8.9930e-01,  1.0090e+00, -1.5640e+00,  1.9449e+00,\n",
      "          -3.0039e-01,  7.0638e-01, -6.0240e-01, -1.0210e+00,  1.1172e+00,\n",
      "          -1.3233e+00,  2.6783e+00,  0.0000e+00,  0.0000e+00,  2.2803e-01,\n",
      "          -3.1017e-01, -1.4341e+00, -9.6290e-02,  1.2759e+00,  2.1823e+00,\n",
      "          -1.0066e+00,  3.5846e-02, -2.8018e-01,  0.0000e+00,  0.0000e+00,\n",
      "           3.9356e-01,  5.7813e-01,  1.1653e+00,  1.5812e+00, -1.4155e+00,\n",
      "           4.2730e-01,  2.9639e-01,  0.0000e+00,  0.0000e+00, -2.1417e-01,\n",
      "           0.0000e+00,  5.2599e-01,  1.3992e+00,  1.0274e+00, -7.9425e-01,\n",
      "           7.5846e-01, -1.0048e+00,  7.5839e-01,  1.0588e+00, -1.2157e+00,\n",
      "          -1.1333e-01,  0.0000e+00,  5.4869e-01, -9.4498e-01, -1.9015e+00,\n",
      "           5.2919e-01,  9.8741e-01,  1.7021e+00,  9.4430e-01,  0.0000e+00,\n",
      "          -1.5948e-02,  3.5439e-01, -1.1760e+00,  1.3726e+00,  2.4481e+00,\n",
      "           2.4346e-01,  4.4130e-02, -4.6665e-01, -9.8946e-01,  1.6411e+00,\n",
      "          -1.0241e+00,  3.0302e+00,  6.2077e-01, -1.0197e-01, -1.2357e+00,\n",
      "           1.8996e-01, -5.0333e-01, -5.7116e-01,  7.1254e-01,  0.0000e+00,\n",
      "           6.3262e-01,  4.0379e-01,  2.2345e-01, -2.3272e+00,  2.9225e-02,\n",
      "          -8.1478e-01, -1.4119e+00, -1.8386e+00,  6.0325e-01, -9.5716e-01,\n",
      "          -2.0099e-01,  4.0319e-02,  2.1509e+00,  1.3966e+00, -2.0883e+00,\n",
      "          -9.2624e-01,  4.4991e-01, -1.1683e+00,  4.2550e-01, -4.6829e-01,\n",
      "          -7.4634e-01, -1.0649e+00, -9.7549e-01, -1.9432e-02,  2.3980e+00,\n",
      "           6.9866e-01, -1.1219e+00,  1.6919e+00, -1.4043e-01, -6.7003e-01,\n",
      "           3.3228e-02,  7.5985e-01,  4.2291e-01, -1.0340e+00, -9.5227e-02,\n",
      "           1.5601e+00,  5.8674e-01, -3.3841e-01,  6.5777e-01,  1.8415e+00,\n",
      "          -2.5274e-01, -2.1786e-01,  6.2397e-01, -2.3639e+00,  1.0560e+00,\n",
      "           3.0291e-01, -7.7224e-02,  1.5530e-01,  0.0000e+00,  0.0000e+00,\n",
      "           1.6826e+00,  1.8528e+00,  2.7175e-01, -1.2704e+00, -7.1305e-01,\n",
      "          -1.2243e+00, -1.0942e+00,  0.0000e+00,  0.0000e+00, -3.0609e+00,\n",
      "           0.0000e+00,  4.9760e-01,  8.2980e-01,  3.1711e-01, -7.9309e-01,\n",
      "           2.7252e-01,  2.3401e+00,  1.0583e+00,  8.3905e-01,  0.0000e+00,\n",
      "           7.2791e-01,  5.9867e-01,  3.5976e-01,  8.4319e-01, -1.8311e+00,\n",
      "           1.3638e+00,  2.1601e+00,  3.3587e-01, -1.0157e+00, -1.1729e+00,\n",
      "          -2.2162e+00,  1.6677e+00,  2.1533e+00,  3.6345e-01,  0.0000e+00,\n",
      "           3.2559e-02,  0.0000e+00, -1.2770e+00, -5.4308e-01, -4.0770e-01,\n",
      "          -1.4477e+00,  9.5343e-01, -8.5204e-01,  8.2951e-01, -1.5605e+00,\n",
      "           0.0000e+00,  6.7550e-01,  0.0000e+00,  0.0000e+00,  1.8938e+00,\n",
      "           1.3090e+00,  5.8032e-01, -2.3179e+00,  1.5503e+00, -2.2256e-01,\n",
      "          -2.2736e-01,  1.7343e+00,  2.7656e-01, -1.5524e+00,  9.2285e-01,\n",
      "          -1.2244e+00, -8.4888e-01, -1.8026e+00, -7.5217e-04,  3.7322e-01,\n",
      "          -1.5739e+00, -1.2387e-01,  9.6636e-01, -1.7375e+00,  1.6948e+00,\n",
      "           0.0000e+00,  6.3403e-01, -1.7230e+00,  0.0000e+00, -1.7171e+00,\n",
      "           0.0000e+00, -2.7300e-01,  0.0000e+00,  1.2392e+00, -1.2283e+00,\n",
      "           0.0000e+00, -5.0851e-01,  5.4285e-01, -2.6129e-01, -1.0224e+00,\n",
      "           1.3339e+00,  3.1135e-01, -5.1005e-02, -2.2878e-01, -1.6131e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0475, 0.1336, 0.1408, 0.0663, 0.1589, 0.1650, 0.1057, 0.0633, 0.0631,\n",
      "         0.0558]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3512, -0.0358,  0.0740,  ..., -0.1123, -0.0137, -0.4843],\n",
      "        [-0.1545,  0.1368, -0.0102,  ...,  0.2145,  0.1240, -0.3899],\n",
      "        [-0.1814, -0.0258, -0.1759,  ..., -0.2081, -0.3684,  0.3987],\n",
      "        ...,\n",
      "        [ 0.3823,  0.1596, -0.3689,  ..., -0.4114,  0.3207,  0.0398],\n",
      "        [ 0.6870,  0.5633, -0.7346,  ..., -0.4178, -0.0167,  0.2175],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1124,  0.2478, -0.1195, -0.1016, -0.2250, -0.1824, -0.1883,\n",
      "          -0.1015,  0.0569,  0.0322,  0.1141, -0.0034,  0.0599,  0.3357,\n",
      "           0.3737,  0.1690,  0.1637,  0.0943, -0.0213,  0.2519, -0.3488,\n",
      "           0.0973, -0.0028,  0.0253, -0.0507, -0.1214, -0.1658,  0.0610,\n",
      "           0.0690, -0.1098,  0.0148, -0.0007, -0.1806,  0.1677,  0.0133,\n",
      "          -0.1075, -0.1555, -0.0569, -0.0964, -0.0229,  0.1557, -0.0543,\n",
      "          -0.0494, -0.2168,  0.1213, -0.1343,  0.1257, -0.2067,  0.2451,\n",
      "           0.1309,  0.0401,  0.1925, -0.2982, -0.0644,  0.0072,  0.0351,\n",
      "           0.0569, -0.0034, -0.1170, -0.0379,  0.1903, -0.2790, -0.0316,\n",
      "           0.1836,  0.0013, -0.0835,  0.0415,  0.1563, -0.0171,  0.0251,\n",
      "           0.1570,  0.1875,  0.0315, -0.0200,  0.0524,  0.0818,  0.0684,\n",
      "           0.1811, -0.1219, -0.1764, -0.1359, -0.0710, -0.1079, -0.0711,\n",
      "           0.0404,  0.1667, -0.0529,  0.1272,  0.0413, -0.2249, -0.0794,\n",
      "           0.1701, -0.0016, -0.0832, -0.2060,  0.0468, -0.0022,  0.1400,\n",
      "          -0.0272, -0.0903,  0.0312, -0.1582,  0.2351,  0.2910, -0.0350,\n",
      "           0.0813, -0.0086, -0.1731,  0.0605,  0.1546,  0.0918, -0.0446,\n",
      "          -0.1285,  0.0509,  0.2039, -0.0805,  0.0888, -0.1378,  0.1112,\n",
      "           0.1160,  0.1755, -0.0574, -0.0164,  0.0087, -0.0760,  0.0032,\n",
      "           0.2348, -0.2927,  0.2897,  0.0462,  0.0862, -0.0428,  0.0882,\n",
      "           0.1657,  0.1061,  0.0074,  0.1054,  0.1292, -0.0957,  0.2020,\n",
      "           0.2543,  0.1803, -0.2662, -0.0217,  0.1125, -0.1718,  0.0279,\n",
      "           0.1979,  0.3030,  0.1410, -0.2901,  0.1055, -0.2603, -0.0454,\n",
      "          -0.2522,  0.3720,  0.1977, -0.1028,  0.0141,  0.1291, -0.2163,\n",
      "           0.0260, -0.1742,  0.0567, -0.2695,  0.0069, -0.0635,  0.0461,\n",
      "           0.1929,  0.0369, -0.0560,  0.2261, -0.0034, -0.1708,  0.1738,\n",
      "           0.0645, -0.0554,  0.1948,  0.4826,  0.1836, -0.0562, -0.2332,\n",
      "          -0.1625, -0.0410, -0.0691, -0.0635, -0.2153, -0.1809, -0.2917,\n",
      "          -0.0819,  0.0659,  0.0092, -0.1804, -0.1805,  0.0476,  0.0693,\n",
      "           0.0581, -0.1466,  0.1611,  0.0436,  0.0375, -0.2725,  0.2064,\n",
      "           0.1624,  0.0312, -0.1058,  0.0819,  0.1748, -0.0313,  0.2775,\n",
      "           0.0173,  0.2328, -0.0272,  0.1591,  0.0971,  0.0727, -0.0400,\n",
      "           0.0602, -0.0962,  0.1278,  0.2036, -0.0779,  0.3410, -0.2307,\n",
      "           0.1091, -0.0547, -0.0032, -0.0711, -0.4494,  0.0669, -0.0855,\n",
      "          -0.0529, -0.0254,  0.1282,  0.1951,  0.0730, -0.0486, -0.0491,\n",
      "           0.1725,  0.1625,  0.0666, -0.0972, -0.1430,  0.1351,  0.0613,\n",
      "          -0.0192,  0.0332, -0.2293,  0.0661, -0.0337,  0.2297,  0.1061,\n",
      "           0.0169, -0.0754, -0.0097,  0.0195]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0857,  0.3989, -0.9670, -0.6820,  0.3765, -0.2018,  1.4650,\n",
      "          -0.0833, -3.5854,  0.9068,  0.4290, -0.6293,  2.6061, -0.6297,\n",
      "          -0.5416, -0.1580,  0.8517,  1.0951,  0.4552,  0.0000, -0.6339,\n",
      "          -0.3837,  0.0000,  1.5116,  0.7540, -0.0753, -0.1877, -0.7591,\n",
      "           1.6542,  0.8617,  1.2322,  1.2192, -1.0345, -0.0827, -1.5352,\n",
      "           1.3954,  0.2808, -3.7460,  0.1980,  1.6016, -0.4589, -1.3991,\n",
      "          -0.2683, -1.7169, -1.5252,  0.6673,  0.5411,  0.3701, -1.3411,\n",
      "           0.1437, -0.6289,  2.7536,  0.6106, -1.0299, -0.0258,  0.2029,\n",
      "          -0.8825, -1.2532, -0.2365, -0.4252,  1.1015,  0.0000, -0.2038,\n",
      "          -0.5021, -2.9654,  0.5505,  1.2793, -1.2885,  0.4118,  0.5264,\n",
      "          -1.2676, -0.0305,  0.7075, -3.6429,  0.3266,  0.0000, -0.1599,\n",
      "           1.0632, -0.0585, -0.1202, -1.4007,  2.1323, -0.9251,  1.0057,\n",
      "          -0.2079,  0.4343,  1.6621, -0.9751, -0.1031, -0.5816,  0.0000,\n",
      "           1.1006, -0.6223, -1.1354,  0.4675, -1.1711,  0.0344,  0.6293,\n",
      "           1.7208, -0.7808,  2.6980, -1.4632,  1.0762,  1.4547, -0.6666,\n",
      "          -0.7626,  1.2131,  0.1275, -1.4732,  0.0000, -0.2489,  0.1345,\n",
      "          -1.0490,  0.0000, -1.6542, -2.9908, -0.0562, -0.5016, -0.1932,\n",
      "           0.0000, -1.4674,  0.7026, -1.4610,  0.0000, -0.9589, -1.3097,\n",
      "           0.8980,  0.1706,  1.2861, -0.7528, -0.8232,  0.5297, -1.5836,\n",
      "           0.9843,  0.2762, -0.5897,  0.6601,  0.5734, -1.1586, -1.0108,\n",
      "          -0.3891,  0.6779, -0.7903, -0.1019, -1.6866, -0.1015, -0.5434,\n",
      "           0.0000, -0.7556,  0.1774,  1.9994, -0.1999, -1.9314, -0.4063,\n",
      "           0.4416, -0.1945,  0.0000, -0.1289,  0.0396,  0.0000, -0.0261,\n",
      "           0.0000,  0.4812, -0.5497, -0.5277,  0.0000,  0.2818,  0.0848,\n",
      "          -0.3580, -0.4782,  0.7385, -0.0325,  0.0198,  0.0000,  1.2781,\n",
      "           0.0000, -0.9881, -2.0782,  1.9700,  0.0864, -0.0297,  0.0351,\n",
      "           0.6718,  0.0000,  0.0000, -0.3410, -2.7846, -0.7850,  0.0000,\n",
      "           1.0126,  3.0757,  0.4946, -0.1441, -0.5950,  0.0000,  2.1662,\n",
      "          -1.1885,  0.5348,  1.8126, -0.9478, -1.6623, -1.0151,  1.2418,\n",
      "          -0.1221,  0.2320,  0.0000, -2.2935,  0.6820, -1.0750, -0.4715,\n",
      "           2.8691, -0.5734, -0.3412,  0.7935,  0.0298, -0.6851, -1.0200,\n",
      "           0.9663, -0.2460,  2.1703, -1.0831,  0.0000, -1.8445,  0.0000,\n",
      "           0.3371,  0.7048,  0.0000, -0.6281,  0.2923, -1.5793, -1.1091,\n",
      "           1.5818, -0.6144,  1.3099, -2.9807,  0.0000,  0.5852,  0.0436,\n",
      "          -1.5810, -0.2877,  0.7415, -3.2497, -0.3048, -0.8528,  0.0000,\n",
      "           0.2752,  0.2751,  0.2527,  0.2610,  0.3867, -0.3656, -0.1583,\n",
      "          -0.5542,  0.0000, -1.1473, -1.1316]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0323, 0.0513, 0.0785, 0.0739, 0.1017, 0.3256, 0.0725, 0.0913, 0.0730,\n",
      "         0.0999]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3524, -0.0361,  0.0712,  ..., -0.1143, -0.0106, -0.4873],\n",
      "        [ 0.1267,  0.1329,  0.2628,  ...,  0.1101,  0.0915,  0.0413],\n",
      "        [ 0.0361,  0.2128, -0.0530,  ..., -0.2869,  0.4924,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.3295e-01,  2.2861e-01, -3.1897e-01, -9.0885e-03, -1.9770e-01,\n",
      "          -1.8477e-01, -3.1611e-02, -2.7595e-01,  6.3584e-02, -4.9389e-03,\n",
      "           9.9329e-02, -1.3889e-01, -2.1137e-01,  2.8099e-02,  2.3395e-01,\n",
      "          -4.6004e-02, -7.4501e-02,  1.7071e-01, -3.5558e-01, -6.4784e-02,\n",
      "          -2.5751e-01, -1.7763e-01,  4.0975e-02,  3.1486e-02, -1.4929e-01,\n",
      "          -2.3468e-01, -6.2300e-02, -3.0535e-01, -3.5803e-03, -9.8718e-02,\n",
      "           1.4494e-01, -1.7671e-01, -2.6348e-01, -9.0039e-02, -6.4004e-02,\n",
      "           5.5399e-02, -3.9451e-01, -2.0582e-01, -2.8911e-01, -1.8748e-02,\n",
      "          -1.1176e-01,  4.6974e-03, -1.3132e-01, -7.4231e-03,  2.4311e-01,\n",
      "           9.7566e-02, -6.4241e-02, -1.7264e-01,  1.7361e-01,  8.4955e-03,\n",
      "          -2.0104e-01, -1.8120e-01, -2.6938e-01, -1.6088e-01, -2.0697e-01,\n",
      "          -3.7687e-02, -1.4759e-01,  2.1044e-01, -3.4969e-03,  3.2971e-01,\n",
      "          -5.6478e-02, -1.2146e-01, -1.2141e-01,  1.1807e-01, -1.1557e-01,\n",
      "           2.9070e-02, -1.2514e-03,  1.2809e-01, -2.5666e-01,  1.1380e-01,\n",
      "           6.6411e-02,  2.8470e-01, -1.2485e-01,  2.9030e-01, -2.9459e-01,\n",
      "           2.6028e-02,  3.4212e-01,  1.5148e-01, -1.4555e-01,  8.3008e-02,\n",
      "          -3.6513e-01, -3.3064e-01, -3.6303e-01, -2.6547e-02, -7.4435e-02,\n",
      "           1.7009e-01,  1.3947e-01,  1.8887e-02,  1.6513e-01, -1.2830e-01,\n",
      "           1.8704e-01,  4.1090e-04, -7.5344e-02, -9.4066e-02,  1.3157e-01,\n",
      "           2.0808e-01,  1.7604e-01,  2.8895e-01, -1.8488e-01,  3.1889e-01,\n",
      "          -3.1256e-01,  1.1560e-01,  1.9812e-01,  6.6391e-02, -2.0462e-01,\n",
      "          -1.5472e-01,  2.3013e-01,  7.8571e-02,  8.4008e-03,  2.4927e-01,\n",
      "           2.2695e-01, -1.9357e-02,  1.1444e-01, -1.4247e-01, -4.5515e-02,\n",
      "          -5.8277e-02,  5.1522e-02, -2.0010e-01, -1.3614e-01, -1.5835e-01,\n",
      "           1.8984e-01, -1.1995e-01, -2.3053e-01, -4.9238e-02, -3.0112e-01,\n",
      "          -1.5031e-01,  9.3742e-02, -1.0890e-01,  2.4289e-01,  7.1454e-02,\n",
      "           2.2434e-01, -4.0982e-01,  3.0058e-01,  1.8583e-01, -1.9033e-01,\n",
      "           5.5563e-02,  2.2967e-01,  1.0218e-01, -2.6710e-02,  2.3636e-01,\n",
      "          -9.1763e-02,  3.1776e-01, -1.1643e-01,  1.2406e-01,  8.1128e-02,\n",
      "           1.2207e-01,  1.1162e-01,  2.5704e-01,  1.0482e-01,  3.1669e-01,\n",
      "          -3.2581e-01,  4.9778e-04,  1.7277e-01,  2.1412e-01,  3.5433e-02,\n",
      "           3.2312e-01, -6.6504e-02,  2.5999e-01,  2.1373e-01, -5.0224e-02,\n",
      "          -1.0669e-01, -8.1644e-02, -2.6944e-01,  3.7326e-01, -1.8105e-02,\n",
      "           1.2215e-01, -6.9829e-02, -1.5917e-01,  9.9841e-02,  3.1290e-01,\n",
      "          -1.8742e-01, -4.3631e-02,  3.3930e-01,  7.5546e-02, -9.7948e-02,\n",
      "          -2.8563e-01, -4.0506e-02,  6.6392e-02,  3.2811e-01, -2.7373e-01,\n",
      "          -1.6815e-01, -4.5717e-02, -2.0136e-01, -1.4081e-01,  2.6785e-01,\n",
      "           2.4950e-01, -3.4243e-01,  1.1293e-01,  1.7091e-01, -2.7124e-01,\n",
      "           7.5336e-02,  1.5537e-01, -3.6751e-01, -1.5195e-01,  4.3616e-02,\n",
      "          -7.4104e-02, -3.5145e-02, -5.2373e-03, -1.7072e-01,  4.1278e-02,\n",
      "          -7.7022e-02,  1.4602e-01, -7.2974e-02,  3.9309e-01,  6.0574e-02,\n",
      "           5.9665e-03, -1.3725e-01,  3.7449e-01, -2.2217e-02,  2.4910e-02,\n",
      "           1.7675e-01, -3.2114e-01, -1.4987e-01,  9.0884e-02, -2.0746e-01,\n",
      "           1.5482e-01, -9.5094e-02,  2.0448e-01, -3.3600e-01,  2.8495e-01,\n",
      "           3.6672e-01, -1.1395e-01,  2.1956e-01, -2.0759e-01,  1.1606e-01,\n",
      "           2.5755e-01,  2.2067e-01, -1.7532e-01, -4.1151e-01,  1.7974e-01,\n",
      "          -2.8648e-01, -1.5376e-01, -7.4213e-02, -3.0712e-01, -4.9375e-02,\n",
      "           1.2141e-01, -3.2910e-01,  2.0390e-02,  2.4242e-01, -1.5254e-02,\n",
      "          -1.0966e-01, -1.4771e-01, -3.8975e-01,  6.9050e-02,  3.1431e-01,\n",
      "          -6.5962e-02, -2.3781e-01, -2.3815e-01,  1.1049e-01,  9.8397e-03,\n",
      "           1.5110e-01,  9.3278e-02, -1.5341e-01, -2.2372e-01,  1.2712e-01,\n",
      "           5.6878e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4819,  1.6543, -1.0095, -1.1127,  0.0000,  0.6460,\n",
      "           0.0000, -0.9023,  0.0940, -0.2098,  0.3159,  0.1274, -0.9578,\n",
      "          -0.3085,  0.3244, -1.8655, -2.1364,  0.6083,  0.0000,  0.7695,\n",
      "           0.2828, -1.2567, -0.9730,  1.1926,  1.4264, -1.6558,  1.0544,\n",
      "           0.9846, -1.2883,  0.3068, -0.9455, -0.7691, -1.5225, -0.3683,\n",
      "           0.4842, -0.9885, -0.3511,  0.3282,  0.6283,  0.6072, -1.1770,\n",
      "           0.3728,  1.2540, -1.7956,  1.9479, -1.4979, -0.4430, -0.2786,\n",
      "           1.1465,  0.8652,  0.0368, -0.0720, -1.0044, -0.2961, -0.8050,\n",
      "          -1.8694,  0.5099,  1.5733,  2.0580, -0.8819, -0.7340,  1.9471,\n",
      "          -0.9065, -0.8593,  0.1078,  0.6390, -0.6174,  0.0212,  0.4296,\n",
      "          -1.5896, -0.0284, -0.6441,  1.4255, -0.4460,  0.5579, -3.6197,\n",
      "          -0.6177, -1.4066, -0.3111,  0.8704,  1.3125,  0.8812, -0.9604,\n",
      "           0.6943,  0.6931,  0.0461, -2.9900,  0.8149, -0.0184, -1.4908,\n",
      "           0.3247, -1.2889,  2.3925,  0.0000,  0.2151, -1.1101,  1.0776,\n",
      "           1.5509, -2.1247,  0.0145, -0.6640,  0.0000, -1.8825,  0.4071,\n",
      "           1.4168,  0.0000, -0.9153,  0.0000,  1.8166, -1.4325,  0.1791,\n",
      "          -0.4977,  1.3007, -0.1467, -0.1099,  0.3373, -1.6428,  0.8517,\n",
      "          -1.2944, -1.3464, -0.0995,  0.8782,  0.5349,  0.2248,  0.8190,\n",
      "          -0.2022, -1.0699,  0.1247, -0.4279, -1.2475,  2.3283,  0.0000,\n",
      "           0.3274, -0.0089, -0.6386, -0.0634, -0.5998, -0.4514,  1.0983,\n",
      "           0.5453, -1.1802, -2.2952, -0.8860,  0.2165, -0.1880,  0.0000,\n",
      "          -0.0827,  1.5432, -0.7186,  0.3217,  0.0000,  1.8152, -1.9312,\n",
      "           0.5128, -0.3341, -0.2285, -0.7582,  0.9341, -0.0179,  0.2297,\n",
      "          -1.1454,  2.2619, -1.7648, -0.3903, -0.6923,  0.5300,  2.1359,\n",
      "          -1.6403, -2.7424,  1.2546, -2.0856, -0.0064, -1.1602, -0.9213,\n",
      "          -0.7985, -0.3068, -0.4307,  0.1182, -1.5138,  0.1504, -0.4529,\n",
      "           0.1996,  0.9702,  0.4842, -0.0759, -1.5025, -0.2144,  0.4038,\n",
      "          -1.4625,  1.0716,  0.6060,  0.5037, -0.5083,  0.7251,  0.0000,\n",
      "           1.8720,  0.0421, -0.8386, -0.2757,  0.0000, -0.2978,  0.2826,\n",
      "           0.3538, -0.0091, -0.7148,  0.6958,  2.0166, -0.7499,  1.8922,\n",
      "           0.0000,  0.1562,  0.0000,  0.1013, -0.5910, -0.0228, -0.1427,\n",
      "           0.0000,  0.4080,  0.0000, -0.6885,  1.8593,  0.6065,  0.4727,\n",
      "           0.0287,  1.5296, -0.3650, -0.2608,  0.8418, -0.2544,  0.7765,\n",
      "          -0.5518,  1.2382,  0.0931,  2.0765,  0.5543, -1.7044,  2.7788,\n",
      "           0.0000,  1.8027, -0.8496,  0.0000, -1.0500, -0.8543,  0.1357,\n",
      "          -1.7793,  0.3816,  1.9828,  0.5690,  0.5474, -1.7499,  0.3684,\n",
      "           0.1555,  0.0000, -2.7262,  0.4074]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0319, 0.1351, 0.1082, 0.0495, 0.1752, 0.2539, 0.0514, 0.0512, 0.0791,\n",
      "         0.0645]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3524, -0.0361,  0.0712,  ..., -0.1143, -0.0106, -0.4873],\n",
      "        [ 0.1267,  0.1329,  0.2628,  ...,  0.1101,  0.0915,  0.0413],\n",
      "        [ 0.0361,  0.2128, -0.0530,  ..., -0.2869,  0.4924,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.2277e-01,  2.0209e-01, -2.7089e-01, -1.0761e-02, -1.1808e-01,\n",
      "          -1.1499e-01, -1.0189e-01, -2.2783e-01,  6.5768e-02,  2.4176e-02,\n",
      "           5.7953e-02, -9.3056e-02, -1.8894e-01,  6.8895e-02,  2.2592e-01,\n",
      "           8.2790e-04, -1.0141e-01,  1.7282e-01, -4.0174e-01, -9.4422e-02,\n",
      "          -2.6439e-01, -1.4558e-01,  7.6213e-03, -5.9471e-02, -1.2764e-01,\n",
      "          -2.1382e-01, -1.7022e-02, -2.9065e-01,  4.4541e-02, -7.4060e-02,\n",
      "           1.4744e-01, -1.1703e-01, -2.5415e-01, -5.0912e-02, -9.4577e-02,\n",
      "           1.9786e-02, -4.2012e-01, -2.0847e-01, -2.6523e-01, -3.6639e-02,\n",
      "          -1.0322e-01,  5.0059e-02, -9.0850e-02, -4.5592e-02,  2.4780e-01,\n",
      "           7.5366e-02, -1.8108e-03, -8.2650e-02,  1.9759e-01,  3.0937e-03,\n",
      "          -1.8154e-01, -2.5778e-01, -2.2424e-01, -2.0785e-01, -2.5840e-01,\n",
      "          -4.3019e-02, -1.4503e-01,  2.2097e-01, -2.2094e-02,  3.1909e-01,\n",
      "          -2.6227e-02, -1.4329e-01, -8.5611e-02,  1.4457e-01, -1.1359e-01,\n",
      "           9.2751e-03,  1.4131e-02,  9.7148e-02, -2.8486e-01,  1.2112e-01,\n",
      "           1.0994e-01,  3.0803e-01, -1.6192e-01,  2.7363e-01, -3.1264e-01,\n",
      "           4.1573e-02,  3.6027e-01,  1.1680e-01, -1.1930e-01,  4.4781e-02,\n",
      "          -3.9948e-01, -2.8432e-01, -3.4744e-01,  5.9680e-03, -5.5058e-02,\n",
      "           1.4647e-01,  1.8258e-01,  3.3710e-02,  1.2904e-01, -5.7536e-02,\n",
      "           1.3647e-01,  1.8045e-02, -1.0215e-01, -1.2844e-01,  1.6835e-01,\n",
      "           2.4129e-01,  1.9411e-01,  2.7684e-01, -1.7571e-01,  3.0368e-01,\n",
      "          -3.1076e-01,  1.2089e-01,  2.0515e-01,  5.2134e-02, -1.5402e-01,\n",
      "          -1.5853e-01,  2.3427e-01,  3.8262e-02, -3.6476e-03,  2.5703e-01,\n",
      "           1.7497e-01,  7.2452e-03,  6.8852e-02, -7.7136e-02,  4.2874e-02,\n",
      "          -6.7762e-02,  7.7031e-02, -2.2082e-01, -1.2308e-01, -1.7248e-01,\n",
      "           1.9746e-01, -9.1423e-02, -2.0345e-01, -3.9614e-02, -3.4585e-01,\n",
      "          -1.5352e-01,  1.3601e-01, -7.5159e-02,  2.6807e-01,  1.2187e-01,\n",
      "           1.8733e-01, -3.9195e-01,  2.7504e-01,  1.6980e-01, -2.0293e-01,\n",
      "          -1.2276e-02,  2.1467e-01,  1.2428e-01,  1.0021e-01,  2.4437e-01,\n",
      "          -7.2015e-02,  3.3370e-01, -7.0628e-02,  1.2526e-01,  3.0089e-02,\n",
      "           1.2742e-01,  1.7108e-01,  2.5109e-01,  8.2272e-02,  2.9079e-01,\n",
      "          -3.2633e-01, -2.8120e-03,  2.0397e-01,  2.4562e-01,  4.6598e-03,\n",
      "           3.4880e-01, -3.6682e-02,  2.9222e-01,  1.6412e-01,  3.8519e-02,\n",
      "          -1.0312e-01, -1.1118e-02, -2.5659e-01,  3.6461e-01, -8.9352e-02,\n",
      "           6.4858e-02, -6.2198e-02, -1.5107e-01, -4.0943e-02,  2.7573e-01,\n",
      "          -1.4633e-01, -8.0613e-02,  2.9107e-01,  1.5839e-01, -3.8056e-02,\n",
      "          -2.9422e-01, -3.3972e-02,  5.1314e-02,  2.9413e-01, -2.8012e-01,\n",
      "          -1.6540e-01,  1.5940e-02, -2.0818e-01, -1.7317e-01,  2.7774e-01,\n",
      "           2.1035e-01, -2.7434e-01,  6.5456e-02,  1.2486e-01, -2.7802e-01,\n",
      "           1.2594e-01,  9.8573e-02, -3.4971e-01, -1.2147e-01, -1.6183e-02,\n",
      "          -3.1207e-02,  3.1572e-02,  2.5481e-02, -1.4975e-01, -3.3000e-03,\n",
      "          -7.6106e-02,  1.1044e-01, -5.5821e-02,  3.6960e-01,  2.2744e-02,\n",
      "           2.4681e-02, -1.4871e-01,  3.6929e-01, -5.8116e-05,  2.6592e-02,\n",
      "           1.6011e-01, -3.2462e-01, -1.6482e-01,  1.9049e-02, -2.0965e-01,\n",
      "           8.7095e-02,  1.8950e-02,  2.3972e-01, -3.7515e-01,  2.4587e-01,\n",
      "           3.6126e-01, -7.5000e-02,  2.3489e-01, -1.7718e-01,  6.3836e-02,\n",
      "           2.9531e-01,  1.9273e-01, -1.7878e-01, -4.5948e-01,  1.4586e-01,\n",
      "          -2.5599e-01, -1.8142e-01, -8.1258e-02, -2.7305e-01, -2.1580e-02,\n",
      "           1.0479e-01, -3.3282e-01, -1.7915e-03,  2.4055e-01, -8.8662e-06,\n",
      "          -8.0626e-02, -1.2461e-01, -4.2442e-01,  1.0194e-01,  3.5882e-01,\n",
      "          -8.5944e-02, -2.3198e-01, -2.4913e-01,  2.5008e-02, -8.3634e-02,\n",
      "           1.4024e-01,  1.2185e-01, -1.1046e-01, -2.2763e-01,  1.6842e-01,\n",
      "           4.9578e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7781, -1.6519, -0.1826, -0.7321,  2.5180, -1.9080,\n",
      "          -0.0327,  0.9501,  1.1944,  1.4103, -0.7569, -0.0650,  0.0645,\n",
      "           1.0464,  1.8853,  0.8702, -0.7848, -0.6403, -1.4035, -0.4985,\n",
      "          -0.3791,  1.1427,  0.2328,  0.1893, -0.6130,  1.4043, -0.1511,\n",
      "          -1.0410,  0.4962, -0.5711,  0.6008, -1.6989,  0.2317, -0.0797,\n",
      "           0.1482,  0.6451, -2.2132,  0.0000,  0.1024, -0.6922, -0.4366,\n",
      "          -1.0644,  0.8181, -0.6329, -0.6567,  1.3726,  0.9367,  1.6036,\n",
      "           0.3695, -1.0080, -1.1718, -1.1122,  1.2531, -1.9748,  1.7089,\n",
      "           0.5928, -1.8922,  0.3415, -0.2936, -0.7705,  0.0000, -0.5941,\n",
      "          -1.6817, -0.8354,  1.2345, -0.3576,  0.2897, -0.7527, -1.1648,\n",
      "           2.2478,  0.7807,  0.2704,  1.2049, -0.3980,  0.3547,  0.2294,\n",
      "          -0.1574, -0.9149,  0.2959, -0.1448,  1.2866,  0.4651,  1.2968,\n",
      "           0.7706,  0.6606,  1.0453, -0.3683, -1.2411, -1.4363,  1.3106,\n",
      "          -1.5854, -0.1109,  3.2389,  0.3469,  1.0036, -0.8685,  0.7311,\n",
      "          -1.6815, -0.9242,  0.1907,  0.0285, -0.5964,  1.0584, -0.2309,\n",
      "           0.7759, -0.9059, -0.3677, -0.2786, -0.5476, -0.1379, -3.2781,\n",
      "          -0.1010, -1.8785,  1.6980,  1.6883,  2.0295, -1.6462, -0.8959,\n",
      "           2.5844,  0.0000,  1.4236, -0.6275,  0.4668,  1.3156, -0.9871,\n",
      "           0.0739, -0.9856, -0.6750,  0.2476, -1.2005,  1.1297,  1.1406,\n",
      "           1.4887,  0.3791,  0.6467, -0.8378,  0.0000,  0.3448, -1.2617,\n",
      "           0.0303,  0.8641,  0.5015,  0.0000, -1.2681, -0.6409,  0.0000,\n",
      "           0.8728, -0.0677,  0.0421, -0.0566,  0.6208,  0.1451, -0.1965,\n",
      "           0.1078, -1.6721, -0.4025,  0.0000, -2.0697,  0.4119,  1.1554,\n",
      "           0.1996,  0.9130,  0.8437,  0.4174,  1.6038,  0.1771, -1.1141,\n",
      "           0.0000,  0.0000,  0.4450, -0.4551,  0.4446, -1.3453,  1.7357,\n",
      "           0.5175,  1.1772,  0.2896, -1.8322, -1.8662,  0.2594, -0.6475,\n",
      "          -1.1658,  0.3288, -0.7440,  0.0000,  0.0000, -1.5176, -2.3033,\n",
      "           0.0000, -1.6243, -1.3211, -0.0501,  1.2995,  0.9805,  0.0000,\n",
      "          -1.1403,  3.0136, -0.2259,  1.0328,  0.0293,  0.1190, -1.3198,\n",
      "          -1.0707,  0.0566,  1.7330,  0.5270,  1.9825, -0.9788, -1.3424,\n",
      "           1.5995, -0.4015,  2.4609, -0.5196,  0.7545,  0.2064, -0.8211,\n",
      "           0.9057, -3.5303,  0.1760, -0.7813, -0.6932, -1.4187,  0.2512,\n",
      "          -0.0649, -1.4656,  0.4270, -0.5198,  0.0463, -0.6252, -0.0714,\n",
      "           0.7483, -2.0271, -1.0489, -0.4316, -0.1122,  0.5160, -2.7971,\n",
      "          -1.4578,  0.0000,  1.0257,  0.1328,  2.7510,  1.0025,  0.5472,\n",
      "          -0.1736,  0.0000,  2.2319,  1.1873,  0.0000,  0.7229,  0.1090,\n",
      "          -2.8556, -0.0138, -0.8379, -0.5804]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0303, 0.1813, 0.1174, 0.1061, 0.0867, 0.1130, 0.0659, 0.1001, 0.1119,\n",
      "         0.0872]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3524, -0.0361,  0.0712,  ..., -0.1143, -0.0106, -0.4873],\n",
      "        [ 0.1267,  0.1329,  0.2628,  ...,  0.1101,  0.0915,  0.0413],\n",
      "        [ 0.0361,  0.2128, -0.0530,  ..., -0.2869,  0.4924,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1965,  0.1512, -0.1289,  0.0333, -0.0149,  0.0093, -0.1204,\n",
      "          -0.0926,  0.0952,  0.1206, -0.0004,  0.0090, -0.0549,  0.0652,\n",
      "           0.1334,  0.0607, -0.0876,  0.0735, -0.2840, -0.0982, -0.1964,\n",
      "          -0.0067, -0.0885, -0.1221, -0.0733, -0.1643, -0.0162, -0.1823,\n",
      "           0.0941, -0.0571,  0.0447,  0.0197, -0.1792,  0.0886, -0.0743,\n",
      "          -0.0280, -0.3103, -0.1621, -0.1458, -0.0942, -0.0862,  0.0265,\n",
      "          -0.0079, -0.0694,  0.2207, -0.0360,  0.0871,  0.0515,  0.1311,\n",
      "           0.0146, -0.1204, -0.2690, -0.0919, -0.1880, -0.2257, -0.0679,\n",
      "          -0.1210,  0.1704, -0.0758,  0.2110,  0.0104, -0.0858,  0.0296,\n",
      "           0.0843, -0.0276, -0.0160,  0.0308, -0.0394, -0.2152,  0.0514,\n",
      "           0.0876,  0.2041, -0.1707,  0.1815, -0.2271, -0.0377,  0.2510,\n",
      "           0.0119, -0.0718, -0.0468, -0.3315, -0.2043, -0.2057,  0.0029,\n",
      "          -0.0246,  0.0679,  0.1403,  0.0120, -0.0208,  0.0087,  0.0187,\n",
      "           0.0643, -0.0754, -0.1190,  0.1852,  0.1789,  0.1498,  0.1782,\n",
      "          -0.1776,  0.1729, -0.2268,  0.0313,  0.1461,  0.0169, -0.1191,\n",
      "          -0.1213,  0.1544, -0.1232, -0.0010,  0.1567,  0.0862,  0.0136,\n",
      "           0.0073,  0.0554,  0.1634, -0.1255,  0.0805, -0.1804, -0.0485,\n",
      "          -0.1239,  0.1638, -0.0279, -0.0431, -0.0609, -0.2515, -0.0999,\n",
      "           0.1730,  0.0102,  0.2213,  0.1901,  0.0903, -0.2627,  0.1761,\n",
      "           0.0378, -0.1571, -0.0542,  0.1202,  0.0761,  0.2391,  0.1269,\n",
      "           0.0306,  0.2342,  0.0418,  0.1015, -0.0435,  0.1116,  0.1900,\n",
      "           0.1159, -0.0046,  0.1617, -0.1183, -0.0641,  0.2220,  0.1707,\n",
      "          -0.1153,  0.2074, -0.0040,  0.2309,  0.0960,  0.1443, -0.0147,\n",
      "           0.0684, -0.1109,  0.1877, -0.1023, -0.0492,  0.0248, -0.1053,\n",
      "          -0.1653,  0.1937, -0.0140, -0.1210,  0.1443,  0.1934,  0.0659,\n",
      "          -0.1947, -0.0100, -0.0047,  0.1339, -0.1914, -0.0637,  0.1219,\n",
      "          -0.1042, -0.1252,  0.1854,  0.1373, -0.1406, -0.0009,  0.1032,\n",
      "          -0.1993,  0.1448,  0.0027, -0.2111, -0.0441, -0.0581,  0.0698,\n",
      "           0.0709,  0.0390, -0.0452, -0.0580, -0.0609,  0.0259,  0.0021,\n",
      "           0.2482, -0.0110,  0.0942, -0.1295,  0.2156,  0.0179,  0.0973,\n",
      "           0.1592, -0.2278, -0.1379, -0.0928, -0.1523, -0.0137,  0.1049,\n",
      "           0.2005, -0.2922,  0.1590,  0.2638, -0.0114,  0.1647, -0.1009,\n",
      "          -0.0257,  0.2163,  0.1232, -0.0888, -0.3165,  0.0272, -0.1724,\n",
      "          -0.1335, -0.0069, -0.1484,  0.0092,  0.0756, -0.2389, -0.0118,\n",
      "           0.1142, -0.0287, -0.0116, -0.0331, -0.3539,  0.0818,  0.3006,\n",
      "          -0.0534, -0.1338, -0.1610, -0.0634, -0.1150,  0.0750,  0.1116,\n",
      "          -0.0180, -0.1290,  0.1413,  0.0368]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7781,  0.0000, -0.1826,  0.0000,  2.5180, -1.9080,\n",
      "          -0.0327,  0.9501,  1.1944,  1.4103, -0.7569, -0.0650,  0.0645,\n",
      "           1.0464,  1.8853,  0.8702, -0.7848, -0.6403, -1.4035, -0.4985,\n",
      "          -0.3791,  1.1427,  0.2328,  0.1893, -0.6130,  0.0000, -0.1511,\n",
      "          -1.0410,  0.4962, -0.5711,  0.6008, -1.6989,  0.2317, -0.0797,\n",
      "           0.1482,  0.6451, -2.2132,  1.0517,  0.1024, -0.6922, -0.4366,\n",
      "          -1.0644,  0.8181, -0.6329, -0.6567,  1.3726,  0.9367,  1.6036,\n",
      "           0.3695,  0.0000, -1.1718, -1.1122,  1.2531, -1.9748,  1.7089,\n",
      "           0.5928, -1.8922,  0.3415, -0.2936, -0.7705,  1.8691,  0.0000,\n",
      "          -1.6817, -0.8354,  1.2345, -0.3576,  0.2897, -0.7527, -1.1648,\n",
      "           2.2478,  0.7807,  0.2704,  1.2049, -0.3980,  0.3547,  0.2294,\n",
      "          -0.1574,  0.0000,  0.0000, -0.1448,  1.2866,  0.4651,  1.2968,\n",
      "           0.7706,  0.6606,  1.0453, -0.3683, -1.2411, -1.4363,  1.3106,\n",
      "          -1.5854, -0.1109,  0.0000,  0.3469,  1.0036, -0.8685,  0.7311,\n",
      "          -1.6815, -0.9242,  0.1907,  0.0285, -0.5964,  1.0584, -0.2309,\n",
      "           0.7759, -0.9059, -0.3677,  0.0000, -0.5476, -0.1379, -3.2781,\n",
      "          -0.1010, -1.8785,  1.6980,  1.6883,  2.0295, -1.6462, -0.8959,\n",
      "           2.5844, -1.3263,  1.4236,  0.0000,  0.4668,  1.3156, -0.9871,\n",
      "           0.0739, -0.9856, -0.6750,  0.2476, -1.2005,  1.1297,  1.1406,\n",
      "           1.4887,  0.3791,  0.6467, -0.8378,  0.2413,  0.3448, -1.2617,\n",
      "           0.0303,  0.8641,  0.5015,  0.9071, -1.2681, -0.6409, -0.4417,\n",
      "           0.8728, -0.0677,  0.0421, -0.0566,  0.6208,  0.1451, -0.1965,\n",
      "           0.0000, -1.6721, -0.4025,  0.2513, -2.0697,  0.4119,  1.1554,\n",
      "           0.1996,  0.9130,  0.0000,  0.4174,  1.6038,  0.1771, -1.1141,\n",
      "           0.0000,  0.2507,  0.4450, -0.4551,  0.4446, -1.3453,  1.7357,\n",
      "           0.5175,  1.1772,  0.2896, -1.8322, -1.8662,  0.2594, -0.6475,\n",
      "          -1.1658,  0.3288, -0.7440,  0.0000,  0.0000, -1.5176,  0.0000,\n",
      "           0.1465, -1.6243,  0.0000, -0.0501,  1.2995,  0.9805, -1.4146,\n",
      "          -1.1403,  3.0136,  0.0000,  1.0328,  0.0293,  0.1190,  0.0000,\n",
      "          -1.0707,  0.0566,  1.7330,  0.0000,  1.9825, -0.9788, -1.3424,\n",
      "           1.5995, -0.4015,  2.4609, -0.5196,  0.7545,  0.0000, -0.8211,\n",
      "           0.9057, -3.5303,  0.1760,  0.0000, -0.6932, -1.4187,  0.2512,\n",
      "           0.0000, -1.4656,  0.4270,  0.0000,  0.0463, -0.6252, -0.0714,\n",
      "           0.7483, -2.0271, -1.0489, -0.4316, -0.1122,  0.5160, -2.7971,\n",
      "          -1.4578, -0.6645,  0.0000,  0.1328,  2.7510,  1.0025,  0.0000,\n",
      "          -0.1736, -1.5052,  2.2319,  1.1873, -0.0478,  0.7229,  0.1090,\n",
      "          -2.8556, -0.0138, -0.8379, -0.5804]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0316, 0.1596, 0.0991, 0.1080, 0.0912, 0.1330, 0.0908, 0.0707, 0.1368,\n",
      "         0.0793]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3524, -0.0361,  0.0712,  ..., -0.1143, -0.0106, -0.4873],\n",
      "        [ 0.1267,  0.1329,  0.2628,  ...,  0.1101,  0.0915,  0.0413],\n",
      "        [ 0.0361,  0.2128, -0.0530,  ..., -0.2869,  0.4924,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2110,  0.1560, -0.1519,  0.0230, -0.0388, -0.0138, -0.1066,\n",
      "          -0.1148,  0.0873,  0.1001,  0.0162, -0.0078, -0.0762,  0.0568,\n",
      "           0.1419,  0.0491, -0.0820,  0.0834, -0.2879, -0.0939, -0.1976,\n",
      "          -0.0265, -0.0698, -0.0965, -0.0751, -0.1631, -0.0180, -0.1955,\n",
      "           0.0808, -0.0622,  0.0549, -0.0059, -0.1817,  0.0656, -0.0722,\n",
      "          -0.0174, -0.3174, -0.1640, -0.1588, -0.0821, -0.0881,  0.0202,\n",
      "          -0.0254, -0.0644,  0.2151, -0.0168,  0.0651,  0.0216,  0.1304,\n",
      "           0.0110, -0.1246, -0.2489, -0.1101, -0.1798, -0.2138, -0.0613,\n",
      "          -0.1199,  0.1679, -0.0640,  0.2246,  0.0023, -0.0834,  0.0095,\n",
      "           0.0862, -0.0352, -0.0043,  0.0238, -0.0180, -0.2148,  0.0604,\n",
      "           0.0821,  0.2125, -0.1566,  0.1923, -0.2251, -0.0258,  0.2529,\n",
      "           0.0302, -0.0793, -0.0257, -0.3247, -0.2078, -0.2220,  0.0019,\n",
      "          -0.0271,  0.0832,  0.1362,  0.0116,  0.0070, -0.0092,  0.0456,\n",
      "           0.0530, -0.0778, -0.1162,  0.1739,  0.1774,  0.1516,  0.1900,\n",
      "          -0.1716,  0.1837, -0.2289,  0.0429,  0.1474,  0.0224, -0.1228,\n",
      "          -0.1258,  0.1602, -0.0926, -0.0005,  0.1638,  0.1010,  0.0121,\n",
      "           0.0215,  0.0302,  0.1342, -0.1145,  0.0720, -0.1767, -0.0606,\n",
      "          -0.1270,  0.1649, -0.0397, -0.0691, -0.0624, -0.2494, -0.1041,\n",
      "           0.1556, -0.0086,  0.2159,  0.1730,  0.1076, -0.2761,  0.1865,\n",
      "           0.0568, -0.1517, -0.0447,  0.1273,  0.0782,  0.2024,  0.1382,\n",
      "           0.0125,  0.2413,  0.0211,  0.0954, -0.0313,  0.1161,  0.1740,\n",
      "           0.1318,  0.0086,  0.1838, -0.1430, -0.0560,  0.2077,  0.1689,\n",
      "          -0.0931,  0.2139, -0.0157,  0.2283,  0.1093,  0.1150, -0.0237,\n",
      "           0.0503, -0.1273,  0.2062, -0.0947, -0.0293,  0.0109, -0.1067,\n",
      "          -0.1280,  0.2044, -0.0342, -0.1058,  0.1731,  0.1797,  0.0409,\n",
      "          -0.2042, -0.0092,  0.0013,  0.1576, -0.2013, -0.0754,  0.0988,\n",
      "          -0.1129, -0.1238,  0.1939,  0.1504, -0.1609,  0.0081,  0.1090,\n",
      "          -0.2026,  0.1305,  0.0234, -0.2275, -0.0551, -0.0448,  0.0528,\n",
      "           0.0613,  0.0335, -0.0573, -0.0463, -0.0625,  0.0444, -0.0051,\n",
      "           0.2613, -0.0018,  0.0812, -0.1292,  0.2275,  0.0110,  0.0851,\n",
      "           0.1564, -0.2324, -0.1356, -0.0645, -0.1552,  0.0072,  0.0794,\n",
      "           0.1937, -0.2910,  0.1683,  0.2733, -0.0227,  0.1604, -0.1198,\n",
      "          -0.0104,  0.2129,  0.1280, -0.0999, -0.3153,  0.0399, -0.1772,\n",
      "          -0.1329, -0.0182, -0.1646, -0.0013,  0.0811, -0.2494, -0.0006,\n",
      "           0.1272, -0.0248, -0.0245, -0.0493, -0.3473,  0.0800,  0.2912,\n",
      "          -0.0544, -0.1471, -0.1667, -0.0349, -0.0984,  0.0818,  0.1059,\n",
      "          -0.0297, -0.1373,  0.1342,  0.0362]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7266e-01, -4.3092e-01,  0.0000e+00,  0.0000e+00, -1.1729e+00,\n",
      "           7.4163e-01, -1.9147e+00,  1.3514e+00,  1.9007e-01,  6.1737e-01,\n",
      "           1.9038e+00,  6.0259e-01,  2.2926e-01, -9.1668e-01, -3.1842e+00,\n",
      "          -6.8284e-02, -1.6338e+00, -9.4358e-01,  1.3603e+00, -1.4359e+00,\n",
      "          -1.4034e-01, -5.2465e-01, -1.1199e+00,  0.0000e+00, -7.5962e-02,\n",
      "           1.3919e+00,  0.0000e+00,  1.9983e+00,  1.2779e-01,  5.5529e-01,\n",
      "           0.0000e+00, -3.8255e-03,  2.2234e-01,  2.0172e+00, -6.3598e-02,\n",
      "          -1.4087e+00, -1.1159e-01, -8.1739e-01,  3.1533e-01,  8.6171e-02,\n",
      "           8.6353e-01, -8.9929e-01,  1.0090e+00, -1.5642e+00,  1.9451e+00,\n",
      "          -3.0043e-01,  7.0653e-01, -6.0250e-01, -1.0210e+00,  1.1173e+00,\n",
      "          -1.3234e+00,  2.6785e+00,  0.0000e+00, -8.4707e-01,  2.2809e-01,\n",
      "          -3.1026e-01,  0.0000e+00, -9.6227e-02,  1.2761e+00,  2.1824e+00,\n",
      "          -1.0067e+00,  3.5778e-02, -2.8021e-01,  2.6573e-01, -6.3258e-02,\n",
      "           0.0000e+00,  5.7819e-01,  1.1654e+00,  1.5812e+00, -1.4155e+00,\n",
      "           4.2727e-01,  0.0000e+00, -3.1056e-02, -7.9829e-01, -2.1415e-01,\n",
      "           1.3947e-01,  5.2604e-01,  1.3993e+00,  1.0275e+00, -7.9435e-01,\n",
      "           7.5856e-01, -1.0047e+00,  7.5849e-01,  1.0589e+00, -1.2158e+00,\n",
      "          -1.1336e-01, -1.1083e+00,  5.4869e-01, -9.4504e-01, -1.9015e+00,\n",
      "           5.2923e-01,  9.8750e-01,  1.7022e+00,  9.4441e-01,  6.0795e-01,\n",
      "          -1.5912e-02,  3.5450e-01, -1.1761e+00,  1.3727e+00,  2.4482e+00,\n",
      "           2.4342e-01,  4.4007e-02, -4.6668e-01, -9.8952e-01,  0.0000e+00,\n",
      "          -1.0242e+00,  3.0305e+00,  6.2086e-01, -1.0195e-01, -1.2357e+00,\n",
      "           1.8999e-01,  0.0000e+00, -5.7123e-01,  0.0000e+00, -7.8085e-01,\n",
      "           6.3266e-01,  4.0380e-01,  2.2337e-01, -2.3273e+00,  2.9212e-02,\n",
      "          -8.1493e-01, -1.4121e+00, -1.8388e+00,  6.0325e-01, -9.5729e-01,\n",
      "          -2.0107e-01,  4.0398e-02,  2.1510e+00,  1.3967e+00, -2.0884e+00,\n",
      "          -9.2622e-01,  4.4997e-01,  0.0000e+00,  4.2554e-01, -4.6823e-01,\n",
      "          -7.4648e-01, -1.0649e+00, -9.7561e-01, -1.9388e-02,  2.3981e+00,\n",
      "           6.9867e-01, -1.1220e+00,  1.6920e+00, -1.4047e-01,  0.0000e+00,\n",
      "           3.3142e-02,  7.5994e-01,  4.2291e-01, -1.0341e+00, -9.5200e-02,\n",
      "           1.5602e+00,  5.8671e-01, -3.3837e-01,  6.5779e-01,  1.8416e+00,\n",
      "          -2.5277e-01, -2.1793e-01,  6.2402e-01, -2.3641e+00,  1.0561e+00,\n",
      "           3.0295e-01, -7.7202e-02,  1.5537e-01,  0.0000e+00, -2.1971e-02,\n",
      "           1.6827e+00,  1.8529e+00,  2.7184e-01, -1.2704e+00,  0.0000e+00,\n",
      "          -1.2243e+00, -1.0943e+00, -2.5913e+00,  5.0589e-01, -3.0611e+00,\n",
      "          -2.8749e-01,  4.9755e-01,  0.0000e+00,  3.1713e-01, -7.9308e-01,\n",
      "           2.7264e-01,  2.3402e+00,  1.0584e+00,  8.3914e-01,  0.0000e+00,\n",
      "           7.2801e-01,  5.9865e-01,  3.5981e-01,  0.0000e+00, -1.8313e+00,\n",
      "           1.3639e+00,  2.1602e+00,  3.3578e-01, -1.0158e+00, -1.1731e+00,\n",
      "          -2.2163e+00,  1.6679e+00,  2.1535e+00,  3.6349e-01,  2.3838e+00,\n",
      "           0.0000e+00, -5.0165e-01,  0.0000e+00, -5.4316e-01, -4.0774e-01,\n",
      "          -1.4478e+00,  9.5341e-01, -8.5208e-01,  8.2941e-01, -1.5606e+00,\n",
      "           6.3740e-01,  6.7543e-01,  2.3986e+00,  5.5297e-02,  1.8938e+00,\n",
      "           1.3092e+00,  5.8028e-01, -2.3180e+00,  1.5503e+00,  0.0000e+00,\n",
      "          -2.2737e-01,  1.7344e+00,  0.0000e+00, -1.5525e+00,  9.2288e-01,\n",
      "          -1.2244e+00, -8.4898e-01, -1.8028e+00, -7.9622e-04,  3.7321e-01,\n",
      "          -1.5740e+00, -1.2394e-01,  9.6638e-01,  0.0000e+00,  1.6948e+00,\n",
      "          -1.4405e+00,  6.3403e-01, -1.7231e+00,  9.8029e-01, -1.7172e+00,\n",
      "           1.5617e+00, -2.7308e-01, -2.5977e+00,  1.2393e+00,  0.0000e+00,\n",
      "           1.8865e+00, -5.0853e-01,  0.0000e+00,  0.0000e+00, -1.0225e+00,\n",
      "           1.3340e+00,  3.1143e-01, -5.0946e-02, -2.2877e-01, -1.6132e+00,\n",
      "           1.8072e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0434, 0.1323, 0.1361, 0.0748, 0.1256, 0.1351, 0.1410, 0.0729, 0.0903,\n",
      "         0.0485]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3524, -0.0361,  0.0712,  ..., -0.1143, -0.0106, -0.4873],\n",
      "        [ 0.1267,  0.1329,  0.2628,  ...,  0.1101,  0.0915,  0.0413],\n",
      "        [ 0.0361,  0.2128, -0.0530,  ..., -0.2869,  0.4924,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2225,  0.1504, -0.1660,  0.0103, -0.0461, -0.0256, -0.1187,\n",
      "          -0.1318,  0.0713,  0.0886,  0.0135, -0.0139, -0.0871,  0.0769,\n",
      "           0.1589,  0.0310, -0.1180,  0.1113, -0.2927, -0.0973, -0.1979,\n",
      "          -0.0445, -0.0542, -0.1159, -0.0835, -0.1485, -0.0119, -0.2097,\n",
      "           0.0964, -0.0471,  0.0827, -0.0185, -0.2018,  0.0390, -0.0766,\n",
      "          -0.0213, -0.3122, -0.1733, -0.1594, -0.0681, -0.0915,  0.0458,\n",
      "          -0.0245, -0.0716,  0.2101, -0.0019,  0.0630,  0.0175,  0.1507,\n",
      "           0.0117, -0.1219, -0.2558, -0.1421, -0.1986, -0.2340, -0.0658,\n",
      "          -0.1370,  0.1757, -0.0713,  0.2114,  0.0010, -0.1159,  0.0033,\n",
      "           0.1049, -0.0504, -0.0148,  0.0203,  0.0110, -0.2378,  0.0909,\n",
      "           0.0896,  0.2188, -0.1458,  0.1940, -0.2403, -0.0085,  0.2813,\n",
      "           0.0420, -0.0864, -0.0170, -0.3355, -0.2075, -0.2408,  0.0028,\n",
      "          -0.0438,  0.0717,  0.1533,  0.0212,  0.0189, -0.0091,  0.0480,\n",
      "           0.0516, -0.0836, -0.1228,  0.1766,  0.1934,  0.1470,  0.1829,\n",
      "          -0.1549,  0.2052, -0.2317,  0.0588,  0.1499,  0.0266, -0.1087,\n",
      "          -0.1287,  0.1653, -0.0715,  0.0083,  0.1864,  0.1160,  0.0224,\n",
      "           0.0124,  0.0175,  0.1271, -0.0986,  0.0834, -0.1829, -0.0676,\n",
      "          -0.1191,  0.1531, -0.0303, -0.0786, -0.0485, -0.2735, -0.1081,\n",
      "           0.1506, -0.0156,  0.2136,  0.1592,  0.1090, -0.2803,  0.1793,\n",
      "           0.0796, -0.1556, -0.0397,  0.1197,  0.0975,  0.2040,  0.1572,\n",
      "          -0.0141,  0.2476, -0.0040,  0.0884, -0.0163,  0.1006,  0.1738,\n",
      "           0.1474,  0.0383,  0.1895, -0.1641, -0.0338,  0.2059,  0.1722,\n",
      "          -0.0773,  0.2423, -0.0054,  0.2432,  0.0952,  0.1159, -0.0505,\n",
      "           0.0538, -0.1457,  0.2317, -0.1037, -0.0110,  0.0099, -0.1128,\n",
      "          -0.1432,  0.1808, -0.0517, -0.1021,  0.1766,  0.1738,  0.0389,\n",
      "          -0.2181, -0.0108,  0.0071,  0.1725, -0.2045, -0.0937,  0.0918,\n",
      "          -0.1172, -0.1356,  0.2075,  0.1364, -0.1720,  0.0126,  0.0840,\n",
      "          -0.2064,  0.1421,  0.0325, -0.2387, -0.0590, -0.0529,  0.0320,\n",
      "           0.0497,  0.0275, -0.0687, -0.0502, -0.0566,  0.0358, -0.0145,\n",
      "           0.2738, -0.0161,  0.0749, -0.1297,  0.2566,  0.0205,  0.0794,\n",
      "           0.1370, -0.2477, -0.1374, -0.0658, -0.1702,  0.0133,  0.0813,\n",
      "           0.2074, -0.2969,  0.1721,  0.2812, -0.0147,  0.1859, -0.1024,\n",
      "           0.0012,  0.2208,  0.1347, -0.1008, -0.3502,  0.0535, -0.1720,\n",
      "          -0.1377, -0.0339, -0.1661,  0.0132,  0.0907, -0.2546, -0.0097,\n",
      "           0.1562, -0.0235, -0.0362, -0.0568, -0.3525,  0.0942,  0.3050,\n",
      "          -0.0674, -0.1381, -0.1771, -0.0443, -0.1203,  0.0988,  0.1159,\n",
      "          -0.0349, -0.1656,  0.1570,  0.0312]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5699e-02,  3.9886e-01, -9.6709e-01, -6.8209e-01,  0.0000e+00,\n",
      "          -2.0179e-01,  1.4650e+00, -8.3247e-02, -3.5856e+00,  9.0679e-01,\n",
      "           4.2903e-01, -6.2936e-01,  0.0000e+00, -6.2975e-01, -5.4166e-01,\n",
      "          -1.5799e-01,  8.5176e-01,  1.0952e+00,  0.0000e+00,  4.3613e-01,\n",
      "          -6.3389e-01, -3.8376e-01,  1.6422e+00,  1.5116e+00,  7.5401e-01,\n",
      "           0.0000e+00, -1.8770e-01, -7.5905e-01,  0.0000e+00,  8.6174e-01,\n",
      "           1.2322e+00,  1.2193e+00, -1.0345e+00, -8.2650e-02, -1.5353e+00,\n",
      "           1.3954e+00,  2.8078e-01, -3.7461e+00,  1.9807e-01,  1.6017e+00,\n",
      "          -4.5888e-01, -1.3992e+00, -2.6831e-01, -1.7171e+00, -1.5253e+00,\n",
      "           6.6729e-01,  5.4116e-01,  3.7007e-01, -1.3412e+00,  1.4369e-01,\n",
      "          -6.2885e-01,  2.7538e+00,  6.1058e-01, -1.0299e+00, -2.5814e-02,\n",
      "           2.0291e-01, -8.8256e-01, -1.2533e+00, -2.3650e-01, -4.2513e-01,\n",
      "           0.0000e+00,  1.4087e+00, -2.0381e-01, -5.0211e-01,  0.0000e+00,\n",
      "           5.5045e-01,  1.2794e+00, -1.2885e+00,  4.1185e-01,  5.2642e-01,\n",
      "          -1.2677e+00, -3.0512e-02,  7.0753e-01, -3.6430e+00,  3.2663e-01,\n",
      "          -2.4056e-03, -1.5982e-01,  1.0634e+00, -5.8573e-02, -1.2025e-01,\n",
      "          -1.4007e+00,  0.0000e+00, -9.2516e-01,  1.0057e+00, -2.0792e-01,\n",
      "           0.0000e+00,  1.6622e+00, -9.7512e-01, -1.0308e-01,  0.0000e+00,\n",
      "          -2.2744e+00,  1.1006e+00, -6.2233e-01, -1.1354e+00,  4.6760e-01,\n",
      "          -1.1712e+00,  3.4483e-02,  6.2934e-01,  1.7208e+00, -7.8091e-01,\n",
      "           2.6981e+00, -1.4633e+00,  1.0762e+00,  1.4548e+00, -6.6664e-01,\n",
      "          -7.6262e-01,  1.2131e+00,  1.2747e-01, -1.4733e+00, -1.2946e-02,\n",
      "          -2.4898e-01,  1.3452e-01, -1.0491e+00,  1.3105e+00,  0.0000e+00,\n",
      "          -2.9910e+00, -5.6204e-02, -5.0176e-01, -1.9317e-01,  4.4469e-01,\n",
      "          -1.4675e+00,  7.0264e-01, -1.4611e+00, -7.2646e-01, -9.5892e-01,\n",
      "          -1.3098e+00,  8.9809e-01,  1.7061e-01,  0.0000e+00, -7.5287e-01,\n",
      "          -8.2319e-01,  5.2962e-01, -1.5837e+00,  9.8427e-01,  2.7618e-01,\n",
      "          -5.8972e-01,  6.6018e-01,  5.7327e-01, -1.1585e+00, -1.0109e+00,\n",
      "          -3.8916e-01,  6.7787e-01, -7.9029e-01, -1.0190e-01, -1.6867e+00,\n",
      "          -1.0149e-01, -5.4341e-01, -8.4466e-01, -7.5562e-01,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00, -1.9315e+00, -4.0629e-01,  4.4167e-01,\n",
      "          -1.9450e-01, -6.4030e-02, -1.2887e-01,  3.9558e-02,  5.3773e-01,\n",
      "          -2.6097e-02,  2.2069e+00,  4.8121e-01, -5.4971e-01, -5.2780e-01,\n",
      "          -8.9317e-01,  2.8182e-01,  8.4864e-02, -3.5804e-01, -4.7823e-01,\n",
      "           7.3858e-01, -3.2596e-02,  1.9850e-02, -1.0021e+00,  1.2781e+00,\n",
      "          -1.0994e+00, -9.8822e-01, -2.0784e+00,  1.9701e+00,  0.0000e+00,\n",
      "          -2.9589e-02,  3.5098e-02,  6.7182e-01,  9.7987e-01,  0.0000e+00,\n",
      "          -3.4101e-01, -2.7847e+00, -7.8506e-01,  1.2102e+00,  1.0127e+00,\n",
      "           3.0759e+00,  4.9460e-01, -1.4412e-01, -5.9504e-01,  5.6095e-01,\n",
      "           0.0000e+00,  0.0000e+00,  5.3475e-01,  1.8127e+00, -9.4789e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2418e+00, -1.2212e-01,  2.3192e-01,\n",
      "          -5.7555e-01, -2.2936e+00,  6.8205e-01, -1.0752e+00, -4.7153e-01,\n",
      "           2.8693e+00, -5.7340e-01, -3.4119e-01,  7.9349e-01,  2.9803e-02,\n",
      "          -6.8515e-01, -1.0201e+00,  9.6629e-01, -2.4601e-01,  2.1704e+00,\n",
      "          -1.0831e+00, -4.2770e-01, -1.8445e+00, -5.0178e-01,  3.3700e-01,\n",
      "           0.0000e+00, -6.9658e-01, -6.2815e-01,  2.9228e-01, -1.5793e+00,\n",
      "          -1.1091e+00,  1.5818e+00, -6.1442e-01,  1.3099e+00, -2.9808e+00,\n",
      "           4.0371e+00,  5.8518e-01,  0.0000e+00, -1.5811e+00, -2.8771e-01,\n",
      "           7.4149e-01, -3.2499e+00,  0.0000e+00, -8.5291e-01,  1.1102e-02,\n",
      "           0.0000e+00,  2.7511e-01,  0.0000e+00,  2.6093e-01,  3.8668e-01,\n",
      "          -3.6562e-01,  0.0000e+00, -5.5426e-01, -5.2650e-02,  0.0000e+00,\n",
      "          -1.1317e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0523, 0.0462, 0.0778, 0.0512, 0.1030, 0.3561, 0.0419, 0.1042, 0.0665,\n",
      "         0.1007]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0359,  0.0717,  ..., -0.1134, -0.0100, -0.4873],\n",
      "        [ 0.1262,  0.1331,  0.2636,  ...,  0.1119,  0.0940,  0.0422],\n",
      "        [ 0.1228,  0.3953,  0.0079,  ...,  0.2011,  0.2312,  0.1531],\n",
      "        ...,\n",
      "        [ 0.0848,  0.1072, -0.3314,  ...,  0.0370,  0.2894, -0.3461],\n",
      "        [ 0.3941,  0.1411, -0.4355,  ..., -0.3504,  0.5114, -0.2855],\n",
      "        [ 0.6876,  0.5535, -0.7469,  ..., -0.3326,  0.0792,  0.0401]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3949e-02, -2.7509e-02, -2.8530e-01,  7.4062e-02,  1.8235e-01,\n",
      "           9.1659e-02, -3.1188e-01, -1.6667e-01, -1.1236e-01,  9.8254e-02,\n",
      "           8.0213e-02,  1.3303e-01,  9.5646e-02,  7.8604e-02,  4.2258e-01,\n",
      "           3.2922e-01,  9.0720e-02, -1.6758e-01, -1.9725e-01,  4.3342e-02,\n",
      "           1.5531e-01, -2.2522e-01, -3.1077e-01, -7.7855e-02, -5.3479e-02,\n",
      "          -2.4027e-01,  6.4498e-02, -2.4924e-01,  4.5401e-02, -7.5323e-02,\n",
      "           2.7435e-01,  4.0105e-02, -1.0308e-01,  1.6543e-01, -2.3005e-01,\n",
      "           1.2597e-01, -3.0786e-01,  1.5820e-01, -8.9259e-02, -1.1348e-01,\n",
      "           1.1584e-01,  4.6640e-02, -2.5135e-01, -1.9613e-01,  3.5454e-01,\n",
      "          -1.7209e-02, -7.8771e-02,  1.3619e-02,  2.3316e-01,  1.4457e-01,\n",
      "          -9.5561e-02, -6.6067e-02,  2.7422e-01,  1.0330e-01, -4.4826e-02,\n",
      "           3.3353e-02, -1.0231e-03, -1.5425e-01,  1.9173e-01,  2.7840e-01,\n",
      "          -8.2287e-02,  4.5029e-02,  7.7578e-02,  9.6793e-02, -4.3626e-02,\n",
      "           1.0557e-01, -2.9938e-01,  4.3635e-02,  1.2386e-01,  2.3989e-01,\n",
      "          -8.6854e-02,  5.6422e-03,  2.8801e-02, -1.2779e-01, -2.2760e-01,\n",
      "          -9.3829e-02,  2.0927e-01,  3.2495e-01,  7.0351e-02,  1.3916e-01,\n",
      "          -8.9937e-02,  5.9076e-03, -3.3605e-01,  3.0884e-01, -7.1268e-02,\n",
      "          -8.9473e-02,  3.3527e-01,  1.2062e-01,  6.7280e-02,  1.2631e-01,\n",
      "           9.7237e-02, -4.5887e-02, -3.0974e-01, -7.3669e-02,  2.6531e-01,\n",
      "          -9.0953e-02,  1.2323e-01,  3.6021e-01, -1.8506e-01,  2.1503e-01,\n",
      "           1.1334e-01, -3.0316e-01, -5.7712e-02,  1.1397e-01, -9.8051e-02,\n",
      "          -5.2865e-02, -3.1946e-01,  2.1945e-02, -3.3895e-01,  3.7646e-01,\n",
      "          -1.3814e-01, -4.2951e-04,  7.1378e-02, -5.8516e-02,  2.9642e-01,\n",
      "           8.6353e-02, -1.0306e-01,  3.0718e-01, -6.4243e-02, -1.5276e-01,\n",
      "           6.4118e-03, -1.3820e-01, -3.6764e-01,  7.0039e-02, -3.2948e-01,\n",
      "          -1.2306e-01,  1.7531e-01, -2.8790e-01,  1.1000e-01,  2.0261e-02,\n",
      "           4.0166e-01, -2.7089e-01, -6.9458e-02,  2.0685e-01,  1.9830e-01,\n",
      "           1.8474e-01,  1.8434e-01, -7.2856e-02,  1.0213e-01,  4.7259e-02,\n",
      "           7.2644e-02,  1.5395e-01,  1.3090e-01,  2.5060e-01,  3.4054e-03,\n",
      "          -3.7422e-02,  2.3657e-01,  2.6505e-01, -6.7813e-02,  2.4975e-01,\n",
      "          -3.2026e-03, -2.3287e-01,  1.2285e-01,  6.4644e-02, -8.4555e-02,\n",
      "           3.0550e-02,  1.4356e-01,  2.8881e-01, -1.4800e-01,  3.9551e-02,\n",
      "          -6.0406e-02,  7.8286e-02, -2.6225e-02,  1.8609e-01, -8.4599e-02,\n",
      "          -8.0743e-02,  5.8111e-05,  1.3388e-01, -2.7324e-02,  3.1443e-01,\n",
      "           7.8557e-02,  2.3222e-01,  8.1100e-02,  3.3359e-01,  1.2842e-01,\n",
      "          -1.9594e-01, -3.7519e-02,  6.2253e-02,  9.3054e-02,  1.7948e-01,\n",
      "          -2.7614e-01, -2.0869e-01,  3.8204e-03,  1.3554e-01,  3.7259e-02,\n",
      "           1.7169e-01, -1.2882e-01,  1.5418e-02, -1.4605e-01,  1.0637e-01,\n",
      "           2.1764e-01, -7.3471e-02, -1.3924e-01, -1.8529e-01, -9.8449e-02,\n",
      "           5.5420e-02, -8.5933e-02,  4.0906e-01, -1.4781e-01,  5.8104e-02,\n",
      "          -1.0071e-01,  1.6543e-01, -1.3347e-02,  3.1495e-02, -8.3351e-02,\n",
      "           1.1149e-01,  3.0586e-02,  1.4462e-01,  3.1813e-02,  1.4012e-02,\n",
      "          -3.1312e-01,  1.5470e-01,  4.5267e-02,  1.4742e-01, -1.2143e-01,\n",
      "          -4.2734e-02, -2.2881e-02,  3.3258e-01, -3.1731e-02, -2.6226e-02,\n",
      "           4.0177e-01, -6.8072e-02,  3.9715e-01, -1.6842e-01,  1.7556e-01,\n",
      "          -3.6673e-02, -2.3798e-01,  7.7612e-02, -3.5878e-01,  4.9980e-02,\n",
      "          -7.3048e-02, -2.3300e-01, -3.2115e-01, -6.8467e-02,  1.0995e-01,\n",
      "          -6.1216e-02, -5.1904e-03, -1.6284e-03,  1.1298e-01,  5.0015e-02,\n",
      "          -1.8750e-03, -1.2612e-01, -2.4462e-01,  1.9071e-01,  1.5494e-01,\n",
      "          -1.0257e-01, -3.0416e-01, -3.8793e-01,  4.1392e-02,  1.8536e-03,\n",
      "           7.4877e-02,  2.0099e-01,  1.3602e-01,  5.8485e-02,  2.1946e-01,\n",
      "          -3.6702e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4820,  1.6543, -1.0096, -1.1128,  0.4006,  0.6461,\n",
      "          -1.2227, -0.9025,  0.0939, -0.2097,  0.3159,  0.1276, -0.9578,\n",
      "          -0.3086,  0.3245, -1.8655, -2.1364,  0.0000,  0.0000,  0.7694,\n",
      "           0.2828, -1.2566, -0.9730,  1.1927,  1.4265, -1.6558,  1.0544,\n",
      "           0.9846, -1.2882,  0.3068, -0.9456, -0.7691, -1.5225, -0.3683,\n",
      "           0.4843, -0.9884, -0.3511,  0.3282,  0.6284,  0.0000, -1.1770,\n",
      "           0.3729,  1.2540, -1.7957,  1.9479, -1.4979, -0.4430, -0.2787,\n",
      "           1.1465,  0.8653,  0.0370, -0.0720, -1.0044, -0.2960,  0.0000,\n",
      "          -1.8696,  0.5099,  1.5733,  2.0581, -0.8819, -0.7341,  1.9471,\n",
      "          -0.9066, -0.8594,  0.1078,  0.6390,  0.0000,  0.0214,  0.4296,\n",
      "          -1.5897, -0.0285, -0.6440,  1.4254, -0.4460,  0.5580, -3.6199,\n",
      "          -0.6177, -1.4067, -0.3113,  0.8704,  1.3127,  0.8812, -0.9604,\n",
      "           0.6942,  0.6930,  0.0461, -2.9902,  0.8149, -0.0184,  0.0000,\n",
      "           0.3247, -1.2889,  2.3925,  1.8842,  0.2151, -1.1100,  1.0777,\n",
      "           0.0000, -2.1248,  0.0146, -0.6642, -1.1343, -1.8824,  0.4071,\n",
      "           1.4168, -1.9889, -0.9152,  0.4129,  1.8167, -1.4326,  0.1792,\n",
      "          -0.4978,  1.3008, -0.1468,  0.0000,  0.3373, -1.6430,  0.8517,\n",
      "          -1.2944, -1.3466, -0.0995,  0.8781,  0.5349,  0.2248,  0.8189,\n",
      "          -0.2020, -1.0699,  0.1248, -0.4279, -1.2475,  2.3283,  1.4194,\n",
      "           0.0000, -0.0089, -0.6386, -0.0633, -0.5998, -0.4515,  1.0983,\n",
      "           0.5453, -1.1802, -2.2953, -0.8860,  0.2165, -0.1881,  0.9174,\n",
      "          -0.0827,  1.5431, -0.7185,  0.3218, -1.3513,  1.8152, -1.9312,\n",
      "           0.5129, -0.3341, -0.2284, -0.7582,  0.9341, -0.0178,  0.2298,\n",
      "          -1.1454,  2.2620, -1.7649, -0.3903, -0.6924,  0.5300,  2.1361,\n",
      "          -1.6404, -2.7424,  1.2547, -2.0858, -0.0064, -1.1602, -0.9213,\n",
      "          -0.7987,  0.0000,  0.0000,  0.1183, -1.5139,  0.1504, -0.4528,\n",
      "           0.1996,  0.9702,  0.4842, -0.0759, -1.5026, -0.2145,  0.4039,\n",
      "          -1.4626,  1.0718,  0.6061,  0.0000, -0.5084,  0.7252, -0.0426,\n",
      "           0.0000,  0.0000, -0.8385, -0.2757,  0.1193, -0.2978,  0.0000,\n",
      "           0.3537, -0.0092, -0.7149,  0.6958,  2.0167, -0.7501,  1.8923,\n",
      "           2.7899,  0.1562,  1.5049,  0.1013, -0.5909, -0.0229, -0.1427,\n",
      "          -1.3820,  0.4080,  0.6378, -0.6886,  1.8593,  0.6065,  0.4726,\n",
      "           0.0287,  1.5296, -0.3651, -0.2608,  0.8417, -0.2545,  0.7764,\n",
      "          -0.5519,  1.2383,  0.0931,  2.0764,  0.5545, -1.7044,  2.7790,\n",
      "          -1.4957,  1.8027, -0.8497,  0.2566,  0.0000, -0.8545,  0.1357,\n",
      "          -1.7794,  0.3817,  1.9828,  0.5690,  0.5474, -1.7499,  0.3684,\n",
      "           0.1555,  1.5691, -2.7264,  0.4074]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0357, 0.1493, 0.0971, 0.0552, 0.1633, 0.2277, 0.0492, 0.0645, 0.1038,\n",
      "         0.0542]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0359,  0.0717,  ..., -0.1134, -0.0100, -0.4873],\n",
      "        [ 0.1262,  0.1331,  0.2636,  ...,  0.1119,  0.0940,  0.0422],\n",
      "        [ 0.1228,  0.3953,  0.0079,  ...,  0.2011,  0.2312,  0.1531],\n",
      "        ...,\n",
      "        [ 0.0848,  0.1072, -0.3314,  ...,  0.0370,  0.2894, -0.3461],\n",
      "        [ 0.3941,  0.1411, -0.4355,  ..., -0.3504,  0.5114, -0.2855],\n",
      "        [ 0.6876,  0.5535, -0.7469,  ..., -0.3326,  0.0792,  0.0401]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0571, -0.0093, -0.2088,  0.1014,  0.2574,  0.1935, -0.3472,\n",
      "          -0.0600, -0.0698,  0.1283,  0.0069,  0.1621,  0.0951,  0.0935,\n",
      "           0.3624,  0.3452,  0.0985, -0.1514, -0.2573, -0.0042,  0.1096,\n",
      "          -0.1936, -0.2908, -0.1879, -0.0426, -0.2362,  0.0910, -0.2391,\n",
      "           0.0423, -0.0354,  0.2198,  0.0879, -0.0787,  0.1718, -0.1915,\n",
      "           0.0859, -0.2996,  0.1252, -0.0806, -0.1680,  0.1248,  0.1006,\n",
      "          -0.1891, -0.2216,  0.3099, -0.0604,  0.0309,  0.0904,  0.2091,\n",
      "           0.1204, -0.1063, -0.1479,  0.2866,  0.0618, -0.0782,  0.0741,\n",
      "           0.0192, -0.0886,  0.1719,  0.3077, -0.0760,  0.0470,  0.0794,\n",
      "           0.1155, -0.0301,  0.1039, -0.2686,  0.0318,  0.0952,  0.1829,\n",
      "          -0.0259,  0.0416, -0.0432, -0.1123, -0.2577, -0.0901,  0.2185,\n",
      "           0.2121,  0.0946,  0.0900, -0.1638,  0.0123, -0.3045,  0.2994,\n",
      "          -0.0580, -0.0667,  0.3211,  0.1060, -0.0028,  0.1879,  0.0590,\n",
      "          -0.0041, -0.2655, -0.0847,  0.2301, -0.0537,  0.1121,  0.3350,\n",
      "          -0.2178,  0.1832,  0.0646, -0.2894, -0.0076,  0.0950, -0.0743,\n",
      "          -0.0845, -0.2668, -0.1081, -0.3187,  0.3048, -0.1863,  0.0740,\n",
      "           0.0296, -0.0303,  0.3453,  0.0453, -0.0484,  0.2251, -0.0663,\n",
      "          -0.1467,  0.1003, -0.1145, -0.2952,  0.0489, -0.3453, -0.1209,\n",
      "           0.2065, -0.2175,  0.1641,  0.0582,  0.3254, -0.2197, -0.0433,\n",
      "           0.1706,  0.1139,  0.0814,  0.2306, -0.0386,  0.1916,  0.0884,\n",
      "           0.0887,  0.1600,  0.1604,  0.2801, -0.0485, -0.0518,  0.2432,\n",
      "           0.2240, -0.0741,  0.1627,  0.0153, -0.2097,  0.1408,  0.1579,\n",
      "          -0.1205,  0.0877,  0.1386,  0.2860, -0.1340,  0.1089, -0.0408,\n",
      "           0.1173,  0.0226,  0.1701, -0.1229, -0.1292, -0.0410,  0.1175,\n",
      "          -0.1422,  0.2863,  0.0793,  0.1574,  0.0622,  0.3458,  0.1731,\n",
      "          -0.1648, -0.0225,  0.0505,  0.0429,  0.1202, -0.1851, -0.1223,\n",
      "          -0.0150,  0.0766,  0.0045,  0.0989, -0.0439, -0.0022, -0.1302,\n",
      "           0.0601,  0.2398, -0.1042, -0.1018, -0.1729, -0.1395,  0.0872,\n",
      "           0.0079,  0.3914, -0.1596, -0.0304, -0.0702,  0.0869,  0.0400,\n",
      "          -0.0264, -0.0869,  0.1051,  0.0358,  0.1076,  0.0532,  0.0049,\n",
      "          -0.2779,  0.1026, -0.0441,  0.0438, -0.0820, -0.1062,  0.0641,\n",
      "           0.3506, -0.0828, -0.0695,  0.3726, -0.0631,  0.3700, -0.1580,\n",
      "           0.0693,  0.0434, -0.2110,  0.0508, -0.3997,  0.0659, -0.1031,\n",
      "          -0.2592, -0.2655,  0.0069,  0.1031, -0.0955, -0.0151, -0.0609,\n",
      "           0.0850,  0.0452,  0.0942, -0.0811, -0.2303,  0.1972,  0.1743,\n",
      "          -0.1104, -0.2800, -0.3301, -0.0571, -0.0663,  0.0674,  0.1929,\n",
      "           0.1184,  0.0417,  0.1994, -0.0417]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7781, -1.6519, -0.1826, -0.7321,  2.5180, -1.9080,\n",
      "          -0.0326,  0.9502,  1.1945,  1.4103, -0.7569, -0.0650,  0.0646,\n",
      "           1.0464,  1.8853,  0.8702,  0.0000, -0.6403, -1.4034, -0.4985,\n",
      "          -0.3790,  1.1427,  0.2329,  0.1893, -0.6130,  1.4043, -0.1511,\n",
      "          -1.0410,  0.4961, -0.5711,  0.6008, -1.6988,  0.2317,  0.0000,\n",
      "           0.1482,  0.6451, -2.2132,  1.0516,  0.1024, -0.6923, -0.4366,\n",
      "          -1.0644,  0.8180, -0.6329,  0.0000,  1.3725,  0.9367,  1.6037,\n",
      "           0.0000, -1.0081, -1.1719, -1.1122,  1.2531, -1.9747,  1.7090,\n",
      "           0.5927, -1.8922,  0.3414, -0.2937, -0.7704,  1.8691, -0.5941,\n",
      "          -1.6817, -0.8353,  1.2345, -0.3576,  0.2896, -0.7527, -1.1648,\n",
      "           2.2478,  0.7807,  0.2705,  1.2050, -0.3981,  0.3547,  0.2294,\n",
      "          -0.1575, -0.9149,  0.2959, -0.1448,  1.2867,  0.4651,  1.2968,\n",
      "           0.7706,  0.6606,  1.0452, -0.3683, -1.2411, -1.4362,  1.3107,\n",
      "          -1.5854,  0.0000,  3.2389,  0.3468,  1.0036, -0.8685,  0.7312,\n",
      "          -1.6815, -0.9243,  0.1906,  0.0286, -0.5964,  0.0000, -0.2309,\n",
      "           0.0000, -0.9059, -0.3677, -0.2786, -0.5476, -0.1378, -3.2781,\n",
      "          -0.1010, -1.8785,  1.6980,  1.6883,  2.0296, -1.6461, -0.8959,\n",
      "           2.5844,  0.0000,  1.4236, -0.6276,  0.0000,  1.3156, -0.9872,\n",
      "           0.0740, -0.9857, -0.6750,  0.2476, -1.2005,  1.1296,  1.1406,\n",
      "           1.4887,  0.3791,  0.6467, -0.8379,  0.2413,  0.3448, -1.2616,\n",
      "           0.0303,  0.8641,  0.5014,  0.9071, -1.2680, -0.6409, -0.4417,\n",
      "           0.8729, -0.0676,  0.0421, -0.0565,  0.6208,  0.1451,  0.0000,\n",
      "           0.1077, -1.6722, -0.4024,  0.2512, -2.0696,  0.4118,  1.1553,\n",
      "           0.0000,  0.9130,  0.8437,  0.4173,  1.6037,  0.1770,  0.0000,\n",
      "          -0.3225,  0.2507,  0.4452, -0.4551,  0.4446, -1.3453,  1.7357,\n",
      "           0.5175,  1.1773,  0.2896, -1.8322, -1.8661,  0.2593, -0.6474,\n",
      "          -1.1658,  0.3287, -0.7439,  0.5920, -1.2417, -1.5177, -2.3034,\n",
      "           0.1466, -1.6243, -1.3211, -0.0500,  1.2996,  0.9805, -1.4146,\n",
      "          -1.1403,  3.0134, -0.2259,  1.0326,  0.0293,  0.1189,  0.0000,\n",
      "           0.0000,  0.0000,  1.7330,  0.5270,  1.9824, -0.9788, -1.3424,\n",
      "           1.5994, -0.4016,  2.4609, -0.5196,  0.7546,  0.2064, -0.8211,\n",
      "           0.9056,  0.0000,  0.1760, -0.7813, -0.6933, -1.4186,  0.2512,\n",
      "          -0.0648, -1.4656,  0.4270, -0.5198,  0.0463,  0.0000, -0.0712,\n",
      "           0.7482,  0.0000, -1.0489,  0.0000, -0.1122,  0.5160, -2.7969,\n",
      "          -1.4579, -0.6645,  1.0257,  0.1329,  2.7511,  1.0024,  0.5472,\n",
      "          -0.1736, -1.5052,  2.2319,  1.1874, -0.0478,  0.7228,  0.1090,\n",
      "          -2.8554, -0.0138, -0.8378, -0.5804]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0412, 0.1599, 0.1093, 0.0847, 0.1069, 0.1230, 0.0766, 0.0985, 0.1089,\n",
      "         0.0909]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0359,  0.0717,  ..., -0.1134, -0.0100, -0.4873],\n",
      "        [ 0.1262,  0.1331,  0.2636,  ...,  0.1119,  0.0940,  0.0422],\n",
      "        [ 0.1228,  0.3953,  0.0079,  ...,  0.2011,  0.2312,  0.1531],\n",
      "        ...,\n",
      "        [ 0.0848,  0.1072, -0.3314,  ...,  0.0370,  0.2894, -0.3461],\n",
      "        [ 0.3941,  0.1411, -0.4355,  ..., -0.3504,  0.5114, -0.2855],\n",
      "        [ 0.6876,  0.5535, -0.7469,  ..., -0.3326,  0.0792,  0.0401]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.3737e-01,  5.0267e-02, -2.1289e-01,  1.2425e-01,  2.3982e-01,\n",
      "           1.7841e-01, -3.1842e-01, -1.0220e-01, -5.0359e-02,  1.4011e-01,\n",
      "           1.7067e-02,  1.1560e-01,  6.5072e-02,  6.1048e-02,  3.9317e-01,\n",
      "           2.9399e-01,  1.5077e-01, -1.0398e-01, -2.7412e-01,  1.2234e-02,\n",
      "           1.0153e-02, -2.0386e-01, -2.8854e-01, -1.8103e-01, -8.5128e-02,\n",
      "          -2.2169e-01,  6.3190e-02, -1.8844e-01,  1.7283e-02, -9.3691e-02,\n",
      "           2.2348e-01,  3.0103e-02, -1.4120e-01,  1.0980e-01, -1.6727e-01,\n",
      "           8.1788e-02, -3.3398e-01,  7.5891e-02, -8.1052e-02, -1.5583e-01,\n",
      "           1.4126e-01,  6.8866e-02, -1.3428e-01, -1.7860e-01,  2.7510e-01,\n",
      "          -7.6212e-02,  5.2693e-02,  4.4749e-02,  1.8177e-01,  1.2059e-01,\n",
      "          -8.6588e-02, -2.3127e-01,  2.3276e-01,  9.4378e-02, -1.1916e-01,\n",
      "           1.1892e-01,  1.0288e-01, -1.3390e-02,  1.4292e-01,  3.0819e-01,\n",
      "          -4.8930e-02,  1.9262e-02,  5.3872e-02,  1.4366e-01, -3.4741e-02,\n",
      "           9.3754e-02, -2.2494e-01,  2.8963e-02,  6.6573e-02,  1.6067e-01,\n",
      "          -4.9838e-02,  6.6858e-02, -4.4738e-02, -6.6020e-02, -2.8030e-01,\n",
      "          -7.6965e-02,  2.1516e-01,  1.6964e-01,  6.8883e-02,  8.1951e-02,\n",
      "          -1.6530e-01, -7.4367e-03, -3.0942e-01,  2.2550e-01, -5.4302e-02,\n",
      "          -4.0038e-02,  2.8456e-01,  9.0576e-02,  6.9606e-03,  1.5878e-01,\n",
      "           5.8345e-02,  2.3308e-02, -2.0719e-01, -1.0281e-01,  1.9174e-01,\n",
      "          -2.9427e-02,  1.1785e-01,  3.6367e-01, -2.1240e-01,  1.7960e-01,\n",
      "          -1.5057e-02, -2.6206e-01, -3.2183e-02,  8.8133e-02, -4.5219e-02,\n",
      "          -6.3502e-02, -1.9333e-01, -5.1352e-02, -2.8444e-01,  3.0348e-01,\n",
      "          -1.4179e-01,  6.0895e-02,  3.5514e-02, -2.8862e-02,  3.0659e-01,\n",
      "           5.2977e-02,  1.4893e-03,  1.7464e-01, -1.0746e-01, -1.3924e-01,\n",
      "           1.1383e-01, -1.7713e-01, -2.4155e-01,  8.6139e-02, -3.0252e-01,\n",
      "          -1.4661e-01,  1.4939e-01, -1.4942e-01,  1.4051e-01,  7.1585e-02,\n",
      "           2.9114e-01, -2.3898e-01,  6.6307e-02,  2.2554e-01,  6.4457e-02,\n",
      "           6.7856e-02,  2.4997e-01, -4.8493e-03,  1.8282e-01,  1.1815e-01,\n",
      "           7.5278e-02,  1.5257e-01,  6.7190e-02,  2.5339e-01, -3.0950e-02,\n",
      "          -1.1626e-01,  1.8106e-01,  2.2890e-01, -6.2938e-02,  1.2639e-01,\n",
      "          -8.6338e-03, -1.5096e-01,  1.5862e-01,  1.4935e-01, -7.4778e-02,\n",
      "           1.5270e-01,  1.1729e-01,  2.6100e-01, -6.3522e-02,  8.7773e-02,\n",
      "          -7.4433e-02,  2.1981e-02, -2.0817e-02,  1.4570e-01, -1.0078e-01,\n",
      "          -8.6999e-02, -1.1192e-01,  1.4107e-01, -1.0547e-01,  2.9640e-01,\n",
      "           8.2940e-02,  1.6592e-01,  9.3277e-02,  3.3529e-01,  1.2250e-01,\n",
      "          -1.3429e-01, -5.5012e-02,  1.0183e-01,  1.2164e-01,  1.4775e-02,\n",
      "          -1.7703e-01, -1.2989e-01, -2.1724e-02,  3.2903e-02,  6.1049e-02,\n",
      "           1.1071e-01, -8.4650e-02, -1.5438e-02, -7.9665e-02,  1.5478e-02,\n",
      "           2.0655e-01, -8.4870e-02, -1.7193e-01, -1.7563e-01, -1.5110e-01,\n",
      "           6.7633e-02,  5.8272e-02,  3.8038e-01, -1.9255e-01, -1.0240e-04,\n",
      "          -4.7931e-02,  1.2418e-01, -2.2711e-03,  1.2095e-02, -5.6147e-02,\n",
      "           1.2688e-02, -1.5209e-02,  1.4252e-01,  4.3012e-02, -1.5630e-02,\n",
      "          -2.3911e-01,  4.2459e-02, -7.5434e-02,  3.0138e-02, -1.2893e-01,\n",
      "          -8.6829e-02,  8.0445e-02,  3.5612e-01, -1.3830e-01, -3.8372e-02,\n",
      "           3.1900e-01, -1.1187e-01,  3.0840e-01, -1.5671e-01,  5.8083e-02,\n",
      "           5.7884e-02, -1.5361e-01, -7.6281e-02, -4.3063e-01,  1.2607e-01,\n",
      "          -1.1769e-01, -2.7896e-01, -1.8848e-01,  2.4009e-02,  8.3842e-02,\n",
      "          -1.1666e-01, -3.6346e-02, -4.9334e-02,  5.8388e-02,  4.5296e-03,\n",
      "           1.2137e-01, -4.3315e-02, -2.4039e-01,  1.5543e-01,  1.7901e-01,\n",
      "          -1.0885e-01, -2.7067e-01, -3.0823e-01, -2.3678e-03, -7.6205e-02,\n",
      "           4.1248e-02,  1.9066e-01,  1.2544e-02,  3.1086e-02,  2.1614e-01,\n",
      "          -3.1286e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000,  0.7781, -1.6519, -0.1826, -0.7321,  2.5180, -1.9080,\n",
      "           0.0000,  0.9502,  1.1945,  1.4103, -0.7569, -0.0650,  0.0646,\n",
      "           1.0464,  1.8853,  0.8702,  0.0000,  0.0000, -1.4034, -0.4985,\n",
      "          -0.3790,  1.1427,  0.2329,  0.1893, -0.6130,  1.4043, -0.1511,\n",
      "          -1.0410,  0.0000, -0.5711,  0.6008, -1.6988,  0.2317, -0.0796,\n",
      "           0.1482,  0.6451, -2.2132,  1.0516,  0.1024,  0.0000, -0.4366,\n",
      "          -1.0644,  0.8180, -0.6329, -0.6566,  1.3725,  0.9367,  1.6037,\n",
      "           0.3696, -1.0081, -1.1719, -1.1122,  1.2531, -1.9747,  1.7090,\n",
      "           0.5927, -1.8922,  0.3414,  0.0000, -0.7704,  1.8691, -0.5941,\n",
      "          -1.6817, -0.8353,  1.2345, -0.3576,  0.2896, -0.7527, -1.1648,\n",
      "           2.2478,  0.7807,  0.2705,  1.2050, -0.3981,  0.3547,  0.2294,\n",
      "          -0.1575, -0.9149,  0.2959, -0.1448,  1.2867,  0.0000,  1.2968,\n",
      "           0.7706,  0.6606,  1.0452,  0.0000, -1.2411, -1.4362,  1.3107,\n",
      "          -1.5854, -0.1110,  3.2389,  0.3468,  1.0036, -0.8685,  0.7312,\n",
      "          -1.6815, -0.9243,  0.1906,  0.0286, -0.5964,  1.0584, -0.2309,\n",
      "           0.7759, -0.9059, -0.3677,  0.0000,  0.0000, -0.1378, -3.2781,\n",
      "          -0.1010,  0.0000,  1.6980,  1.6883,  2.0296, -1.6461, -0.8959,\n",
      "           2.5844, -1.3263,  1.4236, -0.6276,  0.4666,  1.3156, -0.9872,\n",
      "           0.0740, -0.9857, -0.6750,  0.2476, -1.2005,  1.1296,  1.1406,\n",
      "           1.4887,  0.3791,  0.6467,  0.0000,  0.2413,  0.3448, -1.2616,\n",
      "           0.0303,  0.8641,  0.5014,  0.9071, -1.2680, -0.6409, -0.4417,\n",
      "           0.8729, -0.0676,  0.0421, -0.0565,  0.6208,  0.1451, -0.1965,\n",
      "           0.1077, -1.6722, -0.4024,  0.2512, -2.0696,  0.4118,  1.1553,\n",
      "           0.1996,  0.0000,  0.8437,  0.4173,  1.6037,  0.1770, -1.1142,\n",
      "          -0.3225,  0.2507,  0.4452, -0.4551,  0.0000, -1.3453,  1.7357,\n",
      "           0.5175,  1.1773,  0.2896, -1.8322, -1.8661,  0.2593, -0.6474,\n",
      "          -1.1658,  0.3287, -0.7439,  0.5920, -1.2417, -1.5177,  0.0000,\n",
      "           0.1466, -1.6243, -1.3211, -0.0500,  1.2996,  0.9805,  0.0000,\n",
      "          -1.1403,  3.0134, -0.2259,  1.0326,  0.0293,  0.1189, -1.3197,\n",
      "          -1.0707,  0.0566,  1.7330,  0.5270,  1.9824, -0.9788, -1.3424,\n",
      "           1.5994, -0.4016,  2.4609,  0.0000,  0.7546,  0.2064, -0.8211,\n",
      "           0.9056,  0.0000,  0.1760, -0.7813, -0.6933, -1.4186,  0.2512,\n",
      "          -0.0648, -1.4656,  0.4270, -0.5198,  0.0463, -0.6252, -0.0712,\n",
      "           0.7482, -2.0271, -1.0489, -0.4317, -0.1122,  0.5160,  0.0000,\n",
      "          -1.4579, -0.6645,  0.0000,  0.1329,  2.7511,  1.0024,  0.5472,\n",
      "          -0.1736, -1.5052,  2.2319,  1.1874,  0.0000,  0.7228,  0.1090,\n",
      "           0.0000, -0.0138, -0.8378, -0.5804]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0306, 0.1593, 0.1295, 0.0947, 0.0921, 0.1233, 0.0636, 0.0826, 0.1418,\n",
      "         0.0826]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0359,  0.0717,  ..., -0.1134, -0.0100, -0.4873],\n",
      "        [ 0.1262,  0.1331,  0.2636,  ...,  0.1119,  0.0940,  0.0422],\n",
      "        [ 0.1228,  0.3953,  0.0079,  ...,  0.2011,  0.2312,  0.1531],\n",
      "        ...,\n",
      "        [ 0.0848,  0.1072, -0.3314,  ...,  0.0370,  0.2894, -0.3461],\n",
      "        [ 0.3941,  0.1411, -0.4355,  ..., -0.3504,  0.5114, -0.2855],\n",
      "        [ 0.6876,  0.5535, -0.7469,  ..., -0.3326,  0.0792,  0.0401]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1364,  0.0649, -0.2105,  0.1241,  0.2404,  0.1840, -0.3192,\n",
      "          -0.1018, -0.0440,  0.1407,  0.0132,  0.1195,  0.0569,  0.0813,\n",
      "           0.3856,  0.2943,  0.1446, -0.1005, -0.2822,  0.0116,  0.0026,\n",
      "          -0.2046, -0.2716, -0.1969, -0.0826, -0.2144,  0.0784, -0.1978,\n",
      "           0.0249, -0.0876,  0.2196,  0.0338, -0.1405,  0.0942, -0.1520,\n",
      "           0.0779, -0.3406,  0.0659, -0.0925, -0.1424,  0.1398,  0.1002,\n",
      "          -0.1212, -0.1805,  0.2480, -0.0622,  0.0530,  0.0460,  0.1892,\n",
      "           0.1237, -0.0707, -0.2306,  0.2228,  0.0955, -0.1125,  0.1356,\n",
      "           0.1014,  0.0005,  0.1484,  0.3152, -0.0390,  0.0093,  0.0542,\n",
      "           0.1404, -0.0594,  0.1043, -0.2295,  0.0256,  0.0539,  0.1601,\n",
      "          -0.0502,  0.0665, -0.0377, -0.0504, -0.2878, -0.0736,  0.2274,\n",
      "           0.1617,  0.0758,  0.0739, -0.1637,  0.0093, -0.3066,  0.2340,\n",
      "          -0.0589, -0.0393,  0.2960,  0.1023,  0.0034,  0.1760,  0.0774,\n",
      "           0.0194, -0.1973, -0.1102,  0.2007, -0.0161,  0.1171,  0.3731,\n",
      "          -0.1972,  0.1827, -0.0245, -0.2526, -0.0180,  0.0810, -0.0243,\n",
      "          -0.0796, -0.1807, -0.0506, -0.2767,  0.2987, -0.1342,  0.0684,\n",
      "           0.0196, -0.0340,  0.3097,  0.0557,  0.0089,  0.1585, -0.1190,\n",
      "          -0.1316,  0.1079, -0.1706, -0.2276,  0.0947, -0.3075, -0.1625,\n",
      "           0.1405, -0.1387,  0.1345,  0.0737,  0.2867, -0.2428,  0.0811,\n",
      "           0.2324,  0.0679,  0.0569,  0.2552,  0.0050,  0.1876,  0.1397,\n",
      "           0.0473,  0.1614,  0.0573,  0.2558, -0.0267, -0.1155,  0.1673,\n",
      "           0.2238, -0.0609,  0.1172, -0.0156, -0.1377,  0.1575,  0.1708,\n",
      "          -0.0804,  0.1609,  0.1255,  0.2656, -0.0650,  0.1028, -0.0881,\n",
      "           0.0280, -0.0362,  0.1500, -0.1187, -0.0974, -0.1395,  0.1497,\n",
      "          -0.1084,  0.2873,  0.0803,  0.1576,  0.0939,  0.3366,  0.1206,\n",
      "          -0.1323, -0.0570,  0.1103,  0.1186, -0.0022, -0.1724, -0.1270,\n",
      "          -0.0256,  0.0232,  0.0857,  0.1065, -0.0709, -0.0071, -0.0788,\n",
      "           0.0100,  0.2040, -0.0976, -0.1754, -0.1711, -0.1719,  0.0636,\n",
      "           0.0723,  0.3730, -0.1964, -0.0210, -0.0452,  0.1180, -0.0055,\n",
      "          -0.0013, -0.0613,  0.0065, -0.0239,  0.1412,  0.0492, -0.0326,\n",
      "          -0.2611,  0.0480, -0.0813,  0.0238, -0.1248, -0.0838,  0.1043,\n",
      "           0.3592, -0.1482, -0.0432,  0.3232, -0.1223,  0.2927, -0.1559,\n",
      "           0.0451,  0.0678, -0.1447, -0.0905, -0.4456,  0.1294, -0.1059,\n",
      "          -0.2860, -0.1901,  0.0281,  0.0799, -0.1223, -0.0249, -0.0510,\n",
      "           0.0655,  0.0096,  0.1196, -0.0256, -0.2346,  0.1529,  0.1789,\n",
      "          -0.1165, -0.2828, -0.2968, -0.0083, -0.0997,  0.0541,  0.1969,\n",
      "           0.0141,  0.0328,  0.2309, -0.0220]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7781, -1.6519, -0.1826, -0.7321,  2.5180, -1.9080,\n",
      "          -0.0326,  0.9502,  1.1945,  1.4103, -0.7569, -0.0650,  0.0646,\n",
      "           1.0464,  1.8853,  0.8702, -0.7849, -0.6403, -1.4034, -0.4985,\n",
      "          -0.3790,  1.1427,  0.2329,  0.1893, -0.6130,  1.4043, -0.1511,\n",
      "          -1.0410,  0.4961,  0.0000,  0.6008, -1.6988,  0.2317, -0.0796,\n",
      "           0.1482,  0.6451, -2.2132,  1.0516,  0.1024, -0.6923, -0.4366,\n",
      "          -1.0644,  0.8180, -0.6329, -0.6566,  1.3725,  0.9367,  1.6037,\n",
      "           0.3696, -1.0081, -1.1719, -1.1122,  1.2531,  0.0000,  1.7090,\n",
      "           0.5927, -1.8922,  0.3414, -0.2937, -0.7704,  1.8691, -0.5941,\n",
      "          -1.6817, -0.8353,  0.0000, -0.3576,  0.2896, -0.7527, -1.1648,\n",
      "           0.0000,  0.7807,  0.2705,  1.2050, -0.3981,  0.3547,  0.2294,\n",
      "          -0.1575, -0.9149,  0.2959, -0.1448,  1.2867,  0.4651,  1.2968,\n",
      "           0.7706,  0.6606,  1.0452, -0.3683, -1.2411, -1.4362,  1.3107,\n",
      "          -1.5854, -0.1110,  3.2389,  0.3468,  1.0036, -0.8685,  0.7312,\n",
      "          -1.6815, -0.9243,  0.1906,  0.0286,  0.0000,  1.0584, -0.2309,\n",
      "           0.7759, -0.9059, -0.3677, -0.2786, -0.5476, -0.1378, -3.2781,\n",
      "          -0.1010, -1.8785,  1.6980,  1.6883,  2.0296, -1.6461,  0.0000,\n",
      "           2.5844,  0.0000,  1.4236, -0.6276,  0.0000,  1.3156, -0.9872,\n",
      "           0.0740, -0.9857, -0.6750,  0.2476, -1.2005,  1.1296,  1.1406,\n",
      "           1.4887,  0.3791,  0.6467, -0.8379,  0.2413,  0.3448, -1.2616,\n",
      "           0.0303,  0.8641,  0.5014,  0.9071, -1.2680, -0.6409, -0.4417,\n",
      "           0.8729, -0.0676,  0.0421, -0.0565,  0.6208,  0.1451, -0.1965,\n",
      "           0.0000, -1.6722, -0.4024,  0.2512, -2.0696,  0.4118,  1.1553,\n",
      "           0.1996,  0.9130,  0.8437,  0.4173,  1.6037,  0.1770, -1.1142,\n",
      "          -0.3225,  0.2507,  0.4452, -0.4551,  0.0000, -1.3453,  1.7357,\n",
      "           0.5175,  1.1773,  0.2896, -1.8322, -1.8661,  0.2593, -0.6474,\n",
      "           0.0000,  0.0000,  0.0000,  0.5920, -1.2417, -1.5177, -2.3034,\n",
      "           0.1466, -1.6243, -1.3211, -0.0500,  1.2996,  0.9805, -1.4146,\n",
      "           0.0000,  3.0134, -0.2259,  0.0000,  0.0293,  0.1189, -1.3197,\n",
      "          -1.0707,  0.0000,  1.7330,  0.5270,  1.9824, -0.9788, -1.3424,\n",
      "           1.5994, -0.4016,  2.4609, -0.5196,  0.0000,  0.2064, -0.8211,\n",
      "           0.9056, -3.5304,  0.0000, -0.7813, -0.6933, -1.4186,  0.2512,\n",
      "          -0.0648, -1.4656,  0.4270, -0.5198,  0.0463, -0.6252, -0.0712,\n",
      "           0.7482, -2.0271, -1.0489, -0.4317,  0.0000,  0.5160, -2.7969,\n",
      "          -1.4579, -0.6645,  1.0257,  0.1329,  2.7511,  1.0024,  0.5472,\n",
      "          -0.1736, -1.5052,  2.2319,  1.1874, -0.0478,  0.7228,  0.1090,\n",
      "          -2.8554, -0.0138, -0.8378, -0.5804]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0454, 0.1653, 0.1097, 0.1131, 0.0836, 0.1244, 0.0799, 0.0775, 0.1146,\n",
      "         0.0866]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0359,  0.0717,  ..., -0.1134, -0.0100, -0.4873],\n",
      "        [ 0.1262,  0.1331,  0.2636,  ...,  0.1119,  0.0940,  0.0422],\n",
      "        [ 0.1228,  0.3953,  0.0079,  ...,  0.2011,  0.2312,  0.1531],\n",
      "        ...,\n",
      "        [ 0.0848,  0.1072, -0.3314,  ...,  0.0370,  0.2894, -0.3461],\n",
      "        [ 0.3941,  0.1411, -0.4355,  ..., -0.3504,  0.5114, -0.2855],\n",
      "        [ 0.6876,  0.5535, -0.7469,  ..., -0.3326,  0.0792,  0.0401]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1349,  0.0496, -0.2044,  0.1390,  0.2301,  0.1836, -0.3100,\n",
      "          -0.0885, -0.0521,  0.1511,  0.0127,  0.1115,  0.0627,  0.0728,\n",
      "           0.3822,  0.2984,  0.1409, -0.1074, -0.2871,  0.0102,  0.0047,\n",
      "          -0.1954, -0.2864, -0.1922, -0.0872, -0.2122,  0.0742, -0.1899,\n",
      "           0.0177, -0.1028,  0.2141,  0.0420, -0.1390,  0.1087, -0.1640,\n",
      "           0.0738, -0.3278,  0.0828, -0.0749, -0.1586,  0.1470,  0.0815,\n",
      "          -0.1356, -0.1713,  0.2648, -0.0805,  0.0589,  0.0585,  0.1805,\n",
      "           0.1205, -0.0754, -0.2342,  0.2365,  0.0890, -0.1147,  0.1183,\n",
      "           0.1036,  0.0043,  0.1463,  0.3020, -0.0271,  0.0173,  0.0498,\n",
      "           0.1302, -0.0410,  0.1021, -0.2359,  0.0197,  0.0475,  0.1455,\n",
      "          -0.0544,  0.0691, -0.0518, -0.0629, -0.2795, -0.0718,  0.2252,\n",
      "           0.1652,  0.0693,  0.0682, -0.1670,  0.0005, -0.2960,  0.2387,\n",
      "          -0.0436, -0.0378,  0.2913,  0.1010, -0.0089,  0.1777,  0.0608,\n",
      "           0.0258, -0.1991, -0.0951,  0.1895, -0.0203,  0.1244,  0.3718,\n",
      "          -0.2171,  0.1728, -0.0188, -0.2576, -0.0304,  0.0883, -0.0454,\n",
      "          -0.0676, -0.1881, -0.0590, -0.2765,  0.2913, -0.1381,  0.0525,\n",
      "           0.0152, -0.0158,  0.3084,  0.0531,  0.0145,  0.1648, -0.1265,\n",
      "          -0.1435,  0.0936, -0.1707, -0.2166,  0.0782, -0.2954, -0.1450,\n",
      "           0.1495, -0.1414,  0.1435,  0.0856,  0.2845, -0.2462,  0.0748,\n",
      "           0.2142,  0.0770,  0.0503,  0.2511, -0.0050,  0.1887,  0.1222,\n",
      "           0.0644,  0.1479,  0.0671,  0.2495, -0.0355, -0.1112,  0.1796,\n",
      "           0.2135, -0.0875,  0.1119,  0.0017, -0.1489,  0.1631,  0.1538,\n",
      "          -0.0930,  0.1613,  0.1368,  0.2612, -0.0519,  0.0986, -0.0763,\n",
      "           0.0301, -0.0235,  0.1422, -0.0989, -0.0998, -0.1273,  0.1514,\n",
      "          -0.1088,  0.2918,  0.0970,  0.1573,  0.0764,  0.3364,  0.1312,\n",
      "          -0.1269, -0.0712,  0.1013,  0.1174,  0.0071, -0.1617, -0.1123,\n",
      "          -0.0155,  0.0295,  0.0707,  0.1089, -0.0817, -0.0117, -0.0744,\n",
      "           0.0131,  0.2150, -0.1049, -0.1760, -0.1702, -0.1663,  0.0732,\n",
      "           0.0688,  0.3704, -0.1897, -0.0165, -0.0457,  0.1098, -0.0021,\n",
      "           0.0019, -0.0827,  0.0205, -0.0256,  0.1350,  0.0355, -0.0144,\n",
      "          -0.2425,  0.0567, -0.0739,  0.0245, -0.1192, -0.0948,  0.1060,\n",
      "           0.3533, -0.1346, -0.0330,  0.3166, -0.1226,  0.2884, -0.1487,\n",
      "           0.0452,  0.0595, -0.1506, -0.0912, -0.4361,  0.1256, -0.0991,\n",
      "          -0.2693, -0.1876,  0.0324,  0.0893, -0.1144, -0.0183, -0.0463,\n",
      "           0.0369,  0.0032,  0.1265, -0.0255, -0.2415,  0.1528,  0.1705,\n",
      "          -0.1046, -0.2761, -0.2942, -0.0051, -0.0812,  0.0405,  0.1892,\n",
      "           0.0109,  0.0471,  0.2260, -0.0103]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7266e-01, -4.3088e-01,  3.1518e-01, -1.0852e+00, -1.1729e+00,\n",
      "           7.4166e-01, -1.9146e+00,  1.3513e+00,  1.9007e-01,  6.1738e-01,\n",
      "           1.9037e+00,  6.0256e-01,  2.2922e-01, -9.1662e-01, -3.1841e+00,\n",
      "          -6.8272e-02, -1.6338e+00, -9.4357e-01,  1.3603e+00, -1.4358e+00,\n",
      "          -1.4038e-01, -5.2461e-01, -1.1199e+00, -2.5960e+00, -7.5921e-02,\n",
      "           1.3918e+00, -6.1993e-01,  1.9982e+00,  1.2777e-01,  0.0000e+00,\n",
      "           9.1591e-01, -3.8000e-03,  2.2238e-01,  2.0170e+00, -6.3583e-02,\n",
      "          -1.4086e+00, -1.1157e-01, -8.1741e-01,  3.1526e-01,  8.6132e-02,\n",
      "           8.6346e-01, -8.9933e-01,  1.0090e+00, -1.5641e+00,  1.9449e+00,\n",
      "          -3.0037e-01,  0.0000e+00, -6.0245e-01, -1.0210e+00,  1.1173e+00,\n",
      "          -1.3233e+00,  2.6783e+00,  6.6700e-01, -8.4708e-01,  2.2807e-01,\n",
      "          -3.1020e-01, -1.4341e+00, -9.6307e-02,  1.2760e+00,  2.1823e+00,\n",
      "           0.0000e+00,  3.5823e-02, -2.8018e-01,  2.6571e-01, -6.3258e-02,\n",
      "           3.9353e-01,  5.7817e-01,  1.1654e+00,  1.5812e+00, -1.4155e+00,\n",
      "           4.2731e-01,  2.9642e-01, -3.1045e-02, -7.9824e-01, -2.1417e-01,\n",
      "           1.3946e-01,  5.2595e-01,  1.3992e+00,  1.0274e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.0047e+00,  0.0000e+00,  1.0589e+00, -1.2157e+00,\n",
      "          -1.1333e-01, -1.1083e+00,  5.4872e-01, -9.4497e-01, -1.9015e+00,\n",
      "           0.0000e+00,  9.8746e-01,  1.7022e+00,  9.4431e-01,  6.0799e-01,\n",
      "          -1.5889e-02,  3.5439e-01, -1.1760e+00,  1.3727e+00,  2.4481e+00,\n",
      "           2.4344e-01,  4.4070e-02, -4.6668e-01, -9.8944e-01,  1.6412e+00,\n",
      "          -1.0242e+00,  3.0303e+00,  6.2083e-01, -1.0196e-01, -1.2357e+00,\n",
      "           1.8999e-01, -5.0337e-01, -5.7120e-01,  7.1261e-01, -7.8080e-01,\n",
      "           6.3264e-01,  0.0000e+00,  2.2347e-01, -2.3273e+00,  2.9215e-02,\n",
      "          -8.1485e-01, -1.4119e+00, -1.8387e+00,  6.0320e-01, -9.5724e-01,\n",
      "          -2.0101e-01,  4.0317e-02,  2.1509e+00,  1.3966e+00, -2.0884e+00,\n",
      "          -9.2623e-01,  0.0000e+00, -1.1684e+00,  0.0000e+00, -4.6830e-01,\n",
      "          -7.4639e-01, -1.0649e+00, -9.7551e-01, -1.9432e-02,  2.3980e+00,\n",
      "           6.9863e-01, -1.1219e+00,  1.6919e+00, -1.4046e-01,  0.0000e+00,\n",
      "           3.3160e-02,  7.5987e-01,  4.2289e-01, -1.0340e+00, -9.5270e-02,\n",
      "           1.5602e+00,  5.8675e-01, -3.3841e-01,  6.5783e-01,  1.8415e+00,\n",
      "          -2.5275e-01, -2.1789e-01,  6.2403e-01, -2.3639e+00,  1.0560e+00,\n",
      "           0.0000e+00, -7.7215e-02,  1.5532e-01, -1.2123e+00, -2.1903e-02,\n",
      "           1.6826e+00,  0.0000e+00,  2.7176e-01, -1.2704e+00, -7.1304e-01,\n",
      "          -1.2243e+00, -1.0942e+00, -2.5911e+00,  5.0591e-01, -3.0609e+00,\n",
      "          -2.8745e-01,  4.9758e-01,  8.2987e-01,  3.1711e-01, -7.9307e-01,\n",
      "           2.7260e-01,  0.0000e+00,  1.0583e+00,  8.3907e-01, -4.0241e-01,\n",
      "           7.2795e-01,  5.9870e-01,  3.5976e-01,  8.4335e-01, -1.8312e+00,\n",
      "           1.3638e+00,  2.1602e+00,  3.3583e-01, -1.0158e+00, -1.1730e+00,\n",
      "           0.0000e+00,  1.6678e+00,  2.1534e+00,  3.6344e-01,  2.3837e+00,\n",
      "           3.2592e-02, -5.0161e-01, -1.2772e+00, -5.4312e-01,  0.0000e+00,\n",
      "          -1.4478e+00,  9.5344e-01, -8.5207e-01,  8.2951e-01, -1.5605e+00,\n",
      "           6.3727e-01,  0.0000e+00,  2.3985e+00,  5.5320e-02,  1.8938e+00,\n",
      "           1.3091e+00,  5.8028e-01, -2.3180e+00,  1.5503e+00, -2.2255e-01,\n",
      "          -2.2740e-01,  1.7343e+00,  0.0000e+00,  0.0000e+00,  9.2287e-01,\n",
      "          -1.2244e+00, -8.4891e-01, -1.8026e+00, -7.6336e-04,  3.7321e-01,\n",
      "          -1.5739e+00, -1.2390e-01,  9.6635e-01, -1.7376e+00,  1.6948e+00,\n",
      "          -1.4405e+00,  6.3401e-01, -1.7231e+00,  9.8025e-01, -1.7172e+00,\n",
      "           1.5616e+00, -2.7309e-01, -2.5976e+00,  1.2392e+00, -1.2283e+00,\n",
      "           1.8864e+00,  0.0000e+00,  0.0000e+00, -2.6130e-01, -1.0225e+00,\n",
      "           1.3339e+00,  3.1136e-01,  0.0000e+00, -2.2879e-01,  0.0000e+00,\n",
      "           1.8071e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0408, 0.1403, 0.1538, 0.0789, 0.1287, 0.1253, 0.1314, 0.0530, 0.0919,\n",
      "         0.0560]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3520, -0.0359,  0.0717,  ..., -0.1134, -0.0100, -0.4873],\n",
      "        [ 0.1262,  0.1331,  0.2636,  ...,  0.1119,  0.0940,  0.0422],\n",
      "        [ 0.1228,  0.3953,  0.0079,  ...,  0.2011,  0.2312,  0.1531],\n",
      "        ...,\n",
      "        [ 0.0848,  0.1072, -0.3314,  ...,  0.0370,  0.2894, -0.3461],\n",
      "        [ 0.3941,  0.1411, -0.4355,  ..., -0.3504,  0.5114, -0.2855],\n",
      "        [ 0.6876,  0.5535, -0.7469,  ..., -0.3326,  0.0792,  0.0401]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2356e-01,  1.1131e-02, -1.9138e-01,  1.6789e-01,  2.6743e-01,\n",
      "           2.2022e-01, -3.3654e-01, -6.0367e-02, -7.6598e-02,  1.6206e-01,\n",
      "           3.5162e-04,  1.7785e-01,  9.0457e-02,  8.1597e-02,  3.8095e-01,\n",
      "           3.3168e-01,  9.4600e-02, -1.3883e-01, -2.4568e-01, -1.5277e-02,\n",
      "           5.9087e-02, -2.0649e-01, -3.2938e-01, -2.1363e-01, -6.3504e-02,\n",
      "          -2.1151e-01,  8.5143e-02, -1.9240e-01,  5.2235e-02, -9.1183e-02,\n",
      "           1.8738e-01,  7.5340e-02, -1.1737e-01,  1.7341e-01, -1.6126e-01,\n",
      "           6.3898e-02, -3.0069e-01,  9.6100e-02, -4.3231e-02, -1.7646e-01,\n",
      "           1.1985e-01,  8.2304e-02, -1.5818e-01, -2.1493e-01,  2.5739e-01,\n",
      "          -1.1902e-01,  5.5524e-02,  9.3465e-02,  1.8058e-01,  1.1960e-01,\n",
      "          -6.2014e-02, -1.8817e-01,  2.5051e-01,  8.6221e-02, -6.3526e-02,\n",
      "           1.2430e-01,  1.0428e-01, -3.5745e-02,  1.5411e-01,  2.7045e-01,\n",
      "          -4.6956e-02,  3.7435e-02,  9.2147e-02,  1.1744e-01, -3.8106e-03,\n",
      "           1.0692e-01, -2.7378e-01,  1.1274e-02,  9.3169e-02,  1.6522e-01,\n",
      "          -4.6372e-02,  1.7211e-02, -6.1540e-02, -1.0177e-01, -2.5011e-01,\n",
      "          -7.9552e-02,  2.0700e-01,  1.6055e-01,  8.3836e-02,  6.8702e-02,\n",
      "          -1.7683e-01,  1.8364e-02, -3.0993e-01,  2.7581e-01, -5.0978e-02,\n",
      "          -8.9728e-02,  2.8918e-01,  7.4827e-02, -4.7278e-02,  2.1621e-01,\n",
      "           4.5426e-02,  2.7188e-02, -2.2017e-01, -9.9575e-02,  1.9989e-01,\n",
      "          -3.7573e-02,  9.7235e-02,  3.3809e-01, -2.2190e-01,  1.6714e-01,\n",
      "           2.1994e-02, -3.2071e-01, -3.5031e-02,  8.2281e-02, -6.2812e-02,\n",
      "          -8.6444e-02, -2.2201e-01, -1.1485e-01, -2.8710e-01,  2.6695e-01,\n",
      "          -2.0381e-01,  5.5893e-02,  2.1065e-02, -4.7722e-03,  3.5663e-01,\n",
      "           5.0762e-02,  6.9182e-03,  2.0173e-01, -1.4993e-01, -1.3149e-01,\n",
      "           1.1187e-01, -1.5736e-01, -2.3656e-01,  2.4853e-02, -2.9835e-01,\n",
      "          -1.0728e-01,  1.8548e-01, -1.4592e-01,  1.3083e-01,  6.2980e-02,\n",
      "           2.9174e-01, -2.1201e-01, -2.9110e-02,  1.6869e-01,  8.7158e-02,\n",
      "           2.7681e-02,  2.5459e-01, -2.8153e-02,  2.3654e-01,  9.3841e-02,\n",
      "           6.9956e-02,  1.3302e-01,  1.1034e-01,  2.7552e-01, -5.7011e-02,\n",
      "          -1.1133e-01,  1.8219e-01,  1.8721e-01, -8.6719e-02,  1.3135e-01,\n",
      "           7.7519e-02, -1.8991e-01,  1.6914e-01,  1.6962e-01, -1.0316e-01,\n",
      "           1.1967e-01,  1.4787e-01,  2.5335e-01, -8.4177e-02,  1.2608e-01,\n",
      "          -3.9305e-02,  7.3189e-02,  1.8566e-02,  1.1560e-01, -1.0864e-01,\n",
      "          -1.2628e-01, -1.1725e-01,  1.3197e-01, -1.1877e-01,  3.0505e-01,\n",
      "           1.2484e-01,  1.7497e-01,  5.8852e-02,  3.4515e-01,  1.6912e-01,\n",
      "          -1.1770e-01, -2.1702e-02,  9.7149e-02,  5.4373e-02,  5.6067e-02,\n",
      "          -1.3230e-01, -1.1985e-01,  1.2479e-02,  6.2739e-02,  9.3993e-03,\n",
      "           1.0822e-01, -5.3541e-02, -2.3992e-03, -8.2223e-02,  4.5307e-02,\n",
      "           2.4855e-01, -1.3734e-01, -1.4585e-01, -1.7723e-01, -1.6835e-01,\n",
      "           8.2871e-02,  5.3527e-02,  3.8143e-01, -1.5109e-01, -3.7653e-02,\n",
      "          -7.5845e-02,  7.6615e-02, -4.8017e-03, -4.1587e-02, -1.0904e-01,\n",
      "           7.8850e-02,  1.8406e-02,  7.4309e-02,  6.0664e-02,  1.2091e-02,\n",
      "          -2.6469e-01,  7.7307e-02, -6.3878e-02, -8.1033e-04, -9.1078e-02,\n",
      "          -1.2197e-01,  9.0195e-02,  3.2801e-01, -9.5716e-02, -6.2320e-02,\n",
      "           3.0903e-01, -7.1985e-02,  2.9937e-01, -1.5977e-01,  3.4803e-02,\n",
      "           3.0203e-02, -1.8304e-01,  1.8151e-02, -4.1303e-01,  8.5950e-02,\n",
      "          -7.3604e-02, -2.7568e-01, -1.9765e-01,  5.8615e-02,  8.7323e-02,\n",
      "          -1.0277e-01,  3.1847e-02, -3.8020e-02,  1.9968e-02, -1.4336e-03,\n",
      "           1.5206e-01, -8.3742e-03, -2.3715e-01,  1.7476e-01,  1.3486e-01,\n",
      "          -1.0937e-01, -2.7363e-01, -2.7832e-01, -7.1356e-03, -6.2138e-02,\n",
      "           3.3522e-02,  2.0118e-01,  5.1284e-02,  5.2450e-02,  2.2226e-01,\n",
      "          -4.0464e-03]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5665e-02,  3.9883e-01, -9.6719e-01, -6.8215e-01,  3.7649e-01,\n",
      "          -2.0175e-01,  1.4650e+00, -8.3225e-02, -3.5857e+00,  9.0682e-01,\n",
      "           4.2910e-01,  0.0000e+00,  2.6063e+00, -6.2975e-01, -5.4170e-01,\n",
      "          -1.5796e-01,  8.5181e-01,  1.0952e+00,  4.5516e-01,  4.3614e-01,\n",
      "          -6.3391e-01, -3.8381e-01,  1.6423e+00,  1.5116e+00,  7.5404e-01,\n",
      "          -7.5328e-02, -1.8767e-01, -7.5902e-01,  1.6543e+00,  0.0000e+00,\n",
      "           1.2322e+00,  1.2193e+00, -1.0345e+00, -8.2636e-02, -1.5353e+00,\n",
      "           1.3955e+00,  2.8079e-01, -3.7463e+00,  1.9809e-01,  1.6018e+00,\n",
      "           0.0000e+00, -1.3992e+00, -2.6828e-01, -1.7171e+00, -1.5253e+00,\n",
      "           6.6727e-01,  0.0000e+00,  3.7000e-01, -1.3412e+00,  0.0000e+00,\n",
      "          -6.2883e-01,  2.7539e+00,  6.1061e-01, -1.0300e+00, -2.5844e-02,\n",
      "           2.0288e-01, -8.8261e-01, -1.2534e+00, -2.3648e-01, -4.2507e-01,\n",
      "           1.1016e+00,  1.4087e+00, -2.0385e-01, -5.0214e-01, -2.9656e+00,\n",
      "           5.5042e-01,  1.2794e+00, -1.2886e+00,  4.1190e-01,  5.2639e-01,\n",
      "          -1.2678e+00, -3.0521e-02,  7.0757e-01, -3.6432e+00,  3.2667e-01,\n",
      "          -2.4439e-03, -1.5982e-01,  1.0634e+00, -5.8625e-02, -1.2030e-01,\n",
      "           0.0000e+00,  2.1324e+00, -9.2521e-01,  1.0057e+00, -2.0793e-01,\n",
      "           4.3427e-01,  1.6622e+00,  0.0000e+00, -1.0303e-01, -5.8163e-01,\n",
      "          -2.2745e+00,  1.1007e+00, -6.2236e-01, -1.1354e+00,  4.6763e-01,\n",
      "          -1.1712e+00,  3.4524e-02,  6.2938e-01,  1.7209e+00,  0.0000e+00,\n",
      "           2.6982e+00,  0.0000e+00,  1.0762e+00,  1.4549e+00, -6.6668e-01,\n",
      "          -7.6261e-01,  1.2132e+00,  1.2748e-01,  0.0000e+00, -1.2910e-02,\n",
      "          -2.4902e-01,  1.3455e-01, -1.0491e+00,  1.3105e+00, -1.6543e+00,\n",
      "          -2.9911e+00, -5.6179e-02, -5.0185e-01,  0.0000e+00,  4.4466e-01,\n",
      "          -1.4676e+00,  7.0268e-01, -1.4612e+00, -7.2649e-01, -9.5897e-01,\n",
      "          -1.3098e+00,  8.9815e-01,  1.7064e-01,  1.2861e+00, -7.5293e-01,\n",
      "          -8.2316e-01,  5.2960e-01, -1.5837e+00,  9.8428e-01,  2.7619e-01,\n",
      "          -5.8975e-01,  6.6023e-01,  0.0000e+00, -1.1585e+00,  0.0000e+00,\n",
      "          -3.8919e-01,  6.7787e-01, -7.9032e-01, -1.0197e-01,  0.0000e+00,\n",
      "          -1.0153e-01, -5.4343e-01, -8.4467e-01, -7.5563e-01,  1.7741e-01,\n",
      "           1.9995e+00, -1.9991e-01, -1.9316e+00, -4.0629e-01,  4.4172e-01,\n",
      "          -1.9452e-01, -6.3988e-02, -1.2884e-01,  0.0000e+00,  5.3776e-01,\n",
      "          -2.6064e-02,  2.2070e+00,  4.8121e-01, -5.4973e-01, -5.2786e-01,\n",
      "          -8.9326e-01,  2.8183e-01,  8.4943e-02, -3.5804e-01, -4.7825e-01,\n",
      "           0.0000e+00, -3.2689e-02,  1.9842e-02, -1.0021e+00,  1.2781e+00,\n",
      "          -1.0995e+00, -9.8832e-01, -2.0785e+00,  0.0000e+00,  8.6394e-02,\n",
      "          -2.9530e-02,  3.5102e-02,  6.7186e-01,  0.0000e+00, -7.4695e-01,\n",
      "          -3.4102e-01, -2.7849e+00, -7.8513e-01,  1.2103e+00,  1.0127e+00,\n",
      "           3.0760e+00,  4.9461e-01, -1.4410e-01, -5.9514e-01,  5.6099e-01,\n",
      "           2.1663e+00, -1.1886e+00,  5.3474e-01,  1.8128e+00, -9.4795e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2418e+00, -1.2211e-01,  2.3191e-01,\n",
      "          -5.7557e-01,  0.0000e+00,  0.0000e+00, -1.0752e+00, -4.7154e-01,\n",
      "           2.8694e+00, -5.7342e-01, -3.4119e-01,  0.0000e+00,  2.9761e-02,\n",
      "          -6.8521e-01, -1.0202e+00,  9.6628e-01, -2.4602e-01,  2.1706e+00,\n",
      "          -1.0832e+00,  0.0000e+00, -1.8446e+00, -5.0187e-01,  3.3692e-01,\n",
      "           0.0000e+00, -6.9661e-01, -6.2815e-01,  2.9228e-01, -1.5794e+00,\n",
      "          -1.1092e+00,  1.5819e+00, -6.1445e-01,  1.3099e+00, -2.9809e+00,\n",
      "           4.0373e+00,  5.8518e-01,  4.3640e-02, -1.5813e+00, -2.8773e-01,\n",
      "           7.4151e-01, -3.2501e+00, -3.0484e-01, -8.5298e-01,  1.1074e-02,\n",
      "           2.7521e-01,  2.7513e-01,  2.5273e-01,  2.6089e-01,  3.8668e-01,\n",
      "          -3.6563e-01,  0.0000e+00, -5.5427e-01, -5.2675e-02, -1.1474e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0368, 0.0495, 0.0641, 0.0713, 0.1252, 0.3610, 0.0519, 0.0834, 0.0586,\n",
      "         0.0982]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0348,  0.0731,  ..., -0.1115, -0.0112, -0.4874],\n",
      "        [ 0.0528,  0.1140, -0.1213,  ..., -0.1182,  0.3371, -0.4386],\n",
      "        [ 0.0333, -0.0054, -0.0697,  ...,  0.2746,  0.0888, -0.3522],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1420,  0.0810, -0.1183, -0.0991,  0.0311, -0.0672, -0.0625,\n",
      "          -0.1283, -0.0111, -0.0265,  0.0025, -0.1033, -0.0710, -0.0670,\n",
      "           0.0718,  0.0687,  0.0607,  0.0484, -0.2128,  0.1218, -0.1388,\n",
      "          -0.0846,  0.0699,  0.0092, -0.1295, -0.1096,  0.0483, -0.1106,\n",
      "          -0.0258, -0.0164,  0.1388, -0.0956, -0.1144, -0.0578, -0.0245,\n",
      "          -0.0648, -0.1123, -0.0550, -0.0413,  0.0103,  0.0703,  0.0428,\n",
      "          -0.0933, -0.0229,  0.0911,  0.0506, -0.0901, -0.0956,  0.0626,\n",
      "          -0.0359, -0.0645, -0.1295, -0.0898, -0.0072,  0.0237,  0.0186,\n",
      "           0.0546,  0.1093,  0.1533,  0.0961,  0.0588, -0.0574, -0.1196,\n",
      "           0.0093, -0.0358,  0.0407, -0.0416,  0.1588, -0.0714,  0.0452,\n",
      "           0.0010,  0.1416,  0.0523,  0.0662, -0.0577,  0.1373,  0.0923,\n",
      "           0.0781, -0.0474,  0.0931, -0.1267, -0.0425, -0.1626,  0.0121,\n",
      "           0.0225,  0.0374,  0.0639,  0.0801,  0.1513,  0.0699,  0.0296,\n",
      "           0.0381,  0.0243, -0.0115,  0.0327,  0.0457,  0.0355,  0.1717,\n",
      "          -0.0270,  0.1117,  0.0023,  0.1111,  0.0690,  0.0923,  0.0172,\n",
      "           0.0525,  0.0094,  0.1204, -0.0317,  0.0585,  0.0241,  0.0007,\n",
      "          -0.0140, -0.1367, -0.0605,  0.0079,  0.1130, -0.0619, -0.1935,\n",
      "          -0.1356,  0.0037, -0.1119, -0.0994,  0.0824, -0.0596, -0.0363,\n",
      "           0.0660, -0.0223,  0.1296, -0.0406,  0.0224, -0.1308,  0.1228,\n",
      "           0.1134, -0.0148,  0.0478,  0.1931,  0.0574, -0.0864,  0.0952,\n",
      "          -0.0183,  0.0694, -0.0613,  0.0929,  0.1050, -0.0825,  0.0778,\n",
      "           0.1623,  0.0780,  0.1479, -0.1789,  0.0220, -0.0367,  0.0402,\n",
      "           0.0263,  0.1749, -0.0211,  0.1060,  0.0759, -0.0849, -0.0767,\n",
      "           0.0136, -0.1742,  0.1738, -0.0050,  0.1193, -0.0771, -0.0547,\n",
      "           0.0659,  0.0710, -0.1275,  0.0220,  0.1106,  0.0700, -0.0235,\n",
      "          -0.0480, -0.0961,  0.0881,  0.1748, -0.1126, -0.0427,  0.0136,\n",
      "          -0.1110, -0.0370,  0.1853, -0.0079, -0.0774,  0.0293, -0.0550,\n",
      "          -0.0099,  0.0685,  0.0641, -0.2150, -0.1126,  0.0569, -0.0723,\n",
      "          -0.0967,  0.1136, -0.1829,  0.0915, -0.0236,  0.1670, -0.0198,\n",
      "           0.1120, -0.0653, -0.1496, -0.0530,  0.1184,  0.0018, -0.0837,\n",
      "           0.0482, -0.0344, -0.0175,  0.0836,  0.0207,  0.0744,  0.0390,\n",
      "           0.0595, -0.1654,  0.0029,  0.0848, -0.0776,  0.0886, -0.1092,\n",
      "           0.0417,  0.0463,  0.0309, -0.2037, -0.1902,  0.0765, -0.0859,\n",
      "          -0.0816, -0.0800, -0.0185, -0.0035,  0.0160, -0.1200,  0.0458,\n",
      "           0.1386,  0.0603, -0.0941, -0.1140, -0.0976,  0.0793,  0.0974,\n",
      "           0.0181, -0.1293, -0.1552, -0.0522,  0.0573,  0.0306,  0.0489,\n",
      "          -0.1149, -0.0450,  0.0693, -0.0667]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1551, -1.4822,  1.6543, -1.0097, -1.1128,  0.4005,  0.6461,\n",
      "          -1.2228, -0.9026,  0.0939, -0.2096,  0.3160,  0.1277, -0.9578,\n",
      "          -0.3087,  0.3245,  0.0000, -2.1365,  0.6083, -0.5295,  0.7694,\n",
      "           0.2828, -1.2565, -0.9731,  0.0000,  1.4266, -1.6558,  1.0545,\n",
      "           0.9847,  0.0000,  0.3069, -0.9456, -0.7692, -1.5224, -0.3684,\n",
      "           0.4844, -0.9884,  0.0000,  0.3283,  0.6285,  0.6073,  0.0000,\n",
      "           0.3730,  1.2540, -1.7958,  1.9479, -1.4978, -0.4431, -0.2787,\n",
      "           0.0000,  0.8653,  0.0373,  0.0000, -1.0045, -0.2960, -0.8050,\n",
      "          -1.8696,  0.5098,  1.5735,  2.0582, -0.8819, -0.7341,  1.9471,\n",
      "          -0.9067, -0.8595,  0.1078,  0.6391,  0.0000,  0.0215,  0.4295,\n",
      "           0.0000, -0.0285,  0.0000,  1.4253, -0.4459,  0.5581, -3.6200,\n",
      "          -0.6177,  0.0000, -0.3113,  0.8703,  1.3128,  0.8813,  0.0000,\n",
      "           0.6942,  0.6928,  0.0460, -2.9903,  0.8149, -0.0185, -1.4909,\n",
      "           0.3247, -1.2890,  2.3926,  1.8843,  0.2151, -1.1099,  1.0777,\n",
      "           1.5510, -2.1250,  0.0146, -0.6643,  0.0000, -1.8823,  0.4072,\n",
      "           0.0000, -1.9888, -0.9152,  0.4128,  1.8168, -1.4327,  0.0000,\n",
      "           0.0000,  1.3009, -0.1469, -0.1100,  0.3373,  0.0000,  0.8517,\n",
      "          -1.2945, -1.3468, -0.0996,  0.8780,  0.0000,  0.2248,  0.0000,\n",
      "          -0.2019, -1.0699,  0.1249, -0.4280, -1.2474,  2.3283,  1.4194,\n",
      "           0.3274, -0.0088, -0.6387, -0.0633, -0.5999, -0.4515,  0.0000,\n",
      "           0.5454, -1.1803, -2.2954, -0.8861,  0.2164, -0.1881,  0.9174,\n",
      "          -0.0827,  1.5431, -0.7185,  0.3218, -1.3513,  1.8151, -1.9313,\n",
      "           0.5129, -0.3342, -0.2284, -0.7582,  0.9341, -0.0177,  0.2298,\n",
      "          -1.1454,  2.2620, -1.7650, -0.3903, -0.6925,  0.5300,  2.1362,\n",
      "          -1.6405, -2.7424,  1.2549, -2.0859, -0.0065,  0.0000, -0.9213,\n",
      "          -0.7988,  0.0000, -0.4307,  0.1184, -1.5139,  0.1504, -0.4528,\n",
      "           0.1997,  0.9703,  0.4843, -0.0759,  0.0000, -0.2145,  0.4040,\n",
      "          -1.4627,  1.0720,  0.6062,  0.5037,  0.0000,  0.7253, -0.0426,\n",
      "           0.0000,  0.0420,  0.0000, -0.2758,  0.1194, -0.2978,  0.2825,\n",
      "           0.0000, -0.0092, -0.7149,  0.6958,  0.0000, -0.7502,  1.8923,\n",
      "           0.0000,  0.1562,  1.5049,  0.1014, -0.5909, -0.0230, -0.1428,\n",
      "          -1.3820,  0.4080,  0.6379, -0.6886,  1.8594,  0.6064,  0.4725,\n",
      "           0.0000,  1.5297, -0.3651, -0.2608,  0.8417, -0.2545,  0.7764,\n",
      "          -0.5520,  1.2383,  0.0931,  2.0765,  0.5546, -1.7045,  2.7791,\n",
      "          -1.4958,  1.8027, -0.8497,  0.2565, -1.0501, -0.8546,  0.1356,\n",
      "          -1.7794,  0.3818,  0.0000,  0.5689,  0.5474, -1.7500,  0.3684,\n",
      "           0.1555,  1.5691, -2.7265,  0.4074]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0421, 0.1314, 0.0899, 0.0626, 0.1397, 0.2342, 0.0497, 0.0666, 0.1224,\n",
      "         0.0615]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0348,  0.0731,  ..., -0.1115, -0.0112, -0.4874],\n",
      "        [ 0.0528,  0.1140, -0.1213,  ..., -0.1182,  0.3371, -0.4386],\n",
      "        [ 0.0333, -0.0054, -0.0697,  ...,  0.2746,  0.0888, -0.3522],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1556,  0.0975, -0.1373, -0.1285,  0.0459, -0.0709, -0.0917,\n",
      "          -0.1304, -0.0205,  0.0055, -0.0151, -0.1375, -0.0616, -0.1226,\n",
      "           0.0532,  0.1159,  0.0936,  0.0385, -0.2689,  0.1852, -0.1806,\n",
      "          -0.0711,  0.0358,  0.0035, -0.1509, -0.1500,  0.0579, -0.1210,\n",
      "          -0.0129, -0.0335,  0.1609, -0.1121, -0.1439, -0.0311, -0.0303,\n",
      "          -0.1118, -0.1262, -0.0562, -0.0269, -0.0298,  0.1138,  0.0384,\n",
      "          -0.1033, -0.0168,  0.1072,  0.0184, -0.1112, -0.1041,  0.0470,\n",
      "          -0.0508, -0.0613, -0.1779, -0.0630,  0.0072,  0.0052,  0.0126,\n",
      "           0.0824,  0.1353,  0.1968,  0.0989,  0.0893, -0.0573, -0.1316,\n",
      "          -0.0288, -0.0189,  0.0704, -0.0318,  0.1850, -0.0638,  0.0605,\n",
      "          -0.0187,  0.1704,  0.0811,  0.0678, -0.0472,  0.1859,  0.0538,\n",
      "           0.0787, -0.0654,  0.0893, -0.1509, -0.0373, -0.1697,  0.0024,\n",
      "           0.0361,  0.0300,  0.0758,  0.0891,  0.1739,  0.1005,  0.0161,\n",
      "           0.0526,  0.0092, -0.0105,  0.0493,  0.0337,  0.0078,  0.2135,\n",
      "          -0.0522,  0.1087,  0.0359,  0.1253,  0.0797,  0.1036,  0.0272,\n",
      "           0.0969, -0.0242,  0.1136, -0.0154,  0.0674,  0.0121, -0.0023,\n",
      "          -0.0291, -0.1210, -0.0346,  0.0210,  0.1555, -0.0687, -0.2504,\n",
      "          -0.1740,  0.0011, -0.1306, -0.0812,  0.0891, -0.0342, -0.0437,\n",
      "           0.1123, -0.0038,  0.1478, -0.0015, -0.0031, -0.1318,  0.1682,\n",
      "           0.1089,  0.0039,  0.0742,  0.2314,  0.0650, -0.0839,  0.0951,\n",
      "           0.0128,  0.0706, -0.0406,  0.0777,  0.1291, -0.1131,  0.0981,\n",
      "           0.1764,  0.0856,  0.1775, -0.1924,  0.0032, -0.0295,  0.0005,\n",
      "          -0.0039,  0.1959, -0.0375,  0.1362,  0.0866, -0.0932, -0.0823,\n",
      "           0.0501, -0.2180,  0.1949, -0.0367,  0.1602, -0.0895, -0.0623,\n",
      "           0.0785,  0.0589, -0.1300,  0.0433,  0.1050,  0.1192, -0.0087,\n",
      "          -0.0397, -0.1217,  0.1083,  0.1945, -0.1497, -0.0568,  0.0450,\n",
      "          -0.1539, -0.0648,  0.2419, -0.0412, -0.0871,  0.0238, -0.0786,\n",
      "           0.0166,  0.1032,  0.0639, -0.2694, -0.1381,  0.0806, -0.0667,\n",
      "          -0.1166,  0.1802, -0.2406,  0.1228, -0.0279,  0.2069, -0.0063,\n",
      "           0.1295, -0.1146, -0.1792, -0.0746,  0.1055,  0.0114, -0.0475,\n",
      "           0.0783, -0.0116, -0.0111,  0.0640,  0.0433,  0.1072,  0.0804,\n",
      "           0.0496, -0.1853, -0.0308,  0.0631, -0.0777,  0.0951, -0.1545,\n",
      "           0.0293,  0.0173,  0.0186, -0.2705, -0.2084,  0.1030, -0.1190,\n",
      "          -0.1076, -0.0950,  0.0213,  0.0140,  0.0419, -0.1442,  0.0268,\n",
      "           0.1559,  0.0713, -0.1180, -0.1414, -0.1186,  0.0991,  0.1227,\n",
      "           0.0387, -0.1011, -0.1850, -0.0809,  0.0835,  0.0134,  0.0759,\n",
      "          -0.1192, -0.0496,  0.0967, -0.1108]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1248, -0.3707, -1.9359,  1.3419,  0.1083,  0.1241, -0.6882,\n",
      "          -0.1786, -1.8068, -0.7762, -1.4822, -0.3090, -0.6028,  1.6916,\n",
      "          -0.1451, -0.1255, -1.8148, -0.7161,  1.3280, -0.3128,  0.9630,\n",
      "           1.0073, -0.0428, -0.3418, -1.1282, -0.8204,  0.2746, -0.9491,\n",
      "           0.3632,  2.2333,  0.1384,  0.9369, -0.3392, -1.7037,  0.1841,\n",
      "          -0.2828,  0.5669, -0.3878, -0.3375,  0.0000,  0.0000, -2.0180,\n",
      "          -0.4084,  0.0000,  0.5772, -0.6361,  0.8399, -0.3721, -1.4907,\n",
      "          -0.9642,  0.8641, -1.5650,  0.3980,  0.5435,  0.1709,  0.5033,\n",
      "           0.4277,  0.0000, -1.0139, -1.6083,  0.0000,  0.3917,  0.9602,\n",
      "           0.4263,  0.8474,  0.0000,  0.4892,  0.3939,  1.0133,  1.0950,\n",
      "          -1.1825,  0.0000, -2.2647,  0.0783,  1.6002,  0.0000, -0.5928,\n",
      "           0.2456, -0.5500,  0.0271, -2.3358,  0.9360,  1.5187,  0.5053,\n",
      "          -0.7480,  0.0000, -1.2479, -0.9401,  0.1358,  1.2144,  1.3714,\n",
      "           1.6503,  0.0000,  0.0000, -0.1413,  0.0000, -0.1941, -0.5736,\n",
      "           0.4517, -0.7857,  0.0925, -1.2353,  2.0038, -1.5227,  0.4043,\n",
      "           0.0000, -2.5042,  1.7462, -2.4833, -0.2972, -0.3989,  2.9357,\n",
      "          -0.5028,  0.1500,  0.0934,  1.0654, -2.5372,  0.2834,  2.1088,\n",
      "          -0.4925,  3.7334, -0.6417,  0.0000, -1.1388, -2.4267,  2.2446,\n",
      "          -1.5986,  0.6184,  0.0829, -0.2121, -0.6737, -0.0143,  0.3366,\n",
      "          -0.3800,  0.4559, -0.4537,  0.5571, -1.2538, -0.1580,  0.2310,\n",
      "           1.0447, -0.9928,  1.3969, -0.2196,  1.3924, -1.1256,  0.7133,\n",
      "          -0.2055,  0.0616,  0.6922, -0.2327,  0.2494, -0.0080, -1.2221,\n",
      "          -0.7670,  0.0000, -1.0207,  0.1863,  0.2112,  0.2466, -1.7194,\n",
      "          -1.0825, -0.4286,  0.0650,  0.0000,  0.3907, -0.8798, -1.3897,\n",
      "           0.0000, -0.5681, -0.7541,  1.6357,  0.1038,  1.8217, -0.6390,\n",
      "          -0.2868, -0.8054, -0.9423, -1.3860, -0.5040,  0.0137,  0.0000,\n",
      "           0.3939,  1.8214,  0.0914,  0.1407,  0.0000,  0.0000, -1.3158,\n",
      "          -0.5231, -3.1703,  0.0978, -0.1174, -0.1523,  1.3631,  0.6064,\n",
      "          -0.0833, -0.5276,  1.8041,  0.6379,  0.0000, -0.6540, -0.2160,\n",
      "           0.7170, -1.0929, -0.5013,  0.8113, -0.3300, -0.0420, -1.7680,\n",
      "          -0.3098, -1.4710, -0.3065, -1.5566,  0.1766, -0.2566, -0.3588,\n",
      "           1.6116, -0.0881, -1.0716, -0.9378, -1.1934, -1.3430, -0.8289,\n",
      "          -0.6347,  0.0560,  0.0000, -1.0190, -1.9223, -0.1253, -1.2628,\n",
      "           0.1968,  2.0410, -0.3064,  1.9939,  2.5505,  0.5957,  0.0000,\n",
      "          -1.6447,  0.1768,  2.2439, -0.6507, -0.6549,  0.0000, -0.1637,\n",
      "           0.7700,  0.0491,  0.5938, -0.4880, -1.1813,  0.0000,  0.1084,\n",
      "          -1.2285,  0.3958, -1.6534,  0.2299]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1604, 0.0992, 0.0301, 0.1158, 0.1040, 0.1189, 0.1342, 0.0767, 0.0655,\n",
      "         0.0953]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0348,  0.0731,  ..., -0.1115, -0.0112, -0.4874],\n",
      "        [ 0.0528,  0.1140, -0.1213,  ..., -0.1182,  0.3371, -0.4386],\n",
      "        [ 0.0333, -0.0054, -0.0697,  ...,  0.2746,  0.0888, -0.3522],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.9212e-01,  7.4266e-02, -1.1133e-01, -1.3011e-01,  7.1171e-02,\n",
      "          -1.8006e-02, -1.4166e-01, -1.1556e-01, -5.4605e-02, -3.0290e-04,\n",
      "          -2.1692e-02, -1.3009e-01, -5.7758e-02, -6.9269e-02,  1.0475e-01,\n",
      "           1.3197e-01,  7.7207e-02,  7.5871e-02, -2.5735e-01,  1.2017e-01,\n",
      "          -1.4754e-01, -7.8296e-02, -3.3657e-03, -1.8432e-02, -1.6028e-01,\n",
      "          -9.6737e-02,  6.2488e-02, -9.5189e-02, -6.9503e-03, -1.1271e-02,\n",
      "           1.6467e-01, -1.2713e-01, -1.1029e-01, -6.1267e-02, -7.9879e-02,\n",
      "          -1.3987e-01, -7.9447e-02, -6.0422e-02,  3.9478e-02, -2.6571e-02,\n",
      "           1.1563e-01,  4.5721e-02, -1.1449e-01, -6.1392e-02,  1.1238e-01,\n",
      "           2.0567e-02, -5.3812e-02, -5.1304e-02,  6.7511e-02, -7.3782e-02,\n",
      "          -2.1724e-02, -2.1431e-01, -6.0231e-02, -3.7229e-02, -4.6296e-02,\n",
      "           3.5066e-03,  3.1343e-02,  1.4679e-01,  1.7223e-01,  8.4418e-02,\n",
      "           9.8227e-02, -8.6137e-02, -1.7386e-01,  4.1540e-02, -1.2754e-02,\n",
      "           6.5060e-02, -6.0542e-02,  1.6709e-01, -1.3590e-01,  9.9146e-02,\n",
      "          -2.0709e-02,  2.1735e-01,  7.3407e-02,  2.5350e-03, -7.4658e-02,\n",
      "           2.3182e-01,  6.8599e-02,  5.6315e-02, -7.3428e-02,  1.0439e-01,\n",
      "          -1.3972e-01,  8.2401e-03, -1.5737e-01,  4.2690e-02,  5.2036e-02,\n",
      "           4.8957e-02,  8.6332e-02,  9.9494e-02,  1.6113e-01,  9.7186e-02,\n",
      "           5.8744e-03,  1.0819e-01, -3.7942e-02, -1.0848e-02,  2.2921e-02,\n",
      "           3.9605e-02,  6.9514e-02,  2.1028e-01, -2.5770e-02,  9.2807e-02,\n",
      "           7.8269e-02,  1.1451e-01,  2.5390e-02,  1.4246e-01,  5.6531e-02,\n",
      "           9.9792e-02, -2.7560e-02,  1.1549e-01, -5.5067e-02,  1.1358e-01,\n",
      "          -2.8236e-02,  5.2829e-03, -8.3211e-02, -1.2988e-01, -2.2954e-02,\n",
      "           3.5550e-02,  1.6157e-01, -6.7504e-02, -2.4589e-01, -1.6992e-01,\n",
      "           1.7977e-02, -1.5062e-01, -1.0622e-01,  9.3627e-02, -1.0040e-01,\n",
      "          -1.6282e-02,  5.8538e-02, -1.9407e-02,  1.9338e-01,  1.0724e-02,\n",
      "           5.9846e-03, -1.1116e-01,  1.3326e-01,  1.3299e-01,  6.6489e-02,\n",
      "           3.9829e-02,  2.0762e-01,  1.1039e-01,  5.2462e-03,  8.7562e-02,\n",
      "          -3.7271e-02,  1.1464e-01, -6.7984e-02,  5.3998e-02,  6.1402e-02,\n",
      "          -6.9075e-02,  1.0518e-01,  1.8441e-01,  6.5963e-02,  1.7565e-01,\n",
      "          -1.9981e-01,  9.4089e-03, -2.0185e-02, -6.9733e-03,  1.1522e-02,\n",
      "           2.0760e-01, -1.0516e-02,  1.6027e-01,  3.9906e-02, -7.1120e-02,\n",
      "          -1.2178e-01,  7.4480e-02, -2.2541e-01,  1.9725e-01, -1.0027e-01,\n",
      "           1.3148e-01, -7.1071e-02, -1.3892e-02, -5.1659e-03,  2.3913e-02,\n",
      "          -9.6665e-02,  7.6601e-02,  1.1065e-01,  1.5813e-01,  3.4802e-02,\n",
      "          -6.5834e-02, -4.8558e-02,  8.3616e-02,  1.9882e-01, -8.4034e-02,\n",
      "          -5.1042e-02,  4.9291e-02, -1.5131e-01, -4.4035e-02,  2.3477e-01,\n",
      "          -4.8921e-02, -5.2758e-02, -1.8119e-02, -1.1046e-01,  2.5856e-02,\n",
      "           1.0481e-01,  3.3595e-02, -2.6425e-01, -1.2013e-01,  8.0169e-03,\n",
      "          -4.6997e-02, -1.0500e-01,  1.5455e-01, -1.8095e-01,  1.0867e-01,\n",
      "          -5.5599e-03,  1.7531e-01,  2.3144e-02,  1.1794e-01, -1.7411e-01,\n",
      "          -1.6956e-01, -1.0194e-01,  1.0122e-01,  3.1662e-03,  3.1311e-03,\n",
      "           3.5085e-02, -2.3102e-02, -2.7041e-02,  4.3609e-02,  4.2978e-02,\n",
      "           6.0964e-02,  7.9558e-02,  9.3079e-02, -2.0432e-01, -8.4331e-02,\n",
      "           1.0503e-01, -4.6728e-02,  1.4227e-01, -1.7141e-01, -1.1311e-02,\n",
      "           4.8418e-02,  1.8146e-04, -2.3563e-01, -2.5223e-01,  8.4551e-02,\n",
      "          -5.5604e-02, -1.1422e-01, -1.1616e-01,  6.3055e-02,  1.8641e-02,\n",
      "          -3.2141e-03, -1.8139e-01,  3.4967e-02,  1.4882e-01,  7.0117e-02,\n",
      "          -6.6120e-02, -1.8273e-01, -1.2253e-01,  1.4870e-01,  8.9915e-02,\n",
      "           4.2194e-02, -5.7613e-02, -2.1766e-01, -6.1690e-02,  4.1842e-03,\n",
      "           2.5187e-02,  7.6942e-02, -9.3142e-02, -8.0506e-02,  9.9857e-02,\n",
      "          -1.4901e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.6867, -0.7068,  0.9419, -1.9449, -0.4718, -1.5977,  0.0000,\n",
      "           0.1497, -0.2323,  0.1970,  0.5950,  0.3383, -1.4473, -0.1099,\n",
      "           0.1615,  0.7464,  0.3932,  0.0000, -0.1847,  0.5524,  0.0000,\n",
      "          -2.1322, -2.5658, -1.4684, -1.1574,  0.9309,  0.8501,  2.0635,\n",
      "           0.5035,  1.7785,  1.8048, -0.6952,  0.0947,  0.1754,  0.3821,\n",
      "           0.1218, -0.2326,  0.2447,  1.6903,  2.0407, -0.5014, -0.5109,\n",
      "          -0.3384,  0.1867,  1.9460,  0.0000, -1.3544, -0.6582,  0.2090,\n",
      "           0.2206,  0.0000, -0.4071,  0.0544, -1.0081, -0.0542,  2.0198,\n",
      "          -0.7127,  0.4861, -0.1363, -1.2105,  0.4227, -1.3350,  0.0000,\n",
      "          -2.2817,  0.6347,  0.7999,  1.0536,  0.2432, -0.5559, -0.4276,\n",
      "           0.0000,  0.8498,  0.0000, -0.4722, -0.9405,  1.1688,  0.8570,\n",
      "          -0.8299,  1.1914,  0.4706,  2.2731,  1.4673,  0.0346,  1.1938,\n",
      "          -1.5246,  0.1060, -0.6723,  0.3097, -2.8618, -0.2187, -0.3276,\n",
      "          -0.3601,  0.0000,  0.2188,  0.8364,  0.0000, -0.4673,  1.1006,\n",
      "          -0.9367,  0.2231, -0.5090, -1.2021,  0.0000,  0.6541, -0.4680,\n",
      "           1.1877, -0.2857, -0.5092,  0.9255,  2.6184,  1.0166,  0.4314,\n",
      "          -0.3999,  1.3383,  0.6695,  0.0000,  0.7877,  0.0000, -0.7688,\n",
      "          -0.1283,  0.1919, -1.2607, -1.1314, -1.1665,  0.4456,  0.5439,\n",
      "          -1.6481,  0.0000,  0.8721, -0.2565, -0.3055,  0.0000, -1.2061,\n",
      "          -2.2159,  1.7604, -2.3875, -0.7499, -0.3657,  0.0601,  0.4558,\n",
      "           0.6567, -1.7765,  0.5589,  1.2275,  0.0000,  0.0000,  0.0000,\n",
      "          -0.6286, -1.6717,  0.0659, -2.5705,  0.4683,  2.0572, -0.3578,\n",
      "           2.1516,  0.2978,  0.1781,  0.2791,  0.5279, -0.3418, -0.5861,\n",
      "          -0.6196,  0.1947,  1.3339, -0.2813, -0.4439, -0.0499, -0.2582,\n",
      "          -0.4237, -1.6258,  2.0694,  0.1757, -1.2647, -0.0668, -0.4004,\n",
      "           0.0209, -0.8010, -0.7268, -1.2593, -0.3211,  1.2586, -1.5836,\n",
      "           0.6565,  0.2176,  2.7368, -0.9107,  1.5001, -0.5509,  1.0983,\n",
      "          -0.6308, -0.4738,  0.1812,  0.4104,  0.3578,  2.0076,  0.6826,\n",
      "           0.2386, -0.2549, -1.8559,  0.2146, -1.0998, -0.1333, -0.1133,\n",
      "           1.5368, -1.6779,  0.5394,  0.0000, -0.7977, -0.2387, -1.4953,\n",
      "           0.5718, -1.6107,  0.4413,  0.0692,  0.4843,  0.3487, -1.1292,\n",
      "          -0.5587,  0.3719,  0.4950,  0.0000, -0.6525, -0.8378,  1.3495,\n",
      "          -1.0277,  2.1296, -1.3973,  0.2774,  0.4860,  1.3875, -1.1124,\n",
      "          -0.8310,  1.5084,  0.2258,  0.7026,  1.0385, -1.0461,  0.3912,\n",
      "           0.0000, -1.1786, -0.8645,  0.0000, -0.4381,  0.0000,  0.0000,\n",
      "          -1.4585,  0.3423,  0.0000, -1.9409, -1.7757,  0.9706,  0.8948,\n",
      "           1.3877, -0.1040,  0.3676,  0.4516]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0708, 0.0833, 0.0927, 0.0480, 0.1971, 0.1365, 0.0917, 0.0727, 0.1100,\n",
      "         0.0972]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0348,  0.0731,  ..., -0.1115, -0.0112, -0.4874],\n",
      "        [ 0.0528,  0.1140, -0.1213,  ..., -0.1182,  0.3371, -0.4386],\n",
      "        [ 0.0333, -0.0054, -0.0697,  ...,  0.2746,  0.0888, -0.3522],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1982,  0.1224, -0.1658, -0.1183,  0.0143, -0.0968, -0.0733,\n",
      "          -0.1703, -0.0105, -0.0180,  0.0047, -0.1595, -0.0812, -0.1116,\n",
      "           0.1029,  0.0978,  0.1050,  0.0555, -0.2857,  0.1688, -0.1967,\n",
      "          -0.1124,  0.0670,  0.0349, -0.1901, -0.1785,  0.0335, -0.1415,\n",
      "          -0.0482, -0.0419,  0.1793, -0.1410, -0.1605, -0.0689, -0.0364,\n",
      "          -0.0907, -0.1411, -0.0745, -0.0568, -0.0099,  0.1033,  0.0315,\n",
      "          -0.1346, -0.0142,  0.1492,  0.0464, -0.1198, -0.1338,  0.0753,\n",
      "          -0.0469, -0.0977, -0.1846, -0.1118,  0.0018,  0.0177,  0.0158,\n",
      "           0.0692,  0.1610,  0.2093,  0.1398,  0.0780, -0.0704, -0.1721,\n",
      "          -0.0014, -0.0379,  0.0582, -0.0463,  0.2064, -0.0914,  0.0449,\n",
      "          -0.0231,  0.1972,  0.0626,  0.0818, -0.0914,  0.1842,  0.1040,\n",
      "           0.0970, -0.0755,  0.1174, -0.1817, -0.0913, -0.2112,  0.0054,\n",
      "           0.0323,  0.0627,  0.0736,  0.0976,  0.1964,  0.0679,  0.0327,\n",
      "           0.0715,  0.0228,  0.0056,  0.0370,  0.0472,  0.0516,  0.2479,\n",
      "          -0.0716,  0.1477, -0.0074,  0.1329,  0.0884,  0.1356, -0.0083,\n",
      "           0.0896,  0.0044,  0.1467, -0.0452,  0.0833,  0.0372, -0.0169,\n",
      "          -0.0148, -0.1823, -0.0789,  0.0078,  0.1605, -0.0831, -0.2596,\n",
      "          -0.1886,  0.0200, -0.1670, -0.1267,  0.1026, -0.0705, -0.0433,\n",
      "           0.0929, -0.0244,  0.1901, -0.0382,  0.0377, -0.1855,  0.1957,\n",
      "           0.1435, -0.0144,  0.0927,  0.2676,  0.0694, -0.1157,  0.1101,\n",
      "          -0.0095,  0.0981, -0.0776,  0.1265,  0.1379, -0.1039,  0.1051,\n",
      "           0.2131,  0.0883,  0.1999, -0.2335,  0.0073, -0.0317,  0.0401,\n",
      "           0.0185,  0.2303, -0.0322,  0.1479,  0.1211, -0.1243, -0.1028,\n",
      "           0.0047, -0.2415,  0.2337, -0.0028,  0.1755, -0.0987, -0.0695,\n",
      "           0.1152,  0.1245, -0.1628,  0.0410,  0.1500,  0.0880, -0.0254,\n",
      "          -0.0585, -0.1262,  0.1213,  0.2368, -0.1385, -0.0516,  0.0165,\n",
      "          -0.1624, -0.0497,  0.2483,  0.0041, -0.1350,  0.0505, -0.0490,\n",
      "          -0.0135,  0.0887,  0.0869, -0.3012, -0.1612,  0.0917, -0.0877,\n",
      "          -0.1474,  0.1592, -0.2491,  0.1409, -0.0339,  0.2251, -0.0203,\n",
      "           0.1643, -0.0949, -0.1969, -0.0815,  0.1517, -0.0079, -0.0740,\n",
      "           0.0977, -0.0533, -0.0285,  0.1064,  0.0247,  0.1166,  0.0161,\n",
      "           0.0814, -0.2240,  0.0202,  0.1170, -0.1122,  0.1338, -0.1692,\n",
      "           0.0553,  0.0588,  0.0605, -0.2734, -0.2578,  0.1230, -0.1453,\n",
      "          -0.1121, -0.0971, -0.0262, -0.0075,  0.0232, -0.1713,  0.0517,\n",
      "           0.1738,  0.0741, -0.1188, -0.1664, -0.1533,  0.1013,  0.1319,\n",
      "           0.0428, -0.1518, -0.2160, -0.0443,  0.1147,  0.0369,  0.0656,\n",
      "          -0.1625, -0.0575,  0.0801, -0.0958]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7269e-01, -4.3079e-01,  3.1526e-01, -1.0852e+00, -1.1729e+00,\n",
      "           7.4163e-01, -1.9146e+00,  1.3513e+00,  1.9014e-01,  6.1739e-01,\n",
      "           0.0000e+00,  6.0260e-01,  0.0000e+00, -9.1655e-01, -3.1839e+00,\n",
      "          -6.8280e-02,  0.0000e+00, -9.4353e-01,  1.3603e+00, -1.4357e+00,\n",
      "          -1.4039e-01,  0.0000e+00, -1.1199e+00, -2.5959e+00, -7.5949e-02,\n",
      "           1.3916e+00, -6.1993e-01,  1.9981e+00,  1.2773e-01,  5.5521e-01,\n",
      "           9.1581e-01, -3.7963e-03,  2.2244e-01,  2.0169e+00, -6.3564e-02,\n",
      "          -1.4086e+00, -1.1159e-01, -8.1742e-01,  3.1518e-01,  8.6025e-02,\n",
      "           8.6339e-01, -8.9931e-01,  1.0090e+00, -1.5641e+00,  0.0000e+00,\n",
      "           0.0000e+00,  7.0644e-01, -6.0237e-01,  0.0000e+00,  1.1172e+00,\n",
      "          -1.3233e+00,  2.6782e+00,  6.6694e-01, -8.4703e-01,  2.2803e-01,\n",
      "          -3.1014e-01, -1.4340e+00, -9.6328e-02,  1.2759e+00,  2.1821e+00,\n",
      "          -1.0066e+00,  3.5835e-02, -2.8015e-01,  2.6571e-01, -6.3252e-02,\n",
      "           3.9354e-01,  5.7811e-01,  1.1654e+00,  1.5812e+00, -1.4154e+00,\n",
      "           4.2735e-01,  2.9637e-01, -3.1069e-02, -7.9817e-01, -2.1415e-01,\n",
      "           1.3943e-01,  5.2592e-01,  1.3992e+00,  1.0274e+00, -7.9428e-01,\n",
      "           7.5849e-01, -1.0049e+00,  0.0000e+00,  1.0589e+00, -1.2156e+00,\n",
      "          -1.1329e-01, -1.1082e+00,  0.0000e+00, -9.4491e-01, -1.9015e+00,\n",
      "           5.2922e-01,  9.8742e-01,  1.7021e+00,  9.4422e-01,  6.0801e-01,\n",
      "          -1.5935e-02,  0.0000e+00, -1.1760e+00,  1.3725e+00,  2.4481e+00,\n",
      "           2.4347e-01,  4.4173e-02, -4.6662e-01, -9.8937e-01,  1.6411e+00,\n",
      "           0.0000e+00,  3.0301e+00,  6.2074e-01, -1.0194e-01, -1.2357e+00,\n",
      "           1.8998e-01, -5.0339e-01,  0.0000e+00,  7.1257e-01,  0.0000e+00,\n",
      "           0.0000e+00,  4.0378e-01,  2.2352e-01, -2.3272e+00,  2.9226e-02,\n",
      "          -8.1470e-01, -1.4117e+00, -1.8385e+00,  6.0323e-01, -9.5715e-01,\n",
      "          -2.0097e-01,  4.0232e-02,  2.1509e+00,  1.3966e+00, -2.0883e+00,\n",
      "          -9.2629e-01,  4.4993e-01, -1.1682e+00,  4.2548e-01, -4.6838e-01,\n",
      "          -7.4633e-01, -1.0649e+00, -9.7543e-01, -1.9467e-02,  2.3980e+00,\n",
      "           0.0000e+00, -1.1218e+00,  1.6919e+00, -1.4040e-01, -6.7010e-01,\n",
      "           3.3206e-02,  7.5983e-01,  0.0000e+00, -1.0339e+00, -9.5306e-02,\n",
      "           1.5601e+00,  5.8681e-01,  0.0000e+00,  6.5782e-01,  1.8415e+00,\n",
      "          -2.5278e-01, -2.1790e-01,  6.2398e-01, -2.3638e+00,  1.0560e+00,\n",
      "           3.0289e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.1934e-02,\n",
      "           1.6826e+00,  1.8528e+00,  2.7169e-01,  0.0000e+00, -7.1304e-01,\n",
      "          -1.2243e+00, -1.0942e+00, -2.5910e+00,  0.0000e+00, -3.0608e+00,\n",
      "          -2.8738e-01,  4.9766e-01,  0.0000e+00,  3.1706e-01, -7.9310e-01,\n",
      "           2.7255e-01,  0.0000e+00,  1.0583e+00,  8.3903e-01, -4.0240e-01,\n",
      "           0.0000e+00,  5.9882e-01,  3.5979e-01,  8.4326e-01, -1.8311e+00,\n",
      "           1.3637e+00,  2.1601e+00,  3.3588e-01, -1.0157e+00, -1.1729e+00,\n",
      "          -2.2162e+00,  0.0000e+00,  2.1534e+00,  0.0000e+00,  2.3837e+00,\n",
      "           3.2560e-02, -5.0159e-01, -1.2770e+00, -5.4306e-01, -4.0765e-01,\n",
      "          -1.4478e+00,  0.0000e+00,  0.0000e+00,  8.2955e-01, -1.5605e+00,\n",
      "           6.3714e-01,  0.0000e+00,  2.3984e+00,  5.5277e-02,  1.8937e+00,\n",
      "           1.3090e+00,  5.8029e-01,  0.0000e+00,  1.5503e+00,  0.0000e+00,\n",
      "          -2.2742e-01,  1.7343e+00,  2.7650e-01, -1.5524e+00,  9.2292e-01,\n",
      "          -1.2244e+00, -8.4891e-01, -1.8025e+00, -7.3407e-04,  3.7323e-01,\n",
      "          -1.5739e+00, -1.2391e-01,  9.6632e-01, -1.7376e+00,  0.0000e+00,\n",
      "          -1.4406e+00,  6.3400e-01, -1.7230e+00,  9.8027e-01, -1.7171e+00,\n",
      "           0.0000e+00, -2.7303e-01, -2.5975e+00,  1.2391e+00, -1.2282e+00,\n",
      "           1.8862e+00, -5.0851e-01,  5.4287e-01, -2.6128e-01, -1.0224e+00,\n",
      "           1.3339e+00,  3.1132e-01, -5.0942e-02, -2.2877e-01, -1.6131e+00,\n",
      "           1.8070e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0318, 0.0896, 0.1791, 0.0782, 0.1613, 0.1632, 0.0919, 0.0591, 0.0823,\n",
      "         0.0636]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0348,  0.0731,  ..., -0.1115, -0.0112, -0.4874],\n",
      "        [ 0.0528,  0.1140, -0.1213,  ..., -0.1182,  0.3371, -0.4386],\n",
      "        [ 0.0333, -0.0054, -0.0697,  ...,  0.2746,  0.0888, -0.3522],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1757,  0.1062, -0.1592, -0.1655,  0.0863, -0.0858, -0.1041,\n",
      "          -0.1792, -0.0012, -0.0115, -0.0043, -0.1425, -0.0683, -0.1474,\n",
      "           0.0686,  0.1325,  0.1091,  0.0304, -0.3218,  0.2336, -0.2196,\n",
      "          -0.0939,  0.1030, -0.0126, -0.1888, -0.1696,  0.0992, -0.1622,\n",
      "          -0.0148, -0.0214,  0.2086, -0.0964, -0.1795, -0.0332, -0.0172,\n",
      "          -0.1132, -0.1667, -0.0715, -0.0369, -0.0030,  0.1257,  0.0656,\n",
      "          -0.1208, -0.0531,  0.1439,  0.0431, -0.1338, -0.1286,  0.0799,\n",
      "          -0.0485, -0.0894, -0.2085, -0.1101, -0.0024,  0.0663,  0.0223,\n",
      "           0.1216,  0.1570,  0.2409,  0.1217,  0.1101, -0.0642, -0.1424,\n",
      "          -0.0313, -0.0289,  0.0756, -0.0391,  0.2431, -0.0594,  0.0408,\n",
      "          -0.0313,  0.1889,  0.1139,  0.0980, -0.0509,  0.1980,  0.0976,\n",
      "           0.0992, -0.0550,  0.1242, -0.1988, -0.0261, -0.2369,  0.0072,\n",
      "           0.0383,  0.0252,  0.1004,  0.1236,  0.2157,  0.1436,  0.0266,\n",
      "           0.0582,  0.0666, -0.0155,  0.0774,  0.0526,  0.0114,  0.2573,\n",
      "          -0.0439,  0.1370,  0.0374,  0.1765,  0.1118,  0.1403,  0.0586,\n",
      "           0.1143, -0.0257,  0.1586, -0.0276,  0.0438,  0.0279,  0.0034,\n",
      "          -0.0317, -0.1830, -0.0526, -0.0113,  0.1975, -0.0765, -0.3148,\n",
      "          -0.2207, -0.0164, -0.1600, -0.1059,  0.1226, -0.0250, -0.0471,\n",
      "           0.1499, -0.0044,  0.1619, -0.0472,  0.0034, -0.1806,  0.1744,\n",
      "           0.1417, -0.0136,  0.0678,  0.2960,  0.0681, -0.1329,  0.1162,\n",
      "           0.0217,  0.0535, -0.0582,  0.1391,  0.1738, -0.1595,  0.1399,\n",
      "           0.2274,  0.1139,  0.2172, -0.2347,  0.0058, -0.0547,  0.0299,\n",
      "          -0.0122,  0.2430, -0.0373,  0.1477,  0.1212, -0.1189, -0.0793,\n",
      "           0.0638, -0.2378,  0.2358,  0.0156,  0.1878, -0.1077, -0.0844,\n",
      "           0.0923,  0.0881, -0.1873,  0.0110,  0.1473,  0.1147, -0.0186,\n",
      "          -0.0456, -0.1723,  0.1291,  0.2405, -0.1886, -0.0149,  0.0758,\n",
      "          -0.1466, -0.0879,  0.2873, -0.0652, -0.0803,  0.0251, -0.1207,\n",
      "           0.0228,  0.1317,  0.0903, -0.3257, -0.1696,  0.1114, -0.0896,\n",
      "          -0.1557,  0.2255, -0.2999,  0.1349, -0.0445,  0.2708, -0.0208,\n",
      "           0.1491, -0.1065, -0.2314, -0.0804,  0.1445,  0.0165, -0.1432,\n",
      "           0.0892, -0.0115, -0.0182,  0.1124,  0.0624,  0.0980,  0.1165,\n",
      "           0.0688, -0.2470, -0.0216,  0.0907, -0.1133,  0.0939, -0.1618,\n",
      "           0.0430,  0.0199,  0.0236, -0.3260, -0.2567,  0.0777, -0.1135,\n",
      "          -0.1190, -0.1123,  0.0189,  0.0017,  0.0474, -0.1504,  0.0867,\n",
      "           0.1958,  0.1082, -0.1527, -0.1534, -0.1311,  0.1167,  0.1500,\n",
      "           0.0351, -0.2067, -0.2136, -0.1317,  0.1270,  0.0262,  0.0767,\n",
      "          -0.1672, -0.0290,  0.1003, -0.1204]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0857,  0.3989, -0.9672, -0.6822,  0.3765, -0.2017,  1.4650,\n",
      "          -0.0832, -3.5857,  0.9069,  0.4291,  0.0000,  2.6063, -0.6297,\n",
      "          -0.5417, -0.1580,  0.0000,  1.0952,  0.4551,  0.4362, -0.6339,\n",
      "          -0.3838,  1.6423,  1.5116,  0.7540, -0.0753, -0.1877, -0.7590,\n",
      "           1.6543,  0.8617,  1.2322,  1.2193, -1.0345, -0.0826, -1.5353,\n",
      "           1.3955,  0.2808,  0.0000,  0.1981,  1.6018, -0.4589, -1.3992,\n",
      "          -0.2683, -1.7172, -1.5254,  0.6673,  0.5412,  0.3700,  0.0000,\n",
      "           0.1437, -0.6289,  2.7539,  0.6106, -1.0300, -0.0259,  0.2029,\n",
      "           0.0000, -1.2534, -0.2365, -0.4251,  1.1017,  1.4088, -0.2039,\n",
      "          -0.5021, -2.9656,  0.5504,  1.2794, -1.2886,  0.4119,  0.5264,\n",
      "          -1.2679, -0.0305,  0.7076, -3.6432,  0.3267,  0.0000, -0.1598,\n",
      "           1.0635, -0.0586, -0.1203, -1.4007,  2.1324, -0.9252,  1.0057,\n",
      "          -0.2079,  0.4343,  1.6622, -0.9752, -0.1030, -0.5816, -2.2745,\n",
      "           1.1007, -0.6223,  0.0000,  0.4676, -1.1712,  0.0345,  0.6294,\n",
      "           1.7209, -0.7810,  2.6982,  0.0000,  1.0762,  1.4549, -0.6667,\n",
      "          -0.7626,  1.2132,  0.1275, -1.4733, -0.0129, -0.2490,  0.1345,\n",
      "           0.0000,  1.3105, -1.6543, -2.9911, -0.0562, -0.5018, -0.1932,\n",
      "           0.4447,  0.0000,  0.7027, -1.4611, -0.7265, -0.9590, -1.3098,\n",
      "           0.8982,  0.1706,  1.2861, -0.7529, -0.8232,  0.5296, -1.5838,\n",
      "           0.9843,  0.2762,  0.0000,  0.0000,  0.5732, -1.1585, -1.0110,\n",
      "          -0.3892,  0.6779, -0.7903, -0.1020, -1.6868, -0.1016, -0.5434,\n",
      "          -0.8447, -0.7556,  0.1774,  1.9995,  0.0000, -1.9316, -0.4063,\n",
      "           0.4417, -0.1945, -0.0640, -0.1288,  0.0396,  0.5378, -0.0261,\n",
      "           2.2070,  0.4812,  0.0000, -0.5279, -0.8933,  0.2818,  0.0850,\n",
      "          -0.3580, -0.4782,  0.7387, -0.0327,  0.0198,  0.0000,  1.2781,\n",
      "          -1.0995, -0.9883, -2.0785,  1.9702,  0.0864, -0.0295,  0.0351,\n",
      "           0.6719,  0.9799, -0.7470, -0.3410,  0.0000, -0.7851,  1.2103,\n",
      "           1.0127,  3.0760,  0.4946, -0.1441, -0.5951,  0.5610,  2.1663,\n",
      "          -1.1886,  0.5347,  1.8128, -0.9479, -1.6624,  0.0000,  1.2418,\n",
      "          -0.1221,  0.2319,  0.0000, -2.2937,  0.6821, -1.0752, -0.4716,\n",
      "           2.8694, -0.5734,  0.0000,  0.7935,  0.0298,  0.0000, -1.0202,\n",
      "           0.9663, -0.2460,  2.1706, -1.0832, -0.4277, -1.8446, -0.5019,\n",
      "           0.3369,  0.0000, -0.6966, -0.6282,  0.2923, -1.5794,  0.0000,\n",
      "           1.5819, -0.6145,  0.0000, -2.9809,  4.0373,  0.0000,  0.0436,\n",
      "          -1.5813, -0.2877,  0.7415,  0.0000, -0.3049, -0.8529,  0.0111,\n",
      "           0.2752,  0.2752,  0.2527,  0.2609,  0.3867,  0.0000, -0.1583,\n",
      "          -0.5543, -0.0527, -1.1474,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0406, 0.0364, 0.0707, 0.0495, 0.1199, 0.4013, 0.0382, 0.0652, 0.0517,\n",
      "         0.1265]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1120,  0.0543, -0.1148,  ..., -0.4732,  0.2047, -0.2541],\n",
      "        [-0.0408, -0.0905, -0.2784,  ..., -0.5559, -0.3632,  0.4351],\n",
      "        [-0.0779,  0.3698, -0.1817,  ..., -0.0783, -0.5377,  0.1360],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0120e-01,  1.0685e-01, -1.3375e-01,  5.1491e-02, -5.9448e-02,\n",
      "          -1.0146e-01,  5.5042e-02, -6.4951e-02, -5.4675e-02, -9.1768e-02,\n",
      "           4.8258e-02, -9.5976e-02, -6.6492e-02,  1.0313e-01,  1.3305e-01,\n",
      "          -1.3249e-02,  3.1695e-02,  8.4250e-02, -6.7862e-02, -6.1324e-02,\n",
      "          -1.0959e-01, -1.2759e-01,  3.9799e-02,  6.9918e-02, -6.3842e-02,\n",
      "          -9.4266e-02, -3.4510e-02, -8.1432e-02, -4.2599e-03, -4.7167e-03,\n",
      "           2.2994e-02, -1.3136e-01, -9.5240e-02, -2.4560e-02, -4.5229e-02,\n",
      "           4.4440e-02, -1.3964e-01, -4.7568e-02, -1.0031e-01,  3.5918e-03,\n",
      "          -7.1587e-02, -4.6410e-03, -9.4954e-02,  8.7544e-02,  1.0702e-01,\n",
      "           1.2683e-01, -3.6651e-02, -1.3317e-01,  5.5070e-02,  5.6093e-02,\n",
      "          -6.4644e-02,  3.4557e-02, -1.3240e-01,  9.5786e-02,  4.4838e-02,\n",
      "           1.3844e-02, -5.2762e-02,  3.6508e-02,  6.3378e-02,  5.2777e-02,\n",
      "           7.7431e-04, -6.7824e-02, -4.3055e-02,  5.4388e-02, -7.4754e-02,\n",
      "          -3.7101e-02,  2.7460e-02,  2.4217e-02, -1.0465e-01,  8.0732e-02,\n",
      "           9.9378e-02,  7.5935e-02, -3.4964e-02,  8.8519e-02, -1.2966e-01,\n",
      "           1.1167e-01,  1.2600e-01,  9.1091e-02,  2.0781e-02, -2.1261e-02,\n",
      "          -5.8004e-02, -6.0669e-02, -1.0376e-01, -3.4171e-03, -4.4867e-02,\n",
      "           6.5452e-02,  5.2526e-02,  3.6672e-03,  6.1937e-02, -8.2029e-02,\n",
      "          -1.5419e-02, -2.2733e-03, -3.3555e-02, -4.8344e-02, -7.9689e-02,\n",
      "           6.4668e-02,  4.6331e-02,  8.8876e-02, -6.4803e-02,  7.4220e-02,\n",
      "          -1.3016e-01, -1.5157e-02,  5.4219e-02, -6.7115e-03, -6.1159e-02,\n",
      "           4.3279e-02,  2.8441e-02,  1.0557e-01, -1.3633e-02,  8.6531e-02,\n",
      "           1.4386e-03, -3.6754e-02,  5.3741e-02, -1.2802e-01, -7.7886e-02,\n",
      "          -2.2270e-02,  1.0471e-04, -3.1281e-02, -1.2389e-01, -6.1537e-02,\n",
      "           8.1742e-03, -1.2315e-01, -1.5624e-01, -4.0085e-02, -1.1025e-01,\n",
      "          -2.6521e-02, -3.9697e-02, -1.5095e-01,  3.6980e-02, -2.6962e-02,\n",
      "           5.7486e-02, -8.7567e-02,  9.8527e-02,  1.0743e-01, -7.0127e-03,\n",
      "           6.6822e-02,  1.0973e-01,  4.3487e-02, -1.2332e-01,  8.2976e-02,\n",
      "           1.5319e-02,  1.1431e-01, -6.8024e-02,  1.5073e-01,  7.8165e-02,\n",
      "          -3.0668e-02,  1.7442e-02,  9.0966e-02,  9.2448e-02,  1.3569e-01,\n",
      "          -1.6891e-01, -1.0704e-03, -2.8478e-02,  6.1194e-02,  4.4138e-02,\n",
      "           1.6077e-01, -2.2477e-02,  4.1775e-02,  1.7409e-02, -5.0069e-02,\n",
      "           4.1694e-03, -1.3027e-01, -1.3941e-01,  1.0946e-01, -1.9905e-02,\n",
      "           3.5028e-02, -7.8614e-02, -8.2832e-02,  1.7391e-01,  7.4324e-02,\n",
      "          -7.0548e-02,  7.2823e-02,  1.2669e-01,  1.5501e-02, -8.8117e-03,\n",
      "          -1.1624e-02, -6.2539e-02,  1.2465e-01,  1.3420e-01, -4.3905e-02,\n",
      "          -1.0219e-01, -1.5366e-01, -6.3926e-02,  3.2127e-02, -4.4371e-03,\n",
      "           1.6639e-01, -1.0901e-01,  4.9585e-02,  9.5707e-03, -1.4797e-01,\n",
      "           4.5247e-02,  1.4679e-01, -1.1487e-01, -5.1133e-02,  8.6131e-02,\n",
      "          -1.1918e-01, -2.7919e-02, -6.8198e-02, -1.7280e-02,  9.4208e-02,\n",
      "          -9.6155e-02,  4.6143e-02, -5.7766e-02,  1.0275e-01,  4.6047e-02,\n",
      "           3.8537e-03, -6.0970e-03,  1.3381e-01, -4.8298e-02,  2.3201e-02,\n",
      "          -2.7471e-02, -1.3630e-01, -1.1637e-02,  5.3402e-02, -2.0242e-02,\n",
      "           7.7947e-02, -6.3871e-02,  6.9506e-02, -9.2041e-02,  1.4396e-01,\n",
      "           8.3908e-02, -1.2887e-01,  1.2934e-01, -6.6347e-02,  1.4888e-01,\n",
      "           3.4479e-02, -5.7651e-03, -2.3164e-02, -1.3177e-01,  6.2879e-02,\n",
      "          -9.0730e-02,  3.6357e-02, -2.9166e-02, -1.4530e-01, -7.2701e-02,\n",
      "          -4.5674e-02, -7.9637e-02,  9.0963e-03,  1.0164e-01, -3.4959e-02,\n",
      "          -6.8803e-02, -1.1442e-01, -1.9092e-01,  9.6258e-03,  9.6789e-02,\n",
      "          -6.4664e-02, -1.2456e-01, -1.0260e-01,  1.2531e-02, -3.9462e-02,\n",
      "           6.0512e-02,  7.7109e-02,  6.0273e-04, -1.1456e-01, -4.5911e-02,\n",
      "           4.8505e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4820,  1.6544, -1.0096, -1.1127,  0.4005,  0.6460,\n",
      "          -1.2228, -0.9025,  0.0940, -0.2097,  0.3160,  0.0000, -0.9577,\n",
      "          -0.3086,  0.3245, -1.8655, -2.1366,  0.6082,  0.0000,  0.7695,\n",
      "           0.2828, -1.2566, -0.9731,  1.1927,  1.4266, -1.6558,  1.0543,\n",
      "           0.9846, -1.2882,  0.3069, -0.9456, -0.7691, -1.5225, -0.3683,\n",
      "           0.4844,  0.0000, -0.3512,  0.3283,  0.6284,  0.0000, -1.1771,\n",
      "           0.3729,  1.2540, -1.7956,  1.9479, -1.4978, -0.4431, -0.2786,\n",
      "           1.1466,  0.8653,  0.0371, -0.0720, -1.0044, -0.2960, -0.8049,\n",
      "          -1.8696,  0.5100,  1.5734,  2.0581, -0.8820, -0.7342,  0.0000,\n",
      "          -0.9066, -0.8594,  0.1077,  0.6390,  0.0000,  0.0214,  0.4295,\n",
      "          -1.5899, -0.0284, -0.6440,  1.4254, -0.4460,  0.5581, -3.6199,\n",
      "          -0.6178, -1.4068, -0.3112,  0.8704,  1.3127,  0.8813,  0.0000,\n",
      "           0.6942,  0.6929,  0.0460,  0.0000,  0.8148,  0.0000, -1.4907,\n",
      "           0.3247,  0.0000,  2.3926,  0.0000,  0.2151,  0.0000,  1.0777,\n",
      "           1.5508, -2.1249,  0.0145, -0.6642, -1.1343, -1.8824,  0.4072,\n",
      "           1.4168, -1.9890, -0.9152,  0.0000,  1.8167, -1.4326,  0.1792,\n",
      "          -0.4979,  1.3008,  0.0000, -0.1098,  0.3373, -1.6431,  0.8516,\n",
      "          -1.2944, -1.3467, -0.0996,  0.8781,  0.5349,  0.2247,  0.8188,\n",
      "          -0.2020, -1.0699,  0.1248, -0.4279, -1.2474,  2.3283,  1.4194,\n",
      "           0.0000, -0.0088, -0.6387, -0.0634, -0.5999, -0.4514,  1.0982,\n",
      "           0.5454, -1.1802, -2.2953, -0.8861,  0.2165, -0.1881,  0.9174,\n",
      "           0.0000,  1.5431,  0.0000,  0.3218, -1.3513,  1.8152, -1.9313,\n",
      "           0.5129, -0.3341, -0.2284, -0.7583,  0.9340, -0.0177,  0.2299,\n",
      "          -1.1454,  2.2620, -1.7650, -0.3903, -0.6924,  0.5300,  2.1361,\n",
      "          -1.6405, -2.7424,  1.2548, -2.0858, -0.0066,  0.0000, -0.9214,\n",
      "          -0.7987, -0.3070, -0.4306,  0.1182, -1.5139,  0.1504, -0.4528,\n",
      "           0.1996,  0.0000,  0.4843, -0.0759, -1.5028,  0.0000,  0.4040,\n",
      "          -1.4627,  1.0719,  0.6061,  0.0000, -0.5085,  0.7252, -0.0427,\n",
      "           1.8720,  0.0421, -0.8384, -0.2757,  0.1194, -0.2978,  0.0000,\n",
      "           0.3538, -0.0092, -0.7149,  0.6959,  2.0168, -0.7501,  1.8923,\n",
      "           2.7901,  0.1562,  1.5049,  0.1014,  0.0000, -0.0230, -0.1428,\n",
      "          -1.3820,  0.4079,  0.6378, -0.6886,  1.8593,  0.6064,  0.4726,\n",
      "           0.0286,  1.5296, -0.3651, -0.2609,  0.0000, -0.2544,  0.7764,\n",
      "          -0.5520,  1.2382,  0.0932,  2.0765,  0.0000, -1.7046,  2.7790,\n",
      "          -1.4957,  1.8027,  0.0000,  0.0000, -1.0500, -0.8545,  0.1357,\n",
      "          -1.7794,  0.0000,  1.9829,  0.5690,  0.5473, -1.7500,  0.3684,\n",
      "           0.1555,  1.5691, -2.7264,  0.4075]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0328, 0.1592, 0.0953, 0.0546, 0.1769, 0.2158, 0.0536, 0.0588, 0.1069,\n",
      "         0.0459]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1120,  0.0543, -0.1148,  ..., -0.4732,  0.2047, -0.2541],\n",
      "        [-0.0408, -0.0905, -0.2784,  ..., -0.5559, -0.3632,  0.4351],\n",
      "        [-0.0779,  0.3698, -0.1817,  ..., -0.0783, -0.5377,  0.1360],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1350,  0.1397, -0.2153,  0.0627, -0.0771, -0.1554,  0.1016,\n",
      "          -0.0835, -0.0504, -0.1186,  0.0892, -0.1648, -0.0929,  0.1696,\n",
      "           0.2257, -0.0229,  0.0905,  0.0818, -0.0921, -0.1184, -0.1961,\n",
      "          -0.1412,  0.0294,  0.1344, -0.1231, -0.1609, -0.0671, -0.0802,\n",
      "           0.0412, -0.0331,  0.0189, -0.1650, -0.1462,  0.0234, -0.0887,\n",
      "           0.0729, -0.2456, -0.0647, -0.1612, -0.0387, -0.1511, -0.0106,\n",
      "          -0.1102,  0.1338,  0.2151,  0.1870, -0.0537, -0.2210,  0.0888,\n",
      "           0.0984, -0.1163,  0.0621, -0.2098,  0.1792,  0.0963,  0.0185,\n",
      "          -0.0693,  0.0260,  0.1136,  0.0394,  0.0075, -0.1236, -0.0373,\n",
      "           0.0960, -0.0944, -0.0968,  0.0537,  0.0298, -0.1501,  0.1304,\n",
      "           0.1606,  0.0987, -0.0179,  0.0978, -0.1948,  0.1691,  0.1766,\n",
      "           0.1255,  0.0488, -0.0756, -0.0750, -0.1139, -0.1236, -0.0155,\n",
      "          -0.0219,  0.1258,  0.0765, -0.0085,  0.0647, -0.1331, -0.0366,\n",
      "           0.0350, -0.0177, -0.0790, -0.1347,  0.0823,  0.0529,  0.1192,\n",
      "          -0.1052,  0.1103, -0.2072, -0.0564,  0.1115,  0.0046, -0.1043,\n",
      "           0.0775, -0.0015,  0.1180, -0.0086,  0.1445,  0.0588, -0.0592,\n",
      "           0.0728, -0.1873, -0.0861, -0.0425,  0.0010, -0.0293, -0.2068,\n",
      "          -0.1005, -0.0036, -0.2053, -0.2676, -0.0990, -0.1520, -0.0314,\n",
      "          -0.0607, -0.2653,  0.0350, -0.0484,  0.0597, -0.1126,  0.1607,\n",
      "           0.1525, -0.0115,  0.1412,  0.1502,  0.0569, -0.2116,  0.1128,\n",
      "           0.0439,  0.1680, -0.0857,  0.2548,  0.0971, -0.0787,  0.0433,\n",
      "           0.1138,  0.1373,  0.2182, -0.2359, -0.0119, -0.0289,  0.0566,\n",
      "           0.0572,  0.2509, -0.0234,  0.0420,  0.0159, -0.0523,  0.0208,\n",
      "          -0.2121, -0.2419,  0.1517, -0.0556,  0.0591, -0.1232, -0.1083,\n",
      "           0.3012,  0.1019, -0.0660,  0.1267,  0.1644,  0.0007, -0.0044,\n",
      "           0.0198, -0.1247,  0.1809,  0.2383, -0.0486, -0.1815, -0.2584,\n",
      "          -0.1229,  0.0684, -0.0429,  0.2862, -0.1941,  0.0569, -0.0420,\n",
      "          -0.2090,  0.0895,  0.2550, -0.1673, -0.0807,  0.1276, -0.2012,\n",
      "          -0.0251, -0.1144,  0.0185,  0.1455, -0.1902,  0.0696, -0.0908,\n",
      "           0.1341,  0.0599,  0.0374, -0.0132,  0.2137, -0.0953,  0.0671,\n",
      "          -0.0323, -0.1902, -0.0338,  0.0479, -0.0142,  0.1087, -0.1009,\n",
      "           0.1120, -0.1611,  0.2326,  0.1055, -0.2259,  0.2036, -0.0902,\n",
      "           0.2741,  0.0017, -0.0454,  0.0093, -0.1981,  0.0981, -0.1361,\n",
      "           0.0912, -0.0268, -0.2135, -0.0879, -0.0245, -0.1131,  0.0055,\n",
      "           0.1512, -0.0753, -0.0795, -0.2013, -0.3280,  0.0258,  0.1697,\n",
      "          -0.1195, -0.1701, -0.1606, -0.0018, -0.0757,  0.1146,  0.1267,\n",
      "           0.0211, -0.2059, -0.1099,  0.1217]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7782, -1.6519, -0.1827, -0.7320,  2.5181,  0.0000,\n",
      "          -0.0325,  0.9502,  1.1944,  1.4103,  0.0000, -0.0651,  0.0645,\n",
      "           0.0000,  1.8852,  0.8702, -0.7847, -0.6404, -1.4034, -0.4984,\n",
      "          -0.3789,  0.0000,  0.2330,  0.1892,  0.0000,  0.0000, -0.1510,\n",
      "          -1.0411,  0.0000, -0.5711,  0.6008, -1.6987,  0.2317, -0.0796,\n",
      "           0.1482,  0.6451, -2.2132,  1.0515,  0.1023, -0.6924, -0.4366,\n",
      "          -1.0644,  0.8178, -0.6329, -0.6565,  1.3724,  0.9367,  1.6037,\n",
      "           0.0000, -1.0082, -1.1720, -1.1123,  1.2531, -1.9746,  1.7091,\n",
      "           0.5928, -1.8921,  0.3413, -0.2937, -0.7703,  1.8689, -0.5942,\n",
      "           0.0000, -0.8353,  1.2345, -0.3576,  0.0000,  0.0000, -1.1648,\n",
      "           2.2477,  0.7807,  0.2705,  1.2050, -0.3979,  0.0000,  0.2292,\n",
      "          -0.1574, -0.9147,  0.2960, -0.1449,  1.2865,  0.4651,  1.2969,\n",
      "           0.7708,  0.6605,  1.0453,  0.0000, -1.2409, -1.4362,  1.3107,\n",
      "          -1.5854, -0.1111,  3.2387,  0.3469,  1.0036, -0.8686,  0.7311,\n",
      "          -1.6815, -0.9244,  0.1905,  0.0287, -0.5964,  1.0584, -0.2310,\n",
      "           0.7758, -0.9059, -0.3679, -0.2785, -0.5476, -0.1379, -3.2779,\n",
      "          -0.1008, -1.8785,  1.6979,  1.6882,  2.0295,  0.0000, -0.8959,\n",
      "           0.0000, -1.3262,  1.4238, -0.6276,  0.0000,  1.3157, -0.9872,\n",
      "           0.0739, -0.9857, -0.6749,  0.2478,  0.0000,  1.1296,  0.0000,\n",
      "           1.4884,  0.3789,  0.0000, -0.8379,  0.2413,  0.3447, -1.2615,\n",
      "           0.0302,  0.8640,  0.0000,  0.9072,  0.0000, -0.6408, -0.4417,\n",
      "           0.8729, -0.0676,  0.0422, -0.0564,  0.6209,  0.1450, -0.1965,\n",
      "           0.1076, -1.6721, -0.4024,  0.2511, -2.0696,  0.4118,  1.1552,\n",
      "           0.0000,  0.9131,  0.8437,  0.4174,  1.6037,  0.1769, -1.1142,\n",
      "          -0.3226,  0.2509,  0.4451, -0.4551,  0.4446, -1.3454,  1.7357,\n",
      "           0.0000,  1.1774,  0.2896, -1.8321, -1.8661,  0.2592, -0.6474,\n",
      "          -1.1658,  0.3287, -0.7440,  0.5921, -1.2416, -1.5177, -2.3035,\n",
      "           0.1467, -1.6243,  0.0000, -0.0500,  1.2995,  0.0000, -1.4146,\n",
      "           0.0000,  3.0135, -0.2259,  1.0326,  0.0292,  0.1189, -1.3197,\n",
      "          -1.0707,  0.0566,  1.7330,  0.5268,  1.9823, -0.9787,  0.0000,\n",
      "           1.5993, -0.4016,  2.4610, -0.5197,  0.7546,  0.2063, -0.8209,\n",
      "           0.9056, -3.5303,  0.1759,  0.0000, -0.6933, -1.4185,  0.2511,\n",
      "          -0.0647, -1.4657,  0.4271, -0.5198,  0.0462, -0.6252, -0.0711,\n",
      "           0.7482, -2.0271, -1.0489, -0.4317, -0.1123,  0.5160, -2.7969,\n",
      "           0.0000, -0.6645,  1.0256,  0.1328,  2.7512,  1.0024,  0.5471,\n",
      "          -0.1736, -1.5053,  2.2318,  1.1874,  0.0000,  0.7229,  0.0000,\n",
      "          -2.8554, -0.0139, -0.8375, -0.5803]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0344, 0.1578, 0.1109, 0.0856, 0.0896, 0.1351, 0.0758, 0.1048, 0.1268,\n",
      "         0.0791]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1120,  0.0543, -0.1148,  ..., -0.4732,  0.2047, -0.2541],\n",
      "        [-0.0408, -0.0905, -0.2784,  ..., -0.5559, -0.3632,  0.4351],\n",
      "        [-0.0779,  0.3698, -0.1817,  ..., -0.0783, -0.5377,  0.1360],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.6561e-02,  9.9295e-02, -1.6503e-01,  5.2659e-02, -2.6804e-02,\n",
      "          -1.0319e-01,  8.2118e-02, -3.5566e-02, -6.7312e-02, -1.0260e-01,\n",
      "           7.2087e-02, -1.1981e-01, -5.9090e-02,  1.8810e-01,  1.9003e-01,\n",
      "          -6.9507e-05,  6.4020e-02,  6.6672e-02, -5.2072e-02, -1.3168e-01,\n",
      "          -1.5830e-01, -9.9626e-02,  9.6743e-03,  9.1300e-02, -7.4974e-02,\n",
      "          -9.3917e-02, -3.9354e-02, -5.0818e-02,  8.3405e-02, -4.0265e-03,\n",
      "          -3.9404e-03, -1.2001e-01, -1.1145e-01,  6.0228e-02, -8.6188e-02,\n",
      "           4.5148e-02, -2.1414e-01, -4.8188e-02, -1.0209e-01, -4.2371e-02,\n",
      "          -1.5365e-01,  3.2806e-03, -7.5844e-02,  1.0557e-01,  1.7672e-01,\n",
      "           1.6696e-01, -1.6477e-02, -1.7282e-01,  7.7026e-02,  9.4592e-02,\n",
      "          -6.5836e-02,  6.9350e-02, -1.7196e-01,  1.6681e-01,  1.0020e-01,\n",
      "           2.0615e-02, -6.5759e-02, -5.1201e-03,  8.1107e-02, -2.1243e-02,\n",
      "           2.6600e-02, -1.0946e-01,  1.1505e-02,  8.9656e-02, -7.4803e-02,\n",
      "          -9.6913e-02,  5.9069e-02, -3.8280e-03, -1.3587e-01,  1.5001e-01,\n",
      "           1.6729e-01,  6.6346e-02,  6.9635e-04,  6.7478e-02, -1.5202e-01,\n",
      "           1.6429e-01,  1.4378e-01,  9.7261e-02,  6.6196e-02, -1.0022e-01,\n",
      "          -3.6827e-02, -2.5671e-02, -7.6139e-02, -3.4676e-03, -1.2045e-02,\n",
      "           8.9386e-02,  8.1741e-02, -6.4972e-03,  2.5249e-02, -9.5683e-02,\n",
      "          -5.7713e-02,  3.0022e-02, -2.3563e-02, -1.0102e-01, -1.1627e-01,\n",
      "           7.2638e-02,  2.7503e-02,  6.4164e-02, -6.7525e-02,  5.2825e-02,\n",
      "          -1.5997e-01, -7.6858e-02,  8.2959e-02, -1.0175e-02, -4.4075e-02,\n",
      "           7.3132e-02, -3.3075e-02,  8.5651e-02,  6.3462e-03,  1.1643e-01,\n",
      "           1.0345e-02, -3.9373e-02,  4.2113e-02, -1.3795e-01, -3.8215e-02,\n",
      "          -3.9814e-02, -1.9292e-03, -9.0568e-03, -1.8966e-01, -8.1558e-02,\n",
      "          -2.6992e-02, -1.6884e-01, -2.2590e-01, -1.0695e-01, -1.2742e-01,\n",
      "          -1.1124e-02, -6.5839e-02, -2.4245e-01, -8.8508e-03, -2.5756e-02,\n",
      "           1.5276e-02, -3.7085e-02,  9.7220e-02,  1.1917e-01,  2.3141e-02,\n",
      "           9.3786e-02,  8.9801e-02,  5.7495e-02, -1.5253e-01,  8.4155e-02,\n",
      "           5.1957e-02,  1.3411e-01, -5.5977e-02,  2.1589e-01,  6.1793e-02,\n",
      "          -8.1887e-02,  4.7107e-02,  6.9988e-02,  1.2833e-01,  1.8847e-01,\n",
      "          -1.8625e-01, -1.4419e-02, -3.4225e-02,  2.4443e-02,  3.0671e-02,\n",
      "           2.1223e-01, -1.0317e-02,  2.2445e-02, -4.3976e-02, -5.6670e-03,\n",
      "           4.4471e-02, -1.6421e-01, -1.9131e-01,  9.2581e-02, -9.1925e-02,\n",
      "           1.5361e-02, -1.0521e-01, -8.5708e-02,  2.3889e-01,  2.0217e-02,\n",
      "          -2.5589e-02,  1.1626e-01,  1.2120e-01,  3.6063e-02,  2.9171e-02,\n",
      "           4.2810e-02, -9.5727e-02,  1.5362e-01,  1.8179e-01, -3.3827e-02,\n",
      "          -1.5966e-01, -2.2480e-01, -8.3473e-02,  6.9931e-02, -6.5009e-02,\n",
      "           2.4700e-01, -1.0968e-01,  9.2566e-03, -9.2954e-02, -1.7240e-01,\n",
      "           1.0663e-01,  2.2897e-01, -1.0697e-01, -3.9553e-02,  9.6890e-02,\n",
      "          -1.7324e-01,  1.6662e-02, -1.0787e-01,  6.5917e-02,  1.1042e-01,\n",
      "          -1.8574e-01,  3.5290e-02, -7.2390e-02,  8.1185e-02,  3.8828e-02,\n",
      "           6.1562e-02, -4.3442e-03,  1.6571e-01, -7.5986e-02,  7.6295e-02,\n",
      "          -8.0982e-02, -1.5565e-01, -1.4812e-02,  5.2611e-03,  7.3809e-03,\n",
      "           6.0591e-02, -3.7292e-02,  9.5570e-02, -1.2835e-01,  1.8347e-01,\n",
      "           6.7296e-02, -1.8858e-01,  1.6578e-01, -6.1341e-02,  2.3744e-01,\n",
      "          -3.3565e-02, -1.0704e-01,  3.9928e-02, -1.4395e-01,  3.8128e-02,\n",
      "          -6.3003e-02,  1.0835e-01, -2.3419e-02, -1.6212e-01, -7.4232e-02,\n",
      "          -2.5351e-02, -8.4953e-02,  1.4899e-02,  1.2615e-01, -7.3788e-02,\n",
      "          -6.3047e-02, -1.6970e-01, -2.9198e-01,  3.5862e-02,  1.4300e-01,\n",
      "          -1.2991e-01, -1.3623e-01, -1.2090e-01, -4.5837e-02, -1.4136e-01,\n",
      "           9.9713e-02,  1.3177e-01,  8.9514e-02, -1.8661e-01, -1.0382e-01,\n",
      "           1.0376e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2549,  0.7782, -1.6519, -0.1827, -0.7320,  2.5181,  0.0000,\n",
      "          -0.0325,  0.9502,  1.1944,  1.4103, -0.7567, -0.0651,  0.0645,\n",
      "           1.0465,  1.8852,  0.8702, -0.7847, -0.6404, -1.4034, -0.4984,\n",
      "          -0.3789,  1.1427,  0.2330,  0.1892, -0.6133,  1.4042, -0.1510,\n",
      "          -1.0411,  0.4960, -0.5711,  0.6008, -1.6987,  0.2317,  0.0000,\n",
      "           0.0000,  0.6451, -2.2132,  1.0515,  0.1023,  0.0000, -0.4366,\n",
      "          -1.0644,  0.8178, -0.6329, -0.6565,  1.3724,  0.9367,  1.6037,\n",
      "           0.3694, -1.0082, -1.1720, -1.1123,  1.2531, -1.9746,  1.7091,\n",
      "           0.5928, -1.8921,  0.0000, -0.2937, -0.7703,  1.8689, -0.5942,\n",
      "          -1.6815, -0.8353,  1.2345, -0.3576,  0.2896, -0.7527,  0.0000,\n",
      "           2.2477,  0.7807,  0.2705,  0.0000, -0.3979,  0.3545,  0.2292,\n",
      "          -0.1574,  0.0000,  0.2960, -0.1449,  1.2865,  0.0000,  1.2969,\n",
      "           0.7708,  0.6605,  1.0453, -0.3684,  0.0000, -1.4362,  0.0000,\n",
      "          -1.5854, -0.1111,  3.2387,  0.3469,  1.0036, -0.8686,  0.7311,\n",
      "          -1.6815, -0.9244,  0.1905,  0.0287, -0.5964,  1.0584,  0.0000,\n",
      "           0.0000, -0.9059, -0.3679, -0.2785, -0.5476,  0.0000, -3.2779,\n",
      "          -0.1008,  0.0000,  0.0000,  1.6882,  2.0295, -1.6462, -0.8959,\n",
      "           2.5845, -1.3262,  1.4238,  0.0000,  0.0000,  1.3157, -0.9872,\n",
      "           0.0739, -0.9857, -0.6749,  0.2478, -1.2005,  1.1296,  1.1406,\n",
      "           1.4884,  0.3789,  0.6467, -0.8379,  0.2413,  0.3447, -1.2615,\n",
      "           0.0302,  0.8640,  0.5014,  0.9072, -1.2678, -0.6408,  0.0000,\n",
      "           0.8729, -0.0676,  0.0422, -0.0564,  0.6209,  0.1450, -0.1965,\n",
      "           0.1076, -1.6721,  0.0000,  0.2511, -2.0696,  0.4118,  1.1552,\n",
      "           0.1995,  0.9131,  0.8437,  0.4174,  1.6037,  0.1769, -1.1142,\n",
      "          -0.3226,  0.2509,  0.4451, -0.4551,  0.4446, -1.3454,  0.0000,\n",
      "           0.5175,  1.1774,  0.2896, -1.8321, -1.8661,  0.2592,  0.0000,\n",
      "          -1.1658,  0.3287, -0.7440,  0.5921, -1.2416, -1.5177,  0.0000,\n",
      "           0.1467, -1.6243, -1.3210, -0.0500,  1.2995,  0.9805, -1.4146,\n",
      "          -1.1403,  3.0135, -0.2259,  1.0326,  0.0292,  0.0000, -1.3197,\n",
      "          -1.0707,  0.0000,  1.7330,  0.5268,  1.9823,  0.0000, -1.3424,\n",
      "           1.5993, -0.4016,  2.4610, -0.5197,  0.7546,  0.2063, -0.8209,\n",
      "           0.0000, -3.5303,  0.1759, -0.7814, -0.6933, -1.4185,  0.2511,\n",
      "          -0.0647, -1.4657,  0.4271, -0.5198,  0.0000, -0.6252, -0.0711,\n",
      "           0.7482, -2.0271, -1.0489,  0.0000, -0.1123,  0.5160, -2.7969,\n",
      "          -1.4579,  0.0000,  1.0256,  0.1328,  2.7512,  1.0024,  0.5471,\n",
      "          -0.1736, -1.5053,  0.0000,  1.1874, -0.0477,  0.7229,  0.0000,\n",
      "          -2.8554, -0.0139, -0.8375, -0.5803]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0336, 0.1511, 0.1165, 0.0924, 0.1075, 0.1131, 0.0757, 0.1043, 0.1332,\n",
      "         0.0725]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1120,  0.0543, -0.1148,  ..., -0.4732,  0.2047, -0.2541],\n",
      "        [-0.0408, -0.0905, -0.2784,  ..., -0.5559, -0.3632,  0.4351],\n",
      "        [-0.0779,  0.3698, -0.1817,  ..., -0.0783, -0.5377,  0.1360],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.0151e-01,  1.1404e-01, -1.7971e-01,  5.8736e-02, -3.7956e-02,\n",
      "          -1.1476e-01,  8.4622e-02, -4.8075e-02, -7.3760e-02, -1.1413e-01,\n",
      "           7.3925e-02, -1.3029e-01, -7.1092e-02,  1.9308e-01,  2.0107e-01,\n",
      "          -1.8061e-03,  6.3578e-02,  8.3320e-02, -6.5736e-02, -1.3388e-01,\n",
      "          -1.6789e-01, -1.1908e-01,  2.0534e-02,  9.6885e-02, -8.4509e-02,\n",
      "          -1.0507e-01, -4.2831e-02, -6.5092e-02,  7.6147e-02, -4.2708e-03,\n",
      "           1.6409e-03, -1.3755e-01, -1.2208e-01,  4.8626e-02, -8.9656e-02,\n",
      "           5.1993e-02, -2.2434e-01, -5.1858e-02, -1.1310e-01, -3.7583e-02,\n",
      "          -1.5674e-01,  4.8330e-03, -9.2062e-02,  1.1400e-01,  1.8357e-01,\n",
      "           1.8059e-01, -2.1652e-02, -1.8982e-01,  8.3689e-02,  9.4864e-02,\n",
      "          -7.2445e-02,  6.7431e-02, -1.8746e-01,  1.7215e-01,  9.9551e-02,\n",
      "           2.3310e-02, -7.1034e-02,  3.8049e-03,  8.6702e-02, -6.5302e-03,\n",
      "           2.2886e-02, -1.1597e-01, -8.3949e-04,  9.4934e-02, -8.3815e-02,\n",
      "          -9.4591e-02,  5.9543e-02,  4.9507e-03, -1.4902e-01,  1.5385e-01,\n",
      "           1.7465e-01,  7.6964e-02, -6.0896e-03,  8.3603e-02, -1.6931e-01,\n",
      "           1.7524e-01,  1.6248e-01,  1.0866e-01,  6.6023e-02, -9.2835e-02,\n",
      "          -4.7633e-02, -3.6372e-02, -9.5418e-02, -1.8489e-03, -2.0869e-02,\n",
      "           9.6061e-02,  8.3564e-02, -3.0345e-03,  3.9160e-02, -1.0753e-01,\n",
      "          -5.5629e-02,  2.7762e-02, -2.7911e-02, -1.0340e-01, -1.2525e-01,\n",
      "           7.9528e-02,  3.6677e-02,  7.7385e-02, -7.2710e-02,  6.5705e-02,\n",
      "          -1.7647e-01, -7.1123e-02,  8.8414e-02, -1.2576e-02, -5.0316e-02,\n",
      "           7.5593e-02, -2.3331e-02,  1.0417e-01,  3.0621e-04,  1.2672e-01,\n",
      "           8.6909e-03, -4.1369e-02,  4.9369e-02, -1.5605e-01, -5.2283e-02,\n",
      "          -4.1601e-02, -2.1462e-03, -1.5749e-02, -1.9863e-01, -8.9015e-02,\n",
      "          -2.2404e-02, -1.8221e-01, -2.4429e-01, -1.0619e-01, -1.4246e-01,\n",
      "          -1.9914e-02, -6.8085e-02, -2.5540e-01,  1.3998e-03, -3.1036e-02,\n",
      "           2.5689e-02, -5.0274e-02,  1.1120e-01,  1.3287e-01,  2.0694e-02,\n",
      "           9.8677e-02,  1.0531e-01,  6.6195e-02, -1.6443e-01,  9.7924e-02,\n",
      "           4.9916e-02,  1.4732e-01, -6.6191e-02,  2.2809e-01,  7.2044e-02,\n",
      "          -8.4605e-02,  4.6609e-02,  8.5485e-02,  1.3722e-01,  2.0373e-01,\n",
      "          -2.0922e-01, -1.1094e-02, -3.6039e-02,  3.7794e-02,  3.8753e-02,\n",
      "           2.2996e-01, -1.3266e-02,  2.8733e-02, -3.6490e-02, -1.7156e-02,\n",
      "           3.7925e-02, -1.7616e-01, -2.0483e-01,  1.0927e-01, -8.5100e-02,\n",
      "           2.3136e-02, -1.1242e-01, -9.5863e-02,  2.5187e-01,  3.3063e-02,\n",
      "          -4.1212e-02,  1.2294e-01,  1.3946e-01,  3.7099e-02,  2.2838e-02,\n",
      "           3.2827e-02, -1.0035e-01,  1.6663e-01,  1.9644e-01, -4.3058e-02,\n",
      "          -1.6947e-01, -2.3770e-01, -9.0820e-02,  6.6993e-02, -5.7580e-02,\n",
      "           2.6141e-01, -1.1983e-01,  2.3642e-02, -8.6648e-02, -1.8938e-01,\n",
      "           1.0652e-01,  2.4186e-01, -1.2123e-01, -4.9565e-02,  1.0813e-01,\n",
      "          -1.8679e-01,  1.0098e-02, -1.1102e-01,  5.4582e-02,  1.2067e-01,\n",
      "          -1.9047e-01,  4.3296e-02, -7.8951e-02,  1.0021e-01,  4.4947e-02,\n",
      "           5.6990e-02, -4.9613e-03,  1.8198e-01, -7.7881e-02,  7.4058e-02,\n",
      "          -8.3616e-02, -1.7235e-01, -1.4278e-02,  1.7661e-02,  5.2531e-04,\n",
      "           7.4306e-02, -4.8884e-02,  1.0181e-01, -1.3698e-01,  1.9764e-01,\n",
      "           8.0442e-02, -2.0298e-01,  1.8095e-01, -7.0324e-02,  2.4945e-01,\n",
      "          -1.9622e-02, -9.9116e-02,  2.7687e-02, -1.6297e-01,  5.0218e-02,\n",
      "          -7.5207e-02,  1.0581e-01, -3.1806e-02, -1.8022e-01, -8.2665e-02,\n",
      "          -3.6375e-02, -9.5190e-02,  1.5060e-02,  1.3928e-01, -7.3660e-02,\n",
      "          -7.2296e-02, -1.7947e-01, -3.0801e-01,  3.3569e-02,  1.5562e-01,\n",
      "          -1.3519e-01, -1.5421e-01, -1.3484e-01, -3.8141e-02, -1.3847e-01,\n",
      "           1.0459e-01,  1.3641e-01,  8.3119e-02, -1.9303e-01, -1.0513e-01,\n",
      "           1.0674e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7272e-01, -4.3081e-01,  3.1532e-01, -1.0853e+00,  0.0000e+00,\n",
      "           7.4163e-01,  0.0000e+00,  1.3513e+00,  1.9014e-01,  6.1743e-01,\n",
      "           1.9036e+00,  6.0263e-01,  2.2910e-01, -9.1664e-01, -3.1841e+00,\n",
      "          -6.8297e-02, -1.6337e+00, -9.4354e-01,  1.3603e+00, -1.4358e+00,\n",
      "          -1.4038e-01, -5.2448e-01, -1.1200e+00, -2.5960e+00,  0.0000e+00,\n",
      "           1.3917e+00, -6.1998e-01,  1.9982e+00,  0.0000e+00,  5.5531e-01,\n",
      "           9.1594e-01, -3.8225e-03,  2.2240e-01,  2.0171e+00, -6.3563e-02,\n",
      "          -1.4086e+00, -1.1159e-01, -8.1738e-01,  3.1524e-01,  8.6079e-02,\n",
      "           8.6352e-01, -8.9928e-01,  0.0000e+00, -1.5641e+00,  1.9449e+00,\n",
      "          -3.0030e-01,  0.0000e+00, -6.0245e-01, -1.0209e+00,  1.1173e+00,\n",
      "          -1.3234e+00,  2.6783e+00,  6.6700e-01, -8.4704e-01,  2.2808e-01,\n",
      "          -3.1020e-01, -1.4340e+00, -9.6233e-02,  1.2760e+00,  2.1823e+00,\n",
      "          -1.0067e+00,  3.5783e-02, -2.8016e-01,  2.6573e-01, -6.3279e-02,\n",
      "           3.9352e-01,  5.7814e-01,  1.1655e+00,  1.5812e+00, -1.4155e+00,\n",
      "           4.2734e-01,  2.9641e-01, -3.1019e-02, -7.9816e-01, -2.1414e-01,\n",
      "           1.3947e-01,  5.2596e-01,  1.3992e+00,  1.0274e+00, -7.9436e-01,\n",
      "           7.5857e-01, -1.0048e+00,  7.5839e-01,  1.0589e+00, -1.2157e+00,\n",
      "          -1.1330e-01, -1.1083e+00,  5.4872e-01, -9.4496e-01, -1.9015e+00,\n",
      "           5.2926e-01,  9.8751e-01,  1.7022e+00,  9.4430e-01,  6.0801e-01,\n",
      "          -1.5913e-02,  3.5431e-01, -1.1760e+00,  1.3726e+00,  2.4482e+00,\n",
      "           2.4343e-01,  4.4104e-02, -4.6663e-01, -9.8942e-01,  1.6413e+00,\n",
      "          -1.0241e+00,  3.0303e+00,  6.2081e-01, -1.0191e-01, -1.2358e+00,\n",
      "           1.8998e-01, -5.0342e-01,  0.0000e+00,  7.1261e-01, -7.8072e-01,\n",
      "           6.3264e-01,  4.0376e-01,  2.2348e-01, -2.3273e+00,  2.9209e-02,\n",
      "          -8.1479e-01,  0.0000e+00, -1.8386e+00,  6.0325e-01, -9.5726e-01,\n",
      "          -2.0101e-01,  4.0285e-02,  2.1509e+00,  1.3967e+00, -2.0884e+00,\n",
      "          -9.2630e-01,  4.5000e-01, -1.1683e+00,  4.2550e-01, -4.6833e-01,\n",
      "          -7.4643e-01, -1.0649e+00, -9.7552e-01, -1.9438e-02,  2.3981e+00,\n",
      "           6.9864e-01, -1.1219e+00,  1.6919e+00, -1.4043e-01, -6.7010e-01,\n",
      "           3.3163e-02,  7.5990e-01,  4.2282e-01, -1.0340e+00, -9.5280e-02,\n",
      "           1.5601e+00,  5.8680e-01, -3.3842e-01,  6.5786e-01,  1.8416e+00,\n",
      "          -2.5278e-01, -2.1798e-01,  6.2402e-01, -2.3640e+00,  1.0561e+00,\n",
      "           3.0291e-01, -7.7161e-02,  0.0000e+00, -1.2122e+00, -2.1931e-02,\n",
      "           1.6827e+00,  1.8529e+00,  2.7175e-01, -1.2704e+00, -7.1302e-01,\n",
      "          -1.2244e+00, -1.0942e+00,  0.0000e+00,  5.0597e-01, -3.0610e+00,\n",
      "          -2.8740e-01,  4.9762e-01,  0.0000e+00,  3.1706e-01, -7.9308e-01,\n",
      "           2.7265e-01,  0.0000e+00,  1.0584e+00,  8.3909e-01, -4.0237e-01,\n",
      "           7.2789e-01,  5.9883e-01,  3.5985e-01,  8.4336e-01, -1.8312e+00,\n",
      "           0.0000e+00,  2.1602e+00,  3.3581e-01, -1.0158e+00, -1.1730e+00,\n",
      "          -2.2164e+00,  1.6677e+00,  2.1535e+00,  3.6340e-01,  2.3838e+00,\n",
      "           3.2561e-02, -5.0164e-01,  0.0000e+00,  0.0000e+00, -4.0767e-01,\n",
      "          -1.4479e+00,  9.5344e-01, -8.5207e-01,  8.2949e-01, -1.5605e+00,\n",
      "           6.3723e-01,  6.7548e-01,  2.3986e+00,  5.5283e-02,  1.8938e+00,\n",
      "           1.3092e+00,  5.8026e-01,  0.0000e+00,  1.5504e+00, -2.2261e-01,\n",
      "          -2.2742e-01,  1.7344e+00,  2.7648e-01, -1.5525e+00,  9.2297e-01,\n",
      "          -1.2244e+00, -8.4899e-01,  0.0000e+00, -7.6533e-04,  3.7324e-01,\n",
      "          -1.5739e+00,  0.0000e+00,  9.6636e-01, -1.7377e+00,  1.6947e+00,\n",
      "          -1.4407e+00,  6.3399e-01, -1.7232e+00,  0.0000e+00, -1.7172e+00,\n",
      "           0.0000e+00, -2.7304e-01, -2.5976e+00,  1.2392e+00,  0.0000e+00,\n",
      "           1.8864e+00,  0.0000e+00,  0.0000e+00, -2.6125e-01, -1.0225e+00,\n",
      "           1.3339e+00,  3.1139e-01, -5.0902e-02, -2.2874e-01, -1.6132e+00,\n",
      "           1.8071e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0386, 0.1123, 0.1728, 0.0634, 0.1432, 0.1565, 0.1204, 0.0552, 0.0801,\n",
      "         0.0574]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.1120,  0.0543, -0.1148,  ..., -0.4732,  0.2047, -0.2541],\n",
      "        [-0.0408, -0.0905, -0.2784,  ..., -0.5559, -0.3632,  0.4351],\n",
      "        [-0.0779,  0.3698, -0.1817,  ..., -0.0783, -0.5377,  0.1360],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1119,  0.1544, -0.1954,  0.0991, -0.0651, -0.1287,  0.0965,\n",
      "          -0.0600, -0.0959, -0.1251,  0.0739, -0.1430, -0.0668,  0.1950,\n",
      "           0.2069,  0.0020,  0.0610,  0.1115, -0.0574, -0.1314, -0.1785,\n",
      "          -0.1550,  0.0294,  0.1126, -0.0947, -0.1351, -0.0716, -0.0903,\n",
      "           0.0535, -0.0101, -0.0189, -0.1730, -0.1409,  0.0447, -0.0822,\n",
      "           0.0597, -0.2217, -0.0566, -0.1205, -0.0347, -0.1679, -0.0155,\n",
      "          -0.1282,  0.1346,  0.1981,  0.1938, -0.0196, -0.2170,  0.0859,\n",
      "           0.1029, -0.0833,  0.0780, -0.2086,  0.1840,  0.1005,  0.0285,\n",
      "          -0.0917,  0.0257,  0.0753,  0.0201,  0.0157, -0.1033, -0.0105,\n",
      "           0.0848, -0.0944, -0.0795,  0.0765, -0.0094, -0.1676,  0.1460,\n",
      "           0.1830,  0.0761, -0.0343,  0.1241, -0.1970,  0.1787,  0.1883,\n",
      "           0.1220,  0.0610, -0.0919, -0.0725, -0.0588, -0.1163, -0.0067,\n",
      "          -0.0515,  0.0951,  0.0733, -0.0054,  0.0402, -0.1419, -0.0664,\n",
      "           0.0221, -0.0325, -0.0984, -0.1428,  0.0785,  0.0467,  0.0961,\n",
      "          -0.1045,  0.0686, -0.2077, -0.0880,  0.0841, -0.0214, -0.0752,\n",
      "           0.0883, -0.0107,  0.1271, -0.0081,  0.1246, -0.0091, -0.0597,\n",
      "           0.0710, -0.1823, -0.0761, -0.0574, -0.0065, -0.0240, -0.2038,\n",
      "          -0.0991, -0.0099, -0.2057, -0.2563, -0.1132, -0.1560, -0.0248,\n",
      "          -0.0755, -0.2680,  0.0222, -0.0277,  0.0441, -0.0718,  0.1380,\n",
      "           0.1355,  0.0232,  0.1064,  0.1329,  0.0674, -0.1766,  0.0966,\n",
      "           0.0670,  0.1580, -0.0713,  0.2493,  0.0935, -0.0849,  0.0398,\n",
      "           0.0901,  0.1401,  0.2216, -0.2318, -0.0230, -0.0321,  0.0581,\n",
      "           0.0309,  0.2438, -0.0210,  0.0307, -0.0178, -0.0377,  0.0465,\n",
      "          -0.1933, -0.1998,  0.1114, -0.0447,  0.0284, -0.1178, -0.1212,\n",
      "           0.2832,  0.0693, -0.0667,  0.1308,  0.1704,  0.0360,  0.0246,\n",
      "           0.0300, -0.0937,  0.1932,  0.1913, -0.0527, -0.1642, -0.2576,\n",
      "          -0.0836,  0.0744, -0.0618,  0.2947, -0.1307,  0.0558, -0.0491,\n",
      "          -0.2139,  0.1029,  0.2596, -0.1296, -0.0631,  0.1496, -0.1979,\n",
      "          -0.0162, -0.1222,  0.0448,  0.1445, -0.2054,  0.0511, -0.0858,\n",
      "           0.1366,  0.0653,  0.0609, -0.0019,  0.1942, -0.0781,  0.0966,\n",
      "          -0.0811, -0.2041, -0.0053,  0.0381, -0.0116,  0.0994, -0.0822,\n",
      "           0.1041, -0.1327,  0.2298,  0.0995, -0.2268,  0.2000, -0.0921,\n",
      "           0.2658,  0.0037, -0.0762,  0.0158, -0.1664,  0.0614, -0.1054,\n",
      "           0.1118, -0.0285, -0.2115, -0.1149, -0.0685, -0.1058,  0.0198,\n",
      "           0.1408, -0.0870, -0.0896, -0.1793, -0.3344,  0.0072,  0.1711,\n",
      "          -0.1308, -0.1853, -0.1422, -0.0176, -0.1204,  0.1005,  0.1415,\n",
      "           0.0771, -0.1793, -0.1286,  0.1027]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5666e-02,  3.9881e-01, -9.6728e-01, -6.8224e-01,  3.7653e-01,\n",
      "          -2.0172e-01,  1.4650e+00, -8.3194e-02, -3.5858e+00,  9.0689e-01,\n",
      "           4.2916e-01, -6.2940e-01,  2.6064e+00, -6.2975e-01, -5.4172e-01,\n",
      "          -1.5794e-01,  8.5183e-01,  0.0000e+00,  4.5513e-01,  4.3613e-01,\n",
      "          -6.3395e-01,  0.0000e+00,  0.0000e+00,  1.5117e+00,  7.5406e-01,\n",
      "          -7.5304e-02,  0.0000e+00,  0.0000e+00,  1.6544e+00,  8.6179e-01,\n",
      "           1.2322e+00,  1.2193e+00, -1.0346e+00, -8.2639e-02, -1.5353e+00,\n",
      "           1.3955e+00,  2.8079e-01, -3.7463e+00,  1.9812e-01,  1.6019e+00,\n",
      "          -4.5886e-01,  0.0000e+00, -2.6830e-01, -1.7173e+00, -1.5255e+00,\n",
      "           6.6729e-01,  5.4126e-01,  3.6993e-01, -1.3412e+00,  1.4365e-01,\n",
      "           0.0000e+00,  2.7541e+00,  6.1063e-01, -1.0300e+00, -2.5869e-02,\n",
      "           2.0285e-01, -8.8258e-01, -1.2534e+00, -2.3647e-01, -4.2504e-01,\n",
      "           0.0000e+00,  0.0000e+00, -2.0389e-01, -5.0216e-01, -2.9657e+00,\n",
      "           5.5038e-01,  1.2795e+00, -1.2887e+00,  4.1195e-01,  5.2637e-01,\n",
      "          -1.2680e+00,  0.0000e+00,  7.0758e-01,  0.0000e+00,  3.2671e-01,\n",
      "          -2.4852e-03, -1.5981e-01,  1.0635e+00, -5.8694e-02, -1.2035e-01,\n",
      "          -1.4007e+00,  2.1325e+00, -9.2525e-01,  1.0058e+00, -2.0797e-01,\n",
      "           4.3420e-01,  1.6622e+00, -9.7525e-01, -1.0303e-01, -5.8166e-01,\n",
      "          -2.2746e+00,  1.1007e+00, -6.2236e-01, -1.1354e+00,  4.6765e-01,\n",
      "          -1.1713e+00,  3.4523e-02,  6.2942e-01,  1.7210e+00, -7.8113e-01,\n",
      "           2.6983e+00, -1.4634e+00,  1.0762e+00,  1.4550e+00,  0.0000e+00,\n",
      "          -7.6263e-01,  1.2133e+00,  1.2752e-01, -1.4734e+00, -1.2888e-02,\n",
      "           0.0000e+00,  0.0000e+00, -1.0491e+00,  1.3106e+00, -1.6544e+00,\n",
      "           0.0000e+00, -5.6160e-02, -5.0196e-01, -1.9314e-01,  4.4465e-01,\n",
      "          -1.4676e+00,  7.0270e-01,  0.0000e+00, -7.2651e-01,  0.0000e+00,\n",
      "          -1.3099e+00,  8.9824e-01,  1.7069e-01,  1.2862e+00, -7.5299e-01,\n",
      "          -8.2317e-01,  5.2958e-01, -1.5838e+00,  9.8430e-01,  2.7620e-01,\n",
      "          -5.8975e-01,  6.6025e-01,  5.7309e-01, -1.1585e+00, -1.0110e+00,\n",
      "          -3.8925e-01,  6.7789e-01, -7.9035e-01, -1.0203e-01, -1.6869e+00,\n",
      "          -1.0160e-01,  0.0000e+00, -8.4468e-01, -7.5561e-01,  1.7740e-01,\n",
      "           1.9996e+00, -1.9991e-01, -1.9317e+00, -4.0633e-01,  4.4177e-01,\n",
      "          -1.9455e-01,  0.0000e+00, -1.2879e-01,  3.9555e-02,  5.3778e-01,\n",
      "          -2.6031e-02,  2.2070e+00,  4.8124e-01,  0.0000e+00, -5.2794e-01,\n",
      "          -8.9333e-01,  2.8187e-01,  8.5021e-02, -3.5804e-01, -4.7828e-01,\n",
      "           7.3876e-01, -3.2782e-02,  1.9793e-02, -1.0021e+00,  1.2781e+00,\n",
      "          -1.0996e+00, -9.8844e-01, -2.0786e+00,  1.9703e+00,  8.6393e-02,\n",
      "          -2.9495e-02,  3.5087e-02,  6.7195e-01,  9.7992e-01,  0.0000e+00,\n",
      "          -3.4106e-01, -2.7849e+00, -7.8516e-01,  1.2103e+00,  1.0127e+00,\n",
      "           3.0762e+00,  4.9464e-01, -1.4411e-01, -5.9519e-01,  0.0000e+00,\n",
      "           2.1664e+00, -1.1886e+00,  5.3472e-01,  1.8129e+00, -9.4800e-01,\n",
      "          -1.6624e+00, -1.0151e+00,  1.2417e+00, -1.2211e-01,  2.3186e-01,\n",
      "           0.0000e+00, -2.2938e+00,  6.8211e-01,  0.0000e+00, -4.7158e-01,\n",
      "           2.8695e+00, -5.7345e-01, -3.4118e-01,  7.9358e-01,  2.9718e-02,\n",
      "          -6.8523e-01, -1.0204e+00,  9.6627e-01, -2.4605e-01,  2.1706e+00,\n",
      "          -1.0832e+00, -4.2767e-01, -1.8447e+00, -5.0193e-01,  3.3684e-01,\n",
      "           7.0481e-01, -6.9663e-01, -6.2816e-01,  2.9231e-01, -1.5795e+00,\n",
      "           0.0000e+00,  1.5819e+00, -6.1448e-01,  1.3099e+00, -2.9810e+00,\n",
      "           4.0374e+00,  5.8519e-01,  4.3637e-02, -1.5814e+00, -2.8775e-01,\n",
      "           7.4154e-01, -3.2501e+00, -3.0493e-01, -8.5302e-01,  1.1032e-02,\n",
      "           2.7523e-01,  2.7519e-01,  2.5277e-01,  2.6085e-01,  3.8669e-01,\n",
      "          -3.6562e-01, -1.5820e-01,  0.0000e+00, -5.2722e-02, -1.1475e+00,\n",
      "          -1.1317e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0350, 0.0370, 0.0811, 0.0525, 0.1097, 0.3688, 0.0567, 0.0787, 0.0667,\n",
      "         0.1137]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3510, -0.0341,  0.0705,  ..., -0.1111, -0.0119, -0.4890],\n",
      "        [ 0.2941,  0.0492, -0.1791,  ..., -0.3276, -0.1117,  0.1317],\n",
      "        [ 0.0921,  0.1663,  0.1515,  ..., -0.0280,  0.0543,  0.3655],\n",
      "        ...,\n",
      "        [ 0.7550,  0.6273, -0.7582,  ..., -0.4888,  0.0111,  0.0884],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1745,  0.1440, -0.2434, -0.0301,  0.1458,  0.0190, -0.0559,\n",
      "          -0.0464,  0.0682,  0.1705, -0.1466, -0.2189, -0.1424, -0.2314,\n",
      "           0.0016, -0.0486,  0.2040, -0.0847, -0.2964, -0.2048, -0.2959,\n",
      "           0.0224, -0.0766, -0.1412, -0.1735, -0.1066,  0.1720,  0.0218,\n",
      "          -0.0404,  0.1384,  0.0625, -0.1304,  0.1775,  0.0234, -0.0201,\n",
      "          -0.1706, -0.1830,  0.1960, -0.3171,  0.0588,  0.1590,  0.0431,\n",
      "          -0.0259, -0.0983,  0.3038, -0.0688,  0.2073,  0.0253,  0.1972,\n",
      "          -0.0640, -0.3014, -0.0912, -0.1266,  0.0540, -0.2501,  0.0719,\n",
      "          -0.0531,  0.1815,  0.0997,  0.0365, -0.1234, -0.0765, -0.1755,\n",
      "           0.0541,  0.0619, -0.1959, -0.1166, -0.0621,  0.1711, -0.1103,\n",
      "           0.0578,  0.3363, -0.1606, -0.0031, -0.2764,  0.0325,  0.1790,\n",
      "           0.1074,  0.1164,  0.0569, -0.3717,  0.0371,  0.0950,  0.0395,\n",
      "           0.1488, -0.0636, -0.0428, -0.0257, -0.0295, -0.2251, -0.1464,\n",
      "           0.2479,  0.1920, -0.1579,  0.1257,  0.1072, -0.0800,  0.1497,\n",
      "           0.1603,  0.1099,  0.2185,  0.1176,  0.0304,  0.2838, -0.1267,\n",
      "          -0.2267, -0.2136, -0.0655, -0.0692,  0.0880,  0.1099,  0.0883,\n",
      "          -0.0532,  0.0320,  0.2198,  0.0175, -0.2054, -0.1260, -0.1064,\n",
      "           0.0459,  0.2059,  0.1743, -0.0745, -0.0690, -0.0536,  0.1141,\n",
      "          -0.0526,  0.1562,  0.4948, -0.0929, -0.0360, -0.1805,  0.0775,\n",
      "          -0.0052,  0.0654,  0.1283,  0.4213,  0.1294,  0.0085, -0.0345,\n",
      "          -0.1494, -0.0760,  0.0046,  0.4146,  0.0273,  0.1923,  0.0384,\n",
      "           0.2730, -0.2755,  0.1861, -0.2770, -0.0247,  0.0597,  0.4162,\n",
      "          -0.1281,  0.1812, -0.1545,  0.1969,  0.1402,  0.1512, -0.0487,\n",
      "          -0.0430, -0.1599, -0.0768, -0.2895,  0.0414, -0.1477,  0.0688,\n",
      "           0.1233,  0.1915,  0.0621,  0.1284, -0.0146, -0.1255,  0.2660,\n",
      "           0.1540,  0.0907, -0.1691,  0.2225, -0.0485, -0.1573, -0.0591,\n",
      "          -0.1476, -0.1635,  0.0794,  0.0245, -0.2737, -0.1216,  0.0900,\n",
      "          -0.1994, -0.1265,  0.1017, -0.2806,  0.0320,  0.0692, -0.0083,\n",
      "           0.1658,  0.0632, -0.1430,  0.2389,  0.0494, -0.1257, -0.2125,\n",
      "           0.2531,  0.0144,  0.0656, -0.1477,  0.0668, -0.0573, -0.1458,\n",
      "           0.2727, -0.1350, -0.2287, -0.0471, -0.0520,  0.0993,  0.0363,\n",
      "           0.2350, -0.1363,  0.2112,  0.0528, -0.1394,  0.2189, -0.2314,\n",
      "          -0.1963,  0.3122,  0.2213,  0.0685, -0.4607,  0.1469, -0.1777,\n",
      "          -0.3439,  0.1549, -0.0135, -0.1477, -0.3593, -0.3547, -0.0393,\n",
      "           0.1038,  0.1637,  0.2948, -0.1461, -0.0794,  0.0733,  0.2162,\n",
      "          -0.1486, -0.2328, -0.3930, -0.1776, -0.1582,  0.0611, -0.0043,\n",
      "           0.0760, -0.1305, -0.1705, -0.0610]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4822,  1.6545, -1.0096, -1.1127,  0.4005,  0.6461,\n",
      "          -1.2229, -0.9026,  0.0940, -0.2096,  0.3160,  0.1275, -0.9578,\n",
      "          -0.3087,  0.3245, -1.8656, -2.1366,  0.6083, -0.5294,  0.7694,\n",
      "           0.2827, -1.2566, -0.9731,  1.1927,  1.4268, -1.6558,  1.0544,\n",
      "           0.9847, -1.2881,  0.3070, -0.9457, -0.7691, -1.5224, -0.3683,\n",
      "           0.4844, -0.9884, -0.3514,  0.3283,  0.6284,  0.6072, -1.1772,\n",
      "           0.0000,  1.2540, -1.7957,  1.9479, -1.4978, -0.4432,  0.0000,\n",
      "           1.1467,  0.8653,  0.0373, -0.0720, -1.0045, -0.2960, -0.8050,\n",
      "          -1.8697,  0.0000,  1.5736,  0.0000, -0.8820, -0.7342,  1.9472,\n",
      "          -0.9066,  0.0000,  0.1077,  0.6391, -0.6175,  0.0216,  0.4295,\n",
      "          -1.5900, -0.0284, -0.6440,  1.4253, -0.4460,  0.5582, -3.6200,\n",
      "          -0.6177, -1.4069, -0.3113,  0.8704,  1.3129,  0.8813, -0.9604,\n",
      "           0.6941,  0.6928,  0.0459, -2.9902,  0.8148,  0.0000, -1.4909,\n",
      "           0.3247, -1.2889,  2.3927,  1.8842,  0.2151, -1.1099,  1.0777,\n",
      "           1.5510, -2.1250,  0.0145, -0.6644, -1.1343, -1.8824,  0.4073,\n",
      "           1.4168, -1.9889,  0.0000,  0.4129,  1.8169, -1.4327,  0.1792,\n",
      "          -0.4981,  1.3010, -0.1468, -0.1097,  0.3372, -1.6432,  0.8517,\n",
      "          -1.2945, -1.3469, -0.0997,  0.8780,  0.5349,  0.2246,  0.8186,\n",
      "          -0.2019, -1.0698,  0.1249, -0.4280, -1.2474,  0.0000,  1.4194,\n",
      "           0.3274, -0.0087, -0.6389, -0.0633, -0.6000, -0.4514,  0.0000,\n",
      "           0.5454, -1.1804, -2.2953, -0.8862,  0.2163, -0.1882,  0.9174,\n",
      "          -0.0827,  1.5431, -0.7186,  0.0000, -1.3513,  1.8151, -1.9313,\n",
      "           0.5129, -0.3341, -0.2284, -0.7583,  0.0000, -0.0177,  0.2299,\n",
      "          -1.1454,  2.2621, -1.7651, -0.3903, -0.6924,  0.5301,  2.1362,\n",
      "          -1.6406, -2.7425,  0.0000, -2.0860, -0.0067, -1.1603, -0.9215,\n",
      "          -0.7988, -0.3072, -0.4307,  0.1183, -1.5139,  0.1504, -0.4527,\n",
      "           0.1997,  0.9702,  0.4844, -0.0759, -1.5030, -0.2144,  0.4041,\n",
      "          -1.4629,  1.0721,  0.6062,  0.5036, -0.5086,  0.7253, -0.0426,\n",
      "           1.8721,  0.0000, -0.8384, -0.2757,  0.1195, -0.2978,  0.2825,\n",
      "           0.3537, -0.0092, -0.7150,  0.6958,  2.0169, -0.7502,  1.8923,\n",
      "           2.7904,  0.1561,  1.5050,  0.1014, -0.5909,  0.0000, -0.1429,\n",
      "          -1.3821,  0.4079,  0.6380, -0.6886,  1.8594,  0.6064,  0.4726,\n",
      "           0.0285,  1.5296, -0.3652,  0.0000,  0.8417, -0.2545,  0.7763,\n",
      "           0.0000,  1.2383,  0.0932,  2.0765,  0.5544, -1.7046,  2.7792,\n",
      "          -1.4959,  1.8028, -0.8496,  0.2566, -1.0501, -0.8547,  0.1356,\n",
      "           0.0000,  0.3817,  0.0000,  0.5689,  0.5473, -1.7500,  0.3685,\n",
      "           0.1555,  1.5691, -2.7266,  0.4075]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0319, 0.1286, 0.0784, 0.0600, 0.1724, 0.2306, 0.0515, 0.0667, 0.1144,\n",
      "         0.0655]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3510, -0.0341,  0.0705,  ..., -0.1111, -0.0119, -0.4890],\n",
      "        [ 0.2941,  0.0492, -0.1791,  ..., -0.3276, -0.1117,  0.1317],\n",
      "        [ 0.0921,  0.1663,  0.1515,  ..., -0.0280,  0.0543,  0.3655],\n",
      "        ...,\n",
      "        [ 0.7550,  0.6273, -0.7582,  ..., -0.4888,  0.0111,  0.0884],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.8363e-01,  9.0080e-02, -2.4729e-01, -4.6946e-02,  1.8397e-01,\n",
      "           9.1222e-02, -1.0290e-01, -6.6551e-02,  3.4343e-02,  2.3119e-01,\n",
      "          -9.2287e-02, -2.2674e-01, -1.0708e-01, -2.1880e-01,  1.7680e-02,\n",
      "           1.0120e-01,  1.7286e-01, -4.9082e-02, -2.6710e-01, -2.2933e-01,\n",
      "          -3.0727e-01, -1.7349e-02, -1.1284e-01, -8.1118e-02, -1.1109e-01,\n",
      "          -7.0062e-02,  1.4385e-01,  1.6013e-02, -5.3398e-02,  8.9457e-02,\n",
      "           2.1206e-02, -8.2651e-02,  1.5158e-01, -7.1523e-03,  8.8423e-03,\n",
      "          -1.4730e-01, -1.6089e-01,  1.9687e-01, -2.5369e-01,  5.2471e-02,\n",
      "           1.2962e-01,  1.0900e-01, -1.8556e-02, -1.3278e-01,  2.4588e-01,\n",
      "          -2.4485e-02,  1.4503e-01,  1.8104e-02,  1.6834e-01, -8.2916e-03,\n",
      "          -2.0964e-01, -1.5963e-01, -6.7864e-03,  7.9963e-02, -2.8739e-01,\n",
      "           8.3087e-02, -6.0597e-02,  1.9474e-01,  1.0797e-01, -1.9749e-02,\n",
      "          -1.2702e-01, -1.3150e-01, -1.5455e-01,  3.6330e-02,  8.5081e-02,\n",
      "          -1.7984e-01, -1.1660e-01, -1.4203e-01,  1.2237e-01, -1.5134e-01,\n",
      "           1.4324e-01,  3.4345e-01, -1.3127e-01, -2.9320e-02, -2.1833e-01,\n",
      "           4.6831e-02,  1.4929e-01,  1.0475e-01,  7.2312e-02,  5.9770e-02,\n",
      "          -2.8701e-01,  7.4325e-02,  1.6742e-02,  7.4270e-02,  1.0659e-01,\n",
      "          -5.3780e-02, -2.4357e-02,  4.8775e-02, -7.2047e-02, -1.9437e-01,\n",
      "          -8.7626e-02,  2.3851e-01,  8.2417e-02, -1.9279e-01,  1.7577e-01,\n",
      "           1.6775e-01, -6.6797e-02,  2.2939e-01,  1.2170e-01,  5.1496e-02,\n",
      "           2.1037e-01,  1.1723e-01,  2.8225e-02,  2.3702e-01, -1.0035e-01,\n",
      "          -2.5091e-01, -2.1794e-01, -6.1122e-02, -7.2848e-02,  4.5170e-02,\n",
      "           1.0901e-01,  4.9318e-02, -1.0289e-01,  5.8392e-02,  2.0504e-01,\n",
      "           1.0462e-02, -9.9595e-02, -1.5481e-01, -1.2863e-01,  2.6937e-02,\n",
      "           2.5866e-01,  1.3505e-01, -7.2417e-02, -8.3396e-03, -1.8984e-02,\n",
      "           3.9319e-02, -6.3468e-02,  1.3558e-01,  4.5691e-01, -4.6301e-02,\n",
      "          -1.8548e-02, -1.3910e-01,  8.9058e-02,  1.1769e-04,  5.8448e-03,\n",
      "           7.1058e-02,  3.5110e-01,  1.1115e-01,  7.6221e-03, -4.1389e-02,\n",
      "          -1.2712e-01, -5.2318e-02, -8.0842e-02,  3.6860e-01,  1.9227e-02,\n",
      "           1.3047e-01,  1.0237e-01,  3.3066e-01, -2.3587e-01,  1.1016e-01,\n",
      "          -3.3581e-01, -5.7849e-02,  1.6596e-02,  3.6212e-01, -1.1306e-01,\n",
      "           1.3127e-01, -1.3004e-01,  2.2013e-01,  1.0356e-01,  2.0198e-01,\n",
      "          -1.0990e-01, -7.3642e-03, -1.8920e-01, -2.3668e-02, -2.6526e-01,\n",
      "           1.6417e-02, -1.5977e-01,  1.1429e-01,  1.3565e-01,  1.9925e-01,\n",
      "           2.7728e-02,  2.0053e-01, -2.7865e-02, -4.4952e-02,  2.0922e-01,\n",
      "           1.8398e-01,  1.1475e-01, -9.7796e-02,  2.1360e-01, -9.3050e-03,\n",
      "          -8.6981e-02, -5.1849e-02, -1.5331e-01, -1.4211e-01,  7.6710e-02,\n",
      "          -4.6915e-03, -2.2174e-01, -1.3451e-01,  6.2339e-02, -1.3992e-01,\n",
      "          -1.0151e-01,  8.1023e-02, -1.8937e-01,  3.3631e-02,  9.9111e-03,\n",
      "          -3.4354e-02,  5.7294e-02, -6.9027e-03, -2.1254e-01,  2.0531e-01,\n",
      "           2.7177e-02, -1.1453e-01, -9.2854e-02,  2.5531e-01, -4.2827e-02,\n",
      "           8.1160e-02, -1.5817e-01,  6.2552e-03, -9.3388e-02, -1.3114e-01,\n",
      "           2.5910e-01, -8.0100e-02, -2.1254e-01,  3.4789e-02,  3.7401e-03,\n",
      "           1.9811e-02,  4.9327e-02,  2.1701e-01, -1.7759e-01,  1.6937e-01,\n",
      "           1.0202e-01, -1.2868e-01,  2.3740e-01, -2.3654e-01, -1.5478e-01,\n",
      "           2.6403e-01,  2.1069e-01,  8.4527e-02, -4.6429e-01,  1.4125e-01,\n",
      "          -1.7818e-01, -3.2321e-01,  1.3030e-01, -5.4757e-02, -1.7800e-01,\n",
      "          -3.7782e-01, -3.6945e-01,  1.0306e-02,  1.3624e-01,  1.3866e-01,\n",
      "           2.7881e-01, -1.4864e-01, -5.0610e-02,  6.4589e-02,  1.4196e-01,\n",
      "          -1.3467e-01, -2.8152e-01, -2.9254e-01, -2.2799e-01, -1.2225e-01,\n",
      "           9.3658e-02,  1.0025e-02,  9.0117e-02, -1.5884e-01, -1.3002e-01,\n",
      "           1.3312e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2551,  0.7780, -1.6521, -0.1827, -0.7320,  2.5183, -1.9079,\n",
      "           0.0000,  0.9501,  0.0000,  1.4105, -0.7568, -0.0648,  0.0644,\n",
      "           1.0464,  1.8855,  0.8702, -0.7850, -0.6404, -1.4036, -0.4984,\n",
      "           0.0000,  1.1428,  0.2329,  0.1891, -0.6130,  1.4043, -0.1509,\n",
      "          -1.0410,  0.4961, -0.5710,  0.6007, -1.6989,  0.0000, -0.0795,\n",
      "           0.0000,  0.6453, -2.2136,  0.0000,  0.1026, -0.6922, -0.4369,\n",
      "          -1.0646,  0.8179, -0.6328, -0.6567,  0.0000,  0.9368,  1.6036,\n",
      "           0.3695, -1.0083, -1.1716, -1.1122,  1.2529, -1.9749,  1.7090,\n",
      "           0.5928, -1.8923,  0.3413, -0.2935, -0.7705,  0.0000, -0.5944,\n",
      "          -1.6817, -0.8356,  1.2344, -0.3575,  0.2895,  0.0000, -1.1649,\n",
      "           2.2476,  0.7809,  0.2705,  1.2050, -0.3977,  0.3546,  0.2293,\n",
      "          -0.1574, -0.9147,  0.2958, -0.1448,  1.2867,  0.4651,  0.0000,\n",
      "           0.7704,  0.6605,  1.0452, -0.3684, -1.2410, -1.4366,  1.3107,\n",
      "          -1.5853, -0.1111,  3.2391,  0.3468,  1.0035, -0.8686,  0.7312,\n",
      "          -1.6815, -0.9245,  0.1905,  0.0283,  0.0000,  1.0585, -0.2310,\n",
      "           0.7758, -0.9056, -0.3676, -0.2786,  0.0000,  0.0000, -3.2779,\n",
      "          -0.1010, -1.8785,  1.6979,  1.6884,  2.0296, -1.6462, -0.8959,\n",
      "           2.5846, -1.3266,  1.4236, -0.6277,  0.4666,  1.3155, -0.9876,\n",
      "           0.0742, -0.9857, -0.6748,  0.2477, -1.2004,  1.1297,  1.1404,\n",
      "           1.4885,  0.3790,  0.6465, -0.8377,  0.2410,  0.0000, -1.2618,\n",
      "           0.0301,  0.8642,  0.5014,  0.9071, -1.2679, -0.6411, -0.4417,\n",
      "           0.8729,  0.0000,  0.0423, -0.0564,  0.6207,  0.1450, -0.1964,\n",
      "           0.1078, -1.6721, -0.4023,  0.2512, -2.0700,  0.4118,  1.1554,\n",
      "           0.1996,  0.9131,  0.8435,  0.4172,  1.6036,  0.1770, -1.1141,\n",
      "          -0.3226,  0.2508,  0.4453, -0.4554,  0.4444, -1.3453,  1.7357,\n",
      "           0.5175,  1.1771,  0.2894, -1.8322, -1.8661,  0.2595, -0.6475,\n",
      "          -1.1656,  0.0000, -0.7440,  0.5920, -1.2419, -1.5179, -2.3034,\n",
      "           0.1462, -1.6242, -1.3209, -0.0503,  1.2995,  0.9805, -1.4148,\n",
      "          -1.1404,  3.0135, -0.2258,  1.0325,  0.0295,  0.1188, -1.3199,\n",
      "          -1.0708,  0.0566,  1.7328,  0.5269,  1.9826,  0.0000, -1.3426,\n",
      "           1.5997, -0.4016,  2.4612,  0.0000,  0.7546,  0.2063, -0.8213,\n",
      "           0.9056,  0.0000,  0.1761, -0.7814, -0.6932, -1.4186,  0.2510,\n",
      "          -0.0650, -1.4655,  0.4271, -0.5201,  0.0462, -0.6255, -0.0714,\n",
      "           0.7483, -2.0270, -1.0490, -0.4317, -0.1119,  0.5160, -2.7971,\n",
      "          -1.4580,  0.0000,  1.0259,  0.1325,  2.7511,  1.0025,  0.5470,\n",
      "          -0.1733,  0.0000,  2.2319,  1.1873, -0.0479,  0.0000,  0.1091,\n",
      "          -2.8556,  0.0000, -0.8378, -0.5804]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0420, 0.1414, 0.1198, 0.1062, 0.1171, 0.1043, 0.0637, 0.0798, 0.1320,\n",
      "         0.0937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3510, -0.0341,  0.0705,  ..., -0.1111, -0.0119, -0.4890],\n",
      "        [ 0.2941,  0.0492, -0.1791,  ..., -0.3276, -0.1117,  0.1317],\n",
      "        [ 0.0921,  0.1663,  0.1515,  ..., -0.0280,  0.0543,  0.3655],\n",
      "        ...,\n",
      "        [ 0.7550,  0.6273, -0.7582,  ..., -0.4888,  0.0111,  0.0884],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1961,  0.0633, -0.2253, -0.0320,  0.1400,  0.1124, -0.1418,\n",
      "          -0.0943,  0.0315,  0.2101, -0.0785, -0.2120, -0.1185, -0.1714,\n",
      "           0.0331,  0.1821,  0.1428,  0.0095, -0.2651, -0.1870, -0.3010,\n",
      "          -0.0456, -0.1040, -0.0326, -0.1013, -0.0749,  0.1126, -0.0286,\n",
      "          -0.0847,  0.0348,  0.0110, -0.0425,  0.1051, -0.0267, -0.0049,\n",
      "          -0.1244, -0.1676,  0.1217, -0.2060,  0.0179,  0.1038,  0.1486,\n",
      "          -0.0200, -0.1205,  0.2095, -0.0032,  0.0719,  0.0047,  0.1672,\n",
      "           0.0306, -0.2072, -0.2189,  0.0243,  0.0470, -0.3006,  0.0767,\n",
      "          -0.0543,  0.2282,  0.1326,  0.0314, -0.1109, -0.1592, -0.1529,\n",
      "           0.0509,  0.0917, -0.1123, -0.0805, -0.1588,  0.0358, -0.1663,\n",
      "           0.1922,  0.3363, -0.1213, -0.0435, -0.1875,  0.0642,  0.1984,\n",
      "           0.0859,  0.0239,  0.0417, -0.2907,  0.0436, -0.0639,  0.0867,\n",
      "           0.0660, -0.0193,  0.0123,  0.0883, -0.0555, -0.1294, -0.0198,\n",
      "           0.2045,  0.0044, -0.1739,  0.1695,  0.2069,  0.0123,  0.2900,\n",
      "           0.0588,  0.0569,  0.1102,  0.1544,  0.0730,  0.1607, -0.0945,\n",
      "          -0.2224, -0.1461, -0.0390, -0.1217,  0.0534,  0.0781,  0.0369,\n",
      "          -0.0764,  0.0416,  0.1519,  0.0049,  0.0070, -0.1688, -0.1102,\n",
      "          -0.0243,  0.2646,  0.0668, -0.0778,  0.0362, -0.0702, -0.0657,\n",
      "          -0.0424,  0.0730,  0.4312, -0.0061, -0.0055, -0.1042,  0.1233,\n",
      "           0.0293, -0.1025,  0.0515,  0.3329,  0.1029,  0.0233,  0.0125,\n",
      "          -0.0795,  0.0576, -0.1118,  0.3271,  0.0117,  0.0912,  0.1768,\n",
      "           0.3559, -0.1817,  0.0727, -0.3699, -0.0842,  0.0362,  0.3238,\n",
      "          -0.0663,  0.1432, -0.0679,  0.2431,  0.0776,  0.1958, -0.1576,\n",
      "           0.0019, -0.2045,  0.0753, -0.2178, -0.0108, -0.1630,  0.0990,\n",
      "           0.1001,  0.2244, -0.0292,  0.1892,  0.0125,  0.0365,  0.1540,\n",
      "           0.1505,  0.0762, -0.0449,  0.2172, -0.0021, -0.0653, -0.0099,\n",
      "          -0.1801, -0.1162,  0.1047, -0.0082, -0.1584, -0.0984,  0.0363,\n",
      "          -0.1487, -0.0781,  0.0489, -0.1479, -0.0118, -0.0246, -0.0285,\n",
      "          -0.0030, -0.0482, -0.2349,  0.1682, -0.0081, -0.0675, -0.0201,\n",
      "           0.2438, -0.0575,  0.0607, -0.1358,  0.0024, -0.0979, -0.1050,\n",
      "           0.2327, -0.0698, -0.1764,  0.0879,  0.0183, -0.0226,  0.0765,\n",
      "           0.2074, -0.2423,  0.1091,  0.1558, -0.1304,  0.2679, -0.2165,\n",
      "          -0.1039,  0.2643,  0.2063,  0.0419, -0.4579,  0.1450, -0.2014,\n",
      "          -0.3068,  0.0860, -0.0792, -0.1664, -0.3550, -0.3263,  0.0119,\n",
      "           0.1662,  0.1130,  0.2290, -0.1250, -0.1018,  0.0717,  0.1358,\n",
      "          -0.1346, -0.3002, -0.2060, -0.2400, -0.0730,  0.1018,  0.0356,\n",
      "           0.0497, -0.1532, -0.0602,  0.0227]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5703e+00, -1.4753e+00,  2.2747e-01, -7.8503e-02,  3.5252e-01,\n",
      "           5.5341e-01, -2.0051e-01,  2.0888e+00,  1.3115e+00, -1.0356e+00,\n",
      "           6.8481e-01,  2.1685e+00,  1.1880e+00, -8.0517e-01, -1.0888e-01,\n",
      "          -1.1277e+00,  0.0000e+00, -2.9147e-01,  8.4828e-03,  4.2638e-01,\n",
      "          -1.9755e+00, -1.8382e+00, -1.2584e+00,  1.9421e-01, -1.6698e-01,\n",
      "           1.3755e+00, -2.9784e-01, -9.7439e-01,  0.0000e+00,  7.8351e-01,\n",
      "           3.4933e-01,  3.1152e-01,  5.3680e-01,  9.4191e-01,  6.9767e-01,\n",
      "           4.5391e-01, -2.8989e+00,  6.7955e-02,  3.9907e-02,  1.2315e+00,\n",
      "          -7.2213e-01, -1.0137e+00,  2.4816e-01,  1.0037e+00,  6.7117e-02,\n",
      "           3.1144e-01, -1.0371e+00, -1.1821e+00, -4.4481e-01, -1.6405e+00,\n",
      "          -1.5657e+00,  3.1699e+00,  8.6340e-01,  7.6400e-01,  2.2065e+00,\n",
      "           5.5896e-01,  5.9272e-01,  5.6766e-01, -7.5504e-01,  4.1319e-01,\n",
      "           6.2639e-01, -7.1974e-01, -3.6513e-01,  8.9450e-01, -1.3382e+00,\n",
      "           2.3298e+00, -2.4167e+00,  0.0000e+00,  1.1606e+00, -7.1801e-01,\n",
      "           0.0000e+00,  5.5117e-01,  1.8993e-01,  2.3226e-02,  4.0865e-01,\n",
      "           0.0000e+00, -4.8588e-01,  4.3278e-01, -1.3788e+00, -2.4958e+00,\n",
      "           0.0000e+00,  4.0200e-01,  4.9736e-01, -3.8159e-01, -2.3206e+00,\n",
      "           0.0000e+00, -6.3279e-01,  1.8183e+00, -1.9083e+00, -6.5424e-01,\n",
      "          -4.3664e-01, -6.6932e-01, -1.9175e+00,  1.0182e+00, -1.3664e+00,\n",
      "          -1.1212e+00,  2.1716e-01,  1.7942e-02,  3.0416e-01,  7.6356e-01,\n",
      "           9.4163e-01,  9.3351e-01,  2.2438e-01, -1.6316e+00,  2.2440e+00,\n",
      "          -1.4412e-01,  1.2461e-01, -1.0129e+00, -1.2048e+00, -1.4856e+00,\n",
      "          -1.5565e+00, -1.3434e+00,  1.5146e-01, -1.7880e+00, -1.1430e+00,\n",
      "          -1.0661e+00, -1.7874e+00, -1.2148e-01, -1.8688e+00,  9.4009e-02,\n",
      "           6.7204e-01,  5.5180e-01,  1.5532e+00,  4.8413e-01,  1.2908e-01,\n",
      "           5.8228e-01,  7.9535e-01,  5.8578e-02,  3.9308e-01, -5.9738e-02,\n",
      "          -8.6248e-02, -5.3688e-01,  7.0340e-01,  1.1586e+00,  3.2934e-01,\n",
      "          -2.5086e-01,  1.1916e-01, -1.3306e+00, -3.6592e-01, -7.7343e-01,\n",
      "          -5.9706e-01, -1.4721e+00, -1.1961e+00,  2.9617e-02,  5.0127e-01,\n",
      "           2.5935e-01,  1.2103e+00,  1.2554e+00,  0.0000e+00,  0.0000e+00,\n",
      "           7.8796e-02, -5.5410e-02, -7.0962e-01,  1.5831e+00,  0.0000e+00,\n",
      "           2.7990e-01,  1.1350e+00,  3.0536e-01,  2.6068e-01,  1.4422e+00,\n",
      "          -1.7486e-01,  6.8407e-01, -2.1216e-01, -7.2111e-01, -4.6788e-01,\n",
      "          -9.4144e-01,  3.2961e-01,  0.0000e+00,  1.7294e+00,  7.0249e-01,\n",
      "           3.1424e+00,  2.0555e+00,  5.6332e-01,  1.0313e-01, -3.9335e-01,\n",
      "          -9.6629e-01, -4.0507e-01,  1.1920e+00, -2.6503e-01,  0.0000e+00,\n",
      "          -1.3468e-01, -1.2908e-02, -6.0205e-01, -1.5680e+00, -1.8515e+00,\n",
      "          -1.6862e-01,  6.8109e-03,  1.3397e+00,  1.2953e+00,  7.3876e-01,\n",
      "           9.6800e-01,  1.6024e-01, -5.3611e-01,  5.3550e-01, -4.7141e-02,\n",
      "           0.0000e+00, -1.5638e+00,  3.1396e+00, -1.0837e+00, -4.6132e-02,\n",
      "           8.1017e-01, -2.1875e+00,  0.0000e+00,  1.4470e+00, -9.9697e-01,\n",
      "           9.7209e-01, -1.6694e+00, -6.1194e-01, -9.3266e-01, -1.1371e+00,\n",
      "           8.7227e-01,  7.9530e-02, -1.3189e+00, -7.9114e-01,  1.3114e+00,\n",
      "           0.0000e+00,  1.3732e+00,  2.4499e-01, -2.3519e+00,  1.9031e+00,\n",
      "           1.0279e+00,  0.0000e+00,  1.7823e+00,  1.0654e+00, -5.7290e-01,\n",
      "          -5.7360e-01, -1.5896e+00,  1.5561e-03, -3.3779e-01, -2.9544e+00,\n",
      "          -6.4344e-01,  1.5654e+00,  9.3348e-02, -6.2742e-01,  1.6770e+00,\n",
      "           2.2890e+00,  0.0000e+00,  3.2576e-01,  1.5121e+00, -5.3524e-01,\n",
      "          -1.8332e+00,  0.0000e+00, -1.1126e-01,  1.4428e+00, -4.7755e-01,\n",
      "           1.4840e+00, -5.8513e-01,  7.7599e-01, -1.4380e+00, -2.5946e-01,\n",
      "           4.3564e-01,  3.1986e-01, -3.3688e-01,  1.6172e+00,  2.5955e-01,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0602, 0.1471, 0.0514, 0.0624, 0.2897, 0.0943, 0.1019, 0.0777, 0.0483,\n",
      "         0.0672]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3510, -0.0341,  0.0705,  ..., -0.1111, -0.0119, -0.4890],\n",
      "        [ 0.2941,  0.0492, -0.1791,  ..., -0.3276, -0.1117,  0.1317],\n",
      "        [ 0.0921,  0.1663,  0.1515,  ..., -0.0280,  0.0543,  0.3655],\n",
      "        ...,\n",
      "        [ 0.7550,  0.6273, -0.7582,  ..., -0.4888,  0.0111,  0.0884],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2334,  0.0485, -0.3033, -0.0801,  0.2399,  0.1099, -0.1228,\n",
      "          -0.0820, -0.0198,  0.2636, -0.0399, -0.2465, -0.0956, -0.1857,\n",
      "           0.0574,  0.1936,  0.1493,  0.0088, -0.2894, -0.2472, -0.3441,\n",
      "          -0.0857, -0.1175, -0.0617, -0.0691, -0.0533,  0.1437, -0.0122,\n",
      "          -0.0634,  0.0667,  0.0475, -0.0883,  0.1234, -0.0780,  0.0414,\n",
      "          -0.1649, -0.1702,  0.2152, -0.2414,  0.0846,  0.0953,  0.1685,\n",
      "          -0.0096, -0.1749,  0.2046,  0.0487,  0.1320, -0.0063,  0.1536,\n",
      "          -0.0242, -0.1281, -0.2236,  0.0671,  0.0873, -0.3245,  0.1048,\n",
      "          -0.0667,  0.1799,  0.1069, -0.0542, -0.1314, -0.2112, -0.1625,\n",
      "           0.0613,  0.0518, -0.2005, -0.1620, -0.1885,  0.0572, -0.1442,\n",
      "           0.2239,  0.3753, -0.1319, -0.0142, -0.2134,  0.0905,  0.1228,\n",
      "           0.1694,  0.0558,  0.0928, -0.2055,  0.0889, -0.0641,  0.1166,\n",
      "           0.0890, -0.0223,  0.0121,  0.0932, -0.0502, -0.1904, -0.0453,\n",
      "           0.2350, -0.0181, -0.2168,  0.2200,  0.2330, -0.0791,  0.3020,\n",
      "           0.1332,  0.0278,  0.2112,  0.1133,  0.0291,  0.2420, -0.0689,\n",
      "          -0.2802, -0.2201, -0.0229, -0.0560,  0.0219,  0.1150,  0.0234,\n",
      "          -0.1675,  0.0650,  0.1948,  0.0052, -0.0561, -0.1897, -0.1667,\n",
      "           0.0099,  0.3309,  0.1333, -0.1249,  0.0614,  0.0036, -0.0018,\n",
      "          -0.0986,  0.0921,  0.4579, -0.0416,  0.0234, -0.1776,  0.1136,\n",
      "           0.0382,  0.0295,  0.0401,  0.3125,  0.1201, -0.0110, -0.0193,\n",
      "          -0.1226, -0.0445, -0.2057,  0.3755,  0.0314,  0.0775,  0.1360,\n",
      "           0.4147, -0.2112,  0.1066, -0.4472, -0.0362, -0.0577,  0.3560,\n",
      "          -0.0745,  0.1510, -0.1201,  0.2525,  0.1061,  0.2443, -0.1838,\n",
      "          -0.0141, -0.2901,  0.0169, -0.2778,  0.0190, -0.2116,  0.1459,\n",
      "           0.1525,  0.1851, -0.0111,  0.2785, -0.0393,  0.0119,  0.1531,\n",
      "           0.1763,  0.1475, -0.0522,  0.2393, -0.0128, -0.0406, -0.0735,\n",
      "          -0.1829, -0.1460,  0.1004, -0.0428, -0.2407, -0.1497,  0.0598,\n",
      "          -0.1021, -0.0769,  0.0774, -0.1489,  0.0276, -0.0423, -0.0698,\n",
      "          -0.0029, -0.0354, -0.2853,  0.1764,  0.0218, -0.1379, -0.0464,\n",
      "           0.2964, -0.0908,  0.0570, -0.1819,  0.0154, -0.1361, -0.1782,\n",
      "           0.2537, -0.0579, -0.2240,  0.1025,  0.0373, -0.0327,  0.0314,\n",
      "           0.2339, -0.2010,  0.1593,  0.1871, -0.1309,  0.2623, -0.2483,\n",
      "          -0.1317,  0.2435,  0.1991,  0.0503, -0.5104,  0.1685, -0.1784,\n",
      "          -0.3345,  0.0786, -0.1353, -0.1923, -0.4080, -0.4130,  0.0705,\n",
      "           0.1917,  0.1394,  0.2666, -0.1775, -0.0259,  0.0490,  0.1184,\n",
      "          -0.1152, -0.3159, -0.2956, -0.2569, -0.1307,  0.1585,  0.0301,\n",
      "           0.0935, -0.2195, -0.0741,  0.0654]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.8081e+00, -5.2285e-01,  9.9690e-01,  0.0000e+00,  8.0510e-01,\n",
      "           0.0000e+00, -1.8016e+00,  3.9169e-01, -3.9311e-01, -6.3923e-01,\n",
      "          -4.3637e-01,  1.2693e+00,  3.2653e+00, -9.8531e-02,  1.2611e+00,\n",
      "           1.0131e+00,  2.4619e-01, -1.8152e+00,  0.0000e+00,  4.4100e-01,\n",
      "          -6.0529e-01,  1.2529e+00,  0.0000e+00, -8.1104e-02,  2.0973e+00,\n",
      "           0.0000e+00,  1.1440e+00, -7.8120e-04, -1.8630e-01,  2.0641e+00,\n",
      "          -9.4405e-01, -6.2337e-01, -8.0589e-01,  4.7616e-01,  9.7471e-01,\n",
      "           9.6665e-01,  0.0000e+00, -9.4804e-01,  2.4937e+00,  3.4798e-01,\n",
      "           0.0000e+00, -1.2681e+00, -6.4432e-01,  3.7319e-02, -3.0872e-01,\n",
      "           5.5961e-01,  0.0000e+00,  7.8624e-02,  4.3852e-01,  5.7523e-01,\n",
      "          -3.5414e-01,  1.2922e+00,  4.4519e-01,  1.0790e+00,  1.0529e+00,\n",
      "          -6.1729e-01, -7.4765e-01,  4.2724e-01,  0.0000e+00,  1.3508e+00,\n",
      "          -2.1787e+00, -1.7041e+00, -2.6782e-01,  9.8560e-01, -3.0093e+00,\n",
      "          -1.4843e+00,  2.7939e-03,  8.8062e-01, -8.3522e-01, -1.3186e-01,\n",
      "          -5.8811e-02,  4.7845e-01,  3.5235e-02, -4.3724e-01, -3.4770e-01,\n",
      "          -1.3496e+00, -1.2503e+00,  9.0011e-01,  1.6579e-01, -1.8685e-01,\n",
      "          -1.6289e+00,  3.8315e+00,  1.3239e+00,  4.4889e-01, -1.0581e+00,\n",
      "          -1.1322e+00,  3.3256e-02, -7.8621e-01,  4.1296e-01, -2.9005e-01,\n",
      "          -2.4775e+00,  4.2414e-01,  0.0000e+00, -2.4835e-01, -2.7657e-01,\n",
      "          -4.0647e-03, -1.9461e+00,  4.8251e-01,  7.7048e-02,  9.3615e-01,\n",
      "          -6.7954e-01, -8.0993e-01,  8.7176e-01, -1.3502e+00,  1.0823e+00,\n",
      "          -1.9755e-01,  0.0000e+00, -7.8585e-01, -5.1859e-01, -6.3551e-01,\n",
      "           1.0919e+00,  1.5895e+00,  4.6935e-01, -6.9188e-01, -4.5862e-01,\n",
      "          -1.1070e+00, -6.0291e-01,  7.8969e-01,  8.4111e-01, -1.4465e+00,\n",
      "           0.0000e+00,  0.0000e+00, -1.9085e+00, -3.9049e-01,  0.0000e+00,\n",
      "           2.9099e-01,  1.7461e+00,  1.1843e+00,  2.1905e-01,  1.0290e+00,\n",
      "          -7.8478e-01,  8.3278e-01,  6.4871e-01, -3.8302e-01,  2.1418e+00,\n",
      "          -2.8626e-01,  2.5863e+00, -7.8506e-01,  8.6298e-01,  2.8382e-01,\n",
      "          -5.0574e-01, -6.1693e-01,  6.7486e-01, -7.0901e-01, -1.1251e+00,\n",
      "           0.0000e+00,  0.0000e+00, -2.2282e-03,  8.7732e-01,  8.0916e-01,\n",
      "           1.7921e+00,  9.5738e-01,  9.9564e-01, -5.2807e-01, -1.2850e+00,\n",
      "          -6.7338e-01, -1.2646e+00,  3.9124e-01,  7.2316e-01, -2.0582e+00,\n",
      "          -8.9043e-01,  0.0000e+00, -1.0853e+00, -8.6325e-02,  2.8439e-01,\n",
      "          -1.1605e+00, -3.6238e-01,  5.8419e-01,  4.7800e-01,  2.9885e-01,\n",
      "          -1.9848e+00,  3.5877e-01,  1.1840e+00, -1.8167e+00, -1.6615e+00,\n",
      "           8.2704e-01, -2.0325e+00, -1.1485e+00, -1.6293e-01, -1.0227e+00,\n",
      "           7.7912e-01, -2.1568e-01, -3.0906e-01,  1.8124e-01,  7.4813e-01,\n",
      "           7.4801e-01, -2.5952e-01,  1.7882e-01, -1.4154e+00,  2.7858e-01,\n",
      "           1.5772e+00,  5.6065e-01, -2.1479e+00, -1.2114e+00,  2.9404e+00,\n",
      "           1.4769e-01, -2.0049e-01, -3.1044e-01, -9.2182e-02, -8.3726e-01,\n",
      "          -1.6186e+00,  9.1458e-01,  1.0162e+00,  1.6939e+00,  5.4406e-02,\n",
      "           9.5864e-01,  6.6769e-01,  5.4354e-01, -9.3195e-01, -1.5256e+00,\n",
      "           1.0124e+00,  6.7132e-01,  4.6853e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -6.6291e-01, -7.1018e-01,  5.9283e-01,  1.3801e+00, -1.1349e+00,\n",
      "          -1.7686e+00, -1.0757e+00, -1.3857e+00,  1.3251e-01, -1.1518e+00,\n",
      "          -1.5345e+00, -6.3681e-01,  1.4858e-01,  0.0000e+00, -7.7463e-01,\n",
      "           1.2034e+00,  5.3080e-01,  1.7976e+00,  4.7067e-01,  1.3224e+00,\n",
      "           2.8272e+00, -1.6091e-01, -8.6646e-01,  0.0000e+00,  1.1098e+00,\n",
      "          -4.6958e-01, -8.9662e-01, -1.1485e-01,  6.5625e-01,  1.0481e+00,\n",
      "           2.3666e-01, -4.2704e-01, -1.2607e-01,  0.0000e+00,  8.5215e-02,\n",
      "          -3.7615e-01, -4.6659e-01,  6.5852e-01,  2.4090e+00,  2.4293e+00,\n",
      "          -4.8681e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0433, 0.0675, 0.0531, 0.1769, 0.1640, 0.1890, 0.0465, 0.0953, 0.0983,\n",
      "         0.0662]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3510, -0.0341,  0.0705,  ..., -0.1111, -0.0119, -0.4890],\n",
      "        [ 0.2941,  0.0492, -0.1791,  ..., -0.3276, -0.1117,  0.1317],\n",
      "        [ 0.0921,  0.1663,  0.1515,  ..., -0.0280,  0.0543,  0.3655],\n",
      "        ...,\n",
      "        [ 0.7550,  0.6273, -0.7582,  ..., -0.4888,  0.0111,  0.0884],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1919,  0.0462, -0.3050, -0.0131,  0.1160,  0.0564, -0.0897,\n",
      "          -0.0789,  0.0517,  0.2156, -0.1032, -0.2368, -0.1279, -0.1973,\n",
      "          -0.0071,  0.1279,  0.1646,  0.0084, -0.2638, -0.1492, -0.3411,\n",
      "          -0.0265, -0.0955, -0.0615, -0.1190, -0.0807,  0.1343, -0.0457,\n",
      "          -0.0860,  0.0620,  0.0544, -0.0617,  0.1347, -0.0098,  0.0497,\n",
      "          -0.1951, -0.1773,  0.1947, -0.2618,  0.0357,  0.1218,  0.1199,\n",
      "           0.0235, -0.1370,  0.2575, -0.0287,  0.1576, -0.0076,  0.1877,\n",
      "          -0.0427, -0.2821, -0.1491, -0.0526,  0.0112, -0.3290,  0.0866,\n",
      "          -0.0572,  0.1833,  0.0774,  0.0578, -0.1449, -0.1699, -0.1416,\n",
      "           0.0577,  0.0742, -0.1349, -0.1243, -0.1873,  0.1179, -0.1982,\n",
      "           0.1790,  0.3280, -0.1455, -0.0203, -0.2149,  0.0166,  0.1999,\n",
      "           0.1542,  0.0789,  0.0486, -0.3166,  0.0088,  0.0213,  0.0652,\n",
      "           0.1111, -0.0322, -0.0170,  0.0195, -0.0312, -0.1977, -0.0424,\n",
      "           0.2325,  0.0574, -0.1745,  0.1859,  0.2072, -0.0698,  0.2562,\n",
      "           0.1489,  0.0682,  0.1313,  0.1425,  0.1130,  0.2226, -0.1105,\n",
      "          -0.2648, -0.1856, -0.0702, -0.0932,  0.0261,  0.0978,  0.0522,\n",
      "          -0.0536,  0.0639,  0.1896, -0.0067, -0.1231, -0.1697, -0.0857,\n",
      "           0.0319,  0.3069,  0.1721, -0.0864,  0.0246, -0.0306, -0.0167,\n",
      "          -0.0908,  0.0321,  0.4870, -0.0503,  0.0064, -0.1748,  0.1420,\n",
      "           0.0240, -0.0370,  0.1489,  0.3788,  0.0926, -0.0072, -0.0052,\n",
      "          -0.0556,  0.0079, -0.1592,  0.4102,  0.0485,  0.1146,  0.1437,\n",
      "           0.3775, -0.2588,  0.1417, -0.3864, -0.0203,  0.0067,  0.3970,\n",
      "          -0.0828,  0.1884, -0.0679,  0.2404,  0.1502,  0.2135, -0.1459,\n",
      "          -0.0636, -0.2418, -0.0408, -0.2556,  0.0055, -0.2095,  0.0866,\n",
      "           0.1345,  0.2160, -0.0163,  0.2169,  0.0071, -0.0745,  0.1943,\n",
      "           0.1748,  0.0975, -0.1289,  0.2302, -0.0481, -0.0732, -0.0122,\n",
      "          -0.1823, -0.1137,  0.1064, -0.0339, -0.2610, -0.1032,  0.0885,\n",
      "          -0.1779, -0.1198,  0.0702, -0.1737, -0.0127,  0.0234,  0.0015,\n",
      "           0.0660, -0.0224, -0.2197,  0.1816,  0.0336, -0.1480, -0.1053,\n",
      "           0.2935, -0.0286,  0.0645, -0.1235,  0.0609, -0.0988, -0.1636,\n",
      "           0.3107, -0.0805, -0.2078,  0.0708, -0.0073, -0.0181,  0.0417,\n",
      "           0.2444, -0.1829,  0.1530,  0.1615, -0.1675,  0.2596, -0.2110,\n",
      "          -0.1652,  0.2803,  0.2321,  0.0230, -0.4748,  0.1644, -0.2229,\n",
      "          -0.3608,  0.1229, -0.0952, -0.1362, -0.3786, -0.3246,  0.0208,\n",
      "           0.1706,  0.1587,  0.2516, -0.1024, -0.0811,  0.0238,  0.2100,\n",
      "          -0.1336, -0.2712, -0.2895, -0.2377, -0.0864,  0.1478,  0.0337,\n",
      "           0.0564, -0.1378, -0.1113, -0.0304]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.6177e+00,  7.8663e-01, -1.8787e-01,  2.2855e+00,  1.0807e+00,\n",
      "          -7.0720e-01, -7.2140e-01,  0.0000e+00,  1.1642e-01, -4.7346e-01,\n",
      "           3.0652e-01,  2.0243e+00,  0.0000e+00, -1.3040e-01,  1.9829e+00,\n",
      "          -4.8281e-01,  3.0957e-01, -1.6131e+00, -5.4439e-02, -2.5098e-01,\n",
      "           2.8062e-01,  4.0772e-02, -2.2865e+00,  3.6034e-01,  8.3701e-01,\n",
      "          -6.1423e-01,  2.4877e-01,  5.3939e-01,  7.6384e-01, -1.6876e-01,\n",
      "           4.7946e-01, -8.5277e-01,  0.0000e+00, -1.5764e+00, -3.2792e-01,\n",
      "           7.3144e-01, -9.2823e-01, -2.6193e-01, -1.0682e+00, -8.2821e-01,\n",
      "           1.2802e+00, -1.6953e-01,  7.5971e-01, -1.5871e-02,  0.0000e+00,\n",
      "           1.4994e+00, -8.3931e-03,  0.0000e+00, -2.9172e-01, -1.3133e+00,\n",
      "          -3.1377e-01,  1.1770e-01,  1.2317e+00, -1.7521e+00,  6.6048e-01,\n",
      "           3.8509e-01, -4.2281e-01, -6.2561e-01, -1.1284e+00,  1.1971e-01,\n",
      "          -2.3345e+00, -1.0219e+00, -7.7805e-01,  0.0000e+00,  1.2992e+00,\n",
      "          -3.0070e-01, -1.1078e+00,  8.6316e-01, -6.2900e-01, -1.3690e-01,\n",
      "           6.8478e-01,  0.0000e+00,  0.0000e+00, -3.5874e-01, -9.4624e-01,\n",
      "          -4.1445e-01,  7.8733e-01,  2.1952e+00,  0.0000e+00, -5.2217e-01,\n",
      "          -5.4738e-01, -4.2794e-01, -1.1328e+00,  1.4427e+00, -7.0193e-01,\n",
      "           1.3348e+00, -2.0728e+00,  7.6239e-01, -8.8318e-01,  4.5094e-01,\n",
      "           1.8543e+00,  6.8177e-01,  9.3025e-01,  1.1268e+00, -1.6678e+00,\n",
      "          -1.4587e+00, -6.6478e-01,  9.4690e-01,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -3.4050e-01,  3.9153e-01,  4.0101e-01, -2.1416e+00,\n",
      "           1.3503e-01,  1.3837e-03,  2.4167e-01, -9.5453e-01,  7.7114e-01,\n",
      "          -1.8032e+00,  0.0000e+00, -9.7700e-01, -1.4561e+00,  3.1273e-01,\n",
      "           4.4527e-01,  1.2485e-01,  6.7279e-01, -1.6907e+00,  1.3789e+00,\n",
      "           1.1191e+00,  1.6423e+00, -2.6589e-01, -2.4068e-01, -5.1501e-01,\n",
      "           0.0000e+00,  1.2402e+00,  0.0000e+00,  1.2681e+00,  8.5663e-01,\n",
      "           8.1410e-02, -1.0835e+00,  1.6060e+00, -3.3179e-01,  8.1106e-01,\n",
      "          -1.6091e+00, -7.0368e-01, -5.7493e-01,  8.0240e-01,  0.0000e+00,\n",
      "           0.0000e+00, -9.6847e-01,  1.0617e+00,  3.2852e-01,  1.4769e+00,\n",
      "          -5.3187e-01,  0.0000e+00, -5.0050e-01,  0.0000e+00,  2.4225e+00,\n",
      "          -1.3858e+00, -1.5001e+00,  5.5174e-01,  1.6960e+00, -5.8228e-01,\n",
      "           9.3425e-01,  2.2451e-01, -2.4756e-01, -1.3811e+00, -3.9661e-01,\n",
      "           1.8940e+00, -7.9624e-02, -8.4264e-01,  1.7735e+00,  1.5459e+00,\n",
      "          -7.5676e-01,  7.2189e-01,  4.9430e-01, -6.0789e-01, -3.2509e-01,\n",
      "           1.7560e-02, -5.4702e-02,  6.9219e-01,  1.0334e-01,  4.6797e-01,\n",
      "           3.2390e-01, -1.5567e+00, -9.9151e-01, -9.7566e-01, -9.2711e-01,\n",
      "           1.8219e+00, -7.5837e-01, -2.1146e+00, -8.8431e-02, -1.0727e+00,\n",
      "           1.9148e+00,  8.4409e-01, -9.2301e-01,  0.0000e+00, -8.3421e-01,\n",
      "           1.1076e+00, -6.7963e-01,  2.1393e-01,  2.2390e-01,  3.0838e-01,\n",
      "          -7.6375e-01,  1.2579e+00, -1.8682e+00,  8.4677e-01, -1.2198e-01,\n",
      "           4.4668e-01, -2.0827e+00, -1.2646e+00, -2.4551e-01,  2.1626e-01,\n",
      "           8.5981e-01, -2.0677e-01,  0.0000e+00, -1.0470e+00, -6.5201e-01,\n",
      "           8.4177e-01,  7.4115e-01,  6.4815e-01, -9.2507e-01, -9.1514e-01,\n",
      "          -4.2019e-01,  1.0645e+00,  0.0000e+00,  2.8139e+00,  9.2689e-01,\n",
      "           9.0673e-01,  1.1101e+00, -5.7407e-01,  1.8312e+00, -7.5925e-01,\n",
      "           1.7190e-01,  6.2422e-01,  2.7719e+00,  0.0000e+00, -1.2719e+00,\n",
      "           5.6193e-01, -4.7923e-01, -1.4013e+00,  1.5420e+00, -1.3759e+00,\n",
      "          -3.3902e-01,  0.0000e+00,  7.7503e-01, -1.3510e+00,  2.0709e-01,\n",
      "          -1.7202e+00,  2.0482e+00,  5.3120e-01,  0.0000e+00,  5.3953e-02,\n",
      "           8.2940e-01, -2.7118e-01,  7.8916e-01, -1.4193e+00,  0.0000e+00,\n",
      "          -9.3321e-01,  1.8809e+00,  5.1168e-01,  0.0000e+00, -1.1143e+00,\n",
      "          -6.8235e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0563, 0.0844, 0.0953, 0.1571, 0.1339, 0.1159, 0.1133, 0.0745, 0.0987,\n",
      "         0.0705]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3510, -0.0341,  0.0705,  ..., -0.1111, -0.0119, -0.4890],\n",
      "        [ 0.2941,  0.0492, -0.1791,  ..., -0.3276, -0.1117,  0.1317],\n",
      "        [ 0.0921,  0.1663,  0.1515,  ..., -0.0280,  0.0543,  0.3655],\n",
      "        ...,\n",
      "        [ 0.7550,  0.6273, -0.7582,  ..., -0.4888,  0.0111,  0.0884],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.1228e-01,  4.5099e-02, -2.7160e-01, -3.5357e-02,  1.3670e-01,\n",
      "           8.4048e-02, -1.3694e-01, -8.9198e-02,  2.7754e-02,  1.9199e-01,\n",
      "          -1.0245e-01, -2.1611e-01, -1.4422e-01, -1.5647e-01,  1.9618e-02,\n",
      "           1.5494e-01,  1.4056e-01,  3.7417e-02, -2.9172e-01, -1.6293e-01,\n",
      "          -3.2464e-01, -4.5040e-02, -8.1755e-02, -7.0182e-02, -1.1152e-01,\n",
      "          -6.4341e-02,  1.4800e-01, -5.7271e-02, -8.2324e-02,  6.0267e-02,\n",
      "           5.8649e-02, -5.3803e-02,  1.2119e-01, -3.7948e-02,  8.9915e-03,\n",
      "          -1.7931e-01, -1.8984e-01,  1.4518e-01, -2.3670e-01,  3.5591e-02,\n",
      "           1.0911e-01,  1.5931e-01,  7.3474e-03, -1.3935e-01,  2.2105e-01,\n",
      "          -1.6581e-04,  1.2110e-01,  4.1608e-03,  1.9301e-01, -2.4850e-02,\n",
      "          -2.5081e-01, -2.0572e-01, -2.5076e-02,  2.4805e-03, -3.2423e-01,\n",
      "           8.7214e-02, -5.2646e-02,  2.0673e-01,  1.1158e-01,  5.9711e-02,\n",
      "          -1.1979e-01, -1.8606e-01, -1.5851e-01,  8.7227e-02,  7.0795e-02,\n",
      "          -1.1988e-01, -1.1055e-01, -1.6118e-01,  3.9230e-02, -1.5662e-01,\n",
      "           2.0670e-01,  3.4764e-01, -1.3592e-01, -3.1366e-02, -2.1204e-01,\n",
      "           6.8079e-02,  2.2794e-01,  1.3555e-01,  5.4290e-02,  5.1026e-02,\n",
      "          -3.1716e-01,  3.9961e-02, -4.1529e-02,  9.1091e-02,  9.1058e-02,\n",
      "          -1.9348e-02,  2.2051e-02,  5.7329e-02, -1.3642e-02, -1.4362e-01,\n",
      "          -2.0580e-02,  2.1075e-01,  1.6831e-02, -1.7891e-01,  1.7733e-01,\n",
      "           2.2584e-01, -1.3228e-02,  2.7804e-01,  1.2938e-01,  7.6327e-02,\n",
      "           1.1853e-01,  1.7329e-01,  1.0378e-01,  1.8938e-01, -8.0747e-02,\n",
      "          -2.4611e-01, -1.5087e-01, -3.3444e-02, -1.2050e-01,  5.6826e-02,\n",
      "           7.1289e-02,  6.5116e-02, -6.9057e-02,  4.8023e-02,  1.7212e-01,\n",
      "           5.0828e-03, -5.0138e-02, -1.7397e-01, -9.7980e-02, -7.2816e-03,\n",
      "           2.8576e-01,  1.2750e-01, -1.0178e-01,  4.4326e-02, -8.2287e-02,\n",
      "          -6.1070e-02, -6.9301e-02,  2.9572e-02,  4.7229e-01, -3.3054e-02,\n",
      "          -2.0779e-03, -1.4161e-01,  1.2603e-01,  4.9745e-02, -6.7886e-02,\n",
      "           8.9325e-02,  3.6964e-01,  1.2171e-01,  2.6243e-02,  3.8423e-02,\n",
      "          -7.0045e-02,  6.2380e-02, -1.5266e-01,  3.7475e-01,  2.5972e-02,\n",
      "           1.0092e-01,  1.7704e-01,  3.8754e-01, -2.0830e-01,  1.2451e-01,\n",
      "          -4.1061e-01, -3.7223e-02,  1.8549e-02,  3.7401e-01, -5.2117e-02,\n",
      "           2.0137e-01, -5.3404e-02,  2.5838e-01,  1.0242e-01,  2.1044e-01,\n",
      "          -1.7312e-01, -3.0298e-02, -2.4906e-01,  4.1233e-02, -2.6624e-01,\n",
      "          -1.0682e-02, -2.0295e-01,  8.9721e-02,  8.0336e-02,  1.9947e-01,\n",
      "          -3.4806e-02,  2.0026e-01,  1.8384e-02,  9.8940e-03,  1.7181e-01,\n",
      "           1.3795e-01,  8.2116e-02, -9.1550e-02,  2.3978e-01, -3.9854e-02,\n",
      "          -8.5913e-02,  5.9127e-04, -1.9818e-01, -1.2538e-01,  1.2988e-01,\n",
      "          -4.1238e-02, -2.0174e-01, -1.0901e-01,  4.2200e-02, -1.7743e-01,\n",
      "          -9.2090e-02,  5.1472e-02, -1.6904e-01, -1.8982e-02, -2.1482e-02,\n",
      "          -1.1812e-02,  5.7387e-02, -2.6873e-02, -2.2920e-01,  1.6222e-01,\n",
      "           1.1944e-02, -1.1295e-01, -7.4069e-02,  2.7238e-01, -5.0008e-02,\n",
      "           4.4117e-02, -1.2800e-01,  5.0380e-02, -9.3515e-02, -1.5672e-01,\n",
      "           2.5062e-01, -8.2935e-02, -1.9181e-01,  7.8298e-02,  7.7366e-04,\n",
      "          -2.7923e-02,  8.4592e-02,  2.4079e-01, -2.2809e-01,  1.1077e-01,\n",
      "           1.8268e-01, -1.4595e-01,  2.7712e-01, -2.0800e-01, -1.4051e-01,\n",
      "           2.9125e-01,  2.0870e-01,  3.9730e-03, -4.8947e-01,  1.5810e-01,\n",
      "          -2.0022e-01, -3.5057e-01,  7.5350e-02, -8.8214e-02, -1.3925e-01,\n",
      "          -3.7563e-01, -3.2727e-01,  1.8276e-02,  1.9365e-01,  1.4598e-01,\n",
      "           2.3819e-01, -1.1554e-01, -9.8377e-02,  6.3448e-02,  1.9205e-01,\n",
      "          -1.4963e-01, -2.8641e-01, -2.6504e-01, -2.5238e-01, -1.1263e-01,\n",
      "           1.3578e-01,  4.7906e-02,  5.3543e-02, -1.5905e-01, -4.9494e-02,\n",
      "          -2.3963e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0000e+00, -4.3085e-01,  3.1535e-01, -1.0853e+00, -1.1729e+00,\n",
      "           7.4165e-01, -1.9147e+00,  1.3514e+00,  1.9013e-01,  6.1745e-01,\n",
      "           1.9037e+00,  6.0265e-01,  2.2913e-01, -9.1672e-01, -3.1843e+00,\n",
      "          -6.8299e-02, -1.6338e+00, -9.4355e-01,  1.3603e+00, -1.4359e+00,\n",
      "          -1.4037e-01, -5.2455e-01, -1.1201e+00, -2.5961e+00, -7.5965e-02,\n",
      "           1.3917e+00, -6.2003e-01,  1.9983e+00,  0.0000e+00,  5.5540e-01,\n",
      "           9.1604e-01, -3.8527e-03,  2.2234e-01,  2.0172e+00, -6.3575e-02,\n",
      "          -1.4086e+00, -1.1158e-01, -8.1735e-01,  3.1528e-01,  8.6123e-02,\n",
      "           8.6361e-01, -8.9927e-01,  1.0090e+00, -1.5642e+00,  1.9450e+00,\n",
      "          -3.0033e-01,  7.0656e-01, -6.0254e-01, -1.0210e+00,  1.1174e+00,\n",
      "          -1.3235e+00,  2.6785e+00,  6.6704e-01, -8.4707e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.4341e+00, -9.6167e-02,  1.2761e+00,  2.1824e+00,\n",
      "          -1.0068e+00,  3.5718e-02, -2.8017e-01,  0.0000e+00, -6.3280e-02,\n",
      "           3.9352e-01,  5.7819e-01,  1.1655e+00,  1.5813e+00, -1.4155e+00,\n",
      "           0.0000e+00,  2.9643e-01, -3.0988e-02, -7.9818e-01, -2.1412e-01,\n",
      "           0.0000e+00,  5.2599e-01,  1.3992e+00,  1.0274e+00, -7.9445e-01,\n",
      "           0.0000e+00,  0.0000e+00,  7.5846e-01,  1.0589e+00, -1.2159e+00,\n",
      "          -1.1334e-01,  0.0000e+00,  5.4872e-01, -9.4502e-01, -1.9015e+00,\n",
      "           5.2929e-01,  9.8758e-01,  1.7023e+00,  0.0000e+00,  6.0800e-01,\n",
      "          -1.5907e-02,  3.5439e-01, -1.1761e+00,  1.3727e+00,  2.4483e+00,\n",
      "           2.4342e-01,  4.4031e-02, -4.6666e-01, -9.8948e-01,  1.6414e+00,\n",
      "          -1.0242e+00,  3.0305e+00,  6.2088e-01, -1.0191e-01,  0.0000e+00,\n",
      "           1.8998e-01, -5.0345e-01, -5.7115e-01,  7.1267e-01, -7.8076e-01,\n",
      "           6.3268e-01,  4.0375e-01,  2.2342e-01, -2.3273e+00,  2.9199e-02,\n",
      "          -8.1488e-01, -1.4119e+00, -1.8388e+00,  6.0326e-01, -9.5735e-01,\n",
      "          -2.0108e-01,  4.0344e-02,  2.1510e+00,  1.3967e+00, -2.0885e+00,\n",
      "          -9.2630e-01,  4.5005e-01, -1.1684e+00,  4.2552e-01, -4.6829e-01,\n",
      "          -7.4653e-01, -1.0650e+00, -9.7560e-01, -1.9409e-02,  2.3982e+00,\n",
      "           6.9865e-01, -1.1219e+00,  1.6920e+00, -1.4046e-01, -6.7013e-01,\n",
      "           3.3106e-02,  7.5995e-01,  0.0000e+00, -1.0341e+00, -9.5245e-02,\n",
      "           0.0000e+00,  5.8678e-01, -3.3838e-01,  6.5788e-01,  0.0000e+00,\n",
      "          -2.5280e-01, -2.1803e-01,  6.2406e-01, -2.3641e+00,  1.0561e+00,\n",
      "           3.0294e-01, -7.7163e-02,  1.5529e-01, -1.2123e+00, -2.1920e-02,\n",
      "           1.6827e+00,  0.0000e+00,  2.7182e-01, -1.2704e+00, -7.1300e-01,\n",
      "          -1.2244e+00, -1.0942e+00, -2.5911e+00,  5.0600e-01, -3.0613e+00,\n",
      "          -2.8742e-01,  4.9758e-01,  8.2986e-01,  3.1707e-01, -7.9309e-01,\n",
      "           2.7273e-01,  0.0000e+00,  1.0585e+00,  8.3916e-01, -4.0232e-01,\n",
      "           7.2794e-01,  5.9882e-01,  3.5988e-01,  0.0000e+00, -1.8313e+00,\n",
      "           1.3638e+00,  2.1603e+00,  3.3575e-01, -1.0158e+00, -1.1732e+00,\n",
      "          -2.2165e+00,  1.6679e+00,  2.1536e+00,  3.6343e-01,  0.0000e+00,\n",
      "           3.2574e-02, -5.0168e-01, -1.2771e+00, -5.4311e-01, -4.0772e-01,\n",
      "          -1.4479e+00,  9.5343e-01, -8.5208e-01,  8.2942e-01, -1.5606e+00,\n",
      "           6.3733e-01,  6.7541e-01,  2.3987e+00,  5.5313e-02,  1.8938e+00,\n",
      "           1.3093e+00,  5.8023e-01,  0.0000e+00,  1.5504e+00, -2.2259e-01,\n",
      "          -2.2742e-01,  1.7345e+00,  0.0000e+00, -1.5525e+00,  9.2299e-01,\n",
      "          -1.2244e+00, -8.4907e-01, -1.8027e+00, -7.9834e-04,  3.7326e-01,\n",
      "          -1.5740e+00, -1.2395e-01,  9.6638e-01,  0.0000e+00,  1.6948e+00,\n",
      "           0.0000e+00,  6.3397e-01, -1.7233e+00,  9.8032e-01, -1.7173e+00,\n",
      "           1.5615e+00, -2.7307e-01, -2.5977e+00,  1.2393e+00, -1.2282e+00,\n",
      "           0.0000e+00, -5.0854e-01,  5.4283e-01, -2.6126e-01, -1.0226e+00,\n",
      "           1.3340e+00,  3.1146e-01, -5.0855e-02, -2.2874e-01, -1.6133e+00,\n",
      "           1.8072e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0448, 0.1085, 0.1656, 0.0766, 0.1502, 0.1853, 0.1042, 0.0505, 0.0644,\n",
      "         0.0499]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3510, -0.0341,  0.0705,  ..., -0.1111, -0.0119, -0.4890],\n",
      "        [ 0.2941,  0.0492, -0.1791,  ..., -0.3276, -0.1117,  0.1317],\n",
      "        [ 0.0921,  0.1663,  0.1515,  ..., -0.0280,  0.0543,  0.3655],\n",
      "        ...,\n",
      "        [ 0.7550,  0.6273, -0.7582,  ..., -0.4888,  0.0111,  0.0884],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2002,  0.0880, -0.2271, -0.0435,  0.2192,  0.1279, -0.1507,\n",
      "          -0.0579,  0.0417,  0.2403, -0.1175, -0.2137, -0.1308, -0.1953,\n",
      "           0.0195,  0.1498,  0.1738, -0.0297, -0.3249, -0.2399, -0.3318,\n",
      "          -0.0179, -0.1176, -0.1157, -0.1112, -0.0894,  0.1696,  0.0030,\n",
      "          -0.0630,  0.0841,  0.0197, -0.0544,  0.1532, -0.0024, -0.0147,\n",
      "          -0.1581, -0.2033,  0.1649, -0.2687,  0.0372,  0.1316,  0.1549,\n",
      "          -0.0072, -0.1374,  0.2456, -0.0192,  0.1398,  0.0477,  0.1922,\n",
      "           0.0012, -0.2323, -0.2285,  0.0237,  0.0610, -0.3229,  0.0896,\n",
      "          -0.0511,  0.2289,  0.1371,  0.0115, -0.1160, -0.1503, -0.1582,\n",
      "           0.0650,  0.0837, -0.1715, -0.1006, -0.1655,  0.0784, -0.1566,\n",
      "           0.1933,  0.3774, -0.1708, -0.0307, -0.2327,  0.0663,  0.1983,\n",
      "           0.0916,  0.0734,  0.0380, -0.3337,  0.0841, -0.0174,  0.0996,\n",
      "           0.1069, -0.0441,  0.0118,  0.0761, -0.0684, -0.1382, -0.0793,\n",
      "           0.2334,  0.0560, -0.2026,  0.1932,  0.2102, -0.0181,  0.2703,\n",
      "           0.1029,  0.0630,  0.1746,  0.1533,  0.0554,  0.2078, -0.0941,\n",
      "          -0.2569, -0.1875, -0.0649, -0.1120,  0.0590,  0.0746,  0.0652,\n",
      "          -0.1049,  0.0753,  0.2264,  0.0017, -0.0509, -0.1806, -0.1177,\n",
      "          -0.0131,  0.2788,  0.1254, -0.0763,  0.0139, -0.0698, -0.0165,\n",
      "          -0.0329,  0.1340,  0.4937, -0.0182, -0.0335, -0.1260,  0.0979,\n",
      "           0.0067, -0.0512,  0.0308,  0.3835,  0.1297,  0.0592, -0.0024,\n",
      "          -0.1053,  0.0053, -0.0574,  0.3918, -0.0010,  0.1324,  0.1674,\n",
      "           0.3607, -0.2364,  0.1012, -0.3845, -0.0786,  0.0475,  0.3953,\n",
      "          -0.1046,  0.1609, -0.1063,  0.2569,  0.0790,  0.2450, -0.1299,\n",
      "           0.0171, -0.2053,  0.0267, -0.2925, -0.0257, -0.1751,  0.1049,\n",
      "           0.0784,  0.2141,  0.0203,  0.1779, -0.0303,  0.0296,  0.2190,\n",
      "           0.1690,  0.0939, -0.0849,  0.2189, -0.0228, -0.0948, -0.0155,\n",
      "          -0.1884, -0.1628,  0.1045, -0.0152, -0.1778, -0.1421,  0.0470,\n",
      "          -0.1755, -0.0779,  0.0488, -0.1879,  0.0263, -0.0260, -0.0183,\n",
      "           0.0799, -0.0058, -0.2280,  0.1891,  0.0061, -0.1042, -0.0809,\n",
      "           0.2515, -0.0483,  0.0750, -0.1619,  0.0036, -0.0889, -0.1452,\n",
      "           0.2515, -0.0906, -0.2169,  0.0217,  0.0086, -0.0100,  0.1144,\n",
      "           0.2381, -0.2424,  0.1411,  0.1276, -0.1286,  0.2694, -0.2336,\n",
      "          -0.1605,  0.3152,  0.2139,  0.0595, -0.5136,  0.1496, -0.1969,\n",
      "          -0.3522,  0.1111, -0.0642, -0.1847, -0.4055, -0.3779, -0.0010,\n",
      "           0.1566,  0.1454,  0.2906, -0.1349, -0.1032,  0.0840,  0.1779,\n",
      "          -0.1645, -0.3247, -0.2908, -0.2828, -0.1542,  0.0862,  0.0354,\n",
      "           0.0924, -0.1653, -0.0822,  0.0207]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5671e-02,  3.9879e-01, -9.6735e-01, -6.8228e-01,  3.7656e-01,\n",
      "           0.0000e+00,  0.0000e+00, -8.3189e-02, -3.5859e+00,  9.0691e-01,\n",
      "           4.2920e-01, -6.2941e-01,  2.6065e+00, -6.2977e-01, -5.4173e-01,\n",
      "          -1.5792e-01,  8.5186e-01,  1.0952e+00,  4.5513e-01,  4.3612e-01,\n",
      "          -6.3395e-01, -3.8387e-01,  1.6424e+00,  1.5117e+00,  7.5408e-01,\n",
      "          -7.5303e-02, -1.8763e-01, -7.5903e-01,  1.6544e+00,  0.0000e+00,\n",
      "           0.0000e+00,  1.2194e+00, -1.0346e+00, -8.2632e-02, -1.5354e+00,\n",
      "           1.3955e+00,  0.0000e+00,  0.0000e+00,  1.9814e-01,  1.6019e+00,\n",
      "           0.0000e+00, -1.3993e+00,  0.0000e+00, -1.7173e+00, -1.5255e+00,\n",
      "           6.6729e-01,  5.4128e-01,  3.6991e-01, -1.3412e+00,  1.4364e-01,\n",
      "          -6.2885e-01,  0.0000e+00,  6.1064e-01, -1.0300e+00, -2.5876e-02,\n",
      "           2.0283e-01, -8.8262e-01,  0.0000e+00, -2.3645e-01, -4.2502e-01,\n",
      "           1.1017e+00,  1.4088e+00,  0.0000e+00, -5.0219e-01, -2.9658e+00,\n",
      "           0.0000e+00,  1.2795e+00, -1.2887e+00,  4.1200e-01,  5.2637e-01,\n",
      "          -1.2680e+00,  0.0000e+00,  7.0760e-01,  0.0000e+00,  3.2675e-01,\n",
      "          -2.5209e-03, -1.5983e-01,  1.0636e+00, -5.8733e-02, -1.2040e-01,\n",
      "           0.0000e+00,  2.1325e+00, -9.2528e-01,  1.0058e+00, -2.0797e-01,\n",
      "           4.3415e-01,  1.6623e+00, -9.7530e-01, -1.0301e-01, -5.8168e-01,\n",
      "          -2.2746e+00,  1.1008e+00, -6.2236e-01, -1.1354e+00,  0.0000e+00,\n",
      "          -1.1713e+00,  3.4546e-02,  0.0000e+00,  1.7211e+00, -7.8119e-01,\n",
      "           2.6984e+00, -1.4634e+00,  1.0762e+00,  1.4550e+00,  0.0000e+00,\n",
      "          -7.6263e-01,  1.2133e+00,  1.2752e-01, -1.4734e+00, -1.2858e-02,\n",
      "          -2.4907e-01,  1.3456e-01, -1.0492e+00,  1.3106e+00, -1.6544e+00,\n",
      "          -2.9912e+00, -5.6136e-02, -5.0201e-01, -1.9314e-01,  4.4463e-01,\n",
      "          -1.4677e+00,  7.0273e-01, -1.4612e+00, -7.2653e-01, -9.5906e-01,\n",
      "          -1.3100e+00,  8.9828e-01,  1.7071e-01,  1.2862e+00, -7.5301e-01,\n",
      "          -8.2314e-01,  5.2957e-01, -1.5838e+00,  9.8431e-01,  2.7622e-01,\n",
      "          -5.8976e-01,  6.6028e-01,  5.7304e-01, -1.1585e+00, -1.0111e+00,\n",
      "          -3.8927e-01,  6.7789e-01,  0.0000e+00, -1.0205e-01,  0.0000e+00,\n",
      "          -1.0161e-01, -5.4346e-01, -8.4470e-01, -7.5561e-01,  1.7739e-01,\n",
      "           1.9996e+00,  0.0000e+00, -1.9317e+00, -4.0633e-01,  4.4181e-01,\n",
      "          -1.9457e-01, -6.3965e-02,  0.0000e+00,  3.9550e-02,  5.3778e-01,\n",
      "          -2.6005e-02,  2.2071e+00,  4.8124e-01, -5.4971e-01, -5.2799e-01,\n",
      "          -8.9338e-01,  2.8189e-01,  8.5053e-02,  0.0000e+00, -4.7829e-01,\n",
      "           7.3882e-01, -3.2834e-02,  1.9787e-02, -1.0021e+00,  1.2781e+00,\n",
      "           0.0000e+00, -9.8849e-01, -2.0787e+00,  1.9703e+00,  8.6411e-02,\n",
      "           0.0000e+00,  3.5091e-02,  6.7199e-01,  9.7995e-01, -7.4696e-01,\n",
      "          -3.4106e-01, -2.7850e+00, -7.8521e-01,  0.0000e+00,  1.0127e+00,\n",
      "           3.0763e+00,  4.9465e-01, -1.4411e-01, -5.9523e-01,  5.6105e-01,\n",
      "           2.1664e+00, -1.1887e+00,  5.3471e-01,  1.8130e+00, -9.4803e-01,\n",
      "          -1.6624e+00, -1.0151e+00,  1.2417e+00, -1.2211e-01,  2.3187e-01,\n",
      "           0.0000e+00, -2.2938e+00,  6.8212e-01, -1.0753e+00, -4.7159e-01,\n",
      "           0.0000e+00, -5.7347e-01,  0.0000e+00,  0.0000e+00,  2.9712e-02,\n",
      "           0.0000e+00,  0.0000e+00,  9.6626e-01,  0.0000e+00,  2.1707e+00,\n",
      "          -1.0833e+00, -4.2766e-01, -1.8447e+00, -5.0197e-01,  3.3679e-01,\n",
      "           7.0481e-01, -6.9664e-01, -6.2818e-01,  2.9231e-01,  0.0000e+00,\n",
      "          -1.1092e+00,  0.0000e+00, -6.1448e-01,  1.3099e+00, -2.9811e+00,\n",
      "           4.0375e+00,  5.8521e-01,  4.3657e-02, -1.5814e+00, -2.8776e-01,\n",
      "           7.4155e-01, -3.2502e+00, -3.0494e-01, -8.5306e-01,  1.1034e-02,\n",
      "           2.7521e-01,  2.7518e-01,  2.5281e-01,  0.0000e+00,  3.8669e-01,\n",
      "          -3.6563e-01, -1.5818e-01, -5.5431e-01, -5.2725e-02,  0.0000e+00,\n",
      "          -1.1318e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0424, 0.0493, 0.0664, 0.0609, 0.1261, 0.3712, 0.0556, 0.0934, 0.0457,\n",
      "         0.0890]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0265,  0.1434, -0.1416,  ...,  0.5617,  0.1759, -0.1771],\n",
      "        [-0.1597, -0.0520,  0.3840,  ...,  0.2109, -0.1090, -0.1263],\n",
      "        [ 0.1568,  0.0828,  0.3426,  ...,  0.4834,  0.1998, -0.0408],\n",
      "        ...,\n",
      "        [ 0.7578,  0.6284, -0.7384,  ..., -0.4859,  0.0551,  0.3483],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2141,  0.2789, -0.0650, -0.1884,  0.0477,  0.1380, -0.1753,\n",
      "          -0.0282, -0.1047,  0.0203, -0.0020,  0.0977,  0.2001, -0.0951,\n",
      "           0.1075,  0.0521, -0.0561, -0.1130, -0.2992,  0.0346,  0.0538,\n",
      "          -0.4342, -0.1518,  0.0775,  0.0610, -0.0891, -0.1391, -0.2325,\n",
      "          -0.1844,  0.0685,  0.4549, -0.0046,  0.0262,  0.0363, -0.1462,\n",
      "          -0.0734, -0.1587,  0.1828, -0.2234, -0.0084, -0.0777,  0.1318,\n",
      "          -0.2817, -0.2238,  0.1469,  0.0083,  0.0349, -0.1030,  0.0097,\n",
      "          -0.1403, -0.1198, -0.1603,  0.0384, -0.1021, -0.0708, -0.1999,\n",
      "          -0.0736, -0.3345,  0.2989,  0.3150, -0.0609,  0.1139, -0.1330,\n",
      "          -0.1216,  0.0633, -0.1230,  0.0747,  0.1451, -0.1032,  0.3118,\n",
      "          -0.1068,  0.3153, -0.2265, -0.2584, -0.3290, -0.0539,  0.1275,\n",
      "           0.2066, -0.1996,  0.4044,  0.0753, -0.0516, -0.3606,  0.3195,\n",
      "           0.1241,  0.1196,  0.1255,  0.2299,  0.1993, -0.0601, -0.0246,\n",
      "          -0.1206, -0.2480,  0.3582,  0.2074, -0.0611, -0.1125,  0.2009,\n",
      "           0.1002,  0.3586, -0.1287, -0.2705,  0.1131,  0.1028, -0.2298,\n",
      "          -0.3354, -0.1975, -0.0956, -0.0558,  0.3301, -0.2034,  0.0488,\n",
      "           0.0309, -0.2606,  0.1437,  0.1040, -0.0554,  0.1035,  0.0689,\n",
      "           0.0914,  0.1836,  0.0901, -0.3287,  0.0232, -0.2516, -0.3273,\n",
      "          -0.1596,  0.0242,  0.1767, -0.1501,  0.3855, -0.2383,  0.0563,\n",
      "           0.0946, -0.2479, -0.2082, -0.1414,  0.0075, -0.1946,  0.1562,\n",
      "          -0.1139,  0.4080, -0.0164,  0.3676, -0.0592,  0.3180, -0.0750,\n",
      "           0.2923,  0.1811,  0.2761, -0.1110, -0.0161, -0.0624,  0.0970,\n",
      "          -0.1855, -0.1020, -0.3504,  0.1874, -0.2996, -0.1865, -0.1599,\n",
      "          -0.0231, -0.0400,  0.3184, -0.0822,  0.0093, -0.0857,  0.2508,\n",
      "           0.0054,  0.0790, -0.3411, -0.0878,  0.1081,  0.1539,  0.0939,\n",
      "          -0.1389,  0.0684, -0.1158,  0.0709, -0.1753, -0.0281, -0.1578,\n",
      "          -0.0722, -0.0076, -0.1765, -0.0198, -0.1871, -0.1102, -0.1314,\n",
      "          -0.0447,  0.2051,  0.2372, -0.0666, -0.1770,  0.1378, -0.1579,\n",
      "          -0.2235,  0.2274, -0.0809, -0.1696, -0.1895,  0.1873,  0.1356,\n",
      "           0.0227, -0.0428, -0.1186,  0.0814,  0.1669,  0.1173,  0.0305,\n",
      "          -0.1618,  0.0502, -0.1703,  0.0262,  0.0010,  0.0477,  0.0532,\n",
      "           0.2460,  0.0513,  0.0510,  0.2414,  0.0743,  0.2333, -0.2209,\n",
      "           0.1293,  0.1567, -0.0856,  0.0385, -0.3524,  0.0755, -0.1952,\n",
      "          -0.2026, -0.3156, -0.0994,  0.0786, -0.2742, -0.1846,  0.0899,\n",
      "           0.4378,  0.3169,  0.0849, -0.4243, -0.1905,  0.2496,  0.1527,\n",
      "          -0.0584, -0.2293, -0.1630, -0.0286, -0.1434,  0.0200,  0.1903,\n",
      "           0.0256, -0.0875,  0.0166,  0.1353]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.5872, -1.5382, -0.7546,  1.1743, -0.8101, -0.6141, -1.0717,\n",
      "          -1.3127,  0.8379, -1.2590, -0.3344, -0.3279,  1.5497, -1.0905,\n",
      "          -1.3051, -1.7205, -0.1862, -2.1010, -1.3733, -0.3894, -1.3879,\n",
      "           1.1720,  0.0000,  1.4320,  1.9067, -1.1301, -0.2795,  0.0000,\n",
      "           1.8541,  0.5400, -0.2220,  0.1583,  0.8629,  0.0000,  0.1124,\n",
      "           0.4884,  0.0260, -0.8414, -1.0329, -1.7765, -0.9626, -0.3870,\n",
      "          -0.5588,  0.1230,  0.1159,  1.6971, -0.1827,  0.9722,  2.4063,\n",
      "           1.2868,  0.4630,  0.5025,  1.7769,  0.2835, -0.1928,  0.4507,\n",
      "           0.0000, -0.0551, -0.2589, -0.1064,  1.0237, -0.4096,  1.3336,\n",
      "          -0.6536,  0.2772, -0.3839,  0.9525, -1.6850, -1.1699, -0.7887,\n",
      "           0.0000, -1.5125,  0.0231, -0.9737, -0.6341,  0.0378,  0.7242,\n",
      "           0.0447,  0.1145, -0.5425,  1.0743, -1.6209,  2.4654, -0.7318,\n",
      "           0.0000,  0.3704,  0.4051,  0.0000, -0.3130, -0.2495,  1.2639,\n",
      "           1.4981,  0.8409,  1.5752,  0.9576,  0.3810,  1.4621, -1.0043,\n",
      "           0.3876,  2.5202, -0.4162, -0.4033,  0.0000, -1.8309, -0.1045,\n",
      "          -1.2292,  0.0000,  0.6362, -0.1233,  1.6548, -0.3786,  0.6147,\n",
      "          -1.2789,  2.0569, -1.7536,  0.7896,  0.2347,  0.0000, -0.0764,\n",
      "           0.9296,  0.8686,  2.4414, -0.6769,  1.7225,  0.5146, -0.1888,\n",
      "           0.6203, -1.1052,  1.2886,  0.4505,  0.7912,  0.6654,  1.3643,\n",
      "          -1.9301,  0.9718,  0.0000,  0.1495, -0.1501,  1.1243, -0.5446,\n",
      "           0.5539,  0.0000,  0.9022, -1.7465, -2.0191,  0.7694, -0.5768,\n",
      "          -0.1591,  0.0000, -1.1146,  0.0000,  0.0000,  0.8168, -0.9827,\n",
      "          -2.2549, -0.6084,  0.1945,  1.3200,  1.4830, -1.1931,  1.6437,\n",
      "           1.4027, -0.1463, -0.0871, -0.4160,  1.8354, -0.8030,  0.9190,\n",
      "          -0.5721,  0.0329,  1.2196, -2.3010,  1.1171,  0.0000,  1.1491,\n",
      "          -0.3780, -1.5811,  0.1986,  0.7216,  1.4463,  0.5731,  0.0887,\n",
      "           0.1162,  0.0000,  0.5031,  1.3033, -0.2211, -0.2388,  0.1826,\n",
      "          -2.2104, -0.2568,  0.3609, -1.3158,  0.0000,  0.1565, -1.7942,\n",
      "          -1.4364, -0.8882,  0.5561,  0.3951,  0.1623,  0.0939,  0.6942,\n",
      "          -2.4306,  0.0000,  0.7793, -0.2191, -0.8151,  1.0581,  0.0000,\n",
      "          -0.2233, -1.4587,  0.0437, -0.1200,  0.7293,  1.5439,  0.0000,\n",
      "           0.3692, -0.9897,  0.0122, -1.2841,  0.7154, -0.6999, -0.4162,\n",
      "          -3.5975,  0.9405,  1.8602,  0.8237, -0.5736, -0.8765, -0.1285,\n",
      "           0.0671,  0.0377, -1.5637,  2.6763, -2.2634, -0.3977, -1.2050,\n",
      "          -0.4047, -1.1441,  1.1101,  0.0000,  0.4644,  0.1218,  1.4650,\n",
      "           1.4993,  1.5406, -1.9319, -0.9461, -0.9350, -0.3432,  0.8940,\n",
      "          -1.1450, -2.0696,  0.4555,  1.6399]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0434, 0.0722, 0.0774, 0.1756, 0.0825, 0.0649, 0.0926, 0.1239, 0.1629,\n",
      "         0.1045]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0265,  0.1434, -0.1416,  ...,  0.5617,  0.1759, -0.1771],\n",
      "        [-0.1597, -0.0520,  0.3840,  ...,  0.2109, -0.1090, -0.1263],\n",
      "        [ 0.1568,  0.0828,  0.3426,  ...,  0.4834,  0.1998, -0.0408],\n",
      "        ...,\n",
      "        [ 0.7578,  0.6284, -0.7384,  ..., -0.4859,  0.0551,  0.3483],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.5173e-01,  1.7168e-01,  2.3469e-02, -1.2468e-01, -9.0225e-03,\n",
      "           1.8239e-02, -1.3364e-01, -3.2059e-02, -1.2869e-01, -3.1759e-02,\n",
      "           2.2033e-02,  1.4586e-02,  1.0584e-01, -6.6601e-02,  1.6200e-01,\n",
      "           6.2279e-02,  3.3687e-02, -7.0554e-02, -1.9934e-01,  1.1983e-02,\n",
      "          -4.6136e-03, -3.5063e-01, -5.2479e-02,  4.3883e-02, -1.9248e-02,\n",
      "          -3.8204e-02, -5.8737e-03, -2.0567e-01, -9.7576e-02, -6.6601e-02,\n",
      "           3.5789e-01, -2.4363e-02,  2.3985e-02, -8.0377e-02, -5.4953e-02,\n",
      "          -1.8698e-02, -9.8722e-02,  7.7347e-02, -1.8825e-01, -2.3437e-02,\n",
      "          -7.0454e-02,  1.1418e-01, -1.7526e-01, -1.7905e-01,  1.0167e-01,\n",
      "           2.8307e-02,  3.7541e-02, -1.5760e-01, -3.5937e-02, -9.9650e-02,\n",
      "          -1.4951e-01, -1.2938e-01, -1.0354e-02, -1.3105e-01, -1.4364e-01,\n",
      "          -2.3277e-01, -2.0124e-02, -1.5814e-01,  1.7744e-01,  3.8585e-01,\n",
      "          -6.1722e-02,  3.6788e-02, -1.1624e-01, -3.1273e-02, -7.7477e-02,\n",
      "          -8.1391e-02,  4.5860e-02,  1.1372e-01, -7.4364e-02,  1.9329e-01,\n",
      "          -2.4986e-02,  2.8118e-01, -1.5738e-01, -8.6677e-02, -1.7707e-01,\n",
      "           2.0724e-02,  9.9434e-02,  1.2887e-01, -1.7632e-01,  3.3581e-01,\n",
      "           5.6952e-02, -1.5986e-01, -2.7250e-01,  2.4690e-01,  3.3428e-02,\n",
      "           2.0072e-01,  6.5370e-02,  2.1979e-01,  1.8943e-01, -9.0783e-03,\n",
      "           2.8582e-02, -1.2624e-01, -1.2539e-01,  1.7642e-01,  1.7315e-01,\n",
      "          -2.3261e-02, -3.0360e-02,  2.2795e-01, -7.9694e-03,  2.3680e-01,\n",
      "          -1.0063e-01, -8.5130e-02,  1.5572e-01,  1.5169e-02, -5.7702e-02,\n",
      "          -2.0267e-01,  1.9929e-02,  5.8066e-02,  7.5951e-02,  1.9730e-01,\n",
      "           7.7600e-03,  4.3919e-02,  6.5647e-02, -2.1609e-01,  3.0934e-03,\n",
      "           1.1066e-01, -5.4292e-02,  1.5862e-02, -6.4416e-02,  3.6814e-02,\n",
      "           1.9974e-01,  9.6586e-02, -2.2066e-01,  6.7835e-02, -2.0499e-01,\n",
      "          -2.2318e-01, -1.7595e-01,  6.6459e-02,  1.9015e-01, -3.6056e-02,\n",
      "           2.9638e-01, -2.6170e-01,  1.0231e-01,  1.3692e-01, -1.5975e-01,\n",
      "          -1.5571e-01, -6.0406e-02, -1.9628e-02, -1.6091e-01,  5.9324e-02,\n",
      "          -7.8439e-02,  4.1013e-01, -6.1361e-02,  2.8433e-01,  1.6691e-03,\n",
      "           1.8120e-01, -9.8146e-02,  2.9081e-01,  1.2137e-01,  2.3044e-01,\n",
      "          -1.7783e-01, -1.9101e-02, -2.5179e-02,  1.7765e-01, -6.0752e-02,\n",
      "           4.6980e-02, -1.4686e-01,  1.3273e-01, -8.6632e-02, -1.6839e-01,\n",
      "          -1.0969e-01, -1.1139e-01, -1.1590e-01,  2.8962e-01,  4.0320e-02,\n",
      "          -3.5834e-02, -3.4089e-03,  1.7115e-01, -2.9900e-03,  9.0174e-02,\n",
      "          -2.6711e-01, -1.1730e-01,  1.3212e-01,  1.3638e-01, -1.0705e-02,\n",
      "          -7.7117e-02, -2.6638e-02, -1.9681e-02,  1.7809e-01, -1.5512e-01,\n",
      "          -2.8383e-02, -1.2283e-01, -5.8372e-03,  1.1562e-02, -6.3008e-02,\n",
      "           2.6959e-02, -1.3261e-01, -8.7421e-02,  6.4985e-02, -1.4212e-01,\n",
      "           1.5997e-01,  1.1361e-01, -1.0153e-01, -1.6865e-01,  6.7313e-02,\n",
      "          -1.5987e-01, -1.8688e-01,  2.2816e-01, -5.9902e-02, -1.1980e-01,\n",
      "          -1.4451e-01,  2.2897e-01,  7.5968e-02,  1.7892e-01, -7.8232e-02,\n",
      "          -1.1773e-01, -4.5319e-02,  2.1189e-01,  4.4440e-02, -1.9095e-02,\n",
      "          -6.0427e-02,  2.5681e-02, -1.0849e-01,  8.2441e-02, -1.0172e-02,\n",
      "           7.8022e-02, -1.5949e-02,  1.5869e-01, -4.8929e-02,  1.2959e-01,\n",
      "           2.9792e-01, -3.8958e-02,  2.3043e-01, -2.1148e-01, -3.0622e-04,\n",
      "           1.3740e-01, -7.4166e-02, -1.2728e-01, -2.9667e-01,  1.2840e-01,\n",
      "          -1.8844e-01, -6.9371e-02, -1.8250e-01, -1.4106e-01,  1.4696e-02,\n",
      "          -9.6255e-02, -2.6102e-01,  1.2721e-01,  3.4541e-01,  2.1595e-01,\n",
      "          -5.4042e-03, -3.2060e-01, -1.1124e-01,  1.3480e-01,  8.8524e-02,\n",
      "          -1.3309e-01, -2.7033e-01, -1.3912e-01,  1.1773e-01, -4.0382e-02,\n",
      "           4.1786e-02,  1.0254e-01, -3.5113e-02, -6.1166e-03,  1.2401e-01,\n",
      "           7.5768e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0627e+00, -6.9847e-02, -1.8077e+00,  1.3221e+00,  5.1616e-01,\n",
      "           0.0000e+00,  1.1760e-03, -7.2330e-01,  2.1179e+00, -2.1403e-01,\n",
      "           2.8246e-01,  8.3071e-01, -1.1108e+00,  1.9998e-01,  3.1212e-01,\n",
      "           3.5166e-01, -6.8290e-01,  1.6897e-01,  0.0000e+00,  5.4578e-01,\n",
      "           1.8832e+00,  6.0178e-01, -3.6550e-02, -5.3547e-01, -9.9608e-02,\n",
      "           6.5075e-01, -1.6086e+00, -1.3626e+00, -2.1269e+00,  0.0000e+00,\n",
      "           3.9131e-02, -1.4549e+00, -2.0765e+00,  0.0000e+00, -2.8508e-01,\n",
      "          -2.0018e+00,  2.1913e-01,  9.9691e-01,  6.0111e-01,  9.5388e-01,\n",
      "           0.0000e+00, -2.2113e+00, -7.0644e-01,  0.0000e+00,  8.9341e-02,\n",
      "          -1.1386e+00,  2.4260e-01,  7.4171e-01, -7.0977e-01, -1.3359e+00,\n",
      "           1.6090e+00, -1.3697e-01,  6.6307e-01,  1.1163e+00,  0.0000e+00,\n",
      "           3.3347e-01, -4.4977e-01, -8.8844e-01,  1.3385e-01,  6.2859e-01,\n",
      "          -7.0530e-01,  5.6373e-01, -6.9329e-01, -1.5473e+00,  2.8929e-01,\n",
      "           9.5714e-02, -1.7772e-01,  5.9457e-01, -2.1382e+00,  5.5974e-01,\n",
      "           1.8287e-01, -5.1255e-01, -3.4129e-01, -1.1318e+00, -6.4710e-01,\n",
      "           4.6088e-01, -1.0495e+00,  1.1910e-01,  5.1720e-01, -1.8685e-01,\n",
      "          -3.8488e-01,  2.1583e+00,  7.7755e-01, -8.4569e-01,  0.0000e+00,\n",
      "           4.1918e-01,  1.6044e+00, -5.6433e-01, -1.4135e+00, -1.4907e+00,\n",
      "           4.0438e-01, -3.5164e-01,  4.9409e-01, -2.3208e+00,  1.2380e+00,\n",
      "          -9.6269e-01,  1.3203e+00, -9.0774e-01,  0.0000e+00,  9.5534e-01,\n",
      "          -1.2011e+00,  5.9440e-01,  1.0666e+00,  0.0000e+00,  3.6546e-01,\n",
      "           4.0223e-01, -1.2707e+00,  4.5532e-01,  1.9687e+00,  0.0000e+00,\n",
      "          -8.3216e-01,  5.3387e-01,  8.0809e-01,  6.6421e-01, -1.0547e+00,\n",
      "           9.1745e-01, -7.0263e-01,  0.0000e+00,  2.5782e-01,  8.7985e-01,\n",
      "          -8.7681e-01, -1.3969e+00, -3.6505e-01,  0.0000e+00, -1.3008e+00,\n",
      "           1.0693e+00, -8.1161e-01,  6.4922e-01,  2.5573e-01, -1.4894e+00,\n",
      "           2.5026e+00,  3.7802e-01, -1.3459e+00,  0.0000e+00,  3.2015e+00,\n",
      "           0.0000e+00, -3.8336e-01,  1.2822e+00,  0.0000e+00,  1.9378e-01,\n",
      "          -3.9542e-02,  3.0304e+00,  0.0000e+00, -1.8695e-01, -1.1118e+00,\n",
      "           1.2471e+00,  7.7534e-01, -7.7459e-01, -4.5083e-02, -1.3874e+00,\n",
      "           2.3360e+00,  0.0000e+00, -2.8974e-01,  0.0000e+00, -5.8141e-01,\n",
      "           7.8599e-01, -1.8621e+00,  0.0000e+00,  1.9019e-01, -3.6290e+00,\n",
      "          -1.8685e+00,  1.1507e+00, -8.5937e-01,  9.5982e-01, -1.4616e+00,\n",
      "           0.0000e+00,  1.9744e+00,  1.1272e+00, -4.8602e-01, -1.2415e+00,\n",
      "          -2.1184e-01, -1.3225e+00, -1.6393e+00,  0.0000e+00,  6.8264e-01,\n",
      "          -1.3796e+00, -1.2641e-01,  6.0658e-01,  0.0000e+00,  2.5917e-01,\n",
      "           1.3327e+00, -2.5535e+00,  2.7782e-01, -5.8391e-01,  1.6237e+00,\n",
      "          -1.2402e+00, -1.8358e-03, -5.0242e-02,  9.0170e-01,  5.6561e-01,\n",
      "          -4.1994e-01,  3.8794e-01,  0.0000e+00,  8.0957e-01,  0.0000e+00,\n",
      "          -7.8913e-01, -1.4390e+00, -4.1620e-01, -7.5048e-01, -4.5433e-01,\n",
      "          -5.4748e-01,  7.2216e-01, -1.8537e+00,  1.3575e+00,  8.3774e-01,\n",
      "          -1.5242e+00, -3.5876e-01,  6.4809e-01,  2.0067e-01, -2.1785e+00,\n",
      "           8.3562e-01, -1.2914e+00,  0.0000e+00,  2.6111e-01, -1.5634e+00,\n",
      "           0.0000e+00,  1.3415e-01,  2.5768e+00, -3.1315e-02, -5.7927e-01,\n",
      "          -1.4285e+00,  1.9010e+00, -3.8094e-01,  1.4693e+00,  8.0510e-01,\n",
      "           3.6910e-01,  6.6979e-01, -7.0068e-01,  8.9188e-02,  1.0254e+00,\n",
      "           0.0000e+00, -1.4084e+00,  6.5972e-01,  0.0000e+00, -1.6455e+00,\n",
      "          -6.0017e-01,  8.9495e-03, -7.1121e-01,  3.7051e-01, -2.2449e-01,\n",
      "          -7.5246e-01,  5.7211e-01,  5.3080e-01, -6.6345e-01,  1.5466e+00,\n",
      "           5.7865e-01,  1.8919e+00, -8.6444e-01,  4.9332e-01, -3.8739e-01,\n",
      "           5.0029e-01, -9.7531e-01,  1.7728e+00, -1.0633e+00, -8.0808e-01,\n",
      "          -6.2166e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0559, 0.0937, 0.1539, 0.1379, 0.1209, 0.1656, 0.0714, 0.0531, 0.0573,\n",
      "         0.0903]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0265,  0.1434, -0.1416,  ...,  0.5617,  0.1759, -0.1771],\n",
      "        [-0.1597, -0.0520,  0.3840,  ...,  0.2109, -0.1090, -0.1263],\n",
      "        [ 0.1568,  0.0828,  0.3426,  ...,  0.4834,  0.1998, -0.0408],\n",
      "        ...,\n",
      "        [ 0.7578,  0.6284, -0.7384,  ..., -0.4859,  0.0551,  0.3483],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0027e-01,  1.7221e-01,  8.2956e-02, -1.7156e-01,  3.7394e-02,\n",
      "           1.1271e-01, -1.8381e-01,  4.2052e-02, -1.5191e-01, -2.1952e-02,\n",
      "           1.0755e-02,  8.4487e-02,  2.0498e-01, -1.3019e-01,  1.2853e-01,\n",
      "           8.0882e-02, -2.3792e-03, -1.4121e-01, -1.8053e-01,  5.4708e-03,\n",
      "           6.6139e-02, -3.7105e-01, -1.7539e-01, -7.7853e-03,  3.1340e-02,\n",
      "           1.2526e-02, -4.3403e-02, -1.5778e-01, -1.0348e-01, -2.8897e-02,\n",
      "           3.9175e-01,  5.7319e-02,  1.1809e-01, -8.4734e-03, -8.5998e-02,\n",
      "          -8.2985e-02, -8.9729e-02,  1.0620e-01, -1.2863e-01, -6.3811e-02,\n",
      "          -6.8414e-02,  1.2598e-01, -1.6328e-01, -2.6202e-01,  1.0641e-01,\n",
      "          -5.9041e-03,  1.2592e-01, -1.0503e-01, -6.1887e-02, -1.3568e-01,\n",
      "          -1.4963e-01, -1.2977e-01,  5.5428e-02, -1.7432e-01, -1.6106e-01,\n",
      "          -2.8807e-01, -1.7782e-02, -2.7879e-01,  1.7443e-01,  4.0732e-01,\n",
      "          -6.2286e-02,  9.8041e-02, -5.2658e-02, -7.5395e-02, -2.8506e-02,\n",
      "          -9.6902e-02,  9.6092e-02,  8.8637e-02, -3.7298e-02,  2.3858e-01,\n",
      "          -6.1032e-02,  2.5420e-01, -1.5725e-01, -1.7350e-01, -1.6216e-01,\n",
      "          -3.7293e-02,  4.6629e-02,  8.7483e-02, -1.7939e-01,  3.8620e-01,\n",
      "           1.1332e-01, -9.7570e-02, -2.4626e-01,  3.0817e-01,  5.2696e-02,\n",
      "           1.8505e-01,  6.1950e-02,  2.4552e-01,  1.5979e-01,  3.3535e-04,\n",
      "          -2.2288e-02, -1.3858e-01, -1.6970e-01,  2.3921e-01,  2.2174e-01,\n",
      "          -7.7641e-02, -8.8191e-02,  1.7984e-01, -2.9586e-03,  2.1571e-01,\n",
      "           3.7732e-03, -2.1948e-01,  1.4188e-01,  2.2896e-02, -5.9126e-02,\n",
      "          -2.5772e-01, -9.8378e-02, -7.0030e-02,  1.1380e-01,  1.9621e-01,\n",
      "          -6.8898e-02,  1.0448e-01,  1.7881e-02, -1.9277e-01,  1.1049e-01,\n",
      "           1.3525e-01, -8.3223e-02,  6.9380e-02, -6.2751e-02,  6.2745e-02,\n",
      "           2.0664e-01,  1.9573e-01, -2.1610e-01,  6.2890e-02, -2.0094e-01,\n",
      "          -2.4709e-01, -2.0501e-01,  9.6862e-02,  1.9361e-01, -2.3569e-02,\n",
      "           3.0032e-01, -2.2398e-01,  2.4110e-02,  9.3453e-02, -1.8758e-01,\n",
      "          -2.3873e-01, -1.5311e-01, -5.5862e-02, -1.4790e-01,  2.7785e-03,\n",
      "          -8.4987e-02,  4.5256e-01, -3.6552e-02,  3.0966e-01, -6.3002e-02,\n",
      "           2.4026e-01, -1.2141e-01,  2.4553e-01,  1.3607e-01,  2.6267e-01,\n",
      "          -1.2249e-01, -6.3660e-02,  4.9901e-03,  1.5491e-01, -1.7768e-01,\n",
      "          -7.7478e-02, -1.9314e-01,  1.2568e-01, -1.9810e-01, -1.3805e-01,\n",
      "          -8.6156e-02, -4.7911e-02, -4.7989e-02,  2.3576e-01,  2.1928e-02,\n",
      "          -6.9637e-02,  6.2949e-02,  2.3245e-01, -7.5038e-02,  2.8554e-02,\n",
      "          -2.6185e-01, -1.7004e-01,  7.3029e-02,  2.1009e-01,  4.4321e-02,\n",
      "          -7.3387e-02,  2.5338e-02, -8.9380e-02,  7.7713e-02, -1.5388e-01,\n",
      "           1.8888e-02, -1.1327e-01,  5.7097e-02,  3.1447e-03, -1.4668e-01,\n",
      "          -3.3538e-02, -9.5556e-02, -1.5181e-01,  2.7775e-02, -7.6696e-02,\n",
      "           1.8466e-01,  1.2397e-01, -3.3598e-02, -1.4487e-01,  9.2346e-02,\n",
      "          -1.4703e-01, -1.9986e-01,  3.0106e-01,  8.8096e-03, -1.7093e-01,\n",
      "          -1.6089e-01,  2.4405e-01,  1.4274e-01,  1.2986e-01, -1.0507e-01,\n",
      "          -8.0999e-02, -1.9927e-02,  1.6472e-01,  6.6473e-02,  2.9605e-02,\n",
      "          -1.0457e-01,  7.9283e-02, -1.5561e-01,  6.0245e-03, -3.0351e-03,\n",
      "           5.0672e-02, -3.7250e-03,  1.9630e-01,  2.9411e-02,  8.0029e-02,\n",
      "           3.2122e-01,  3.0959e-02,  2.2003e-01, -2.4508e-01, -4.1816e-02,\n",
      "           8.3750e-02, -1.3322e-01, -7.3439e-02, -2.2298e-01,  5.9694e-02,\n",
      "          -1.6739e-01, -7.5421e-02, -2.3834e-01, -7.4965e-02,  4.9139e-02,\n",
      "          -1.5170e-01, -2.6473e-01,  1.7725e-01,  3.6613e-01,  2.7953e-01,\n",
      "           6.7075e-03, -3.8008e-01, -1.0473e-01,  1.7435e-01,  8.1023e-02,\n",
      "          -1.6334e-01, -2.5635e-01, -1.2961e-01,  7.4440e-02, -9.0964e-02,\n",
      "           7.5444e-03,  1.1857e-01,  7.0469e-02,  4.8459e-02,  9.6855e-02,\n",
      "           5.8761e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.2437e-01,  3.5255e-01, -8.0081e-02, -1.3113e+00, -1.3290e+00,\n",
      "           2.4069e+00, -8.3509e-01, -9.9390e-01, -2.5780e+00, -2.0714e+00,\n",
      "           0.0000e+00,  8.3902e-02,  8.7725e-02,  1.9776e+00, -2.2523e+00,\n",
      "           1.7774e+00,  1.7626e+00,  0.0000e+00,  7.5156e-01,  1.2899e+00,\n",
      "           8.2139e-02, -2.0854e-01,  1.2020e+00, -2.5483e-01, -2.2054e+00,\n",
      "           8.8678e-01, -1.7972e+00, -7.7292e-01,  6.5448e-01,  1.1356e+00,\n",
      "           1.0219e-01, -8.1088e-01,  1.6570e-01,  1.1107e+00,  5.9842e-01,\n",
      "          -6.6252e-01, -5.5469e-01, -1.5767e+00,  0.0000e+00,  1.1561e+00,\n",
      "          -3.1753e-01, -4.7132e-01,  3.8196e-01,  0.0000e+00, -7.3546e-03,\n",
      "           1.6406e-01,  6.4235e-01, -3.8481e-01, -1.0134e+00,  1.3017e-01,\n",
      "           3.5801e+00, -8.3315e-02,  1.3067e+00, -9.5574e-01, -1.6349e+00,\n",
      "           2.0185e-01,  3.2100e-01,  2.6926e+00,  3.3403e+00, -5.3409e-01,\n",
      "          -9.6699e-03,  0.0000e+00, -2.0303e+00,  7.1012e-01, -1.6008e+00,\n",
      "          -6.8047e-01,  1.5329e+00, -7.2068e-01, -1.2593e+00, -8.2400e-01,\n",
      "          -2.0331e+00, -4.3923e-01,  1.5241e-01, -1.0314e-01, -2.4096e-03,\n",
      "           9.1083e-02,  0.0000e+00,  0.0000e+00,  2.0717e+00,  1.6739e-01,\n",
      "           6.6209e-02,  8.9689e-01,  0.0000e+00,  2.1252e-01,  6.4409e-01,\n",
      "           1.5536e+00, -1.9321e+00,  1.8702e+00,  1.4205e+00,  8.6670e-01,\n",
      "          -4.7474e-01, -2.9534e-01, -4.8489e-01, -1.1562e+00,  0.0000e+00,\n",
      "          -1.3482e+00, -1.9771e-01, -6.9363e-02, -1.0940e+00,  0.0000e+00,\n",
      "           1.4957e+00, -2.7932e-01,  7.0518e-02, -4.9074e-01, -6.8168e-01,\n",
      "          -1.6432e+00,  2.7502e-01,  1.1505e+00,  2.2237e+00,  7.5056e-01,\n",
      "          -4.6500e-03,  0.0000e+00, -5.8790e-01,  1.4413e-02,  1.6837e-01,\n",
      "           1.2384e+00,  0.0000e+00, -1.9479e-01, -8.2613e-01,  2.0125e+00,\n",
      "          -1.0752e+00, -1.6012e+00,  0.0000e+00, -7.1157e-01, -1.1192e+00,\n",
      "           1.3888e+00, -3.1886e-01,  2.8103e+00,  3.3496e-01,  4.3697e-01,\n",
      "          -1.4599e-01, -1.2206e+00,  2.0291e+00,  1.6185e+00,  9.4368e-02,\n",
      "           6.0936e-01,  1.3760e-01, -7.1077e-01,  1.0007e+00, -4.1823e-01,\n",
      "          -8.6296e-01, -1.1859e+00,  1.0432e+00, -8.7960e-01,  4.6326e-01,\n",
      "          -1.5588e+00,  1.1385e+00, -5.8105e-01, -4.9429e-01,  2.0514e+00,\n",
      "           5.6265e-01,  0.0000e+00, -1.2228e+00, -6.3242e-01,  1.3044e+00,\n",
      "           6.8260e-01,  1.4305e+00,  2.6892e-01,  0.0000e+00,  3.0881e-01,\n",
      "           1.3124e-01, -1.8825e+00, -1.6898e-01,  5.5578e-01, -1.5973e+00,\n",
      "           1.8262e+00, -2.2882e+00, -1.4161e+00, -6.9003e-01,  5.4735e-02,\n",
      "           1.8333e-01, -8.3080e-01,  3.0991e-01,  1.2493e+00,  1.5159e+00,\n",
      "           0.0000e+00, -9.5982e-01, -6.4993e-02,  2.3535e-01,  1.3197e+00,\n",
      "          -5.6791e-01, -2.8792e-02, -2.9168e-02,  5.3558e-01, -1.2823e+00,\n",
      "           0.0000e+00, -1.1040e+00,  1.8826e-01,  3.1355e-01,  1.4664e+00,\n",
      "          -5.2896e-01,  0.0000e+00,  0.0000e+00,  4.8204e-01, -1.0952e+00,\n",
      "          -9.5117e-02,  1.6142e+00, -8.4965e-01,  1.5263e+00, -9.1878e-01,\n",
      "           0.0000e+00, -8.3608e-01,  1.0336e+00, -1.7186e+00,  0.0000e+00,\n",
      "           2.2368e-01,  4.0896e-02,  1.0941e+00, -2.2127e-02, -3.7820e-01,\n",
      "           1.0672e+00, -7.1595e-02,  1.3193e+00,  2.6265e+00,  2.6309e-01,\n",
      "          -2.5239e+00, -1.1873e+00,  9.4480e-01, -1.7475e+00, -1.7460e+00,\n",
      "          -1.3551e+00,  1.3867e+00, -3.8459e-01,  1.9109e+00, -1.7618e+00,\n",
      "           5.1126e-01,  7.2390e-01,  0.0000e+00,  3.2955e+00,  5.7670e-01,\n",
      "           1.8207e-01, -2.8379e-01,  1.5445e-01, -1.7616e+00,  6.3761e-01,\n",
      "          -1.2167e+00,  1.4666e+00,  5.0882e-01, -4.0273e-01,  1.1722e-01,\n",
      "           0.0000e+00,  0.0000e+00,  6.0239e-01, -2.8883e-01, -1.4350e+00,\n",
      "           1.0126e+00,  4.7668e-01, -1.9684e+00,  2.5177e+00, -1.4498e+00,\n",
      "           1.3675e+00, -5.7720e-01, -1.0445e+00,  0.0000e+00,  1.2500e+00,\n",
      "           1.1791e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.1090, 0.1093, 0.0485, 0.1115, 0.1159, 0.0988, 0.1300, 0.0570, 0.1548,\n",
      "         0.0653]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0265,  0.1434, -0.1416,  ...,  0.5617,  0.1759, -0.1771],\n",
      "        [-0.1597, -0.0520,  0.3840,  ...,  0.2109, -0.1090, -0.1263],\n",
      "        [ 0.1568,  0.0828,  0.3426,  ...,  0.4834,  0.1998, -0.0408],\n",
      "        ...,\n",
      "        [ 0.7578,  0.6284, -0.7384,  ..., -0.4859,  0.0551,  0.3483],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1898,  0.1491,  0.0162, -0.1449,  0.0662,  0.1369, -0.1992,\n",
      "           0.0067, -0.1196, -0.0248,  0.0133,  0.0631,  0.0983, -0.0511,\n",
      "           0.1462,  0.0737, -0.0272, -0.0968, -0.2084, -0.0144,  0.0483,\n",
      "          -0.3161, -0.1003,  0.0245,  0.0464, -0.0057,  0.0081, -0.1821,\n",
      "          -0.0487,  0.0108,  0.3679,  0.0263,  0.0759, -0.0417, -0.0895,\n",
      "          -0.0492, -0.1058,  0.0809, -0.1668, -0.0708, -0.0756,  0.1411,\n",
      "          -0.1784, -0.2294,  0.0746,  0.0352,  0.0667, -0.1195, -0.0454,\n",
      "          -0.1111, -0.1220, -0.1109,  0.0380, -0.1781, -0.1536, -0.2231,\n",
      "          -0.0343, -0.2604,  0.1879,  0.3598, -0.0860,  0.0774, -0.0767,\n",
      "          -0.0598, -0.0278, -0.0586,  0.0504,  0.1153, -0.0470,  0.2138,\n",
      "           0.0044,  0.2734, -0.1034, -0.1252, -0.1774,  0.0137,  0.1222,\n",
      "           0.0955, -0.1462,  0.3566,  0.0832, -0.0807, -0.2882,  0.2608,\n",
      "           0.0379,  0.1407,  0.0721,  0.2204,  0.1913,  0.0275,  0.0213,\n",
      "          -0.1687, -0.2189,  0.1967,  0.1911, -0.0307, -0.0582,  0.1697,\n",
      "           0.0442,  0.2167, -0.0362, -0.0674,  0.1346,  0.0328, -0.0296,\n",
      "          -0.2639, -0.0281,  0.0268,  0.0333,  0.1845, -0.1007,  0.0738,\n",
      "           0.0046, -0.2237,  0.0704,  0.1315, -0.0603,  0.0020, -0.0817,\n",
      "           0.0277,  0.1441,  0.1785, -0.2218,  0.0772, -0.2069, -0.2206,\n",
      "          -0.1546,  0.0242,  0.1518, -0.0370,  0.2753, -0.2053, -0.0186,\n",
      "           0.1352, -0.1765, -0.2131, -0.0668, -0.0081, -0.1477,  0.0446,\n",
      "          -0.0942,  0.4015, -0.0331,  0.2580, -0.0167,  0.1986, -0.0725,\n",
      "           0.2660,  0.1416,  0.2308, -0.1127, -0.0144, -0.0143,  0.1487,\n",
      "          -0.1044, -0.0170, -0.1694,  0.1002, -0.1591, -0.1643, -0.1279,\n",
      "          -0.0456, -0.0604,  0.2725, -0.0148, -0.0781, -0.0064,  0.1781,\n",
      "          -0.0715,  0.0224, -0.2454, -0.0983,  0.1188,  0.1651,  0.0261,\n",
      "          -0.0728,  0.0223, -0.0537,  0.0874, -0.1283, -0.0145, -0.1059,\n",
      "           0.0100, -0.0067, -0.1060, -0.0307, -0.0713, -0.1178, -0.0094,\n",
      "          -0.1151,  0.1803,  0.1039, -0.0580, -0.1663,  0.0289, -0.1511,\n",
      "          -0.1715,  0.2121, -0.0155, -0.1274, -0.1455,  0.2103,  0.0975,\n",
      "           0.1463, -0.1087, -0.0736, -0.0057,  0.1627,  0.1071, -0.0149,\n",
      "          -0.1229,  0.0582, -0.1414,  0.0378,  0.0135,  0.0263,  0.0412,\n",
      "           0.1498, -0.0067,  0.0604,  0.3004,  0.0458,  0.2041, -0.2172,\n",
      "          -0.0045,  0.1233, -0.1208, -0.0639, -0.2549,  0.0789, -0.1826,\n",
      "          -0.0990, -0.1950, -0.1012,  0.0492, -0.1509, -0.2484,  0.0803,\n",
      "           0.3779,  0.2283,  0.0416, -0.3338, -0.1124,  0.1602,  0.0556,\n",
      "          -0.1262, -0.2365, -0.1305,  0.0692, -0.0995,  0.0311,  0.1367,\n",
      "           0.0225,  0.0054,  0.1011,  0.0384]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7274e-01, -4.3085e-01,  3.1538e-01, -1.0854e+00, -1.1730e+00,\n",
      "           7.4165e-01, -1.9147e+00,  1.3514e+00,  1.9013e-01,  6.1747e-01,\n",
      "           1.9037e+00,  0.0000e+00,  0.0000e+00, -9.1676e-01, -3.1844e+00,\n",
      "          -6.8301e-02, -1.6339e+00, -9.4356e-01,  0.0000e+00, -1.4359e+00,\n",
      "          -1.4036e-01, -5.2457e-01, -1.1201e+00, -2.5962e+00, -7.5975e-02,\n",
      "           0.0000e+00, -6.2006e-01,  1.9984e+00,  1.2773e-01,  5.5545e-01,\n",
      "           9.1611e-01, -3.8730e-03,  2.2231e-01,  2.0173e+00, -6.3567e-02,\n",
      "           0.0000e+00,  0.0000e+00, -8.1734e-01,  3.1530e-01,  8.6160e-02,\n",
      "           8.6367e-01, -8.9925e-01,  1.0090e+00, -1.5643e+00,  1.9451e+00,\n",
      "           0.0000e+00,  7.0662e-01, -6.0260e-01, -1.0210e+00,  1.1174e+00,\n",
      "          -1.3235e+00,  0.0000e+00,  6.6707e-01, -8.4709e-01,  2.2813e-01,\n",
      "          -3.1025e-01, -1.4341e+00, -9.6111e-02,  1.2761e+00,  0.0000e+00,\n",
      "          -1.0068e+00,  0.0000e+00, -2.8017e-01,  2.6573e-01, -6.3286e-02,\n",
      "           3.9351e-01,  5.7821e-01,  1.1656e+00,  1.5813e+00, -1.4155e+00,\n",
      "           0.0000e+00,  2.9645e-01, -3.0963e-02, -7.9819e-01, -2.1411e-01,\n",
      "           1.3951e-01,  5.2601e-01,  0.0000e+00,  1.0275e+00, -7.9451e-01,\n",
      "           7.5864e-01, -1.0048e+00,  7.5852e-01,  1.0590e+00, -1.2159e+00,\n",
      "          -1.1335e-01, -1.1084e+00,  5.4874e-01, -9.4505e-01, -1.9015e+00,\n",
      "           5.2932e-01,  9.8763e-01,  1.7023e+00,  9.4437e-01,  6.0800e-01,\n",
      "          -1.5889e-02,  3.5443e-01, -1.1762e+00,  1.3728e+00,  2.4483e+00,\n",
      "           2.4340e-01,  0.0000e+00, -4.6667e-01, -9.8951e-01,  1.6415e+00,\n",
      "           0.0000e+00,  3.0307e+00,  6.2091e-01, -1.0189e-01, -1.2358e+00,\n",
      "           1.9000e-01, -5.0348e-01, -5.7117e-01,  7.1270e-01, -7.8078e-01,\n",
      "           0.0000e+00,  4.0376e-01,  2.2339e-01, -2.3274e+00,  2.9205e-02,\n",
      "          -8.1493e-01, -1.4120e+00, -1.8389e+00,  6.0327e-01, -9.5741e-01,\n",
      "          -2.0111e-01,  4.0372e-02,  2.1510e+00,  1.3967e+00, -2.0885e+00,\n",
      "          -9.2632e-01,  4.5009e-01, -1.1685e+00,  4.2554e-01, -4.6828e-01,\n",
      "          -7.4659e-01, -1.0650e+00, -9.7565e-01, -1.9393e-02,  2.3982e+00,\n",
      "           6.9865e-01, -1.1220e+00,  1.6920e+00, -1.4046e-01, -6.7013e-01,\n",
      "           3.3073e-02,  7.5998e-01,  4.2282e-01, -1.0341e+00, -9.5228e-02,\n",
      "           1.5602e+00,  5.8678e-01, -3.3835e-01,  6.5789e-01,  1.8417e+00,\n",
      "          -2.5282e-01, -2.1807e-01,  6.2410e-01, -2.3642e+00,  1.0562e+00,\n",
      "           3.0296e-01,  0.0000e+00,  1.5532e-01, -1.2124e+00, -2.1923e-02,\n",
      "           1.6828e+00,  0.0000e+00,  2.7186e-01, -1.2705e+00, -7.1300e-01,\n",
      "          -1.2244e+00, -1.0942e+00, -2.5912e+00,  5.0603e-01, -3.0614e+00,\n",
      "          -2.8742e-01,  4.9757e-01,  8.2992e-01,  3.1708e-01, -7.9309e-01,\n",
      "           2.7277e-01,  2.3401e+00,  1.0586e+00,  8.3921e-01, -4.0231e-01,\n",
      "           7.2799e-01,  5.9883e-01,  0.0000e+00,  8.4347e-01, -1.8314e+00,\n",
      "           1.3638e+00,  2.1604e+00,  3.3572e-01, -1.0158e+00, -1.1732e+00,\n",
      "          -2.2166e+00,  1.6679e+00,  2.1537e+00,  3.6345e-01,  2.3838e+00,\n",
      "           3.2571e-02, -5.0171e-01, -1.2772e+00, -5.4313e-01, -4.0775e-01,\n",
      "          -1.4480e+00,  9.5343e-01, -8.5210e-01,  8.2938e-01, -1.5607e+00,\n",
      "           6.3736e-01,  6.7537e-01,  2.3988e+00,  5.5307e-02,  1.8939e+00,\n",
      "           1.3093e+00,  5.8022e-01, -2.3179e+00,  1.5505e+00, -2.2258e-01,\n",
      "          -2.2742e-01,  1.7346e+00,  2.7646e-01, -1.5526e+00,  0.0000e+00,\n",
      "           0.0000e+00, -8.4910e-01, -1.8028e+00, -8.1743e-04,  3.7327e-01,\n",
      "          -1.5741e+00, -1.2398e-01,  9.6639e-01, -1.7378e+00,  1.6949e+00,\n",
      "          -1.4407e+00,  6.3396e-01, -1.7234e+00,  9.8034e-01, -1.7173e+00,\n",
      "           1.5616e+00, -2.7310e-01, -2.5977e+00,  1.2393e+00, -1.2282e+00,\n",
      "           1.8866e+00, -5.0855e-01,  5.4281e-01, -2.6127e-01, -1.0226e+00,\n",
      "           1.3340e+00,  3.1150e-01, -5.0832e-02, -2.2873e-01, -1.6134e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0486, 0.1163, 0.1573, 0.0671, 0.1742, 0.1029, 0.1449, 0.0539, 0.0770,\n",
      "         0.0577]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.0265,  0.1434, -0.1416,  ...,  0.5617,  0.1759, -0.1771],\n",
      "        [-0.1597, -0.0520,  0.3840,  ...,  0.2109, -0.1090, -0.1263],\n",
      "        [ 0.1568,  0.0828,  0.3426,  ...,  0.4834,  0.1998, -0.0408],\n",
      "        ...,\n",
      "        [ 0.7578,  0.6284, -0.7384,  ..., -0.4859,  0.0551,  0.3483],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.0288e-01,  1.4272e-01,  4.3774e-02, -1.9726e-01,  7.0222e-02,\n",
      "           1.1199e-01, -2.2741e-01,  1.8335e-02, -1.7386e-01, -8.8368e-02,\n",
      "           6.9509e-03,  8.3467e-02,  1.4630e-01, -1.2527e-01,  1.5269e-01,\n",
      "           7.9987e-02, -3.7396e-02, -1.1268e-01, -2.0758e-01, -2.4298e-02,\n",
      "           8.4736e-02, -3.7326e-01, -1.4090e-01, -3.8725e-02,  3.9591e-02,\n",
      "           2.9689e-05, -1.3757e-02, -1.6334e-01, -9.1804e-02,  1.3580e-02,\n",
      "           3.9710e-01,  3.3375e-02,  1.2638e-01, -4.8077e-02, -1.3195e-01,\n",
      "          -8.7967e-02, -1.2187e-01,  5.2203e-02, -1.3435e-01, -6.2383e-02,\n",
      "          -5.3151e-02,  1.4765e-01, -1.8548e-01, -2.7673e-01,  1.0514e-01,\n",
      "           4.4098e-02,  1.1824e-01, -1.0634e-01, -1.7493e-02, -1.5345e-01,\n",
      "          -1.7847e-01, -1.1052e-01,  2.9664e-02, -1.9206e-01, -1.8059e-01,\n",
      "          -2.5567e-01, -3.1376e-02, -2.8952e-01,  1.8537e-01,  4.2761e-01,\n",
      "          -8.3031e-02,  7.6361e-02, -7.3081e-02, -1.9448e-02, -5.5132e-02,\n",
      "          -8.8063e-02,  6.3823e-02,  1.4138e-01, -2.9314e-02,  2.5966e-01,\n",
      "           1.7631e-03,  2.4070e-01, -1.2584e-01, -1.4807e-01, -1.6961e-01,\n",
      "           2.0632e-02,  9.9427e-02,  1.0092e-01, -1.5914e-01,  3.9231e-01,\n",
      "           7.1818e-02, -8.8761e-02, -2.7475e-01,  3.0911e-01,  2.8367e-02,\n",
      "           1.9092e-01,  8.4900e-02,  2.3620e-01,  2.1078e-01,  1.3105e-03,\n",
      "          -4.0005e-03, -1.2866e-01, -2.0703e-01,  1.9923e-01,  1.7937e-01,\n",
      "          -6.5658e-02, -7.1202e-02,  1.5570e-01, -3.4300e-03,  2.3899e-01,\n",
      "           5.7995e-02, -1.7123e-01,  1.5731e-01,  2.4894e-02, -3.7902e-02,\n",
      "          -2.6860e-01, -1.0938e-01, -5.3333e-02,  7.2410e-02,  2.0901e-01,\n",
      "          -9.5614e-02,  1.7492e-01,  5.3338e-03, -2.2153e-01,  9.4550e-02,\n",
      "           1.4853e-01, -8.8879e-02,  5.8191e-02, -1.0283e-01,  2.3280e-02,\n",
      "           2.0018e-01,  2.0328e-01, -2.7787e-01,  8.1227e-02, -2.5559e-01,\n",
      "          -2.3658e-01, -1.7022e-01,  2.7037e-03,  2.3921e-01, -4.9041e-02,\n",
      "           2.9648e-01, -2.1072e-01, -2.9298e-02,  1.4526e-01, -2.0164e-01,\n",
      "          -2.2682e-01, -1.0306e-01, -2.2181e-02, -1.5068e-01,  5.0265e-02,\n",
      "          -1.0934e-01,  4.7843e-01, -5.7139e-02,  3.1370e-01, -6.6153e-02,\n",
      "           2.1521e-01, -9.4939e-02,  2.6500e-01,  1.7726e-01,  2.9207e-01,\n",
      "          -1.8462e-01, -4.7248e-02, -9.1851e-03,  2.0466e-01, -1.3020e-01,\n",
      "          -2.7618e-02, -1.8278e-01,  1.4257e-01, -1.9972e-01, -1.3165e-01,\n",
      "          -1.0391e-01, -2.5525e-02, -8.7506e-02,  2.6771e-01, -6.1796e-03,\n",
      "          -6.5096e-02,  5.9694e-02,  1.7917e-01, -1.0318e-01,  1.3951e-02,\n",
      "          -2.7304e-01, -1.4238e-01,  8.8700e-02,  2.3724e-01,  2.1515e-02,\n",
      "          -1.2306e-01,  3.5407e-02, -8.1560e-02,  1.0107e-01, -1.2702e-01,\n",
      "          -1.3500e-02, -1.5092e-01,  1.8673e-02, -6.1634e-03, -1.1671e-01,\n",
      "          -5.7102e-02, -7.9041e-02, -1.3721e-01,  6.5359e-03, -8.8568e-02,\n",
      "           1.7583e-01,  1.4702e-01, -4.9317e-02, -1.7024e-01,  8.1136e-02,\n",
      "          -1.7498e-01, -1.7479e-01,  3.0662e-01, -2.1723e-03, -1.5834e-01,\n",
      "          -1.4850e-01,  2.4767e-01,  1.4956e-01,  1.5491e-01, -9.7010e-02,\n",
      "          -9.3605e-02,  1.1143e-02,  1.8636e-01,  6.5554e-02, -1.6722e-02,\n",
      "          -1.1353e-01,  4.0621e-02, -1.7388e-01,  1.7378e-02, -1.1763e-02,\n",
      "           5.6020e-02, -4.0977e-02,  2.0872e-01, -7.6505e-03,  5.2558e-02,\n",
      "           3.6827e-01,  5.5294e-02,  2.5622e-01, -2.5447e-01, -3.3345e-02,\n",
      "           9.7701e-02, -1.4064e-01, -5.9924e-02, -2.2934e-01,  5.2726e-02,\n",
      "          -1.7649e-01, -1.0350e-01, -2.8324e-01, -8.4012e-02,  6.1461e-02,\n",
      "          -1.6071e-01, -2.9819e-01,  1.4365e-01,  4.0644e-01,  2.7971e-01,\n",
      "          -2.1707e-02, -4.1123e-01, -1.0893e-01,  2.0035e-01,  1.0137e-01,\n",
      "          -1.8824e-01, -2.5628e-01, -1.8448e-01,  3.1741e-02, -1.1467e-01,\n",
      "           3.3918e-02,  1.2786e-01,  9.6732e-02, -6.3905e-03,  9.4900e-02,\n",
      "           2.8444e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5595e-02,  3.9878e-01, -9.6723e-01, -6.8216e-01,  3.7656e-01,\n",
      "          -2.0171e-01,  1.4650e+00, -8.3246e-02, -3.5857e+00,  9.0689e-01,\n",
      "           4.2907e-01, -6.2940e-01,  2.6064e+00, -6.2973e-01,  0.0000e+00,\n",
      "          -1.5799e-01,  8.5181e-01,  1.0952e+00,  4.5520e-01,  4.3613e-01,\n",
      "          -6.3391e-01, -3.8381e-01,  1.6424e+00,  1.5117e+00,  7.5402e-01,\n",
      "          -7.5184e-02, -1.8765e-01, -7.5907e-01,  1.6544e+00,  8.6179e-01,\n",
      "           1.2322e+00,  0.0000e+00, -1.0345e+00,  0.0000e+00, -1.5353e+00,\n",
      "           0.0000e+00,  2.8080e-01, -3.7463e+00,  1.9814e-01,  1.6018e+00,\n",
      "           0.0000e+00,  0.0000e+00, -2.6829e-01, -1.7172e+00, -1.5254e+00,\n",
      "           6.6731e-01,  5.4123e-01,  3.6996e-01, -1.3412e+00,  1.4363e-01,\n",
      "          -6.2880e-01,  2.7542e+00,  6.1064e-01, -1.0299e+00, -2.5836e-02,\n",
      "           2.0290e-01, -8.8252e-01, -1.2535e+00, -2.3646e-01, -4.2510e-01,\n",
      "           1.1016e+00,  1.4088e+00, -2.0391e-01,  0.0000e+00,  0.0000e+00,\n",
      "           5.5036e-01,  0.0000e+00,  0.0000e+00,  4.1187e-01,  0.0000e+00,\n",
      "          -1.2679e+00, -3.0555e-02,  7.0759e-01, -3.6434e+00,  3.2667e-01,\n",
      "          -2.3914e-03, -1.5982e-01,  1.0635e+00,  0.0000e+00, -1.2031e-01,\n",
      "          -1.4008e+00,  2.1324e+00, -9.2514e-01,  1.0057e+00, -2.0802e-01,\n",
      "           4.3421e-01,  1.6622e+00,  0.0000e+00, -1.0308e-01, -5.8165e-01,\n",
      "          -2.2745e+00,  0.0000e+00, -6.2236e-01, -1.1354e+00,  4.6767e-01,\n",
      "          -1.1713e+00,  3.4491e-02,  6.2942e-01,  1.7210e+00, -7.8105e-01,\n",
      "           2.6983e+00, -1.4633e+00,  1.0762e+00,  1.4550e+00, -6.6670e-01,\n",
      "          -7.6264e-01,  1.2132e+00,  1.2756e-01, -1.4733e+00, -1.2947e-02,\n",
      "          -2.4903e-01,  1.3442e-01, -1.0491e+00,  1.3106e+00,  0.0000e+00,\n",
      "          -2.9911e+00, -5.6130e-02, -5.0194e-01, -1.9314e-01,  4.4466e-01,\n",
      "          -1.4675e+00,  7.0270e-01, -1.4611e+00, -7.2650e-01, -9.5897e-01,\n",
      "          -1.3099e+00,  8.9820e-01,  1.7069e-01,  1.2862e+00, -7.5297e-01,\n",
      "           0.0000e+00,  5.2959e-01, -1.5838e+00,  9.8433e-01,  2.7622e-01,\n",
      "          -5.8974e-01,  6.6019e-01,  5.7311e-01, -1.1585e+00, -1.0110e+00,\n",
      "          -3.8921e-01,  6.7781e-01, -7.9037e-01, -1.0202e-01, -1.6869e+00,\n",
      "          -1.0154e-01, -5.4341e-01, -8.4470e-01, -7.5564e-01,  1.7743e-01,\n",
      "           1.9995e+00, -1.9994e-01, -1.9316e+00, -4.0634e-01,  4.4172e-01,\n",
      "          -1.9447e-01, -6.3943e-02, -1.2876e-01,  3.9552e-02,  5.3772e-01,\n",
      "          -2.6047e-02,  2.2069e+00,  4.8124e-01, -5.4972e-01, -5.2794e-01,\n",
      "          -8.9325e-01,  2.8189e-01,  8.5014e-02, -3.5805e-01, -4.7826e-01,\n",
      "           7.3875e-01, -3.2740e-02,  1.9793e-02, -1.0021e+00,  1.2781e+00,\n",
      "          -1.0996e+00, -9.8836e-01, -2.0786e+00,  1.9703e+00,  8.6391e-02,\n",
      "          -2.9462e-02,  3.5076e-02,  6.7193e-01,  9.7986e-01, -7.4695e-01,\n",
      "          -3.4111e-01, -2.7848e+00, -7.8511e-01,  1.2104e+00,  1.0127e+00,\n",
      "           3.0762e+00,  4.9459e-01, -1.4411e-01, -5.9516e-01,  5.6095e-01,\n",
      "           0.0000e+00, -1.1887e+00,  0.0000e+00,  1.8129e+00, -9.4803e-01,\n",
      "          -1.6623e+00, -1.0151e+00,  1.2417e+00, -1.2207e-01,  2.3187e-01,\n",
      "          -5.7560e-01, -2.2938e+00,  6.8207e-01, -1.0752e+00, -4.7158e-01,\n",
      "           2.8696e+00, -5.7343e-01, -3.4118e-01,  7.9361e-01,  2.9693e-02,\n",
      "          -6.8527e-01, -1.0204e+00,  0.0000e+00, -2.4607e-01,  2.1706e+00,\n",
      "          -1.0832e+00, -4.2764e-01,  0.0000e+00, -5.0187e-01,  3.3689e-01,\n",
      "           7.0485e-01, -6.9665e-01, -6.2813e-01,  2.9236e-01, -1.5795e+00,\n",
      "          -1.1090e+00,  1.5819e+00, -6.1440e-01,  1.3100e+00, -2.9810e+00,\n",
      "           4.0374e+00,  5.8520e-01,  4.3637e-02, -1.5812e+00, -2.8781e-01,\n",
      "           7.4154e-01, -3.2500e+00,  0.0000e+00, -8.5295e-01,  1.1050e-02,\n",
      "           2.7528e-01,  2.7519e-01,  2.5280e-01,  2.6086e-01,  3.8672e-01,\n",
      "          -3.6567e-01,  0.0000e+00, -5.5427e-01, -5.2699e-02, -1.1475e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0413, 0.0468, 0.0486, 0.0605, 0.1418, 0.3769, 0.0439, 0.0736, 0.0719,\n",
      "         0.0947]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3003, -0.2338,  0.2631, -0.0243,  0.3168,  0.3299, -0.1370,\n",
      "           0.1112,  0.0379,  0.3162,  0.0237, -0.0407,  0.2678, -0.1197,\n",
      "           0.1189,  0.1150, -0.1884, -0.0333, -0.0634, -0.1750, -0.3100,\n",
      "          -0.2319,  0.1163, -0.2043,  0.0826,  0.0547, -0.3108, -0.3110,\n",
      "           0.0231, -0.0670,  0.1713,  0.0819, -0.1114, -0.2605, -0.3146,\n",
      "          -0.0134,  0.0894,  0.1401,  0.2028, -0.0568,  0.2152,  0.3292,\n",
      "          -0.0620,  0.2383,  0.0618,  0.1191, -0.0336,  0.0231, -0.1600,\n",
      "          -0.0736, -0.0543, -0.1962, -0.0739, -0.0963,  0.1895,  0.2395,\n",
      "          -0.0282,  0.0118, -0.0683,  0.2808,  0.2948, -0.3841,  0.0070,\n",
      "           0.0271,  0.1789,  0.3302,  0.2742,  0.0758, -0.1378,  0.0940,\n",
      "          -0.1336,  0.4605,  0.0132,  0.1377, -0.1524, -0.0557,  0.0540,\n",
      "           0.1422, -0.0268,  0.1058, -0.0790, -0.1136,  0.0971, -0.0782,\n",
      "           0.1283,  0.2875,  0.2043,  0.1376,  0.1920, -0.0498, -0.0167,\n",
      "           0.0560, -0.0454,  0.0270, -0.1570,  0.0431,  0.1936,  0.0104,\n",
      "          -0.0392,  0.0500, -0.1305,  0.2588,  0.0744, -0.0537,  0.2907,\n",
      "          -0.1298, -0.1708, -0.1322,  0.0579, -0.0396,  0.1690, -0.1461,\n",
      "          -0.1978,  0.0888, -0.0206, -0.2236, -0.0390, -0.0338,  0.1248,\n",
      "          -0.1792,  0.0713, -0.1044,  0.1741,  0.3286, -0.3262, -0.2182,\n",
      "          -0.0271,  0.0271,  0.0731, -0.1232,  0.0127,  0.0110,  0.3816,\n",
      "           0.4827,  0.0232, -0.2940,  0.1035,  0.0079,  0.1522,  0.3391,\n",
      "          -0.1039,  0.0471, -0.0926,  0.0410,  0.0692,  0.1697, -0.1021,\n",
      "          -0.0384, -0.0104, -0.2303, -0.0544, -0.1351,  0.0325,  0.2182,\n",
      "          -0.0831,  0.0344,  0.0969,  0.1322, -0.1987,  0.2040,  0.2458,\n",
      "          -0.1113,  0.1730,  0.0974, -0.0489,  0.1368,  0.0429,  0.3496,\n",
      "           0.0569,  0.2118,  0.0401,  0.2068,  0.0245,  0.2428, -0.1611,\n",
      "           0.0139,  0.1620,  0.0150, -0.1708,  0.2002, -0.1312, -0.0666,\n",
      "          -0.0188, -0.0039, -0.3207, -0.0079,  0.1319, -0.0327, -0.1501,\n",
      "          -0.0396, -0.0620,  0.0670, -0.1966, -0.1888, -0.4253, -0.1761,\n",
      "          -0.1404, -0.0802, -0.0308, -0.0920, -0.0767, -0.2161,  0.0653,\n",
      "           0.1959, -0.3760,  0.1366,  0.0488,  0.2779,  0.0151,  0.0083,\n",
      "           0.1118,  0.2264, -0.2896,  0.2615,  0.1027,  0.1969,  0.1104,\n",
      "          -0.1525,  0.0190,  0.1680, -0.0256, -0.0249,  0.1571,  0.1559,\n",
      "          -0.3624,  0.2236,  0.0823, -0.2995, -0.3476,  0.2774, -0.0136,\n",
      "          -0.0119,  0.1323,  0.0906,  0.0141,  0.1119,  0.0683, -0.0969,\n",
      "           0.2168,  0.0776,  0.2278, -0.1610, -0.0831, -0.1438,  0.2397,\n",
      "           0.1058,  0.1699, -0.0895,  0.1409,  0.1266, -0.0526,  0.1648,\n",
      "          -0.1807, -0.3169,  0.0481, -0.2456]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4823,  1.6545, -1.0097, -1.1127,  0.4005,  0.6461,\n",
      "          -1.2230, -0.9027,  0.0940, -0.2096,  0.3161,  0.1276, -0.9578,\n",
      "          -0.3088,  0.3245, -1.8656, -2.1366,  0.6083, -0.5295,  0.7694,\n",
      "           0.2827, -1.2565, -0.9732,  1.1928,  1.4269, -1.6559,  1.0544,\n",
      "           0.9847, -1.2881,  0.0000, -0.9457, -0.7692, -1.5224, -0.3684,\n",
      "           0.4845, -0.9884, -0.3514,  0.3284,  0.6285,  0.6072, -1.1773,\n",
      "           0.3730,  1.2541, -1.7958,  1.9479, -1.4977, -0.4432, -0.2787,\n",
      "           1.1468,  0.8654,  0.0000, -0.0720, -1.0045, -0.2960, -0.8050,\n",
      "           0.0000,  0.5099,  1.5737,  0.0000, -0.8820, -0.7342,  1.9472,\n",
      "          -0.9067, -0.8595,  0.1077,  0.6392, -0.6176,  0.0217,  0.4295,\n",
      "          -1.5901, -0.0285, -0.6440,  0.0000, -0.4459,  0.5582, -3.6201,\n",
      "          -0.6178, -1.4069, -0.3114,  0.8704,  1.3129,  0.8814, -0.9605,\n",
      "           0.6941,  0.6927,  0.0458, -2.9902,  0.8148,  0.0000, -1.4909,\n",
      "           0.3247, -1.2889,  2.3927,  1.8843,  0.2151, -1.1099,  1.0777,\n",
      "           1.5511, -2.1251,  0.0145, -0.6645, -1.1343, -1.8824,  0.4073,\n",
      "           1.4169, -1.9890, -0.9152,  0.4129,  1.8170, -1.4328,  0.1793,\n",
      "          -0.4981,  0.0000, -0.1469, -0.1097,  0.3372, -1.6433,  0.8517,\n",
      "          -1.2945, -1.3470,  0.0000,  0.8780,  0.0000,  0.2247,  0.0000,\n",
      "          -0.2018, -1.0698,  0.1250, -0.4280, -1.2474,  2.3284,  1.4194,\n",
      "           0.3274, -0.0086, -0.6389, -0.0633, -0.6000, -0.4514,  1.0982,\n",
      "           0.5454, -1.1804, -2.2954, -0.8863,  0.2163, -0.1882,  0.9175,\n",
      "          -0.0827,  1.5431, -0.7185,  0.3218, -1.3513,  1.8151, -1.9313,\n",
      "           0.0000, -0.3342, -0.2284, -0.7583,  0.9339, -0.0176,  0.2299,\n",
      "          -1.1454,  2.2622, -1.7651, -0.3903, -0.6925,  0.5301,  2.1363,\n",
      "          -1.6407, -2.7425,  0.0000, -2.0861, -0.0067, -1.1603, -0.9215,\n",
      "          -0.7989, -0.3072, -0.4307,  0.1184,  0.0000,  0.0000, -0.4527,\n",
      "           0.0000,  0.9703,  0.4845, -0.0759, -1.5031, -0.2144,  0.4042,\n",
      "          -1.4629,  1.0721,  0.6062,  0.5037, -0.5086,  0.7253, -0.0426,\n",
      "           1.8721,  0.0420, -0.8383, -0.2757,  0.1195, -0.2979,  0.2824,\n",
      "           0.3537, -0.0092, -0.7151,  0.6958,  2.0169, -0.7503,  1.8923,\n",
      "           2.7905,  0.1561,  1.5050,  0.1014,  0.0000, -0.0231,  0.0000,\n",
      "           0.0000,  0.4078,  0.0000, -0.6886,  1.8595,  0.6064,  0.4726,\n",
      "           0.0285,  1.5296, -0.3652, -0.2609,  0.8416, -0.2545,  0.7762,\n",
      "          -0.5522,  1.2384,  0.0932,  2.0765,  0.0000,  0.0000,  0.0000,\n",
      "          -1.4960,  1.8028, -0.8497,  0.2566, -1.0502, -0.8548,  0.1357,\n",
      "          -1.7794,  0.3818,  1.9830,  0.5689,  0.0000, -1.7500,  0.3685,\n",
      "           0.1555,  1.5691, -2.7268,  0.4076]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0388, 0.1312, 0.0922, 0.0527, 0.1730, 0.2357, 0.0510, 0.0531, 0.0994,\n",
      "         0.0728]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2846, -0.1435,  0.1920, -0.0088,  0.2924,  0.2701, -0.1579,\n",
      "           0.1423,  0.0596,  0.2959, -0.0283, -0.0604,  0.2196, -0.0544,\n",
      "           0.1148,  0.1542, -0.0981, -0.0644, -0.1731, -0.1604, -0.3062,\n",
      "          -0.1767,  0.0417, -0.1760,  0.0052, -0.0644, -0.3036, -0.2453,\n",
      "          -0.0376, -0.0546,  0.1473,  0.0682, -0.0762, -0.1958, -0.3213,\n",
      "          -0.0484, -0.0066,  0.0889,  0.0917, -0.1018,  0.1393,  0.2633,\n",
      "          -0.0545,  0.2055,  0.1340,  0.1050,  0.0129,  0.0666, -0.0980,\n",
      "          -0.0398, -0.0873, -0.2209, -0.0555, -0.0891,  0.0680,  0.1961,\n",
      "          -0.0251,  0.0598, -0.0446,  0.2419,  0.2640, -0.3253,  0.0098,\n",
      "           0.0139,  0.1282,  0.2908,  0.2767,  0.0362, -0.1662,  0.0191,\n",
      "          -0.0915,  0.4548, -0.0317,  0.1761, -0.2076, -0.0490,  0.0694,\n",
      "           0.0621, -0.0331,  0.0527, -0.1639, -0.1765,  0.0325, -0.0605,\n",
      "           0.1020,  0.2339,  0.1897,  0.1273,  0.1287, -0.0322, -0.0305,\n",
      "           0.0980, -0.0099, -0.0183, -0.0776,  0.0543,  0.2181,  0.0506,\n",
      "          -0.1279,  0.0586, -0.1481,  0.2172,  0.1300, -0.0033,  0.2156,\n",
      "          -0.1292, -0.1108, -0.1309,  0.0114, -0.0136,  0.1056, -0.1789,\n",
      "          -0.1620,  0.1173,  0.0570, -0.1860, -0.0319, -0.0667,  0.0827,\n",
      "          -0.2146,  0.1003, -0.1396,  0.1475,  0.2906, -0.3334, -0.1656,\n",
      "           0.0748,  0.0536,  0.1279, -0.0967,  0.0134, -0.0557,  0.3541,\n",
      "           0.4201, -0.0147, -0.2387,  0.1289, -0.0008,  0.2140,  0.3293,\n",
      "          -0.0542,  0.1370, -0.0322,  0.1549,  0.0348,  0.1707, -0.0450,\n",
      "          -0.0142, -0.0493, -0.1659, -0.0850, -0.1569,  0.0402,  0.2600,\n",
      "          -0.1273,  0.0715,  0.1111,  0.1438, -0.1297,  0.2005,  0.1960,\n",
      "          -0.1003,  0.0855,  0.0726, -0.0545,  0.0673,  0.0264,  0.2704,\n",
      "           0.0344,  0.2740,  0.0428,  0.1549, -0.0053,  0.2718, -0.1102,\n",
      "          -0.0444,  0.1212,  0.0455, -0.1525,  0.0923, -0.0666, -0.0215,\n",
      "          -0.0697, -0.0269, -0.2543,  0.0429,  0.0716,  0.0104, -0.0562,\n",
      "          -0.0954, -0.0226,  0.0339, -0.2239, -0.1828, -0.3423, -0.0489,\n",
      "          -0.0652, -0.0534,  0.0113, -0.0363, -0.1290, -0.1804,  0.0315,\n",
      "           0.1957, -0.3222,  0.1229, -0.0012,  0.2466, -0.0021,  0.0188,\n",
      "           0.1377,  0.1444, -0.2782,  0.1658,  0.0812,  0.1619,  0.0909,\n",
      "          -0.0557, -0.0684,  0.1627,  0.0322, -0.0181,  0.2124,  0.1044,\n",
      "          -0.3118,  0.2426,  0.1216, -0.2693, -0.3960,  0.2586, -0.0715,\n",
      "          -0.0693,  0.1181,  0.0653,  0.0184,  0.0853,  0.0350, -0.0911,\n",
      "           0.1779,  0.0512,  0.2276, -0.0792, -0.1748, -0.0851,  0.2700,\n",
      "           0.1027,  0.1323, -0.1638,  0.0726,  0.1305, -0.0175,  0.1209,\n",
      "          -0.1539, -0.2639,  0.0568, -0.2072]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2550,  0.7780,  0.0000, -0.1827, -0.7320,  2.5183, -1.9080,\n",
      "          -0.0326,  0.0000,  1.1946,  1.4105, -0.7568,  0.0000,  0.0643,\n",
      "           1.0464,  1.8856,  0.0000, -0.7850, -0.6404, -1.4037, -0.4984,\n",
      "          -0.3791,  1.1428,  0.2329,  0.1892, -0.6130,  1.4043, -0.1509,\n",
      "          -1.0410,  0.4961, -0.5710,  0.6007, -1.6989,  0.2320, -0.0795,\n",
      "           0.1482,  0.6453, -2.2135,  1.0518,  0.1026, -0.6922,  0.0000,\n",
      "          -1.0646,  0.8179, -0.6329, -0.6567,  1.3727,  0.9367,  1.6037,\n",
      "           0.3695, -1.0083, -1.1716,  0.0000,  0.0000, -1.9748,  1.7090,\n",
      "           0.5929, -1.8922,  0.3413, -0.2935, -0.7705,  1.8691, -0.5944,\n",
      "          -1.6817,  0.0000,  1.2343, -0.3576,  0.0000, -0.7527, -1.1648,\n",
      "           2.2475,  0.0000,  0.2705,  1.2051, -0.3977,  0.3546,  0.2292,\n",
      "          -0.1574, -0.9147,  0.2958, -0.1448,  1.2867,  0.4651,  1.2969,\n",
      "           0.7704,  0.6605,  1.0452, -0.3684, -1.2410, -1.4366,  1.3108,\n",
      "           0.0000, -0.1111,  3.2392,  0.3469,  1.0035, -0.8686,  0.7312,\n",
      "          -1.6815, -0.9244,  0.1904,  0.0283, -0.5963,  1.0585, -0.2310,\n",
      "           0.7758, -0.9056,  0.0000, -0.2786, -0.5473, -0.1379,  0.0000,\n",
      "          -0.1010,  0.0000,  1.6979,  0.0000,  2.0296,  0.0000, -0.8959,\n",
      "           2.5846,  0.0000,  1.4236, -0.6277,  0.4666,  1.3155, -0.9876,\n",
      "           0.0742, -0.9857, -0.6749,  0.2477, -1.2003,  1.1298,  1.1404,\n",
      "           1.4885,  0.3790,  0.6465, -0.8377,  0.2411,  0.0000, -1.2617,\n",
      "           0.0301,  0.8642,  0.5014,  0.9072, -1.2678, -0.6410, -0.4417,\n",
      "           0.8729, -0.0679,  0.0423, -0.0564,  0.6207,  0.1450, -0.1964,\n",
      "           0.1078, -1.6721, -0.4023,  0.2512, -2.0700,  0.4119,  1.1554,\n",
      "           0.0000,  0.9131,  0.8436,  0.4172,  1.6036,  0.1770, -1.1140,\n",
      "          -0.3226,  0.0000,  0.4454, -0.4554,  0.4444, -1.3453,  1.7357,\n",
      "           0.5175,  1.1771,  0.2894, -1.8322, -1.8660,  0.2595, -0.6475,\n",
      "          -1.1656,  0.3288, -0.7440,  0.5920, -1.2419, -1.5178, -2.3034,\n",
      "           0.1463, -1.6242, -1.3210, -0.0503,  1.2995,  0.9805, -1.4147,\n",
      "          -1.1404,  3.0135, -0.2258,  1.0324,  0.0295,  0.1188, -1.3200,\n",
      "          -1.0708,  0.0566,  1.7329,  0.5269,  1.9826, -0.9787, -1.3426,\n",
      "           1.5996, -0.4016,  2.4612, -0.5197,  0.7546,  0.2063, -0.8213,\n",
      "           0.9055, -3.5307,  0.1761, -0.7814, -0.6931, -1.4186,  0.2511,\n",
      "          -0.0650, -1.4655,  0.4271, -0.5201,  0.0462, -0.6255, -0.0713,\n",
      "           0.0000, -2.0269, -1.0490, -0.4317, -0.1120,  0.5160, -2.7972,\n",
      "          -1.4579, -0.6646,  1.0259,  0.0000,  2.7511,  1.0025,  0.0000,\n",
      "          -0.1733, -1.5053,  2.2319,  1.1873, -0.0479,  0.0000,  0.1091,\n",
      "          -2.8556, -0.0138, -0.8378, -0.5803]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0354, 0.1456, 0.0927, 0.1125, 0.1215, 0.1210, 0.0899, 0.0895, 0.1160,\n",
      "         0.0759]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3177, -0.0960,  0.1143, -0.0283,  0.2395,  0.1878, -0.1710,\n",
      "           0.1448,  0.0357,  0.2544, -0.0401, -0.0576,  0.1333, -0.0131,\n",
      "           0.0762,  0.1349, -0.0874, -0.0455, -0.2596, -0.1184, -0.2628,\n",
      "          -0.1994,  0.0165, -0.1661, -0.0386, -0.0839, -0.2800, -0.1953,\n",
      "          -0.0365, -0.0992,  0.1253,  0.0076, -0.0334, -0.1531, -0.3465,\n",
      "          -0.0249, -0.0468,  0.0210,  0.0173, -0.1069,  0.1117,  0.2132,\n",
      "          -0.1015,  0.2008,  0.1465,  0.1437, -0.0076,  0.0286, -0.0227,\n",
      "          -0.0546, -0.1091, -0.2552, -0.0343, -0.0855,  0.0431,  0.1711,\n",
      "          -0.0026,  0.1026, -0.0007,  0.2474,  0.2131, -0.3072, -0.0321,\n",
      "           0.0314,  0.1040,  0.2739,  0.2010,  0.0600, -0.2200,  0.0052,\n",
      "          -0.0295,  0.4619, -0.0433,  0.1948, -0.2227,  0.0142,  0.1110,\n",
      "           0.0061, -0.0652,  0.0711, -0.1981, -0.1935, -0.0438, -0.0269,\n",
      "           0.0913,  0.1520,  0.1869,  0.1525,  0.1228, -0.0010, -0.0472,\n",
      "           0.1355, -0.0098, -0.0493, -0.0431,  0.1041,  0.2062,  0.0931,\n",
      "          -0.1200,  0.1427, -0.1763,  0.2477,  0.1675,  0.0024,  0.1584,\n",
      "          -0.1569, -0.0246, -0.0492, -0.0646,  0.0382,  0.0781, -0.2178,\n",
      "          -0.0790,  0.0829,  0.0205, -0.1078, -0.0405, -0.1481, -0.0016,\n",
      "          -0.2397,  0.1070, -0.1122,  0.0812,  0.2832, -0.3437, -0.1434,\n",
      "           0.1225,  0.0183,  0.1485, -0.1230,  0.0390, -0.1270,  0.3194,\n",
      "           0.3752, -0.0363, -0.2112,  0.1755,  0.0172,  0.2108,  0.3657,\n",
      "          -0.0867,  0.1732,  0.0023,  0.1795,  0.0341,  0.1639, -0.0189,\n",
      "           0.0306, -0.0287, -0.1094, -0.0894, -0.1096,  0.0608,  0.2718,\n",
      "          -0.1149,  0.0640,  0.0942,  0.1714, -0.0657,  0.1148,  0.1263,\n",
      "          -0.1069,  0.0193,  0.0846, -0.0960,  0.0593, -0.0070,  0.2181,\n",
      "          -0.0175,  0.2998, -0.0527,  0.1495, -0.0373,  0.2830, -0.0973,\n",
      "          -0.1223,  0.0682,  0.0695, -0.0807,  0.0066, -0.0148, -0.0394,\n",
      "          -0.0665, -0.0117, -0.1984,  0.0155, -0.0271,  0.0258, -0.0282,\n",
      "          -0.1428, -0.0005,  0.0359, -0.2589, -0.1830, -0.3256, -0.0217,\n",
      "          -0.0186, -0.0764,  0.0242, -0.0026, -0.1367, -0.1895, -0.0522,\n",
      "           0.2012, -0.2825,  0.0841,  0.0019,  0.2326, -0.0414, -0.0127,\n",
      "           0.1223,  0.1032, -0.2569,  0.1497,  0.0882,  0.1857,  0.0421,\n",
      "          -0.0317, -0.1237,  0.1719,  0.0677,  0.0243,  0.2694,  0.0622,\n",
      "          -0.2161,  0.2183,  0.1433, -0.2497, -0.4372,  0.2099, -0.0807,\n",
      "          -0.0754,  0.0667, -0.0085,  0.0180,  0.0960,  0.0343, -0.0984,\n",
      "           0.1925,  0.0616,  0.2512, -0.0417, -0.1870,  0.0262,  0.2682,\n",
      "           0.0909,  0.0710, -0.2327,  0.0212,  0.1072, -0.0038,  0.0297,\n",
      "          -0.1414, -0.2650,  0.0864, -0.1555]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.1507, -1.9324,  1.1065,  1.6619, -2.4264, -2.4602,  0.1949,\n",
      "           0.0000, -0.2327,  1.8952, -0.2356,  0.8705,  2.4092,  1.4403,\n",
      "           2.2206,  0.5097,  0.0000, -1.6017, -1.0199,  0.0000,  0.5041,\n",
      "           0.5238,  0.8652, -1.7472, -0.1087, -0.1204,  0.8293,  0.0000,\n",
      "          -0.1887, -0.0165, -0.7932, -0.0778,  0.0078, -0.7905,  2.1051,\n",
      "           0.0000, -1.3324,  1.7354, -0.2218,  0.0168, -0.5285,  0.0000,\n",
      "          -0.0883, -2.7268,  0.4841,  0.8136, -0.0842,  1.6984, -0.9230,\n",
      "           0.0000, -1.0167,  0.1704,  0.2828, -0.3304, -1.7667,  0.0000,\n",
      "           0.0000, -0.2368, -0.0246,  1.4545,  0.6630, -0.2458,  1.3723,\n",
      "           1.8328, -1.0246,  2.3432, -0.8897, -1.2140,  0.0000,  1.2400,\n",
      "          -0.1054,  0.6031,  1.0073,  0.7216,  0.5516,  0.3815, -1.4711,\n",
      "           2.7792,  0.8552, -0.7878, -0.0501, -1.7533,  0.7946,  2.1977,\n",
      "           0.2711, -0.3116,  1.2464, -0.5048, -1.6790,  2.4544, -2.1385,\n",
      "           1.6574,  0.8506, -0.2185,  0.0000, -0.8605,  0.7811, -0.2185,\n",
      "           1.9840, -0.3263, -1.5424, -0.6218,  0.8025, -0.1111, -0.2968,\n",
      "           0.0000,  0.6104, -0.3091, -1.1505,  2.4539, -0.1246,  0.7452,\n",
      "           0.4779,  1.1362,  0.4131,  0.0677,  0.0000, -1.6302, -1.9447,\n",
      "          -1.3154,  1.6390,  0.5942, -1.6958,  2.4452,  0.4006,  0.0908,\n",
      "           0.6818,  0.8984,  1.5903, -1.4772, -1.0451, -0.6086,  0.8205,\n",
      "           0.0700,  0.8081,  0.6834, -1.6467, -1.0175, -0.6087, -0.8658,\n",
      "          -0.9097,  2.0293,  0.5667,  0.1407,  0.3312,  0.0460, -0.0119,\n",
      "          -0.4895, -0.6659,  0.5752, -0.6916,  0.4845,  0.2664,  0.9840,\n",
      "          -0.8534,  1.4694, -1.7663,  0.2197, -1.7690, -1.0140, -0.7182,\n",
      "          -0.7529, -1.3589, -0.1616,  0.5813,  0.0000,  2.0720, -1.5470,\n",
      "           0.5572, -0.9986, -0.9759, -0.0917, -0.1291, -0.5327,  1.6092,\n",
      "          -1.7428,  0.0000, -0.8790,  1.8205, -0.2834,  0.3597, -1.4146,\n",
      "          -1.0204,  0.2665, -1.1314, -0.5694, -0.7400, -1.0497, -0.7970,\n",
      "           0.1991,  0.0000,  0.2691,  0.0000, -2.8684,  1.4272, -1.0422,\n",
      "           1.3879, -0.5156,  0.6173,  0.5736, -1.3505, -0.1956,  3.1102,\n",
      "           0.0000, -0.8129,  0.0806,  0.1386,  1.2153, -0.7017,  1.5613,\n",
      "          -0.2634, -0.3437, -0.5455,  0.1525, -0.6779, -0.2119, -1.4317,\n",
      "           0.0000,  0.9295, -1.0254,  1.0137, -0.2113, -1.0267,  0.0000,\n",
      "           1.0292, -1.3060, -0.9202,  1.2535, -0.5897,  0.4006, -0.4863,\n",
      "          -1.5442,  1.8204, -0.6760, -0.5308,  0.3102,  1.7600, -2.0990,\n",
      "          -0.6670,  0.9979, -0.8193, -0.0705,  1.7355, -0.7611, -0.1642,\n",
      "           0.4654, -1.1378, -0.9494, -0.6742,  1.5715,  1.3108, -1.1274,\n",
      "           0.7891,  1.6607,  2.0153,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0734, 0.0852, 0.0667, 0.0767, 0.1417, 0.1288, 0.0497, 0.1530, 0.1571,\n",
      "         0.0677]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.3712, -0.0733,  0.0889, -0.0773,  0.2147,  0.1376, -0.1571,\n",
      "           0.0574,  0.0016,  0.1952,  0.0080, -0.0988,  0.0838, -0.0191,\n",
      "           0.1122,  0.0906, -0.1184,  0.0023, -0.2803, -0.1277, -0.2670,\n",
      "          -0.2597,  0.0903, -0.1421, -0.0563, -0.0694, -0.2491, -0.2413,\n",
      "          -0.0636, -0.0765,  0.2095, -0.0494, -0.0698, -0.2595, -0.3505,\n",
      "          -0.0092, -0.0502, -0.0144,  0.0308, -0.0424,  0.0959,  0.2375,\n",
      "          -0.1365,  0.2117,  0.1347,  0.1878, -0.0758, -0.0312,  0.0031,\n",
      "          -0.0810, -0.1098, -0.2433, -0.1174, -0.0885,  0.0644,  0.1734,\n",
      "          -0.0369,  0.0987,  0.0483,  0.2731,  0.2088, -0.3640, -0.1189,\n",
      "           0.0819,  0.0827,  0.3005,  0.1508,  0.1380, -0.2667,  0.0759,\n",
      "          -0.0140,  0.4949, -0.0098,  0.1877, -0.2221,  0.0746,  0.1636,\n",
      "           0.0622, -0.1098,  0.1211, -0.1683, -0.1956, -0.1009, -0.0084,\n",
      "           0.0526,  0.2211,  0.2137,  0.1714,  0.2111, -0.0317,  0.0467,\n",
      "           0.1513, -0.0421, -0.0348, -0.0638,  0.1262,  0.2231,  0.1372,\n",
      "          -0.0809,  0.1775, -0.1779,  0.2871,  0.1597,  0.0220,  0.1645,\n",
      "          -0.1720, -0.0062,  0.0471, -0.0791,  0.0897,  0.1254, -0.1969,\n",
      "          -0.0784, -0.0163, -0.0528, -0.0744, -0.0247, -0.1260, -0.0341,\n",
      "          -0.2419,  0.1138, -0.1448,  0.0108,  0.3192, -0.3670, -0.1767,\n",
      "           0.0522, -0.0398,  0.1771, -0.1699,  0.0942, -0.1671,  0.3286,\n",
      "           0.4437, -0.0400, -0.2019,  0.1986,  0.0455,  0.1188,  0.4039,\n",
      "          -0.1474,  0.2256, -0.0876,  0.1346,  0.0605,  0.1223, -0.0491,\n",
      "           0.0949,  0.0280, -0.0638, -0.1959, -0.0695,  0.0235,  0.2477,\n",
      "          -0.0383,  0.1466,  0.0536,  0.1852, -0.0608,  0.0609,  0.0646,\n",
      "          -0.1454, -0.0356,  0.1763, -0.0841,  0.1087, -0.0530,  0.1992,\n",
      "           0.0182,  0.2729, -0.1063,  0.1561,  0.0303,  0.2484, -0.1419,\n",
      "          -0.1526,  0.0556,  0.0891,  0.0170,  0.0222, -0.0762, -0.0690,\n",
      "          -0.1079, -0.0316, -0.1469,  0.0285, -0.0534,  0.0489, -0.0702,\n",
      "          -0.1475, -0.0341,  0.0660, -0.3095, -0.2127, -0.3262, -0.0925,\n",
      "          -0.0864, -0.1008, -0.0412,  0.0182, -0.1373, -0.1550, -0.0418,\n",
      "           0.2475, -0.3091,  0.0310,  0.0281,  0.2967, -0.0342, -0.0563,\n",
      "           0.0855,  0.0803, -0.2693,  0.2285,  0.0553,  0.2395,  0.0014,\n",
      "          -0.0293, -0.1188,  0.1569,  0.1098,  0.0041,  0.2827,  0.0522,\n",
      "          -0.1687,  0.2193,  0.1684, -0.3229, -0.4675,  0.2557, -0.0743,\n",
      "          -0.0959,  0.0015, -0.0326,  0.0043,  0.1101, -0.0161, -0.0954,\n",
      "           0.2693,  0.0774,  0.2055, -0.1214, -0.1810,  0.0358,  0.2576,\n",
      "           0.0930,  0.0413, -0.2587,  0.0604,  0.0873,  0.0138,  0.0293,\n",
      "          -0.1633, -0.2969,  0.0977, -0.1640]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-1.4359e+00,  0.0000e+00, -4.0644e-01,  4.8469e-01, -3.9967e-01,\n",
      "          -8.0662e-01, -8.3191e-01,  0.0000e+00,  8.7879e-01, -2.9268e-01,\n",
      "          -3.9620e-01, -1.9254e+00, -3.6671e-01,  4.2889e-01,  6.8749e-01,\n",
      "          -1.8163e+00,  0.0000e+00, -6.3006e-01, -1.5093e+00,  3.0563e+00,\n",
      "           7.3372e-01,  0.0000e+00,  6.7797e-01,  1.3935e+00, -1.7027e-01,\n",
      "           8.8072e-01,  2.3013e+00, -2.9738e-01, -7.3245e-01,  4.4255e-01,\n",
      "           4.9668e-01, -6.8966e-01, -8.2699e-01, -7.0069e-01,  9.7373e-01,\n",
      "           0.0000e+00, -8.9451e-02, -4.0168e-01,  2.4596e+00,  1.0322e-01,\n",
      "          -1.2991e+00, -6.0226e-01,  0.0000e+00, -1.6854e-01, -1.3839e-01,\n",
      "          -2.1205e-02,  7.1693e-02,  2.1155e+00, -1.7890e+00,  3.4220e-01,\n",
      "           3.6695e-01, -8.2689e-01,  5.6033e-01, -4.4636e-01, -1.7785e+00,\n",
      "           2.8571e-01, -5.2027e-01, -1.3869e+00, -1.2868e+00,  7.1980e-02,\n",
      "          -2.3305e+00,  9.7438e-01,  1.1729e+00, -1.2496e+00,  1.2882e+00,\n",
      "          -3.1186e-01,  4.7101e-01,  0.0000e+00,  0.0000e+00,  1.7613e-01,\n",
      "          -6.3550e-01,  8.0157e-02,  4.5747e-01, -5.0136e-01,  7.0891e-01,\n",
      "          -1.3296e+00, -9.6580e-01, -4.3894e-02, -6.9989e-01, -9.7699e-01,\n",
      "          -1.8657e-02, -8.3523e-01,  2.4281e-01,  8.2829e-01,  4.2375e-01,\n",
      "          -1.0971e+00,  0.0000e+00,  4.6604e-01,  0.0000e+00, -7.1958e-01,\n",
      "           1.1215e+00,  9.5017e-01, -1.5605e+00,  1.3513e+00, -1.4052e-01,\n",
      "           0.0000e+00, -1.6447e+00,  7.3592e-01, -2.8383e+00, -4.9483e-01,\n",
      "           2.8651e-01,  1.0351e+00,  1.1025e+00,  6.5453e-01,  1.2241e+00,\n",
      "           6.0895e-01, -1.4802e+00, -1.3035e+00,  5.8826e-01, -4.5145e-02,\n",
      "          -1.2980e+00,  0.0000e+00,  3.5170e-01,  2.4129e-01, -3.0979e-01,\n",
      "           1.5325e+00,  0.0000e+00, -2.1008e-02, -6.6228e-01,  1.9723e+00,\n",
      "           4.3409e-01, -2.4350e-05, -4.3350e-01,  0.0000e+00, -8.1069e-01,\n",
      "           1.4829e-01,  1.8920e-01,  3.3591e-01, -3.1064e-01, -8.8972e-01,\n",
      "          -1.0471e+00,  1.5088e+00,  2.1819e+00,  0.0000e+00, -2.3733e+00,\n",
      "           6.6433e-01, -5.7075e-01,  0.0000e+00, -1.9307e-01,  3.2264e-01,\n",
      "           6.0678e-01, -9.7465e-01,  6.2165e-01,  2.1190e-01, -5.8096e-01,\n",
      "           9.8115e-01,  1.0617e-01, -9.8032e-01, -2.6494e-01, -6.5679e-01,\n",
      "          -6.1522e-01, -1.0792e+00,  0.0000e+00,  2.1163e+00, -1.9530e+00,\n",
      "          -2.9195e-02,  0.0000e+00,  3.2838e-01,  1.3125e+00, -3.3073e-01,\n",
      "          -1.1541e+00, -3.4868e-01, -1.2723e-01,  6.3688e-01,  1.5709e+00,\n",
      "           0.0000e+00, -5.1742e-01,  9.2600e-01, -8.8579e-03,  5.1929e-01,\n",
      "          -7.2077e-01,  1.3156e+00,  0.0000e+00, -1.6220e+00,  3.8330e-01,\n",
      "          -4.2589e-01, -8.4101e-01,  0.0000e+00, -2.5171e+00,  3.7628e-01,\n",
      "           1.7782e+00, -1.4127e+00, -7.7055e-01,  1.2166e+00,  4.4600e-01,\n",
      "          -1.5094e+00,  1.2453e+00,  7.8406e-01,  0.0000e+00,  2.7379e-01,\n",
      "          -2.2718e-01, -7.1442e-01, -4.0750e-01,  2.6205e+00, -4.6809e-01,\n",
      "          -7.1123e-01, -9.4142e-04,  6.4316e-01, -7.1633e-01,  8.8288e-01,\n",
      "           1.9976e+00,  5.6803e-01, -1.2208e+00,  2.2138e+00, -1.4102e+00,\n",
      "           1.4733e+00, -9.7407e-01,  1.6827e+00,  1.6252e+00,  7.0096e-01,\n",
      "           1.3270e+00,  2.3861e-01,  9.8438e-02,  3.8030e-01,  1.0407e+00,\n",
      "           6.7116e-01,  1.2925e+00, -1.2210e-01,  5.0717e-01,  4.9384e-01,\n",
      "           0.0000e+00,  0.0000e+00,  3.9579e-01, -3.4000e-01, -4.7630e-01,\n",
      "          -9.5817e-01, -1.8362e+00,  2.0684e+00, -2.1300e+00,  1.8422e+00,\n",
      "           4.8545e-01,  1.1121e+00,  2.0120e-01,  5.1204e-01,  0.0000e+00,\n",
      "          -2.0875e+00, -2.8641e-01, -7.5657e-01,  1.1396e-01,  2.6693e+00,\n",
      "          -2.6804e+00, -2.0693e+00,  1.2185e+00,  1.8937e+00, -1.7895e+00,\n",
      "          -4.0043e-01, -2.0626e+00, -6.2452e-01,  6.2872e-01,  1.2002e+00,\n",
      "           4.8336e-01,  1.9058e+00,  0.0000e+00, -5.5214e-03, -1.4084e+00,\n",
      "          -1.0332e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0793, 0.0927, 0.1669, 0.1233, 0.1359, 0.1156, 0.0725, 0.1025, 0.0573,\n",
      "         0.0540]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2896, -0.1247,  0.1017, -0.0290,  0.2748,  0.2366, -0.2149,\n",
      "           0.1995,  0.0159,  0.2922, -0.0917, -0.0477,  0.1666,  0.0252,\n",
      "           0.0955,  0.1787, -0.0783, -0.0560, -0.2264, -0.1391, -0.2396,\n",
      "          -0.1381, -0.0334, -0.1841, -0.0312, -0.0361, -0.2837, -0.1751,\n",
      "          -0.0220, -0.0710,  0.1156,  0.0136,  0.0073, -0.1317, -0.3734,\n",
      "          -0.0989, -0.0052,  0.0622,  0.0380, -0.1286,  0.1091,  0.2114,\n",
      "          -0.0860,  0.1635,  0.1194,  0.1374,  0.0574,  0.0989, -0.0565,\n",
      "          -0.0486, -0.0645, -0.2285, -0.0256, -0.0950,  0.0031,  0.1711,\n",
      "          -0.0147,  0.0926, -0.0469,  0.1648,  0.2283, -0.2894,  0.0313,\n",
      "           0.0037,  0.1056,  0.2786,  0.2373,  0.0258, -0.1860,  0.0075,\n",
      "          -0.0497,  0.4631,  0.0169,  0.1967, -0.2189,  0.0057,  0.0738,\n",
      "          -0.0334, -0.0106,  0.0656, -0.1959, -0.1482, -0.0205, -0.0423,\n",
      "           0.1127,  0.0919,  0.1617,  0.1502,  0.0793,  0.0027, -0.0937,\n",
      "           0.1190,  0.0009, -0.0795, -0.0437,  0.0615,  0.2008,  0.0152,\n",
      "          -0.1127,  0.0807, -0.0990,  0.2331,  0.1478,  0.0228,  0.2326,\n",
      "          -0.1394, -0.0896, -0.1009, -0.0416,  0.0167,  0.0350, -0.2198,\n",
      "          -0.1346,  0.1673,  0.0864, -0.1065, -0.0451, -0.1098,  0.0122,\n",
      "          -0.2196,  0.0719, -0.1074,  0.1292,  0.2651, -0.3451, -0.0890,\n",
      "           0.1563,  0.0488,  0.0978, -0.1276, -0.0110, -0.0564,  0.2643,\n",
      "           0.3903,  0.0491, -0.2204,  0.0901,  0.0381,  0.3056,  0.3401,\n",
      "          -0.0833,  0.1600,  0.0169,  0.1789,  0.0063,  0.1992, -0.0397,\n",
      "          -0.0037, -0.0401, -0.1231, -0.0297, -0.1364,  0.0298,  0.2624,\n",
      "          -0.1736,  0.0164,  0.1527,  0.1657, -0.1149,  0.1726,  0.1413,\n",
      "          -0.0696,  0.0182,  0.0160, -0.1516,  0.0221,  0.0477,  0.2574,\n",
      "          -0.0228,  0.2630,  0.0143,  0.2132, -0.0611,  0.3249, -0.0727,\n",
      "          -0.1134,  0.1350,  0.0510, -0.1567, -0.0075,  0.0208, -0.0321,\n",
      "          -0.0225, -0.0080, -0.2255,  0.0144,  0.0186, -0.0050, -0.0306,\n",
      "          -0.1007,  0.0239,  0.0397, -0.2477, -0.1691, -0.3327,  0.0303,\n",
      "           0.0353, -0.0548,  0.1025, -0.0107, -0.1582, -0.2204, -0.0457,\n",
      "           0.1587, -0.3249,  0.1055, -0.0533,  0.1914, -0.0376,  0.0299,\n",
      "           0.1133,  0.1257, -0.2295,  0.0898,  0.1194,  0.1479,  0.0595,\n",
      "          -0.0120, -0.1214,  0.1530,  0.0609,  0.0706,  0.2860,  0.0665,\n",
      "          -0.2870,  0.2107,  0.0962, -0.1752, -0.4330,  0.1818, -0.0087,\n",
      "          -0.0657,  0.0793,  0.0753,  0.0503,  0.0986,  0.0405, -0.0515,\n",
      "           0.1426,  0.0363,  0.2758,  0.0031, -0.1637,  0.0409,  0.2413,\n",
      "           0.0944,  0.1583, -0.2385,  0.0214,  0.0937,  0.0271,  0.0534,\n",
      "          -0.0965, -0.2906,  0.1000, -0.2135]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-2.5905e+00,  0.0000e+00,  1.8477e+00, -1.1139e+00,  5.8346e-01,\n",
      "          -8.2143e-01, -6.9822e-01,  0.0000e+00, -1.0463e+00,  5.6673e-01,\n",
      "          -2.8551e-01, -9.1776e-01, -1.6914e-01,  3.6911e-01, -8.2691e-01,\n",
      "          -8.5103e-01,  1.2078e+00,  0.0000e+00, -3.9530e-01,  0.0000e+00,\n",
      "          -5.3029e-01, -1.6347e+00,  2.4092e-01, -8.1734e-01,  4.6134e-01,\n",
      "           1.4620e+00, -1.2139e+00, -2.9749e+00,  1.9562e-01,  0.0000e+00,\n",
      "           9.9470e-01,  8.5860e-01, -1.4370e-01,  6.3851e-01, -3.0589e-01,\n",
      "          -1.5729e-01,  5.2187e-01,  1.3944e+00, -1.2674e+00,  8.0148e-01,\n",
      "          -2.5757e-01,  1.0916e+00, -2.8096e+00,  7.2352e-01, -7.5964e-01,\n",
      "          -2.3572e+00,  1.8219e+00,  1.4624e+00, -1.9356e+00, -1.7399e+00,\n",
      "          -5.7111e-01, -1.1549e+00,  8.2637e-02,  5.5921e-01, -1.7007e-03,\n",
      "          -7.5043e-01,  8.8327e-01, -1.3651e+00,  0.0000e+00,  7.2136e-01,\n",
      "          -5.6550e-01,  1.8047e+00,  9.0492e-01,  3.7974e-02, -9.4308e-01,\n",
      "           1.2635e-01, -1.5005e+00,  1.1984e+00,  5.9874e-01,  9.7603e-01,\n",
      "          -3.1682e-01,  2.2564e+00, -6.4566e-01, -2.6432e+00,  2.4010e+00,\n",
      "           0.0000e+00,  1.1277e+00, -6.2619e-01,  5.3433e-01, -1.3395e+00,\n",
      "           2.5958e-01,  2.7118e+00,  0.0000e+00,  2.1466e-01,  1.5898e+00,\n",
      "          -7.4653e-01, -5.1750e-01,  4.0731e-01,  0.0000e+00, -1.5288e-01,\n",
      "          -4.1028e-02,  7.2586e-01, -6.9500e-01, -7.3602e-01, -1.6594e+00,\n",
      "           1.8404e-01,  5.9518e-01,  4.9618e-01,  9.7642e-01, -7.0966e-01,\n",
      "           1.4806e-02,  2.1172e-01, -5.2233e-01, -3.5079e-01,  2.1304e+00,\n",
      "          -6.2923e-01,  2.2143e+00, -8.9908e-01,  6.0390e-01, -1.3878e+00,\n",
      "           1.2313e+00,  4.2113e-01, -6.0457e-01,  1.0429e+00,  1.1162e+00,\n",
      "           1.8995e+00, -5.0551e-01, -2.0517e+00, -5.4560e-01, -8.2395e-02,\n",
      "          -1.2556e+00,  6.2387e-01, -2.0715e+00, -9.2465e-03,  9.0130e-01,\n",
      "           6.2568e-03,  2.0812e+00, -1.7635e+00, -9.4281e-02, -1.5596e-01,\n",
      "           2.7791e-01, -1.0115e+00, -2.3883e-01, -9.4614e-01, -9.4280e-01,\n",
      "          -4.2920e-03,  1.6730e+00, -3.9980e-01, -2.5971e+00, -8.4371e-01,\n",
      "           1.9129e-01, -1.0511e-01,  0.0000e+00,  1.1367e+00,  1.6517e+00,\n",
      "           8.1893e-01,  0.0000e+00, -2.4014e+00,  0.0000e+00, -1.2669e+00,\n",
      "           0.0000e+00,  3.1337e-01,  2.9594e-01, -2.2407e-01, -6.5777e-01,\n",
      "           4.0845e-01, -6.5665e-02, -1.4978e+00,  1.7000e+00,  2.3572e-01,\n",
      "           1.1937e+00,  1.5419e-01, -1.5540e+00, -1.2306e+00,  2.2025e+00,\n",
      "          -4.2862e-01,  0.0000e+00,  3.4689e-01,  2.8455e+00, -4.3744e-01,\n",
      "           1.6508e+00, -1.4261e+00,  8.6631e-02,  0.0000e+00,  0.0000e+00,\n",
      "           1.8269e+00,  7.3536e-01,  2.9156e-02, -5.8043e-02,  6.1954e-01,\n",
      "           9.0021e-01,  1.1408e+00, -1.4176e+00,  0.0000e+00, -4.2011e-01,\n",
      "          -5.0579e-01,  1.7310e+00, -2.9694e-01,  4.5426e-01,  0.0000e+00,\n",
      "           1.5771e+00,  9.8921e-01,  4.4343e-01, -7.1656e-01, -8.5897e-02,\n",
      "          -1.8156e-01,  8.2299e-01,  3.2930e-01, -7.0405e-01,  1.2835e+00,\n",
      "           0.0000e+00,  0.0000e+00, -1.5630e+00, -7.4134e-01, -1.3195e+00,\n",
      "          -8.1595e-01,  2.3602e+00,  1.3782e+00,  4.1180e-02,  0.0000e+00,\n",
      "           7.8526e-01,  0.0000e+00,  2.8381e-01,  2.4399e+00, -1.0053e+00,\n",
      "          -2.9792e-01,  1.3609e+00, -8.7816e-01,  0.0000e+00, -5.3168e-01,\n",
      "           1.5058e+00,  1.2342e+00, -5.0080e-01, -2.7324e+00,  1.8473e+00,\n",
      "          -7.1842e-01,  8.5986e-02, -3.0041e-01, -8.4867e-02,  1.8858e-01,\n",
      "          -2.6281e-01,  1.2739e-01,  0.0000e+00,  8.3872e-02, -1.7555e-01,\n",
      "           1.0152e+00, -9.7416e-01, -1.4035e+00,  1.1172e+00,  5.4497e-01,\n",
      "           5.9224e-01,  6.1955e-01,  1.2944e+00,  0.0000e+00,  5.8276e-01,\n",
      "          -2.3044e-01, -1.8645e-01, -2.0799e+00,  1.3676e+00, -3.3818e-01,\n",
      "           0.0000e+00,  1.3829e+00, -1.6416e+00,  0.0000e+00, -9.4355e-01,\n",
      "          -2.1638e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0595, 0.1542, 0.1275, 0.1019, 0.1508, 0.1589, 0.0521, 0.0556, 0.0762,\n",
      "         0.0634]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.2763, -0.1165,  0.1404, -0.0007,  0.2756,  0.2637, -0.1962,\n",
      "           0.1877,  0.0544,  0.2971, -0.0805, -0.0495,  0.1964, -0.0081,\n",
      "           0.1144,  0.1882, -0.0572, -0.0645, -0.2179, -0.1362, -0.2757,\n",
      "          -0.1285, -0.0284, -0.1790, -0.0228, -0.0781, -0.2874, -0.1851,\n",
      "          -0.0297, -0.0663,  0.1166,  0.0537, -0.0254, -0.1216, -0.3388,\n",
      "          -0.0896, -0.0314,  0.0814,  0.0424, -0.1376,  0.1253,  0.2131,\n",
      "          -0.0600,  0.1642,  0.1515,  0.0946,  0.0719,  0.1043, -0.0635,\n",
      "          -0.0251, -0.0805, -0.2318, -0.0127, -0.0920,  0.0039,  0.1781,\n",
      "          -0.0113,  0.0928, -0.0524,  0.1958,  0.2369, -0.2758,  0.0342,\n",
      "          -0.0030,  0.1131,  0.2590,  0.2565, -0.0005, -0.1691, -0.0166,\n",
      "          -0.0701,  0.4444, -0.0320,  0.1828, -0.2309, -0.0363,  0.0684,\n",
      "          -0.0145, -0.0058,  0.0400, -0.2060, -0.1720,  0.0134, -0.0527,\n",
      "           0.1212,  0.1428,  0.1677,  0.1281,  0.0753, -0.0019, -0.0984,\n",
      "           0.1114,  0.0081, -0.0649, -0.0422,  0.0489,  0.2227,  0.0341,\n",
      "          -0.1436,  0.0569, -0.1209,  0.1955,  0.1358,  0.0190,  0.2066,\n",
      "          -0.1140, -0.0935, -0.1470, -0.0121,  0.0005,  0.0451, -0.1997,\n",
      "          -0.1441,  0.1699,  0.1098, -0.1621, -0.0273, -0.0948,  0.0454,\n",
      "          -0.2247,  0.0934, -0.1281,  0.1449,  0.2599, -0.3358, -0.1075,\n",
      "           0.1517,  0.0747,  0.1286, -0.0823, -0.0190, -0.0519,  0.3106,\n",
      "           0.3639,  0.0166, -0.2140,  0.1164,  0.0143,  0.2961,  0.3145,\n",
      "          -0.0419,  0.1492,  0.0228,  0.2017,  0.0116,  0.1950, -0.0143,\n",
      "          -0.0219, -0.0712, -0.1412, -0.0403, -0.1620,  0.0533,  0.2676,\n",
      "          -0.1834,  0.0419,  0.1482,  0.1535, -0.1111,  0.2096,  0.1719,\n",
      "          -0.0685,  0.0402,  0.0256, -0.1000,  0.0271,  0.0466,  0.2519,\n",
      "          -0.0125,  0.2830,  0.0514,  0.1745, -0.0471,  0.3043, -0.0637,\n",
      "          -0.0799,  0.1299,  0.0481, -0.1691,  0.0326, -0.0058, -0.0108,\n",
      "          -0.0559, -0.0190, -0.2305,  0.0346,  0.0506, -0.0024, -0.0176,\n",
      "          -0.1117,  0.0221,  0.0193, -0.2336, -0.1610, -0.3212,  0.0299,\n",
      "           0.0212, -0.0357,  0.0727, -0.0227, -0.1524, -0.1926, -0.0042,\n",
      "           0.1684, -0.3040,  0.1244, -0.0564,  0.1966, -0.0280,  0.0345,\n",
      "           0.1384,  0.1235, -0.2502,  0.0810,  0.1078,  0.1229,  0.0921,\n",
      "          -0.0132, -0.1217,  0.1546,  0.0583,  0.0230,  0.2513,  0.0709,\n",
      "          -0.3140,  0.2421,  0.1059, -0.1956, -0.4185,  0.2055, -0.0624,\n",
      "          -0.0764,  0.1082,  0.0710,  0.0317,  0.0690,  0.0300, -0.0677,\n",
      "           0.1308,  0.0362,  0.2601, -0.0142, -0.1841, -0.0227,  0.2615,\n",
      "           0.0920,  0.1471, -0.2057,  0.0276,  0.1138,  0.0005,  0.0906,\n",
      "          -0.1237, -0.2557,  0.0737, -0.2047]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2886,  1.3169,  2.0391,  0.0000,  0.6607,  0.2468, -0.1053,\n",
      "          -1.4848,  0.8815,  0.9776,  0.2953,  0.1450,  0.6679, -0.7735,\n",
      "           1.4400,  0.0547, -0.7505, -2.0129,  0.5492,  0.5520,  1.2677,\n",
      "           0.2286, -0.0931, -0.9292, -2.2745, -1.6840,  0.7096, -0.7789,\n",
      "          -1.6775, -1.0351, -0.2547,  1.4538,  0.1771,  1.4771,  0.6742,\n",
      "          -0.0203,  0.0000,  2.2027,  1.9105,  1.8212, -1.1543,  0.8147,\n",
      "           0.0000, -0.3131, -0.9474,  0.0000,  0.0910, -0.4498,  0.9951,\n",
      "           1.1382, -0.7596, -1.4270, -0.7677,  1.2277,  0.3004,  0.0000,\n",
      "          -1.8220,  0.0000, -0.3915, -0.3829, -0.3249, -1.0036,  0.9552,\n",
      "          -0.3512, -0.1532,  0.5429, -2.6088, -0.2180,  2.0308, -1.6270,\n",
      "           0.0000, -1.2562, -0.8638, -0.8522, -3.1511, -0.2798, -0.3768,\n",
      "           1.6946,  0.3381,  0.7359,  0.0000, -0.3066,  0.2118,  1.0083,\n",
      "          -1.7340, -0.2841,  1.2852, -0.5779, -0.4272,  0.2125,  1.5010,\n",
      "           0.0000, -0.8678,  0.6750,  0.0420, -1.0028,  0.2279,  0.4872,\n",
      "           0.0562, -0.3386,  0.0000,  0.0000, -0.7690, -0.1170, -1.3479,\n",
      "          -0.3051,  0.7931, -2.4743,  2.0976, -0.6051,  0.3151, -0.5208,\n",
      "          -0.4856,  0.9442, -0.0925, -1.4523, -0.0910, -0.9090,  0.5259,\n",
      "           0.2350,  0.0000,  0.3921,  0.4635, -0.5968, -1.7096, -0.4026,\n",
      "           0.2429, -1.3461, -1.0463, -0.5124,  0.5608,  0.4698,  0.5907,\n",
      "          -0.5859,  0.6563,  0.1636,  0.0000, -1.3329, -1.2449, -1.1038,\n",
      "           0.4318, -2.6137, -0.9142,  2.3404, -1.0565,  0.0000, -0.7291,\n",
      "           0.5483, -0.5942,  0.1237,  1.0025,  0.6088,  1.0814,  2.4564,\n",
      "           0.1198, -0.5362, -0.6337,  0.1251, -1.1677,  0.5778,  0.0000,\n",
      "          -0.1319, -0.0248,  0.0000, -0.9760, -1.0209, -0.7908, -0.5031,\n",
      "           1.7596, -0.0273,  0.2637, -2.0253, -0.6429, -4.0320,  0.9885,\n",
      "           0.0812,  0.8267,  0.6681, -1.2728,  0.3457,  0.5356,  0.1563,\n",
      "           0.0000,  0.6139, -1.6616,  0.9680, -0.8343, -0.9034, -0.2832,\n",
      "           0.6666,  0.9253,  2.1916, -0.2308,  0.5009, -1.7934,  1.4115,\n",
      "          -0.4694, -0.0513, -0.4531,  0.9908,  0.5037, -0.7296,  0.5849,\n",
      "          -0.9473, -0.0544, -0.8242,  1.6584,  2.4624,  1.4845,  2.4294,\n",
      "           2.0491, -0.0089, -0.6047, -0.7610,  0.5710,  0.5983, -0.1009,\n",
      "          -1.1171, -0.5031,  1.3838,  1.1681, -0.2125,  0.3715, -0.1669,\n",
      "           0.2793, -0.3910,  0.3694, -1.7447,  1.3566,  1.0109,  1.6523,\n",
      "          -0.5249, -0.8466, -0.6972,  0.9556,  1.1696, -0.6311, -1.5428,\n",
      "           0.5653,  1.0092, -0.1686,  2.1453,  0.0000,  0.8127, -0.5752,\n",
      "          -0.9474, -1.4175,  2.5374, -0.2552, -1.0944,  0.6715,  0.7761,\n",
      "          -1.3934,  2.0639, -2.8866, -0.5685]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0761, 0.0792, 0.2145, 0.1195, 0.1134, 0.1710, 0.0582, 0.0419, 0.0889,\n",
      "         0.0375]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.7919e-01, -1.1652e-01,  6.3686e-02,  2.1853e-02,  2.6027e-01,\n",
      "           2.5069e-01, -1.9896e-01,  1.9550e-01,  3.4723e-02,  3.3284e-01,\n",
      "          -1.1215e-01, -7.0443e-02,  1.9412e-01,  1.0696e-02,  1.3656e-01,\n",
      "           1.9650e-01, -4.3237e-02, -6.7255e-02, -1.8745e-01, -1.4236e-01,\n",
      "          -2.7448e-01, -1.1654e-01, -6.0615e-02, -1.5235e-01, -4.4523e-02,\n",
      "          -6.2773e-02, -3.0950e-01, -1.9329e-01, -3.5593e-02, -9.4245e-02,\n",
      "           8.7712e-02, -1.4540e-03, -1.2204e-02, -1.2142e-01, -3.8039e-01,\n",
      "          -1.1532e-01,  9.7924e-03,  1.0098e-01,  4.4493e-03, -1.4974e-01,\n",
      "           1.3022e-01,  1.9542e-01, -9.1325e-02,  1.7222e-01,  1.2922e-01,\n",
      "           1.2774e-01,  7.6735e-02,  1.0755e-01, -9.5045e-02, -4.8251e-02,\n",
      "          -7.7554e-02, -2.2433e-01, -2.6368e-02, -8.0364e-02,  7.7248e-03,\n",
      "           1.7150e-01, -1.9442e-02,  1.0637e-01, -6.0388e-02,  1.7589e-01,\n",
      "           2.2270e-01, -2.7786e-01,  6.2577e-02, -2.5699e-02,  9.4670e-02,\n",
      "           2.5171e-01,  2.8152e-01, -7.5752e-03, -1.2136e-01, -1.8186e-02,\n",
      "          -5.8174e-02,  4.6931e-01,  1.1337e-02,  2.1531e-01, -2.4551e-01,\n",
      "          -3.1163e-02,  5.9825e-02, -1.9903e-02,  3.8808e-02,  6.1345e-02,\n",
      "          -2.2577e-01, -1.8288e-01,  2.3872e-04, -8.4930e-02,  1.3949e-01,\n",
      "           9.3535e-02,  1.2479e-01,  1.3612e-01,  6.0958e-02, -2.8318e-02,\n",
      "          -1.2411e-01,  8.9494e-02,  1.2429e-02, -4.7348e-02, -7.5473e-02,\n",
      "           3.4356e-02,  1.9724e-01, -3.1175e-03, -1.5259e-01,  6.1429e-02,\n",
      "          -1.0203e-01,  2.1902e-01,  1.5060e-01,  1.8320e-02,  2.1608e-01,\n",
      "          -1.1342e-01, -1.2780e-01, -1.5098e-01, -2.7125e-02, -4.8890e-03,\n",
      "           3.5595e-02, -2.3160e-01, -1.5118e-01,  1.9964e-01,  9.2392e-02,\n",
      "          -1.3377e-01, -4.4328e-02, -9.2232e-02,  3.8321e-02, -2.0850e-01,\n",
      "           7.7339e-02, -1.2659e-01,  1.4912e-01,  2.3768e-01, -3.5014e-01,\n",
      "          -8.2620e-02,  1.6524e-01,  6.4515e-02,  9.7081e-02, -1.2299e-01,\n",
      "          -2.3981e-02, -3.3261e-02,  2.9756e-01,  4.0939e-01,  6.1257e-02,\n",
      "          -1.7997e-01,  8.5654e-02,  3.6443e-02,  3.0867e-01,  3.1117e-01,\n",
      "          -5.8213e-02,  1.3674e-01,  2.8577e-02,  2.0218e-01,  9.8028e-03,\n",
      "           2.3082e-01, -5.7137e-02, -1.0044e-02, -6.4215e-02, -1.3412e-01,\n",
      "          -5.1638e-03, -1.6178e-01,  4.2754e-02,  2.9060e-01, -1.9084e-01,\n",
      "          -7.1243e-03,  1.6804e-01,  1.7538e-01, -9.9228e-02,  2.0357e-01,\n",
      "           1.7403e-01, -7.5387e-02,  6.6325e-03,  7.9609e-03, -1.3541e-01,\n",
      "           2.7812e-02,  7.8291e-02,  2.7275e-01,  6.1488e-02,  3.0811e-01,\n",
      "           5.7552e-02,  2.4971e-01, -4.5861e-02,  3.0505e-01, -7.3645e-02,\n",
      "          -7.6133e-02,  1.5890e-01,  4.5052e-02, -1.8886e-01,  7.5072e-03,\n",
      "           3.7997e-03, -6.6706e-02, -1.6757e-02, -2.0119e-04, -2.5635e-01,\n",
      "           7.7167e-02,  1.1530e-02,  3.8575e-03,  1.9619e-02, -8.1583e-02,\n",
      "           2.1794e-02,  6.5727e-02, -2.5237e-01, -1.8687e-01, -3.0875e-01,\n",
      "           1.2325e-02,  3.0311e-02, -3.6093e-02,  1.0415e-01, -7.0896e-05,\n",
      "          -1.6704e-01, -2.1573e-01, -2.1181e-02,  1.6042e-01, -3.0877e-01,\n",
      "           1.0852e-01, -7.7544e-02,  1.9849e-01, -4.6512e-02,  7.4324e-02,\n",
      "           1.7767e-01,  1.0560e-01, -2.1585e-01,  8.0008e-02,  1.2999e-01,\n",
      "           1.3831e-01,  4.0364e-02, -6.4656e-03, -1.3442e-01,  2.0926e-01,\n",
      "           6.0381e-02,  4.7402e-02,  3.0056e-01,  5.7506e-02, -3.1958e-01,\n",
      "           2.5480e-01,  8.6856e-02, -1.3280e-01, -4.3461e-01,  2.1317e-01,\n",
      "          -4.1598e-02, -5.4870e-02,  1.2232e-01,  8.2303e-02,  5.0647e-02,\n",
      "           9.1387e-02,  2.3876e-02, -4.2040e-02,  9.8709e-02,  1.7209e-02,\n",
      "           2.7564e-01, -3.3067e-03, -1.9412e-01,  3.9852e-03,  2.5131e-01,\n",
      "           1.1627e-01,  1.7716e-01, -2.2655e-01,  5.7776e-02,  1.3342e-01,\n",
      "           4.1409e-02,  9.4587e-02, -1.2319e-01, -3.1438e-01,  8.1793e-02,\n",
      "          -2.1701e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0758,  0.0000,  0.0157,  0.5054,  0.3060, -0.7297, -0.4466,\n",
      "          -0.5702, -0.3965, -1.6494, -0.2719,  1.2976, -0.1513,  0.3630,\n",
      "           0.0000, -2.3380,  0.2715, -0.6453, -0.0690,  0.4583, -0.0679,\n",
      "           1.5239, -0.1171,  0.3188,  1.9443, -0.1278,  0.0832,  0.0000,\n",
      "           1.0938,  0.8250, -0.9437,  0.6088,  0.5275, -0.5946, -1.7208,\n",
      "           1.1170,  0.9357, -1.0320,  0.8456, -2.1177, -0.5777, -0.1105,\n",
      "           0.0000, -1.3950,  0.8396,  0.9603,  0.5623, -0.2475, -1.2511,\n",
      "           0.0000, -0.5665, -0.1108,  0.4985,  0.0000,  0.0444, -0.4576,\n",
      "          -1.0686,  0.5138, -0.0437, -0.1042,  0.5397, -1.3392,  1.2344,\n",
      "          -1.0604, -0.3582, -0.3656, -0.6718,  0.3685,  1.3529,  1.1737,\n",
      "          -0.2404,  0.9299, -1.5400, -0.6883, -0.8407, -1.6715,  0.0154,\n",
      "           0.8900, -0.3419,  0.0000,  2.4115,  1.8472, -1.7461,  2.9247,\n",
      "          -0.3657,  1.2687, -0.6707,  0.2101,  0.0497,  0.0000,  0.6474,\n",
      "          -1.4145, -0.5169,  1.0870, -1.1973,  2.9605,  0.6829,  0.9798,\n",
      "           0.5048,  0.2083, -0.5184,  0.4280,  0.0000, -1.6335,  0.2554,\n",
      "          -0.5740,  1.2758, -0.7194,  0.2216,  0.4711, -0.7789, -0.2945,\n",
      "           0.8928,  0.0000,  0.1869,  0.4504,  0.0000,  0.0374, -0.4686,\n",
      "           1.5041,  0.8312,  0.8753, -0.0218,  2.3835, -0.1035,  0.0000,\n",
      "           1.1469,  0.1470, -1.2390, -0.6784, -0.6270, -0.0105, -2.9853,\n",
      "          -0.3596,  1.9166, -0.6173, -0.3105,  0.4948, -0.4168, -0.8982,\n",
      "          -0.2762,  0.7360,  0.7387,  1.1560,  0.6395, -0.3644, -1.1429,\n",
      "          -0.4463,  0.5974, -0.1376, -0.2322,  1.4043,  0.0000,  0.0000,\n",
      "          -0.7648,  0.8840,  0.2749, -0.4991, -0.8230, -0.2009, -2.2220,\n",
      "           0.0000,  0.0408,  0.6492, -0.9963,  0.0000,  1.9677, -0.5139,\n",
      "           1.1480,  0.2528, -0.3891, -0.5695, -0.4859,  0.2455,  1.0051,\n",
      "          -1.6923,  0.0000,  1.1650, -1.6189,  0.9848, -0.3867, -0.0269,\n",
      "           0.0988, -0.4358, -0.3655,  1.6978,  1.2416,  0.0000,  0.7273,\n",
      "          -0.4671,  0.0172, -0.2008,  1.7225, -0.8318, -0.5861,  0.4885,\n",
      "          -1.9777, -0.9198,  0.7340,  0.5389,  2.5073,  0.7511,  1.4233,\n",
      "           0.4864,  1.3715, -2.1816,  0.0000,  0.3671, -1.2948, -1.0768,\n",
      "          -0.4240,  2.0234, -0.7941,  1.4183,  0.2653, -0.9233, -0.0651,\n",
      "           0.4051,  0.7621,  0.4610,  2.2215,  1.4773,  1.4895,  1.2216,\n",
      "          -2.2532,  1.5824, -1.7020, -1.9643,  1.2618,  2.9839, -0.1220,\n",
      "          -0.8842,  1.7628,  0.0000,  0.2790,  0.0000, -0.0303,  0.8927,\n",
      "           0.7607,  0.0000, -1.7120, -0.7356,  1.2249,  0.9197, -1.9125,\n",
      "           1.4957, -0.4389,  0.4867,  0.1600,  0.3723,  0.3412,  0.0206,\n",
      "          -0.2826,  0.0000, -0.8130,  1.8611]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0347, 0.0687, 0.1462, 0.0697, 0.2154, 0.1087, 0.0855, 0.0678, 0.0573,\n",
      "         0.1461]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.4294e-01, -1.3927e-01,  1.4998e-01, -4.4815e-02,  2.6926e-01,\n",
      "           2.2033e-01, -1.6669e-01,  1.9796e-01,  3.3218e-02,  2.7351e-01,\n",
      "          -5.8537e-02, -4.5985e-02,  1.9279e-01,  1.2178e-02,  6.5918e-02,\n",
      "           1.4984e-01, -9.7005e-02, -9.1402e-02, -1.7937e-01, -1.5140e-01,\n",
      "          -2.3652e-01, -1.3249e-01,  1.6986e-02, -1.6359e-01, -3.0009e-03,\n",
      "          -4.7098e-02, -3.2206e-01, -1.9154e-01, -4.8917e-02, -1.8507e-02,\n",
      "           1.2709e-01,  6.0839e-02, -9.5567e-03, -1.6606e-01, -3.1882e-01,\n",
      "          -7.8330e-02, -3.1060e-03,  6.8452e-02,  5.6807e-02, -1.1555e-01,\n",
      "           6.6896e-02,  2.3423e-01, -4.0373e-02,  1.7952e-01,  1.0611e-01,\n",
      "           1.2931e-01,  2.8652e-02,  8.6556e-02, -8.7105e-02, -8.2441e-03,\n",
      "          -6.4065e-02, -1.5192e-01, -6.6085e-02, -7.5482e-02,  2.0352e-02,\n",
      "           1.7686e-01, -2.2114e-02,  3.7563e-02, -7.1554e-02,  1.2848e-01,\n",
      "           2.4692e-01, -2.8477e-01,  5.8843e-02, -2.2605e-02,  1.1508e-01,\n",
      "           3.0609e-01,  2.8073e-01,  3.7179e-02, -1.7823e-01,  2.8691e-03,\n",
      "          -9.8216e-02,  4.1161e-01,  3.4601e-02,  2.1248e-01, -1.7849e-01,\n",
      "          -4.9055e-02,  3.8926e-02, -2.4024e-05, -4.5345e-02,  3.9540e-02,\n",
      "          -1.5262e-01, -1.5993e-01,  1.6559e-03, -5.7739e-02,  6.1404e-02,\n",
      "           1.3452e-01,  1.6533e-01,  1.2322e-01,  8.1952e-02, -3.1134e-02,\n",
      "          -2.6326e-02,  9.8350e-02,  3.6188e-02, -8.1760e-02, -2.8360e-02,\n",
      "           3.4898e-02,  1.8299e-01, -6.7527e-03, -1.2512e-01,  4.2890e-02,\n",
      "          -1.0235e-01,  2.0693e-01,  1.5175e-01,  2.0040e-02,  2.3885e-01,\n",
      "          -1.6031e-01, -1.0359e-01, -1.0927e-01,  1.8531e-02, -2.5879e-02,\n",
      "           8.1430e-02, -2.0067e-01, -1.3899e-01,  1.6080e-01,  9.4320e-02,\n",
      "          -1.2789e-01, -7.1952e-02, -6.3427e-02,  6.0287e-02, -1.9560e-01,\n",
      "           5.3423e-02, -1.1313e-01,  1.6905e-01,  2.7366e-01, -2.9659e-01,\n",
      "          -1.0273e-01,  1.2681e-01,  6.1503e-02,  4.9873e-02, -1.3748e-01,\n",
      "          -5.2443e-03, -5.0995e-02,  2.6041e-01,  3.9506e-01,  2.0863e-02,\n",
      "          -2.2249e-01,  4.6119e-02, -1.2456e-02,  2.5452e-01,  3.3900e-01,\n",
      "          -6.6824e-02,  1.5217e-01, -1.4473e-02,  1.8107e-01,  3.4285e-02,\n",
      "           1.6582e-01, -7.1707e-02, -4.1525e-02, -2.6040e-02, -1.3866e-01,\n",
      "          -3.7040e-02, -1.5234e-01, -1.8204e-02,  2.3616e-01, -1.6383e-01,\n",
      "           2.0139e-02,  1.3989e-01,  1.0527e-01, -1.3128e-01,  1.7229e-01,\n",
      "           1.7017e-01, -9.6791e-02,  7.6095e-02, -1.0392e-02, -7.5341e-02,\n",
      "           2.2289e-02,  4.2117e-02,  2.4934e-01,  2.4207e-02,  2.4551e-01,\n",
      "           3.1260e-02,  1.6484e-01, -4.8783e-02,  2.8531e-01, -1.1295e-01,\n",
      "          -8.5925e-02,  1.2232e-01,  5.3838e-02, -1.8987e-01, -1.4655e-03,\n",
      "           1.1429e-02, -4.8010e-03, -2.6834e-02, -1.2801e-02, -2.5308e-01,\n",
      "           2.2607e-02,  3.7485e-02,  2.9111e-02, -3.2151e-02, -9.7502e-02,\n",
      "          -1.1664e-02,  4.1032e-02, -2.0684e-01, -1.6219e-01, -2.9593e-01,\n",
      "           4.4553e-02, -8.1185e-03, -7.4994e-02,  1.0001e-01, -1.6891e-02,\n",
      "          -1.6224e-01, -1.9924e-01, -3.1694e-02,  1.6276e-01, -3.0959e-01,\n",
      "           1.3884e-01, -1.9940e-02,  1.8952e-01, -6.1219e-03,  1.4260e-02,\n",
      "           8.6981e-02,  1.5106e-01, -2.4398e-01,  1.1524e-01,  8.4502e-02,\n",
      "           1.6780e-01,  5.2346e-02, -3.9447e-02, -4.6068e-02,  1.3842e-01,\n",
      "           2.7245e-02,  4.1240e-02,  2.1887e-01,  1.0890e-01, -2.7533e-01,\n",
      "           1.6232e-01,  1.2176e-01, -2.0900e-01, -3.6498e-01,  2.0433e-01,\n",
      "          -1.9530e-02, -6.2929e-02,  1.0553e-01,  9.0075e-02,  4.6277e-02,\n",
      "           1.1618e-01,  7.9843e-02, -5.6083e-02,  1.5725e-01,  1.9285e-02,\n",
      "           2.2846e-01,  2.8942e-02, -1.3829e-01, -3.3754e-02,  2.3488e-01,\n",
      "           8.7016e-02,  1.7375e-01, -1.8556e-01,  4.1077e-02,  1.4020e-01,\n",
      "           2.1595e-02,  5.6918e-02, -9.1124e-02, -2.4362e-01,  7.0776e-02,\n",
      "          -2.1274e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7275e-01,  0.0000e+00,  3.1540e-01, -1.0854e+00, -1.1730e+00,\n",
      "           7.4166e-01, -1.9147e+00,  1.3514e+00,  1.9013e-01,  6.1749e-01,\n",
      "           1.9038e+00,  6.0265e-01,  2.2914e-01,  0.0000e+00, -3.1845e+00,\n",
      "          -6.8299e-02, -1.6339e+00, -9.4357e-01,  1.3602e+00, -1.4360e+00,\n",
      "          -1.4036e-01, -5.2460e-01, -1.1202e+00, -2.5963e+00,  0.0000e+00,\n",
      "           1.3918e+00, -6.2008e-01,  1.9985e+00,  1.2774e-01,  5.5549e-01,\n",
      "           9.1616e-01, -3.8850e-03,  2.2228e-01,  2.0173e+00,  0.0000e+00,\n",
      "          -1.4087e+00, -1.1155e-01, -8.1734e-01,  3.1533e-01,  8.6180e-02,\n",
      "           8.6372e-01, -8.9925e-01,  1.0090e+00, -1.5643e+00,  1.9452e+00,\n",
      "          -3.0036e-01,  7.0668e-01,  0.0000e+00, -1.0210e+00,  1.1175e+00,\n",
      "          -1.3236e+00,  2.6786e+00,  6.6709e-01, -8.4711e-01,  2.2815e-01,\n",
      "          -3.1028e-01, -1.4341e+00,  0.0000e+00,  1.2762e+00,  2.1825e+00,\n",
      "           0.0000e+00,  3.5677e-02, -2.8018e-01,  2.6573e-01, -6.3302e-02,\n",
      "           3.9351e-01,  0.0000e+00,  0.0000e+00,  1.5813e+00, -1.4155e+00,\n",
      "           4.2732e-01,  0.0000e+00, -3.0941e-02, -7.9821e-01, -2.1410e-01,\n",
      "           1.3953e-01,  5.2603e-01,  1.3993e+00,  1.0275e+00, -7.9456e-01,\n",
      "           7.5868e-01, -1.0048e+00,  7.5857e-01,  1.0590e+00, -1.2160e+00,\n",
      "          -1.1336e-01,  0.0000e+00,  5.4875e-01, -9.4507e-01, -1.9016e+00,\n",
      "           5.2934e-01,  9.8767e-01,  0.0000e+00,  9.4441e-01,  6.0800e-01,\n",
      "          -1.5887e-02,  3.5447e-01, -1.1762e+00,  1.3729e+00,  2.4484e+00,\n",
      "           2.4340e-01,  4.3991e-02, -4.6669e-01, -9.8953e-01,  1.6415e+00,\n",
      "          -1.0243e+00,  3.0308e+00,  6.2094e-01, -1.0188e-01, -1.2358e+00,\n",
      "           1.8999e-01,  0.0000e+00, -5.7120e-01,  7.1273e-01, -7.8080e-01,\n",
      "           6.3270e-01,  4.0375e-01,  2.2336e-01, -2.3274e+00,  2.9200e-02,\n",
      "          -8.1498e-01, -1.4121e+00, -1.8390e+00,  6.0328e-01, -9.5746e-01,\n",
      "          -2.0114e-01,  4.0406e-02,  2.1511e+00,  1.3968e+00, -2.0886e+00,\n",
      "          -9.2632e-01,  4.5012e-01, -1.1686e+00,  4.2555e-01, -4.6826e-01,\n",
      "          -7.4665e-01, -1.0650e+00, -9.7569e-01, -1.9383e-02,  2.3982e+00,\n",
      "           6.9865e-01, -1.1220e+00,  1.6921e+00, -1.4047e-01, -6.7015e-01,\n",
      "           3.3047e-02,  7.6001e-01,  4.2282e-01, -1.0342e+00, -9.5210e-02,\n",
      "           1.5602e+00,  5.8677e-01, -3.3833e-01,  6.5790e-01,  1.8417e+00,\n",
      "          -2.5283e-01, -2.1810e-01,  6.2412e-01, -2.3643e+00,  1.0562e+00,\n",
      "           3.0297e-01, -7.7165e-02,  1.5534e-01, -1.2124e+00, -2.1924e-02,\n",
      "           1.6829e+00,  1.8531e+00,  2.7190e-01,  0.0000e+00, -7.1299e-01,\n",
      "          -1.2245e+00, -1.0942e+00, -2.5912e+00,  5.0604e-01,  0.0000e+00,\n",
      "          -2.8743e-01,  4.9755e-01,  8.2995e-01,  3.1708e-01, -7.9310e-01,\n",
      "           2.7282e-01,  2.3401e+00,  1.0586e+00,  8.3924e-01, -4.0229e-01,\n",
      "           7.2802e-01,  5.9882e-01,  3.5991e-01,  8.4353e-01, -1.8314e+00,\n",
      "           1.3638e+00,  2.1605e+00,  3.3569e-01, -1.0159e+00, -1.1733e+00,\n",
      "          -2.2166e+00,  1.6680e+00,  2.1537e+00,  3.6347e-01,  2.3838e+00,\n",
      "           3.2576e-02,  0.0000e+00, -1.2773e+00, -5.4315e-01, -4.0778e-01,\n",
      "           0.0000e+00,  9.5342e-01, -8.5211e-01,  8.2935e-01, -1.5607e+00,\n",
      "           0.0000e+00,  6.7534e-01,  2.3989e+00,  5.5312e-02,  1.8939e+00,\n",
      "           1.3094e+00,  5.8020e-01,  0.0000e+00,  1.5505e+00, -2.2257e-01,\n",
      "          -2.2742e-01,  1.7346e+00,  2.7644e-01, -1.5526e+00,  9.2302e-01,\n",
      "          -1.2244e+00, -8.4914e-01, -1.8029e+00, -8.3199e-04,  3.7327e-01,\n",
      "          -1.5741e+00, -1.2400e-01,  0.0000e+00, -1.7379e+00,  1.6949e+00,\n",
      "          -1.4407e+00,  6.3395e-01, -1.7234e+00,  9.8036e-01, -1.7174e+00,\n",
      "           1.5616e+00, -2.7312e-01, -2.5978e+00,  1.2394e+00, -1.2282e+00,\n",
      "           1.8867e+00, -5.0857e-01,  5.4280e-01, -2.6127e-01, -1.0227e+00,\n",
      "           1.3341e+00,  3.1153e-01, -5.0814e-02, -2.2872e-01, -1.6135e+00,\n",
      "           1.8072e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0423, 0.1178, 0.1669, 0.1071, 0.1368, 0.1107, 0.1266, 0.0547, 0.0790,\n",
      "         0.0581]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3516, -0.0350,  0.0686,  ..., -0.1124, -0.0111, -0.4901],\n",
      "        [ 0.1255,  0.1340,  0.2611,  ...,  0.1109,  0.0909,  0.0395],\n",
      "        [-0.0100,  0.0630, -0.4322,  ..., -0.4484,  0.1999, -0.1671],\n",
      "        ...,\n",
      "        [ 0.5983, -0.0809,  0.0869,  ..., -0.5194,  0.4359, -0.0217],\n",
      "        [ 0.7852,  0.4882, -0.5963,  ..., -0.4417,  0.0331,  0.2230],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.7432e-01, -1.2719e-01,  1.1830e-01, -8.3312e-03,  2.7727e-01,\n",
      "           2.2087e-01, -1.8756e-01,  2.1345e-01,  3.6076e-02,  3.1312e-01,\n",
      "          -8.1394e-02, -4.5640e-02,  1.8195e-01,  9.5795e-03,  5.7008e-02,\n",
      "           1.7180e-01, -7.1440e-02, -9.4097e-02, -2.1813e-01, -1.4300e-01,\n",
      "          -2.5241e-01, -1.5008e-01, -3.8632e-02, -1.7434e-01, -3.5886e-02,\n",
      "          -7.3531e-02, -3.2500e-01, -1.7616e-01, -3.6700e-02, -8.9281e-02,\n",
      "           7.4229e-02,  2.9967e-02, -3.8838e-04, -1.1629e-01, -3.6886e-01,\n",
      "          -6.3939e-02, -2.5969e-03,  5.0227e-02,  2.8552e-02, -1.4944e-01,\n",
      "           1.0148e-01,  2.1033e-01, -7.9652e-02,  1.9464e-01,  1.3551e-01,\n",
      "           1.3469e-01,  3.5733e-02,  9.0227e-02, -7.2304e-02, -4.9183e-02,\n",
      "          -8.9973e-02, -2.4644e-01, -1.3287e-02, -8.3514e-02,  1.8815e-02,\n",
      "           1.6214e-01, -3.2039e-03,  8.9326e-02, -4.5516e-02,  1.8808e-01,\n",
      "           2.3504e-01, -2.8832e-01,  4.1148e-02, -8.5750e-03,  1.1449e-01,\n",
      "           2.8389e-01,  2.7079e-01,  1.9017e-02, -1.8168e-01, -2.5120e-02,\n",
      "          -5.7955e-02,  4.6098e-01, -1.2646e-02,  2.1141e-01, -2.1440e-01,\n",
      "          -1.6697e-02,  5.2808e-02, -2.5962e-02, -3.3131e-02,  4.2617e-02,\n",
      "          -2.0612e-01, -1.8082e-01, -1.2583e-02, -4.8550e-02,  1.0078e-01,\n",
      "           1.0389e-01,  1.5717e-01,  1.4437e-01,  6.0351e-02, -5.9401e-03,\n",
      "          -8.2995e-02,  1.2863e-01,  1.1260e-02, -4.9174e-02, -4.1295e-02,\n",
      "           7.2158e-02,  1.8272e-01,  3.5830e-02, -1.5006e-01,  9.6046e-02,\n",
      "          -1.4167e-01,  2.3485e-01,  1.7719e-01,  8.5261e-03,  1.9083e-01,\n",
      "          -1.5602e-01, -7.7663e-02, -1.0899e-01, -5.3817e-02, -6.0097e-03,\n",
      "           4.6902e-02, -2.4258e-01, -1.1627e-01,  1.6037e-01,  7.4460e-02,\n",
      "          -1.0691e-01, -6.4274e-02, -1.3290e-01,  2.7930e-02, -2.2558e-01,\n",
      "           8.5863e-02, -1.0515e-01,  1.4569e-01,  2.6061e-01, -3.3120e-01,\n",
      "          -1.0521e-01,  1.5517e-01,  5.2001e-02,  1.0053e-01, -1.2292e-01,\n",
      "           6.9625e-03, -8.5536e-02,  2.8698e-01,  3.8480e-01,  4.6874e-03,\n",
      "          -2.1950e-01,  1.1159e-01,  6.8109e-03,  2.8538e-01,  3.4039e-01,\n",
      "          -5.9896e-02,  1.5259e-01,  3.8597e-02,  1.9497e-01,  3.2276e-03,\n",
      "           1.9876e-01, -3.6403e-02, -9.2050e-03, -5.4094e-02, -1.3650e-01,\n",
      "          -1.8357e-02, -1.4762e-01,  4.6556e-02,  2.8199e-01, -1.6465e-01,\n",
      "          -2.9156e-03,  1.3229e-01,  1.6195e-01, -8.9092e-02,  1.5075e-01,\n",
      "           1.6522e-01, -8.3788e-02,  5.3781e-02,  5.7885e-03, -1.2540e-01,\n",
      "           1.7135e-02,  4.0294e-02,  2.5405e-01, -3.8547e-03,  3.0448e-01,\n",
      "           8.9127e-04,  1.7804e-01, -7.4469e-02,  3.2092e-01, -7.8411e-02,\n",
      "          -9.8660e-02,  1.0426e-01,  5.2724e-02, -1.6689e-01, -1.1234e-02,\n",
      "           3.7329e-02, -2.2567e-02, -1.9872e-02,  3.3457e-04, -2.4978e-01,\n",
      "           2.4318e-02, -9.6041e-03,  1.7385e-02, -5.7241e-03, -1.0459e-01,\n",
      "           1.0254e-02,  3.4868e-02, -2.2854e-01, -1.8074e-01, -3.2152e-01,\n",
      "           3.2401e-02,  5.1992e-03, -6.2915e-02,  9.5905e-02, -1.5442e-03,\n",
      "          -1.4682e-01, -2.2209e-01, -5.3973e-02,  1.6474e-01, -3.0369e-01,\n",
      "           1.1652e-01, -1.9538e-02,  1.9189e-01, -3.5082e-02,  4.6644e-02,\n",
      "           1.4491e-01,  1.2210e-01, -2.4036e-01,  1.0855e-01,  1.0621e-01,\n",
      "           1.6449e-01,  4.1569e-02, -2.3648e-02, -1.0740e-01,  1.7858e-01,\n",
      "           3.3528e-02,  5.6420e-02,  2.7971e-01,  7.3485e-02, -2.5836e-01,\n",
      "           1.9871e-01,  1.2097e-01, -1.9246e-01, -4.1806e-01,  1.9186e-01,\n",
      "          -4.1269e-02, -5.9878e-02,  1.1281e-01,  5.4089e-02,  4.7347e-02,\n",
      "           1.0943e-01,  6.8803e-02, -7.9280e-02,  1.3882e-01,  3.6777e-02,\n",
      "           2.7931e-01,  1.3211e-02, -1.9374e-01,  3.0175e-02,  2.6111e-01,\n",
      "           1.0928e-01,  1.3152e-01, -2.2663e-01,  1.7816e-02,  1.3032e-01,\n",
      "           1.6468e-02,  3.5735e-02, -1.0505e-01, -2.6898e-01,  8.2612e-02,\n",
      "          -1.8498e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5622e-02,  3.9876e-01, -9.6731e-01, -6.8221e-01,  3.7657e-01,\n",
      "          -2.0171e-01,  1.4650e+00, -8.3220e-02, -3.5858e+00,  9.0691e-01,\n",
      "           4.2912e-01, -6.2943e-01,  2.6065e+00, -6.2971e-01, -5.4172e-01,\n",
      "          -1.5793e-01,  8.5183e-01,  1.0952e+00,  4.5518e-01,  4.3616e-01,\n",
      "          -6.3392e-01, -3.8382e-01,  1.6424e+00,  1.5117e+00,  7.5405e-01,\n",
      "          -7.5251e-02, -1.8767e-01, -7.5906e-01,  1.6544e+00,  8.6173e-01,\n",
      "           0.0000e+00,  1.2193e+00,  0.0000e+00, -8.2621e-02, -1.5354e+00,\n",
      "           1.3955e+00,  0.0000e+00, -3.7464e+00,  1.9814e-01,  0.0000e+00,\n",
      "          -4.5885e-01, -1.3992e+00, -2.6829e-01, -1.7173e+00, -1.5255e+00,\n",
      "           6.6728e-01,  5.4123e-01,  3.6994e-01, -1.3412e+00,  1.4358e-01,\n",
      "          -6.2879e-01,  0.0000e+00,  6.1064e-01, -1.0300e+00, -2.5870e-02,\n",
      "           2.0286e-01, -8.8254e-01, -1.2535e+00, -2.3648e-01,  0.0000e+00,\n",
      "           1.1017e+00,  1.4088e+00, -2.0393e-01, -5.0219e-01, -2.9657e+00,\n",
      "           5.5036e-01,  1.2794e+00, -1.2887e+00,  4.1190e-01,  5.2638e-01,\n",
      "          -1.2680e+00, -3.0558e-02,  7.0762e-01, -3.6435e+00,  3.2672e-01,\n",
      "          -2.4274e-03, -1.5983e-01,  1.0635e+00,  0.0000e+00, -1.2036e-01,\n",
      "          -1.4008e+00,  2.1325e+00, -9.2522e-01,  1.0057e+00, -2.0799e-01,\n",
      "           4.3420e-01,  1.6622e+00, -9.7527e-01, -1.0303e-01, -5.8167e-01,\n",
      "          -2.2746e+00,  1.1007e+00, -6.2238e-01, -1.1354e+00,  0.0000e+00,\n",
      "           0.0000e+00,  3.4521e-02,  6.2947e-01,  0.0000e+00,  0.0000e+00,\n",
      "           2.6983e+00, -1.4634e+00,  1.0762e+00,  1.4550e+00, -6.6676e-01,\n",
      "          -7.6260e-01,  0.0000e+00,  1.2754e-01, -1.4734e+00, -1.2921e-02,\n",
      "          -2.4904e-01,  1.3444e-01, -1.0491e+00,  1.3106e+00,  0.0000e+00,\n",
      "          -2.9912e+00, -5.6116e-02, -5.0197e-01, -1.9317e-01,  4.4462e-01,\n",
      "          -1.4676e+00,  7.0276e-01, -1.4611e+00, -7.2652e-01, -9.5899e-01,\n",
      "          -1.3099e+00,  8.9825e-01,  1.7068e-01,  1.2861e+00, -7.5300e-01,\n",
      "          -8.2310e-01,  5.2958e-01,  0.0000e+00,  9.8431e-01,  2.7618e-01,\n",
      "          -5.8972e-01,  6.6024e-01,  5.7306e-01, -1.1585e+00, -1.0111e+00,\n",
      "          -3.8925e-01,  6.7784e-01,  0.0000e+00, -1.0206e-01, -1.6870e+00,\n",
      "          -1.0155e-01, -5.4343e-01, -8.4473e-01,  0.0000e+00,  1.7742e-01,\n",
      "           1.9996e+00,  0.0000e+00, -1.9317e+00, -4.0634e-01,  4.4173e-01,\n",
      "          -1.9447e-01, -6.3926e-02,  0.0000e+00,  3.9574e-02,  5.3774e-01,\n",
      "          -2.6043e-02,  2.2070e+00,  4.8121e-01, -5.4969e-01, -5.2797e-01,\n",
      "          -8.9330e-01,  2.8188e-01,  0.0000e+00, -3.5806e-01, -4.7827e-01,\n",
      "           7.3878e-01, -3.2794e-02,  1.9802e-02, -1.0021e+00,  1.2782e+00,\n",
      "          -1.0996e+00, -9.8838e-01,  0.0000e+00,  1.9704e+00,  8.6432e-02,\n",
      "          -2.9448e-02,  3.5076e-02,  6.7195e-01,  9.7987e-01, -7.4695e-01,\n",
      "          -3.4111e-01, -2.7849e+00, -7.8517e-01,  1.2104e+00,  1.0127e+00,\n",
      "           3.0763e+00,  4.9456e-01,  0.0000e+00, -5.9521e-01,  5.6096e-01,\n",
      "           2.1663e+00, -1.1887e+00,  5.3474e-01,  1.8130e+00,  0.0000e+00,\n",
      "          -1.6623e+00,  0.0000e+00,  1.2418e+00, -1.2206e-01,  0.0000e+00,\n",
      "          -5.7561e-01, -2.2938e+00,  6.8209e-01, -1.0752e+00, -4.7156e-01,\n",
      "           2.8696e+00, -5.7342e-01, -3.4119e-01,  7.9367e-01,  2.9682e-02,\n",
      "          -6.8533e-01, -1.0205e+00,  9.6626e-01,  0.0000e+00,  2.1707e+00,\n",
      "          -1.0832e+00,  0.0000e+00, -1.8446e+00, -5.0192e-01,  3.3682e-01,\n",
      "           0.0000e+00, -6.9665e-01, -6.2812e-01,  2.9236e-01, -1.5796e+00,\n",
      "          -1.1090e+00,  1.5819e+00, -6.1443e-01,  1.3100e+00, -2.9810e+00,\n",
      "           4.0374e+00,  5.8521e-01,  4.3655e-02, -1.5813e+00, -2.8780e-01,\n",
      "           7.4154e-01, -3.2501e+00, -3.0489e-01, -8.5300e-01,  1.1056e-02,\n",
      "           2.7526e-01,  2.7522e-01,  2.5282e-01,  2.6085e-01,  3.8674e-01,\n",
      "           0.0000e+00, -1.5826e-01, -5.5430e-01, -5.2689e-02, -1.1475e+00,\n",
      "           0.0000e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0355, 0.0521, 0.0699, 0.0820, 0.1138, 0.3040, 0.0622, 0.0917, 0.0636,\n",
      "         0.1252]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0998,  0.1450, -0.0464,  0.0854, -0.1637,  0.0144, -0.1453,\n",
      "           0.0748,  0.1294,  0.0883, -0.0254, -0.0452,  0.0573, -0.0130,\n",
      "          -0.0992,  0.2121,  0.0453,  0.2598, -0.1875,  0.2688, -0.2935,\n",
      "           0.0038, -0.0220,  0.1511, -0.1081, -0.0316,  0.0450, -0.1551,\n",
      "          -0.3018, -0.1333,  0.0117,  0.0894, -0.0065, -0.1240,  0.2347,\n",
      "          -0.2286, -0.1477,  0.0880, -0.1024, -0.0704, -0.0422, -0.0700,\n",
      "           0.0891,  0.0765,  0.2434, -0.1154,  0.1861, -0.0603,  0.2195,\n",
      "           0.0509, -0.3350,  0.0096, -0.1960,  0.0536, -0.2339,  0.1145,\n",
      "           0.1605,  0.1760, -0.1640,  0.2425, -0.0732, -0.0830, -0.0320,\n",
      "           0.2390, -0.0398, -0.0205, -0.1374, -0.2512, -0.0477, -0.1837,\n",
      "           0.3246,  0.1316, -0.1415,  0.1269, -0.0521, -0.1171,  0.0573,\n",
      "           0.0372,  0.1393, -0.0375, -0.1739, -0.0020, -0.1265,  0.1523,\n",
      "           0.0301,  0.0462, -0.0416, -0.0461,  0.0550, -0.0549,  0.0514,\n",
      "           0.1887,  0.0312, -0.1566,  0.1916,  0.2954,  0.0674,  0.2922,\n",
      "          -0.0684, -0.0689, -0.0529,  0.0584,  0.3560,  0.0400, -0.1180,\n",
      "          -0.2325, -0.1078, -0.2074,  0.0304, -0.0296,  0.1845,  0.0944,\n",
      "          -0.0216, -0.0627,  0.1523, -0.0376,  0.0955, -0.1101, -0.0884,\n",
      "          -0.0266,  0.1908,  0.0884,  0.0318,  0.0130, -0.0064, -0.1094,\n",
      "          -0.1621, -0.1576,  0.1967,  0.0597, -0.0586, -0.1262,  0.3110,\n",
      "           0.0314,  0.0823,  0.1118,  0.2056,  0.1156,  0.0989, -0.0180,\n",
      "           0.1290,  0.2737, -0.4379,  0.3851, -0.1445,  0.0821,  0.1576,\n",
      "           0.3144, -0.0792,  0.1172, -0.4005, -0.0411,  0.2010,  0.2682,\n",
      "          -0.1578,  0.3097,  0.2330,  0.2009, -0.0299,  0.0452,  0.0720,\n",
      "          -0.1907, -0.2538, -0.0443, -0.0774, -0.0106, -0.1964,  0.1879,\n",
      "           0.0017,  0.2212, -0.2632, -0.0461,  0.0811,  0.0892,  0.1303,\n",
      "           0.0795, -0.0227, -0.0042,  0.2342, -0.0838,  0.0191, -0.1528,\n",
      "           0.0012, -0.0913,  0.2680, -0.1569, -0.1727, -0.0564,  0.0899,\n",
      "          -0.1159, -0.1343, -0.1414, -0.0678, -0.1023,  0.0646,  0.1193,\n",
      "           0.0348,  0.2005,  0.1549,  0.1029,  0.0484,  0.0398,  0.1075,\n",
      "           0.2353, -0.0165,  0.0036,  0.0133,  0.1680, -0.0348,  0.0320,\n",
      "           0.3154,  0.0554, -0.0698,  0.2557, -0.1036, -0.1275,  0.1523,\n",
      "           0.2980, -0.1269,  0.0156,  0.2579, -0.2929,  0.2058, -0.1109,\n",
      "          -0.2507,  0.2522,  0.3631, -0.2048, -0.1450,  0.0163, -0.0986,\n",
      "          -0.3329, -0.1637, -0.0196,  0.0851, -0.2251, -0.1225,  0.1501,\n",
      "           0.1171,  0.2200, -0.0808,  0.0863, -0.1222,  0.0135,  0.3488,\n",
      "          -0.0860, -0.1866, -0.2174, -0.1913, -0.0528,  0.2512, -0.0013,\n",
      "          -0.1392,  0.1670,  0.1981, -0.1658]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4823,  1.6545, -1.0097, -1.1127,  0.4004,  0.6462,\n",
      "           0.0000, -0.9027,  0.0940, -0.2095,  0.3161,  0.1276, -0.9577,\n",
      "          -0.3088,  0.3245, -1.8656, -2.1366,  0.6083, -0.5295,  0.7694,\n",
      "           0.2828, -1.2565, -0.9732,  1.1928,  1.4268, -1.6559,  0.0000,\n",
      "           0.9846, -1.2882,  0.0000, -0.9457, -0.7692, -1.5225, -0.3684,\n",
      "           0.4845, -0.9884, -0.3513,  0.3283,  0.6285,  0.6071, -1.1772,\n",
      "           0.3730,  1.2540, -1.7958,  0.0000, -1.4978,  0.0000,  0.0000,\n",
      "           1.1467,  0.8655,  0.0374, -0.0720, -1.0045, -0.2960, -0.8050,\n",
      "          -1.8697,  0.5100,  1.5737,  2.0583, -0.8819, -0.7343,  1.9472,\n",
      "          -0.9066, -0.8594,  0.0000,  0.6392, -0.6176,  0.0217,  0.4295,\n",
      "          -1.5902, -0.0285,  0.0000,  1.4253, -0.4459,  0.5582, -3.6202,\n",
      "          -0.6178, -1.4070, -0.3114,  0.8704,  1.3129,  0.8814, -0.9605,\n",
      "           0.6941,  0.6927,  0.0000, -2.9903,  0.8148, -0.0185, -1.4910,\n",
      "           0.3247, -1.2889,  2.3927,  1.8844,  0.2152, -1.1099,  1.0777,\n",
      "           1.5511,  0.0000,  0.0145,  0.0000,  0.0000, -1.8823,  0.4073,\n",
      "           1.4169, -1.9891, -0.9152,  0.0000,  1.8170, -1.4328,  0.1793,\n",
      "          -0.4981,  1.3010, -0.1469,  0.0000,  0.3372, -1.6433,  0.8518,\n",
      "          -1.2945, -1.3470, -0.0997,  0.8781,  0.5349,  0.0000,  0.8186,\n",
      "          -0.2018, -1.0698,  0.1250, -0.4280, -1.2473,  2.3283,  0.0000,\n",
      "           0.3275, -0.0087, -0.6388, -0.0633, -0.6000, -0.4515,  1.0982,\n",
      "           0.5454, -1.1805, -2.2955, -0.8863,  0.2162, -0.1882,  0.0000,\n",
      "          -0.0827,  1.5431, -0.7185,  0.3218, -1.3512,  1.8151, -1.9314,\n",
      "           0.5129, -0.3341,  0.0000, -0.7583,  0.9339, -0.0176,  0.0000,\n",
      "          -1.1454,  2.2623, -1.7651, -0.3903, -0.6925,  0.5301,  2.1363,\n",
      "          -1.6407, -2.7425,  1.2550, -2.0861, -0.0068, -1.1603, -0.9214,\n",
      "          -0.7989, -0.3073, -0.4307,  0.1185, -1.5139,  0.1505, -0.4526,\n",
      "           0.1998,  0.9703,  0.4845, -0.0760, -1.5032, -0.2145,  0.4041,\n",
      "          -1.4628,  1.0721,  0.6062,  0.5037, -0.5086,  0.7253,  0.0000,\n",
      "           0.0000,  0.0420, -0.8383,  0.0000,  0.1195,  0.0000,  0.2824,\n",
      "           0.3538, -0.0091, -0.7151,  0.6958,  2.0168, -0.7503,  1.8923,\n",
      "           2.7905,  0.1561,  1.5050,  0.1015, -0.5908, -0.0231, -0.1429,\n",
      "          -1.3822,  0.4078,  0.6380, -0.6887,  1.8595,  0.6064,  0.4726,\n",
      "           0.0284,  1.5296, -0.3652, -0.2608,  0.8416, -0.2546,  0.7763,\n",
      "          -0.5522,  1.2384,  0.0932,  2.0766,  0.0000, -1.7046,  2.7793,\n",
      "          -1.4960,  0.0000, -0.8497,  0.0000, -1.0502, -0.8548,  0.1357,\n",
      "          -1.7795,  0.3818,  1.9829,  0.5689,  0.0000, -1.7500,  0.3684,\n",
      "           0.1555,  0.0000, -2.7268,  0.4076]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0288, 0.1442, 0.0998, 0.0468, 0.1865, 0.2327, 0.0487, 0.0536, 0.0881,\n",
      "         0.0708]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 5.6721e-02,  8.0783e-02, -7.0711e-02,  4.8382e-02, -1.9355e-01,\n",
      "          -1.6188e-03, -1.8123e-01,  5.5609e-02,  1.3917e-01,  1.2217e-01,\n",
      "          -5.1368e-02,  8.2072e-03,  7.8299e-02,  2.2624e-02, -4.9086e-02,\n",
      "           2.6823e-01,  1.4413e-02,  2.7276e-01, -1.5339e-01,  2.6955e-01,\n",
      "          -3.1917e-01, -2.7303e-02, -3.9539e-02,  1.2376e-01, -1.4431e-01,\n",
      "          -7.7519e-03,  4.8749e-02, -1.2627e-01, -2.7160e-01, -1.0474e-01,\n",
      "           1.1154e-02,  1.1305e-01,  4.9202e-02, -1.0096e-01,  1.7985e-01,\n",
      "          -2.6788e-01, -4.7936e-02,  6.0178e-02, -4.9932e-02, -7.3940e-02,\n",
      "           2.5648e-02, -8.9504e-02,  1.3815e-01,  1.9515e-03,  2.2940e-01,\n",
      "          -1.2248e-01,  2.7589e-01, -2.1829e-02,  2.2889e-01,  2.7198e-02,\n",
      "          -2.7454e-01,  3.8298e-02, -1.5747e-01, -5.4141e-03, -2.4829e-01,\n",
      "           1.1883e-01,  1.4931e-01,  1.3643e-01, -1.9469e-01,  2.3370e-01,\n",
      "          -4.0269e-02, -1.5764e-01, -1.0919e-03,  2.2892e-01, -3.0150e-02,\n",
      "           6.6385e-02, -1.3460e-01, -2.5202e-01, -5.9666e-02, -2.0113e-01,\n",
      "           3.2237e-01,  1.2771e-01, -1.1523e-01,  9.9372e-02,  2.6441e-02,\n",
      "          -9.6504e-02,  1.1740e-02,  1.3691e-02,  7.0297e-02, -3.8700e-02,\n",
      "          -1.5734e-01,  5.0741e-02, -4.8265e-02,  1.3749e-01,  5.0590e-02,\n",
      "           1.8050e-03, -5.9512e-02, -2.3059e-03, -9.0910e-03, -3.5152e-02,\n",
      "           6.6722e-02,  1.8370e-01, -7.2157e-05, -1.3735e-01,  2.0506e-01,\n",
      "           2.8432e-01,  6.6877e-03,  2.8212e-01, -4.0503e-02, -1.5065e-01,\n",
      "           4.0061e-02,  4.6128e-02,  3.7108e-01,  6.2545e-02, -6.6430e-02,\n",
      "          -1.5381e-01, -1.1549e-01, -2.5537e-01,  6.2270e-02, -4.8693e-02,\n",
      "           1.6260e-01,  6.6219e-02, -4.7350e-02,  5.0055e-02,  1.6614e-01,\n",
      "          -5.3510e-02,  1.2039e-01, -1.3571e-01, -2.9332e-02,  2.8898e-02,\n",
      "           1.8786e-01,  1.0253e-01,  2.5713e-02,  1.4981e-02,  3.9186e-03,\n",
      "          -6.4041e-02, -1.8928e-01, -1.5201e-01,  2.3521e-01,  6.9119e-02,\n",
      "          -4.8903e-02, -9.2289e-02,  2.4161e-01,  3.5481e-02,  1.0320e-01,\n",
      "           7.2732e-02,  1.9340e-01,  9.1980e-02,  1.2566e-01, -9.4667e-03,\n",
      "           1.5061e-01,  3.0680e-01, -4.8619e-01,  3.8781e-01, -1.2103e-01,\n",
      "           3.5379e-02,  1.7058e-01,  3.2503e-01, -4.6079e-02,  8.9052e-02,\n",
      "          -3.8871e-01, -4.0426e-02,  1.4865e-01,  2.2429e-01, -2.2302e-01,\n",
      "           3.1037e-01,  2.5961e-01,  1.8190e-01, -3.1064e-03,  1.3697e-01,\n",
      "           2.1680e-02, -1.1571e-01, -2.6191e-01, -8.9996e-02, -1.2469e-01,\n",
      "          -3.7615e-02, -1.9558e-01,  1.9165e-01, -9.6451e-03,  1.9354e-01,\n",
      "          -1.9595e-01,  5.2530e-02, -1.5463e-03,  7.6840e-02,  1.6514e-01,\n",
      "           9.5149e-02,  2.6623e-02, -1.3693e-02,  2.3726e-01, -8.0655e-02,\n",
      "           1.0737e-03, -1.6289e-01, -9.1383e-03, -4.5731e-02,  2.2718e-01,\n",
      "          -2.2421e-01, -1.4008e-01, -1.1319e-01,  5.9571e-02, -9.6869e-02,\n",
      "          -9.9663e-02, -1.0988e-01, -8.7897e-02, -6.6456e-02,  9.6699e-02,\n",
      "           1.9939e-01,  6.0657e-02,  1.7705e-01,  1.4712e-01,  9.4158e-02,\n",
      "           4.8088e-02, -4.1668e-02,  8.6246e-02,  1.9783e-01, -2.1782e-02,\n",
      "          -3.1850e-02,  4.4501e-02,  1.2820e-01, -7.3611e-02,  6.9132e-02,\n",
      "           2.8315e-01,  1.3045e-01, -5.4533e-02,  2.5034e-01, -6.9041e-02,\n",
      "          -1.2198e-01,  1.2762e-01,  2.8200e-01, -1.0241e-01,  3.4082e-02,\n",
      "           2.9021e-01, -2.7299e-01,  2.5783e-01, -1.7077e-01, -3.3241e-01,\n",
      "           1.7956e-01,  3.5107e-01, -2.0004e-01, -1.5918e-01, -7.4596e-03,\n",
      "          -7.7170e-02, -2.6758e-01, -1.2872e-01,  2.6345e-02,  9.9745e-02,\n",
      "          -2.1549e-01, -1.2115e-01,  1.4365e-01,  6.9907e-02,  2.5690e-01,\n",
      "          -3.9738e-02,  1.1225e-01, -9.5502e-02,  4.7572e-02,  2.9647e-01,\n",
      "          -6.6987e-02, -1.0939e-01, -2.0651e-01, -1.9409e-01, -5.8713e-02,\n",
      "           2.7074e-01, -2.0874e-02, -1.2347e-01,  1.9928e-01,  1.8709e-01,\n",
      "          -2.2325e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2550,  0.7781, -1.6520, -0.1827, -0.7320,  2.5181, -1.9080,\n",
      "          -0.0326,  0.9502,  1.1945,  0.0000, -0.7568, -0.0649,  0.0644,\n",
      "           1.0464,  0.0000,  0.8702,  0.0000, -0.6404, -1.4035, -0.4983,\n",
      "          -0.3790,  1.1427,  0.2329,  0.1892, -0.6133,  1.4041, -0.1510,\n",
      "          -1.0411,  0.4960,  0.0000,  0.6008, -1.6987,  0.2319, -0.0795,\n",
      "           0.1481,  0.6452, -2.2133,  1.0516,  0.1025, -0.6923, -0.4369,\n",
      "          -1.0645,  0.8180, -0.6329,  0.0000,  1.3725,  0.9367,  1.6037,\n",
      "           0.3694, -1.0084, -1.1718, -1.1122,  1.2529, -1.9746,  1.7089,\n",
      "           0.5930, -1.8920,  0.3411, -0.2937, -0.7705,  0.0000, -0.5943,\n",
      "          -1.6815, -0.8355,  1.2343, -0.3577,  0.2896,  0.0000,  0.0000,\n",
      "           2.2476,  0.7809,  0.2705,  1.2052, -0.3978,  0.3547,  0.2292,\n",
      "          -0.1575, -0.9147,  0.2960, -0.1448,  1.2865,  0.4651,  1.2969,\n",
      "           0.7706,  0.6605,  1.0451,  0.0000, -1.2410, -1.4364,  1.3108,\n",
      "          -1.5852,  0.0000,  3.2389,  0.3468,  1.0036, -0.8685,  0.7312,\n",
      "          -1.6816, -0.9243,  0.1904,  0.0286, -0.5964,  1.0585, -0.2309,\n",
      "           0.7757, -0.9057, -0.3676, -0.2786, -0.5475,  0.0000, -3.2779,\n",
      "          -0.1008, -1.8785,  1.6980,  1.6884,  0.0000,  0.0000, -0.8959,\n",
      "           2.5846, -1.3266,  1.4236, -0.6274,  0.4668,  0.0000, -0.9874,\n",
      "           0.0000, -0.9857, -0.6750,  0.2478, -1.2005,  1.1297,  1.1405,\n",
      "           1.4884,  0.3789,  0.6467, -0.8378,  0.2411,  0.3448, -1.2616,\n",
      "           0.0302,  0.8641,  0.5015,  0.9072, -1.2678, -0.6409, -0.4418,\n",
      "           0.8729, -0.0678,  0.0424, -0.0565,  0.6208,  0.1451, -0.1964,\n",
      "           0.1076, -1.6721, -0.4023,  0.2511, -2.0697,  0.4118,  1.1553,\n",
      "           0.1996,  0.0000,  0.8436,  0.4173,  1.6036,  0.1770, -1.1140,\n",
      "          -0.3226,  0.2508,  0.4452, -0.4552,  0.4445, -1.3453,  1.7358,\n",
      "           0.5175,  1.1773,  0.2896, -1.8321, -1.8660,  0.2593, -0.6474,\n",
      "          -1.1657,  0.3287, -0.7439,  0.5919, -1.2416, -1.5176, -2.3037,\n",
      "           0.1464, -1.6243, -1.3211, -0.0501,  1.2996,  0.9804, -1.4147,\n",
      "          -1.1404,  3.0134, -0.2259,  1.0325,  0.0294,  0.1188, -1.3198,\n",
      "          -1.0707,  0.0567,  1.7330,  0.5268,  1.9823, -0.9786, -1.3425,\n",
      "           1.5994,  0.0000,  2.4610, -0.5197,  0.7546,  0.2063, -0.8210,\n",
      "           0.9056, -3.5305,  0.1759, -0.7814, -0.6932, -1.4184,  0.2512,\n",
      "           0.0000, -1.4656,  0.4272, -0.5200,  0.0462, -0.6254, -0.0712,\n",
      "           0.0000, -2.0269, -1.0489, -0.4316, -0.1122,  0.5161, -2.7972,\n",
      "          -1.4577, -0.6645,  1.0258,  0.1326,  2.7512,  1.0026,  0.5471,\n",
      "          -0.1735, -1.5053,  2.2319,  1.1874, -0.0479,  0.7230,  0.1090,\n",
      "          -2.8554, -0.0138, -0.8377, -0.5804]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0423, 0.1532, 0.1026, 0.1125, 0.1283, 0.1222, 0.0722, 0.1116, 0.0890,\n",
      "         0.0662]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1145,  0.1364, -0.0832,  0.0132, -0.1818, -0.0568, -0.1632,\n",
      "           0.0052,  0.1155,  0.0886, -0.0425,  0.0009,  0.0345,  0.0299,\n",
      "           0.0546,  0.2182,  0.0286,  0.2612, -0.2428,  0.2129, -0.3219,\n",
      "          -0.1163, -0.0231,  0.0836, -0.2003, -0.0869,  0.0449, -0.0990,\n",
      "          -0.2622, -0.0949,  0.0573,  0.0415,  0.0357, -0.1247,  0.0859,\n",
      "          -0.2327, -0.0765, -0.0269, -0.0839, -0.0440,  0.0734, -0.1029,\n",
      "           0.0900,  0.0085,  0.2372, -0.0611,  0.2502, -0.0320,  0.2294,\n",
      "           0.0113, -0.2255, -0.0079, -0.1381, -0.0036, -0.2100,  0.0978,\n",
      "           0.1164,  0.1582, -0.1166,  0.2680,  0.0045, -0.1904, -0.0565,\n",
      "           0.2283, -0.0736,  0.0677, -0.1054, -0.1430, -0.1170, -0.1350,\n",
      "           0.2760,  0.1842, -0.1516,  0.1304, -0.0207, -0.0120,  0.0270,\n",
      "           0.0020,  0.0129,  0.0054, -0.1755, -0.0079, -0.0800,  0.1310,\n",
      "           0.0345,  0.0544, -0.0256,  0.0529,  0.0187, -0.0200,  0.0652,\n",
      "           0.1545, -0.0157, -0.0866,  0.1826,  0.2654,  0.0521,  0.3095,\n",
      "          -0.1028, -0.0990,  0.0128,  0.0418,  0.3409,  0.0743, -0.0755,\n",
      "          -0.0774, -0.0361, -0.1833,  0.0589,  0.0242,  0.1590,  0.0237,\n",
      "          -0.0486,  0.0293,  0.0998, -0.0445,  0.1517, -0.1615, -0.0498,\n",
      "          -0.0180,  0.1895,  0.0331, -0.0655,  0.0368, -0.0847, -0.0507,\n",
      "          -0.1394, -0.0881,  0.2867,  0.0526,  0.0076, -0.1478,  0.2381,\n",
      "           0.0817,  0.0627,  0.0164,  0.2308,  0.0964,  0.0934,  0.0553,\n",
      "           0.0906,  0.3543, -0.4296,  0.3905, -0.0915,  0.0141,  0.1688,\n",
      "           0.3074,  0.0146,  0.1123, -0.4162, -0.0493,  0.1509,  0.2331,\n",
      "          -0.2010,  0.3271,  0.2000,  0.1840,  0.0347,  0.1306, -0.0167,\n",
      "          -0.0917, -0.2919,  0.0351, -0.1074, -0.0019, -0.1737,  0.1356,\n",
      "           0.0084,  0.2237, -0.1754,  0.0642, -0.0120,  0.1160,  0.1190,\n",
      "           0.0282,  0.0090,  0.0456,  0.2674, -0.1077, -0.0730, -0.2061,\n",
      "          -0.0835, -0.0579,  0.2187, -0.1389, -0.1459, -0.0842,  0.0759,\n",
      "          -0.1338, -0.0448, -0.0587, -0.1849, -0.0612,  0.1167,  0.1632,\n",
      "           0.0535,  0.1764,  0.0590,  0.1163,  0.0104, -0.0024,  0.0510,\n",
      "           0.1924, -0.0061, -0.1022,  0.0212,  0.1672, -0.1091,  0.0655,\n",
      "           0.2136,  0.0786, -0.0730,  0.2182, -0.0639, -0.0347,  0.0682,\n",
      "           0.2834, -0.1581,  0.0915,  0.3139, -0.2516,  0.3087, -0.2083,\n",
      "          -0.2843,  0.1934,  0.3447, -0.2369, -0.2461,  0.0682, -0.1234,\n",
      "          -0.2251, -0.1454, -0.0267,  0.0563, -0.1950, -0.1799,  0.1029,\n",
      "           0.0610,  0.2352, -0.0343,  0.0432, -0.1626,  0.0896,  0.2784,\n",
      "          -0.0598, -0.1312, -0.2423, -0.1315, -0.0550,  0.2331, -0.0242,\n",
      "          -0.1422,  0.1455,  0.1835, -0.1706]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.5704e+00, -1.4752e+00,  2.2746e-01, -7.8436e-02,  3.5254e-01,\n",
      "           5.5340e-01,  0.0000e+00,  2.0888e+00,  1.3116e+00,  0.0000e+00,\n",
      "           6.8469e-01,  2.1685e+00,  0.0000e+00, -8.0512e-01, -1.0883e-01,\n",
      "          -1.1278e+00,  1.9605e+00, -2.9147e-01,  8.4115e-03,  4.2646e-01,\n",
      "          -1.9754e+00, -1.8382e+00, -1.2585e+00,  1.9423e-01, -1.6700e-01,\n",
      "           1.3755e+00, -2.9787e-01, -9.7442e-01,  1.8409e+00,  7.8349e-01,\n",
      "           3.4928e-01,  3.1145e-01,  5.3688e-01,  9.4180e-01,  6.9765e-01,\n",
      "           4.5389e-01, -2.8989e+00,  6.7998e-02,  3.9920e-02,  1.2313e+00,\n",
      "          -7.2215e-01, -1.0136e+00,  0.0000e+00,  1.0038e+00,  6.7183e-02,\n",
      "           3.1147e-01, -1.0373e+00, -1.1821e+00, -4.4469e-01,  0.0000e+00,\n",
      "          -1.5657e+00,  3.1698e+00,  8.6338e-01,  7.6404e-01,  2.2065e+00,\n",
      "           5.5893e-01,  5.9276e-01,  5.6774e-01, -7.5506e-01,  4.1323e-01,\n",
      "           6.2638e-01, -7.1967e-01, -3.6506e-01,  8.9458e-01, -1.3380e+00,\n",
      "           2.3298e+00, -2.4168e+00,  9.1989e-02,  1.1606e+00, -7.1803e-01,\n",
      "           7.5247e-02,  5.5113e-01,  1.8987e-01,  2.3368e-02,  4.0861e-01,\n",
      "          -9.0040e-01, -4.8585e-01,  4.3272e-01, -1.3788e+00, -2.4957e+00,\n",
      "          -3.6231e+00,  4.0188e-01,  4.9728e-01, -3.8159e-01, -2.3205e+00,\n",
      "          -1.0349e+00, -6.3280e-01,  1.8183e+00, -1.9084e+00,  0.0000e+00,\n",
      "          -4.3657e-01, -6.6932e-01, -1.9175e+00,  1.0182e+00, -1.3665e+00,\n",
      "          -1.1212e+00,  2.1708e-01,  1.8002e-02,  3.0413e-01,  7.6358e-01,\n",
      "           9.4163e-01,  9.3360e-01,  2.2447e-01, -1.6316e+00,  2.2439e+00,\n",
      "           0.0000e+00,  1.2455e-01, -1.0129e+00, -1.2049e+00, -1.4856e+00,\n",
      "          -1.5565e+00, -1.3435e+00,  1.5159e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.0659e+00, -1.7874e+00, -1.2137e-01, -1.8688e+00,  9.3987e-02,\n",
      "           6.7224e-01,  5.5176e-01,  1.5532e+00,  4.8417e-01,  1.2917e-01,\n",
      "           5.8234e-01,  7.9527e-01,  5.8590e-02,  3.9305e-01, -5.9642e-02,\n",
      "           0.0000e+00,  0.0000e+00,  7.0352e-01,  1.1586e+00,  3.2930e-01,\n",
      "          -2.5075e-01,  1.1914e-01, -1.3305e+00, -3.6584e-01, -7.7341e-01,\n",
      "          -5.9695e-01, -1.4721e+00, -1.1960e+00,  2.9718e-02,  5.0125e-01,\n",
      "           2.5941e-01,  1.2103e+00,  1.2555e+00,  6.3323e-01,  0.0000e+00,\n",
      "           7.8764e-02, -5.5324e-02,  0.0000e+00,  1.5831e+00,  1.2670e+00,\n",
      "           2.7992e-01,  1.1349e+00,  3.0530e-01,  2.6071e-01,  1.4422e+00,\n",
      "          -1.7481e-01,  6.8405e-01, -2.1216e-01, -7.2107e-01, -4.6786e-01,\n",
      "          -9.4136e-01,  3.2956e-01,  2.5667e-01,  1.7294e+00,  7.0251e-01,\n",
      "           0.0000e+00,  2.0556e+00,  5.6335e-01,  1.0313e-01, -3.9323e-01,\n",
      "          -9.6629e-01, -4.0494e-01,  1.1921e+00, -2.6504e-01, -1.5079e+00,\n",
      "          -1.3481e-01, -1.2911e-02, -6.0211e-01,  0.0000e+00, -1.8515e+00,\n",
      "          -1.6862e-01,  6.9106e-03,  0.0000e+00,  1.2953e+00,  7.3879e-01,\n",
      "           9.6783e-01,  1.6018e-01, -5.3609e-01,  5.3556e-01, -4.7197e-02,\n",
      "          -1.2979e+00, -1.5639e+00,  3.1396e+00,  0.0000e+00, -4.6066e-02,\n",
      "           0.0000e+00, -2.1875e+00, -2.6966e+00,  1.4470e+00, -9.9693e-01,\n",
      "           9.7214e-01, -1.6693e+00,  0.0000e+00, -9.3253e-01, -1.1371e+00,\n",
      "           8.7218e-01,  7.9507e-02, -1.3189e+00,  0.0000e+00,  0.0000e+00,\n",
      "          -2.8302e-01,  1.3733e+00,  0.0000e+00, -2.3518e+00,  1.9030e+00,\n",
      "           0.0000e+00, -1.4199e+00,  1.7824e+00,  1.0654e+00, -5.7285e-01,\n",
      "          -5.7365e-01, -1.5897e+00,  1.5897e-03, -3.3776e-01, -2.9543e+00,\n",
      "          -6.4335e-01,  1.5654e+00,  9.3442e-02, -6.2735e-01,  0.0000e+00,\n",
      "           2.2889e+00, -2.1839e+00,  3.2576e-01,  1.5122e+00, -5.3520e-01,\n",
      "          -1.8332e+00, -1.1667e+00, -1.1120e-01,  1.4429e+00, -4.7745e-01,\n",
      "           1.4839e+00, -5.8515e-01,  7.7596e-01, -1.4379e+00, -2.5949e-01,\n",
      "           4.3560e-01,  0.0000e+00, -3.3686e-01,  1.6172e+00,  2.5957e-01,\n",
      "          -7.0423e-02]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0392, 0.1846, 0.0509, 0.0695, 0.2338, 0.1123, 0.0795, 0.0800, 0.0651,\n",
      "         0.0852]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5003e-02,  5.9409e-02, -1.3777e-01,  3.0629e-02, -1.8809e-01,\n",
      "          -2.7104e-02, -1.9923e-01, -5.6145e-03,  1.3265e-01,  1.0119e-01,\n",
      "          -6.5012e-02,  7.5353e-03,  1.5106e-02,  6.1417e-02,  2.4368e-02,\n",
      "           2.7811e-01,  1.3604e-02,  2.7789e-01, -2.0521e-01,  2.2490e-01,\n",
      "          -3.4519e-01, -7.0511e-02, -1.8289e-02,  9.6350e-02, -1.7236e-01,\n",
      "          -5.6048e-02,  5.3944e-02, -1.3507e-01, -2.4341e-01, -9.2091e-02,\n",
      "           5.0554e-02,  9.0602e-02,  4.6204e-02, -1.0094e-01,  1.1824e-01,\n",
      "          -2.6625e-01, -5.8176e-02,  1.1175e-02, -7.5469e-02, -6.2772e-02,\n",
      "           7.2074e-02, -6.2308e-02,  1.2866e-01, -3.0358e-02,  2.3445e-01,\n",
      "          -8.9428e-02,  2.8309e-01, -1.5430e-02,  2.4339e-01, -6.4912e-03,\n",
      "          -2.6312e-01,  4.9610e-04, -1.3779e-01, -6.0612e-02, -2.5310e-01,\n",
      "           1.2133e-01,  1.0949e-01,  1.3571e-01, -1.4408e-01,  2.6960e-01,\n",
      "          -2.4970e-02, -2.2829e-01, -3.2370e-02,  2.2411e-01, -3.9508e-02,\n",
      "           1.0042e-01, -1.2017e-01, -1.9512e-01, -9.2117e-02, -1.8143e-01,\n",
      "           3.1754e-01,  1.7995e-01, -1.2651e-01,  1.0463e-01,  1.6276e-03,\n",
      "          -3.5887e-02,  6.7975e-02,  3.1966e-02,  2.6158e-02, -1.6875e-02,\n",
      "          -1.9652e-01,  1.6810e-02, -5.8683e-02,  1.1887e-01,  6.2079e-02,\n",
      "           8.8223e-03, -2.4061e-02,  3.1919e-02,  1.4860e-02, -1.8124e-02,\n",
      "           8.9897e-02,  1.5393e-01, -3.6209e-02, -1.0451e-01,  1.9602e-01,\n",
      "           2.9112e-01,  1.9546e-02,  2.9482e-01, -2.3769e-02, -1.1269e-01,\n",
      "           1.7802e-02,  8.0831e-02,  3.6956e-01,  8.5175e-02, -5.4297e-02,\n",
      "          -1.0856e-01, -4.2111e-02, -2.0774e-01,  3.7615e-02, -2.0722e-02,\n",
      "           1.3888e-01,  2.2375e-02, -2.5633e-02,  7.7051e-02,  1.3631e-01,\n",
      "          -5.4004e-02,  1.1687e-01, -1.8323e-01, -8.3712e-03,  6.0428e-03,\n",
      "           2.0127e-01,  7.7942e-02, -5.2701e-02,  3.9905e-02, -7.2746e-02,\n",
      "          -6.6561e-02, -1.5091e-01, -1.7104e-01,  2.9773e-01,  5.3183e-02,\n",
      "          -9.7260e-03, -1.2770e-01,  2.2807e-01,  8.4759e-02,  4.9525e-02,\n",
      "           6.4284e-02,  2.5130e-01,  1.0012e-01,  1.1067e-01,  7.2895e-02,\n",
      "           1.3322e-01,  3.4560e-01, -4.5665e-01,  3.9835e-01, -6.8625e-02,\n",
      "           8.1664e-03,  2.0115e-01,  3.6037e-01, -2.5158e-02,  8.6901e-02,\n",
      "          -4.1677e-01, -1.2665e-02,  1.1295e-01,  2.4414e-01, -1.8734e-01,\n",
      "           3.4880e-01,  2.4132e-01,  1.9136e-01,  5.6869e-02,  1.6599e-01,\n",
      "          -6.2951e-02, -9.0527e-02, -3.0434e-01, -2.4051e-02, -1.4814e-01,\n",
      "          -2.9600e-02, -2.2966e-01,  1.3343e-01, -4.6045e-03,  2.0470e-01,\n",
      "          -1.7094e-01,  1.2817e-01,  2.2991e-04,  7.1992e-02,  1.5148e-01,\n",
      "           6.6339e-02,  2.4936e-02,  2.7410e-03,  2.7679e-01, -1.0622e-01,\n",
      "          -5.3755e-02, -1.6403e-01, -9.4258e-02, -2.3476e-02,  2.2955e-01,\n",
      "          -1.8625e-01, -1.3991e-01, -9.8190e-02,  4.6965e-02, -1.4143e-01,\n",
      "          -6.6761e-02, -7.9941e-02, -1.4142e-01, -7.5547e-02,  1.0366e-01,\n",
      "           2.0532e-01,  8.5135e-02,  1.2997e-01,  5.6802e-02,  9.1926e-02,\n",
      "           3.9202e-02, -7.9516e-02,  5.0486e-02,  2.0630e-01, -1.5074e-02,\n",
      "          -7.1571e-02,  5.2907e-02,  1.5490e-01, -9.8106e-02,  4.9112e-02,\n",
      "           2.4748e-01,  1.1252e-01, -6.3616e-02,  2.3640e-01, -4.7452e-02,\n",
      "          -1.0872e-01,  1.0653e-01,  2.7833e-01, -1.5150e-01,  5.6948e-02,\n",
      "           3.3056e-01, -2.6255e-01,  3.1197e-01, -1.9115e-01, -3.1614e-01,\n",
      "           1.9686e-01,  3.3550e-01, -2.1736e-01, -2.6114e-01,  3.9891e-02,\n",
      "          -1.1808e-01, -2.5514e-01, -1.0386e-01, -1.8017e-02,  8.4931e-02,\n",
      "          -2.0881e-01, -1.4536e-01,  9.5549e-02,  9.2856e-02,  2.5102e-01,\n",
      "          -1.4697e-02,  9.5816e-02, -1.3458e-01,  7.2920e-02,  2.8715e-01,\n",
      "          -5.8418e-02, -1.0501e-01, -2.1596e-01, -1.8782e-01, -6.3073e-02,\n",
      "           2.6360e-01, -1.0708e-02, -1.3947e-01,  1.4033e-01,  1.6475e-01,\n",
      "          -2.1761e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-5.5611e-01, -6.6752e-01,  4.4818e-01, -1.9026e+00,  0.0000e+00,\n",
      "           9.8108e-01,  0.0000e+00, -5.3028e-01,  5.9522e-01, -4.8397e-01,\n",
      "           1.8334e-01,  1.3000e+00, -1.9740e+00,  1.3462e-01, -1.4681e+00,\n",
      "          -9.6074e-02, -1.1776e+00, -2.0437e+00,  3.1264e-02,  0.0000e+00,\n",
      "          -1.9192e+00,  0.0000e+00, -4.0017e-01,  8.7084e-01, -2.4260e+00,\n",
      "           4.7924e-01, -1.0928e+00,  4.5599e-03, -6.0921e-02, -1.9770e+00,\n",
      "           1.2934e+00,  9.6530e-01,  1.1068e+00,  8.6878e-01,  1.9314e+00,\n",
      "          -1.2653e+00, -1.9603e+00,  1.0075e-01, -1.0475e+00, -1.4165e-01,\n",
      "           4.5773e-01, -1.0746e+00,  9.1594e-01, -1.9289e+00, -9.1780e-01,\n",
      "          -9.7690e-02,  3.6578e-01,  0.0000e+00,  0.0000e+00, -1.5497e-01,\n",
      "          -1.2826e-01,  1.3126e+00,  3.8007e-01, -3.5300e-01,  1.7833e-01,\n",
      "          -6.4426e-01, -1.2124e+00, -9.2775e-01, -4.0082e-02,  0.0000e+00,\n",
      "          -7.6674e-01,  5.1544e-01,  8.2053e-01, -1.7466e+00, -6.7489e-01,\n",
      "          -1.0796e+00, -1.7057e+00,  1.1719e+00,  1.0845e+00, -8.1963e-03,\n",
      "           0.0000e+00, -6.6916e-01, -8.9701e-01, -1.3921e+00,  2.7432e+00,\n",
      "           5.4320e-03, -8.6971e-01, -1.2628e+00,  7.0899e-01,  1.0475e+00,\n",
      "           2.7294e-01, -1.7427e+00, -9.6493e-01, -9.8261e-01,  0.0000e+00,\n",
      "           4.7694e-01, -4.7976e-01,  9.0051e-01,  0.0000e+00, -1.7185e+00,\n",
      "          -5.8389e-01,  1.0274e+00,  0.0000e+00,  0.0000e+00,  1.7447e+00,\n",
      "          -7.7824e-01, -2.4245e-01,  1.4734e+00,  2.2941e+00,  2.3303e-01,\n",
      "          -2.3903e-02, -7.8883e-01, -5.0481e-01, -4.5008e-01,  0.0000e+00,\n",
      "          -9.7676e-01, -3.5789e-03, -1.9308e+00,  7.4881e-01, -1.8669e-01,\n",
      "           1.0570e+00, -2.0601e+00,  0.0000e+00,  0.0000e+00,  1.1431e+00,\n",
      "           2.0674e-01, -4.1656e-01,  2.8918e-01,  1.9441e+00, -3.5156e-01,\n",
      "           1.1845e+00,  2.2724e+00, -5.5385e-01,  5.4050e-01, -2.3775e+00,\n",
      "           0.0000e+00,  0.0000e+00,  1.1536e+00,  0.0000e+00, -4.1053e-01,\n",
      "          -1.1762e+00, -1.4003e-01,  2.1895e+00,  5.1645e-01,  1.6347e+00,\n",
      "          -1.1627e+00, -1.1915e+00,  0.0000e+00,  1.0924e+00,  0.0000e+00,\n",
      "          -4.8415e-01,  1.1301e+00, -1.5268e+00, -9.5817e-01, -3.0561e-01,\n",
      "           1.6800e+00,  0.0000e+00, -1.1175e+00,  6.8176e-01, -9.2911e-01,\n",
      "           0.0000e+00,  0.0000e+00,  4.9822e-01, -4.1028e-01,  9.8518e-01,\n",
      "          -6.6107e-01,  1.6734e+00,  1.2684e-01, -1.4359e+00,  1.5271e-01,\n",
      "          -9.7561e-01, -1.2523e+00, -8.7781e-01,  1.6578e+00,  0.0000e+00,\n",
      "           2.2842e-01,  0.0000e+00,  3.0126e+00, -1.0333e+00,  1.0488e+00,\n",
      "           8.1311e-01,  9.4077e-01, -5.5875e-01,  9.0235e-01,  6.9359e-01,\n",
      "          -6.5139e-01,  1.7731e+00,  7.3679e-01, -3.6251e+00,  1.7553e+00,\n",
      "           1.0286e+00, -9.4568e-01,  1.1828e-04,  5.3377e-01,  5.5779e-02,\n",
      "          -1.2997e+00, -4.2029e-01,  2.5009e-01, -1.0185e+00,  7.9631e-02,\n",
      "           0.0000e+00, -5.3271e-01,  0.0000e+00,  1.6365e+00, -2.4513e+00,\n",
      "           2.3028e-02, -9.4407e-01,  0.0000e+00,  1.1158e+00,  0.0000e+00,\n",
      "           8.1822e-01, -6.6406e-02,  7.3093e-01,  0.0000e+00,  1.3948e+00,\n",
      "          -1.3905e-01,  2.2679e+00,  9.2240e-01,  3.8146e-02,  0.0000e+00,\n",
      "           2.5442e-01, -5.6717e-01,  1.1324e+00, -4.4971e-01,  7.2171e-01,\n",
      "           5.2385e-01,  8.7760e-01,  3.2780e-01, -5.4252e-01, -5.6256e-01,\n",
      "          -6.5432e-01, -3.8955e-01, -1.3929e+00, -7.1590e-01,  2.2039e-01,\n",
      "           8.2061e-02,  8.5506e-01, -3.9080e-01,  0.0000e+00, -1.2445e-01,\n",
      "           1.6866e+00,  8.8743e-01,  1.0443e-01,  1.2080e+00,  1.9215e+00,\n",
      "          -2.1418e-01, -1.2407e+00,  1.1500e+00,  1.3855e+00,  0.0000e+00,\n",
      "           2.0031e+00, -2.3015e+00, -1.1122e+00,  7.1836e-01, -2.5683e-01,\n",
      "           3.7202e-01, -1.4434e-02, -4.5996e-01,  5.2446e-01,  0.0000e+00,\n",
      "          -6.5143e-01,  1.0557e+00,  0.0000e+00,  6.1670e-01, -1.2299e+00,\n",
      "          -1.6374e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0699, 0.0808, 0.1626, 0.0468, 0.0567, 0.1690, 0.0880, 0.1572, 0.0706,\n",
      "         0.0984]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.8768e-01,  1.8799e-01, -8.6072e-02, -1.8243e-03, -2.1501e-01,\n",
      "          -8.5379e-02, -1.2085e-01, -1.1790e-02,  6.0879e-02,  4.0744e-02,\n",
      "           1.0218e-03, -5.9918e-02,  1.2974e-02, -1.3762e-02,  5.5468e-02,\n",
      "           1.4420e-01,  3.1338e-02,  2.8798e-01, -2.4806e-01,  2.2063e-01,\n",
      "          -2.8377e-01, -1.5548e-01,  3.5177e-04,  1.2586e-01, -2.0360e-01,\n",
      "          -5.4420e-02,  3.4305e-02, -1.2008e-01, -2.9924e-01, -1.0222e-01,\n",
      "           9.6592e-02, -3.9834e-02, -4.0058e-03, -1.9201e-01,  1.0660e-01,\n",
      "          -2.1490e-01, -9.6054e-02, -2.1284e-02, -8.3509e-02, -1.2692e-02,\n",
      "           4.9133e-02, -1.0003e-01,  1.6351e-02,  5.1131e-02,  2.3052e-01,\n",
      "          -2.0539e-02,  1.6956e-01, -1.0070e-01,  2.1754e-01,  1.9847e-02,\n",
      "          -2.3682e-01, -2.6873e-03, -2.1364e-01,  4.9596e-02, -1.8140e-01,\n",
      "           7.9982e-02,  1.0637e-01,  1.9105e-01, -7.9479e-02,  2.5425e-01,\n",
      "          -6.9813e-03, -1.5517e-01, -1.1718e-01,  2.5625e-01, -9.0713e-02,\n",
      "           2.0548e-02, -1.2372e-01, -8.5926e-02, -1.4110e-01, -7.8276e-02,\n",
      "           2.3297e-01,  1.9074e-01, -1.1291e-01,  1.2987e-01, -5.9946e-02,\n",
      "           2.5522e-02,  4.1393e-02,  2.7410e-02,  2.6280e-02,  6.4440e-02,\n",
      "          -1.4981e-01, -3.2787e-02, -1.4740e-01,  1.4646e-01, -3.3141e-04,\n",
      "           1.0424e-01, -2.3979e-02,  3.5255e-02,  8.4544e-02, -7.3665e-02,\n",
      "           7.6808e-02,  1.7881e-01,  2.2507e-04, -8.9358e-02,  1.5396e-01,\n",
      "           2.5399e-01,  8.9359e-02,  3.2970e-01, -1.0999e-01, -4.1132e-02,\n",
      "           1.6713e-03,  4.9807e-02,  3.0218e-01,  8.4702e-02, -9.6788e-02,\n",
      "          -1.0224e-01, -6.0607e-02, -1.0372e-01,  5.3144e-02,  7.8154e-02,\n",
      "           1.9730e-01,  6.8103e-02, -5.8785e-02, -9.9287e-02,  3.5553e-02,\n",
      "          -6.5984e-03,  1.5375e-01, -1.1483e-01, -1.3225e-01, -3.3321e-02,\n",
      "           1.7789e-01, -3.5977e-03, -8.7598e-02,  3.8414e-02, -7.8876e-02,\n",
      "          -5.8384e-02, -1.9235e-01, -1.0200e-01,  2.5052e-01,  7.5955e-03,\n",
      "           2.4874e-02, -1.6996e-01,  2.7704e-01,  1.1742e-01,  1.0647e-01,\n",
      "           4.8635e-02,  2.0688e-01,  1.1907e-01,  4.1792e-02,  4.3270e-02,\n",
      "           2.5734e-02,  3.3542e-01, -4.8621e-01,  3.5839e-01, -1.0246e-01,\n",
      "           3.7015e-02,  1.1636e-01,  3.0266e-01,  4.4124e-02,  1.8046e-01,\n",
      "          -4.3197e-01, -4.6005e-02,  1.7127e-01,  2.1996e-01, -1.3921e-01,\n",
      "           3.2557e-01,  1.6982e-01,  1.9988e-01,  5.5970e-03,  1.9484e-02,\n",
      "          -6.3450e-03, -1.5533e-01, -3.0702e-01,  9.9469e-02, -7.7480e-02,\n",
      "           6.8232e-02, -1.4027e-01,  1.6735e-01,  5.3758e-02,  2.2682e-01,\n",
      "          -2.4634e-01,  2.5995e-02,  7.0700e-02,  1.1511e-01,  6.7194e-02,\n",
      "          -3.3880e-03,  9.6804e-03,  6.0994e-02,  2.9702e-01, -7.7560e-02,\n",
      "          -8.1167e-02, -2.2640e-01, -6.2049e-02, -8.2267e-02,  2.5300e-01,\n",
      "          -9.7555e-02, -1.9419e-01, -5.3635e-02,  7.6140e-02, -1.1001e-01,\n",
      "          -8.2458e-02, -4.1225e-02, -2.1735e-01, -9.3295e-02,  9.4007e-02,\n",
      "           7.0783e-02, -2.2043e-02,  1.9515e-01,  6.1719e-02,  1.4891e-01,\n",
      "           1.4139e-02,  8.8252e-02,  6.7236e-02,  2.3188e-01, -3.4870e-02,\n",
      "          -1.1974e-01, -2.0396e-02,  2.0176e-01, -9.3661e-02,  5.7137e-02,\n",
      "           2.0889e-01,  2.9041e-02, -8.0168e-02,  2.6414e-01, -9.6219e-02,\n",
      "           2.3491e-02,  1.3034e-02,  2.9564e-01, -1.5118e-01,  8.8522e-02,\n",
      "           3.1332e-01, -2.6662e-01,  2.8981e-01, -2.0287e-01, -2.1687e-01,\n",
      "           1.9516e-01,  3.5566e-01, -2.4686e-01, -2.2799e-01,  9.6907e-02,\n",
      "          -1.0665e-01, -2.4841e-01, -2.0672e-01, -2.7524e-02,  4.3344e-02,\n",
      "          -1.9438e-01, -2.1147e-01,  1.3993e-01,  1.0321e-01,  2.0972e-01,\n",
      "          -8.3069e-02, -3.3641e-02, -1.4575e-01,  9.7163e-02,  2.7693e-01,\n",
      "          -6.4547e-02, -1.5768e-01, -2.7164e-01, -6.7003e-02, -3.2755e-02,\n",
      "           2.5207e-01, -1.9298e-02, -1.5887e-01,  1.1285e-01,  1.9990e-01,\n",
      "          -1.6261e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 3.9127e-01, -1.3354e+00,  2.1101e-01, -2.2618e+00,  6.8938e-04,\n",
      "          -1.7007e+00, -8.2230e-01, -3.5067e-01,  3.1387e-01, -3.1734e-01,\n",
      "          -5.1623e-01, -1.1943e+00,  0.0000e+00,  6.3676e-01, -1.0269e+00,\n",
      "           3.4041e-02,  2.2510e+00,  0.0000e+00, -3.4947e-01, -2.1469e+00,\n",
      "          -8.9398e-02,  4.3755e-01,  1.5177e-01, -6.3555e-02,  6.1425e-01,\n",
      "          -8.8230e-01, -6.4892e-01, -7.3373e-01,  9.6870e-01,  3.6049e-01,\n",
      "          -1.2032e+00, -1.6627e+00, -4.8444e-01,  1.0810e+00,  2.7625e-01,\n",
      "           1.1333e-01,  7.0574e-02, -6.6598e-01, -1.2916e+00, -6.1789e-01,\n",
      "          -8.8202e-01,  1.1468e+00, -3.5134e-01, -1.3347e+00, -9.4534e-01,\n",
      "          -5.9039e-01,  1.2608e-01,  1.0109e-01, -1.6833e+00, -3.3104e-01,\n",
      "           7.8905e-01, -5.4590e-01, -1.1098e+00,  2.6849e+00, -1.3920e+00,\n",
      "           1.3366e+00, -2.3902e-01, -4.5460e-01, -5.1377e-01,  0.0000e+00,\n",
      "           3.2387e-01,  5.7426e-01, -3.6223e-01,  2.0315e+00,  0.0000e+00,\n",
      "           1.1532e+00, -1.1816e+00, -6.0146e-01,  1.7067e+00, -1.2018e-01,\n",
      "          -1.9138e-01, -8.5855e-01,  3.7921e-02, -4.5710e-01, -7.3673e-01,\n",
      "           0.0000e+00, -2.1243e-01,  4.6162e-01, -1.1862e+00, -1.5067e-01,\n",
      "           5.7759e-01,  0.0000e+00,  8.9069e-01, -4.0327e-01, -3.5795e-01,\n",
      "           1.5703e+00,  8.1604e-01, -3.0959e-01, -4.1277e-01,  1.1865e+00,\n",
      "          -4.7687e-01,  2.3074e+00,  7.6899e-01, -1.4538e-02, -3.5859e-02,\n",
      "          -6.2499e-01,  0.0000e+00, -7.1168e-01, -3.7923e-01,  1.2894e+00,\n",
      "          -4.8411e-01,  0.0000e+00, -9.0990e-01,  2.9468e-01, -6.7464e-01,\n",
      "          -1.6351e+00, -9.7362e-01,  3.3128e-01, -2.2966e+00, -1.0294e+00,\n",
      "          -2.6872e-01,  9.2795e-01, -9.1699e-01,  8.7434e-01,  4.2045e-01,\n",
      "          -8.8498e-01, -1.0783e+00,  6.7065e-01,  7.2833e-01,  1.2682e+00,\n",
      "          -5.9004e-01, -1.1836e+00,  1.4784e+00,  0.0000e+00, -7.4196e-02,\n",
      "           6.9783e-01, -1.6769e+00, -2.9829e+00,  0.0000e+00, -5.9242e-01,\n",
      "           1.3421e-01, -6.6619e-01, -4.8746e-01, -2.3582e-01, -1.4568e+00,\n",
      "           5.9205e-01,  0.0000e+00,  0.0000e+00,  7.3946e-01, -4.4768e-01,\n",
      "          -1.3400e+00,  0.0000e+00, -2.3503e+00, -1.0212e+00, -5.1426e-01,\n",
      "           1.3420e+00,  6.0361e-01,  1.3350e+00, -1.8696e+00,  1.5140e+00,\n",
      "           5.2505e-01, -3.2018e-01,  9.3403e-01, -4.1034e-01, -2.4314e-01,\n",
      "           1.4547e-01,  8.9762e-01,  1.2121e+00, -6.1581e-01,  7.2379e-01,\n",
      "           8.0022e-02,  1.3867e+00,  6.2123e-01,  1.6514e+00, -7.3490e-01,\n",
      "           7.5354e-01,  0.0000e+00, -9.3740e-01,  4.5693e-01, -2.5354e-02,\n",
      "          -6.1645e-01,  5.2289e-01,  0.0000e+00, -7.8582e-01,  1.5513e+00,\n",
      "           0.0000e+00,  5.0683e-01, -1.3202e-01,  9.3660e-01,  1.4383e+00,\n",
      "          -3.3950e+00,  7.0413e-01,  1.7652e+00, -1.4552e+00,  6.3002e-01,\n",
      "          -3.9006e-02,  2.0233e+00,  1.0558e+00, -1.3489e+00, -1.2684e+00,\n",
      "           3.9557e-01,  0.0000e+00, -2.2390e-01, -7.6044e-01,  1.1300e+00,\n",
      "           3.9223e-01,  1.1399e-01,  6.0584e-01, -3.4487e-01, -9.0647e-01,\n",
      "           0.0000e+00, -4.3903e-01, -1.4187e+00, -5.7941e-02,  1.8545e+00,\n",
      "           0.0000e+00, -3.5659e-01,  0.0000e+00, -2.9118e-01,  7.7787e-01,\n",
      "          -9.2166e-01,  5.6638e-01, -8.5514e-02, -5.3830e-01,  4.9210e-01,\n",
      "           4.7625e-01, -1.1377e+00, -6.6268e-01,  0.0000e+00,  1.0407e+00,\n",
      "          -8.7499e-02, -6.5453e-01,  1.7758e+00,  7.0429e-01,  6.8838e-01,\n",
      "           0.0000e+00,  5.6091e-02, -1.0737e+00,  1.1689e+00, -5.7930e-01,\n",
      "          -6.1000e-01,  2.5956e-01,  8.1843e-01,  6.5341e-01,  3.9908e-01,\n",
      "          -1.1063e+00,  8.7324e-02, -1.7437e+00, -1.0924e+00, -3.6881e-01,\n",
      "          -8.4192e-01, -1.7034e-01,  4.1767e-01,  0.0000e+00, -1.1296e+00,\n",
      "           3.3947e+00, -1.9507e+00, -1.8441e+00, -4.7457e-01, -2.8951e-01,\n",
      "          -7.1094e-01, -7.4518e-02,  0.0000e+00, -9.2436e-01,  0.0000e+00,\n",
      "           2.7557e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0649, 0.0555, 0.1327, 0.1683, 0.1432, 0.1119, 0.0585, 0.0602, 0.1753,\n",
      "         0.0295]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.0925,  0.1003, -0.0254,  0.0097, -0.1270, -0.0006, -0.1483,\n",
      "           0.0657,  0.1209,  0.0952, -0.0760,  0.0009,  0.1180, -0.0398,\n",
      "          -0.0110,  0.1950,  0.0357,  0.2082, -0.2217,  0.2079, -0.2624,\n",
      "          -0.0828, -0.0932,  0.0065, -0.1751, -0.0487,  0.0709, -0.0520,\n",
      "          -0.2325, -0.0717,  0.0438,  0.0883,  0.0812, -0.0579,  0.0701,\n",
      "          -0.2472, -0.1072, -0.0057, -0.0398, -0.0522,  0.0791, -0.0880,\n",
      "           0.1401, -0.0092,  0.2451, -0.0892,  0.2915,  0.0191,  0.2200,\n",
      "          -0.0185, -0.2137, -0.0484, -0.0717, -0.0322, -0.2404,  0.0667,\n",
      "           0.1192,  0.1389, -0.1459,  0.2595,  0.0205, -0.1581, -0.0136,\n",
      "           0.1958, -0.0517,  0.0367, -0.0686, -0.1941, -0.0725, -0.1492,\n",
      "           0.2343,  0.1591, -0.1606,  0.0831, -0.0305, -0.0496, -0.0025,\n",
      "          -0.0409,  0.0388, -0.0159, -0.1431, -0.0052, -0.0006,  0.1425,\n",
      "           0.0282,  0.0862, -0.0248,  0.0447, -0.0307, -0.0014,  0.0130,\n",
      "           0.1650, -0.0034, -0.1046,  0.2078,  0.2359,  0.0467,  0.2592,\n",
      "          -0.0993, -0.1122,  0.0198, -0.0321,  0.3300,  0.0406, -0.0445,\n",
      "          -0.0992, -0.0842, -0.2352,  0.0906,  0.0263,  0.1150,  0.0380,\n",
      "          -0.0513,  0.0637,  0.1448, -0.0587,  0.1235, -0.1258, -0.0384,\n",
      "          -0.0118,  0.2313,  0.0859, -0.0302,  0.0646, -0.0906, -0.0634,\n",
      "          -0.1255, -0.0042,  0.3115,  0.0866,  0.0039, -0.1347,  0.2216,\n",
      "           0.0233,  0.0256, -0.0147,  0.1862,  0.0513,  0.1328, -0.0100,\n",
      "           0.1086,  0.3739, -0.3346,  0.3644, -0.1428,  0.0313,  0.1879,\n",
      "           0.2363, -0.0367,  0.1064, -0.3852, -0.0841,  0.1693,  0.2442,\n",
      "          -0.2299,  0.2570,  0.1817,  0.1873, -0.0028,  0.1912,  0.0238,\n",
      "          -0.0683, -0.2243, -0.0106, -0.0904, -0.0396, -0.1088,  0.1231,\n",
      "          -0.0776,  0.1866, -0.1362,  0.0131, -0.0492,  0.1711,  0.1173,\n",
      "           0.0134,  0.0039,  0.0015,  0.1713, -0.1267, -0.0386, -0.1025,\n",
      "          -0.0555, -0.0785,  0.1702, -0.1542, -0.1012, -0.0987,  0.0881,\n",
      "          -0.1189, -0.0316, -0.0733, -0.1217, -0.0133,  0.1112,  0.1887,\n",
      "           0.0559,  0.2113,  0.0572,  0.0813, -0.0041, -0.0010,  0.0703,\n",
      "           0.1580, -0.0071, -0.0715,  0.0026,  0.1532, -0.1188,  0.0716,\n",
      "           0.1954,  0.0605, -0.0857,  0.1441, -0.0742, -0.0781,  0.1237,\n",
      "           0.3182, -0.1231,  0.0195,  0.2714, -0.1987,  0.2750, -0.1639,\n",
      "          -0.3013,  0.1824,  0.3045, -0.2310, -0.1953,  0.0538, -0.1112,\n",
      "          -0.2341, -0.1450, -0.0182,  0.0360, -0.2241, -0.1698,  0.0968,\n",
      "           0.0323,  0.2398, -0.0179,  0.0397, -0.1670,  0.0610,  0.2937,\n",
      "          -0.0927, -0.1126, -0.2102, -0.1443, -0.0697,  0.1826, -0.0246,\n",
      "          -0.0518,  0.1806,  0.1827, -0.1487]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 5.5975e-02,  1.3966e+00,  0.0000e+00, -4.0587e-01,  6.8778e-01,\n",
      "           5.9976e-01, -1.4478e+00, -1.4727e+00, -1.0470e+00,  5.7973e-01,\n",
      "          -3.3636e-01, -6.9792e-01,  7.2707e-01,  1.4434e+00,  3.2541e-01,\n",
      "          -8.1960e-01, -9.1939e-01,  0.0000e+00, -1.2039e+00, -1.5433e+00,\n",
      "           1.0640e+00,  8.7411e-01, -6.9428e-01,  2.0892e+00, -2.6627e-01,\n",
      "          -8.5766e-01,  1.5226e+00,  1.3197e-01,  1.3219e+00,  0.0000e+00,\n",
      "          -1.9321e-01, -1.1082e+00, -3.4424e-01,  0.0000e+00,  7.6675e-01,\n",
      "           0.0000e+00, -1.3034e+00,  1.6983e-01,  1.4643e+00,  0.0000e+00,\n",
      "          -1.2390e+00, -4.0279e-01,  1.7996e+00,  1.2774e+00, -1.5144e+00,\n",
      "           5.7710e-01,  5.5615e-01,  2.6267e+00, -1.7988e+00, -1.0838e+00,\n",
      "          -7.2579e-01,  7.4326e-01, -2.6341e-01,  8.8137e-01,  0.0000e+00,\n",
      "           7.0569e-01, -1.0622e+00,  0.0000e+00, -2.2617e+00,  1.6991e-01,\n",
      "          -3.3866e-01, -1.7076e-01,  0.0000e+00,  3.4878e-02, -6.2743e-01,\n",
      "           1.0429e+00,  9.5760e-01, -7.5029e-01, -1.1188e+00,  0.0000e+00,\n",
      "          -2.4931e+00, -1.6847e+00, -4.5407e-01,  0.0000e+00,  2.8177e-01,\n",
      "          -5.7870e-01, -4.4445e-01,  5.6669e-01,  2.8707e-01,  5.3404e-01,\n",
      "          -3.0004e-01,  1.3547e+00,  5.1087e-01, -1.8841e+00,  0.0000e+00,\n",
      "           1.0877e+00,  3.5559e-01,  7.1571e-01,  1.5002e+00,  0.0000e+00,\n",
      "          -1.6661e-01, -1.2455e+00,  1.1947e+00, -4.4605e-02,  1.9481e+00,\n",
      "           0.0000e+00, -2.4649e-02, -7.2179e-01,  1.0623e+00,  1.9403e+00,\n",
      "           4.1532e-01,  1.6341e+00, -6.4934e-01, -6.9438e-01,  1.5575e-01,\n",
      "           1.0180e-01,  2.1365e+00, -5.1618e-01, -1.1827e+00,  0.0000e+00,\n",
      "          -1.7723e+00,  9.9156e-03, -2.6122e-01,  4.6621e-01,  5.9551e-01,\n",
      "          -3.8774e-01, -7.5741e-01,  0.0000e+00,  2.2529e-01,  0.0000e+00,\n",
      "           0.0000e+00, -3.8321e-01,  0.0000e+00,  2.3809e-01, -1.5541e+00,\n",
      "           5.7725e-01, -1.6094e+00, -5.1585e-01,  1.2111e+00, -1.2094e+00,\n",
      "           3.3105e-01,  1.3290e+00, -2.1866e-01,  1.4222e-01,  1.0296e+00,\n",
      "          -6.6791e-01,  2.3730e-01,  1.9317e+00,  4.4536e-01,  2.9481e-01,\n",
      "           5.5257e-01, -2.1605e+00, -3.9699e-01, -4.2131e-01,  3.9895e-01,\n",
      "          -5.0121e-01, -2.5877e+00,  0.0000e+00, -6.9365e-02, -5.3065e-01,\n",
      "           8.3814e-01, -9.9027e-01, -3.9267e-02, -2.5221e+00, -1.9587e-01,\n",
      "          -7.2383e-01,  1.2075e+00,  3.7673e-01, -1.3394e+00,  6.6330e-01,\n",
      "           0.0000e+00,  5.9569e-01,  4.8267e-01, -5.4047e-01, -1.2941e+00,\n",
      "           0.0000e+00,  1.3904e+00, -1.5662e+00, -5.0912e-02,  0.0000e+00,\n",
      "          -1.6646e+00,  4.1745e-01, -8.3182e-01, -1.1188e+00,  2.9810e-02,\n",
      "           0.0000e+00, -1.1318e+00, -1.1742e+00, -3.4875e-01,  0.0000e+00,\n",
      "           1.8413e+00, -4.2802e-01,  9.7539e-01, -1.2725e+00,  1.3405e+00,\n",
      "          -1.1678e-01, -9.4497e-02,  6.1286e-01, -1.3765e-01, -9.2785e-01,\n",
      "           1.3762e+00,  1.0346e+00, -1.0623e+00,  1.5563e+00,  7.3242e-01,\n",
      "          -2.0252e+00, -7.9519e-01, -5.8129e-01,  1.2862e+00,  1.2824e-01,\n",
      "          -4.2128e-01,  0.0000e+00,  9.0646e-01, -1.2269e+00,  0.0000e+00,\n",
      "           9.3443e-01,  1.4675e+00,  8.9708e-01, -4.2415e-01, -3.4106e-01,\n",
      "           4.4344e-04,  0.0000e+00, -7.5147e-02, -1.0059e+00, -1.8590e+00,\n",
      "           8.4098e-01,  4.4717e-01,  6.8112e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.2046e-02, -3.9617e-01,  1.0766e+00,  1.8438e+00,  1.1008e-01,\n",
      "          -1.5029e+00, -1.0160e+00, -2.8083e-01,  1.1909e+00, -2.6776e-01,\n",
      "           2.3237e-01,  4.8472e-01, -4.7441e-01,  5.0121e-01,  9.7821e-01,\n",
      "          -1.8399e+00, -3.7922e-02, -2.2156e+00,  2.2124e+00, -1.6620e+00,\n",
      "          -1.9081e+00,  0.0000e+00,  7.5065e-01, -1.5541e+00, -7.0500e-01,\n",
      "          -6.6985e-01, -1.3455e+00, -5.2711e-01,  1.4093e+00,  5.6607e-01,\n",
      "          -9.7651e-01,  0.0000e+00, -5.0478e-01, -7.3578e-01,  8.6529e-01,\n",
      "           6.5942e-01]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0733, 0.1161, 0.0964, 0.1352, 0.1179, 0.1492, 0.1306, 0.0536, 0.0873,\n",
      "         0.0402]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.1138,  0.1250, -0.0369,  0.0074, -0.1332,  0.0057, -0.2021,\n",
      "           0.0518,  0.0992,  0.0907, -0.0568,  0.0104,  0.0546,  0.0295,\n",
      "           0.0103,  0.2366,  0.0172,  0.2625, -0.2526,  0.2134, -0.2982,\n",
      "          -0.0740, -0.0410,  0.0527, -0.1623, -0.0329,  0.0834, -0.0937,\n",
      "          -0.2551, -0.0776,  0.0583,  0.0747,  0.0490, -0.1168,  0.0959,\n",
      "          -0.2598, -0.0964,  0.0017, -0.0508, -0.0489,  0.0603, -0.0714,\n",
      "           0.1090, -0.0010,  0.2277, -0.0751,  0.2682,  0.0069,  0.2350,\n",
      "           0.0065, -0.2276, -0.0382, -0.1264, -0.0116, -0.2325,  0.0983,\n",
      "           0.1252,  0.1604, -0.1339,  0.2450,  0.0119, -0.1784, -0.0451,\n",
      "           0.2525, -0.0618,  0.0390, -0.1135, -0.1712, -0.1201, -0.1168,\n",
      "           0.2920,  0.1895, -0.1496,  0.1055, -0.0253, -0.0034,  0.0285,\n",
      "          -0.0121,  0.0568, -0.0055, -0.1609,  0.0503, -0.0794,  0.1639,\n",
      "           0.0421,  0.0519, -0.0059,  0.0421,  0.0214,  0.0087,  0.0422,\n",
      "           0.1742, -0.0228, -0.1249,  0.1980,  0.2788,  0.0691,  0.2937,\n",
      "          -0.0700, -0.1128,  0.0289,  0.0427,  0.3325,  0.0640, -0.0353,\n",
      "          -0.1160, -0.0654, -0.1959,  0.0518,  0.0254,  0.1352,  0.0637,\n",
      "          -0.0803,  0.0247,  0.1506, -0.0387,  0.1502, -0.1461, -0.0677,\n",
      "          -0.0275,  0.1911,  0.0626, -0.0412,  0.0427, -0.0906, -0.0604,\n",
      "          -0.1393, -0.0795,  0.2699,  0.0732, -0.0303, -0.1142,  0.2364,\n",
      "           0.0695,  0.0911, -0.0093,  0.2046,  0.1233,  0.1573,  0.0383,\n",
      "           0.0865,  0.3503, -0.4125,  0.3750, -0.1466,  0.0358,  0.1864,\n",
      "           0.2996, -0.0073,  0.1100, -0.4180, -0.0516,  0.1704,  0.2407,\n",
      "          -0.2029,  0.3231,  0.2182,  0.2012, -0.0279,  0.1429,  0.0038,\n",
      "          -0.0847, -0.2763,  0.0166, -0.1437, -0.0281, -0.1666,  0.1626,\n",
      "          -0.0717,  0.1802, -0.1787,  0.0290, -0.0084,  0.1711,  0.1436,\n",
      "           0.0265,  0.0154,  0.0217,  0.2443, -0.1047, -0.0499, -0.1664,\n",
      "          -0.0565, -0.0859,  0.2376, -0.1727, -0.0992, -0.1155,  0.0410,\n",
      "          -0.1183, -0.0442, -0.1136, -0.1445, -0.0457,  0.0702,  0.1697,\n",
      "           0.0783,  0.2078,  0.0961,  0.0926,  0.0235,  0.0035,  0.0841,\n",
      "           0.1786, -0.0400, -0.0777,  0.0074,  0.1594, -0.0829,  0.0589,\n",
      "           0.2001,  0.0840, -0.0713,  0.1970, -0.0720, -0.0962,  0.1543,\n",
      "           0.3071, -0.1609,  0.0115,  0.2974, -0.2354,  0.2850, -0.1778,\n",
      "          -0.3101,  0.2127,  0.3262, -0.2370, -0.2330,  0.0345, -0.0706,\n",
      "          -0.2624, -0.1749,  0.0106,  0.0696, -0.2226, -0.1769,  0.1175,\n",
      "           0.0744,  0.2465, -0.0333,  0.0447, -0.1448,  0.0999,  0.2983,\n",
      "          -0.0840, -0.1361, -0.2439, -0.1783, -0.1174,  0.2270, -0.0116,\n",
      "          -0.1056,  0.1481,  0.2131, -0.1870]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.7275e-01, -4.3086e-01,  3.1541e-01, -1.0854e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.9148e+00,  1.3514e+00,  1.9012e-01,  6.1750e-01,\n",
      "           1.9038e+00,  6.0266e-01,  2.2917e-01, -9.1680e-01, -3.1846e+00,\n",
      "          -6.8301e-02, -1.6339e+00, -9.4357e-01,  0.0000e+00, -1.4360e+00,\n",
      "          -1.4035e-01, -5.2463e-01, -1.1202e+00, -2.5964e+00, -7.5979e-02,\n",
      "           1.3918e+00, -6.2010e-01,  1.9985e+00,  1.2775e-01,  5.5553e-01,\n",
      "           9.1622e-01, -3.9021e-03,  2.2225e-01,  2.0174e+00, -6.3579e-02,\n",
      "          -1.4087e+00, -1.1154e-01, -8.1734e-01,  0.0000e+00,  8.6211e-02,\n",
      "           8.6378e-01, -8.9924e-01,  1.0090e+00, -1.5643e+00,  1.9452e+00,\n",
      "          -3.0037e-01,  7.0674e-01, -6.0264e-01, -1.0210e+00,  0.0000e+00,\n",
      "          -1.3236e+00,  2.6787e+00,  6.6712e-01, -8.4713e-01,  2.2817e-01,\n",
      "           0.0000e+00, -1.4341e+00, -9.6089e-02,  1.2762e+00,  2.1826e+00,\n",
      "          -1.0069e+00,  3.5651e-02, -2.8019e-01,  2.6573e-01, -6.3318e-02,\n",
      "           3.9350e-01,  5.7823e-01,  1.1656e+00,  1.5813e+00, -1.4156e+00,\n",
      "           4.2731e-01,  2.9646e-01, -3.0927e-02, -7.9823e-01,  0.0000e+00,\n",
      "           0.0000e+00,  5.2605e-01,  0.0000e+00,  1.0275e+00, -7.9461e-01,\n",
      "           7.5871e-01, -1.0048e+00,  7.5861e-01,  1.0590e+00, -1.2161e+00,\n",
      "          -1.1337e-01, -1.1084e+00,  5.4875e-01, -9.4509e-01, -1.9016e+00,\n",
      "           5.2937e-01,  9.8771e-01,  1.7024e+00,  9.4446e-01,  6.0800e-01,\n",
      "          -1.5883e-02,  3.5451e-01, -1.1762e+00,  1.3729e+00,  2.4484e+00,\n",
      "           2.4339e-01,  4.3950e-02, -4.6670e-01, -9.8956e-01,  1.6416e+00,\n",
      "          -1.0243e+00,  3.0309e+00,  6.2096e-01, -1.0187e-01, -1.2358e+00,\n",
      "           1.9001e-01, -5.0350e-01, -5.7123e-01,  7.1275e-01, -7.8082e-01,\n",
      "           6.3272e-01,  4.0376e-01,  2.2333e-01, -2.3274e+00,  2.9192e-02,\n",
      "          -8.1502e-01, -1.4121e+00, -1.8390e+00,  0.0000e+00, -9.5751e-01,\n",
      "          -2.0117e-01,  0.0000e+00,  2.1511e+00,  0.0000e+00, -2.0886e+00,\n",
      "          -9.2633e-01,  4.5015e-01, -1.1686e+00,  4.2557e-01, -4.6824e-01,\n",
      "          -7.4670e-01, -1.0650e+00,  0.0000e+00, -1.9366e-02,  2.3983e+00,\n",
      "           6.9866e-01, -1.1220e+00,  1.6921e+00, -1.4048e-01, -6.7017e-01,\n",
      "           3.3024e-02,  7.6004e-01,  4.2281e-01, -1.0342e+00, -9.5200e-02,\n",
      "           1.5602e+00,  0.0000e+00, -3.3831e-01,  6.5792e-01,  1.8418e+00,\n",
      "          -2.5285e-01, -2.1813e-01,  6.2415e-01, -2.3644e+00,  1.0562e+00,\n",
      "           3.0298e-01, -7.7166e-02,  1.5537e-01, -1.2124e+00, -2.1926e-02,\n",
      "           0.0000e+00,  1.8531e+00,  0.0000e+00,  0.0000e+00, -7.1299e-01,\n",
      "          -1.2245e+00,  0.0000e+00, -2.5913e+00,  5.0606e-01, -3.0615e+00,\n",
      "          -2.8744e-01,  4.9754e-01,  8.2998e-01,  3.1708e-01, -7.9311e-01,\n",
      "           2.7287e-01,  2.3402e+00,  1.0587e+00,  8.3928e-01, -4.0227e-01,\n",
      "           7.2804e-01,  0.0000e+00,  0.0000e+00,  8.4358e-01, -1.8315e+00,\n",
      "           1.3638e+00,  2.1606e+00,  3.3566e-01, -1.0159e+00,  0.0000e+00,\n",
      "          -2.2167e+00,  1.6681e+00,  2.1538e+00,  3.6349e-01,  2.3838e+00,\n",
      "           3.2581e-02, -5.0173e-01, -1.2773e+00, -5.4318e-01, -4.0780e-01,\n",
      "          -1.4480e+00,  0.0000e+00,  0.0000e+00,  8.2931e-01, -1.5607e+00,\n",
      "           6.3742e-01,  6.7531e-01,  2.3990e+00,  5.5315e-02,  0.0000e+00,\n",
      "           1.3094e+00,  5.8018e-01, -2.3179e+00,  1.5505e+00, -2.2257e-01,\n",
      "          -2.2743e-01,  1.7347e+00,  2.7642e-01,  0.0000e+00,  9.2304e-01,\n",
      "          -1.2244e+00, -8.4917e-01, -1.8029e+00, -8.3582e-04,  3.7327e-01,\n",
      "          -1.5742e+00, -1.2402e-01,  9.6640e-01, -1.7379e+00,  1.6950e+00,\n",
      "           0.0000e+00,  6.3395e-01,  0.0000e+00,  9.8037e-01, -1.7174e+00,\n",
      "           0.0000e+00, -2.7314e-01, -2.5979e+00,  1.2394e+00,  0.0000e+00,\n",
      "           1.8868e+00, -5.0858e-01,  5.4280e-01, -2.6128e-01, -1.0227e+00,\n",
      "           1.3341e+00,  3.1157e-01, -5.0795e-02, -2.2871e-01, -1.6136e+00,\n",
      "           1.8073e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0494, 0.1210, 0.1767, 0.0720, 0.1651, 0.1016, 0.1362, 0.0622, 0.0651,\n",
      "         0.0507]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 0.3509, -0.0355,  0.0681,  ..., -0.1124, -0.0120, -0.4895],\n",
      "        [-0.1490,  0.1361, -0.0212,  ...,  0.2097,  0.1294, -0.3994],\n",
      "        [ 0.1326,  0.1723,  0.1677,  ...,  0.5342,  0.3806, -0.2515],\n",
      "        ...,\n",
      "        [ 0.7467,  0.6127, -0.7055,  ..., -0.3231,  0.0943,  0.1229],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 1.2979e-01,  9.9050e-02, -8.2839e-02, -3.4073e-02, -1.9859e-01,\n",
      "          -4.3876e-02, -1.8516e-01,  1.9147e-02,  8.2850e-02,  7.2304e-02,\n",
      "          -5.7835e-02,  7.7027e-03,  5.4805e-02,  1.0184e-02,  3.0295e-02,\n",
      "           2.1662e-01, -1.2852e-02,  2.9913e-01, -2.3746e-01,  2.3490e-01,\n",
      "          -3.0140e-01, -1.4086e-01, -3.2662e-02,  4.8731e-02, -1.9286e-01,\n",
      "           1.0206e-02,  9.1751e-02, -9.6231e-02, -2.6541e-01, -5.8473e-02,\n",
      "           9.5316e-02,  4.8370e-02,  7.8249e-02, -1.3897e-01,  7.8228e-02,\n",
      "          -2.8467e-01, -6.3693e-02, -1.6226e-02, -3.5143e-02, -1.8595e-02,\n",
      "           1.0437e-01, -7.2321e-02,  1.2337e-01, -2.8431e-02,  2.1569e-01,\n",
      "          -4.3227e-02,  2.9490e-01, -2.4158e-02,  2.4857e-01, -1.8843e-02,\n",
      "          -2.1613e-01, -2.8070e-04, -1.5001e-01, -3.6462e-02, -2.3690e-01,\n",
      "           9.3756e-02,  1.1574e-01,  1.4302e-01, -1.4095e-01,  2.5880e-01,\n",
      "           2.1113e-02, -2.3142e-01, -4.6050e-02,  2.5732e-01, -7.4477e-02,\n",
      "           7.5752e-02, -1.1480e-01, -1.4449e-01, -1.2558e-01, -1.0951e-01,\n",
      "           2.7988e-01,  1.8450e-01, -1.1190e-01,  9.9416e-02,  9.5374e-03,\n",
      "           1.6495e-02,  2.2001e-02, -9.6665e-04,  1.5833e-02,  3.7055e-02,\n",
      "          -1.3194e-01,  4.9236e-02, -4.8511e-02,  1.6028e-01,  2.5207e-02,\n",
      "           6.4027e-02, -1.8749e-02,  6.4220e-02,  1.6516e-02, -1.8364e-02,\n",
      "           7.4559e-02,  1.6601e-01, -2.7380e-02, -1.2401e-01,  2.1303e-01,\n",
      "           2.7941e-01,  2.9642e-02,  2.9712e-01, -3.9092e-02, -1.2497e-01,\n",
      "           7.2853e-02,  3.2007e-02,  3.5950e-01,  6.7510e-02, -1.0982e-02,\n",
      "          -9.7987e-02, -8.2609e-02, -1.8777e-01,  9.6827e-02,  4.6085e-02,\n",
      "           1.5618e-01,  7.6041e-02, -7.8020e-02,  4.0717e-02,  1.1168e-01,\n",
      "          -2.9681e-02,  1.4757e-01, -1.4228e-01, -6.2977e-02,  1.8805e-02,\n",
      "           2.0926e-01,  8.4226e-02, -7.5657e-02,  6.3929e-02, -9.0667e-02,\n",
      "          -5.4952e-02, -2.0494e-01, -8.4126e-02,  2.9917e-01,  3.8837e-02,\n",
      "           3.7831e-03, -1.2415e-01,  2.1955e-01,  9.6807e-02,  8.9452e-02,\n",
      "          -1.2087e-02,  1.9014e-01,  9.8297e-02,  1.1590e-01,  5.0151e-02,\n",
      "           6.9223e-02,  3.9604e-01, -4.9855e-01,  3.8112e-01, -1.2106e-01,\n",
      "           6.7468e-03,  1.7053e-01,  3.1515e-01,  3.9273e-02,  1.4445e-01,\n",
      "          -4.5046e-01, -4.0133e-02,  1.3820e-01,  2.3670e-01, -2.0712e-01,\n",
      "           3.2745e-01,  2.1629e-01,  2.0338e-01, -1.0871e-02,  1.6527e-01,\n",
      "          -3.4554e-02, -8.8233e-02, -2.9894e-01,  2.4190e-02, -1.4708e-01,\n",
      "          -4.7442e-03, -1.5072e-01,  1.6467e-01, -4.3261e-02,  1.7164e-01,\n",
      "          -1.9008e-01,  8.3046e-02, -2.0660e-02,  1.5553e-01,  1.1100e-01,\n",
      "           1.2174e-02,  3.8607e-02,  1.7057e-02,  2.6536e-01, -1.1981e-01,\n",
      "          -9.1642e-02, -1.8035e-01, -6.2671e-02, -6.6700e-02,  2.2442e-01,\n",
      "          -1.9481e-01, -1.2084e-01, -1.2743e-01,  3.7890e-02, -1.1297e-01,\n",
      "          -5.4251e-02, -6.1283e-02, -1.7599e-01, -3.4639e-02,  1.0462e-01,\n",
      "           1.7340e-01,  5.5512e-02,  1.9868e-01,  6.0475e-02,  1.0216e-01,\n",
      "           1.8369e-02, -8.5885e-03,  6.4038e-02,  1.8969e-01, -3.3969e-02,\n",
      "          -1.2283e-01,  1.8548e-02,  1.7751e-01, -1.1873e-01,  5.5031e-02,\n",
      "           1.7679e-01,  1.0276e-01, -6.9918e-02,  2.3530e-01, -7.9513e-02,\n",
      "          -5.0766e-02,  1.0183e-01,  3.2170e-01, -1.2608e-01,  3.3485e-02,\n",
      "           3.3470e-01, -2.4009e-01,  3.2031e-01, -2.0635e-01, -3.2780e-01,\n",
      "           1.6529e-01,  3.3982e-01, -2.5955e-01, -2.3613e-01,  5.5775e-02,\n",
      "          -7.1928e-02, -2.4203e-01, -1.8903e-01,  8.4362e-03,  6.4386e-02,\n",
      "          -2.2888e-01, -1.9606e-01,  1.3081e-01,  7.9992e-02,  2.7243e-01,\n",
      "          -4.6521e-02,  2.9077e-02, -1.1674e-01,  1.1068e-01,  2.8702e-01,\n",
      "          -9.7404e-02, -1.0929e-01, -2.4521e-01, -1.4478e-01, -1.0198e-01,\n",
      "           2.6504e-01, -2.6388e-02, -9.2864e-02,  1.6131e-01,  2.2196e-01,\n",
      "          -2.1223e-01]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 8.5626e-02,  3.9876e-01, -9.6737e-01, -6.8225e-01,  3.7659e-01,\n",
      "          -2.0169e-01,  1.4650e+00, -8.3204e-02, -3.5859e+00,  0.0000e+00,\n",
      "           4.2916e-01, -6.2944e-01,  2.6066e+00, -6.2972e-01, -5.4172e-01,\n",
      "           0.0000e+00,  8.5185e-01,  1.0952e+00,  4.5517e-01,  4.3615e-01,\n",
      "          -6.3393e-01, -3.8385e-01,  1.6425e+00,  1.5117e+00,  7.5409e-01,\n",
      "          -7.5263e-02, -1.8766e-01, -7.5902e-01,  1.6545e+00,  0.0000e+00,\n",
      "           1.2322e+00,  1.2193e+00,  0.0000e+00, -8.2616e-02, -1.5354e+00,\n",
      "           0.0000e+00,  2.8080e-01, -3.7465e+00,  1.9816e-01,  1.6018e+00,\n",
      "          -4.5884e-01,  0.0000e+00, -2.6828e-01, -1.7173e+00,  0.0000e+00,\n",
      "           6.6727e-01,  5.4126e-01,  3.6991e-01, -1.3412e+00,  1.4355e-01,\n",
      "          -6.2878e-01,  0.0000e+00,  6.1066e-01, -1.0300e+00,  0.0000e+00,\n",
      "           2.0284e-01, -8.8259e-01, -1.2536e+00,  0.0000e+00, -4.2511e-01,\n",
      "           1.1017e+00,  1.4088e+00, -2.0395e-01, -5.0222e-01, -2.9658e+00,\n",
      "           5.5035e-01,  1.2794e+00, -1.2887e+00,  4.1193e-01,  5.2637e-01,\n",
      "          -1.2680e+00, -3.0576e-02,  7.0763e-01, -3.6436e+00,  3.2676e-01,\n",
      "          -2.4870e-03, -1.5984e-01,  1.0635e+00, -5.8625e-02, -1.2041e-01,\n",
      "          -1.4009e+00,  2.1326e+00, -9.2526e-01,  1.0057e+00, -2.0799e-01,\n",
      "           4.3417e-01,  1.6623e+00, -9.7530e-01, -1.0299e-01,  0.0000e+00,\n",
      "          -2.2746e+00,  1.1007e+00, -6.2237e-01, -1.1354e+00,  4.6771e-01,\n",
      "          -1.1713e+00,  3.4548e-02,  6.2948e-01,  1.7210e+00, -7.8112e-01,\n",
      "           2.6984e+00, -1.4634e+00,  1.0762e+00,  1.4551e+00, -6.6678e-01,\n",
      "          -7.6259e-01,  1.2132e+00,  1.2754e-01, -1.4734e+00, -1.2890e-02,\n",
      "          -2.4906e-01,  1.3448e-01,  0.0000e+00,  1.3106e+00,  0.0000e+00,\n",
      "          -2.9913e+00, -5.6092e-02,  0.0000e+00, -1.9319e-01,  4.4459e-01,\n",
      "          -1.4676e+00,  7.0279e-01, -1.4612e+00,  0.0000e+00, -9.5903e-01,\n",
      "          -1.3100e+00,  8.9832e-01,  1.7071e-01,  0.0000e+00, -7.5302e-01,\n",
      "          -8.2309e-01,  5.2957e-01, -1.5838e+00,  9.8432e-01,  2.7617e-01,\n",
      "           0.0000e+00,  6.6028e-01,  5.7300e-01, -1.1585e+00,  0.0000e+00,\n",
      "          -3.8927e-01,  6.7784e-01, -7.9040e-01, -1.0209e-01, -1.6871e+00,\n",
      "          -1.0158e-01, -5.4345e-01, -8.4474e-01, -7.5564e-01,  1.7741e-01,\n",
      "           1.9996e+00, -1.9997e-01,  0.0000e+00, -4.0634e-01,  0.0000e+00,\n",
      "          -1.9450e-01, -6.3898e-02, -1.2875e-01,  3.9578e-02,  0.0000e+00,\n",
      "          -2.6003e-02,  2.2070e+00,  4.8120e-01, -5.4968e-01, -5.2802e-01,\n",
      "          -8.9335e-01,  2.8187e-01,  8.5058e-02, -3.5807e-01, -4.7828e-01,\n",
      "           7.3884e-01, -3.2845e-02,  0.0000e+00, -1.0021e+00,  1.2782e+00,\n",
      "          -1.0997e+00, -9.8841e-01, -2.0786e+00,  1.9704e+00,  8.6458e-02,\n",
      "          -2.9392e-02,  3.5083e-02,  6.7198e-01,  9.7992e-01, -7.4695e-01,\n",
      "          -3.4109e-01, -2.7850e+00, -7.8522e-01,  1.2104e+00,  1.0127e+00,\n",
      "           3.0764e+00,  4.9457e-01,  0.0000e+00, -5.9526e-01,  5.6099e-01,\n",
      "           2.1664e+00, -1.1888e+00,  5.3473e-01,  1.8131e+00,  0.0000e+00,\n",
      "          -1.6624e+00, -1.0151e+00,  1.2418e+00, -1.2206e-01,  2.3188e-01,\n",
      "          -5.7560e-01, -2.2939e+00,  6.8210e-01, -1.0753e+00,  0.0000e+00,\n",
      "           2.8697e+00, -5.7346e-01, -3.4118e-01,  7.9371e-01,  0.0000e+00,\n",
      "          -6.8538e-01, -1.0206e+00,  9.6625e-01, -2.4608e-01,  2.1708e+00,\n",
      "           0.0000e+00, -4.2767e-01, -1.8447e+00, -5.0197e-01,  3.3677e-01,\n",
      "           7.0482e-01, -6.9665e-01, -6.2815e-01,  2.9237e-01, -1.5796e+00,\n",
      "           0.0000e+00,  1.5820e+00, -6.1445e-01,  1.3100e+00, -2.9811e+00,\n",
      "           4.0375e+00,  5.8523e-01,  4.3675e-02, -1.5814e+00, -2.8781e-01,\n",
      "           0.0000e+00,  0.0000e+00, -3.0491e-01, -8.5305e-01,  1.1049e-02,\n",
      "           2.7524e-01,  2.7523e-01,  2.5285e-01,  2.6084e-01,  3.8676e-01,\n",
      "          -3.6568e-01, -1.5823e-01, -5.5430e-01, -5.2699e-02, -1.1475e+00,\n",
      "          -1.1317e+00]]], device='cuda:0', grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0529, 0.0445, 0.0712, 0.0610, 0.1456, 0.3542, 0.0559, 0.0729, 0.0519,\n",
      "         0.0901]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2895, -0.5080,  0.3528,  ...,  0.0061, -0.0199,  0.1255],\n",
      "        [-0.0516, -0.5458,  0.4906,  ..., -0.4028, -0.0006, -0.2205],\n",
      "        [ 0.0810, -0.2752, -0.2565,  ..., -0.3497, -0.3362,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.4312,  0.0824, -0.2128, -0.0318,  0.0700, -0.0129, -0.0478,\n",
      "           0.0045, -0.1808, -0.0278,  0.0555, -0.1002,  0.0222,  0.0926,\n",
      "           0.0044,  0.0628, -0.3561,  0.3757, -0.2915,  0.0719, -0.2257,\n",
      "          -0.2848,  0.1463, -0.0984,  0.1144,  0.0984, -0.0196, -0.2466,\n",
      "           0.0957, -0.1055,  0.3349, -0.1057, -0.0492, -0.2054, -0.2207,\n",
      "          -0.0061, -0.1111,  0.0828,  0.1129,  0.0894,  0.1364,  0.2164,\n",
      "          -0.3178,  0.0309, -0.0645,  0.1422, -0.1032, -0.1111,  0.0634,\n",
      "           0.1269, -0.1365, -0.0882, -0.1625,  0.0406, -0.0041,  0.2214,\n",
      "           0.0713,  0.0846,  0.1508,  0.3128,  0.0176, -0.1676, -0.1179,\n",
      "           0.2673,  0.0659,  0.2009, -0.1946,  0.3524, -0.3145,  0.1568,\n",
      "           0.1058,  0.2922, -0.0301, -0.0744, -0.2496,  0.2614,  0.3309,\n",
      "           0.1189,  0.1589,  0.3663, -0.0319,  0.1176,  0.0329, -0.0918,\n",
      "           0.0412, -0.1115,  0.3171,  0.0866,  0.3140,  0.1008, -0.0651,\n",
      "          -0.1549, -0.0904, -0.0566, -0.1973,  0.1692,  0.0804,  0.0528,\n",
      "           0.1723,  0.3138,  0.0473,  0.2266,  0.1156, -0.2075,  0.2198,\n",
      "          -0.0775,  0.0844,  0.2442, -0.1579,  0.0146,  0.1383,  0.1435,\n",
      "          -0.0972, -0.0083, -0.0827,  0.0622,  0.0299, -0.0669, -0.1639,\n",
      "          -0.1451,  0.1123,  0.0866, -0.2368,  0.3552, -0.2736, -0.1038,\n",
      "           0.0720, -0.1982,  0.0925, -0.2697, -0.0106, -0.0651,  0.0171,\n",
      "           0.1890,  0.0974,  0.0607,  0.1123,  0.2430, -0.0823,  0.3015,\n",
      "          -0.1700,  0.0182, -0.3029, -0.1108,  0.2087, -0.0123,  0.0465,\n",
      "           0.1976,  0.3324,  0.1628, -0.2363,  0.0343,  0.2262,  0.2020,\n",
      "           0.0427,  0.2071,  0.1084, -0.0404, -0.1251,  0.0916, -0.1419,\n",
      "          -0.0620, -0.2517,  0.1711,  0.0917,  0.0926,  0.0744,  0.2361,\n",
      "           0.0880,  0.2524, -0.2177,  0.2265,  0.0563,  0.1768, -0.1538,\n",
      "          -0.2230,  0.0084,  0.0729,  0.2111,  0.2168, -0.3437, -0.2056,\n",
      "          -0.2303,  0.1383, -0.0271,  0.0270, -0.1964,  0.1551, -0.0111,\n",
      "          -0.1807,  0.0611, -0.0041, -0.1538, -0.1137, -0.2616, -0.3297,\n",
      "           0.0726, -0.0597, -0.1479, -0.1104, -0.0536,  0.1398, -0.0583,\n",
      "           0.2936, -0.0247,  0.1036, -0.1904,  0.4353, -0.3266, -0.1400,\n",
      "           0.0198,  0.1296, -0.1957,  0.1853,  0.2018,  0.0543,  0.0576,\n",
      "          -0.0897, -0.0405,  0.1208,  0.1294, -0.0028, -0.0775,  0.0049,\n",
      "          -0.1489,  0.1588, -0.1066, -0.0944, -0.4135, -0.0298, -0.0050,\n",
      "           0.0138,  0.0259,  0.0332,  0.2090,  0.1602,  0.0484,  0.0228,\n",
      "           0.1986,  0.1007, -0.0945,  0.0237, -0.0258,  0.1218,  0.0996,\n",
      "          -0.2777, -0.0621,  0.0071,  0.1010, -0.2186,  0.1239,  0.2314,\n",
      "          -0.2950, -0.1961, -0.0385, -0.0188]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.1550, -1.4824,  1.6545, -1.0097, -1.1127,  0.4004,  0.6462,\n",
      "           0.0000, -0.9028,  0.0939, -0.2095,  0.3161,  0.1277, -0.9578,\n",
      "          -0.3088,  0.3245, -1.8657, -2.1366,  0.6084, -0.5296,  0.7694,\n",
      "           0.2828, -1.2564, -0.9733,  0.0000,  1.4268, -1.6559,  1.0544,\n",
      "           0.9847, -1.2881,  0.3071, -0.9457, -0.7692, -1.5225, -0.3685,\n",
      "           0.4846,  0.0000, -0.3514,  0.3283,  0.6285,  0.6071, -1.1772,\n",
      "           0.3731,  1.2540,  0.0000,  1.9479,  0.0000, -0.4432, -0.2786,\n",
      "           0.0000,  0.8656,  0.0000, -0.0720, -1.0045, -0.2960, -0.8050,\n",
      "          -1.8698,  0.5100,  1.5738,  0.0000, -0.8819,  0.0000,  1.9472,\n",
      "          -0.9067, -0.8595,  0.1077,  0.6393, -0.6176,  0.0218,  0.4296,\n",
      "           0.0000, -0.0286, -0.6439,  1.4252, -0.4459,  0.5582, -3.6203,\n",
      "           0.0000, -1.4070, -0.3115,  0.8703,  1.3130,  0.8814,  0.0000,\n",
      "           0.6941,  0.6926,  0.0458, -2.9903,  0.8149, -0.0185, -1.4911,\n",
      "           0.3247, -1.2890,  2.3927,  0.0000,  0.2152, -1.1098,  1.0777,\n",
      "           1.5512, -2.1251,  0.0145, -0.6645, -1.1343, -1.8823,  0.4074,\n",
      "           1.4169,  0.0000, -0.9152,  0.4128,  1.8171, -1.4329,  0.1793,\n",
      "           0.0000,  1.3011, -0.1470, -0.1097,  0.3372, -1.6434,  0.0000,\n",
      "          -1.2945, -1.3470, -0.0997,  0.8781,  0.5349,  0.0000,  0.8185,\n",
      "          -0.2017, -1.0698,  0.1251, -0.4280, -1.2473,  2.3284,  0.0000,\n",
      "           0.3275,  0.0000, -0.6388, -0.0632, -0.6001, -0.4515,  1.0982,\n",
      "           0.5454, -1.1805, -2.2955, -0.8864,  0.0000,  0.0000,  0.9175,\n",
      "           0.0000,  1.5431, -0.7185,  0.3218, -1.3513,  1.8150, -1.9314,\n",
      "           0.5130, -0.3342, -0.2283, -0.7583,  0.9339, -0.0176,  0.2299,\n",
      "          -1.1453,  2.2623, -1.7652, -0.3903, -0.6925,  0.0000,  2.1364,\n",
      "          -1.6408, -2.7426,  1.2552, -2.0863, -0.0068, -1.1604, -0.9214,\n",
      "          -0.7990, -0.3073,  0.0000,  0.1185, -1.5140,  0.1505, -0.4526,\n",
      "           0.1998,  0.9703,  0.4846, -0.0760, -1.5033, -0.2145,  0.4042,\n",
      "          -1.4629,  1.0722,  0.6062,  0.5037, -0.5086,  0.7254, -0.0425,\n",
      "           1.8721,  0.0419, -0.8382, -0.2757,  0.1196,  0.0000,  0.0000,\n",
      "           0.3538, -0.0091, -0.7151,  0.6958,  2.0169, -0.7504,  0.0000,\n",
      "           2.7906,  0.1560,  1.5050,  0.1015, -0.5908, -0.0232, -0.1430,\n",
      "          -1.3822,  0.4078,  0.6381,  0.0000,  1.8596,  0.0000,  0.4726,\n",
      "           0.0284,  1.5296, -0.3652, -0.2608,  0.8416,  0.0000,  0.7762,\n",
      "          -0.5523,  1.2385,  0.0932,  2.0766,  0.5544, -1.7045,  2.7795,\n",
      "          -1.4961,  1.8028, -0.8498,  0.2566, -1.0502, -0.8549,  0.0000,\n",
      "          -1.7795,  0.3819,  0.0000,  0.5689,  0.5473, -1.7501,  0.3685,\n",
      "           0.1555,  1.5691, -2.7269,  0.4076]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0270, 0.1360, 0.0915, 0.0421, 0.2450, 0.2355, 0.0494, 0.0516, 0.0686,\n",
      "         0.0534]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2895, -0.5080,  0.3528,  ...,  0.0061, -0.0199,  0.1255],\n",
      "        [-0.0516, -0.5458,  0.4906,  ..., -0.4028, -0.0006, -0.2205],\n",
      "        [ 0.0810, -0.2752, -0.2565,  ..., -0.3497, -0.3362,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 0.4019,  0.0469, -0.1548,  0.0459,  0.1072,  0.0528, -0.0120,\n",
      "           0.0445, -0.1499,  0.0649,  0.0640, -0.1087,  0.1188,  0.0265,\n",
      "          -0.0346,  0.0867, -0.3599,  0.3561, -0.1981,  0.0632, -0.2524,\n",
      "          -0.2740,  0.0819, -0.0982,  0.1423,  0.1125, -0.0803, -0.2431,\n",
      "           0.1144, -0.1528,  0.2849, -0.0582, -0.0365, -0.1472, -0.2187,\n",
      "           0.0407, -0.0306,  0.1393,  0.1908,  0.0516,  0.1694,  0.2052,\n",
      "          -0.3291,  0.0438, -0.0550,  0.0743, -0.0863, -0.0705, -0.0233,\n",
      "           0.1176, -0.1528, -0.1062, -0.1211,  0.0559,  0.0414,  0.2577,\n",
      "           0.1015,  0.0688,  0.1136,  0.3413,  0.0198, -0.1463, -0.0656,\n",
      "           0.2456,  0.1188,  0.2039, -0.1850,  0.3276, -0.2817,  0.1004,\n",
      "           0.0541,  0.2650, -0.0754, -0.1130, -0.2224,  0.2071,  0.2795,\n",
      "           0.1357,  0.1940,  0.3739, -0.0068,  0.1521,  0.1680, -0.1507,\n",
      "           0.0899, -0.1144,  0.3228,  0.0760,  0.2624,  0.0721, -0.1227,\n",
      "          -0.1635, -0.0919,  0.0310, -0.2687,  0.1600,  0.0274,  0.0351,\n",
      "           0.1531,  0.2859,  0.0437,  0.1888,  0.0923, -0.2409,  0.2086,\n",
      "          -0.0416,  0.0334,  0.1615, -0.1683, -0.0565,  0.1494,  0.1351,\n",
      "          -0.1380,  0.0255, -0.0663,  0.0292,  0.0219, -0.0442, -0.1221,\n",
      "          -0.1328,  0.1278,  0.1157, -0.1673,  0.3282, -0.2405, -0.0840,\n",
      "           0.0743, -0.1876,  0.0760, -0.2194, -0.0221, -0.0157,  0.0399,\n",
      "           0.1462,  0.1249,  0.0619,  0.1112,  0.2000, -0.0766,  0.2200,\n",
      "          -0.1177, -0.0907, -0.2881, -0.1425,  0.1824,  0.0140,  0.0390,\n",
      "           0.1317,  0.2916,  0.0914, -0.1272, -0.0019,  0.2775,  0.1799,\n",
      "          -0.0055,  0.1190,  0.1092, -0.0871, -0.1342,  0.1570, -0.0694,\n",
      "          -0.0378, -0.1667,  0.1098,  0.1679,  0.0792,  0.1546,  0.3028,\n",
      "           0.1336,  0.3050, -0.1488,  0.2594,  0.0250,  0.1473, -0.1325,\n",
      "          -0.1322,  0.0494,  0.0417,  0.1358,  0.3156, -0.3353, -0.2084,\n",
      "          -0.1793,  0.1939, -0.0996,  0.0497, -0.1742,  0.1279,  0.0169,\n",
      "          -0.0839,  0.0614, -0.0182, -0.0926, -0.1276, -0.2777, -0.3615,\n",
      "           0.0218, -0.0453, -0.1396, -0.1358, -0.0082,  0.1075, -0.0119,\n",
      "           0.2813, -0.0385,  0.1439, -0.1929,  0.4262, -0.3258, -0.0562,\n",
      "           0.1069,  0.1653, -0.1892,  0.1939,  0.2241,  0.0259,  0.0587,\n",
      "          -0.1503,  0.0194,  0.1556,  0.0730, -0.0089, -0.1196,  0.0315,\n",
      "          -0.1930,  0.1496, -0.1430, -0.0529, -0.3633, -0.0620, -0.0094,\n",
      "           0.0716,  0.1479,  0.0876,  0.2210,  0.1645,  0.1045,  0.0250,\n",
      "           0.1045,  0.1046, -0.0607,  0.0088, -0.0393,  0.0594,  0.0906,\n",
      "          -0.2304, -0.0277,  0.0714,  0.1453, -0.1885,  0.0899,  0.2747,\n",
      "          -0.3255, -0.1838, -0.1033, -0.0413]]], device='cuda:0',\n",
      "       grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2550,  0.7780, -1.6520, -0.1826, -0.7320,  2.5181, -1.9080,\n",
      "          -0.0326,  0.9502,  0.0000,  1.4103, -0.7568, -0.0649,  0.0644,\n",
      "           1.0464,  0.0000,  0.8701, -0.7849,  0.0000, -1.4036,  0.0000,\n",
      "          -0.3790,  1.1427,  0.2328,  0.1894, -0.6133,  1.4042, -0.1510,\n",
      "          -1.0411,  0.4960, -0.5710,  0.6008, -1.6987,  0.2319, -0.0796,\n",
      "           0.1481,  0.6452, -2.2134,  0.0000,  0.1024, -0.6923, -0.4369,\n",
      "          -1.0645,  0.8179, -0.6330, -0.6567,  1.3726,  0.9367,  1.6037,\n",
      "           0.3693, -1.0083,  0.0000, -1.1121,  1.2529,  0.0000,  1.7090,\n",
      "           0.5930,  0.0000,  0.3412, -0.2936,  0.0000,  0.0000, -0.5944,\n",
      "          -1.6816,  0.0000,  1.2343, -0.3577,  0.2896, -0.7528, -1.1646,\n",
      "           2.2476,  0.0000,  0.2704,  1.2052, -0.3977,  0.3547,  0.2291,\n",
      "           0.0000,  0.0000,  0.2960, -0.1448,  1.2865,  0.0000,  1.2969,\n",
      "           0.7706,  0.6606,  1.0451, -0.3684, -1.2409, -1.4364,  1.3109,\n",
      "          -1.5852, -0.1110,  3.2390,  0.3469,  1.0036, -0.8686,  0.7311,\n",
      "          -1.6816, -0.9243,  0.1903,  0.0286, -0.5963,  1.0585,  0.0000,\n",
      "           0.7758, -0.9057,  0.0000, -0.2786, -0.5475, -0.1378, -3.2779,\n",
      "          -0.1008, -1.8785,  1.6980,  1.6884,  2.0295, -1.6462, -0.8958,\n",
      "           2.5846, -1.3266,  1.4236, -0.6274,  0.0000,  1.3155, -0.9874,\n",
      "           0.0741, -0.9857, -0.6750,  0.0000, -1.2004,  1.1297,  1.1405,\n",
      "           1.4885,  0.3790,  0.6467, -0.8379,  0.0000,  0.0000, -1.2616,\n",
      "           0.0302,  0.8641,  0.5015,  0.9073, -1.2677, -0.6409, -0.4418,\n",
      "           0.8729, -0.0678,  0.0000, -0.0565,  0.6208,  0.1451, -0.1964,\n",
      "           0.0000, -1.6720, -0.4023,  0.2512, -2.0697,  0.4119,  1.1553,\n",
      "           0.1996,  0.9131,  0.8436,  0.4172,  1.6037,  0.1770, -1.1141,\n",
      "          -0.3225,  0.2508,  0.0000, -0.4552,  0.4446, -1.3454,  1.7359,\n",
      "           0.0000,  0.0000,  0.2895, -1.8322, -1.8660,  0.2594,  0.0000,\n",
      "          -1.1657,  0.3287, -0.7439,  0.5919, -1.2417, -1.5176, -2.3037,\n",
      "           0.1464, -1.6242, -1.3212, -0.0501,  1.2996,  0.9805, -1.4147,\n",
      "          -1.1405,  3.0134, -0.2259,  1.0325,  0.0294,  0.1189, -1.3199,\n",
      "          -1.0707,  0.0567,  1.7331,  0.5268,  1.9822,  0.0000, -1.3425,\n",
      "           1.5993, -0.4015,  2.4610, -0.5197,  0.7546,  0.2063, -0.8211,\n",
      "           0.9055, -3.5306,  0.1759,  0.0000,  0.0000, -1.4185,  0.0000,\n",
      "          -0.0648, -1.4656,  0.4272, -0.5200,  0.0462, -0.6254,  0.0000,\n",
      "           0.0000, -2.0269, -1.0489, -0.4316, -0.1122,  0.5161, -2.7972,\n",
      "          -1.4576, -0.6645,  1.0257,  0.1326,  2.7512,  1.0026,  0.5471,\n",
      "          -0.1735, -1.5052,  0.0000,  1.1875, -0.0479,  0.7230,  0.1090,\n",
      "          -2.8554, -0.0139, -0.8378, -0.5803]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0370, 0.1581, 0.1084, 0.1203, 0.1347, 0.1117, 0.0670, 0.0869, 0.0918,\n",
      "         0.0842]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2895, -0.5080,  0.3528,  ...,  0.0061, -0.0199,  0.1255],\n",
      "        [-0.0516, -0.5458,  0.4906,  ..., -0.4028, -0.0006, -0.2205],\n",
      "        [ 0.0810, -0.2752, -0.2565,  ..., -0.3497, -0.3362,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[ 2.9608e-01, -6.2832e-02, -7.9896e-02,  7.4939e-02,  6.6028e-02,\n",
      "           7.2480e-02,  5.7310e-02,  5.5592e-02, -9.1251e-02,  1.0256e-01,\n",
      "           5.2112e-02, -1.0800e-01,  1.4057e-01, -7.6294e-02, -4.6236e-03,\n",
      "           2.2367e-02, -3.2339e-01,  3.1997e-01, -1.3564e-01,  4.2336e-02,\n",
      "          -2.6317e-01, -2.3123e-01,  5.2677e-02, -7.1590e-02,  8.5719e-02,\n",
      "           1.5547e-01, -1.7223e-01, -1.9985e-01,  1.3580e-01, -1.9188e-01,\n",
      "           1.9984e-01,  1.4537e-02, -6.2165e-02, -5.5836e-02, -1.2995e-01,\n",
      "           5.9981e-02,  1.5129e-02,  1.1715e-01,  1.5260e-01, -4.6159e-02,\n",
      "           2.1364e-01,  1.1221e-01, -3.1555e-01,  3.0012e-02, -4.0614e-02,\n",
      "           5.8687e-02, -3.5395e-02, -4.0500e-02, -8.0313e-02,  8.3010e-02,\n",
      "          -2.1933e-01, -1.2162e-01, -7.7775e-02,  8.9373e-02,  7.5370e-02,\n",
      "           2.0808e-01,  7.3702e-02,  6.5794e-02,  5.5319e-02,  2.8486e-01,\n",
      "           2.4529e-02, -1.5076e-01,  1.5799e-02,  1.7863e-01,  1.5418e-01,\n",
      "           1.6358e-01, -1.6303e-01,  2.6180e-01, -1.9013e-01,  7.5620e-02,\n",
      "           1.4661e-02,  2.0178e-01, -1.1468e-01, -7.8064e-02, -1.7037e-01,\n",
      "           1.3611e-01,  2.0089e-01,  1.2786e-01,  1.5804e-01,  2.8849e-01,\n",
      "          -6.0566e-03,  8.3452e-02,  2.1281e-01, -1.6056e-01,  1.1173e-01,\n",
      "          -4.1262e-02,  2.4842e-01,  1.0232e-01,  2.2040e-01,  4.6985e-03,\n",
      "          -1.6665e-01, -9.8566e-02, -3.7021e-02,  5.6557e-02, -2.6977e-01,\n",
      "           1.6511e-01,  3.1015e-02,  6.8077e-02,  9.5886e-02,  2.8306e-01,\n",
      "          -1.2759e-02,  1.4875e-01,  4.2162e-02, -2.3586e-01,  9.7654e-02,\n",
      "           4.4137e-02, -2.0851e-02,  2.4441e-02, -1.0353e-01, -3.6402e-02,\n",
      "           1.7530e-01,  8.4238e-02, -8.2842e-02,  3.0507e-02, -4.4351e-02,\n",
      "          -6.8569e-02,  5.1749e-03, -3.4375e-02, -6.5870e-02, -1.4114e-01,\n",
      "           1.0127e-01,  5.1720e-02, -8.7218e-02,  2.4099e-01, -1.8424e-01,\n",
      "          -6.8054e-02,  4.2236e-02, -1.5133e-01,  6.5897e-02, -1.2709e-01,\n",
      "           6.1628e-03,  7.0096e-03,  1.2427e-01,  1.1229e-01,  1.1339e-01,\n",
      "           1.8848e-02,  9.8535e-02,  1.1157e-01, -6.6629e-02,  1.4995e-01,\n",
      "          -7.7231e-02, -1.5378e-01, -2.1593e-01, -1.1468e-01,  1.5592e-01,\n",
      "           7.5705e-02,  1.5771e-03,  2.8792e-02,  2.1946e-01, -2.6963e-02,\n",
      "          -1.4613e-02, -3.5066e-02,  2.3965e-01,  1.2998e-01, -2.7244e-02,\n",
      "           4.6630e-02,  6.0534e-02, -3.3559e-02, -9.4750e-02,  1.3588e-01,\n",
      "           2.9935e-03, -3.5716e-02, -9.4252e-02,  9.1941e-02,  1.6072e-01,\n",
      "           1.2661e-01,  1.6500e-01,  2.8952e-01,  1.6379e-01,  2.9673e-01,\n",
      "          -1.1631e-01,  2.6356e-01, -1.0704e-02,  7.6457e-02, -8.9283e-02,\n",
      "          -3.5534e-02,  4.3513e-02,  3.5337e-02,  8.4521e-02,  2.7910e-01,\n",
      "          -2.9176e-01, -1.9458e-01, -6.5348e-02,  1.7106e-01, -9.2109e-02,\n",
      "           1.3495e-02, -1.4864e-01,  3.6737e-02,  1.9635e-02, -4.1137e-02,\n",
      "           6.5490e-02,  2.6175e-02, -1.0837e-01, -9.9790e-02, -2.7785e-01,\n",
      "          -3.5621e-01,  1.0651e-02, -3.3764e-02, -1.5671e-01, -1.1563e-01,\n",
      "           3.9129e-02,  3.5764e-02, -1.8573e-02,  2.0189e-01, -4.3315e-02,\n",
      "           9.1260e-02, -1.5308e-01,  3.3537e-01, -2.4638e-01, -6.7345e-02,\n",
      "           9.8836e-02,  1.4463e-01, -1.5115e-01,  2.0952e-01,  1.6022e-01,\n",
      "           3.0153e-02,  6.5063e-03, -1.6243e-01,  4.8946e-02,  1.7004e-01,\n",
      "           2.2697e-02, -1.7404e-02, -1.0550e-01,  8.7597e-02, -1.4137e-01,\n",
      "           9.4077e-02, -1.2125e-01, -1.6539e-02, -3.2717e-01,  1.9846e-02,\n",
      "           3.0622e-04,  9.6969e-02,  1.7717e-01,  5.3254e-02,  1.2510e-01,\n",
      "           1.6056e-01,  5.6511e-02,  1.1331e-02,  7.0789e-02,  9.2238e-02,\n",
      "           3.2688e-02, -1.3396e-02,  4.9814e-04, -2.5489e-02,  3.4554e-02,\n",
      "          -1.2080e-01,  5.1555e-02,  5.4234e-02,  1.6568e-01, -1.2606e-01,\n",
      "           4.3473e-03,  2.1573e-01, -3.1439e-01, -1.9114e-01, -1.0537e-01,\n",
      "          -2.9487e-02]]], device='cuda:0', grad_fn=<BmmBackward>)\n",
      "embedded size\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.2550,  0.7780, -1.6520, -0.1826, -0.7320,  2.5181,  0.0000,\n",
      "          -0.0326,  0.9502,  1.1945,  1.4103, -0.7568, -0.0649,  0.0644,\n",
      "           1.0464,  0.0000,  0.0000, -0.7849, -0.6404, -1.4036,  0.0000,\n",
      "          -0.3790,  1.1427,  0.2328,  0.0000, -0.6133,  1.4042, -0.1510,\n",
      "          -1.0411,  0.0000, -0.5710,  0.6008, -1.6987,  0.2319, -0.0796,\n",
      "           0.1481,  0.6452, -2.2134,  1.0516,  0.1024,  0.0000, -0.4369,\n",
      "          -1.0645,  0.8179, -0.6330,  0.0000,  0.0000,  0.9367,  1.6037,\n",
      "           0.3693, -1.0083, -1.1717, -1.1121,  1.2529, -1.9746,  1.7090,\n",
      "           0.5930, -1.8921,  0.3412, -0.2936, -0.7705,  1.8690, -0.5944,\n",
      "          -1.6816, -0.8355,  1.2343, -0.3577,  0.2896, -0.7528, -1.1646,\n",
      "           0.0000,  0.7809,  0.2704,  1.2052, -0.3977,  0.0000,  0.2291,\n",
      "          -0.1575, -0.9147,  0.2960, -0.1448,  1.2865,  0.4651,  1.2969,\n",
      "           0.0000,  0.6606,  1.0451, -0.3684, -1.2409, -1.4364,  1.3109,\n",
      "           0.0000, -0.1110,  3.2390,  0.3469,  1.0036, -0.8686,  0.7311,\n",
      "          -1.6816, -0.9243,  0.1903,  0.0286, -0.5963,  1.0585, -0.2309,\n",
      "           0.7758, -0.9057, -0.3676, -0.2786, -0.5475, -0.1378, -3.2779,\n",
      "          -0.1008, -1.8785,  1.6980,  1.6884,  0.0000, -1.6462, -0.8958,\n",
      "           0.0000, -1.3266,  1.4236, -0.6274,  0.4668,  1.3155, -0.9874,\n",
      "           0.0741, -0.9857,  0.0000,  0.2478, -1.2004,  1.1297,  1.1405,\n",
      "           1.4885,  0.3790,  0.6467,  0.0000,  0.2411,  0.3448, -1.2616,\n",
      "           0.0302,  0.8641,  0.5015,  0.9073, -1.2677, -0.6409, -0.4418,\n",
      "           0.8729, -0.0678,  0.0424, -0.0565,  0.6208,  0.1451, -0.1964,\n",
      "           0.1075, -1.6720, -0.4023,  0.2512, -2.0697,  0.4119,  0.0000,\n",
      "           0.1996,  0.9131,  0.8436,  0.4172,  0.0000,  0.1770, -1.1141,\n",
      "          -0.3225,  0.2508,  0.4452, -0.4552,  0.4446,  0.0000,  1.7359,\n",
      "           0.5175,  0.0000,  0.2895, -1.8322, -1.8660,  0.2594,  0.0000,\n",
      "          -1.1657,  0.3287, -0.7439,  0.5919, -1.2417,  0.0000, -2.3037,\n",
      "           0.1464,  0.0000, -1.3212, -0.0501,  1.2996,  0.9805, -1.4147,\n",
      "          -1.1405,  3.0134, -0.2259,  1.0325,  0.0294,  0.1189, -1.3199,\n",
      "          -1.0707,  0.0567,  1.7331,  0.5268,  1.9822, -0.9787,  0.0000,\n",
      "           1.5993, -0.4015,  2.4610, -0.5197,  0.7546,  0.2063, -0.8211,\n",
      "           0.9055, -3.5306,  0.1759, -0.7814,  0.0000, -1.4185,  0.2512,\n",
      "          -0.0648, -1.4656,  0.4272, -0.5200,  0.0462,  0.0000, -0.0712,\n",
      "           0.7483, -2.0269, -1.0489, -0.4316, -0.1122,  0.5161, -2.7972,\n",
      "          -1.4576, -0.6645,  1.0257,  0.1326,  2.7512,  1.0026,  0.5471,\n",
      "          -0.1735, -1.5052,  2.2318,  0.0000, -0.0479,  0.7230,  0.1090,\n",
      "          -2.8554, -0.0139, -0.8378, -0.5803]]], device='cuda:0',\n",
      "       grad_fn=<FusedDropoutBackward>)\n",
      "attn_weights size\n",
      "torch.Size([1, 10])\n",
      "tensor([[0.0406, 0.1547, 0.1214, 0.0938, 0.1393, 0.1298, 0.0717, 0.0870, 0.0942,\n",
      "         0.0676]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "encoder_outputs size\n",
      "torch.Size([10, 256])\n",
      "tensor([[-0.2895, -0.5080,  0.3528,  ...,  0.0061, -0.0199,  0.1255],\n",
      "        [-0.0516, -0.5458,  0.4906,  ..., -0.4028, -0.0006, -0.2205],\n",
      "        [ 0.0810, -0.2752, -0.2565,  ..., -0.3497, -0.3362,  0.1388],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "attn_aplied size\n",
      "torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-7ea4b06f8a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-29eaa6fdc28a>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-77785d753587>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m---> 40\u001b[0;31m                 decoder_input, decoder_hidden, encoder_outputs)\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# detach from history as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/miniconda3/envs/pytorch-venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-dc4ce285e729>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attn_aplied size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_applied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_applied\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/miniconda3/envs/pytorch-venv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/miniconda3/envs/pytorch-venv/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/miniconda3/envs/pytorch-venv/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/miniconda3/envs/pytorch-venv/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                         \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'{{:.{}f}}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/miniconda3/envs/pytorch-venv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    466\u001b[0m                           \u001b[0;34m'iterations executed (and might lead to errors or silently give '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                           'incorrect results).', category=RuntimeWarning)\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis assez bon nageur .\n",
      "= i m a pretty good swimmer .\n",
      "< i m pretty good good swimmer . <EOS>\n",
      "\n",
      "> je suis en train de faire mes devoirs .\n",
      "= i am doing my homework .\n",
      "< i am doing my homework . <EOS>\n",
      "\n",
      "> nous sommes toutes dingues .\n",
      "= we re all crazy .\n",
      "< we re all crazy . <EOS>\n",
      "\n",
      "> il est irrealiste .\n",
      "= he is unrealistic .\n",
      "< he is loaded . <EOS>\n",
      "\n",
      "> je suis content de la voir .\n",
      "= i am glad to see her .\n",
      "< i m glad to see . <EOS>\n",
      "\n",
      "> j en ai marre des devoirs !\n",
      "= i m fed up with homework .\n",
      "< i m fed up with ! <EOS>\n",
      "\n",
      "> vous etes fort courageuse .\n",
      "= you re very brave .\n",
      "< you re very brave . <EOS>\n",
      "\n",
      "> nous ne sommes pas en securite .\n",
      "= we re not safe .\n",
      "< we re not safe . <EOS>\n",
      "\n",
      "> il a l habitude de realiser des discours .\n",
      "= he is used to making speeches .\n",
      "< he is used to making making . <EOS>\n",
      "\n",
      "> je cherche quelqu un .\n",
      "= i m looking for someone .\n",
      "< i am looking for a . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Attention\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
    "\n",
    "You could simply run ``plt.matshow(attentions)`` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb508bf6dd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = elle a cinq ans de moins que moi .\n",
      "output = she s five years younger than me . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = elle est trop petit .\n",
      "output = she s too generous . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = je ne crains pas de mourir .\n",
      "output = i m not going to die . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = c est un jeune directeur plein de talent .\n",
      "output = he is a talented young director . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "* Try with a different dataset\n",
    "    * Another language pair\n",
    "    * Human → Machine (e.g. IOT commands)\n",
    "    * Chat → Response\n",
    "    * Question → Answer\n",
    "* Replace the embeddings with pre-trained word embeddings such as word2vec or GloVe\n",
    "* Try with more layers, more hidden units, and more sentences. Compare the training time and results.\n",
    "* If you use a translation file where pairs have two of the same phrase (I am test \\t I am test), you can use this as an autoencoder. Try this:\n",
    "    * Train as an autoencoder\n",
    "    * Save only the Encoder network\n",
    "    * Train a new Decoder for translation from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
